2020-12-31 09:42:46  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 09:42:46  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 09:42:46  [ main:62 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 09:42:46  [ main:391 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 09:42:46  [ main:522 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 09:42:46  [ main:612 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 09:42:46  [ main:613 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 09:42:46  [ main:613 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 09:42:46  [ main:614 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 09:42:46  [ main:614 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 09:42:47  [ main:1009 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50165.
2020-12-31 09:42:47  [ main:1037 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 09:42:47  [ main:1062 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 09:42:47  [ main:1064 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 09:42:47  [ main:1064 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 09:42:47  [ main:1079 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-27620848-cd1a-4cbf-9f36-372b657927d7
2020-12-31 09:42:47  [ main:1106 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 09:42:47  [ main:1125 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 09:42:47  [ main:1230 ] - [ INFO ]  Logging initialized @2153ms
2020-12-31 09:42:47  [ main:1294 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 09:42:47  [ main:1310 ] - [ INFO ]  Started @2234ms
2020-12-31 09:42:47  [ main:1328 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 09:42:47  [ main:1329 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 09:42:47  [ main:1348 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1349 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1350 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1351 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1351 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1352 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1352 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1354 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1354 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1355 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1356 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1356 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1357 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1358 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1358 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1359 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1360 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1360 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1361 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1362 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1369 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1370 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1371 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1371 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1372 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 09:42:47  [ main:1373 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 09:42:47  [ main:1492 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 09:42:47  [ main:1553 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50166.
2020-12-31 09:42:47  [ main:1554 ] - [ INFO ]  Server created on 192.168.3.166:50166
2020-12-31 09:42:47  [ main:1556 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 09:42:47  [ main:1582 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50166, None)
2020-12-31 09:42:47  [ dispatcher-event-loop-10:1585 ] - [ INFO ]  Registering block manager 192.168.3.166:50166 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50166, None)
2020-12-31 09:42:47  [ main:1587 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50166, None)
2020-12-31 09:42:47  [ main:1588 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50166, None)
2020-12-31 09:42:47  [ main:1750 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 09:42:48  [ main:2185 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 09:42:48  [ main:2332 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 09:42:48  [ dispatcher-event-loop-12:2334 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50166 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 09:42:48  [ main:2337 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:14
2020-12-31 09:42:48  [ main:2487 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 09:42:48  [ main:2545 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:50
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2564 ] - [ INFO ]  Registering RDD 2 (repartition at TransformationRDD.scala:46)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2566 ] - [ INFO ]  Registering RDD 7 (map at TransformationRDD.scala:48)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2568 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:50) with 1 output partitions
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2568 ] - [ INFO ]  Final stage: ResultStage 2 (foreach at TransformationRDD.scala:50)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2569 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 1)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2570 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 1)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2575 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at repartition at TransformationRDD.scala:46), which has no missing parents
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2618 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 2004.4 MB)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2621 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.1 KB, free 2004.4 MB)
2020-12-31 09:42:48  [ dispatcher-event-loop-13:2622 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50166 (size: 3.1 KB, free: 2004.6 MB)
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2623 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2641 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at repartition at TransformationRDD.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 09:42:48  [ dag-scheduler-event-loop:2642 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 09:42:48  [ dispatcher-event-loop-14:2690 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 09:42:48  [ dispatcher-event-loop-14:2692 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 09:42:48  [ Executor task launch worker for task 0:2701 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 09:42:48  [ Executor task launch worker for task 1:2702 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 09:42:49  [ Executor task launch worker for task 1:3034 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 09:42:49  [ Executor task launch worker for task 0:3034 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 09:42:49  [ Executor task launch worker for task 0:3371 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1031 bytes result sent to driver
2020-12-31 09:42:49  [ Executor task launch worker for task 1:3371 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1031 bytes result sent to driver
2020-12-31 09:42:49  [ task-result-getter-0:3378 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 699 ms on localhost (executor driver) (1/2)
2020-12-31 09:42:49  [ task-result-getter-1:3380 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 688 ms on localhost (executor driver) (2/2)
2020-12-31 09:42:49  [ task-result-getter-1:3380 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3388 ] - [ INFO ]  ShuffleMapStage 0 (repartition at TransformationRDD.scala:46) finished in 0.795 s
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3388 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3389 ] - [ INFO ]  running: Set()
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3389 ] - [ INFO ]  waiting: Set(ShuffleMapStage 1, ResultStage 2)
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3389 ] - [ INFO ]  failed: Set()
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3393 ] - [ INFO ]  Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:48), which has no missing parents
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3406 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.4 KB, free 2004.4 MB)
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3408 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KB, free 2004.4 MB)
2020-12-31 09:42:49  [ dispatcher-event-loop-3:3408 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50166 (size: 3.1 KB, free: 2004.6 MB)
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3409 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3411 ] - [ INFO ]  Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:48) (first 15 tasks are for partitions Vector(0))
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3411 ] - [ INFO ]  Adding task set 1.0 with 1 tasks
2020-12-31 09:42:49  [ dispatcher-event-loop-4:3436 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7406 bytes)
2020-12-31 09:42:49  [ Executor task launch worker for task 2:3436 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 09:42:49  [ Executor task launch worker for task 2:3487 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 09:42:49  [ Executor task launch worker for task 2:3488 ] - [ INFO ]  Started 0 remote fetches in 6 ms
2020-12-31 09:42:49  [ Executor task launch worker for task 2:3524 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1160 bytes result sent to driver
2020-12-31 09:42:49  [ task-result-getter-2:3525 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 111 ms on localhost (executor driver) (1/1)
2020-12-31 09:42:49  [ task-result-getter-2:3525 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3526 ] - [ INFO ]  ShuffleMapStage 1 (map at TransformationRDD.scala:48) finished in 0.126 s
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3526 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3526 ] - [ INFO ]  running: Set()
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3526 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3526 ] - [ INFO ]  failed: Set()
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3527 ] - [ INFO ]  Submitting ResultStage 2 (ShuffledRDD[8] at sortByKey at TransformationRDD.scala:49), which has no missing parents
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3530 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 2004.3 MB)
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3531 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.3 MB)
2020-12-31 09:42:49  [ dispatcher-event-loop-7:3532 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:50166 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3532 ] - [ INFO ]  Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3533 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[8] at sortByKey at TransformationRDD.scala:49) (first 15 tasks are for partitions Vector(0))
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3533 ] - [ INFO ]  Adding task set 2.0 with 1 tasks
2020-12-31 09:42:49  [ dispatcher-event-loop-8:3535 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 09:42:49  [ Executor task launch worker for task 3:3535 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 3)
2020-12-31 09:42:49  [ Executor task launch worker for task 3:3539 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2020-12-31 09:42:49  [ Executor task launch worker for task 3:3539 ] - [ INFO ]  Started 0 remote fetches in 0 ms
2020-12-31 09:42:49  [ Executor task launch worker for task 3:3575 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 3). 1101 bytes result sent to driver
2020-12-31 09:42:49  [ task-result-getter-3:3576 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 3) in 42 ms on localhost (executor driver) (1/1)
2020-12-31 09:42:49  [ task-result-getter-3:3576 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 09:42:49  [ dag-scheduler-event-loop:3577 ] - [ INFO ]  ResultStage 2 (foreach at TransformationRDD.scala:50) finished in 0.049 s
2020-12-31 09:42:49  [ main:3582 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:50, took 1.035760 s
2020-12-31 09:42:49  [ Thread-1:3585 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 09:42:49  [ Thread-1:3594 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 09:42:49  [ Thread-1:3595 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 09:42:49  [ dispatcher-event-loop-13:3602 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 09:42:49  [ Thread-1:3613 ] - [ INFO ]  MemoryStore cleared
2020-12-31 09:42:49  [ Thread-1:3614 ] - [ INFO ]  BlockManager stopped
2020-12-31 09:42:49  [ Thread-1:3625 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 09:42:49  [ dispatcher-event-loop-1:3627 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 09:42:49  [ Thread-1:3634 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 09:42:49  [ Thread-1:3635 ] - [ INFO ]  Shutdown hook called
2020-12-31 09:42:49  [ Thread-1:3635 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-b6a97285-58f3-4c09-8fd6-f2f61af84ebc
2020-12-31 09:44:56  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 09:44:56  [ main:0 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 09:44:56  [ main:43 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 09:44:56  [ main:237 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 09:44:56  [ main:317 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 09:44:56  [ main:382 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 09:44:56  [ main:383 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 09:44:56  [ main:384 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 09:44:56  [ main:385 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 09:44:56  [ main:385 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 09:44:57  [ main:720 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50191.
2020-12-31 09:44:57  [ main:741 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 09:44:57  [ main:759 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 09:44:57  [ main:761 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 09:44:57  [ main:762 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 09:44:57  [ main:774 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-de816c61-0922-4899-9508-52847800affe
2020-12-31 09:44:57  [ main:794 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 09:44:57  [ main:808 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 09:44:57  [ main:880 ] - [ INFO ]  Logging initialized @1660ms
2020-12-31 09:44:57  [ main:926 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 09:44:57  [ main:939 ] - [ INFO ]  Started @1719ms
2020-12-31 09:44:57  [ main:954 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 09:44:57  [ main:954 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 09:44:57  [ main:977 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:978 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:978 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:984 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:987 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:988 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:988 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:989 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:992 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:992 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:998 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:999 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:999 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:1000 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 09:44:57  [ main:1001 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 09:44:57  [ main:1101 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 09:44:57  [ main:1160 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50193.
2020-12-31 09:44:57  [ main:1161 ] - [ INFO ]  Server created on 192.168.3.166:50193
2020-12-31 09:44:57  [ main:1163 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 09:44:57  [ main:1183 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50193, None)
2020-12-31 09:44:57  [ dispatcher-event-loop-10:1186 ] - [ INFO ]  Registering block manager 192.168.3.166:50193 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50193, None)
2020-12-31 09:44:57  [ main:1187 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50193, None)
2020-12-31 09:44:57  [ main:1188 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50193, None)
2020-12-31 09:44:57  [ main:1294 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 09:44:58  [ main:1667 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 09:44:58  [ main:1855 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 09:44:58  [ dispatcher-event-loop-12:1857 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50193 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 09:44:58  [ main:1860 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:14
2020-12-31 09:44:58  [ main:1976 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 09:44:58  [ main:2019 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:50
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2033 ] - [ INFO ]  Registering RDD 2 (repartition at TransformationRDD.scala:46)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2034 ] - [ INFO ]  Registering RDD 7 (map at TransformationRDD.scala:48)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2036 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:50) with 1 output partitions
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2036 ] - [ INFO ]  Final stage: ResultStage 2 (foreach at TransformationRDD.scala:50)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2036 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 1)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2038 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 1)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2042 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at repartition at TransformationRDD.scala:46), which has no missing parents
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2071 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 2004.4 MB)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2073 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.1 KB, free 2004.4 MB)
2020-12-31 09:44:58  [ dispatcher-event-loop-13:2073 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50193 (size: 3.1 KB, free: 2004.6 MB)
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2074 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2086 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at repartition at TransformationRDD.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 09:44:58  [ dag-scheduler-event-loop:2087 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 09:44:58  [ dispatcher-event-loop-14:2118 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 09:44:58  [ dispatcher-event-loop-14:2120 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 09:44:58  [ Executor task launch worker for task 0:2126 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 09:44:58  [ Executor task launch worker for task 1:2127 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 09:44:58  [ Executor task launch worker for task 1:2374 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 09:44:58  [ Executor task launch worker for task 0:2374 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 09:44:59  [ Executor task launch worker for task 0:2589 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1031 bytes result sent to driver
2020-12-31 09:44:59  [ Executor task launch worker for task 1:2589 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1031 bytes result sent to driver
2020-12-31 09:44:59  [ task-result-getter-0:2598 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 486 ms on localhost (executor driver) (1/2)
2020-12-31 09:44:59  [ task-result-getter-1:2600 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 480 ms on localhost (executor driver) (2/2)
2020-12-31 09:44:59  [ task-result-getter-1:2601 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2609 ] - [ INFO ]  ShuffleMapStage 0 (repartition at TransformationRDD.scala:46) finished in 0.555 s
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2610 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2610 ] - [ INFO ]  running: Set()
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2611 ] - [ INFO ]  waiting: Set(ShuffleMapStage 1, ResultStage 2)
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2611 ] - [ INFO ]  failed: Set()
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2616 ] - [ INFO ]  Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:48), which has no missing parents
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2628 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.4 KB, free 2004.4 MB)
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2629 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KB, free 2004.4 MB)
2020-12-31 09:44:59  [ dispatcher-event-loop-3:2630 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50193 (size: 3.1 KB, free: 2004.6 MB)
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2631 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2633 ] - [ INFO ]  Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:48) (first 15 tasks are for partitions Vector(0))
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2633 ] - [ INFO ]  Adding task set 1.0 with 1 tasks
2020-12-31 09:44:59  [ dispatcher-event-loop-4:2654 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7406 bytes)
2020-12-31 09:44:59  [ Executor task launch worker for task 2:2655 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 09:44:59  [ Executor task launch worker for task 2:2707 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 09:44:59  [ Executor task launch worker for task 2:2709 ] - [ INFO ]  Started 0 remote fetches in 6 ms
2020-12-31 09:44:59  [ Executor task launch worker for task 2:2744 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1160 bytes result sent to driver
2020-12-31 09:44:59  [ task-result-getter-2:2745 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 109 ms on localhost (executor driver) (1/1)
2020-12-31 09:44:59  [ task-result-getter-2:2745 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2746 ] - [ INFO ]  ShuffleMapStage 1 (map at TransformationRDD.scala:48) finished in 0.124 s
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2746 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2746 ] - [ INFO ]  running: Set()
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2746 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2747 ] - [ INFO ]  failed: Set()
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2747 ] - [ INFO ]  Submitting ResultStage 2 (ShuffledRDD[8] at sortByKey at TransformationRDD.scala:49), which has no missing parents
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2751 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 2004.3 MB)
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2753 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.3 MB)
2020-12-31 09:44:59  [ dispatcher-event-loop-7:2754 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:50193 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2755 ] - [ INFO ]  Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2756 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[8] at sortByKey at TransformationRDD.scala:49) (first 15 tasks are for partitions Vector(0))
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2756 ] - [ INFO ]  Adding task set 2.0 with 1 tasks
2020-12-31 09:44:59  [ dispatcher-event-loop-8:2758 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 09:44:59  [ Executor task launch worker for task 3:2759 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 3)
2020-12-31 09:44:59  [ Executor task launch worker for task 3:2763 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2020-12-31 09:44:59  [ Executor task launch worker for task 3:2763 ] - [ INFO ]  Started 0 remote fetches in 0 ms
2020-12-31 09:44:59  [ Executor task launch worker for task 3:2797 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 3). 1101 bytes result sent to driver
2020-12-31 09:44:59  [ task-result-getter-3:2798 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 3) in 40 ms on localhost (executor driver) (1/1)
2020-12-31 09:44:59  [ task-result-getter-3:2798 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 09:44:59  [ dag-scheduler-event-loop:2800 ] - [ INFO ]  ResultStage 2 (foreach at TransformationRDD.scala:50) finished in 0.050 s
2020-12-31 09:44:59  [ main:2804 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:50, took 0.784673 s
2020-12-31 09:44:59  [ Thread-1:2808 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 09:44:59  [ Thread-1:2815 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 09:44:59  [ Thread-1:2815 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 09:44:59  [ dispatcher-event-loop-13:2823 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 09:44:59  [ Thread-1:2834 ] - [ INFO ]  MemoryStore cleared
2020-12-31 09:44:59  [ Thread-1:2834 ] - [ INFO ]  BlockManager stopped
2020-12-31 09:44:59  [ Thread-1:2838 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 09:44:59  [ dispatcher-event-loop-1:2839 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 09:44:59  [ Thread-1:2856 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 09:44:59  [ Thread-1:2856 ] - [ INFO ]  Shutdown hook called
2020-12-31 09:44:59  [ Thread-1:2857 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-d762b5a5-84d0-425a-b7dc-2fe228608965
2020-12-31 10:16:00  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:16:00  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:16:00  [ main:46 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:16:01  [ main:240 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:16:01  [ main:322 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:16:01  [ main:379 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:16:01  [ main:380 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:16:01  [ main:380 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:16:01  [ main:381 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:16:01  [ main:381 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:16:01  [ main:704 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50501.
2020-12-31 10:16:01  [ main:725 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:16:01  [ main:740 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:16:01  [ main:741 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:16:01  [ main:742 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:16:01  [ main:754 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-e4bf7a17-3bd2-43cb-80da-c29da02c4ea6
2020-12-31 10:16:01  [ main:775 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:16:01  [ main:788 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:16:01  [ main:862 ] - [ INFO ]  Logging initialized @1638ms
2020-12-31 10:16:01  [ main:909 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:16:01  [ main:924 ] - [ INFO ]  Started @1701ms
2020-12-31 10:16:01  [ main:940 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:16:01  [ main:940 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:16:01  [ main:959 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:959 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:960 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:961 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:962 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:962 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:963 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:964 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:965 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:965 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:966 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:967 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:967 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:968 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:969 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:969 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:970 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:971 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:971 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:972 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:977 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:978 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:978 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:979 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:16:01  [ main:981 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:16:01  [ main:1085 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:16:01  [ main:1141 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50502.
2020-12-31 10:16:01  [ main:1141 ] - [ INFO ]  Server created on 192.168.3.166:50502
2020-12-31 10:16:01  [ main:1142 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:16:01  [ main:1160 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50502, None)
2020-12-31 10:16:01  [ dispatcher-event-loop-10:1164 ] - [ INFO ]  Registering block manager 192.168.3.166:50502 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50502, None)
2020-12-31 10:16:01  [ main:1166 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50502, None)
2020-12-31 10:16:01  [ main:1166 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50502, None)
2020-12-31 10:16:02  [ main:1284 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:16:02  [ main:1650 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:16:02  [ main:1789 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:16:02  [ dispatcher-event-loop-12:1791 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50502 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:16:02  [ main:1794 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:16:02  [ main:1867 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:16:02  [ main:1907 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1924 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 4 output partitions
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1924 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at TransformationRDD.scala:53)
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1925 ] - [ INFO ]  Parents of final stage: List()
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1926 ] - [ INFO ]  Missing parents: List()
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1930 ] - [ INFO ]  Submitting ResultStage 0 (UnionRDD[6] at union at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1981 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 2004.4 MB)
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1983 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:16:02  [ dispatcher-event-loop-13:1984 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50502 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1984 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1995 ] - [ INFO ]  Submitting 4 missing tasks from ResultStage 0 (UnionRDD[6] at union at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2020-12-31 10:16:02  [ dag-scheduler-event-loop:1996 ] - [ INFO ]  Adding task set 0.0 with 4 tasks
2020-12-31 10:16:02  [ dispatcher-event-loop-14:2034 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7501 bytes)
2020-12-31 10:16:02  [ dispatcher-event-loop-14:2036 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7501 bytes)
2020-12-31 10:16:02  [ dispatcher-event-loop-14:2036 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7501 bytes)
2020-12-31 10:16:02  [ dispatcher-event-loop-14:2037 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7501 bytes)
2020-12-31 10:16:02  [ Executor task launch worker for task 0:2044 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:16:02  [ Executor task launch worker for task 1:2044 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:16:02  [ Executor task launch worker for task 2:2045 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2020-12-31 10:16:02  [ Executor task launch worker for task 3:2045 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2020-12-31 10:16:03  [ Executor task launch worker for task 3:2309 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:16:03  [ Executor task launch worker for task 1:2309 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:16:03  [ Executor task launch worker for task 2:2309 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:16:03  [ Executor task launch worker for task 0:2309 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:16:03  [ Executor task launch worker for task 3:2338 ] - [ INFO ]  Finished task 3.0 in stage 0.0 (TID 3). 800 bytes result sent to driver
2020-12-31 10:16:03  [ Executor task launch worker for task 1:2338 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 800 bytes result sent to driver
2020-12-31 10:16:03  [ Executor task launch worker for task 0:2338 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 800 bytes result sent to driver
2020-12-31 10:16:03  [ Executor task launch worker for task 2:2338 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2). 800 bytes result sent to driver
2020-12-31 10:16:03  [ task-result-getter-0:2344 ] - [ INFO ]  Finished task 3.0 in stage 0.0 (TID 3) in 306 ms on localhost (executor driver) (1/4)
2020-12-31 10:16:03  [ task-result-getter-2:2345 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 322 ms on localhost (executor driver) (2/4)
2020-12-31 10:16:03  [ task-result-getter-1:2345 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 309 ms on localhost (executor driver) (3/4)
2020-12-31 10:16:03  [ task-result-getter-3:2346 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2) in 310 ms on localhost (executor driver) (4/4)
2020-12-31 10:16:03  [ task-result-getter-3:2346 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:16:03  [ dag-scheduler-event-loop:2352 ] - [ INFO ]  ResultStage 0 (foreach at TransformationRDD.scala:53) finished in 0.401 s
2020-12-31 10:16:03  [ main:2356 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 0.449150 s
2020-12-31 10:16:03  [ Thread-1:2360 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:16:03  [ Thread-1:2368 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:16:03  [ Thread-1:2369 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:16:03  [ dispatcher-event-loop-9:2375 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:16:03  [ Thread-1:2386 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:16:03  [ Thread-1:2387 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:16:03  [ Thread-1:2390 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:16:03  [ dispatcher-event-loop-14:2391 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:16:03  [ Thread-1:2398 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:16:03  [ Thread-1:2398 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:16:03  [ Thread-1:2398 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-98408f1e-d9a6-4aaa-9ee2-d192aee2ff1c
2020-12-31 10:17:00  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:17:00  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:17:00  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:17:01  [ main:280 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:17:01  [ main:378 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:17:01  [ main:428 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:17:01  [ main:429 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:17:01  [ main:429 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:17:01  [ main:430 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:17:01  [ main:430 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:17:01  [ main:736 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50512.
2020-12-31 10:17:01  [ main:755 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:17:01  [ main:771 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:17:01  [ main:772 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:17:01  [ main:773 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:17:01  [ main:786 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-15096704-16ee-4cc4-aab0-049a4bd74088
2020-12-31 10:17:01  [ main:809 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:17:01  [ main:822 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:17:01  [ main:893 ] - [ INFO ]  Logging initialized @1715ms
2020-12-31 10:17:01  [ main:937 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:17:01  [ main:949 ] - [ INFO ]  Started @1771ms
2020-12-31 10:17:01  [ main:962 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:17:01  [ main:963 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:17:01  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:984 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:987 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:987 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:988 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:989 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:989 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:995 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:998 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:17:01  [ main:999 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:17:02  [ main:1087 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:17:02  [ main:1138 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50513.
2020-12-31 10:17:02  [ main:1139 ] - [ INFO ]  Server created on 192.168.3.166:50513
2020-12-31 10:17:02  [ main:1140 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:17:02  [ main:1155 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50513, None)
2020-12-31 10:17:02  [ dispatcher-event-loop-10:1158 ] - [ INFO ]  Registering block manager 192.168.3.166:50513 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50513, None)
2020-12-31 10:17:02  [ main:1160 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50513, None)
2020-12-31 10:17:02  [ main:1161 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50513, None)
2020-12-31 10:17:02  [ main:1273 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:02  [ main:1586 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:17:02  [ main:1705 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:17:02  [ dispatcher-event-loop-12:1707 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50513 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:17:02  [ main:1709 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:17:02  [ main:1782 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:17:02  [ main:1832 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1850 ] - [ INFO ]  Registering RDD 5 (map at TransformationRDD.scala:52)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1851 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:51)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1853 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1853 ] - [ INFO ]  Final stage: ResultStage 2 (foreach at TransformationRDD.scala:53)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1854 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1855 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1859 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1900 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 2004.4 MB)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1903 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:17:02  [ dispatcher-event-loop-13:1903 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50513 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1904 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1917 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1918 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1936 ] - [ INFO ]  Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1940 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 4.9 KB, free 2004.4 MB)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1941 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:17:02  [ dispatcher-event-loop-15:1942 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50513 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1943 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1944 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:17:02  [ dag-scheduler-event-loop:1944 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:17:02  [ dispatcher-event-loop-14:1957 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:02  [ dispatcher-event-loop-14:1959 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:02  [ dispatcher-event-loop-14:1965 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:02  [ dispatcher-event-loop-14:1965 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:02  [ Executor task launch worker for task 2:1967 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:17:02  [ Executor task launch worker for task 3:1967 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:17:02  [ Executor task launch worker for task 1:1967 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:17:02  [ Executor task launch worker for task 0:1967 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:17:03  [ Executor task launch worker for task 1:2239 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:17:03  [ Executor task launch worker for task 2:2240 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:17:03  [ Executor task launch worker for task 0:2239 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:17:03  [ Executor task launch worker for task 3:2239 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:17:03  [ Executor task launch worker for task 1:2290 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1032 bytes result sent to driver
2020-12-31 10:17:03  [ Executor task launch worker for task 2:2290 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1032 bytes result sent to driver
2020-12-31 10:17:03  [ Executor task launch worker for task 3:2290 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1032 bytes result sent to driver
2020-12-31 10:17:03  [ Executor task launch worker for task 0:2290 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1032 bytes result sent to driver
2020-12-31 10:17:03  [ task-result-getter-2:2296 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 330 ms on localhost (executor driver) (1/2)
2020-12-31 10:17:03  [ task-result-getter-3:2297 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 351 ms on localhost (executor driver) (1/2)
2020-12-31 10:17:03  [ task-result-getter-0:2297 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 338 ms on localhost (executor driver) (2/2)
2020-12-31 10:17:03  [ task-result-getter-0:2298 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:17:03  [ task-result-getter-1:2298 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 333 ms on localhost (executor driver) (2/2)
2020-12-31 10:17:03  [ task-result-getter-1:2298 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2304 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:52) finished in 0.422 s
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2304 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2305 ] - [ INFO ]  running: Set(ShuffleMapStage 1)
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2305 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2305 ] - [ INFO ]  failed: Set()
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2309 ] - [ INFO ]  ShuffleMapStage 1 (map at TransformationRDD.scala:51) finished in 0.370 s
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2309 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2309 ] - [ INFO ]  running: Set()
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2309 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2309 ] - [ INFO ]  failed: Set()
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2310 ] - [ INFO ]  Submitting ResultStage 2 (MapPartitionsRDD[8] at join at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2317 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 4.4 KB, free 2004.4 MB)
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2319 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.3 MB)
2020-12-31 10:17:03  [ dispatcher-event-loop-9:2320 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:50513 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2320 ] - [ INFO ]  Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2322 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at join at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2322 ] - [ INFO ]  Adding task set 2.0 with 2 tasks
2020-12-31 10:17:03  [ dispatcher-event-loop-10:2325 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:17:03  [ dispatcher-event-loop-10:2325 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:17:03  [ Executor task launch worker for task 5:2325 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 5)
2020-12-31 10:17:03  [ Executor task launch worker for task 4:2325 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 4)
2020-12-31 10:17:03  [ Executor task launch worker for task 4:2456 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:03  [ Executor task launch worker for task 5:2456 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:03  [ Executor task launch worker for task 5:2457 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:17:03  [ Executor task launch worker for task 4:2457 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:17:03  [ dispatcher-event-loop-0:2464 ] - [ INFO ]  Removed broadcast_1_piece0 on 192.168.3.166:50513 in memory (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:17:03  [ dispatcher-event-loop-3:2468 ] - [ INFO ]  Removed broadcast_2_piece0 on 192.168.3.166:50513 in memory (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:17:03  [ Executor task launch worker for task 5:2475 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:03  [ Executor task launch worker for task 4:2475 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:03  [ Executor task launch worker for task 5:2475 ] - [ INFO ]  Started 0 remote fetches in 1 ms
2020-12-31 10:17:03  [ Executor task launch worker for task 4:2475 ] - [ INFO ]  Started 0 remote fetches in 0 ms
2020-12-31 10:17:03  [ Executor task launch worker for task 4:2509 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4). 1144 bytes result sent to driver
2020-12-31 10:17:03  [ Executor task launch worker for task 5:2509 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5). 1144 bytes result sent to driver
2020-12-31 10:17:03  [ task-result-getter-2:2510 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4) in 186 ms on localhost (executor driver) (1/2)
2020-12-31 10:17:03  [ task-result-getter-3:2511 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5) in 185 ms on localhost (executor driver) (2/2)
2020-12-31 10:17:03  [ task-result-getter-3:2511 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 10:17:03  [ dag-scheduler-event-loop:2513 ] - [ INFO ]  ResultStage 2 (foreach at TransformationRDD.scala:53) finished in 0.202 s
2020-12-31 10:17:03  [ main:2516 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 0.683904 s
2020-12-31 10:17:03  [ Thread-1:2520 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:17:03  [ Thread-1:2527 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:17:03  [ Thread-1:2528 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:17:03  [ dispatcher-event-loop-8:2534 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:17:03  [ Thread-1:2548 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:17:03  [ Thread-1:2548 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:17:03  [ Thread-1:2549 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:17:03  [ dispatcher-event-loop-12:2551 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:17:03  [ Thread-1:2558 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:17:03  [ Thread-1:2558 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:17:03  [ Thread-1:2559 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-1b57c582-0d4c-4754-b405-bfcd51f68f4c
2020-12-31 10:17:29  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:17:29  [ main:0 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:17:29  [ main:42 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:17:30  [ main:290 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:17:30  [ main:400 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:17:30  [ main:453 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:17:30  [ main:453 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:17:30  [ main:454 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:17:30  [ main:454 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:17:30  [ main:454 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:17:30  [ main:750 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50522.
2020-12-31 10:17:30  [ main:770 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:17:30  [ main:786 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:17:30  [ main:789 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:17:30  [ main:789 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:17:30  [ main:806 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-f70014be-103c-4841-ae9a-3116c99221d7
2020-12-31 10:17:30  [ main:832 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:17:30  [ main:846 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:17:30  [ main:922 ] - [ INFO ]  Logging initialized @1720ms
2020-12-31 10:17:30  [ main:966 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:17:30  [ main:976 ] - [ INFO ]  Started @1775ms
2020-12-31 10:17:30  [ main:990 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:17:30  [ main:991 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:17:30  [ main:1008 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1009 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1010 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1011 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1012 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1012 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1013 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1014 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1015 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1015 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1016 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1017 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1017 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1018 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1019 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1019 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1020 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1021 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1021 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1022 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1026 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1027 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1028 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1028 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1029 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:17:30  [ main:1030 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:17:31  [ main:1123 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:17:31  [ main:1183 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50523.
2020-12-31 10:17:31  [ main:1184 ] - [ INFO ]  Server created on 192.168.3.166:50523
2020-12-31 10:17:31  [ main:1185 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:17:31  [ main:1204 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50523, None)
2020-12-31 10:17:31  [ dispatcher-event-loop-10:1208 ] - [ INFO ]  Registering block manager 192.168.3.166:50523 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50523, None)
2020-12-31 10:17:31  [ main:1211 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50523, None)
2020-12-31 10:17:31  [ main:1212 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50523, None)
2020-12-31 10:17:31  [ main:1344 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:17:31  [ main:1694 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:17:31  [ main:1804 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:17:31  [ dispatcher-event-loop-12:1806 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50523 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:17:31  [ main:1808 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:17:31  [ main:1886 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:17:31  [ main:1939 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1956 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:51)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1959 ] - [ INFO ]  Registering RDD 6 (map at TransformationRDD.scala:52)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1960 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1961 ] - [ INFO ]  Final stage: ResultStage 2 (foreach at TransformationRDD.scala:53)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1961 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1963 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:1967 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2015 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 2004.4 MB)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2017 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:17:31  [ dispatcher-event-loop-13:2018 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50523 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2019 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2033 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2034 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2058 ] - [ INFO ]  Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2065 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.2 KB, free 2004.4 MB)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2068 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 2004.4 MB)
2020-12-31 10:17:31  [ dispatcher-event-loop-15:2069 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50523 (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2069 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2070 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:17:31  [ dag-scheduler-event-loop:2070 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:17:31  [ dispatcher-event-loop-14:2082 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:31  [ dispatcher-event-loop-14:2084 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:31  [ dispatcher-event-loop-14:2092 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:31  [ dispatcher-event-loop-14:2093 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:17:31  [ Executor task launch worker for task 2:2094 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:17:31  [ Executor task launch worker for task 3:2094 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:17:31  [ Executor task launch worker for task 1:2095 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:17:31  [ Executor task launch worker for task 0:2095 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:17:32  [ Executor task launch worker for task 0:2440 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:17:32  [ Executor task launch worker for task 2:2440 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:17:32  [ Executor task launch worker for task 1:2440 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:17:32  [ Executor task launch worker for task 3:2440 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:17:32  [ Executor task launch worker for task 3:2502 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1032 bytes result sent to driver
2020-12-31 10:17:32  [ Executor task launch worker for task 0:2502 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1032 bytes result sent to driver
2020-12-31 10:17:32  [ Executor task launch worker for task 2:2502 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1032 bytes result sent to driver
2020-12-31 10:17:32  [ Executor task launch worker for task 1:2502 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1032 bytes result sent to driver
2020-12-31 10:17:32  [ task-result-getter-0:2509 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 415 ms on localhost (executor driver) (1/2)
2020-12-31 10:17:32  [ task-result-getter-1:2511 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 440 ms on localhost (executor driver) (1/2)
2020-12-31 10:17:32  [ task-result-getter-3:2511 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 427 ms on localhost (executor driver) (2/2)
2020-12-31 10:17:32  [ task-result-getter-3:2512 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:17:32  [ task-result-getter-2:2513 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 421 ms on localhost (executor driver) (2/2)
2020-12-31 10:17:32  [ task-result-getter-2:2513 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2519 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:51) finished in 0.526 s
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2520 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2520 ] - [ INFO ]  running: Set(ShuffleMapStage 1)
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2520 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2521 ] - [ INFO ]  failed: Set()
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  ShuffleMapStage 1 (map at TransformationRDD.scala:52) finished in 0.463 s
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  running: Set()
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  failed: Set()
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2525 ] - [ INFO ]  Submitting ResultStage 2 (MapPartitionsRDD[9] at join at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2533 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 4.4 KB, free 2004.4 MB)
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2541 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.3 MB)
2020-12-31 10:17:32  [ dispatcher-event-loop-9:2542 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:50523 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2543 ] - [ INFO ]  Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2544 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at join at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2544 ] - [ INFO ]  Adding task set 2.0 with 2 tasks
2020-12-31 10:17:32  [ dispatcher-event-loop-11:2548 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:17:32  [ dispatcher-event-loop-11:2548 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:17:32  [ Executor task launch worker for task 4:2548 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 4)
2020-12-31 10:17:32  [ Executor task launch worker for task 5:2548 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 5)
2020-12-31 10:17:32  [ dispatcher-event-loop-0:2558 ] - [ INFO ]  Removed broadcast_1_piece0 on 192.168.3.166:50523 in memory (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:17:32  [ Executor task launch worker for task 4:2606 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:32  [ Executor task launch worker for task 5:2606 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:32  [ Executor task launch worker for task 4:2608 ] - [ INFO ]  Started 0 remote fetches in 8 ms
2020-12-31 10:17:32  [ Executor task launch worker for task 5:2608 ] - [ INFO ]  Started 0 remote fetches in 8 ms
2020-12-31 10:17:32  [ Executor task launch worker for task 4:2628 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2020-12-31 10:17:32  [ Executor task launch worker for task 5:2628 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:17:32  [ Executor task launch worker for task 4:2628 ] - [ INFO ]  Started 0 remote fetches in 1 ms
2020-12-31 10:17:32  [ Executor task launch worker for task 5:2628 ] - [ INFO ]  Started 0 remote fetches in 1 ms
2020-12-31 10:17:32  [ dispatcher-event-loop-3:2738 ] - [ INFO ]  Removed broadcast_2_piece0 on 192.168.3.166:50523 in memory (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 10:17:32  [ Executor task launch worker for task 4:2757 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4). 1144 bytes result sent to driver
2020-12-31 10:17:32  [ Executor task launch worker for task 5:2757 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5). 1144 bytes result sent to driver
2020-12-31 10:17:32  [ task-result-getter-0:2758 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4) in 212 ms on localhost (executor driver) (1/2)
2020-12-31 10:17:32  [ task-result-getter-1:2759 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5) in 211 ms on localhost (executor driver) (2/2)
2020-12-31 10:17:32  [ task-result-getter-1:2759 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 10:17:32  [ dag-scheduler-event-loop:2761 ] - [ INFO ]  ResultStage 2 (foreach at TransformationRDD.scala:53) finished in 0.232 s
2020-12-31 10:17:32  [ main:2765 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 0.826102 s
2020-12-31 10:17:32  [ Thread-1:2769 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:17:32  [ Thread-1:2777 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:17:32  [ Thread-1:2778 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:17:32  [ dispatcher-event-loop-8:2786 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:17:32  [ Thread-1:2800 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:17:32  [ Thread-1:2800 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:17:32  [ Thread-1:2801 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:17:32  [ dispatcher-event-loop-15:2803 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:17:32  [ Thread-1:2812 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:17:32  [ Thread-1:2812 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:17:32  [ Thread-1:2813 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-884bf057-79e0-4bdf-931c-7ddabda339e4
2020-12-31 10:22:27  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:22:27  [ main:0 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:22:27  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:22:27  [ main:230 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:22:27  [ main:300 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:22:27  [ main:346 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:22:27  [ main:346 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:22:27  [ main:347 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:22:27  [ main:347 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:22:27  [ main:348 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:22:28  [ main:626 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50553.
2020-12-31 10:22:28  [ main:646 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:22:28  [ main:660 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:22:28  [ main:662 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:22:28  [ main:662 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:22:28  [ main:677 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-924e2b6a-96fe-48c1-b0cf-39d7248b705d
2020-12-31 10:22:28  [ main:701 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:22:28  [ main:714 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:22:28  [ main:786 ] - [ INFO ]  Logging initialized @1558ms
2020-12-31 10:22:28  [ main:831 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:22:28  [ main:846 ] - [ INFO ]  Started @1619ms
2020-12-31 10:22:28  [ main:864 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:22:28  [ main:864 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:22:28  [ main:889 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:890 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:891 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:892 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:893 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:893 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:894 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:895 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:896 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:897 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:898 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:898 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:899 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:900 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:901 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:901 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:902 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:903 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:904 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:905 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:914 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:22:28  [ main:1013 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:22:28  [ main:1088 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50554.
2020-12-31 10:22:28  [ main:1089 ] - [ INFO ]  Server created on 192.168.3.166:50554
2020-12-31 10:22:28  [ main:1090 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:22:28  [ main:1109 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50554, None)
2020-12-31 10:22:28  [ dispatcher-event-loop-10:1113 ] - [ INFO ]  Registering block manager 192.168.3.166:50554 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50554, None)
2020-12-31 10:22:28  [ main:1115 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50554, None)
2020-12-31 10:22:28  [ main:1115 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50554, None)
2020-12-31 10:22:28  [ main:1227 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:22:28  [ main:1598 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ main:1743 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ dispatcher-event-loop-12:1745 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50554 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:22:29  [ main:1748 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:22:29  [ main:1837 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:22:29  [ main:1888 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1907 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:51)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1909 ] - [ INFO ]  Registering RDD 6 (map at TransformationRDD.scala:52)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1911 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1911 ] - [ INFO ]  Final stage: ResultStage 2 (foreach at TransformationRDD.scala:53)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1912 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1913 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1917 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1967 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1971 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ dispatcher-event-loop-13:1972 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50554 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1973 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1993 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:22:29  [ dag-scheduler-event-loop:1994 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2019 ] - [ INFO ]  Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2025 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.2 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2027 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ dispatcher-event-loop-15:2028 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50554 (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2029 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2030 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2030 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:22:29  [ dispatcher-event-loop-14:2045 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:22:29  [ dispatcher-event-loop-14:2047 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:22:29  [ dispatcher-event-loop-14:2054 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:22:29  [ dispatcher-event-loop-14:2055 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:22:29  [ Executor task launch worker for task 2:2056 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:22:29  [ Executor task launch worker for task 0:2056 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:22:29  [ Executor task launch worker for task 3:2056 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:22:29  [ Executor task launch worker for task 1:2056 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:22:29  [ Executor task launch worker for task 1:2387 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:22:29  [ Executor task launch worker for task 3:2391 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:22:29  [ Executor task launch worker for task 0:2393 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:22:29  [ Executor task launch worker for task 2:2399 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:22:29  [ Executor task launch worker for task 3:2459 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 989 bytes result sent to driver
2020-12-31 10:22:29  [ Executor task launch worker for task 2:2460 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1032 bytes result sent to driver
2020-12-31 10:22:29  [ Executor task launch worker for task 0:2462 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 989 bytes result sent to driver
2020-12-31 10:22:29  [ task-result-getter-0:2467 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 411 ms on localhost (executor driver) (1/2)
2020-12-31 10:22:29  [ task-result-getter-1:2469 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 415 ms on localhost (executor driver) (2/2)
2020-12-31 10:22:29  [ task-result-getter-1:2470 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:22:29  [ task-result-getter-2:2471 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 439 ms on localhost (executor driver) (1/2)
2020-12-31 10:22:29  [ Executor task launch worker for task 1:2473 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 989 bytes result sent to driver
2020-12-31 10:22:29  [ task-result-getter-3:2474 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 427 ms on localhost (executor driver) (2/2)
2020-12-31 10:22:29  [ task-result-getter-3:2474 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2476 ] - [ INFO ]  ShuffleMapStage 1 (map at TransformationRDD.scala:52) finished in 0.453 s
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2477 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2477 ] - [ INFO ]  running: Set(ShuffleMapStage 0)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2478 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2478 ] - [ INFO ]  failed: Set()
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2484 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:51) finished in 0.542 s
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2484 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2485 ] - [ INFO ]  running: Set()
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2485 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2485 ] - [ INFO ]  failed: Set()
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2486 ] - [ INFO ]  Submitting ResultStage 2 (MapPartitionsRDD[8] at cogroup at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2494 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 2004.4 MB)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2497 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2004.3 MB)
2020-12-31 10:22:29  [ dispatcher-event-loop-9:2498 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:50554 (size: 2.3 KB, free: 2004.6 MB)
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2498 ] - [ INFO ]  Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2500 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at cogroup at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:22:29  [ dag-scheduler-event-loop:2500 ] - [ INFO ]  Adding task set 2.0 with 2 tasks
2020-12-31 10:22:29  [ dispatcher-event-loop-10:2504 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:22:29  [ dispatcher-event-loop-10:2504 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:22:29  [ Executor task launch worker for task 5:2505 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 5)
2020-12-31 10:22:29  [ Executor task launch worker for task 4:2505 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 4)
2020-12-31 10:22:29  [ dispatcher-event-loop-0:2568 ] - [ INFO ]  Removed broadcast_2_piece0 on 192.168.3.166:50554 in memory (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 10:22:29  [ dispatcher-event-loop-3:2573 ] - [ INFO ]  Removed broadcast_1_piece0 on 192.168.3.166:50554 in memory (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:22:29  [ Executor task launch worker for task 5:2574 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:22:29  [ Executor task launch worker for task 4:2574 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:22:29  [ Executor task launch worker for task 5:2575 ] - [ INFO ]  Started 0 remote fetches in 6 ms
2020-12-31 10:22:29  [ Executor task launch worker for task 4:2575 ] - [ INFO ]  Started 0 remote fetches in 6 ms
2020-12-31 10:22:29  [ Executor task launch worker for task 4:2590 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2020-12-31 10:22:29  [ Executor task launch worker for task 5:2590 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:22:29  [ Executor task launch worker for task 4:2590 ] - [ INFO ]  Started 0 remote fetches in 0 ms
2020-12-31 10:22:29  [ Executor task launch worker for task 5:2590 ] - [ INFO ]  Started 0 remote fetches in 0 ms
2020-12-31 10:22:29  [ Executor task launch worker for task 4:2617 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4). 1187 bytes result sent to driver
2020-12-31 10:22:29  [ Executor task launch worker for task 5:2617 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5). 1187 bytes result sent to driver
2020-12-31 10:22:30  [ task-result-getter-0:2619 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4) in 117 ms on localhost (executor driver) (1/2)
2020-12-31 10:22:30  [ task-result-getter-1:2619 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5) in 115 ms on localhost (executor driver) (2/2)
2020-12-31 10:22:30  [ task-result-getter-1:2619 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 10:22:30  [ dag-scheduler-event-loop:2621 ] - [ INFO ]  ResultStage 2 (foreach at TransformationRDD.scala:53) finished in 0.133 s
2020-12-31 10:22:30  [ main:2626 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 0.737589 s
2020-12-31 10:22:30  [ Thread-1:2630 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:22:30  [ Thread-1:2637 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:22:30  [ Thread-1:2638 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:22:30  [ dispatcher-event-loop-5:2645 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:22:30  [ Thread-1:2656 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:22:30  [ Thread-1:2656 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:22:30  [ Thread-1:2657 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:22:30  [ dispatcher-event-loop-12:2658 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:22:30  [ Thread-1:2665 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:22:30  [ Thread-1:2665 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:22:30  [ Thread-1:2665 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-ce200f80-1867-4ee1-99f5-c3afa8ad236d
2020-12-31 10:23:19  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:23:19  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:23:19  [ main:40 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:23:19  [ main:260 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:23:19  [ main:358 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:23:19  [ main:429 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:23:19  [ main:429 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:23:19  [ main:429 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:23:19  [ main:430 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:23:19  [ main:430 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:23:19  [ main:730 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50564.
2020-12-31 10:23:19  [ main:750 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:23:19  [ main:765 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:23:19  [ main:767 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:23:19  [ main:767 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:23:19  [ main:780 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-2c1ee22e-7288-41f6-b176-0db2ea74bef1
2020-12-31 10:23:19  [ main:803 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:23:19  [ main:816 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:23:20  [ main:888 ] - [ INFO ]  Logging initialized @1653ms
2020-12-31 10:23:20  [ main:931 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:23:20  [ main:943 ] - [ INFO ]  Started @1708ms
2020-12-31 10:23:20  [ main:957 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:23:20  [ main:957 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:23:20  [ main:974 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:975 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:975 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:976 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:977 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:977 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:978 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:979 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:984 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:984 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:992 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:993 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:993 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:994 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:23:20  [ main:1078 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:23:20  [ main:1130 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50565.
2020-12-31 10:23:20  [ main:1130 ] - [ INFO ]  Server created on 192.168.3.166:50565
2020-12-31 10:23:20  [ main:1131 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:23:20  [ main:1149 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50565, None)
2020-12-31 10:23:20  [ dispatcher-event-loop-10:1152 ] - [ INFO ]  Registering block manager 192.168.3.166:50565 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50565, None)
2020-12-31 10:23:20  [ main:1153 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50565, None)
2020-12-31 10:23:20  [ main:1154 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50565, None)
2020-12-31 10:23:20  [ main:1269 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:23:20  [ main:1625 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ main:1984 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ dispatcher-event-loop-12:1986 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50565 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:23:21  [ main:1989 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:23:21  [ main:2067 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:23:21  [ main:2111 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2127 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:51)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2129 ] - [ INFO ]  Registering RDD 6 (map at TransformationRDD.scala:52)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2130 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2131 ] - [ INFO ]  Final stage: ResultStage 2 (foreach at TransformationRDD.scala:53)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2131 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2133 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2137 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2178 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2180 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ dispatcher-event-loop-13:2181 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50565 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2181 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2195 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2196 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2222 ] - [ INFO ]  Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2227 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.2 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2229 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ dispatcher-event-loop-15:2230 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50565 (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2231 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2232 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2232 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:23:21  [ dispatcher-event-loop-14:2246 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:23:21  [ dispatcher-event-loop-14:2248 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:23:21  [ dispatcher-event-loop-14:2255 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:23:21  [ dispatcher-event-loop-14:2255 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:23:21  [ Executor task launch worker for task 2:2256 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:23:21  [ Executor task launch worker for task 0:2256 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:23:21  [ Executor task launch worker for task 3:2256 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:23:21  [ Executor task launch worker for task 1:2256 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:23:21  [ Executor task launch worker for task 1:2591 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:23:21  [ Executor task launch worker for task 3:2591 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:23:21  [ Executor task launch worker for task 0:2591 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:23:21  [ Executor task launch worker for task 2:2591 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:23:21  [ Executor task launch worker for task 1:2652 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1032 bytes result sent to driver
2020-12-31 10:23:21  [ Executor task launch worker for task 3:2652 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1032 bytes result sent to driver
2020-12-31 10:23:21  [ Executor task launch worker for task 0:2652 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1032 bytes result sent to driver
2020-12-31 10:23:21  [ Executor task launch worker for task 2:2652 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1032 bytes result sent to driver
2020-12-31 10:23:21  [ task-result-getter-2:2658 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 422 ms on localhost (executor driver) (1/2)
2020-12-31 10:23:21  [ task-result-getter-0:2659 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 412 ms on localhost (executor driver) (2/2)
2020-12-31 10:23:21  [ task-result-getter-0:2660 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:23:21  [ task-result-getter-1:2660 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 405 ms on localhost (executor driver) (1/2)
2020-12-31 10:23:21  [ task-result-getter-3:2661 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 407 ms on localhost (executor driver) (2/2)
2020-12-31 10:23:21  [ task-result-getter-3:2661 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2665 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:51) finished in 0.505 s
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2666 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2666 ] - [ INFO ]  running: Set(ShuffleMapStage 1)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2667 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2667 ] - [ INFO ]  failed: Set()
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2671 ] - [ INFO ]  ShuffleMapStage 1 (map at TransformationRDD.scala:52) finished in 0.445 s
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2671 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2671 ] - [ INFO ]  running: Set()
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2671 ] - [ INFO ]  waiting: Set(ResultStage 2)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2671 ] - [ INFO ]  failed: Set()
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2672 ] - [ INFO ]  Submitting ResultStage 2 (MapPartitionsRDD[9] at map at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2679 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 4.4 KB, free 2004.4 MB)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2681 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 2004.3 MB)
2020-12-31 10:23:21  [ dispatcher-event-loop-9:2681 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:50565 (size: 2.5 KB, free: 2004.6 MB)
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2682 ] - [ INFO ]  Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2683 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at map at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:23:21  [ dag-scheduler-event-loop:2683 ] - [ INFO ]  Adding task set 2.0 with 2 tasks
2020-12-31 10:23:21  [ dispatcher-event-loop-10:2685 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:23:21  [ dispatcher-event-loop-10:2686 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7204 bytes)
2020-12-31 10:23:21  [ Executor task launch worker for task 5:2686 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 5)
2020-12-31 10:23:21  [ Executor task launch worker for task 4:2686 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 4)
2020-12-31 10:23:21  [ Executor task launch worker for task 4:2734 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:23:21  [ Executor task launch worker for task 5:2734 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:23:21  [ Executor task launch worker for task 4:2736 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:23:21  [ Executor task launch worker for task 5:2736 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:23:21  [ dispatcher-event-loop-0:2847 ] - [ INFO ]  Removed broadcast_2_piece0 on 192.168.3.166:50565 in memory (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 10:23:21  [ dispatcher-event-loop-3:2851 ] - [ INFO ]  Removed broadcast_1_piece0 on 192.168.3.166:50565 in memory (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:23:21  [ Executor task launch worker for task 4:2854 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2020-12-31 10:23:21  [ Executor task launch worker for task 5:2854 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:23:21  [ Executor task launch worker for task 4:2854 ] - [ INFO ]  Started 0 remote fetches in 1 ms
2020-12-31 10:23:21  [ Executor task launch worker for task 5:2854 ] - [ INFO ]  Started 0 remote fetches in 0 ms
2020-12-31 10:23:22  [ Executor task launch worker for task 5:2891 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5). 1144 bytes result sent to driver
2020-12-31 10:23:22  [ Executor task launch worker for task 4:2891 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4). 1144 bytes result sent to driver
2020-12-31 10:23:22  [ task-result-getter-2:2892 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5) in 206 ms on localhost (executor driver) (1/2)
2020-12-31 10:23:22  [ task-result-getter-0:2892 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4) in 208 ms on localhost (executor driver) (2/2)
2020-12-31 10:23:22  [ task-result-getter-0:2892 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 10:23:22  [ dag-scheduler-event-loop:2893 ] - [ INFO ]  ResultStage 2 (foreach at TransformationRDD.scala:53) finished in 0.219 s
2020-12-31 10:23:22  [ main:2897 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 0.785299 s
2020-12-31 10:23:22  [ Thread-1:2901 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:23:22  [ Thread-1:2909 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:23:22  [ Thread-1:2910 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:23:22  [ dispatcher-event-loop-8:2917 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:23:22  [ Thread-1:2927 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:23:22  [ Thread-1:2928 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:23:22  [ Thread-1:2929 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:23:22  [ dispatcher-event-loop-12:2930 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:23:22  [ Thread-1:2937 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:23:22  [ Thread-1:2937 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:23:22  [ Thread-1:2937 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-1f57e6f4-936e-406b-bb18-a17b65d89dfb
2020-12-31 10:31:08  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:31:08  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:31:08  [ main:52 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:31:09  [ main:283 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:31:09  [ main:389 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:31:09  [ main:454 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:31:09  [ main:455 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:31:09  [ main:455 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:31:09  [ main:456 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:31:09  [ main:457 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:31:09  [ main:786 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50641.
2020-12-31 10:31:09  [ main:809 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:31:09  [ main:824 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:31:09  [ main:826 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:31:09  [ main:826 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:31:09  [ main:840 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-f288be4c-5be5-4af9-a8b1-e4c86f62acb8
2020-12-31 10:31:09  [ main:863 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:31:09  [ main:878 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:31:09  [ main:951 ] - [ INFO ]  Logging initialized @1744ms
2020-12-31 10:31:09  [ main:996 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:31:09  [ main:1007 ] - [ INFO ]  Started @1801ms
2020-12-31 10:31:09  [ main:1022 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:31:09  [ main:1022 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:31:09  [ main:1039 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1040 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1040 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1042 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1042 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1043 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1043 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1044 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1045 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1046 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1046 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1046 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1047 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1048 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1048 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1049 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1049 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1050 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1050 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1051 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1056 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1056 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1057 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1058 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1058 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:31:09  [ main:1059 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:31:10  [ main:1152 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:31:10  [ main:1206 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50642.
2020-12-31 10:31:10  [ main:1206 ] - [ INFO ]  Server created on 192.168.3.166:50642
2020-12-31 10:31:10  [ main:1207 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:31:10  [ main:1226 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50642, None)
2020-12-31 10:31:10  [ dispatcher-event-loop-10:1229 ] - [ INFO ]  Registering block manager 192.168.3.166:50642 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50642, None)
2020-12-31 10:31:10  [ main:1231 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50642, None)
2020-12-31 10:31:10  [ main:1231 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50642, None)
2020-12-31 10:31:10  [ main:1345 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:10  [ main:1673 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:31:10  [ main:1796 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:31:10  [ dispatcher-event-loop-12:1798 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50642 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:31:10  [ main:1800 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:31:10  [ main:1862 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:31:10  [ main:1911 ] - [ INFO ]  Starting job: take at TransformationRDD.scala:52
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1929 ] - [ INFO ]  Got job 0 (take at TransformationRDD.scala:52) with 1 output partitions
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1929 ] - [ INFO ]  Final stage: ResultStage 0 (take at TransformationRDD.scala:52)
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1930 ] - [ INFO ]  Parents of final stage: List()
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1931 ] - [ INFO ]  Missing parents: List()
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1935 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1960 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.6 KB, free 2004.4 MB)
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1962 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KB, free 2004.4 MB)
2020-12-31 10:31:10  [ dispatcher-event-loop-13:1963 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50642 (size: 2.6 KB, free: 2004.6 MB)
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1963 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1976 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0))
2020-12-31 10:31:10  [ dag-scheduler-event-loop:1977 ] - [ INFO ]  Adding task set 0.0 with 1 tasks
2020-12-31 10:31:10  [ dispatcher-event-loop-14:2017 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7392 bytes)
2020-12-31 10:31:10  [ Executor task launch worker for task 0:2026 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:31:11  [ Executor task launch worker for task 0:2259 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:31:11  [ Executor task launch worker for task 0:2281 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 911 bytes result sent to driver
2020-12-31 10:31:11  [ task-result-getter-0:2285 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 277 ms on localhost (executor driver) (1/1)
2020-12-31 10:31:11  [ task-result-getter-0:2287 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:31:11  [ dag-scheduler-event-loop:2291 ] - [ INFO ]  ResultStage 0 (take at TransformationRDD.scala:52) finished in 0.334 s
2020-12-31 10:31:11  [ main:2295 ] - [ INFO ]  Job 0 finished: take at TransformationRDD.scala:52, took 0.383891 s
2020-12-31 10:31:11  [ Thread-1:2298 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:31:11  [ Thread-1:2306 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:31:11  [ Thread-1:2307 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:31:11  [ dispatcher-event-loop-3:2313 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:31:11  [ Thread-1:2321 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:31:11  [ Thread-1:2321 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:31:11  [ Thread-1:2324 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:31:11  [ dispatcher-event-loop-8:2326 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:31:11  [ Thread-1:2332 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:31:11  [ Thread-1:2332 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:31:11  [ Thread-1:2332 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-f90019ed-18f5-4ccf-8e1c-12f4abf9dd0c
2020-12-31 10:31:17  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:31:17  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:31:17  [ main:45 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:31:17  [ main:285 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:31:17  [ main:400 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:31:17  [ main:453 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:31:17  [ main:453 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:31:17  [ main:454 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:31:17  [ main:454 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:31:17  [ main:455 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:31:17  [ main:762 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50647.
2020-12-31 10:31:17  [ main:781 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:31:17  [ main:796 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:31:17  [ main:798 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:31:17  [ main:799 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:31:17  [ main:812 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-8796902c-99a2-4f9f-99aa-14a5e660a7b2
2020-12-31 10:31:17  [ main:835 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:31:17  [ main:849 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:31:17  [ main:925 ] - [ INFO ]  Logging initialized @1732ms
2020-12-31 10:31:17  [ main:977 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:31:17  [ main:989 ] - [ INFO ]  Started @1796ms
2020-12-31 10:31:18  [ main:1004 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:31:18  [ main:1005 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:31:18  [ main:1023 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1024 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1025 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1026 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1026 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1027 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1028 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1029 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1030 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1030 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1031 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1031 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1032 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1033 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1033 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1034 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1034 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1035 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1035 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1036 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1040 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1041 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1042 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1043 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1043 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1044 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:31:18  [ main:1135 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:31:18  [ main:1196 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50648.
2020-12-31 10:31:18  [ main:1197 ] - [ INFO ]  Server created on 192.168.3.166:50648
2020-12-31 10:31:18  [ main:1198 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:31:18  [ main:1216 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50648, None)
2020-12-31 10:31:18  [ dispatcher-event-loop-10:1219 ] - [ INFO ]  Registering block manager 192.168.3.166:50648 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50648, None)
2020-12-31 10:31:18  [ main:1221 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50648, None)
2020-12-31 10:31:18  [ main:1221 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50648, None)
2020-12-31 10:31:18  [ main:1338 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:18  [ main:1668 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:31:18  [ main:1771 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:31:18  [ dispatcher-event-loop-12:1773 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50648 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:31:18  [ main:1775 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:31:18  [ main:1842 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:31:18  [ main:1888 ] - [ INFO ]  Starting job: take at TransformationRDD.scala:52
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1905 ] - [ INFO ]  Got job 0 (take at TransformationRDD.scala:52) with 1 output partitions
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1905 ] - [ INFO ]  Final stage: ResultStage 0 (take at TransformationRDD.scala:52)
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1905 ] - [ INFO ]  Parents of final stage: List()
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1907 ] - [ INFO ]  Missing parents: List()
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1910 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1934 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.6 KB, free 2004.4 MB)
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1936 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KB, free 2004.4 MB)
2020-12-31 10:31:18  [ dispatcher-event-loop-13:1936 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50648 (size: 2.6 KB, free: 2004.6 MB)
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1937 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1950 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0))
2020-12-31 10:31:18  [ dag-scheduler-event-loop:1951 ] - [ INFO ]  Adding task set 0.0 with 1 tasks
2020-12-31 10:31:18  [ dispatcher-event-loop-14:1990 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7392 bytes)
2020-12-31 10:31:19  [ Executor task launch worker for task 0:2000 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:31:19  [ Executor task launch worker for task 0:2235 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:31:19  [ Executor task launch worker for task 0:2257 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 911 bytes result sent to driver
2020-12-31 10:31:19  [ task-result-getter-0:2262 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 281 ms on localhost (executor driver) (1/1)
2020-12-31 10:31:19  [ task-result-getter-0:2264 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:31:19  [ dag-scheduler-event-loop:2269 ] - [ INFO ]  ResultStage 0 (take at TransformationRDD.scala:52) finished in 0.337 s
2020-12-31 10:31:19  [ main:2273 ] - [ INFO ]  Job 0 finished: take at TransformationRDD.scala:52, took 0.384796 s
2020-12-31 10:31:19  [ Thread-1:2277 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:31:19  [ Thread-1:2287 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:31:19  [ Thread-1:2288 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:31:19  [ dispatcher-event-loop-3:2294 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:31:19  [ Thread-1:2302 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:31:19  [ Thread-1:2302 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:31:19  [ Thread-1:2305 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:31:19  [ dispatcher-event-loop-8:2307 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:31:19  [ Thread-1:2313 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:31:19  [ Thread-1:2313 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:31:19  [ Thread-1:2314 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-db56c9d4-f58f-4bb7-8d38-69620ed903f4
2020-12-31 10:31:37  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:31:37  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:31:37  [ main:48 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:31:37  [ main:302 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:31:37  [ main:383 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:31:37  [ main:430 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:31:37  [ main:430 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:31:37  [ main:431 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:31:37  [ main:431 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:31:37  [ main:431 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:31:37  [ main:725 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50655.
2020-12-31 10:31:37  [ main:743 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:31:37  [ main:757 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:31:37  [ main:759 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:31:37  [ main:759 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:31:37  [ main:771 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-c0bfd7af-748c-47cf-89fd-11b55d375f52
2020-12-31 10:31:37  [ main:794 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:31:37  [ main:807 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:31:37  [ main:879 ] - [ INFO ]  Logging initialized @1780ms
2020-12-31 10:31:38  [ main:929 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:31:38  [ main:942 ] - [ INFO ]  Started @1844ms
2020-12-31 10:31:38  [ main:959 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:31:38  [ main:960 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:31:38  [ main:979 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:980 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:984 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:987 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:988 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:988 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:989 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:998 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:999 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:31:38  [ main:1090 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:31:38  [ main:1141 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50656.
2020-12-31 10:31:38  [ main:1142 ] - [ INFO ]  Server created on 192.168.3.166:50656
2020-12-31 10:31:38  [ main:1143 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:31:38  [ main:1158 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50656, None)
2020-12-31 10:31:38  [ dispatcher-event-loop-10:1161 ] - [ INFO ]  Registering block manager 192.168.3.166:50656 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50656, None)
2020-12-31 10:31:38  [ main:1163 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50656, None)
2020-12-31 10:31:38  [ main:1163 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50656, None)
2020-12-31 10:31:38  [ main:1267 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:31:38  [ main:1594 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:31:38  [ main:1696 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:31:38  [ dispatcher-event-loop-12:1697 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50656 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:31:38  [ main:1700 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:31:38  [ main:1791 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:31:38  [ main:1841 ] - [ INFO ]  Starting job: take at TransformationRDD.scala:52
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1855 ] - [ INFO ]  Registering RDD 3 (repartition at TransformationRDD.scala:51)
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1858 ] - [ INFO ]  Got job 0 (take at TransformationRDD.scala:52) with 1 output partitions
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1858 ] - [ INFO ]  Final stage: ResultStage 1 (take at TransformationRDD.scala:52)
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1859 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1860 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1864 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at repartition at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1891 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 2004.4 MB)
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1894 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2020-12-31 10:31:38  [ dispatcher-event-loop-13:1895 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50656 (size: 3.2 KB, free: 2004.6 MB)
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1895 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1910 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at repartition at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:31:38  [ dag-scheduler-event-loop:1911 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:31:39  [ dispatcher-event-loop-14:1948 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:31:39  [ dispatcher-event-loop-14:1950 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:31:39  [ Executor task launch worker for task 0:1957 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:31:39  [ Executor task launch worker for task 1:1957 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:31:39  [ Executor task launch worker for task 0:2213 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+55
2020-12-31 10:31:39  [ Executor task launch worker for task 1:2213 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:55+56
2020-12-31 10:31:39  [ Executor task launch worker for task 1:2418 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1034 bytes result sent to driver
2020-12-31 10:31:39  [ Executor task launch worker for task 0:2418 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1034 bytes result sent to driver
2020-12-31 10:31:39  [ task-result-getter-1:2426 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 485 ms on localhost (executor driver) (1/2)
2020-12-31 10:31:39  [ task-result-getter-0:2429 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 479 ms on localhost (executor driver) (2/2)
2020-12-31 10:31:39  [ task-result-getter-0:2430 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2437 ] - [ INFO ]  ShuffleMapStage 0 (repartition at TransformationRDD.scala:51) finished in 0.559 s
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2438 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2438 ] - [ INFO ]  running: Set()
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2439 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2439 ] - [ INFO ]  failed: Set()
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2442 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2451 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.1 KB, free 2004.4 MB)
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2453 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:31:39  [ dispatcher-event-loop-3:2454 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50656 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2454 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2456 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0))
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2456 ] - [ INFO ]  Adding task set 1.0 with 1 tasks
2020-12-31 10:31:39  [ dispatcher-event-loop-4:2472 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7417 bytes)
2020-12-31 10:31:39  [ Executor task launch worker for task 2:2473 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:31:39  [ Executor task launch worker for task 2:2513 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:31:39  [ Executor task launch worker for task 2:2514 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2020-12-31 10:31:39  [ Executor task launch worker for task 2:2535 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 783 bytes result sent to driver
2020-12-31 10:31:39  [ task-result-getter-2:2537 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 78 ms on localhost (executor driver) (1/1)
2020-12-31 10:31:39  [ task-result-getter-2:2537 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:31:39  [ dag-scheduler-event-loop:2538 ] - [ INFO ]  ResultStage 1 (take at TransformationRDD.scala:52) finished in 0.089 s
2020-12-31 10:31:39  [ main:2541 ] - [ INFO ]  Job 0 finished: take at TransformationRDD.scala:52, took 0.700116 s
2020-12-31 10:31:39  [ Thread-1:2545 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:31:39  [ Thread-1:2551 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:31:39  [ Thread-1:2551 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:31:39  [ dispatcher-event-loop-9:2557 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:31:39  [ Thread-1:2566 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:31:39  [ Thread-1:2567 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:31:39  [ Thread-1:2570 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:31:39  [ dispatcher-event-loop-14:2571 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:31:39  [ Thread-1:2578 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:31:39  [ Thread-1:2578 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:31:39  [ Thread-1:2579 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-dd2d40b9-6824-4c95-8baf-0e11acb2edb6
2020-12-31 10:36:25  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:36:25  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:36:25  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:36:25  [ main:248 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:36:25  [ main:341 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:36:25  [ main:386 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:36:25  [ main:386 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:36:25  [ main:387 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:36:25  [ main:387 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:36:25  [ main:387 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:36:25  [ main:660 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50795.
2020-12-31 10:36:26  [ main:679 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:36:26  [ main:696 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:36:26  [ main:698 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:36:26  [ main:698 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:36:26  [ main:716 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-27b18583-18be-4169-806a-e68b0dacd9fc
2020-12-31 10:36:26  [ main:740 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:36:26  [ main:756 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:36:26  [ main:834 ] - [ INFO ]  Logging initialized @1659ms
2020-12-31 10:36:26  [ main:890 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:36:26  [ main:905 ] - [ INFO ]  Started @1731ms
2020-12-31 10:36:26  [ main:922 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:36:26  [ main:922 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:36:26  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:943 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:946 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:946 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:947 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:948 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:949 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:954 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:955 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:956 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:957 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:957 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:963 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:964 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:965 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:966 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:967 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:968 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:36:26  [ main:1063 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:36:26  [ main:1125 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50796.
2020-12-31 10:36:26  [ main:1126 ] - [ INFO ]  Server created on 192.168.3.166:50796
2020-12-31 10:36:26  [ main:1128 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:36:26  [ main:1150 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50796, None)
2020-12-31 10:36:26  [ dispatcher-event-loop-10:1153 ] - [ INFO ]  Registering block manager 192.168.3.166:50796 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50796, None)
2020-12-31 10:36:26  [ main:1156 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50796, None)
2020-12-31 10:36:26  [ main:1156 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50796, None)
2020-12-31 10:36:26  [ main:1281 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:26  [ main:1647 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:36:27  [ main:1791 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:36:27  [ dispatcher-event-loop-12:1793 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50796 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:36:27  [ main:1796 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:36:27  [ main:1911 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:36:27  [ main:1971 ] - [ INFO ]  Starting job: take at TransformationRDD.scala:52
2020-12-31 10:36:27  [ dag-scheduler-event-loop:1985 ] - [ INFO ]  Registering RDD 3 (repartition at TransformationRDD.scala:51)
2020-12-31 10:36:27  [ dag-scheduler-event-loop:1988 ] - [ INFO ]  Got job 0 (take at TransformationRDD.scala:52) with 1 output partitions
2020-12-31 10:36:27  [ dag-scheduler-event-loop:1988 ] - [ INFO ]  Final stage: ResultStage 1 (take at TransformationRDD.scala:52)
2020-12-31 10:36:27  [ dag-scheduler-event-loop:1988 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:36:27  [ dag-scheduler-event-loop:1990 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:36:27  [ dag-scheduler-event-loop:1994 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at repartition at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:36:27  [ dag-scheduler-event-loop:2021 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 2004.4 MB)
2020-12-31 10:36:27  [ dag-scheduler-event-loop:2023 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2020-12-31 10:36:27  [ dispatcher-event-loop-13:2024 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50796 (size: 3.2 KB, free: 2004.6 MB)
2020-12-31 10:36:27  [ dag-scheduler-event-loop:2024 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:36:27  [ dag-scheduler-event-loop:2039 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at repartition at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:36:27  [ dag-scheduler-event-loop:2040 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:36:27  [ dispatcher-event-loop-14:2077 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:36:27  [ dispatcher-event-loop-14:2080 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:36:27  [ Executor task launch worker for task 0:2087 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:36:27  [ Executor task launch worker for task 1:2087 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:36:27  [ Executor task launch worker for task 0:2377 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 10:36:27  [ Executor task launch worker for task 1:2377 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 10:36:27  [ Executor task launch worker for task 1:2662 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1034 bytes result sent to driver
2020-12-31 10:36:27  [ Executor task launch worker for task 0:2662 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1034 bytes result sent to driver
2020-12-31 10:36:28  [ task-result-getter-1:2670 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 601 ms on localhost (executor driver) (1/2)
2020-12-31 10:36:28  [ task-result-getter-0:2672 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 593 ms on localhost (executor driver) (2/2)
2020-12-31 10:36:28  [ task-result-getter-0:2673 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2678 ] - [ INFO ]  ShuffleMapStage 0 (repartition at TransformationRDD.scala:51) finished in 0.670 s
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2679 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2679 ] - [ INFO ]  running: Set()
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2679 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2680 ] - [ INFO ]  failed: Set()
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2684 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2695 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 5.1 KB, free 2004.4 MB)
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2698 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2004.4 MB)
2020-12-31 10:36:28  [ dispatcher-event-loop-3:2698 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50796 (size: 2.9 KB, free: 2004.6 MB)
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2699 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2702 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0))
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2702 ] - [ INFO ]  Adding task set 1.0 with 1 tasks
2020-12-31 10:36:28  [ dispatcher-event-loop-4:2721 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7417 bytes)
2020-12-31 10:36:28  [ Executor task launch worker for task 2:2721 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:36:28  [ Executor task launch worker for task 2:2774 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:36:28  [ Executor task launch worker for task 2:2775 ] - [ INFO ]  Started 0 remote fetches in 8 ms
2020-12-31 10:36:28  [ Executor task launch worker for task 2:2808 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 777 bytes result sent to driver
2020-12-31 10:36:28  [ task-result-getter-2:2810 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 105 ms on localhost (executor driver) (1/1)
2020-12-31 10:36:28  [ task-result-getter-2:2810 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:36:28  [ dag-scheduler-event-loop:2813 ] - [ INFO ]  ResultStage 1 (take at TransformationRDD.scala:52) finished in 0.121 s
2020-12-31 10:36:28  [ main:2819 ] - [ INFO ]  Job 0 finished: take at TransformationRDD.scala:52, took 0.847038 s
2020-12-31 10:36:28  [ Thread-1:2825 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:36:28  [ Thread-1:2833 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:36:28  [ Thread-1:2834 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:36:28  [ dispatcher-event-loop-9:2843 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:36:28  [ Thread-1:2857 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:36:28  [ Thread-1:2858 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:36:28  [ Thread-1:2862 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:36:28  [ dispatcher-event-loop-14:2883 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:36:28  [ Thread-1:2902 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:36:28  [ Thread-1:2903 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:36:28  [ Thread-1:2903 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-7fc848a2-4e82-4aec-9957-82cbfbf5e800
2020-12-31 10:36:41  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:36:41  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:36:41  [ main:48 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:36:41  [ main:290 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:36:41  [ main:385 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:36:41  [ main:442 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:36:41  [ main:442 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:36:41  [ main:443 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:36:41  [ main:443 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:36:41  [ main:444 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:36:42  [ main:784 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50806.
2020-12-31 10:36:42  [ main:804 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:36:42  [ main:820 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:36:42  [ main:822 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:36:42  [ main:822 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:36:42  [ main:836 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-a9d2e803-ac28-4d05-b979-76a273fbd6c1
2020-12-31 10:36:42  [ main:859 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:36:42  [ main:872 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:36:42  [ main:944 ] - [ INFO ]  Logging initialized @1761ms
2020-12-31 10:36:42  [ main:993 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:36:42  [ main:1006 ] - [ INFO ]  Started @1824ms
2020-12-31 10:36:42  [ main:1022 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:36:42  [ main:1023 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:36:42  [ main:1042 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1043 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1043 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1044 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1045 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1045 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1046 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1047 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1047 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1048 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1048 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1049 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1049 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1050 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1050 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1051 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1052 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1052 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1053 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1053 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1058 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1059 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1059 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1060 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1060 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:36:42  [ main:1061 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:36:42  [ main:1150 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:36:42  [ main:1203 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50807.
2020-12-31 10:36:42  [ main:1203 ] - [ INFO ]  Server created on 192.168.3.166:50807
2020-12-31 10:36:42  [ main:1204 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:36:42  [ main:1223 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50807, None)
2020-12-31 10:36:42  [ dispatcher-event-loop-10:1226 ] - [ INFO ]  Registering block manager 192.168.3.166:50807 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50807, None)
2020-12-31 10:36:42  [ main:1228 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50807, None)
2020-12-31 10:36:42  [ main:1228 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50807, None)
2020-12-31 10:36:42  [ main:1332 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:36:43  [ main:1650 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:36:43  [ main:1768 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:36:43  [ dispatcher-event-loop-12:1770 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50807 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:36:43  [ main:1772 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:36:43  [ main:1862 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:36:43  [ main:1915 ] - [ INFO ]  Starting job: take at TransformationRDD.scala:52
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1931 ] - [ INFO ]  Registering RDD 3 (repartition at TransformationRDD.scala:51)
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1933 ] - [ INFO ]  Got job 0 (take at TransformationRDD.scala:52) with 1 output partitions
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1934 ] - [ INFO ]  Final stage: ResultStage 1 (take at TransformationRDD.scala:52)
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1934 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1935 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1939 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at repartition at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1967 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 2004.4 MB)
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1969 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2020-12-31 10:36:43  [ dispatcher-event-loop-13:1970 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50807 (size: 3.2 KB, free: 2004.6 MB)
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1971 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1984 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at repartition at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:36:43  [ dag-scheduler-event-loop:1985 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:36:43  [ dispatcher-event-loop-14:2021 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:36:43  [ dispatcher-event-loop-14:2023 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:36:43  [ Executor task launch worker for task 1:2030 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:36:43  [ Executor task launch worker for task 0:2031 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:36:43  [ Executor task launch worker for task 1:2279 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 10:36:43  [ Executor task launch worker for task 0:2279 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 10:36:44  [ Executor task launch worker for task 1:2511 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1034 bytes result sent to driver
2020-12-31 10:36:44  [ Executor task launch worker for task 0:2511 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1034 bytes result sent to driver
2020-12-31 10:36:44  [ task-result-getter-0:2517 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 493 ms on localhost (executor driver) (1/2)
2020-12-31 10:36:44  [ task-result-getter-1:2518 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 506 ms on localhost (executor driver) (2/2)
2020-12-31 10:36:44  [ task-result-getter-1:2519 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  ShuffleMapStage 0 (repartition at TransformationRDD.scala:51) finished in 0.571 s
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2524 ] - [ INFO ]  running: Set()
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2525 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2525 ] - [ INFO ]  failed: Set()
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2527 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[6] at repartition at TransformationRDD.scala:51), which has no missing parents
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2536 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 2004.4 MB)
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2538 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2004.4 MB)
2020-12-31 10:36:44  [ dispatcher-event-loop-3:2539 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50807 (size: 2.7 KB, free: 2004.6 MB)
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2539 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2541 ] - [ INFO ]  Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at repartition at TransformationRDD.scala:51) (first 15 tasks are for partitions Vector(0))
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2541 ] - [ INFO ]  Adding task set 1.0 with 1 tasks
2020-12-31 10:36:44  [ dispatcher-event-loop-4:2558 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7417 bytes)
2020-12-31 10:36:44  [ Executor task launch worker for task 2:2559 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:36:44  [ Executor task launch worker for task 2:2603 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:36:44  [ Executor task launch worker for task 2:2605 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:36:44  [ Executor task launch worker for task 2:2628 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 733 bytes result sent to driver
2020-12-31 10:36:44  [ task-result-getter-2:2629 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 86 ms on localhost (executor driver) (1/1)
2020-12-31 10:36:44  [ task-result-getter-2:2629 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:36:44  [ dag-scheduler-event-loop:2630 ] - [ INFO ]  ResultStage 1 (take at TransformationRDD.scala:52) finished in 0.097 s
2020-12-31 10:36:44  [ main:2634 ] - [ INFO ]  Job 0 finished: take at TransformationRDD.scala:52, took 0.718319 s
2020-12-31 10:36:44  [ Thread-1:2638 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:36:44  [ Thread-1:2644 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:36:44  [ Thread-1:2645 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:36:44  [ dispatcher-event-loop-9:2651 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:36:44  [ Thread-1:2665 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:36:44  [ Thread-1:2665 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:36:44  [ Thread-1:2669 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:36:44  [ dispatcher-event-loop-14:2670 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:36:44  [ Thread-1:2682 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:36:44  [ Thread-1:2683 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:36:44  [ Thread-1:2683 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-761006ee-37ce-491f-936f-faef74a07905
2020-12-31 10:40:09  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:40:09  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:40:09  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:40:09  [ main:261 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:40:10  [ main:371 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:40:10  [ main:449 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:40:10  [ main:451 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:40:10  [ main:452 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:40:10  [ main:452 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:40:10  [ main:453 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:40:10  [ main:750 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50832.
2020-12-31 10:40:10  [ main:770 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:40:10  [ main:786 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:40:10  [ main:788 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:40:10  [ main:789 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:40:10  [ main:803 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-ce0b9278-c496-4752-9fb3-96d95f039b46
2020-12-31 10:40:10  [ main:827 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:40:10  [ main:840 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:40:10  [ main:915 ] - [ INFO ]  Logging initialized @1705ms
2020-12-31 10:40:10  [ main:963 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:40:10  [ main:976 ] - [ INFO ]  Started @1767ms
2020-12-31 10:40:10  [ main:991 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:40:10  [ main:991 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:40:10  [ main:1008 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1009 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1010 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1010 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1011 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1011 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1012 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1012 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1013 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1013 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1014 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1014 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1015 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1016 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1016 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1017 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1017 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1018 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1018 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1019 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1023 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1024 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1025 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1025 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1025 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:40:10  [ main:1027 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:40:10  [ main:1129 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:40:10  [ main:1195 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50833.
2020-12-31 10:40:10  [ main:1196 ] - [ INFO ]  Server created on 192.168.3.166:50833
2020-12-31 10:40:10  [ main:1197 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:40:10  [ main:1217 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50833, None)
2020-12-31 10:40:10  [ dispatcher-event-loop-10:1221 ] - [ INFO ]  Registering block manager 192.168.3.166:50833 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50833, None)
2020-12-31 10:40:10  [ main:1223 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50833, None)
2020-12-31 10:40:10  [ main:1223 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50833, None)
2020-12-31 10:40:11  [ main:1347 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:11  [ main:1700 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:40:11  [ main:1831 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:40:11  [ dispatcher-event-loop-12:1833 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50833 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:40:11  [ main:1836 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:40:11  [ main:1915 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:40:11  [ main:1965 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:40:11  [ dag-scheduler-event-loop:2194 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:52)
2020-12-31 10:40:11  [ dag-scheduler-event-loop:2198 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 10:40:11  [ dag-scheduler-event-loop:2198 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at TransformationRDD.scala:53)
2020-12-31 10:40:11  [ dag-scheduler-event-loop:2199 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:40:11  [ dag-scheduler-event-loop:2202 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:40:11  [ dag-scheduler-event-loop:2209 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2278 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 2004.4 MB)
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2281 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2020-12-31 10:40:12  [ dispatcher-event-loop-13:2282 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50833 (size: 3.3 KB, free: 2004.6 MB)
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2283 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2301 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2302 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:40:12  [ dispatcher-event-loop-14:2344 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:40:12  [ dispatcher-event-loop-14:2347 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:40:12  [ Executor task launch worker for task 0:2356 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:40:12  [ Executor task launch worker for task 1:2356 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:40:12  [ Executor task launch worker for task 1:2684 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 10:40:12  [ Executor task launch worker for task 0:2684 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 10:40:12  [ Executor task launch worker for task 1:2830 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 10:40:12  [ Executor task launch worker for task 0:2830 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 10:40:12  [ task-result-getter-0:2837 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 490 ms on localhost (executor driver) (1/2)
2020-12-31 10:40:12  [ task-result-getter-1:2839 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 506 ms on localhost (executor driver) (2/2)
2020-12-31 10:40:12  [ task-result-getter-1:2839 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2845 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:52) finished in 0.601 s
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2845 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2846 ] - [ INFO ]  running: Set()
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2846 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2847 ] - [ INFO ]  failed: Set()
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2850 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2859 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 4.0 KB, free 2004.4 MB)
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2861 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2020-12-31 10:40:12  [ dispatcher-event-loop-3:2862 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50833 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2862 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2865 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2865 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:40:12  [ dispatcher-event-loop-4:2870 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 10:40:12  [ dispatcher-event-loop-4:2870 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 10:40:12  [ Executor task launch worker for task 3:2871 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:40:12  [ Executor task launch worker for task 2:2871 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:40:12  [ Executor task launch worker for task 2:2890 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:40:12  [ Executor task launch worker for task 3:2890 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:40:12  [ Executor task launch worker for task 2:2891 ] - [ INFO ]  Started 0 remote fetches in 6 ms
2020-12-31 10:40:12  [ Executor task launch worker for task 3:2891 ] - [ INFO ]  Started 0 remote fetches in 6 ms
2020-12-31 10:40:12  [ Executor task launch worker for task 2:2970 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1101 bytes result sent to driver
2020-12-31 10:40:12  [ Executor task launch worker for task 3:2970 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1101 bytes result sent to driver
2020-12-31 10:40:12  [ task-result-getter-2:2972 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 104 ms on localhost (executor driver) (1/2)
2020-12-31 10:40:12  [ task-result-getter-3:2973 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 103 ms on localhost (executor driver) (2/2)
2020-12-31 10:40:12  [ task-result-getter-3:2973 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:40:12  [ dag-scheduler-event-loop:2975 ] - [ INFO ]  ResultStage 1 (foreach at TransformationRDD.scala:53) finished in 0.119 s
2020-12-31 10:40:12  [ main:2980 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 1.014637 s
2020-12-31 10:40:12  [ Thread-1:2984 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:40:12  [ Thread-1:3003 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:40:12  [ Thread-1:3004 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:40:12  [ Spark Context Cleaner:3005 ] - [ INFO ]  Cleaned accumulator 48
2020-12-31 10:40:12  [ Spark Context Cleaner:3005 ] - [ INFO ]  Cleaned accumulator 41
2020-12-31 10:40:12  [ Spark Context Cleaner:3005 ] - [ INFO ]  Cleaned accumulator 28
2020-12-31 10:40:12  [ Spark Context Cleaner:3005 ] - [ INFO ]  Cleaned accumulator 31
2020-12-31 10:40:12  [ Spark Context Cleaner:3005 ] - [ INFO ]  Cleaned accumulator 25
2020-12-31 10:40:12  [ dispatcher-event-loop-11:3108 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:40:12  [ Thread-1:3121 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:40:12  [ Thread-1:3122 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:40:12  [ Thread-1:3125 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:40:12  [ dispatcher-event-loop-15:3126 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:40:12  [ Thread-1:3133 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:40:12  [ Thread-1:3133 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:40:12  [ Thread-1:3134 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-97063c3c-6d68-4caa-b29a-502cef4d38be
2020-12-31 10:40:46  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:40:46  [ main:0 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:40:46  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:40:46  [ main:254 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:40:46  [ main:348 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:40:47  [ main:409 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:40:47  [ main:410 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:40:47  [ main:410 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:40:47  [ main:411 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:40:47  [ main:411 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:40:47  [ main:722 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50852.
2020-12-31 10:40:47  [ main:745 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:40:47  [ main:761 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:40:47  [ main:763 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:40:47  [ main:763 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:40:47  [ main:778 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-09bf3860-1735-44b2-8632-3c854c2f8b40
2020-12-31 10:40:47  [ main:802 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:40:47  [ main:819 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:40:47  [ main:896 ] - [ INFO ]  Logging initialized @1696ms
2020-12-31 10:40:47  [ main:939 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:40:47  [ main:950 ] - [ INFO ]  Started @1751ms
2020-12-31 10:40:47  [ main:964 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:40:47  [ main:964 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:40:47  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:981 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:982 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:983 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:984 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:985 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:986 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:987 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:987 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:988 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:989 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:989 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:995 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:40:47  [ main:998 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:40:47  [ main:1086 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:40:47  [ main:1138 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50853.
2020-12-31 10:40:47  [ main:1138 ] - [ INFO ]  Server created on 192.168.3.166:50853
2020-12-31 10:40:47  [ main:1139 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:40:47  [ main:1156 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50853, None)
2020-12-31 10:40:47  [ dispatcher-event-loop-10:1159 ] - [ INFO ]  Registering block manager 192.168.3.166:50853 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50853, None)
2020-12-31 10:40:47  [ main:1160 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50853, None)
2020-12-31 10:40:47  [ main:1161 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50853, None)
2020-12-31 10:40:47  [ main:1266 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:40:48  [ main:1592 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:40:48  [ main:1688 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:40:48  [ dispatcher-event-loop-12:1690 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50853 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:40:48  [ main:1693 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:40:48  [ main:1762 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:40:48  [ main:1802 ] - [ INFO ]  Starting job: foreach at TransformationRDD.scala:53
2020-12-31 10:40:48  [ dag-scheduler-event-loop:1997 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:52)
2020-12-31 10:40:48  [ dag-scheduler-event-loop:1999 ] - [ INFO ]  Got job 0 (foreach at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 10:40:48  [ dag-scheduler-event-loop:1999 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at TransformationRDD.scala:53)
2020-12-31 10:40:48  [ dag-scheduler-event-loop:1999 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2001 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2005 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2046 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 2004.4 MB)
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2054 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2020-12-31 10:40:48  [ dispatcher-event-loop-13:2055 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50853 (size: 3.3 KB, free: 2004.6 MB)
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2056 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2067 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:40:48  [ dag-scheduler-event-loop:2068 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:40:48  [ dispatcher-event-loop-14:2102 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:40:48  [ dispatcher-event-loop-14:2104 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:40:48  [ Executor task launch worker for task 0:2111 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:40:48  [ Executor task launch worker for task 1:2111 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:40:48  [ Executor task launch worker for task 1:2361 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 10:40:48  [ Executor task launch worker for task 0:2361 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 10:40:49  [ Executor task launch worker for task 0:2481 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 10:40:49  [ Executor task launch worker for task 1:2481 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 10:40:49  [ task-result-getter-1:2488 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 383 ms on localhost (executor driver) (1/2)
2020-12-31 10:40:49  [ task-result-getter-0:2490 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 397 ms on localhost (executor driver) (2/2)
2020-12-31 10:40:49  [ task-result-getter-0:2491 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2496 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:52) finished in 0.469 s
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2497 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2497 ] - [ INFO ]  running: Set()
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2497 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2498 ] - [ INFO ]  failed: Set()
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2500 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at TransformationRDD.scala:53), which has no missing parents
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2510 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 4.0 KB, free 2004.4 MB)
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2511 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2020-12-31 10:40:49  [ dispatcher-event-loop-3:2512 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50853 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2513 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2515 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2515 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:40:49  [ dispatcher-event-loop-4:2519 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 10:40:49  [ dispatcher-event-loop-4:2519 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 10:40:49  [ Executor task launch worker for task 3:2520 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:40:49  [ Executor task launch worker for task 2:2520 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:40:49  [ Executor task launch worker for task 3:2537 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:40:49  [ Executor task launch worker for task 2:2537 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:40:49  [ Executor task launch worker for task 3:2538 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2020-12-31 10:40:49  [ Executor task launch worker for task 2:2538 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2020-12-31 10:40:49  [ Executor task launch worker for task 2:2595 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1101 bytes result sent to driver
2020-12-31 10:40:49  [ Executor task launch worker for task 3:2595 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1101 bytes result sent to driver
2020-12-31 10:40:49  [ task-result-getter-3:2597 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 78 ms on localhost (executor driver) (1/2)
2020-12-31 10:40:49  [ task-result-getter-2:2598 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 80 ms on localhost (executor driver) (2/2)
2020-12-31 10:40:49  [ task-result-getter-2:2598 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:40:49  [ dag-scheduler-event-loop:2599 ] - [ INFO ]  ResultStage 1 (foreach at TransformationRDD.scala:53) finished in 0.092 s
2020-12-31 10:40:49  [ main:2605 ] - [ INFO ]  Job 0 finished: foreach at TransformationRDD.scala:53, took 0.802235 s
2020-12-31 10:40:49  [ Thread-1:2696 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 12
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 8
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 9
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 10
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 1
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 22
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 33
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 43
2020-12-31 10:40:49  [ Spark Context Cleaner:2698 ] - [ INFO ]  Cleaned accumulator 49
2020-12-31 10:40:49  [ Spark Context Cleaner:2699 ] - [ INFO ]  Cleaned accumulator 5
2020-12-31 10:40:49  [ Spark Context Cleaner:2699 ] - [ INFO ]  Cleaned accumulator 27
2020-12-31 10:40:49  [ Spark Context Cleaner:2699 ] - [ INFO ]  Cleaned accumulator 44
2020-12-31 10:40:49  [ Spark Context Cleaner:2699 ] - [ INFO ]  Cleaned accumulator 47
2020-12-31 10:40:49  [ Spark Context Cleaner:2699 ] - [ INFO ]  Cleaned accumulator 18
2020-12-31 10:40:49  [ Spark Context Cleaner:2699 ] - [ INFO ]  Cleaned accumulator 35
2020-12-31 10:40:49  [ Thread-1:2705 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:40:49  [ Thread-1:2706 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:40:49  [ dispatcher-event-loop-11:2712 ] - [ INFO ]  Removed broadcast_2_piece0 on 192.168.3.166:50853 in memory (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:40:49  [ dispatcher-event-loop-14:2720 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:40:49  [ Thread-1:2730 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:40:49  [ Thread-1:2730 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:40:49  [ Thread-1:2731 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:40:49  [ dispatcher-event-loop-3:2733 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:40:49  [ Thread-1:2739 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:40:49  [ Thread-1:2740 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:40:49  [ Thread-1:2740 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-eec17dcd-f5d8-4265-b6b5-172d8ef5d2a0
2020-12-31 10:41:54  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:41:54  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:41:55  [ main:41 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:41:55  [ main:254 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:41:55  [ main:337 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:41:55  [ main:404 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:41:55  [ main:405 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:41:55  [ main:405 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:41:55  [ main:406 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:41:55  [ main:406 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:41:55  [ main:701 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50865.
2020-12-31 10:41:55  [ main:721 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:41:55  [ main:740 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:41:55  [ main:742 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:41:55  [ main:743 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:41:55  [ main:757 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-ce4187e8-7475-4406-857a-b11cf7db298f
2020-12-31 10:41:55  [ main:779 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:41:55  [ main:792 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:41:55  [ main:862 ] - [ INFO ]  Logging initialized @1648ms
2020-12-31 10:41:55  [ main:905 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:41:55  [ main:917 ] - [ INFO ]  Started @1703ms
2020-12-31 10:41:55  [ main:931 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:41:55  [ main:931 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:41:55  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:954 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:955 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:956 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:956 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:957 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:957 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:958 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:959 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:960 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:960 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:961 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:961 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:962 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:966 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:967 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:968 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:968 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:969 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:41:55  [ main:970 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:41:56  [ main:1061 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:41:56  [ main:1117 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50866.
2020-12-31 10:41:56  [ main:1118 ] - [ INFO ]  Server created on 192.168.3.166:50866
2020-12-31 10:41:56  [ main:1119 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:41:56  [ main:1138 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50866, None)
2020-12-31 10:41:56  [ dispatcher-event-loop-10:1141 ] - [ INFO ]  Registering block manager 192.168.3.166:50866 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50866, None)
2020-12-31 10:41:56  [ main:1143 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50866, None)
2020-12-31 10:41:56  [ main:1143 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50866, None)
2020-12-31 10:41:56  [ main:1256 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:41:56  [ main:1617 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:41:56  [ main:1743 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:41:56  [ dispatcher-event-loop-12:1745 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50866 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:41:56  [ main:1747 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:41:56  [ main:1823 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:41:56  [ main:1883 ] - [ INFO ]  mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2020-12-31 10:41:56  [ main:1888 ] - [ INFO ]  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
2020-12-31 10:41:56  [ main:1908 ] - [ INFO ]  Starting job: runJob at SparkHadoopWriter.scala:78
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2102 ] - [ INFO ]  Registering RDD 3 (map at TransformationRDD.scala:52)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2105 ] - [ INFO ]  Got job 0 (runJob at SparkHadoopWriter.scala:78) with 2 output partitions
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2105 ] - [ INFO ]  Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:78)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2105 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2107 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2112 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2165 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 2004.4 MB)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2167 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2020-12-31 10:41:57  [ dispatcher-event-loop-13:2168 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50866 (size: 3.3 KB, free: 2004.6 MB)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2168 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2179 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2180 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:41:57  [ dispatcher-event-loop-14:2217 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:41:57  [ dispatcher-event-loop-14:2219 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:41:57  [ Executor task launch worker for task 1:2227 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:41:57  [ Executor task launch worker for task 0:2228 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:41:57  [ Executor task launch worker for task 1:2520 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 10:41:57  [ Executor task launch worker for task 0:2520 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 10:41:57  [ Executor task launch worker for task 0:2655 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 10:41:57  [ Executor task launch worker for task 1:2655 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 10:41:57  [ task-result-getter-0:2662 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 455 ms on localhost (executor driver) (1/2)
2020-12-31 10:41:57  [ task-result-getter-1:2664 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 445 ms on localhost (executor driver) (2/2)
2020-12-31 10:41:57  [ task-result-getter-1:2665 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2671 ] - [ INFO ]  ShuffleMapStage 0 (map at TransformationRDD.scala:52) finished in 0.523 s
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2672 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2672 ] - [ INFO ]  running: Set()
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2673 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2673 ] - [ INFO ]  failed: Set()
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2676 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at saveAsTextFile at TransformationRDD.scala:54), which has no missing parents
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2699 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 66.9 KB, free 2004.3 MB)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2702 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.3 KB, free 2004.3 MB)
2020-12-31 10:41:57  [ dispatcher-event-loop-3:2703 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50866 (size: 24.3 KB, free: 2004.6 MB)
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2704 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2706 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at saveAsTextFile at TransformationRDD.scala:54) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2706 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:41:57  [ dispatcher-event-loop-4:2711 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 10:41:57  [ dispatcher-event-loop-4:2711 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2711 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2711 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2764 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2764 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2766 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2766 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:41:57  [ dispatcher-event-loop-9:2901 ] - [ INFO ]  Removed broadcast_1_piece0 on 192.168.3.166:50866 in memory (size: 3.3 KB, free: 2004.6 MB)
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2914 ] - [ INFO ]  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2914 ] - [ INFO ]  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2953 ] - [ INFO ]  Saved output of task 'attempt_20201231104156_0005_m_000000_0' to file:/Users/liuwenyi/IdeaProjects/satan/data/result.txt/_temporary/0/task_20201231104156_0005_m_000000
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2954 ] - [ INFO ]  Saved output of task 'attempt_20201231104156_0005_m_000001_0' to file:/Users/liuwenyi/IdeaProjects/satan/data/result.txt/_temporary/0/task_20201231104156_0005_m_000001
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2954 ] - [ INFO ]  attempt_20201231104156_0005_m_000000_0: Committed
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2954 ] - [ INFO ]  attempt_20201231104156_0005_m_000001_0: Committed
2020-12-31 10:41:57  [ Executor task launch worker for task 2:2957 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1508 bytes result sent to driver
2020-12-31 10:41:57  [ Executor task launch worker for task 3:2957 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1508 bytes result sent to driver
2020-12-31 10:41:57  [ task-result-getter-2:2959 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 250 ms on localhost (executor driver) (1/2)
2020-12-31 10:41:57  [ task-result-getter-3:2959 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 248 ms on localhost (executor driver) (2/2)
2020-12-31 10:41:57  [ task-result-getter-3:2959 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:41:57  [ dag-scheduler-event-loop:2960 ] - [ INFO ]  ResultStage 1 (runJob at SparkHadoopWriter.scala:78) finished in 0.277 s
2020-12-31 10:41:57  [ main:2965 ] - [ INFO ]  Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 1.055911 s
2020-12-31 10:41:57  [ main:2983 ] - [ INFO ]  Job job_20201231104156_0005 committed.
2020-12-31 10:41:57  [ Thread-1:2985 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:41:57  [ Thread-1:2992 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:41:57  [ Thread-1:2993 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:41:57  [ dispatcher-event-loop-15:3000 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:41:58  [ Thread-1:3012 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:41:58  [ Thread-1:3013 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:41:58  [ Thread-1:3014 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:41:58  [ dispatcher-event-loop-5:3015 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:41:58  [ Thread-1:3023 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:41:58  [ Thread-1:3023 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:41:58  [ Thread-1:3024 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-b45f7fc0-d1d1-4cc5-a39d-b6cf16d014ea
2020-12-31 10:46:00  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 10:46:00  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 10:46:00  [ main:58 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 10:46:00  [ main:247 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 10:46:00  [ main:318 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 10:46:01  [ main:370 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 10:46:01  [ main:371 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 10:46:01  [ main:371 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 10:46:01  [ main:372 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 10:46:01  [ main:372 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 10:46:01  [ main:665 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50916.
2020-12-31 10:46:01  [ main:685 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 10:46:01  [ main:703 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 10:46:01  [ main:705 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 10:46:01  [ main:705 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 10:46:01  [ main:720 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-0461e8b0-0b42-4328-8349-6ebb404b333f
2020-12-31 10:46:01  [ main:744 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 10:46:01  [ main:759 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 10:46:01  [ main:831 ] - [ INFO ]  Logging initialized @1606ms
2020-12-31 10:46:01  [ main:882 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 10:46:01  [ main:897 ] - [ INFO ]  Started @1672ms
2020-12-31 10:46:01  [ main:912 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:46:01  [ main:913 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 10:46:01  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:937 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:938 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:939 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:939 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:940 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:941 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:943 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 10:46:01  [ main:954 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 10:46:01  [ main:1055 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 10:46:01  [ main:1114 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50917.
2020-12-31 10:46:01  [ main:1114 ] - [ INFO ]  Server created on 192.168.3.166:50917
2020-12-31 10:46:01  [ main:1115 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 10:46:01  [ main:1134 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 50917, None)
2020-12-31 10:46:01  [ dispatcher-event-loop-10:1137 ] - [ INFO ]  Registering block manager 192.168.3.166:50917 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 50917, None)
2020-12-31 10:46:01  [ main:1139 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 50917, None)
2020-12-31 10:46:01  [ main:1139 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 50917, None)
2020-12-31 10:46:01  [ main:1250 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 10:46:02  [ main:1621 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 10:46:02  [ main:1758 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 10:46:02  [ dispatcher-event-loop-12:1760 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:50917 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 10:46:02  [ main:1762 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 10:46:02  [ main:1858 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 10:46:02  [ main:1908 ] - [ INFO ]  Starting job: countByKey at TransformationRDD.scala:52
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2107 ] - [ INFO ]  Registering RDD 4 (countByKey at TransformationRDD.scala:52)
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2109 ] - [ INFO ]  Got job 0 (countByKey at TransformationRDD.scala:52) with 2 output partitions
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2109 ] - [ INFO ]  Final stage: ResultStage 1 (countByKey at TransformationRDD.scala:52)
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2110 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2111 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2116 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2160 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2162 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2004.4 MB)
2020-12-31 10:46:02  [ dispatcher-event-loop-13:2162 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:50917 (size: 3.4 KB, free: 2004.6 MB)
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2174 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:46:02  [ dag-scheduler-event-loop:2175 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 10:46:02  [ dispatcher-event-loop-14:2210 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:46:02  [ dispatcher-event-loop-14:2211 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 10:46:02  [ Executor task launch worker for task 0:2218 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 10:46:02  [ Executor task launch worker for task 1:2219 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 10:46:03  [ Executor task launch worker for task 1:2517 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 10:46:03  [ Executor task launch worker for task 0:2517 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 10:46:03  [ Executor task launch worker for task 1:2639 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 10:46:03  [ Executor task launch worker for task 0:2639 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 10:46:03  [ task-result-getter-1:2645 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 445 ms on localhost (executor driver) (1/2)
2020-12-31 10:46:03  [ task-result-getter-0:2647 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 436 ms on localhost (executor driver) (2/2)
2020-12-31 10:46:03  [ task-result-getter-0:2648 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2654 ] - [ INFO ]  ShuffleMapStage 0 (countByKey at TransformationRDD.scala:52) finished in 0.508 s
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2655 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2655 ] - [ INFO ]  running: Set()
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2655 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2656 ] - [ INFO ]  failed: Set()
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2658 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:52), which has no missing parents
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2667 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 2004.4 MB)
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2670 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2020-12-31 10:46:03  [ dispatcher-event-loop-3:2671 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:50917 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2672 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2674 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:52) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2674 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 10:46:03  [ dispatcher-event-loop-4:2679 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 10:46:03  [ dispatcher-event-loop-4:2679 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 10:46:03  [ Executor task launch worker for task 3:2679 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 10:46:03  [ Executor task launch worker for task 2:2679 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 10:46:03  [ Executor task launch worker for task 3:2700 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:46:03  [ Executor task launch worker for task 2:2700 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 10:46:03  [ Executor task launch worker for task 2:2701 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:46:03  [ Executor task launch worker for task 3:2701 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 10:46:03  [ Executor task launch worker for task 3:2757 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 7013 bytes result sent to driver
2020-12-31 10:46:03  [ Executor task launch worker for task 2:2757 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 6810 bytes result sent to driver
2020-12-31 10:46:03  [ task-result-getter-2:2760 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 81 ms on localhost (executor driver) (1/2)
2020-12-31 10:46:03  [ task-result-getter-3:2760 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 83 ms on localhost (executor driver) (2/2)
2020-12-31 10:46:03  [ task-result-getter-3:2761 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 10:46:03  [ dag-scheduler-event-loop:2762 ] - [ INFO ]  ResultStage 1 (countByKey at TransformationRDD.scala:52) finished in 0.096 s
2020-12-31 10:46:03  [ main:2769 ] - [ INFO ]  Job 0 finished: countByKey at TransformationRDD.scala:52, took 0.859980 s
2020-12-31 10:46:03  [ Thread-1:2781 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 30
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 10
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 19
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 22
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 31
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 45
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 9
2020-12-31 10:46:03  [ Spark Context Cleaner:2794 ] - [ INFO ]  Cleaned accumulator 18
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 29
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 2
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 1
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 26
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 15
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 48
2020-12-31 10:46:03  [ Spark Context Cleaner:2795 ] - [ INFO ]  Cleaned accumulator 17
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 4
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 0
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 8
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 38
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 13
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 24
2020-12-31 10:46:03  [ Spark Context Cleaner:2796 ] - [ INFO ]  Cleaned accumulator 25
2020-12-31 10:46:03  [ Spark Context Cleaner:2797 ] - [ INFO ]  Cleaned accumulator 32
2020-12-31 10:46:03  [ Thread-1:2797 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 10:46:03  [ Spark Context Cleaner:2797 ] - [ INFO ]  Cleaned accumulator 21
2020-12-31 10:46:03  [ Spark Context Cleaner:2797 ] - [ INFO ]  Cleaned accumulator 14
2020-12-31 10:46:03  [ Spark Context Cleaner:2797 ] - [ INFO ]  Cleaned accumulator 12
2020-12-31 10:46:03  [ Thread-1:2798 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 10:46:03  [ dispatcher-event-loop-11:2919 ] - [ INFO ]  Removed broadcast_2_piece0 on 192.168.3.166:50917 in memory (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 10:46:03  [ dispatcher-event-loop-14:2928 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 10:46:03  [ Thread-1:2940 ] - [ INFO ]  MemoryStore cleared
2020-12-31 10:46:03  [ Thread-1:2940 ] - [ INFO ]  BlockManager stopped
2020-12-31 10:46:03  [ Thread-1:2941 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 10:46:03  [ dispatcher-event-loop-3:2943 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 10:46:03  [ Thread-1:2950 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 10:46:03  [ Thread-1:2950 ] - [ INFO ]  Shutdown hook called
2020-12-31 10:46:03  [ Thread-1:2950 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-1ddd06a5-0870-413e-a58d-0acfa6ce609f
2020-12-31 14:08:31  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 14:08:31  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 14:08:31  [ main:53 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 14:08:31  [ main:402 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 14:08:31  [ main:587 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 14:08:31  [ main:702 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 14:08:31  [ main:702 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 14:08:31  [ main:703 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 14:08:31  [ main:704 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 14:08:31  [ main:704 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 14:08:32  [ main:1291 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 53303.
2020-12-31 14:08:32  [ main:1336 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 14:08:32  [ main:1366 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 14:08:32  [ main:1370 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 14:08:32  [ main:1370 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 14:08:32  [ main:1391 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-fb616706-85b6-4c13-85fa-603578c18900
2020-12-31 14:08:32  [ main:1425 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 14:08:32  [ main:1443 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 14:08:32  [ main:1570 ] - [ INFO ]  Logging initialized @2490ms
2020-12-31 14:08:32  [ main:1657 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 14:08:32  [ main:1680 ] - [ INFO ]  Started @2601ms
2020-12-31 14:08:32  [ main:1709 ] - [ INFO ]  Started ServerConnector@150ab4ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 14:08:32  [ main:1709 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 14:08:32  [ main:1743 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62435e70{/jobs,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1744 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@54227100{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1745 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1746 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1747 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1748 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5778826f{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1749 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b64c4b7{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1750 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1751 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1752 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1753 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1754 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1754 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1755 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1756 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/environment,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1757 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1757 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1758 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1759 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1760 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2dbf4cbd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1769 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@20b5f2ac{/static,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1770 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@42a9e5d1{/,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1771 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b080f3a{/api,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1772 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7d3430a7{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1772 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6f603e89{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 14:08:32  [ main:1774 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 14:08:33  [ main:1922 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 14:08:33  [ main:1990 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53305.
2020-12-31 14:08:33  [ main:1990 ] - [ INFO ]  Server created on 192.168.3.166:53305
2020-12-31 14:08:33  [ main:1992 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 14:08:33  [ main:2017 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 53305, None)
2020-12-31 14:08:33  [ dispatcher-event-loop-10:2020 ] - [ INFO ]  Registering block manager 192.168.3.166:53305 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 53305, None)
2020-12-31 14:08:33  [ main:2023 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 53305, None)
2020-12-31 14:08:33  [ main:2024 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 53305, None)
2020-12-31 14:08:33  [ main:2231 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@46292372{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 14:08:33  [ main:2718 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 14:08:34  [ main:3066 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 14:08:34  [ dispatcher-event-loop-12:3069 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:53305 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 14:08:34  [ main:3073 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 14:08:34  [ main:3794 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 14:08:35  [ main:3887 ] - [ INFO ]  Starting job: countByKey at TransformationRDD.scala:53
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4200 ] - [ INFO ]  Registering RDD 4 (countByKey at TransformationRDD.scala:53)
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4203 ] - [ INFO ]  Got job 0 (countByKey at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4204 ] - [ INFO ]  Final stage: ResultStage 1 (countByKey at TransformationRDD.scala:53)
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4204 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4206 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4212 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:53), which has no missing parents
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4257 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4259 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2004.4 MB)
2020-12-31 14:08:35  [ dispatcher-event-loop-13:4260 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:53305 (size: 3.4 KB, free: 2004.6 MB)
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4260 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4273 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:08:35  [ dag-scheduler-event-loop:4274 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 14:08:35  [ dispatcher-event-loop-14:4314 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 14:08:35  [ dispatcher-event-loop-14:4317 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 14:08:35  [ Executor task launch worker for task 1:4325 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 14:08:35  [ Executor task launch worker for task 0:4325 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 14:08:35  [ Executor task launch worker for task 1:4773 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 14:08:35  [ Executor task launch worker for task 0:4773 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 14:08:36  [ Executor task launch worker for task 0:4932 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 14:08:36  [ Executor task launch worker for task 1:4932 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 14:08:36  [ task-result-getter-0:4942 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 638 ms on localhost (executor driver) (1/2)
2020-12-31 14:08:36  [ task-result-getter-1:4945 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 629 ms on localhost (executor driver) (2/2)
2020-12-31 14:08:36  [ task-result-getter-1:4946 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4955 ] - [ INFO ]  ShuffleMapStage 0 (countByKey at TransformationRDD.scala:53) finished in 0.715 s
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4956 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4956 ] - [ INFO ]  running: Set()
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4957 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4957 ] - [ INFO ]  failed: Set()
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4960 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:53), which has no missing parents
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4970 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 2004.4 MB)
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4972 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2020-12-31 14:08:36  [ dispatcher-event-loop-3:4973 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:53305 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4974 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4976 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:08:36  [ dag-scheduler-event-loop:4976 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 14:08:36  [ dispatcher-event-loop-4:4981 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 14:08:36  [ dispatcher-event-loop-4:4982 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 14:08:36  [ Executor task launch worker for task 2:4982 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 14:08:36  [ Executor task launch worker for task 3:4982 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 14:08:36  [ Executor task launch worker for task 2:5009 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 14:08:36  [ Executor task launch worker for task 3:5009 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 14:08:36  [ Executor task launch worker for task 3:5010 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 14:08:36  [ Executor task launch worker for task 2:5010 ] - [ INFO ]  Started 0 remote fetches in 7 ms
2020-12-31 14:08:36  [ Executor task launch worker for task 2:5073 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 6810 bytes result sent to driver
2020-12-31 14:08:36  [ Executor task launch worker for task 3:5074 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 7013 bytes result sent to driver
2020-12-31 14:08:36  [ task-result-getter-2:5077 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 97 ms on localhost (executor driver) (1/2)
2020-12-31 14:08:36  [ task-result-getter-3:5077 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 95 ms on localhost (executor driver) (2/2)
2020-12-31 14:08:36  [ task-result-getter-3:5078 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 14:08:36  [ dag-scheduler-event-loop:5080 ] - [ INFO ]  ResultStage 1 (countByKey at TransformationRDD.scala:53) finished in 0.111 s
2020-12-31 14:08:36  [ main:5087 ] - [ INFO ]  Job 0 finished: countByKey at TransformationRDD.scala:53, took 1.199593 s
2020-12-31 14:08:36  [ Thread-1:5103 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 14:08:36  [ Thread-1:5114 ] - [ INFO ]  Stopped Spark@150ab4ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 14:08:36  [ Thread-1:5115 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 14:08:36  [ dispatcher-event-loop-11:5125 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 14:08:36  [ Thread-1:5142 ] - [ INFO ]  MemoryStore cleared
2020-12-31 14:08:36  [ Thread-1:5143 ] - [ INFO ]  BlockManager stopped
2020-12-31 14:08:36  [ Thread-1:5148 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 14:08:36  [ dispatcher-event-loop-15:5150 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 14:08:36  [ Thread-1:5157 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 14:08:36  [ Thread-1:5157 ] - [ INFO ]  Shutdown hook called
2020-12-31 14:08:36  [ Thread-1:5158 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-734840e6-cd52-4787-b02e-a48350cfbb33
2020-12-31 14:09:13  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 14:09:13  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 14:09:13  [ main:43 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 14:09:13  [ main:343 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 14:09:13  [ main:446 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 14:09:13  [ main:512 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 14:09:13  [ main:513 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 14:09:13  [ main:514 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 14:09:13  [ main:514 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 14:09:13  [ main:515 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 14:09:14  [ main:999 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 53389.
2020-12-31 14:09:14  [ main:1024 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 14:09:14  [ main:1049 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 14:09:14  [ main:1051 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 14:09:14  [ main:1052 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 14:09:14  [ main:1072 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-a7edd3a1-d72a-4be1-8817-a68d67cf4e57
2020-12-31 14:09:14  [ main:1101 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 14:09:14  [ main:1118 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 14:09:14  [ main:1216 ] - [ INFO ]  Logging initialized @2171ms
2020-12-31 14:09:14  [ main:1293 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 14:09:14  [ main:1309 ] - [ INFO ]  Started @2265ms
2020-12-31 14:09:14  [ main:1326 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 14:09:14  [ main:1326 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 14:09:14  [ main:1348 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1349 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1350 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1352 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1352 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1353 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1354 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1355 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1356 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1357 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1357 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1358 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1360 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1361 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1362 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1363 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1363 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1364 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1365 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1365 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1373 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1373 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1374 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1375 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1375 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 14:09:14  [ main:1377 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 14:09:14  [ main:1519 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 14:09:14  [ main:1592 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53390.
2020-12-31 14:09:14  [ main:1593 ] - [ INFO ]  Server created on 192.168.3.166:53390
2020-12-31 14:09:14  [ main:1594 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 14:09:14  [ main:1617 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 53390, None)
2020-12-31 14:09:14  [ dispatcher-event-loop-10:1621 ] - [ INFO ]  Registering block manager 192.168.3.166:53390 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 53390, None)
2020-12-31 14:09:14  [ main:1623 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 53390, None)
2020-12-31 14:09:14  [ main:1623 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 53390, None)
2020-12-31 14:09:14  [ main:1822 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 14:09:15  [ main:2435 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 14:09:15  [ main:2600 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 14:09:15  [ dispatcher-event-loop-12:2603 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:53390 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 14:09:15  [ main:2606 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 14:09:16  [ main:3177 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 14:09:16  [ main:3248 ] - [ INFO ]  Starting job: countByKey at TransformationRDD.scala:53
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3501 ] - [ INFO ]  Registering RDD 4 (countByKey at TransformationRDD.scala:53)
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3504 ] - [ INFO ]  Got job 0 (countByKey at TransformationRDD.scala:53) with 2 output partitions
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3504 ] - [ INFO ]  Final stage: ResultStage 1 (countByKey at TransformationRDD.scala:53)
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3505 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3507 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3512 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:53), which has no missing parents
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3559 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3562 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2004.4 MB)
2020-12-31 14:09:16  [ dispatcher-event-loop-13:3563 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:53390 (size: 3.4 KB, free: 2004.6 MB)
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3564 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3580 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:09:16  [ dag-scheduler-event-loop:3581 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 14:09:16  [ dispatcher-event-loop-14:3625 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 14:09:16  [ dispatcher-event-loop-14:3627 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 14:09:16  [ Executor task launch worker for task 0:3638 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 14:09:16  [ Executor task launch worker for task 1:3638 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 14:09:17  [ Executor task launch worker for task 1:4289 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 14:09:17  [ Executor task launch worker for task 0:4289 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 14:09:17  [ Executor task launch worker for task 0:4479 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 14:09:17  [ Executor task launch worker for task 1:4479 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 14:09:17  [ task-result-getter-0:4488 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 872 ms on localhost (executor driver) (1/2)
2020-12-31 14:09:17  [ task-result-getter-1:4490 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 863 ms on localhost (executor driver) (2/2)
2020-12-31 14:09:17  [ task-result-getter-1:4491 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4499 ] - [ INFO ]  ShuffleMapStage 0 (countByKey at TransformationRDD.scala:53) finished in 0.959 s
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4500 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4501 ] - [ INFO ]  running: Set()
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4502 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4502 ] - [ INFO ]  failed: Set()
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4506 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:53), which has no missing parents
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4518 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 2004.4 MB)
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4520 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2020-12-31 14:09:17  [ dispatcher-event-loop-3:4522 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:53390 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4523 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4526 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:53) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4526 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 14:09:17  [ dispatcher-event-loop-4:4532 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 14:09:17  [ dispatcher-event-loop-4:4533 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 14:09:17  [ Executor task launch worker for task 2:4533 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 14:09:17  [ Executor task launch worker for task 3:4533 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 14:09:17  [ Executor task launch worker for task 3:4564 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 14:09:17  [ Executor task launch worker for task 2:4564 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 14:09:17  [ Executor task launch worker for task 2:4567 ] - [ INFO ]  Started 0 remote fetches in 12 ms
2020-12-31 14:09:17  [ Executor task launch worker for task 3:4567 ] - [ INFO ]  Started 0 remote fetches in 12 ms
2020-12-31 14:09:17  [ Executor task launch worker for task 3:4643 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 7013 bytes result sent to driver
2020-12-31 14:09:17  [ Executor task launch worker for task 2:4643 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 6810 bytes result sent to driver
2020-12-31 14:09:17  [ task-result-getter-2:4646 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 114 ms on localhost (executor driver) (1/2)
2020-12-31 14:09:17  [ task-result-getter-3:4647 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 117 ms on localhost (executor driver) (2/2)
2020-12-31 14:09:17  [ task-result-getter-3:4647 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 14:09:17  [ dag-scheduler-event-loop:4649 ] - [ INFO ]  ResultStage 1 (countByKey at TransformationRDD.scala:53) finished in 0.134 s
2020-12-31 14:09:17  [ main:4657 ] - [ INFO ]  Job 0 finished: countByKey at TransformationRDD.scala:53, took 1.408027 s
2020-12-31 14:09:17  [ Thread-1:4677 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 14:09:17  [ Thread-1:4686 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 14:09:17  [ Thread-1:4688 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 14:09:17  [ dispatcher-event-loop-11:4697 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 14:09:17  [ Thread-1:4716 ] - [ INFO ]  MemoryStore cleared
2020-12-31 14:09:17  [ Thread-1:4717 ] - [ INFO ]  BlockManager stopped
2020-12-31 14:09:17  [ Thread-1:4722 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 14:09:17  [ dispatcher-event-loop-15:4725 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 14:09:17  [ Thread-1:4737 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 14:09:17  [ Thread-1:4738 ] - [ INFO ]  Shutdown hook called
2020-12-31 14:09:17  [ Thread-1:4739 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-b8ef4552-bba6-481d-a6a7-9782ecb02ffa
2020-12-31 14:16:12  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2020-12-31 14:16:12  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2020-12-31 14:16:12  [ main:81 ] - [ INFO ]  Running Spark version 2.4.4
2020-12-31 14:16:12  [ main:369 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-12-31 14:16:12  [ main:482 ] - [ INFO ]  Submitted application: TransformationRDD
2020-12-31 14:16:13  [ main:562 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2020-12-31 14:16:13  [ main:563 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2020-12-31 14:16:13  [ main:564 ] - [ INFO ]  Changing view acls groups to: 
2020-12-31 14:16:13  [ main:565 ] - [ INFO ]  Changing modify acls groups to: 
2020-12-31 14:16:13  [ main:565 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2020-12-31 14:16:13  [ main:1002 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54179.
2020-12-31 14:16:13  [ main:1030 ] - [ INFO ]  Registering MapOutputTracker
2020-12-31 14:16:13  [ main:1052 ] - [ INFO ]  Registering BlockManagerMaster
2020-12-31 14:16:13  [ main:1055 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-12-31 14:16:13  [ main:1056 ] - [ INFO ]  BlockManagerMasterEndpoint up
2020-12-31 14:16:13  [ main:1076 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-03437707-271e-4425-aaad-b1dc12422138
2020-12-31 14:16:13  [ main:1109 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2020-12-31 14:16:13  [ main:1127 ] - [ INFO ]  Registering OutputCommitCoordinator
2020-12-31 14:16:13  [ main:1228 ] - [ INFO ]  Logging initialized @2442ms
2020-12-31 14:16:13  [ main:1296 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-12-31 14:16:13  [ main:1314 ] - [ INFO ]  Started @2530ms
2020-12-31 14:16:13  [ main:1334 ] - [ INFO ]  Started ServerConnector@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 14:16:13  [ main:1335 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2020-12-31 14:16:13  [ main:1358 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6cbcf243{/jobs,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1359 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f9a01c1{/jobs/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1360 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2611b9a3{/jobs/job,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1361 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b5894c8{/jobs/job/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1362 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1433046b{/stages,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1362 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3f446bef{/stages/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1363 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1365 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4763c727{/stages/stage/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1366 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@72445aba{/stages/pool,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1366 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@61bcd567{/stages/pool/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1367 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1c80e49b{/storage,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1368 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@458342d3{/storage/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1369 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@15c25153{/storage/rdd,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1370 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1252b961{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1371 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@9ed238c{/environment,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1371 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56276db8{/environment/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1372 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51e8e6e6{/executors,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1372 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@56f6d40b{/executors/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1373 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@36676c1a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1374 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b408dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1380 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d098f9b{/static,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1381 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4c51bb7{/,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1382 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@83298d7{/api,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1382 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6b54655f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1383 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@665e9289{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-12-31 14:16:13  [ main:1385 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2020-12-31 14:16:13  [ main:1521 ] - [ INFO ]  Starting executor ID driver on host localhost
2020-12-31 14:16:14  [ main:1606 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54181.
2020-12-31 14:16:14  [ main:1607 ] - [ INFO ]  Server created on 192.168.3.166:54181
2020-12-31 14:16:14  [ main:1608 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-12-31 14:16:14  [ main:1630 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54181, None)
2020-12-31 14:16:14  [ dispatcher-event-loop-10:1634 ] - [ INFO ]  Registering block manager 192.168.3.166:54181 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54181, None)
2020-12-31 14:16:14  [ main:1636 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54181, None)
2020-12-31 14:16:14  [ main:1636 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54181, None)
2020-12-31 14:16:14  [ main:1823 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3fcdcf{/metrics/json,null,AVAILABLE,@Spark}
2020-12-31 14:16:14  [ main:2273 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2020-12-31 14:16:14  [ main:2440 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2020-12-31 14:16:14  [ dispatcher-event-loop-12:2442 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54181 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 14:16:14  [ main:2446 ] - [ INFO ]  Created broadcast 0 from textFile at TransformationRDD.scala:13
2020-12-31 14:16:15  [ main:2588 ] - [ INFO ]  Total input paths to process : 1
2020-12-31 14:16:15  [ main:2657 ] - [ INFO ]  Starting job: countByKey at TransformationRDD.scala:54
2020-12-31 14:16:15  [ dag-scheduler-event-loop:2970 ] - [ INFO ]  Registering RDD 4 (countByKey at TransformationRDD.scala:54)
2020-12-31 14:16:15  [ dag-scheduler-event-loop:2972 ] - [ INFO ]  Got job 0 (countByKey at TransformationRDD.scala:54) with 2 output partitions
2020-12-31 14:16:15  [ dag-scheduler-event-loop:2973 ] - [ INFO ]  Final stage: ResultStage 1 (countByKey at TransformationRDD.scala:54)
2020-12-31 14:16:15  [ dag-scheduler-event-loop:2973 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2020-12-31 14:16:15  [ dag-scheduler-event-loop:2975 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2020-12-31 14:16:15  [ dag-scheduler-event-loop:2980 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:54), which has no missing parents
2020-12-31 14:16:15  [ dag-scheduler-event-loop:3067 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 2004.4 MB)
2020-12-31 14:16:15  [ dag-scheduler-event-loop:3070 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 2004.4 MB)
2020-12-31 14:16:15  [ dispatcher-event-loop-13:3072 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54181 (size: 4.1 KB, free: 2004.6 MB)
2020-12-31 14:16:15  [ dag-scheduler-event-loop:3073 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:16:15  [ dag-scheduler-event-loop:3089 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at countByKey at TransformationRDD.scala:54) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:16:15  [ dag-scheduler-event-loop:3090 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2020-12-31 14:16:15  [ dispatcher-event-loop-14:3158 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7381 bytes)
2020-12-31 14:16:15  [ dispatcher-event-loop-14:3162 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7381 bytes)
2020-12-31 14:16:15  [ Executor task launch worker for task 0:3174 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2020-12-31 14:16:15  [ Executor task launch worker for task 1:3175 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2020-12-31 14:16:16  [ Executor task launch worker for task 1:3742 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 14:16:16  [ Executor task launch worker for task 0:3742 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 14:16:16  [ Executor task launch worker for task 1:3912 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1161 bytes result sent to driver
2020-12-31 14:16:16  [ Executor task launch worker for task 0:3913 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1161 bytes result sent to driver
2020-12-31 14:16:16  [ task-result-getter-1:3920 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 781 ms on localhost (executor driver) (1/2)
2020-12-31 14:16:16  [ task-result-getter-0:3923 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 762 ms on localhost (executor driver) (2/2)
2020-12-31 14:16:16  [ task-result-getter-0:3925 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3933 ] - [ INFO ]  ShuffleMapStage 0 (countByKey at TransformationRDD.scala:54) finished in 0.913 s
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3933 ] - [ INFO ]  looking for newly runnable stages
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3934 ] - [ INFO ]  running: Set()
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3934 ] - [ INFO ]  waiting: Set(ResultStage 1)
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3934 ] - [ INFO ]  failed: Set()
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3938 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:54), which has no missing parents
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3948 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 2004.4 MB)
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3951 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2020-12-31 14:16:16  [ dispatcher-event-loop-3:3952 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54181 (size: 2.4 KB, free: 2004.6 MB)
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3953 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3957 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[5] at countByKey at TransformationRDD.scala:54) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:16:16  [ dag-scheduler-event-loop:3957 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2020-12-31 14:16:16  [ dispatcher-event-loop-4:3962 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7141 bytes)
2020-12-31 14:16:16  [ dispatcher-event-loop-4:3963 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7141 bytes)
2020-12-31 14:16:16  [ Executor task launch worker for task 3:3963 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2020-12-31 14:16:16  [ Executor task launch worker for task 2:3963 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2020-12-31 14:16:16  [ Executor task launch worker for task 2:3987 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 14:16:16  [ Executor task launch worker for task 3:3987 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2020-12-31 14:16:16  [ Executor task launch worker for task 3:3989 ] - [ INFO ]  Started 0 remote fetches in 8 ms
2020-12-31 14:16:16  [ Executor task launch worker for task 2:3989 ] - [ INFO ]  Started 0 remote fetches in 8 ms
2020-12-31 14:16:16  [ Executor task launch worker for task 2:4059 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 6810 bytes result sent to driver
2020-12-31 14:16:16  [ Executor task launch worker for task 3:4059 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 7013 bytes result sent to driver
2020-12-31 14:16:16  [ task-result-getter-2:4062 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 101 ms on localhost (executor driver) (1/2)
2020-12-31 14:16:16  [ task-result-getter-3:4063 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 100 ms on localhost (executor driver) (2/2)
2020-12-31 14:16:16  [ task-result-getter-3:4063 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4066 ] - [ INFO ]  ResultStage 1 (countByKey at TransformationRDD.scala:54) finished in 0.119 s
2020-12-31 14:16:16  [ main:4075 ] - [ INFO ]  Job 0 finished: countByKey at TransformationRDD.scala:54, took 1.417566 s
2020-12-31 14:16:16  [ main:4084 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 214.7 KB, free 2004.1 MB)
2020-12-31 14:16:16  [ main:4107 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.1 MB)
2020-12-31 14:16:16  [ dispatcher-event-loop-9:4109 ] - [ INFO ]  Added broadcast_3_piece0 in memory on 192.168.3.166:54181 (size: 20.4 KB, free: 2004.6 MB)
2020-12-31 14:16:16  [ main:4110 ] - [ INFO ]  Created broadcast 3 from countByKey at TransformationRDD.scala:54
2020-12-31 14:16:16  [ main:4117 ] - [ INFO ]  Starting job: countByKey at TransformationRDD.scala:54
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4118 ] - [ INFO ]  Got job 1 (countByKey at TransformationRDD.scala:54) with 2 output partitions
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4119 ] - [ INFO ]  Final stage: ResultStage 2 (countByKey at TransformationRDD.scala:54)
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4119 ] - [ INFO ]  Parents of final stage: List()
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4119 ] - [ INFO ]  Missing parents: List()
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4120 ] - [ INFO ]  Submitting ResultStage 2 (/Users/liuwenyi/IdeaProjects/satan/data/word.txt MapPartitionsRDD[1] at textFile at TransformationRDD.scala:13), which has no missing parents
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4126 ] - [ INFO ]  Block broadcast_4 stored as values in memory (estimated size 5.3 KB, free 2004.1 MB)
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4128 ] - [ INFO ]  Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 2004.1 MB)
2020-12-31 14:16:16  [ dispatcher-event-loop-10:4129 ] - [ INFO ]  Added broadcast_4_piece0 in memory on 192.168.3.166:54181 (size: 3.0 KB, free: 2004.6 MB)
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4130 ] - [ INFO ]  Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4131 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 2 (/Users/liuwenyi/IdeaProjects/satan/data/word.txt MapPartitionsRDD[1] at textFile at TransformationRDD.scala:13) (first 15 tasks are for partitions Vector(0, 1))
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4131 ] - [ INFO ]  Adding task set 2.0 with 2 tasks
2020-12-31 14:16:16  [ dispatcher-event-loop-11:4133 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7392 bytes)
2020-12-31 14:16:16  [ dispatcher-event-loop-11:4134 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7392 bytes)
2020-12-31 14:16:16  [ Executor task launch worker for task 4:4134 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 4)
2020-12-31 14:16:16  [ Executor task launch worker for task 5:4134 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 5)
2020-12-31 14:16:16  [ Executor task launch worker for task 4:4157 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:0+4458
2020-12-31 14:16:16  [ Executor task launch worker for task 5:4157 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/word.txt:4458+4458
2020-12-31 14:16:16  [ Executor task launch worker for task 4:4199 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4). 800 bytes result sent to driver
2020-12-31 14:16:16  [ Executor task launch worker for task 5:4199 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5). 757 bytes result sent to driver
2020-12-31 14:16:16  [ task-result-getter-1:4201 ] - [ INFO ]  Finished task 0.0 in stage 2.0 (TID 4) in 68 ms on localhost (executor driver) (1/2)
2020-12-31 14:16:16  [ task-result-getter-0:4201 ] - [ INFO ]  Finished task 1.0 in stage 2.0 (TID 5) in 68 ms on localhost (executor driver) (2/2)
2020-12-31 14:16:16  [ task-result-getter-0:4201 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-12-31 14:16:16  [ dag-scheduler-event-loop:4203 ] - [ INFO ]  ResultStage 2 (countByKey at TransformationRDD.scala:54) finished in 0.079 s
2020-12-31 14:16:16  [ main:4204 ] - [ INFO ]  Job 1 finished: countByKey at TransformationRDD.scala:54, took 0.086593 s
2020-12-31 14:16:16  [ main:4205 ] - [ INFO ]  Checkpointing took 123 ms.
2020-12-31 14:16:16  [ main:4208 ] - [ INFO ]  Block broadcast_5 stored as values in memory (estimated size 214.7 KB, free 2003.9 MB)
2020-12-31 14:16:16  [ main:4229 ] - [ INFO ]  Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2003.9 MB)
2020-12-31 14:16:16  [ dispatcher-event-loop-15:4230 ] - [ INFO ]  Added broadcast_5_piece0 in memory on 192.168.3.166:54181 (size: 20.4 KB, free: 2004.5 MB)
2020-12-31 14:16:16  [ main:4231 ] - [ INFO ]  Created broadcast 5 from countByKey at TransformationRDD.scala:54
2020-12-31 14:16:16  [ main:4236 ] - [ INFO ]  Done checkpointing RDD 1 to file:/Users/liuwenyi/IdeaProjects/satan/data/checkpoint_result/946416bd-1656-4dce-b1e2-a8bc0b2f26ac/rdd-1, new parent is RDD 6
2020-12-31 14:16:16  [ Thread-1:4241 ] - [ INFO ]  Invoking stop() from shutdown hook
2020-12-31 14:16:16  [ Thread-1:4253 ] - [ INFO ]  Stopped Spark@71b3bc45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-12-31 14:16:16  [ Thread-1:4254 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2020-12-31 14:16:16  [ dispatcher-event-loop-3:4266 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2020-12-31 14:16:16  [ Thread-1:4282 ] - [ INFO ]  MemoryStore cleared
2020-12-31 14:16:16  [ Thread-1:4283 ] - [ INFO ]  BlockManager stopped
2020-12-31 14:16:16  [ Thread-1:4394 ] - [ INFO ]  BlockManagerMaster stopped
2020-12-31 14:16:16  [ dispatcher-event-loop-7:4396 ] - [ INFO ]  OutputCommitCoordinator stopped!
2020-12-31 14:16:16  [ Thread-1:4405 ] - [ INFO ]  Successfully stopped SparkContext
2020-12-31 14:16:16  [ Thread-1:4405 ] - [ INFO ]  Shutdown hook called
2020-12-31 14:16:16  [ Thread-1:4406 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-88ea985b-2ce5-4550-abc3-4f3ab466c9b5
