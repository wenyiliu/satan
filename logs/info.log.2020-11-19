2020-11-19 10:13:25  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 10:13:25  [ main:770 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 10:13:25  [ main:771 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 10:13:26  [ main:974 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:26  [ main:979 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:26  [ main:992 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:26  [ main:1079 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:26  [ main:1157 ] - [ INFO ]  Submitting tokens for job: job_local2007936094_0001
2020-11-19 10:13:26  [ main:1248 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:26  [ main:1249 ] - [ INFO ]  Running job: job_local2007936094_0001
2020-11-19 10:13:26  [ Thread-18:1249 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:26  [ Thread-18:1253 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:26  [ Thread-18:1255 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:26  [ Thread-18:1291 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1292 ] - [ INFO ]  Starting task: attempt_local2007936094_0001_m_000000_0
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1315 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1315 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1317 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1370 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1474 ] - [ INFO ]  
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1475 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1476 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1476 ] - [ INFO ]  bufstart = 0; bufend = 20411; bufvoid = 104857600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1476 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213032(104852128); length = 1365/6553600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1486 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1490 ] - [ INFO ]  Task:attempt_local2007936094_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1502 ] - [ INFO ]  map
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1502 ] - [ INFO ]  Task 'attempt_local2007936094_0001_m_000000_0' done.
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1502 ] - [ INFO ]  Finishing task: attempt_local2007936094_0001_m_000000_0
2020-11-19 10:13:26  [ Thread-18:1502 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:26  [ Thread-18:1505 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:26  [ pool-6-thread-1:1505 ] - [ INFO ]  Starting task: attempt_local2007936094_0001_r_000000_0
2020-11-19 10:13:26  [ pool-6-thread-1:1509 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:26  [ pool-6-thread-1:1510 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:26  [ pool-6-thread-1:1510 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:26  [ pool-6-thread-1:1512 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54532f11
2020-11-19 10:13:26  [ pool-6-thread-1:1523 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:26  [ EventFetcher for fetching Map Completion Events:1524 ] - [ INFO ]  attempt_local2007936094_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:26  [ localfetcher#1:1544 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2007936094_0001_m_000000_0 decomp: 21097 len: 21101 to MEMORY
2020-11-19 10:13:26  [ localfetcher#1:1548 ] - [ INFO ]  Read 21097 bytes from map-output for attempt_local2007936094_0001_m_000000_0
2020-11-19 10:13:26  [ localfetcher#1:1549 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 21097, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->21097
2020-11-19 10:13:26  [ EventFetcher for fetching Map Completion Events:1550 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:26  [ pool-6-thread-1:1551 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:26  [ pool-6-thread-1:1551 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:26  [ pool-6-thread-1:1555 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:26  [ pool-6-thread-1:1559 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 21093 bytes
2020-11-19 10:13:26  [ pool-6-thread-1:1561 ] - [ INFO ]  Merged 1 segments, 21097 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:26  [ pool-6-thread-1:1562 ] - [ INFO ]  Merging 1 files, 21101 bytes from disk
2020-11-19 10:13:26  [ pool-6-thread-1:1562 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:26  [ pool-6-thread-1:1562 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:26  [ pool-6-thread-1:1563 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 21093 bytes
2020-11-19 10:13:26  [ pool-6-thread-1:1563 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:26  [ pool-6-thread-1:1584 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 10:13:26  [ pool-6-thread-1:1697 ] - [ INFO ]  Task:attempt_local2007936094_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:26  [ pool-6-thread-1:1703 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:26  [ pool-6-thread-1:1703 ] - [ INFO ]  Task attempt_local2007936094_0001_r_000000_0 is allowed to commit now
2020-11-19 10:13:26  [ pool-6-thread-1:1724 ] - [ INFO ]  Saved output of task 'attempt_local2007936094_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2007936094_0001_r_000000
2020-11-19 10:13:26  [ pool-6-thread-1:1725 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:26  [ pool-6-thread-1:1725 ] - [ INFO ]  Task 'attempt_local2007936094_0001_r_000000_0' done.
2020-11-19 10:13:26  [ pool-6-thread-1:1725 ] - [ INFO ]  Finishing task: attempt_local2007936094_0001_r_000000_0
2020-11-19 10:13:26  [ Thread-18:1725 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:27  [ main:2251 ] - [ INFO ]  Job job_local2007936094_0001 running in uber mode : false
2020-11-19 10:13:27  [ main:2252 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:27  [ main:2252 ] - [ INFO ]  Job job_local2007936094_0001 completed successfully
2020-11-19 10:13:27  [ main:2259 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=42584
		FILE: Number of bytes written=631493
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=174
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=342
		Map output bytes=20411
		Map output materialized bytes=21101
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=21101
		Reduce input records=342
		Reduce output records=3
		Spilled Records=684
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=174
2020-11-19 10:13:27  [ main:2375 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:27  [ main:2384 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:27  [ main:2389 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:27  [ main:2395 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:27  [ main:2438 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:27  [ main:2460 ] - [ INFO ]  Submitting tokens for job: job_local323101412_0002
2020-11-19 10:13:27  [ main:2512 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:27  [ main:2512 ] - [ INFO ]  Running job: job_local323101412_0002
2020-11-19 10:13:27  [ Thread-48:2512 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:27  [ Thread-48:2512 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:27  [ Thread-48:2512 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:27  [ Thread-48:2520 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2520 ] - [ INFO ]  Starting task: attempt_local323101412_0002_m_000000_0
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2521 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2521 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2523 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2573 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2662 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2663 ] - [ INFO ]  Task:attempt_local323101412_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2669 ] - [ INFO ]  map
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2669 ] - [ INFO ]  Task 'attempt_local323101412_0002_m_000000_0' done.
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2669 ] - [ INFO ]  Finishing task: attempt_local323101412_0002_m_000000_0
2020-11-19 10:13:27  [ Thread-48:2669 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:27  [ Thread-48:2670 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:27  [ pool-9-thread-1:2670 ] - [ INFO ]  Starting task: attempt_local323101412_0002_r_000000_0
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67a496cf
2020-11-19 10:13:27  [ pool-9-thread-1:2672 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:27  [ EventFetcher for fetching Map Completion Events:2672 ] - [ INFO ]  attempt_local323101412_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:27  [ localfetcher#2:2673 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local323101412_0002_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 10:13:27  [ localfetcher#2:2673 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local323101412_0002_m_000000_0
2020-11-19 10:13:27  [ localfetcher#2:2673 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 10:13:27  [ EventFetcher for fetching Map Completion Events:2674 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:27  [ pool-9-thread-1:2674 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:27  [ pool-9-thread-1:2674 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:27  [ pool-9-thread-1:2675 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:27  [ pool-9-thread-1:2675 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 10:13:27  [ pool-9-thread-1:2675 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:27  [ pool-9-thread-1:2732 ] - [ INFO ]  Task:attempt_local323101412_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:27  [ pool-9-thread-1:2737 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:27  [ pool-9-thread-1:2738 ] - [ INFO ]  Task attempt_local323101412_0002_r_000000_0 is allowed to commit now
2020-11-19 10:13:27  [ pool-9-thread-1:2754 ] - [ INFO ]  Saved output of task 'attempt_local323101412_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local323101412_0002_r_000000
2020-11-19 10:13:27  [ pool-9-thread-1:2755 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:27  [ pool-9-thread-1:2755 ] - [ INFO ]  Task 'attempt_local323101412_0002_r_000000_0' done.
2020-11-19 10:13:27  [ pool-9-thread-1:2755 ] - [ INFO ]  Finishing task: attempt_local323101412_0002_r_000000_0
2020-11-19 10:13:27  [ Thread-48:2755 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:28  [ main:3513 ] - [ INFO ]  Job job_local323101412_0002 running in uber mode : false
2020-11-19 10:13:28  [ main:3514 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:28  [ main:3514 ] - [ INFO ]  Job job_local323101412_0002 completed successfully
2020-11-19 10:13:28  [ main:3517 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85596
		FILE: Number of bytes written=1221282
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125908
		HDFS: Number of bytes written=874
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=844103680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 10:13:29  [ main:3823 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:29  [ main:3834 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:29  [ main:3838 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:29  [ main:3845 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:29  [ main:3885 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:29  [ main:3909 ] - [ INFO ]  Submitting tokens for job: job_local859066095_0003
2020-11-19 10:13:29  [ main:3958 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:29  [ main:3958 ] - [ INFO ]  Running job: job_local859066095_0003
2020-11-19 10:13:29  [ Thread-78:3958 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:29  [ Thread-78:3959 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:29  [ Thread-78:3959 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:29  [ Thread-78:3967 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3967 ] - [ INFO ]  Starting task: attempt_local859066095_0003_m_000000_0
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3988 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4215 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4216 ] - [ INFO ]  Task:attempt_local859066095_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4223 ] - [ INFO ]  map
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4223 ] - [ INFO ]  Task 'attempt_local859066095_0003_m_000000_0' done.
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4223 ] - [ INFO ]  Finishing task: attempt_local859066095_0003_m_000000_0
2020-11-19 10:13:29  [ Thread-78:4223 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:29  [ Thread-78:4224 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:29  [ pool-12-thread-1:4224 ] - [ INFO ]  Starting task: attempt_local859066095_0003_r_000000_0
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@538bd303
2020-11-19 10:13:29  [ pool-12-thread-1:4226 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:29  [ EventFetcher for fetching Map Completion Events:4226 ] - [ INFO ]  attempt_local859066095_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:29  [ localfetcher#3:4227 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local859066095_0003_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 10:13:29  [ localfetcher#3:4228 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local859066095_0003_m_000000_0
2020-11-19 10:13:29  [ localfetcher#3:4228 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 10:13:29  [ EventFetcher for fetching Map Completion Events:4228 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:29  [ pool-12-thread-1:4229 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:29  [ pool-12-thread-1:4229 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:29  [ pool-12-thread-1:4230 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:29  [ pool-12-thread-1:4230 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:13:29  [ pool-12-thread-1:4232 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:29  [ pool-12-thread-1:4285 ] - [ INFO ]  Task:attempt_local859066095_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:29  [ pool-12-thread-1:4291 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:29  [ pool-12-thread-1:4291 ] - [ INFO ]  Task attempt_local859066095_0003_r_000000_0 is allowed to commit now
2020-11-19 10:13:29  [ pool-12-thread-1:4308 ] - [ INFO ]  Saved output of task 'attempt_local859066095_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local859066095_0003_r_000000
2020-11-19 10:13:29  [ pool-12-thread-1:4309 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:29  [ pool-12-thread-1:4309 ] - [ INFO ]  Task 'attempt_local859066095_0003_r_000000_0' done.
2020-11-19 10:13:29  [ pool-12-thread-1:4309 ] - [ INFO ]  Finishing task: attempt_local859066095_0003_r_000000_0
2020-11-19 10:13:29  [ Thread-78:4309 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:30  [ main:4959 ] - [ INFO ]  Job job_local859066095_0003 running in uber mode : false
2020-11-19 10:13:30  [ main:4959 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:30  [ main:4959 ] - [ INFO ]  Job job_local859066095_0003 completed successfully
2020-11-19 10:13:30  [ main:4962 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86792
		FILE: Number of bytes written=1790153
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190286
		HDFS: Number of bytes written=1941
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=177
2020-11-19 10:13:31  [ main:6258 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:31  [ main:6275 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:31  [ main:6281 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:31  [ main:6288 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:31  [ main:6334 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:31  [ main:6354 ] - [ INFO ]  Submitting tokens for job: job_local1838117753_0004
2020-11-19 10:13:31  [ main:6394 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:31  [ main:6395 ] - [ INFO ]  Running job: job_local1838117753_0004
2020-11-19 10:13:31  [ Thread-108:6395 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:31  [ Thread-108:6395 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:31  [ Thread-108:6395 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:31  [ Thread-108:6402 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6402 ] - [ INFO ]  Starting task: attempt_local1838117753_0004_m_000000_0
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6403 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6403 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6403 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6404 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6483 ] - [ INFO ]  
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6487 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6488 ] - [ INFO ]  Task:attempt_local1838117753_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6496 ] - [ INFO ]  map
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6496 ] - [ INFO ]  Task 'attempt_local1838117753_0004_m_000000_0' done.
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6496 ] - [ INFO ]  Finishing task: attempt_local1838117753_0004_m_000000_0
2020-11-19 10:13:31  [ Thread-108:6496 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:31  [ Thread-108:6496 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:31  [ pool-15-thread-1:6497 ] - [ INFO ]  Starting task: attempt_local1838117753_0004_r_000000_0
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5616d409
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:31  [ EventFetcher for fetching Map Completion Events:6499 ] - [ INFO ]  attempt_local1838117753_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:31  [ localfetcher#4:6500 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1838117753_0004_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:31  [ localfetcher#4:6500 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1838117753_0004_m_000000_0
2020-11-19 10:13:31  [ localfetcher#4:6500 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:31  [ EventFetcher for fetching Map Completion Events:6500 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:31  [ pool-15-thread-1:6503 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:31  [ pool-15-thread-1:6545 ] - [ INFO ]  Task:attempt_local1838117753_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:31  [ pool-15-thread-1:6551 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:31  [ pool-15-thread-1:6551 ] - [ INFO ]  Task attempt_local1838117753_0004_r_000000_0 is allowed to commit now
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  Saved output of task 'attempt_local1838117753_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1838117753_0004_r_000000
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  Task 'attempt_local1838117753_0004_r_000000_0' done.
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  Finishing task: attempt_local1838117753_0004_r_000000_0
2020-11-19 10:13:31  [ Thread-108:6570 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:32  [ main:7396 ] - [ INFO ]  Job job_local1838117753_0004 running in uber mode : false
2020-11-19 10:13:32  [ main:7396 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:32  [ main:7397 ] - [ INFO ]  Job job_local1838117753_0004 completed successfully
2020-11-19 10:13:32  [ main:7399 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=87980
		FILE: Number of bytes written=2362070
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254664
		HDFS: Number of bytes written=3006
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:32  [ main:7690 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:32  [ main:7702 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:32  [ main:7707 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:32  [ main:7712 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:32  [ main:7752 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:32  [ main:7772 ] - [ INFO ]  Submitting tokens for job: job_local1620197152_0005
2020-11-19 10:13:33  [ main:7809 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:33  [ main:7809 ] - [ INFO ]  Running job: job_local1620197152_0005
2020-11-19 10:13:33  [ Thread-138:7809 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:33  [ Thread-138:7810 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:33  [ Thread-138:7810 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:33  [ Thread-138:7818 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7818 ] - [ INFO ]  Starting task: attempt_local1620197152_0005_m_000000_0
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7819 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7819 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7819 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7820 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7829 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7902 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7903 ] - [ INFO ]  Task:attempt_local1620197152_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7910 ] - [ INFO ]  map
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7910 ] - [ INFO ]  Task 'attempt_local1620197152_0005_m_000000_0' done.
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7910 ] - [ INFO ]  Finishing task: attempt_local1620197152_0005_m_000000_0
2020-11-19 10:13:33  [ Thread-138:7910 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:33  [ Thread-138:7910 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:33  [ pool-18-thread-1:7910 ] - [ INFO ]  Starting task: attempt_local1620197152_0005_r_000000_0
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68bdd6a4
2020-11-19 10:13:33  [ pool-18-thread-1:7912 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:33  [ EventFetcher for fetching Map Completion Events:7912 ] - [ INFO ]  attempt_local1620197152_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:33  [ localfetcher#5:7913 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local1620197152_0005_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:33  [ localfetcher#5:7913 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1620197152_0005_m_000000_0
2020-11-19 10:13:33  [ localfetcher#5:7913 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:33  [ EventFetcher for fetching Map Completion Events:7913 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:33  [ pool-18-thread-1:7913 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:33  [ pool-18-thread-1:7913 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:33  [ pool-18-thread-1:7914 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:33  [ pool-18-thread-1:7914 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:33  [ pool-18-thread-1:7914 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:33  [ pool-18-thread-1:7967 ] - [ INFO ]  Task:attempt_local1620197152_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:33  [ pool-18-thread-1:7973 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:33  [ pool-18-thread-1:7973 ] - [ INFO ]  Task attempt_local1620197152_0005_r_000000_0 is allowed to commit now
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  Saved output of task 'attempt_local1620197152_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1620197152_0005_r_000000
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  Task 'attempt_local1620197152_0005_r_000000_0' done.
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  Finishing task: attempt_local1620197152_0005_r_000000_0
2020-11-19 10:13:33  [ Thread-138:7992 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:34  [ main:8813 ] - [ INFO ]  Job job_local1620197152_0005 running in uber mode : false
2020-11-19 10:13:34  [ main:8813 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:34  [ main:8813 ] - [ INFO ]  Job job_local1620197152_0005 completed successfully
2020-11-19 10:13:34  [ main:8815 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=89172
		FILE: Number of bytes written=2933991
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319064
		HDFS: Number of bytes written=4086
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=90
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:34  [ main:9118 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:34  [ main:9129 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:34  [ main:9134 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:34  [ main:9140 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:34  [ main:9179 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:34  [ main:9196 ] - [ INFO ]  Submitting tokens for job: job_local514750714_0006
2020-11-19 10:13:34  [ main:9236 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:34  [ main:9236 ] - [ INFO ]  Running job: job_local514750714_0006
2020-11-19 10:13:34  [ Thread-168:9236 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:34  [ Thread-168:9236 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:34  [ Thread-168:9236 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:34  [ Thread-168:9245 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]  Starting task: attempt_local514750714_0006_m_000000_0
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9246 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9387 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9388 ] - [ INFO ]  Task:attempt_local514750714_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9396 ] - [ INFO ]  map
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9396 ] - [ INFO ]  Task 'attempt_local514750714_0006_m_000000_0' done.
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9396 ] - [ INFO ]  Finishing task: attempt_local514750714_0006_m_000000_0
2020-11-19 10:13:34  [ Thread-168:9396 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:34  [ Thread-168:9397 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:34  [ pool-21-thread-1:9397 ] - [ INFO ]  Starting task: attempt_local514750714_0006_r_000000_0
2020-11-19 10:13:34  [ pool-21-thread-1:9397 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@478bafde
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:34  [ EventFetcher for fetching Map Completion Events:9398 ] - [ INFO ]  attempt_local514750714_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:34  [ localfetcher#6:9399 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local514750714_0006_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:34  [ localfetcher#6:9399 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local514750714_0006_m_000000_0
2020-11-19 10:13:34  [ localfetcher#6:9399 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:34  [ EventFetcher for fetching Map Completion Events:9400 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:34  [ pool-21-thread-1:9400 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:34  [ pool-21-thread-1:9400 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:34  [ pool-21-thread-1:9402 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:34  [ pool-21-thread-1:9402 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:34  [ pool-21-thread-1:9456 ] - [ INFO ]  Task:attempt_local514750714_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:34  [ pool-21-thread-1:9462 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:34  [ pool-21-thread-1:9462 ] - [ INFO ]  Task attempt_local514750714_0006_r_000000_0 is allowed to commit now
2020-11-19 10:13:34  [ pool-21-thread-1:9478 ] - [ INFO ]  Saved output of task 'attempt_local514750714_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local514750714_0006_r_000000
2020-11-19 10:13:34  [ pool-21-thread-1:9479 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:34  [ pool-21-thread-1:9479 ] - [ INFO ]  Task 'attempt_local514750714_0006_r_000000_0' done.
2020-11-19 10:13:34  [ pool-21-thread-1:9479 ] - [ INFO ]  Finishing task: attempt_local514750714_0006_r_000000_0
2020-11-19 10:13:34  [ Thread-168:9479 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:35  [ main:10238 ] - [ INFO ]  Job job_local514750714_0006 running in uber mode : false
2020-11-19 10:13:35  [ main:10238 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:35  [ main:10239 ] - [ INFO ]  Job job_local514750714_0006 completed successfully
2020-11-19 10:13:35  [ main:10241 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=90364
		FILE: Number of bytes written=3502862
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383470
		HDFS: Number of bytes written=5166
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=61
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:35  [ main:10509 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:35  [ main:10520 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:35  [ main:10524 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:35  [ main:10530 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:35  [ main:10566 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:35  [ main:10582 ] - [ INFO ]  Submitting tokens for job: job_local1921099520_0007
2020-11-19 10:13:35  [ main:10616 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:35  [ main:10616 ] - [ INFO ]  Running job: job_local1921099520_0007
2020-11-19 10:13:35  [ Thread-198:10616 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:35  [ Thread-198:10616 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:35  [ Thread-198:10617 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:35  [ Thread-198:10624 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10624 ] - [ INFO ]  Starting task: attempt_local1921099520_0007_m_000000_0
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10695 ] - [ INFO ]  
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10698 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10699 ] - [ INFO ]  Task:attempt_local1921099520_0007_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10705 ] - [ INFO ]  map
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10705 ] - [ INFO ]  Task 'attempt_local1921099520_0007_m_000000_0' done.
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10705 ] - [ INFO ]  Finishing task: attempt_local1921099520_0007_m_000000_0
2020-11-19 10:13:35  [ Thread-198:10705 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:35  [ Thread-198:10706 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  Starting task: attempt_local1921099520_0007_r_000000_0
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@43784ce4
2020-11-19 10:13:35  [ pool-24-thread-1:10707 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:35  [ EventFetcher for fetching Map Completion Events:10707 ] - [ INFO ]  attempt_local1921099520_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:35  [ localfetcher#7:10708 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local1921099520_0007_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:35  [ localfetcher#7:10708 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1921099520_0007_m_000000_0
2020-11-19 10:13:35  [ localfetcher#7:10708 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:35  [ EventFetcher for fetching Map Completion Events:10709 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:35  [ pool-24-thread-1:10709 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:35  [ pool-24-thread-1:10709 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:35  [ pool-24-thread-1:10711 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:35  [ pool-24-thread-1:10711 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:35  [ pool-24-thread-1:10760 ] - [ INFO ]  Task:attempt_local1921099520_0007_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:35  [ pool-24-thread-1:10766 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:35  [ pool-24-thread-1:10766 ] - [ INFO ]  Task attempt_local1921099520_0007_r_000000_0 is allowed to commit now
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  Saved output of task 'attempt_local1921099520_0007_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1921099520_0007_r_000000
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  Task 'attempt_local1921099520_0007_r_000000_0' done.
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  Finishing task: attempt_local1921099520_0007_r_000000_0
2020-11-19 10:13:36  [ Thread-198:10787 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:36  [ main:11617 ] - [ INFO ]  Job job_local1921099520_0007 running in uber mode : false
2020-11-19 10:13:36  [ main:11617 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:36  [ main:11617 ] - [ INFO ]  Job job_local1921099520_0007 completed successfully
2020-11-19 10:13:36  [ main:11619 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=91554
		FILE: Number of bytes written=4074780
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=447876
		HDFS: Number of bytes written=6246
		HDFS: Number of read operations=401
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=134
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:37  [ main:11936 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:37  [ main:11947 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:37  [ main:11952 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:37  [ main:11957 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:37  [ main:11996 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:37  [ main:12013 ] - [ INFO ]  Submitting tokens for job: job_local694841777_0008
2020-11-19 10:13:37  [ main:12048 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:37  [ main:12048 ] - [ INFO ]  Running job: job_local694841777_0008
2020-11-19 10:13:37  [ Thread-228:12048 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:37  [ Thread-228:12048 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:37  [ Thread-228:12048 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:37  [ Thread-228:12056 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]  Starting task: attempt_local694841777_0008_m_000000_0
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12057 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12133 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12134 ] - [ INFO ]  Task:attempt_local694841777_0008_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12140 ] - [ INFO ]  map
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12140 ] - [ INFO ]  Task 'attempt_local694841777_0008_m_000000_0' done.
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12140 ] - [ INFO ]  Finishing task: attempt_local694841777_0008_m_000000_0
2020-11-19 10:13:37  [ Thread-228:12140 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:37  [ Thread-228:12141 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:37  [ pool-27-thread-1:12141 ] - [ INFO ]  Starting task: attempt_local694841777_0008_r_000000_0
2020-11-19 10:13:37  [ pool-27-thread-1:12141 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@170f9268
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:37  [ EventFetcher for fetching Map Completion Events:12142 ] - [ INFO ]  attempt_local694841777_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:37  [ localfetcher#8:12143 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local694841777_0008_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:37  [ localfetcher#8:12143 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local694841777_0008_m_000000_0
2020-11-19 10:13:37  [ localfetcher#8:12143 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:37  [ EventFetcher for fetching Map Completion Events:12144 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:37  [ pool-27-thread-1:12144 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:37  [ pool-27-thread-1:12144 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:37  [ pool-27-thread-1:12146 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:37  [ pool-27-thread-1:12146 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:37  [ pool-27-thread-1:12187 ] - [ INFO ]  Task:attempt_local694841777_0008_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:37  [ pool-27-thread-1:12193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:37  [ pool-27-thread-1:12193 ] - [ INFO ]  Task attempt_local694841777_0008_r_000000_0 is allowed to commit now
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  Saved output of task 'attempt_local694841777_0008_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local694841777_0008_r_000000
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  Task 'attempt_local694841777_0008_r_000000_0' done.
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  Finishing task: attempt_local694841777_0008_r_000000_0
2020-11-19 10:13:37  [ Thread-228:12210 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:38  [ main:13049 ] - [ INFO ]  Job job_local694841777_0008 running in uber mode : false
2020-11-19 10:13:38  [ main:13050 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:38  [ main:13050 ] - [ INFO ]  Job job_local694841777_0008 completed successfully
2020-11-19 10:13:38  [ main:13051 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=92746
		FILE: Number of bytes written=4643653
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=512282
		HDFS: Number of bytes written=7326
		HDFS: Number of read operations=469
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=156
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:38  [ main:13314 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:38  [ main:13324 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:38  [ main:13328 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:38  [ main:13334 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:38  [ main:13373 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:38  [ main:13390 ] - [ INFO ]  Submitting tokens for job: job_local633411448_0009
2020-11-19 10:13:38  [ main:13424 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:38  [ main:13424 ] - [ INFO ]  Running job: job_local633411448_0009
2020-11-19 10:13:38  [ Thread-258:13424 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:38  [ Thread-258:13424 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:38  [ Thread-258:13424 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:38  [ Thread-258:13433 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13433 ] - [ INFO ]  Starting task: attempt_local633411448_0009_m_000000_0
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13511 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13512 ] - [ INFO ]  Task:attempt_local633411448_0009_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13519 ] - [ INFO ]  map
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13520 ] - [ INFO ]  Task 'attempt_local633411448_0009_m_000000_0' done.
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13520 ] - [ INFO ]  Finishing task: attempt_local633411448_0009_m_000000_0
2020-11-19 10:13:38  [ Thread-258:13520 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:38  [ Thread-258:13520 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:38  [ pool-30-thread-1:13520 ] - [ INFO ]  Starting task: attempt_local633411448_0009_r_000000_0
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f849f75
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:38  [ EventFetcher for fetching Map Completion Events:13522 ] - [ INFO ]  attempt_local633411448_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:38  [ localfetcher#9:13522 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local633411448_0009_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:38  [ localfetcher#9:13522 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local633411448_0009_m_000000_0
2020-11-19 10:13:38  [ localfetcher#9:13523 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:38  [ EventFetcher for fetching Map Completion Events:13523 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:38  [ pool-30-thread-1:13523 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:38  [ pool-30-thread-1:13523 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:38  [ pool-30-thread-1:13524 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:38  [ pool-30-thread-1:13524 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:38  [ pool-30-thread-1:13524 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:38  [ pool-30-thread-1:13567 ] - [ INFO ]  Task:attempt_local633411448_0009_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:38  [ pool-30-thread-1:13573 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:38  [ pool-30-thread-1:13573 ] - [ INFO ]  Task attempt_local633411448_0009_r_000000_0 is allowed to commit now
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  Saved output of task 'attempt_local633411448_0009_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local633411448_0009_r_000000
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  Task 'attempt_local633411448_0009_r_000000_0' done.
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  Finishing task: attempt_local633411448_0009_r_000000_0
2020-11-19 10:13:38  [ Thread-258:13589 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:39  [ main:14429 ] - [ INFO ]  Job job_local633411448_0009 running in uber mode : false
2020-11-19 10:13:39  [ main:14430 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:39  [ main:14430 ] - [ INFO ]  Job job_local633411448_0009 completed successfully
2020-11-19 10:13:39  [ main:14431 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=93938
		FILE: Number of bytes written=5212524
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=576688
		HDFS: Number of bytes written=8406
		HDFS: Number of read operations=537
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=178
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:39  [ main:14682 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:39  [ main:14695 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:39  [ main:14699 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:39  [ main:14704 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:39  [ main:14744 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:39  [ main:14762 ] - [ INFO ]  Submitting tokens for job: job_local1836307206_0010
2020-11-19 10:13:40  [ main:14798 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:40  [ main:14799 ] - [ INFO ]  Running job: job_local1836307206_0010
2020-11-19 10:13:40  [ Thread-288:14799 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:40  [ Thread-288:14799 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:40  [ Thread-288:14799 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:40  [ Thread-288:14807 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]  Starting task: attempt_local1836307206_0010_m_000000_0
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14808 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14895 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14896 ] - [ INFO ]  Task:attempt_local1836307206_0010_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14901 ] - [ INFO ]  map
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14901 ] - [ INFO ]  Task 'attempt_local1836307206_0010_m_000000_0' done.
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14901 ] - [ INFO ]  Finishing task: attempt_local1836307206_0010_m_000000_0
2020-11-19 10:13:40  [ Thread-288:14901 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:40  [ Thread-288:14902 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:40  [ pool-33-thread-1:14902 ] - [ INFO ]  Starting task: attempt_local1836307206_0010_r_000000_0
2020-11-19 10:13:40  [ pool-33-thread-1:14902 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64ced2fd
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:40  [ EventFetcher for fetching Map Completion Events:14903 ] - [ INFO ]  attempt_local1836307206_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:40  [ localfetcher#10:14904 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1836307206_0010_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:40  [ localfetcher#10:14904 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1836307206_0010_m_000000_0
2020-11-19 10:13:40  [ localfetcher#10:14904 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:40  [ EventFetcher for fetching Map Completion Events:14905 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:40  [ pool-33-thread-1:14905 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:40  [ pool-33-thread-1:14905 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:40  [ pool-33-thread-1:14906 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:40  [ pool-33-thread-1:14906 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:40  [ pool-33-thread-1:14906 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:40  [ pool-33-thread-1:14961 ] - [ INFO ]  Task:attempt_local1836307206_0010_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:40  [ pool-33-thread-1:14966 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:40  [ pool-33-thread-1:14966 ] - [ INFO ]  Task attempt_local1836307206_0010_r_000000_0 is allowed to commit now
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  Saved output of task 'attempt_local1836307206_0010_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1836307206_0010_r_000000
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  Task 'attempt_local1836307206_0010_r_000000_0' done.
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  Finishing task: attempt_local1836307206_0010_r_000000_0
2020-11-19 10:13:40  [ Thread-288:14982 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:41  [ main:15801 ] - [ INFO ]  Job job_local1836307206_0010 running in uber mode : false
2020-11-19 10:13:41  [ main:15801 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:41  [ main:15801 ] - [ INFO ]  Job job_local1836307206_0010 completed successfully
2020-11-19 10:13:41  [ main:15802 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=95128
		FILE: Number of bytes written=5784442
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=641094
		HDFS: Number of bytes written=9486
		HDFS: Number of read operations=605
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=200
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1504706560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:41  [ main:16056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:41  [ main:16065 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:41  [ main:16069 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:41  [ main:16075 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:41  [ main:16113 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:41  [ main:16133 ] - [ INFO ]  Submitting tokens for job: job_local2041082458_0011
2020-11-19 10:13:41  [ main:16178 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:41  [ main:16178 ] - [ INFO ]  Running job: job_local2041082458_0011
2020-11-19 10:13:41  [ Thread-318:16178 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:41  [ Thread-318:16179 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:41  [ Thread-318:16179 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:41  [ Thread-318:16186 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16186 ] - [ INFO ]  Starting task: attempt_local2041082458_0011_m_000000_0
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16265 ] - [ INFO ]  
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16268 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16269 ] - [ INFO ]  Task:attempt_local2041082458_0011_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16275 ] - [ INFO ]  map
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16275 ] - [ INFO ]  Task 'attempt_local2041082458_0011_m_000000_0' done.
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16275 ] - [ INFO ]  Finishing task: attempt_local2041082458_0011_m_000000_0
2020-11-19 10:13:41  [ Thread-318:16275 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:41  [ Thread-318:16275 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:41  [ pool-36-thread-1:16275 ] - [ INFO ]  Starting task: attempt_local2041082458_0011_r_000000_0
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@779e96ed
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:41  [ EventFetcher for fetching Map Completion Events:16277 ] - [ INFO ]  attempt_local2041082458_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:41  [ localfetcher#11:16278 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local2041082458_0011_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:41  [ localfetcher#11:16278 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local2041082458_0011_m_000000_0
2020-11-19 10:13:41  [ localfetcher#11:16278 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:41  [ EventFetcher for fetching Map Completion Events:16278 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:41  [ pool-36-thread-1:16278 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:41  [ pool-36-thread-1:16278 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:41  [ pool-36-thread-1:16279 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:41  [ pool-36-thread-1:16279 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:41  [ pool-36-thread-1:16324 ] - [ INFO ]  Task:attempt_local2041082458_0011_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:41  [ pool-36-thread-1:16330 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:41  [ pool-36-thread-1:16330 ] - [ INFO ]  Task attempt_local2041082458_0011_r_000000_0 is allowed to commit now
2020-11-19 10:13:41  [ pool-36-thread-1:16348 ] - [ INFO ]  Saved output of task 'attempt_local2041082458_0011_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2041082458_0011_r_000000
2020-11-19 10:13:41  [ pool-36-thread-1:16349 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:41  [ pool-36-thread-1:16349 ] - [ INFO ]  Task 'attempt_local2041082458_0011_r_000000_0' done.
2020-11-19 10:13:41  [ pool-36-thread-1:16349 ] - [ INFO ]  Finishing task: attempt_local2041082458_0011_r_000000_0
2020-11-19 10:13:41  [ Thread-318:16349 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:42  [ main:17179 ] - [ INFO ]  Job job_local2041082458_0011 running in uber mode : false
2020-11-19 10:13:42  [ main:17179 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:42  [ main:17180 ] - [ INFO ]  Job job_local2041082458_0011 completed successfully
2020-11-19 10:13:42  [ main:17181 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=96320
		FILE: Number of bytes written=6356363
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=705500
		HDFS: Number of bytes written=10566
		HDFS: Number of read operations=673
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=222
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1514143744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:42  [ main:17474 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:42  [ main:17486 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:42  [ main:17491 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:42  [ main:17496 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:42  [ main:17531 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:42  [ main:17546 ] - [ INFO ]  Submitting tokens for job: job_local1518534492_0012
2020-11-19 10:13:42  [ main:17582 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:42  [ main:17582 ] - [ INFO ]  Running job: job_local1518534492_0012
2020-11-19 10:13:42  [ Thread-348:17582 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:42  [ Thread-348:17583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:42  [ Thread-348:17583 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:42  [ Thread-348:17591 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]  Starting task: attempt_local1518534492_0012_m_000000_0
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17592 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17626 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17751 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17752 ] - [ INFO ]  Task:attempt_local1518534492_0012_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17757 ] - [ INFO ]  map
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17757 ] - [ INFO ]  Task 'attempt_local1518534492_0012_m_000000_0' done.
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17757 ] - [ INFO ]  Finishing task: attempt_local1518534492_0012_m_000000_0
2020-11-19 10:13:42  [ Thread-348:17757 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:42  [ Thread-348:17758 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:42  [ pool-39-thread-1:17758 ] - [ INFO ]  Starting task: attempt_local1518534492_0012_r_000000_0
2020-11-19 10:13:42  [ pool-39-thread-1:17758 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7f90cf5b
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:42  [ EventFetcher for fetching Map Completion Events:17759 ] - [ INFO ]  attempt_local1518534492_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:42  [ localfetcher#12:17760 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local1518534492_0012_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:42  [ localfetcher#12:17760 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1518534492_0012_m_000000_0
2020-11-19 10:13:42  [ localfetcher#12:17760 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:42  [ EventFetcher for fetching Map Completion Events:17760 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:43  [ pool-39-thread-1:17810 ] - [ INFO ]  Task:attempt_local1518534492_0012_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:43  [ pool-39-thread-1:17815 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:43  [ pool-39-thread-1:17815 ] - [ INFO ]  Task attempt_local1518534492_0012_r_000000_0 is allowed to commit now
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  Saved output of task 'attempt_local1518534492_0012_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1518534492_0012_r_000000
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  Task 'attempt_local1518534492_0012_r_000000_0' done.
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  Finishing task: attempt_local1518534492_0012_r_000000_0
2020-11-19 10:13:43  [ Thread-348:17831 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:43  [ main:18585 ] - [ INFO ]  Job job_local1518534492_0012 running in uber mode : false
2020-11-19 10:13:43  [ main:18586 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:43  [ main:18586 ] - [ INFO ]  Job job_local1518534492_0012 completed successfully
2020-11-19 10:13:43  [ main:18587 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=97512
		FILE: Number of bytes written=6928286
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=769906
		HDFS: Number of bytes written=11646
		HDFS: Number of read operations=741
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=244
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=39
		Total committed heap usage (bytes)=2015363072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:44  [ main:18900 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:44  [ main:18910 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:44  [ main:18914 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:44  [ main:18924 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:44  [ main:18961 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:44  [ main:18981 ] - [ INFO ]  Submitting tokens for job: job_local1027567860_0013
2020-11-19 10:13:44  [ main:19019 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:44  [ main:19019 ] - [ INFO ]  Running job: job_local1027567860_0013
2020-11-19 10:13:44  [ Thread-378:19019 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:44  [ Thread-378:19019 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:44  [ Thread-378:19019 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:44  [ Thread-378:19040 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19040 ] - [ INFO ]  Starting task: attempt_local1027567860_0013_m_000000_0
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19050 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19125 ] - [ INFO ]  
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19125 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19126 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19126 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19126 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19129 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19130 ] - [ INFO ]  Task:attempt_local1027567860_0013_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19139 ] - [ INFO ]  map
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19139 ] - [ INFO ]  Task 'attempt_local1027567860_0013_m_000000_0' done.
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19139 ] - [ INFO ]  Finishing task: attempt_local1027567860_0013_m_000000_0
2020-11-19 10:13:44  [ Thread-378:19139 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:44  [ Thread-378:19140 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]  Starting task: attempt_local1027567860_0013_r_000000_0
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:44  [ pool-42-thread-1:19141 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61ae3b10
2020-11-19 10:13:44  [ pool-42-thread-1:19141 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:44  [ EventFetcher for fetching Map Completion Events:19141 ] - [ INFO ]  attempt_local1027567860_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:44  [ localfetcher#13:19142 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local1027567860_0013_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:44  [ localfetcher#13:19142 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1027567860_0013_m_000000_0
2020-11-19 10:13:44  [ localfetcher#13:19142 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:44  [ EventFetcher for fetching Map Completion Events:19142 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:44  [ pool-42-thread-1:19142 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:44  [ pool-42-thread-1:19142 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:44  [ pool-42-thread-1:19143 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:44  [ pool-42-thread-1:19185 ] - [ INFO ]  Task:attempt_local1027567860_0013_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:44  [ pool-42-thread-1:19190 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:44  [ pool-42-thread-1:19190 ] - [ INFO ]  Task attempt_local1027567860_0013_r_000000_0 is allowed to commit now
2020-11-19 10:13:44  [ pool-42-thread-1:19209 ] - [ INFO ]  Saved output of task 'attempt_local1027567860_0013_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1027567860_0013_r_000000
2020-11-19 10:13:44  [ pool-42-thread-1:19209 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:44  [ pool-42-thread-1:19210 ] - [ INFO ]  Task 'attempt_local1027567860_0013_r_000000_0' done.
2020-11-19 10:13:44  [ pool-42-thread-1:19210 ] - [ INFO ]  Finishing task: attempt_local1027567860_0013_r_000000_0
2020-11-19 10:13:44  [ Thread-378:19210 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:45  [ main:20022 ] - [ INFO ]  Job job_local1027567860_0013 running in uber mode : false
2020-11-19 10:13:45  [ main:20022 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:45  [ main:20022 ] - [ INFO ]  Job job_local1027567860_0013 completed successfully
2020-11-19 10:13:45  [ main:20023 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=98702
		FILE: Number of bytes written=7500208
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=834312
		HDFS: Number of bytes written=12726
		HDFS: Number of read operations=809
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=266
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2015363072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:45  [ main:20303 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:45  [ main:20313 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:45  [ main:20317 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:45  [ main:20322 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:45  [ main:20361 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:45  [ main:20379 ] - [ INFO ]  Submitting tokens for job: job_local1130360853_0014
2020-11-19 10:13:45  [ main:20417 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:45  [ main:20417 ] - [ INFO ]  Running job: job_local1130360853_0014
2020-11-19 10:13:45  [ Thread-408:20417 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:45  [ Thread-408:20418 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:45  [ Thread-408:20418 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:45  [ Thread-408:20425 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20425 ] - [ INFO ]  Starting task: attempt_local1130360853_0014_m_000000_0
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20425 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20426 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20426 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20426 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20453 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20527 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20528 ] - [ INFO ]  Task:attempt_local1130360853_0014_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20536 ] - [ INFO ]  map
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20536 ] - [ INFO ]  Task 'attempt_local1130360853_0014_m_000000_0' done.
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20536 ] - [ INFO ]  Finishing task: attempt_local1130360853_0014_m_000000_0
2020-11-19 10:13:45  [ Thread-408:20536 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:45  [ Thread-408:20536 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:45  [ pool-45-thread-1:20536 ] - [ INFO ]  Starting task: attempt_local1130360853_0014_r_000000_0
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@430da8cd
2020-11-19 10:13:45  [ pool-45-thread-1:20538 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:45  [ EventFetcher for fetching Map Completion Events:20538 ] - [ INFO ]  attempt_local1130360853_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:45  [ localfetcher#14:20539 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local1130360853_0014_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:45  [ localfetcher#14:20539 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1130360853_0014_m_000000_0
2020-11-19 10:13:45  [ localfetcher#14:20539 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:45  [ EventFetcher for fetching Map Completion Events:20539 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:45  [ pool-45-thread-1:20539 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:45  [ pool-45-thread-1:20539 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:45  [ pool-45-thread-1:20540 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:45  [ pool-45-thread-1:20540 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:45  [ pool-45-thread-1:20542 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:45  [ pool-45-thread-1:20596 ] - [ INFO ]  Task:attempt_local1130360853_0014_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:45  [ pool-45-thread-1:20602 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:45  [ pool-45-thread-1:20602 ] - [ INFO ]  Task attempt_local1130360853_0014_r_000000_0 is allowed to commit now
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  Saved output of task 'attempt_local1130360853_0014_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1130360853_0014_r_000000
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  Task 'attempt_local1130360853_0014_r_000000_0' done.
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  Finishing task: attempt_local1130360853_0014_r_000000_0
2020-11-19 10:13:45  [ Thread-408:20618 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:46  [ main:21422 ] - [ INFO ]  Job job_local1130360853_0014 running in uber mode : false
2020-11-19 10:13:46  [ main:21422 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:46  [ main:21423 ] - [ INFO ]  Job job_local1130360853_0014 completed successfully
2020-11-19 10:13:46  [ main:21423 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=99894
		FILE: Number of bytes written=8072133
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=898718
		HDFS: Number of bytes written=13806
		HDFS: Number of read operations=877
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=288
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2015363072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:46  [ main:21729 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:46  [ main:21741 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:46  [ main:21745 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:46  [ main:21751 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:47  [ main:21788 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:47  [ main:21809 ] - [ INFO ]  Submitting tokens for job: job_local739671580_0015
2020-11-19 10:13:47  [ main:21852 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:47  [ main:21852 ] - [ INFO ]  Running job: job_local739671580_0015
2020-11-19 10:13:47  [ Thread-438:21852 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:47  [ Thread-438:21852 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:47  [ Thread-438:21852 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:47  [ Thread-438:21860 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21860 ] - [ INFO ]  Starting task: attempt_local739671580_0015_m_000000_0
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21860 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21861 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21861 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21861 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21944 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21945 ] - [ INFO ]  Task:attempt_local739671580_0015_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21951 ] - [ INFO ]  map
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21951 ] - [ INFO ]  Task 'attempt_local739671580_0015_m_000000_0' done.
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21951 ] - [ INFO ]  Finishing task: attempt_local739671580_0015_m_000000_0
2020-11-19 10:13:47  [ Thread-438:21951 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:47  [ Thread-438:21952 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  Starting task: attempt_local739671580_0015_r_000000_0
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@587c4103
2020-11-19 10:13:47  [ pool-48-thread-1:21953 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:47  [ EventFetcher for fetching Map Completion Events:21953 ] - [ INFO ]  attempt_local739671580_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:47  [ localfetcher#15:21953 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local739671580_0015_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:47  [ localfetcher#15:21954 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local739671580_0015_m_000000_0
2020-11-19 10:13:47  [ localfetcher#15:21954 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:47  [ EventFetcher for fetching Map Completion Events:21954 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:47  [ pool-48-thread-1:21954 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:47  [ pool-48-thread-1:21954 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:47  [ pool-48-thread-1:21955 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:47  [ pool-48-thread-1:21955 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:47  [ pool-48-thread-1:21957 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:47  [ pool-48-thread-1:21997 ] - [ INFO ]  Task:attempt_local739671580_0015_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:47  [ pool-48-thread-1:22002 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:47  [ pool-48-thread-1:22002 ] - [ INFO ]  Task attempt_local739671580_0015_r_000000_0 is allowed to commit now
2020-11-19 10:13:47  [ pool-48-thread-1:22018 ] - [ INFO ]  Saved output of task 'attempt_local739671580_0015_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local739671580_0015_r_000000
2020-11-19 10:13:47  [ pool-48-thread-1:22019 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:47  [ pool-48-thread-1:22019 ] - [ INFO ]  Task 'attempt_local739671580_0015_r_000000_0' done.
2020-11-19 10:13:47  [ pool-48-thread-1:22019 ] - [ INFO ]  Finishing task: attempt_local739671580_0015_r_000000_0
2020-11-19 10:13:47  [ Thread-438:22019 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:48  [ main:22855 ] - [ INFO ]  Job job_local739671580_0015 running in uber mode : false
2020-11-19 10:13:48  [ main:22855 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:48  [ main:22855 ] - [ INFO ]  Job job_local739671580_0015 completed successfully
2020-11-19 10:13:48  [ main:22857 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=101086
		FILE: Number of bytes written=8641008
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=963124
		HDFS: Number of bytes written=14886
		HDFS: Number of read operations=945
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=310
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2024800256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:48  [ main:23168 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:48  [ main:23179 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:48  [ main:23184 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:48  [ main:23190 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:48  [ main:23229 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:48  [ main:23247 ] - [ INFO ]  Submitting tokens for job: job_local1625719503_0016
2020-11-19 10:13:48  [ main:23281 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:48  [ main:23281 ] - [ INFO ]  Running job: job_local1625719503_0016
2020-11-19 10:13:48  [ Thread-468:23281 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:48  [ Thread-468:23281 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:48  [ Thread-468:23282 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:48  [ Thread-468:23289 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23289 ] - [ INFO ]  Starting task: attempt_local1625719503_0016_m_000000_0
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23299 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23375 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23376 ] - [ INFO ]  Task:attempt_local1625719503_0016_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23381 ] - [ INFO ]  map
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23381 ] - [ INFO ]  Task 'attempt_local1625719503_0016_m_000000_0' done.
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23381 ] - [ INFO ]  Finishing task: attempt_local1625719503_0016_m_000000_0
2020-11-19 10:13:48  [ Thread-468:23381 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:48  [ Thread-468:23382 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]  Starting task: attempt_local1625719503_0016_r_000000_0
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:48  [ pool-51-thread-1:23383 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3888df8f
2020-11-19 10:13:48  [ pool-51-thread-1:23383 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:48  [ EventFetcher for fetching Map Completion Events:23383 ] - [ INFO ]  attempt_local1625719503_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:48  [ localfetcher#16:23384 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local1625719503_0016_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:48  [ localfetcher#16:23384 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1625719503_0016_m_000000_0
2020-11-19 10:13:48  [ localfetcher#16:23384 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:48  [ EventFetcher for fetching Map Completion Events:23384 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:48  [ pool-51-thread-1:23385 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:48  [ pool-51-thread-1:23385 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:48  [ pool-51-thread-1:23442 ] - [ INFO ]  Task:attempt_local1625719503_0016_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:48  [ pool-51-thread-1:23447 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:48  [ pool-51-thread-1:23447 ] - [ INFO ]  Task attempt_local1625719503_0016_r_000000_0 is allowed to commit now
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  Saved output of task 'attempt_local1625719503_0016_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1625719503_0016_r_000000
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  Task 'attempt_local1625719503_0016_r_000000_0' done.
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  Finishing task: attempt_local1625719503_0016_r_000000_0
2020-11-19 10:13:48  [ Thread-468:23466 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:49  [ main:24284 ] - [ INFO ]  Job job_local1625719503_0016 running in uber mode : false
2020-11-19 10:13:49  [ main:24284 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:49  [ main:24284 ] - [ INFO ]  Job job_local1625719503_0016 completed successfully
2020-11-19 10:13:49  [ main:24285 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=102276
		FILE: Number of bytes written=9212930
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1027530
		HDFS: Number of bytes written=15966
		HDFS: Number of read operations=1013
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=332
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2024800256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:49  [ main:24575 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:49  [ main:24584 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:49  [ main:24588 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:49  [ main:24594 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:49  [ main:24627 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:49  [ main:24643 ] - [ INFO ]  Submitting tokens for job: job_local1070818853_0017
2020-11-19 10:13:49  [ main:24675 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:49  [ main:24675 ] - [ INFO ]  Running job: job_local1070818853_0017
2020-11-19 10:13:49  [ Thread-498:24676 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:49  [ Thread-498:24676 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:49  [ Thread-498:24676 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:49  [ Thread-498:24683 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24683 ] - [ INFO ]  Starting task: attempt_local1070818853_0017_m_000000_0
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24683 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24683 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24684 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24684 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24693 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24766 ] - [ INFO ]  
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24769 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24770 ] - [ INFO ]  Task:attempt_local1070818853_0017_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24776 ] - [ INFO ]  map
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24776 ] - [ INFO ]  Task 'attempt_local1070818853_0017_m_000000_0' done.
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24776 ] - [ INFO ]  Finishing task: attempt_local1070818853_0017_m_000000_0
2020-11-19 10:13:49  [ Thread-498:24776 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:49  [ Thread-498:24777 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  Starting task: attempt_local1070818853_0017_r_000000_0
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21df333d
2020-11-19 10:13:49  [ pool-54-thread-1:24778 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:49  [ EventFetcher for fetching Map Completion Events:24778 ] - [ INFO ]  attempt_local1070818853_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:49  [ localfetcher#17:24779 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local1070818853_0017_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:49  [ localfetcher#17:24779 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1070818853_0017_m_000000_0
2020-11-19 10:13:49  [ localfetcher#17:24779 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:49  [ EventFetcher for fetching Map Completion Events:24779 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:49  [ pool-54-thread-1:24779 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:49  [ pool-54-thread-1:24779 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:49  [ pool-54-thread-1:24780 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:49  [ pool-54-thread-1:24780 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:50  [ pool-54-thread-1:24847 ] - [ INFO ]  Task:attempt_local1070818853_0017_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:50  [ pool-54-thread-1:24854 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:50  [ pool-54-thread-1:24854 ] - [ INFO ]  Task attempt_local1070818853_0017_r_000000_0 is allowed to commit now
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  Saved output of task 'attempt_local1070818853_0017_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1070818853_0017_r_000000
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  Task 'attempt_local1070818853_0017_r_000000_0' done.
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  Finishing task: attempt_local1070818853_0017_r_000000_0
2020-11-19 10:13:50  [ Thread-498:24870 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:50  [ main:25677 ] - [ INFO ]  Job job_local1070818853_0017 running in uber mode : false
2020-11-19 10:13:50  [ main:25677 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:50  [ main:25677 ] - [ INFO ]  Job job_local1070818853_0017 completed successfully
2020-11-19 10:13:50  [ main:25678 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=103468
		FILE: Number of bytes written=9784855
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1091936
		HDFS: Number of bytes written=17046
		HDFS: Number of read operations=1081
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=354
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2337275904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:51  [ main:25957 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:51  [ main:25967 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:51  [ main:25971 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:51  [ main:25976 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:51  [ main:26011 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:51  [ main:26028 ] - [ INFO ]  Submitting tokens for job: job_local1137772343_0018
2020-11-19 10:13:51  [ main:26063 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:51  [ main:26063 ] - [ INFO ]  Running job: job_local1137772343_0018
2020-11-19 10:13:51  [ Thread-528:26064 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:51  [ Thread-528:26064 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:51  [ Thread-528:26064 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:51  [ Thread-528:26071 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]  Starting task: attempt_local1137772343_0018_m_000000_0
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26072 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26151 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26152 ] - [ INFO ]  Task:attempt_local1137772343_0018_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26157 ] - [ INFO ]  map
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26157 ] - [ INFO ]  Task 'attempt_local1137772343_0018_m_000000_0' done.
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26157 ] - [ INFO ]  Finishing task: attempt_local1137772343_0018_m_000000_0
2020-11-19 10:13:51  [ Thread-528:26157 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:51  [ Thread-528:26158 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  Starting task: attempt_local1137772343_0018_r_000000_0
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@203836d2
2020-11-19 10:13:51  [ pool-57-thread-1:26159 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:51  [ EventFetcher for fetching Map Completion Events:26159 ] - [ INFO ]  attempt_local1137772343_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:51  [ localfetcher#18:26159 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local1137772343_0018_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:51  [ localfetcher#18:26160 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1137772343_0018_m_000000_0
2020-11-19 10:13:51  [ localfetcher#18:26160 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:51  [ EventFetcher for fetching Map Completion Events:26160 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:51  [ pool-57-thread-1:26160 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:51  [ pool-57-thread-1:26160 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:51  [ pool-57-thread-1:26161 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:51  [ pool-57-thread-1:26161 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:51  [ pool-57-thread-1:26218 ] - [ INFO ]  Task:attempt_local1137772343_0018_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:51  [ pool-57-thread-1:26224 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:51  [ pool-57-thread-1:26224 ] - [ INFO ]  Task attempt_local1137772343_0018_r_000000_0 is allowed to commit now
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  Saved output of task 'attempt_local1137772343_0018_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1137772343_0018_r_000000
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  Task 'attempt_local1137772343_0018_r_000000_0' done.
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  Finishing task: attempt_local1137772343_0018_r_000000_0
2020-11-19 10:13:51  [ Thread-528:26244 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 10:14:54  [ main:585 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 10:14:54  [ main:585 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 10:14:54  [ main:775 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:54  [ main:779 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:54  [ main:791 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:54  [ main:866 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:54  [ main:933 ] - [ INFO ]  Submitting tokens for job: job_local853577622_0001
2020-11-19 10:14:54  [ main:1031 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:54  [ main:1032 ] - [ INFO ]  Running job: job_local853577622_0001
2020-11-19 10:14:54  [ Thread-18:1032 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:54  [ Thread-18:1035 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:54  [ Thread-18:1037 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:54  [ Thread-18:1080 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1081 ] - [ INFO ]  Starting task: attempt_local853577622_0001_m_000000_0
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1099 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1100 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1102 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1154 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1247 ] - [ INFO ]  
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  bufstart = 0; bufend = 19877; bufvoid = 104857600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213068(104852272); length = 1329/6553600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1260 ] - [ INFO ]  Task:attempt_local853577622_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1273 ] - [ INFO ]  map
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1273 ] - [ INFO ]  Task 'attempt_local853577622_0001_m_000000_0' done.
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1273 ] - [ INFO ]  Finishing task: attempt_local853577622_0001_m_000000_0
2020-11-19 10:14:54  [ Thread-18:1273 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:54  [ Thread-18:1275 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:54  [ pool-6-thread-1:1275 ] - [ INFO ]  Starting task: attempt_local853577622_0001_r_000000_0
2020-11-19 10:14:54  [ pool-6-thread-1:1280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:54  [ pool-6-thread-1:1280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:54  [ pool-6-thread-1:1281 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:54  [ pool-6-thread-1:1282 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57dc39e0
2020-11-19 10:14:54  [ pool-6-thread-1:1291 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:54  [ EventFetcher for fetching Map Completion Events:1293 ] - [ INFO ]  attempt_local853577622_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:54  [ localfetcher#1:1313 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local853577622_0001_m_000000_0 decomp: 20545 len: 20549 to MEMORY
2020-11-19 10:14:54  [ localfetcher#1:1317 ] - [ INFO ]  Read 20545 bytes from map-output for attempt_local853577622_0001_m_000000_0
2020-11-19 10:14:54  [ localfetcher#1:1318 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20545, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20545
2020-11-19 10:14:54  [ EventFetcher for fetching Map Completion Events:1319 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:54  [ pool-6-thread-1:1319 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:54  [ pool-6-thread-1:1320 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:54  [ pool-6-thread-1:1324 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:54  [ pool-6-thread-1:1324 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20541 bytes
2020-11-19 10:14:54  [ pool-6-thread-1:1327 ] - [ INFO ]  Merged 1 segments, 20545 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:54  [ pool-6-thread-1:1327 ] - [ INFO ]  Merging 1 files, 20549 bytes from disk
2020-11-19 10:14:54  [ pool-6-thread-1:1328 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:54  [ pool-6-thread-1:1328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:54  [ pool-6-thread-1:1328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20541 bytes
2020-11-19 10:14:54  [ pool-6-thread-1:1329 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:54  [ pool-6-thread-1:1351 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 10:14:55  [ pool-6-thread-1:1484 ] - [ INFO ]  Task:attempt_local853577622_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:55  [ pool-6-thread-1:1493 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:55  [ pool-6-thread-1:1493 ] - [ INFO ]  Task attempt_local853577622_0001_r_000000_0 is allowed to commit now
2020-11-19 10:14:55  [ pool-6-thread-1:1516 ] - [ INFO ]  Saved output of task 'attempt_local853577622_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local853577622_0001_r_000000
2020-11-19 10:14:55  [ pool-6-thread-1:1517 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:55  [ pool-6-thread-1:1517 ] - [ INFO ]  Task 'attempt_local853577622_0001_r_000000_0' done.
2020-11-19 10:14:55  [ pool-6-thread-1:1517 ] - [ INFO ]  Finishing task: attempt_local853577622_0001_r_000000_0
2020-11-19 10:14:55  [ Thread-18:1517 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:55  [ main:2037 ] - [ INFO ]  Job job_local853577622_0001 running in uber mode : false
2020-11-19 10:14:55  [ main:2038 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:55  [ main:2039 ] - [ INFO ]  Job job_local853577622_0001 completed successfully
2020-11-19 10:14:55  [ main:2046 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=41480
		FILE: Number of bytes written=626805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=181
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=333
		Map output bytes=19877
		Map output materialized bytes=20549
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20549
		Reduce input records=333
		Reduce output records=3
		Spilled Records=666
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:55  [ main:2188 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:55  [ main:2200 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:55  [ main:2204 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:55  [ main:2210 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:55  [ main:2252 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:55  [ main:2272 ] - [ INFO ]  Submitting tokens for job: job_local1814568215_0002
2020-11-19 10:14:55  [ main:2315 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:55  [ main:2315 ] - [ INFO ]  Running job: job_local1814568215_0002
2020-11-19 10:14:55  [ Thread-48:2315 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:55  [ Thread-48:2315 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:55  [ Thread-48:2315 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:55  [ Thread-48:2325 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2325 ] - [ INFO ]  Starting task: attempt_local1814568215_0002_m_000000_0
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2326 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2326 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2326 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2327 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2368 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2465 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2467 ] - [ INFO ]  Task:attempt_local1814568215_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  map
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  Task 'attempt_local1814568215_0002_m_000000_0' done.
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  Finishing task: attempt_local1814568215_0002_m_000000_0
2020-11-19 10:14:56  [ Thread-48:2474 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:56  [ Thread-48:2475 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:56  [ pool-9-thread-1:2475 ] - [ INFO ]  Starting task: attempt_local1814568215_0002_r_000000_0
2020-11-19 10:14:56  [ pool-9-thread-1:2475 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:56  [ pool-9-thread-1:2476 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:56  [ pool-9-thread-1:2476 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:56  [ pool-9-thread-1:2476 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a73e19a
2020-11-19 10:14:56  [ pool-9-thread-1:2477 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:56  [ EventFetcher for fetching Map Completion Events:2477 ] - [ INFO ]  attempt_local1814568215_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:56  [ localfetcher#2:2478 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1814568215_0002_m_000000_0 decomp: 183 len: 187 to MEMORY
2020-11-19 10:14:56  [ localfetcher#2:2478 ] - [ INFO ]  Read 183 bytes from map-output for attempt_local1814568215_0002_m_000000_0
2020-11-19 10:14:56  [ localfetcher#2:2478 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 183, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->183
2020-11-19 10:14:56  [ EventFetcher for fetching Map Completion Events:2479 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:56  [ pool-9-thread-1:2479 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:56  [ pool-9-thread-1:2479 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:56  [ pool-9-thread-1:2480 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 179 bytes
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merged 1 segments, 183 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merging 1 files, 187 bytes from disk
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:56  [ pool-9-thread-1:2482 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 179 bytes
2020-11-19 10:14:56  [ pool-9-thread-1:2482 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:56  [ pool-9-thread-1:2539 ] - [ INFO ]  Task:attempt_local1814568215_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:56  [ pool-9-thread-1:2545 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:56  [ pool-9-thread-1:2545 ] - [ INFO ]  Task attempt_local1814568215_0002_r_000000_0 is allowed to commit now
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  Saved output of task 'attempt_local1814568215_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1814568215_0002_r_000000
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  Task 'attempt_local1814568215_0002_r_000000_0' done.
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  Finishing task: attempt_local1814568215_0002_r_000000_0
2020-11-19 10:14:56  [ Thread-48:2564 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:56  [ main:3318 ] - [ INFO ]  Job job_local1814568215_0002 running in uber mode : false
2020-11-19 10:14:56  [ main:3319 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:56  [ main:3319 ] - [ INFO ]  Job job_local1814568215_0002 completed successfully
2020-11-19 10:14:56  [ main:3321 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=83366
		FILE: Number of bytes written=1219057
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125936
		HDFS: Number of bytes written=905
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=187
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=187
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:57  [ main:3616 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:57  [ main:3628 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:57  [ main:3632 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:57  [ main:3639 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:57  [ main:3682 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:57  [ main:3706 ] - [ INFO ]  Submitting tokens for job: job_local614724230_0003
2020-11-19 10:14:57  [ main:3756 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:57  [ main:3756 ] - [ INFO ]  Running job: job_local614724230_0003
2020-11-19 10:14:57  [ Thread-78:3756 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:57  [ Thread-78:3756 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:57  [ Thread-78:3756 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:57  [ Thread-78:3765 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3765 ] - [ INFO ]  Starting task: attempt_local614724230_0003_m_000000_0
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3766 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3766 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3766 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3767 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3789 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3977 ] - [ INFO ]  
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3983 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3984 ] - [ INFO ]  Task:attempt_local614724230_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3991 ] - [ INFO ]  map
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3991 ] - [ INFO ]  Task 'attempt_local614724230_0003_m_000000_0' done.
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3991 ] - [ INFO ]  Finishing task: attempt_local614724230_0003_m_000000_0
2020-11-19 10:14:57  [ Thread-78:3991 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:57  [ Thread-78:3992 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:57  [ pool-12-thread-1:3992 ] - [ INFO ]  Starting task: attempt_local614724230_0003_r_000000_0
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a6d5f8e
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:57  [ EventFetcher for fetching Map Completion Events:3994 ] - [ INFO ]  attempt_local614724230_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:57  [ localfetcher#3:3995 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local614724230_0003_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:14:57  [ localfetcher#3:3995 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local614724230_0003_m_000000_0
2020-11-19 10:14:57  [ localfetcher#3:3995 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:14:57  [ EventFetcher for fetching Map Completion Events:3996 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:57  [ pool-12-thread-1:3996 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:57  [ pool-12-thread-1:3996 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:57  [ pool-12-thread-1:3998 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:57  [ pool-12-thread-1:3998 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:57  [ pool-12-thread-1:3998 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:57  [ pool-12-thread-1:4048 ] - [ INFO ]  Task:attempt_local614724230_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:57  [ pool-12-thread-1:4054 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:57  [ pool-12-thread-1:4054 ] - [ INFO ]  Task attempt_local614724230_0003_r_000000_0 is allowed to commit now
2020-11-19 10:14:57  [ pool-12-thread-1:4070 ] - [ INFO ]  Saved output of task 'attempt_local614724230_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local614724230_0003_r_000000
2020-11-19 10:14:57  [ pool-12-thread-1:4071 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:57  [ pool-12-thread-1:4071 ] - [ INFO ]  Task 'attempt_local614724230_0003_r_000000_0' done.
2020-11-19 10:14:57  [ pool-12-thread-1:4071 ] - [ INFO ]  Finishing task: attempt_local614724230_0003_r_000000_0
2020-11-19 10:14:57  [ Thread-78:4071 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:58  [ main:4757 ] - [ INFO ]  Job job_local614724230_0003 running in uber mode : false
2020-11-19 10:14:58  [ main:4757 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:58  [ main:4758 ] - [ INFO ]  Job job_local614724230_0003 completed successfully
2020-11-19 10:14:58  [ main:4761 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84542
		FILE: Number of bytes written=1787920
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190352
		HDFS: Number of bytes written=1991
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=94
		Total committed heap usage (bytes)=1027604480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:58  [ main:5079 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:58  [ main:5089 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:58  [ main:5093 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:58  [ main:5098 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:58  [ main:5138 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:58  [ main:5157 ] - [ INFO ]  Submitting tokens for job: job_local1521157371_0004
2020-11-19 10:14:58  [ main:5197 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:58  [ main:5197 ] - [ INFO ]  Running job: job_local1521157371_0004
2020-11-19 10:14:58  [ Thread-108:5197 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:58  [ Thread-108:5197 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:58  [ Thread-108:5198 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:58  [ Thread-108:5207 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  Starting task: attempt_local1521157371_0004_m_000000_0
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5208 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5208 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5208 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5295 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5296 ] - [ INFO ]  Task:attempt_local1521157371_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5303 ] - [ INFO ]  map
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5303 ] - [ INFO ]  Task 'attempt_local1521157371_0004_m_000000_0' done.
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5303 ] - [ INFO ]  Finishing task: attempt_local1521157371_0004_m_000000_0
2020-11-19 10:14:58  [ Thread-108:5304 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:58  [ Thread-108:5304 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:58  [ pool-15-thread-1:5304 ] - [ INFO ]  Starting task: attempt_local1521157371_0004_r_000000_0
2020-11-19 10:14:58  [ pool-15-thread-1:5305 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@131866ad
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:58  [ EventFetcher for fetching Map Completion Events:5306 ] - [ INFO ]  attempt_local1521157371_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:58  [ localfetcher#4:5307 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1521157371_0004_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:14:58  [ localfetcher#4:5308 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1521157371_0004_m_000000_0
2020-11-19 10:14:58  [ localfetcher#4:5308 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:14:58  [ EventFetcher for fetching Map Completion Events:5308 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:58  [ pool-15-thread-1:5308 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:58  [ pool-15-thread-1:5309 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:58  [ pool-15-thread-1:5309 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:58  [ pool-15-thread-1:5309 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:58  [ pool-15-thread-1:5311 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:58  [ pool-15-thread-1:5371 ] - [ INFO ]  Task:attempt_local1521157371_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:58  [ pool-15-thread-1:5379 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:58  [ pool-15-thread-1:5379 ] - [ INFO ]  Task attempt_local1521157371_0004_r_000000_0 is allowed to commit now
2020-11-19 10:14:58  [ pool-15-thread-1:5400 ] - [ INFO ]  Saved output of task 'attempt_local1521157371_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1521157371_0004_r_000000
2020-11-19 10:14:58  [ pool-15-thread-1:5401 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:58  [ pool-15-thread-1:5401 ] - [ INFO ]  Task 'attempt_local1521157371_0004_r_000000_0' done.
2020-11-19 10:14:58  [ pool-15-thread-1:5401 ] - [ INFO ]  Finishing task: attempt_local1521157371_0004_r_000000_0
2020-11-19 10:14:58  [ Thread-108:5401 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:59  [ main:6202 ] - [ INFO ]  Job job_local1521157371_0004 running in uber mode : false
2020-11-19 10:14:59  [ main:6203 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:59  [ main:6203 ] - [ INFO ]  Job job_local1521157371_0004 completed successfully
2020-11-19 10:14:59  [ main:6205 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85732
		FILE: Number of bytes written=2359838
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254768
		HDFS: Number of bytes written=3077
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1027604480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:59  [ main:6289 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:59  [ main:6305 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:59  [ main:6310 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:59  [ main:6317 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:59  [ main:6358 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:59  [ main:6378 ] - [ INFO ]  Submitting tokens for job: job_local435709595_0005
2020-11-19 10:14:59  [ main:6413 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:59  [ main:6413 ] - [ INFO ]  Running job: job_local435709595_0005
2020-11-19 10:14:59  [ Thread-134:6413 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:59  [ Thread-134:6414 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:59  [ Thread-134:6414 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:59  [ Thread-134:6422 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6422 ] - [ INFO ]  Starting task: attempt_local435709595_0005_m_000000_0
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6423 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6423 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6423 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6424 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/tmp/center.txt:0+181
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  Spilling map output
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  bufstart = 0; bufend = 123; bufvoid = 104857600
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6494 ] - [ INFO ]  Finished spill 0
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6495 ] - [ INFO ]  Task:attempt_local435709595_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6502 ] - [ INFO ]  map
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6502 ] - [ INFO ]  Task 'attempt_local435709595_0005_m_000000_0' done.
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6502 ] - [ INFO ]  Finishing task: attempt_local435709595_0005_m_000000_0
2020-11-19 10:15:00  [ Thread-134:6502 ] - [ INFO ]  map task executor complete.
2020-11-19 10:15:00  [ Thread-134:6503 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:15:00  [ pool-18-thread-1:6503 ] - [ INFO ]  Starting task: attempt_local435709595_0005_r_000000_0
2020-11-19 10:15:00  [ pool-18-thread-1:6503 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52aeabe3
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:15:00  [ EventFetcher for fetching Map Completion Events:6504 ] - [ INFO ]  attempt_local435709595_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:15:00  [ localfetcher#5:6505 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local435709595_0005_m_000000_0 decomp: 131 len: 135 to MEMORY
2020-11-19 10:15:00  [ localfetcher#5:6505 ] - [ INFO ]  Read 131 bytes from map-output for attempt_local435709595_0005_m_000000_0
2020-11-19 10:15:00  [ localfetcher#5:6505 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 131, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->131
2020-11-19 10:15:00  [ EventFetcher for fetching Map Completion Events:6506 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:15:00  [ pool-18-thread-1:6506 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:15:00  [ pool-18-thread-1:6506 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:15:00  [ pool-18-thread-1:6507 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:15:00  [ pool-18-thread-1:6507 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 127 bytes
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merged 1 segments, 131 bytes to disk to satisfy reduce memory limit
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merging 1 files, 135 bytes from disk
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 127 bytes
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:15:00  [ pool-18-thread-1:6556 ] - [ INFO ]  Task:attempt_local435709595_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 10:15:00  [ pool-18-thread-1:6563 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:15:00  [ pool-18-thread-1:6563 ] - [ INFO ]  Task attempt_local435709595_0005_r_000000_0 is allowed to commit now
2020-11-19 10:15:00  [ main:7414 ] - [ INFO ]  Job job_local435709595_0005 running in uber mode : false
2020-11-19 10:15:00  [ main:7415 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 10:15:00  [ pool-18-thread-1:7444 ] - [ INFO ]  Saved output of task 'attempt_local435709595_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local435709595_0005_r_000000
2020-11-19 10:15:00  [ pool-18-thread-1:7445 ] - [ INFO ]  reduce > reduce
2020-11-19 10:15:00  [ pool-18-thread-1:7445 ] - [ INFO ]  Task 'attempt_local435709595_0005_r_000000_0' done.
2020-11-19 10:15:00  [ pool-18-thread-1:7445 ] - [ INFO ]  Finishing task: attempt_local435709595_0005_r_000000_0
2020-11-19 10:15:00  [ Thread-134:7445 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:15:01  [ main:8419 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:15:01  [ main:8419 ] - [ INFO ]  Job job_local435709595_0005 completed successfully
2020-11-19 10:15:01  [ main:8421 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86804
		FILE: Number of bytes written=2925191
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=256216
		HDFS: Number of bytes written=3381
		HDFS: Number of read operations=245
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=82
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Map output bytes=123
		Map output materialized bytes=135
		Input split bytes=123
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=135
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1027604480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=181
	File Output Format Counters 
		Bytes Written=123
2020-11-19 10:18:12  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 10:18:12  [ main:565 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 10:18:12  [ main:565 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 10:18:12  [ main:747 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:12  [ main:752 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:12  [ main:766 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:12  [ main:839 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:12  [ main:902 ] - [ INFO ]  Submitting tokens for job: job_local2080574219_0001
2020-11-19 10:18:13  [ main:999 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:13  [ main:1000 ] - [ INFO ]  Running job: job_local2080574219_0001
2020-11-19 10:18:13  [ Thread-18:1000 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:13  [ Thread-18:1004 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:13  [ Thread-18:1006 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:13  [ Thread-18:1041 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1041 ] - [ INFO ]  Starting task: attempt_local2080574219_0001_m_000000_0
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1060 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1064 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1064 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1067 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1207 ] - [ INFO ]  
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  bufstart = 0; bufend = 19965; bufvoid = 104857600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213064(104852256); length = 1333/6553600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1217 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1220 ] - [ INFO ]  Task:attempt_local2080574219_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  map
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  Task 'attempt_local2080574219_0001_m_000000_0' done.
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  Finishing task: attempt_local2080574219_0001_m_000000_0
2020-11-19 10:18:13  [ Thread-18:1231 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:13  [ Thread-18:1233 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:13  [ pool-6-thread-1:1233 ] - [ INFO ]  Starting task: attempt_local2080574219_0001_r_000000_0
2020-11-19 10:18:13  [ pool-6-thread-1:1237 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:13  [ pool-6-thread-1:1238 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:13  [ pool-6-thread-1:1238 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:13  [ pool-6-thread-1:1239 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7eea48c7
2020-11-19 10:18:13  [ pool-6-thread-1:1247 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:13  [ EventFetcher for fetching Map Completion Events:1249 ] - [ INFO ]  attempt_local2080574219_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:13  [ localfetcher#1:1267 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2080574219_0001_m_000000_0 decomp: 20635 len: 20639 to MEMORY
2020-11-19 10:18:13  [ localfetcher#1:1271 ] - [ INFO ]  Read 20635 bytes from map-output for attempt_local2080574219_0001_m_000000_0
2020-11-19 10:18:13  [ localfetcher#1:1272 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20635, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20635
2020-11-19 10:18:13  [ EventFetcher for fetching Map Completion Events:1273 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:13  [ pool-6-thread-1:1273 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:13  [ pool-6-thread-1:1273 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:13  [ pool-6-thread-1:1277 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:13  [ pool-6-thread-1:1278 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20631 bytes
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merged 1 segments, 20635 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merging 1 files, 20639 bytes from disk
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:13  [ pool-6-thread-1:1281 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20631 bytes
2020-11-19 10:18:13  [ pool-6-thread-1:1281 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:13  [ pool-6-thread-1:1300 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 10:18:13  [ pool-6-thread-1:1407 ] - [ INFO ]  Task:attempt_local2080574219_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:13  [ pool-6-thread-1:1414 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:13  [ pool-6-thread-1:1414 ] - [ INFO ]  Task attempt_local2080574219_0001_r_000000_0 is allowed to commit now
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  Saved output of task 'attempt_local2080574219_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2080574219_0001_r_000000
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  Task 'attempt_local2080574219_0001_r_000000_0' done.
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  Finishing task: attempt_local2080574219_0001_r_000000_0
2020-11-19 10:18:13  [ Thread-18:1444 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:14  [ main:2002 ] - [ INFO ]  Job job_local2080574219_0001 running in uber mode : false
2020-11-19 10:18:14  [ main:2003 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:14  [ main:2004 ] - [ INFO ]  Job job_local2080574219_0001 completed successfully
2020-11-19 10:18:14  [ main:2011 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=41660
		FILE: Number of bytes written=630107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=178
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=334
		Map output bytes=19965
		Map output materialized bytes=20639
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20639
		Reduce input records=334
		Reduce output records=3
		Spilled Records=668
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 10:18:14  [ main:2119 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:14  [ main:2130 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:14  [ main:2135 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:14  [ main:2141 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:14  [ main:2182 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:14  [ main:2201 ] - [ INFO ]  Submitting tokens for job: job_local1023893339_0002
2020-11-19 10:18:14  [ main:2242 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:14  [ main:2242 ] - [ INFO ]  Running job: job_local1023893339_0002
2020-11-19 10:18:14  [ Thread-48:2242 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:14  [ Thread-48:2243 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:14  [ Thread-48:2243 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:14  [ Thread-48:2250 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2250 ] - [ INFO ]  Starting task: attempt_local1023893339_0002_m_000000_0
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2251 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2252 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2252 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2253 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2294 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2372 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2373 ] - [ INFO ]  Task:attempt_local1023893339_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2382 ] - [ INFO ]  map
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2382 ] - [ INFO ]  Task 'attempt_local1023893339_0002_m_000000_0' done.
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2382 ] - [ INFO ]  Finishing task: attempt_local1023893339_0002_m_000000_0
2020-11-19 10:18:14  [ Thread-48:2382 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:14  [ Thread-48:2382 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:14  [ pool-9-thread-1:2383 ] - [ INFO ]  Starting task: attempt_local1023893339_0002_r_000000_0
2020-11-19 10:18:14  [ pool-9-thread-1:2383 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@18b11366
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:14  [ EventFetcher for fetching Map Completion Events:2385 ] - [ INFO ]  attempt_local1023893339_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:14  [ localfetcher#2:2385 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1023893339_0002_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 10:18:14  [ localfetcher#2:2386 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1023893339_0002_m_000000_0
2020-11-19 10:18:14  [ localfetcher#2:2386 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 10:18:14  [ EventFetcher for fetching Map Completion Events:2386 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:14  [ pool-9-thread-1:2386 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:14  [ pool-9-thread-1:2387 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:14  [ pool-9-thread-1:2387 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:14  [ pool-9-thread-1:2387 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:18:14  [ pool-9-thread-1:2389 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:14  [ pool-9-thread-1:2439 ] - [ INFO ]  Task:attempt_local1023893339_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:14  [ pool-9-thread-1:2445 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:14  [ pool-9-thread-1:2446 ] - [ INFO ]  Task attempt_local1023893339_0002_r_000000_0 is allowed to commit now
2020-11-19 10:18:14  [ pool-9-thread-1:2463 ] - [ INFO ]  Saved output of task 'attempt_local1023893339_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1023893339_0002_r_000000
2020-11-19 10:18:14  [ pool-9-thread-1:2464 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:14  [ pool-9-thread-1:2464 ] - [ INFO ]  Task 'attempt_local1023893339_0002_r_000000_0' done.
2020-11-19 10:18:14  [ pool-9-thread-1:2464 ] - [ INFO ]  Finishing task: attempt_local1023893339_0002_r_000000_0
2020-11-19 10:18:14  [ Thread-48:2464 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:15  [ main:3244 ] - [ INFO ]  Job job_local1023893339_0002 running in uber mode : false
2020-11-19 10:18:15  [ main:3245 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:15  [ main:3245 ] - [ INFO ]  Job job_local1023893339_0002 completed successfully
2020-11-19 10:18:15  [ main:3247 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=83738
		FILE: Number of bytes written=1222467
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125924
		HDFS: Number of bytes written=890
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 10:18:15  [ main:3554 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:15  [ main:3564 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:15  [ main:3568 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:15  [ main:3574 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:15  [ main:3609 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:15  [ main:3634 ] - [ INFO ]  Submitting tokens for job: job_local968598121_0003
2020-11-19 10:18:15  [ main:3687 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:15  [ main:3687 ] - [ INFO ]  Running job: job_local968598121_0003
2020-11-19 10:18:15  [ Thread-78:3687 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:15  [ Thread-78:3687 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:15  [ Thread-78:3687 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:15  [ Thread-78:3696 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3696 ] - [ INFO ]  Starting task: attempt_local968598121_0003_m_000000_0
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3697 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3697 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3698 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3719 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3805 ] - [ INFO ]  
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3809 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3912 ] - [ INFO ]  Task:attempt_local968598121_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  map
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  Task 'attempt_local968598121_0003_m_000000_0' done.
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  Finishing task: attempt_local968598121_0003_m_000000_0
2020-11-19 10:18:15  [ Thread-78:3918 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:15  [ Thread-78:3919 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:15  [ pool-12-thread-1:3919 ] - [ INFO ]  Starting task: attempt_local968598121_0003_r_000000_0
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55b16c99
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:15  [ EventFetcher for fetching Map Completion Events:3921 ] - [ INFO ]  attempt_local968598121_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:15  [ localfetcher#3:3922 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local968598121_0003_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:15  [ localfetcher#3:3922 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local968598121_0003_m_000000_0
2020-11-19 10:18:15  [ localfetcher#3:3922 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:15  [ EventFetcher for fetching Map Completion Events:3923 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:15  [ pool-12-thread-1:3923 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:15  [ pool-12-thread-1:3923 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:15  [ pool-12-thread-1:3924 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:15  [ pool-12-thread-1:3924 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:15  [ pool-12-thread-1:3926 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:15  [ pool-12-thread-1:3926 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:15  [ pool-12-thread-1:3969 ] - [ INFO ]  Task:attempt_local968598121_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:15  [ pool-12-thread-1:3974 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:15  [ pool-12-thread-1:3974 ] - [ INFO ]  Task attempt_local968598121_0003_r_000000_0 is allowed to commit now
2020-11-19 10:18:15  [ pool-12-thread-1:3993 ] - [ INFO ]  Saved output of task 'attempt_local968598121_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local968598121_0003_r_000000
2020-11-19 10:18:15  [ pool-12-thread-1:3994 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:15  [ pool-12-thread-1:3994 ] - [ INFO ]  Task 'attempt_local968598121_0003_r_000000_0' done.
2020-11-19 10:18:15  [ pool-12-thread-1:3994 ] - [ INFO ]  Finishing task: attempt_local968598121_0003_r_000000_0
2020-11-19 10:18:15  [ Thread-78:3994 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:16  [ main:4687 ] - [ INFO ]  Job job_local968598121_0003 running in uber mode : false
2020-11-19 10:18:16  [ main:4687 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:16  [ main:4688 ] - [ INFO ]  Job job_local968598121_0003 completed successfully
2020-11-19 10:18:16  [ main:4690 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84926
		FILE: Number of bytes written=1791336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190310
		HDFS: Number of bytes written=1960
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=100
		Total committed heap usage (bytes)=1026555904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:16  [ main:4958 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:16  [ main:4974 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:16  [ main:4980 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:16  [ main:4988 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:17  [ main:5034 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:17  [ main:5058 ] - [ INFO ]  Submitting tokens for job: job_local863482358_0004
2020-11-19 10:18:17  [ main:5104 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:17  [ main:5104 ] - [ INFO ]  Running job: job_local863482358_0004
2020-11-19 10:18:17  [ Thread-108:5104 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:17  [ Thread-108:5104 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:17  [ Thread-108:5104 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:17  [ Thread-108:5115 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5115 ] - [ INFO ]  Starting task: attempt_local863482358_0004_m_000000_0
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5116 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5116 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5116 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5117 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5206 ] - [ INFO ]  
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5206 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5210 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  Task:attempt_local863482358_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  map
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  Task 'attempt_local863482358_0004_m_000000_0' done.
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  Finishing task: attempt_local863482358_0004_m_000000_0
2020-11-19 10:18:17  [ Thread-108:5218 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:17  [ Thread-108:5219 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:17  [ pool-15-thread-1:5219 ] - [ INFO ]  Starting task: attempt_local863482358_0004_r_000000_0
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7211e92
2020-11-19 10:18:17  [ pool-15-thread-1:5221 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:17  [ EventFetcher for fetching Map Completion Events:5221 ] - [ INFO ]  attempt_local863482358_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:17  [ localfetcher#4:5222 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local863482358_0004_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:17  [ localfetcher#4:5223 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local863482358_0004_m_000000_0
2020-11-19 10:18:17  [ localfetcher#4:5223 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:17  [ EventFetcher for fetching Map Completion Events:5223 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:17  [ pool-15-thread-1:5223 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:17  [ pool-15-thread-1:5223 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:17  [ pool-15-thread-1:5224 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:17  [ pool-15-thread-1:5224 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:17  [ pool-15-thread-1:5274 ] - [ INFO ]  Task:attempt_local863482358_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:17  [ pool-15-thread-1:5281 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:17  [ pool-15-thread-1:5281 ] - [ INFO ]  Task attempt_local863482358_0004_r_000000_0 is allowed to commit now
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  Saved output of task 'attempt_local863482358_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local863482358_0004_r_000000
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  Task 'attempt_local863482358_0004_r_000000_0' done.
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  Finishing task: attempt_local863482358_0004_r_000000_0
2020-11-19 10:18:17  [ Thread-108:5300 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:18  [ main:6108 ] - [ INFO ]  Job job_local863482358_0004 running in uber mode : false
2020-11-19 10:18:18  [ main:6108 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:18  [ main:6109 ] - [ INFO ]  Job job_local863482358_0004 completed successfully
2020-11-19 10:18:18  [ main:6111 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86118
		FILE: Number of bytes written=2360209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254712
		HDFS: Number of bytes written=3040
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1026555904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:18  [ main:6465 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:18  [ main:6476 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:18  [ main:6481 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:18  [ main:6487 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:18  [ main:6528 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:18  [ main:6548 ] - [ INFO ]  Submitting tokens for job: job_local62746438_0005
2020-11-19 10:18:18  [ main:6583 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:18  [ main:6583 ] - [ INFO ]  Running job: job_local62746438_0005
2020-11-19 10:18:18  [ Thread-138:6584 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:18  [ Thread-138:6584 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:18  [ Thread-138:6584 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:18  [ Thread-138:6591 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6591 ] - [ INFO ]  Starting task: attempt_local62746438_0005_m_000000_0
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6592 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6592 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6592 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6593 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6675 ] - [ INFO ]  
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6679 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6680 ] - [ INFO ]  Task:attempt_local62746438_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6686 ] - [ INFO ]  map
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6686 ] - [ INFO ]  Task 'attempt_local62746438_0005_m_000000_0' done.
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6686 ] - [ INFO ]  Finishing task: attempt_local62746438_0005_m_000000_0
2020-11-19 10:18:18  [ Thread-138:6686 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:18  [ Thread-138:6687 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:18  [ pool-18-thread-1:6687 ] - [ INFO ]  Starting task: attempt_local62746438_0005_r_000000_0
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@62b7934b
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:18  [ EventFetcher for fetching Map Completion Events:6689 ] - [ INFO ]  attempt_local62746438_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:18  [ localfetcher#5:6689 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local62746438_0005_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:18  [ localfetcher#5:6690 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local62746438_0005_m_000000_0
2020-11-19 10:18:18  [ localfetcher#5:6690 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:18  [ EventFetcher for fetching Map Completion Events:6690 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:18  [ pool-18-thread-1:6690 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:18  [ pool-18-thread-1:6690 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:18  [ pool-18-thread-1:6691 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:18  [ pool-18-thread-1:6691 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:18  [ pool-18-thread-1:6739 ] - [ INFO ]  Task:attempt_local62746438_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:18  [ pool-18-thread-1:6745 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:18  [ pool-18-thread-1:6745 ] - [ INFO ]  Task attempt_local62746438_0005_r_000000_0 is allowed to commit now
2020-11-19 10:18:18  [ pool-18-thread-1:6765 ] - [ INFO ]  Saved output of task 'attempt_local62746438_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local62746438_0005_r_000000
2020-11-19 10:18:18  [ pool-18-thread-1:6766 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:18  [ pool-18-thread-1:6766 ] - [ INFO ]  Task 'attempt_local62746438_0005_r_000000_0' done.
2020-11-19 10:18:18  [ pool-18-thread-1:6766 ] - [ INFO ]  Finishing task: attempt_local62746438_0005_r_000000_0
2020-11-19 10:18:18  [ Thread-138:6766 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:19  [ main:7584 ] - [ INFO ]  Job job_local62746438_0005 running in uber mode : false
2020-11-19 10:18:19  [ main:7585 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:19  [ main:7585 ] - [ INFO ]  Job job_local62746438_0005 completed successfully
2020-11-19 10:18:19  [ main:7587 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=87310
		FILE: Number of bytes written=2926032
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319118
		HDFS: Number of bytes written=4120
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=90
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1026555904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:19  [ main:7860 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:19  [ main:7871 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:19  [ main:7876 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:19  [ main:7883 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:19  [ main:7922 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:19  [ main:7939 ] - [ INFO ]  Submitting tokens for job: job_local1668807133_0006
2020-11-19 10:18:19  [ main:7978 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:19  [ main:7979 ] - [ INFO ]  Running job: job_local1668807133_0006
2020-11-19 10:18:19  [ Thread-168:7979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:19  [ Thread-168:7979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:19  [ Thread-168:7979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:19  [ Thread-168:7986 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8032 ] - [ INFO ]  Starting task: attempt_local1668807133_0006_m_000000_0
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8032 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8033 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8033 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8033 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8042 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8117 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8118 ] - [ INFO ]  Task:attempt_local1668807133_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8124 ] - [ INFO ]  map
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8124 ] - [ INFO ]  Task 'attempt_local1668807133_0006_m_000000_0' done.
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8124 ] - [ INFO ]  Finishing task: attempt_local1668807133_0006_m_000000_0
2020-11-19 10:18:20  [ Thread-168:8124 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:20  [ Thread-168:8124 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:20  [ pool-21-thread-1:8124 ] - [ INFO ]  Starting task: attempt_local1668807133_0006_r_000000_0
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35a693b9
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:20  [ EventFetcher for fetching Map Completion Events:8126 ] - [ INFO ]  attempt_local1668807133_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:20  [ localfetcher#6:8126 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local1668807133_0006_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:20  [ localfetcher#6:8127 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1668807133_0006_m_000000_0
2020-11-19 10:18:20  [ localfetcher#6:8127 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:20  [ EventFetcher for fetching Map Completion Events:8127 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:20  [ pool-21-thread-1:8127 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:20  [ pool-21-thread-1:8127 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:20  [ pool-21-thread-1:8128 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:20  [ pool-21-thread-1:8128 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:20  [ pool-21-thread-1:8128 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:20  [ pool-21-thread-1:8187 ] - [ INFO ]  Task:attempt_local1668807133_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:20  [ pool-21-thread-1:8193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:20  [ pool-21-thread-1:8193 ] - [ INFO ]  Task attempt_local1668807133_0006_r_000000_0 is allowed to commit now
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  Saved output of task 'attempt_local1668807133_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1668807133_0006_r_000000
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  Task 'attempt_local1668807133_0006_r_000000_0' done.
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  Finishing task: attempt_local1668807133_0006_r_000000_0
2020-11-19 10:18:20  [ Thread-168:8212 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:20  [ main:8981 ] - [ INFO ]  Job job_local1668807133_0006 running in uber mode : false
2020-11-19 10:18:20  [ main:8981 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:20  [ main:8981 ] - [ INFO ]  Job job_local1668807133_0006 completed successfully
2020-11-19 10:18:20  [ main:8983 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=88500
		FILE: Number of bytes written=3497950
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383524
		HDFS: Number of bytes written=5200
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=835715072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:21  [ main:9272 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:21  [ main:9283 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:21  [ main:9288 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:21  [ main:9294 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:21  [ main:9332 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:21  [ main:9349 ] - [ INFO ]  Submitting tokens for job: job_local120107098_0007
2020-11-19 10:18:21  [ main:9385 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:21  [ main:9385 ] - [ INFO ]  Running job: job_local120107098_0007
2020-11-19 10:18:21  [ Thread-198:9385 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:21  [ Thread-198:9385 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:21  [ Thread-198:9385 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:21  [ Thread-198:9392 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]  Starting task: attempt_local120107098_0007_m_000000_0
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9394 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9402 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9501 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9502 ] - [ INFO ]  Task:attempt_local120107098_0007_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9507 ] - [ INFO ]  map
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9507 ] - [ INFO ]  Task 'attempt_local120107098_0007_m_000000_0' done.
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9507 ] - [ INFO ]  Finishing task: attempt_local120107098_0007_m_000000_0
2020-11-19 10:18:21  [ Thread-198:9507 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:21  [ Thread-198:9508 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:21  [ pool-24-thread-1:9508 ] - [ INFO ]  Starting task: attempt_local120107098_0007_r_000000_0
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@670f98df
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:21  [ EventFetcher for fetching Map Completion Events:9510 ] - [ INFO ]  attempt_local120107098_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:21  [ localfetcher#7:9511 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local120107098_0007_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:21  [ localfetcher#7:9511 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local120107098_0007_m_000000_0
2020-11-19 10:18:21  [ localfetcher#7:9511 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:21  [ EventFetcher for fetching Map Completion Events:9511 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:21  [ pool-24-thread-1:9556 ] - [ INFO ]  Task:attempt_local120107098_0007_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:21  [ pool-24-thread-1:9562 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:21  [ pool-24-thread-1:9562 ] - [ INFO ]  Task attempt_local120107098_0007_r_000000_0 is allowed to commit now
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  Saved output of task 'attempt_local120107098_0007_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local120107098_0007_r_000000
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  Task 'attempt_local120107098_0007_r_000000_0' done.
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  Finishing task: attempt_local120107098_0007_r_000000_0
2020-11-19 10:18:21  [ Thread-198:9584 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:22  [ main:10390 ] - [ INFO ]  Job job_local120107098_0007 running in uber mode : false
2020-11-19 10:18:22  [ main:10390 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:22  [ main:10390 ] - [ INFO ]  Job job_local120107098_0007 completed successfully
2020-11-19 10:18:22  [ main:10392 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=89692
		FILE: Number of bytes written=4066823
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=447930
		HDFS: Number of bytes written=6280
		HDFS: Number of read operations=401
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=134
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=836763648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:22  [ main:10664 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:22  [ main:10674 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:22  [ main:10679 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:22  [ main:10686 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:22  [ main:10726 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:22  [ main:10744 ] - [ INFO ]  Submitting tokens for job: job_local2010153951_0008
2020-11-19 10:18:22  [ main:10780 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:22  [ main:10780 ] - [ INFO ]  Running job: job_local2010153951_0008
2020-11-19 10:18:22  [ Thread-228:10780 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:22  [ Thread-228:10780 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:22  [ Thread-228:10780 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:22  [ Thread-228:10789 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10789 ] - [ INFO ]  Starting task: attempt_local2010153951_0008_m_000000_0
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10862 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10863 ] - [ INFO ]  Task:attempt_local2010153951_0008_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10870 ] - [ INFO ]  map
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10872 ] - [ INFO ]  Task 'attempt_local2010153951_0008_m_000000_0' done.
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10872 ] - [ INFO ]  Finishing task: attempt_local2010153951_0008_m_000000_0
2020-11-19 10:18:22  [ Thread-228:10872 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:22  [ Thread-228:10873 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:22  [ pool-27-thread-1:10873 ] - [ INFO ]  Starting task: attempt_local2010153951_0008_r_000000_0
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@302e1cd6
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:22  [ EventFetcher for fetching Map Completion Events:10875 ] - [ INFO ]  attempt_local2010153951_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:22  [ localfetcher#8:10876 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local2010153951_0008_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:22  [ localfetcher#8:10876 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2010153951_0008_m_000000_0
2020-11-19 10:18:22  [ localfetcher#8:10876 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:22  [ EventFetcher for fetching Map Completion Events:10877 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:22  [ pool-27-thread-1:10877 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:22  [ pool-27-thread-1:10877 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:22  [ pool-27-thread-1:10879 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:22  [ pool-27-thread-1:10879 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:22  [ pool-27-thread-1:10879 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:22  [ pool-27-thread-1:10935 ] - [ INFO ]  Task:attempt_local2010153951_0008_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:22  [ pool-27-thread-1:10941 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:22  [ pool-27-thread-1:10941 ] - [ INFO ]  Task attempt_local2010153951_0008_r_000000_0 is allowed to commit now
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  Saved output of task 'attempt_local2010153951_0008_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2010153951_0008_r_000000
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  Task 'attempt_local2010153951_0008_r_000000_0' done.
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  Finishing task: attempt_local2010153951_0008_r_000000_0
2020-11-19 10:18:22  [ Thread-228:10958 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:23  [ main:11784 ] - [ INFO ]  Job job_local2010153951_0008 running in uber mode : false
2020-11-19 10:18:23  [ main:11785 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:23  [ main:11785 ] - [ INFO ]  Job job_local2010153951_0008 completed successfully
2020-11-19 10:18:23  [ main:11786 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=90884
		FILE: Number of bytes written=4638742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=512336
		HDFS: Number of bytes written=7360
		HDFS: Number of read operations=469
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=156
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1058013184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:24  [ main:12080 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:24  [ main:12091 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:24  [ main:12095 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:24  [ main:12102 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:24  [ main:12136 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:24  [ main:12153 ] - [ INFO ]  Submitting tokens for job: job_local1892191704_0009
2020-11-19 10:18:24  [ main:12193 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:24  [ main:12193 ] - [ INFO ]  Running job: job_local1892191704_0009
2020-11-19 10:18:24  [ Thread-258:12193 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:24  [ Thread-258:12194 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:24  [ Thread-258:12194 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:24  [ Thread-258:12202 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]  Starting task: attempt_local1892191704_0009_m_000000_0
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12203 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12214 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12287 ] - [ INFO ]  
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12290 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12291 ] - [ INFO ]  Task:attempt_local1892191704_0009_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12296 ] - [ INFO ]  map
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12296 ] - [ INFO ]  Task 'attempt_local1892191704_0009_m_000000_0' done.
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12297 ] - [ INFO ]  Finishing task: attempt_local1892191704_0009_m_000000_0
2020-11-19 10:18:24  [ Thread-258:12297 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:24  [ Thread-258:12297 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:24  [ pool-30-thread-1:12297 ] - [ INFO ]  Starting task: attempt_local1892191704_0009_r_000000_0
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f0f48ae
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:24  [ EventFetcher for fetching Map Completion Events:12299 ] - [ INFO ]  attempt_local1892191704_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:24  [ localfetcher#9:12299 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local1892191704_0009_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:24  [ localfetcher#9:12299 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1892191704_0009_m_000000_0
2020-11-19 10:18:24  [ localfetcher#9:12300 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:24  [ EventFetcher for fetching Map Completion Events:12300 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:24  [ pool-30-thread-1:12300 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:24  [ pool-30-thread-1:12300 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:24  [ pool-30-thread-1:12301 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:24  [ pool-30-thread-1:12301 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:24  [ pool-30-thread-1:12345 ] - [ INFO ]  Task:attempt_local1892191704_0009_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:24  [ pool-30-thread-1:12351 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:24  [ pool-30-thread-1:12351 ] - [ INFO ]  Task attempt_local1892191704_0009_r_000000_0 is allowed to commit now
2020-11-19 10:18:24  [ pool-30-thread-1:12367 ] - [ INFO ]  Saved output of task 'attempt_local1892191704_0009_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1892191704_0009_r_000000
2020-11-19 10:18:24  [ pool-30-thread-1:12368 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:24  [ pool-30-thread-1:12368 ] - [ INFO ]  Task 'attempt_local1892191704_0009_r_000000_0' done.
2020-11-19 10:18:24  [ pool-30-thread-1:12368 ] - [ INFO ]  Finishing task: attempt_local1892191704_0009_r_000000_0
2020-11-19 10:18:24  [ Thread-258:12368 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:25  [ main:13194 ] - [ INFO ]  Job job_local1892191704_0009 running in uber mode : false
2020-11-19 10:18:25  [ main:13195 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:25  [ main:13195 ] - [ INFO ]  Job job_local1892191704_0009 completed successfully
2020-11-19 10:18:25  [ main:13196 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=92074
		FILE: Number of bytes written=5210660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=576742
		HDFS: Number of bytes written=8440
		HDFS: Number of read operations=537
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=178
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1068498944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:25  [ main:13479 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:25  [ main:13489 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:25  [ main:13494 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:25  [ main:13500 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:25  [ main:13538 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:25  [ main:13555 ] - [ INFO ]  Submitting tokens for job: job_local1486998289_0010
2020-11-19 10:18:25  [ main:13592 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:25  [ main:13592 ] - [ INFO ]  Running job: job_local1486998289_0010
2020-11-19 10:18:25  [ Thread-288:13592 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:25  [ Thread-288:13593 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:25  [ Thread-288:13593 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:25  [ Thread-288:13600 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]  Starting task: attempt_local1486998289_0010_m_000000_0
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13601 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13673 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13674 ] - [ INFO ]  Task:attempt_local1486998289_0010_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13680 ] - [ INFO ]  map
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13680 ] - [ INFO ]  Task 'attempt_local1486998289_0010_m_000000_0' done.
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13680 ] - [ INFO ]  Finishing task: attempt_local1486998289_0010_m_000000_0
2020-11-19 10:18:25  [ Thread-288:13680 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:25  [ Thread-288:13681 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:25  [ pool-33-thread-1:13681 ] - [ INFO ]  Starting task: attempt_local1486998289_0010_r_000000_0
2020-11-19 10:18:25  [ pool-33-thread-1:13681 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a9ff27d
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:25  [ EventFetcher for fetching Map Completion Events:13682 ] - [ INFO ]  attempt_local1486998289_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:25  [ localfetcher#10:13683 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1486998289_0010_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:25  [ localfetcher#10:13683 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1486998289_0010_m_000000_0
2020-11-19 10:18:25  [ localfetcher#10:13683 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:25  [ EventFetcher for fetching Map Completion Events:13684 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:25  [ pool-33-thread-1:13684 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:25  [ pool-33-thread-1:13684 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:25  [ pool-33-thread-1:13686 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:25  [ pool-33-thread-1:13686 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:25  [ pool-33-thread-1:13686 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:25  [ pool-33-thread-1:13740 ] - [ INFO ]  Task:attempt_local1486998289_0010_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:25  [ pool-33-thread-1:13745 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:25  [ pool-33-thread-1:13745 ] - [ INFO ]  Task attempt_local1486998289_0010_r_000000_0 is allowed to commit now
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  Saved output of task 'attempt_local1486998289_0010_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1486998289_0010_r_000000
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  Task 'attempt_local1486998289_0010_r_000000_0' done.
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  Finishing task: attempt_local1486998289_0010_r_000000_0
2020-11-19 10:18:25  [ Thread-288:13762 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:26  [ main:14594 ] - [ INFO ]  Job job_local1486998289_0010 running in uber mode : false
2020-11-19 10:18:26  [ main:14595 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:26  [ main:14595 ] - [ INFO ]  Job job_local1486998289_0010 completed successfully
2020-11-19 10:18:26  [ main:14596 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=93266
		FILE: Number of bytes written=5782581
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=641148
		HDFS: Number of bytes written=9520
		HDFS: Number of read operations=605
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=200
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1269825536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:26  [ main:14866 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:26  [ main:14876 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:26  [ main:14881 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:26  [ main:14887 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:26  [ main:14928 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:26  [ main:14945 ] - [ INFO ]  Submitting tokens for job: job_local1132607359_0011
2020-11-19 10:18:26  [ main:14978 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:26  [ main:14978 ] - [ INFO ]  Running job: job_local1132607359_0011
2020-11-19 10:18:26  [ Thread-318:14979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:26  [ Thread-318:14979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:26  [ Thread-318:14979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:26  [ Thread-318:14986 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  Starting task: attempt_local1132607359_0011_m_000000_0
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15092 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15093 ] - [ INFO ]  Task:attempt_local1132607359_0011_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15099 ] - [ INFO ]  map
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15099 ] - [ INFO ]  Task 'attempt_local1132607359_0011_m_000000_0' done.
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15099 ] - [ INFO ]  Finishing task: attempt_local1132607359_0011_m_000000_0
2020-11-19 10:18:27  [ Thread-318:15099 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:27  [ Thread-318:15100 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:27  [ pool-36-thread-1:15100 ] - [ INFO ]  Starting task: attempt_local1132607359_0011_r_000000_0
2020-11-19 10:18:27  [ pool-36-thread-1:15100 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1bffb309
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:27  [ EventFetcher for fetching Map Completion Events:15101 ] - [ INFO ]  attempt_local1132607359_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:27  [ localfetcher#11:15102 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local1132607359_0011_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:27  [ localfetcher#11:15102 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1132607359_0011_m_000000_0
2020-11-19 10:18:27  [ localfetcher#11:15102 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:27  [ EventFetcher for fetching Map Completion Events:15103 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:27  [ pool-36-thread-1:15103 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:27  [ pool-36-thread-1:15103 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:27  [ pool-36-thread-1:15105 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:27  [ pool-36-thread-1:15148 ] - [ INFO ]  Task:attempt_local1132607359_0011_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:27  [ pool-36-thread-1:15153 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:27  [ pool-36-thread-1:15153 ] - [ INFO ]  Task attempt_local1132607359_0011_r_000000_0 is allowed to commit now
2020-11-19 10:18:27  [ pool-36-thread-1:15170 ] - [ INFO ]  Saved output of task 'attempt_local1132607359_0011_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1132607359_0011_r_000000
2020-11-19 10:18:27  [ pool-36-thread-1:15171 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:27  [ pool-36-thread-1:15171 ] - [ INFO ]  Task 'attempt_local1132607359_0011_r_000000_0' done.
2020-11-19 10:18:27  [ pool-36-thread-1:15171 ] - [ INFO ]  Finishing task: attempt_local1132607359_0011_r_000000_0
2020-11-19 10:18:27  [ Thread-318:15171 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:27  [ main:15982 ] - [ INFO ]  Job job_local1132607359_0011 running in uber mode : false
2020-11-19 10:18:27  [ main:15983 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:27  [ main:15983 ] - [ INFO ]  Job job_local1132607359_0011 completed successfully
2020-11-19 10:18:27  [ main:15984 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=94458
		FILE: Number of bytes written=6354500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=705554
		HDFS: Number of bytes written=10600
		HDFS: Number of read operations=673
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=222
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1269825536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:28  [ main:16256 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:28  [ main:16266 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:28  [ main:16271 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:28  [ main:16277 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:28  [ main:16312 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:28  [ main:16331 ] - [ INFO ]  Submitting tokens for job: job_local448977998_0012
2020-11-19 10:18:28  [ main:16371 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:28  [ main:16371 ] - [ INFO ]  Running job: job_local448977998_0012
2020-11-19 10:18:28  [ Thread-348:16371 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:28  [ Thread-348:16371 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:28  [ Thread-348:16371 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:28  [ Thread-348:16379 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]  Starting task: attempt_local448977998_0012_m_000000_0
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16380 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16462 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16463 ] - [ INFO ]  Task:attempt_local448977998_0012_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16470 ] - [ INFO ]  map
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16470 ] - [ INFO ]  Task 'attempt_local448977998_0012_m_000000_0' done.
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16471 ] - [ INFO ]  Finishing task: attempt_local448977998_0012_m_000000_0
2020-11-19 10:18:28  [ Thread-348:16471 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:28  [ Thread-348:16471 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:28  [ pool-39-thread-1:16471 ] - [ INFO ]  Starting task: attempt_local448977998_0012_r_000000_0
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74015e73
2020-11-19 10:18:28  [ pool-39-thread-1:16473 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:28  [ EventFetcher for fetching Map Completion Events:16473 ] - [ INFO ]  attempt_local448977998_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:28  [ localfetcher#12:16474 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local448977998_0012_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:28  [ localfetcher#12:16474 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local448977998_0012_m_000000_0
2020-11-19 10:18:28  [ localfetcher#12:16474 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:28  [ EventFetcher for fetching Map Completion Events:16475 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:28  [ pool-39-thread-1:16475 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:28  [ pool-39-thread-1:16475 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:28  [ pool-39-thread-1:16476 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:28  [ pool-39-thread-1:16476 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:28  [ pool-39-thread-1:16531 ] - [ INFO ]  Task:attempt_local448977998_0012_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:28  [ pool-39-thread-1:16536 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:28  [ pool-39-thread-1:16536 ] - [ INFO ]  Task attempt_local448977998_0012_r_000000_0 is allowed to commit now
2020-11-19 10:18:28  [ pool-39-thread-1:16552 ] - [ INFO ]  Saved output of task 'attempt_local448977998_0012_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local448977998_0012_r_000000
2020-11-19 10:18:28  [ pool-39-thread-1:16553 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:28  [ pool-39-thread-1:16553 ] - [ INFO ]  Task 'attempt_local448977998_0012_r_000000_0' done.
2020-11-19 10:18:28  [ pool-39-thread-1:16553 ] - [ INFO ]  Finishing task: attempt_local448977998_0012_r_000000_0
2020-11-19 10:18:28  [ Thread-348:16553 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:29  [ main:17375 ] - [ INFO ]  Job job_local448977998_0012 running in uber mode : false
2020-11-19 10:18:29  [ main:17375 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:29  [ main:17375 ] - [ INFO ]  Job job_local448977998_0012 completed successfully
2020-11-19 10:18:29  [ main:17376 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=95648
		FILE: Number of bytes written=6923374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=769960
		HDFS: Number of bytes written=11680
		HDFS: Number of read operations=741
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=244
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1286602752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:29  [ main:17661 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:29  [ main:17673 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:29  [ main:17678 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:29  [ main:17684 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:29  [ main:17721 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:29  [ main:17738 ] - [ INFO ]  Submitting tokens for job: job_local1152972653_0013
2020-11-19 10:18:29  [ main:17778 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:29  [ main:17778 ] - [ INFO ]  Running job: job_local1152972653_0013
2020-11-19 10:18:29  [ Thread-378:17778 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:29  [ Thread-378:17778 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:29  [ Thread-378:17779 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:29  [ Thread-378:17787 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]  Starting task: attempt_local1152972653_0013_m_000000_0
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17788 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17874 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17875 ] - [ INFO ]  Task:attempt_local1152972653_0013_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17881 ] - [ INFO ]  map
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17881 ] - [ INFO ]  Task 'attempt_local1152972653_0013_m_000000_0' done.
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17881 ] - [ INFO ]  Finishing task: attempt_local1152972653_0013_m_000000_0
2020-11-19 10:18:29  [ Thread-378:17881 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:29  [ Thread-378:17882 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  Starting task: attempt_local1152972653_0013_r_000000_0
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27eb4427
2020-11-19 10:18:29  [ pool-42-thread-1:17883 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:29  [ EventFetcher for fetching Map Completion Events:17883 ] - [ INFO ]  attempt_local1152972653_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:29  [ localfetcher#13:17884 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local1152972653_0013_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:29  [ localfetcher#13:17884 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1152972653_0013_m_000000_0
2020-11-19 10:18:29  [ localfetcher#13:17884 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:29  [ EventFetcher for fetching Map Completion Events:17884 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:29  [ pool-42-thread-1:17884 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:29  [ pool-42-thread-1:17884 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:29  [ pool-42-thread-1:17886 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:29  [ pool-42-thread-1:17886 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:29  [ pool-42-thread-1:17942 ] - [ INFO ]  Task:attempt_local1152972653_0013_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:29  [ pool-42-thread-1:17948 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:29  [ pool-42-thread-1:17948 ] - [ INFO ]  Task attempt_local1152972653_0013_r_000000_0 is allowed to commit now
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  Saved output of task 'attempt_local1152972653_0013_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1152972653_0013_r_000000
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  Task 'attempt_local1152972653_0013_r_000000_0' done.
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  Finishing task: attempt_local1152972653_0013_r_000000_0
2020-11-19 10:18:29  [ Thread-378:17967 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:30  [ main:18779 ] - [ INFO ]  Job job_local1152972653_0013 running in uber mode : false
2020-11-19 10:18:30  [ main:18779 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:30  [ main:18779 ] - [ INFO ]  Job job_local1152972653_0013 completed successfully
2020-11-19 10:18:30  [ main:18780 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=96840
		FILE: Number of bytes written=7495299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=834366
		HDFS: Number of bytes written=12760
		HDFS: Number of read operations=809
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=266
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1286602752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:31  [ main:19064 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:31  [ main:19073 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:31  [ main:19078 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:31  [ main:19082 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:31  [ main:19118 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:31  [ main:19138 ] - [ INFO ]  Submitting tokens for job: job_local691028471_0014
2020-11-19 10:18:31  [ main:19178 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:31  [ main:19178 ] - [ INFO ]  Running job: job_local691028471_0014
2020-11-19 10:18:31  [ Thread-408:19178 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:31  [ Thread-408:19178 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:31  [ Thread-408:19178 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:31  [ Thread-408:19185 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19185 ] - [ INFO ]  Starting task: attempt_local691028471_0014_m_000000_0
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19272 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19273 ] - [ INFO ]  Task:attempt_local691028471_0014_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19278 ] - [ INFO ]  map
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19278 ] - [ INFO ]  Task 'attempt_local691028471_0014_m_000000_0' done.
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19278 ] - [ INFO ]  Finishing task: attempt_local691028471_0014_m_000000_0
2020-11-19 10:18:31  [ Thread-408:19278 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:31  [ Thread-408:19279 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:31  [ pool-45-thread-1:19279 ] - [ INFO ]  Starting task: attempt_local691028471_0014_r_000000_0
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2efed196
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:31  [ EventFetcher for fetching Map Completion Events:19280 ] - [ INFO ]  attempt_local691028471_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:31  [ localfetcher#14:19281 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local691028471_0014_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:31  [ localfetcher#14:19281 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local691028471_0014_m_000000_0
2020-11-19 10:18:31  [ localfetcher#14:19281 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:31  [ EventFetcher for fetching Map Completion Events:19282 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:31  [ pool-45-thread-1:19282 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:31  [ pool-45-thread-1:19282 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:31  [ pool-45-thread-1:19284 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:31  [ pool-45-thread-1:19325 ] - [ INFO ]  Task:attempt_local691028471_0014_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:31  [ pool-45-thread-1:19331 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:31  [ pool-45-thread-1:19331 ] - [ INFO ]  Task attempt_local691028471_0014_r_000000_0 is allowed to commit now
2020-11-19 10:18:31  [ pool-45-thread-1:19348 ] - [ INFO ]  Saved output of task 'attempt_local691028471_0014_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local691028471_0014_r_000000
2020-11-19 10:18:31  [ pool-45-thread-1:19349 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:31  [ pool-45-thread-1:19349 ] - [ INFO ]  Task 'attempt_local691028471_0014_r_000000_0' done.
2020-11-19 10:18:31  [ pool-45-thread-1:19349 ] - [ INFO ]  Finishing task: attempt_local691028471_0014_r_000000_0
2020-11-19 10:18:31  [ Thread-408:19349 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:32  [ main:20178 ] - [ INFO ]  Job job_local691028471_0014 running in uber mode : false
2020-11-19 10:18:32  [ main:20178 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:32  [ main:20179 ] - [ INFO ]  Job job_local691028471_0014 completed successfully
2020-11-19 10:18:32  [ main:20180 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=98032
		FILE: Number of bytes written=8064174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=898772
		HDFS: Number of bytes written=13840
		HDFS: Number of read operations=877
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=288
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1519386624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:32  [ main:20463 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:32  [ main:20473 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:32  [ main:20477 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:32  [ main:20485 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:32  [ main:20522 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:32  [ main:20540 ] - [ INFO ]  Submitting tokens for job: job_local935923951_0015
2020-11-19 10:18:32  [ main:20574 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:32  [ main:20574 ] - [ INFO ]  Running job: job_local935923951_0015
2020-11-19 10:18:32  [ Thread-438:20574 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:32  [ Thread-438:20575 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:32  [ Thread-438:20575 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:32  [ Thread-438:20582 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20582 ] - [ INFO ]  Starting task: attempt_local935923951_0015_m_000000_0
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20658 ] - [ INFO ]  
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20661 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20662 ] - [ INFO ]  Task:attempt_local935923951_0015_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20670 ] - [ INFO ]  map
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20670 ] - [ INFO ]  Task 'attempt_local935923951_0015_m_000000_0' done.
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20670 ] - [ INFO ]  Finishing task: attempt_local935923951_0015_m_000000_0
2020-11-19 10:18:32  [ Thread-438:20670 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:32  [ Thread-438:20670 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:32  [ pool-48-thread-1:20670 ] - [ INFO ]  Starting task: attempt_local935923951_0015_r_000000_0
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@246c289e
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:32  [ EventFetcher for fetching Map Completion Events:20671 ] - [ INFO ]  attempt_local935923951_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:32  [ localfetcher#15:20672 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local935923951_0015_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:32  [ localfetcher#15:20672 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local935923951_0015_m_000000_0
2020-11-19 10:18:32  [ localfetcher#15:20672 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:32  [ EventFetcher for fetching Map Completion Events:20673 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:32  [ pool-48-thread-1:20673 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:32  [ pool-48-thread-1:20673 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:32  [ pool-48-thread-1:20721 ] - [ INFO ]  Task:attempt_local935923951_0015_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:32  [ pool-48-thread-1:20727 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:32  [ pool-48-thread-1:20727 ] - [ INFO ]  Task attempt_local935923951_0015_r_000000_0 is allowed to commit now
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  Saved output of task 'attempt_local935923951_0015_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local935923951_0015_r_000000
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  Task 'attempt_local935923951_0015_r_000000_0' done.
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  Finishing task: attempt_local935923951_0015_r_000000_0
2020-11-19 10:18:32  [ Thread-438:20743 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:33  [ main:21575 ] - [ INFO ]  Job job_local935923951_0015 running in uber mode : false
2020-11-19 10:18:33  [ main:21575 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:33  [ main:21576 ] - [ INFO ]  Job job_local935923951_0015 completed successfully
2020-11-19 10:18:33  [ main:21577 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=99222
		FILE: Number of bytes written=8633048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=963178
		HDFS: Number of bytes written=14920
		HDFS: Number of read operations=945
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=310
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1519386624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:33  [ main:21865 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:33  [ main:21877 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:33  [ main:21882 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:33  [ main:21888 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:33  [ main:21927 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:33  [ main:21945 ] - [ INFO ]  Submitting tokens for job: job_local510652144_0016
2020-11-19 10:18:33  [ main:21979 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:33  [ main:21979 ] - [ INFO ]  Running job: job_local510652144_0016
2020-11-19 10:18:33  [ Thread-468:21979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:33  [ Thread-468:21979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:33  [ Thread-468:21979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:33  [ Thread-468:21987 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21987 ] - [ INFO ]  Starting task: attempt_local510652144_0016_m_000000_0
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21988 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21988 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21988 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21989 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22097 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22098 ] - [ INFO ]  Task:attempt_local510652144_0016_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22104 ] - [ INFO ]  map
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22104 ] - [ INFO ]  Task 'attempt_local510652144_0016_m_000000_0' done.
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22104 ] - [ INFO ]  Finishing task: attempt_local510652144_0016_m_000000_0
2020-11-19 10:18:34  [ Thread-468:22104 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:34  [ Thread-468:22104 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:34  [ pool-51-thread-1:22104 ] - [ INFO ]  Starting task: attempt_local510652144_0016_r_000000_0
2020-11-19 10:18:34  [ pool-51-thread-1:22105 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:34  [ pool-51-thread-1:22105 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:34  [ pool-51-thread-1:22105 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:34  [ pool-51-thread-1:22106 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7064db35
2020-11-19 10:18:34  [ pool-51-thread-1:22106 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:34  [ EventFetcher for fetching Map Completion Events:22106 ] - [ INFO ]  attempt_local510652144_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:34  [ localfetcher#16:22107 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local510652144_0016_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:34  [ localfetcher#16:22107 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local510652144_0016_m_000000_0
2020-11-19 10:18:34  [ localfetcher#16:22107 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:34  [ EventFetcher for fetching Map Completion Events:22107 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:34  [ pool-51-thread-1:22154 ] - [ INFO ]  Task:attempt_local510652144_0016_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:34  [ pool-51-thread-1:22160 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:34  [ pool-51-thread-1:22160 ] - [ INFO ]  Task attempt_local510652144_0016_r_000000_0 is allowed to commit now
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  Saved output of task 'attempt_local510652144_0016_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local510652144_0016_r_000000
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  Task 'attempt_local510652144_0016_r_000000_0' done.
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  Finishing task: attempt_local510652144_0016_r_000000_0
2020-11-19 10:18:34  [ Thread-468:22178 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:34  [ main:22984 ] - [ INFO ]  Job job_local510652144_0016 running in uber mode : false
2020-11-19 10:18:34  [ main:22984 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:34  [ main:22984 ] - [ INFO ]  Job job_local510652144_0016 completed successfully
2020-11-19 10:18:34  [ main:22985 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=100414
		FILE: Number of bytes written=9201925
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1027584
		HDFS: Number of bytes written=16000
		HDFS: Number of read operations=1013
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=332
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1519386624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:35  [ main:23264 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:35  [ main:23275 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:35  [ main:23279 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:35  [ main:23284 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:35  [ main:23320 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:35  [ main:23337 ] - [ INFO ]  Submitting tokens for job: job_local1479460518_0017
2020-11-19 10:18:35  [ main:23373 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:35  [ main:23373 ] - [ INFO ]  Running job: job_local1479460518_0017
2020-11-19 10:18:35  [ Thread-498:23373 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:35  [ Thread-498:23373 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:35  [ Thread-498:23373 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:35  [ Thread-498:23382 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]  Starting task: attempt_local1479460518_0017_m_000000_0
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23383 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23457 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23458 ] - [ INFO ]  Task:attempt_local1479460518_0017_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23468 ] - [ INFO ]  map
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23469 ] - [ INFO ]  Task 'attempt_local1479460518_0017_m_000000_0' done.
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23469 ] - [ INFO ]  Finishing task: attempt_local1479460518_0017_m_000000_0
2020-11-19 10:18:35  [ Thread-498:23469 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:35  [ Thread-498:23469 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:35  [ pool-54-thread-1:23469 ] - [ INFO ]  Starting task: attempt_local1479460518_0017_r_000000_0
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27bdc7bf
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:35  [ EventFetcher for fetching Map Completion Events:23470 ] - [ INFO ]  attempt_local1479460518_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:35  [ localfetcher#17:23471 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local1479460518_0017_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:35  [ localfetcher#17:23471 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1479460518_0017_m_000000_0
2020-11-19 10:18:35  [ localfetcher#17:23471 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:35  [ EventFetcher for fetching Map Completion Events:23471 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:35  [ pool-54-thread-1:23471 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:35  [ pool-54-thread-1:23472 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:35  [ pool-54-thread-1:23472 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:35  [ pool-54-thread-1:23472 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:35  [ pool-54-thread-1:23527 ] - [ INFO ]  Task:attempt_local1479460518_0017_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:35  [ pool-54-thread-1:23532 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:35  [ pool-54-thread-1:23532 ] - [ INFO ]  Task attempt_local1479460518_0017_r_000000_0 is allowed to commit now
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  Saved output of task 'attempt_local1479460518_0017_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1479460518_0017_r_000000
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  Task 'attempt_local1479460518_0017_r_000000_0' done.
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  Finishing task: attempt_local1479460518_0017_r_000000_0
2020-11-19 10:18:35  [ Thread-498:23551 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:36  [ main:24375 ] - [ INFO ]  Job job_local1479460518_0017 running in uber mode : false
2020-11-19 10:18:36  [ main:24375 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:36  [ main:24375 ] - [ INFO ]  Job job_local1479460518_0017 completed successfully
2020-11-19 10:18:36  [ main:24376 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=101606
		FILE: Number of bytes written=9773848
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1091990
		HDFS: Number of bytes written=17080
		HDFS: Number of read operations=1081
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=354
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1548746752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:36  [ main:24661 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:36  [ main:24672 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:36  [ main:24677 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:36  [ main:24685 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:36  [ main:24724 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:36  [ main:24741 ] - [ INFO ]  Submitting tokens for job: job_local851378642_0018
2020-11-19 10:18:36  [ main:24773 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:36  [ main:24773 ] - [ INFO ]  Running job: job_local851378642_0018
2020-11-19 10:18:36  [ Thread-528:24773 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:36  [ Thread-528:24773 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:36  [ Thread-528:24773 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:36  [ Thread-528:24781 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24781 ] - [ INFO ]  Starting task: attempt_local851378642_0018_m_000000_0
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24863 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24864 ] - [ INFO ]  Task:attempt_local851378642_0018_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24870 ] - [ INFO ]  map
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24870 ] - [ INFO ]  Task 'attempt_local851378642_0018_m_000000_0' done.
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24870 ] - [ INFO ]  Finishing task: attempt_local851378642_0018_m_000000_0
2020-11-19 10:18:36  [ Thread-528:24870 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:36  [ Thread-528:24871 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]  Starting task: attempt_local851378642_0018_r_000000_0
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:36  [ pool-57-thread-1:24872 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d5c2b79
2020-11-19 10:18:36  [ pool-57-thread-1:24872 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:36  [ EventFetcher for fetching Map Completion Events:24872 ] - [ INFO ]  attempt_local851378642_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:36  [ localfetcher#18:24873 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local851378642_0018_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:36  [ localfetcher#18:24873 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local851378642_0018_m_000000_0
2020-11-19 10:18:36  [ localfetcher#18:24873 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:36  [ EventFetcher for fetching Map Completion Events:24873 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:36  [ pool-57-thread-1:24874 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:36  [ pool-57-thread-1:24874 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:36  [ pool-57-thread-1:24920 ] - [ INFO ]  Task:attempt_local851378642_0018_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:36  [ pool-57-thread-1:24925 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:36  [ pool-57-thread-1:24925 ] - [ INFO ]  Task attempt_local851378642_0018_r_000000_0 is allowed to commit now
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  Saved output of task 'attempt_local851378642_0018_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local851378642_0018_r_000000
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  Task 'attempt_local851378642_0018_r_000000_0' done.
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  Finishing task: attempt_local851378642_0018_r_000000_0
2020-11-19 10:18:36  [ Thread-528:24943 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:37  [ main:25777 ] - [ INFO ]  Job job_local851378642_0018 running in uber mode : false
2020-11-19 10:18:37  [ main:25777 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:37  [ main:25778 ] - [ INFO ]  Job job_local851378642_0018 completed successfully
2020-11-19 10:18:37  [ main:25778 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=102796
		FILE: Number of bytes written=10342722
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1156396
		HDFS: Number of bytes written=18160
		HDFS: Number of read operations=1149
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=376
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1548746752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:38  [ main:26043 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:38  [ main:26053 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:38  [ main:26058 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:38  [ main:26063 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:38  [ main:26099 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:38  [ main:26116 ] - [ INFO ]  Submitting tokens for job: job_local904095313_0019
2020-11-19 10:18:38  [ main:26152 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:38  [ main:26152 ] - [ INFO ]  Running job: job_local904095313_0019
2020-11-19 10:18:38  [ Thread-558:26152 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:38  [ Thread-558:26153 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:38  [ Thread-558:26153 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:38  [ Thread-558:26160 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26160 ] - [ INFO ]  Starting task: attempt_local904095313_0019_m_000000_0
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26176 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26248 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26249 ] - [ INFO ]  Task:attempt_local904095313_0019_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26256 ] - [ INFO ]  map
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26256 ] - [ INFO ]  Task 'attempt_local904095313_0019_m_000000_0' done.
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26256 ] - [ INFO ]  Finishing task: attempt_local904095313_0019_m_000000_0
2020-11-19 10:18:38  [ Thread-558:26256 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:38  [ Thread-558:26256 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:38  [ pool-60-thread-1:26256 ] - [ INFO ]  Starting task: attempt_local904095313_0019_r_000000_0
2020-11-19 10:18:38  [ pool-60-thread-1:26256 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fab5ad9
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:38  [ EventFetcher for fetching Map Completion Events:26257 ] - [ INFO ]  attempt_local904095313_0019_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:38  [ localfetcher#19:26258 ] - [ INFO ]  localfetcher#19 about to shuffle output of map attempt_local904095313_0019_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:38  [ localfetcher#19:26258 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local904095313_0019_m_000000_0
2020-11-19 10:18:38  [ localfetcher#19:26258 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:38  [ EventFetcher for fetching Map Completion Events:26258 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:38  [ pool-60-thread-1:26258 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:38  [ pool-60-thread-1:26258 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:38  [ pool-60-thread-1:26260 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:38  [ pool-60-thread-1:26260 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:38  [ pool-60-thread-1:26301 ] - [ INFO ]  Task:attempt_local904095313_0019_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:38  [ pool-60-thread-1:26306 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:38  [ pool-60-thread-1:26306 ] - [ INFO ]  Task attempt_local904095313_0019_r_000000_0 is allowed to commit now
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  Saved output of task 'attempt_local904095313_0019_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local904095313_0019_r_000000
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  Task 'attempt_local904095313_0019_r_000000_0' done.
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  Finishing task: attempt_local904095313_0019_r_000000_0
2020-11-19 10:18:38  [ Thread-558:26324 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:39  [ main:27156 ] - [ INFO ]  Job job_local904095313_0019 running in uber mode : false
2020-11-19 10:18:39  [ main:27156 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:39  [ main:27156 ] - [ INFO ]  Job job_local904095313_0019 completed successfully
2020-11-19 10:18:39  [ main:27157 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=103988
		FILE: Number of bytes written=10911599
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1220802
		HDFS: Number of bytes written=19240
		HDFS: Number of read operations=1217
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=398
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1548746752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:39  [ main:27418 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:39  [ main:27428 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:39  [ main:27432 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:39  [ main:27437 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:39  [ main:27475 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:39  [ main:27494 ] - [ INFO ]  Submitting tokens for job: job_local1472890628_0020
2020-11-19 10:18:39  [ main:27532 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:39  [ main:27532 ] - [ INFO ]  Running job: job_local1472890628_0020
2020-11-19 10:18:39  [ Thread-588:27532 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:39  [ Thread-588:27532 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:39  [ Thread-588:27532 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:39  [ Thread-588:27539 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27539 ] - [ INFO ]  Starting task: attempt_local1472890628_0020_m_000000_0
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27615 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27616 ] - [ INFO ]  Task:attempt_local1472890628_0020_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27621 ] - [ INFO ]  map
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27621 ] - [ INFO ]  Task 'attempt_local1472890628_0020_m_000000_0' done.
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27621 ] - [ INFO ]  Finishing task: attempt_local1472890628_0020_m_000000_0
2020-11-19 10:18:39  [ Thread-588:27622 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:39  [ Thread-588:27622 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:39  [ pool-63-thread-1:27622 ] - [ INFO ]  Starting task: attempt_local1472890628_0020_r_000000_0
2020-11-19 10:18:39  [ pool-63-thread-1:27622 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30809f99
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:39  [ EventFetcher for fetching Map Completion Events:27623 ] - [ INFO ]  attempt_local1472890628_0020_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:39  [ localfetcher#20:27624 ] - [ INFO ]  localfetcher#20 about to shuffle output of map attempt_local1472890628_0020_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:39  [ localfetcher#20:27624 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1472890628_0020_m_000000_0
2020-11-19 10:18:39  [ localfetcher#20:27624 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:39  [ EventFetcher for fetching Map Completion Events:27624 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:39  [ pool-63-thread-1:27624 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:39  [ pool-63-thread-1:27625 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:39  [ pool-63-thread-1:27625 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:39  [ pool-63-thread-1:27625 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:39  [ pool-63-thread-1:27667 ] - [ INFO ]  Task:attempt_local1472890628_0020_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:39  [ pool-63-thread-1:27674 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:39  [ pool-63-thread-1:27674 ] - [ INFO ]  Task attempt_local1472890628_0020_r_000000_0 is allowed to commit now
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  Saved output of task 'attempt_local1472890628_0020_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1472890628_0020_r_000000
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  Task 'attempt_local1472890628_0020_r_000000_0' done.
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  Finishing task: attempt_local1472890628_0020_r_000000_0
2020-11-19 10:18:39  [ Thread-588:27690 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:40  [ main:28534 ] - [ INFO ]  Job job_local1472890628_0020 running in uber mode : false
2020-11-19 10:18:40  [ main:28534 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:40  [ main:28534 ] - [ INFO ]  Job job_local1472890628_0020 completed successfully
2020-11-19 10:18:40  [ main:28535 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=105180
		FILE: Number of bytes written=11483522
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1285208
		HDFS: Number of bytes written=20320
		HDFS: Number of read operations=1285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=420
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1793064960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:40  [ main:28813 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:40  [ main:28825 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:40  [ main:28830 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:40  [ main:28835 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:40  [ main:28872 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:40  [ main:28889 ] - [ INFO ]  Submitting tokens for job: job_local938339314_0021
2020-11-19 10:18:40  [ main:28921 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:40  [ main:28921 ] - [ INFO ]  Running job: job_local938339314_0021
2020-11-19 10:18:40  [ Thread-618:28921 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:40  [ Thread-618:28921 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:40  [ Thread-618:28921 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:40  [ Thread-618:28928 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  Starting task: attempt_local938339314_0021_m_000000_0
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28996 ] - [ INFO ]  
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28998 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:28999 ] - [ INFO ]  Task:attempt_local938339314_0021_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:29005 ] - [ INFO ]  map
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:29006 ] - [ INFO ]  Task 'attempt_local938339314_0021_m_000000_0' done.
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:29006 ] - [ INFO ]  Finishing task: attempt_local938339314_0021_m_000000_0
2020-11-19 10:18:41  [ Thread-618:29006 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:41  [ Thread-618:29006 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:41  [ pool-66-thread-1:29006 ] - [ INFO ]  Starting task: attempt_local938339314_0021_r_000000_0
2020-11-19 10:18:41  [ pool-66-thread-1:29006 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c649262
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:41  [ EventFetcher for fetching Map Completion Events:29007 ] - [ INFO ]  attempt_local938339314_0021_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:41  [ localfetcher#21:29008 ] - [ INFO ]  localfetcher#21 about to shuffle output of map attempt_local938339314_0021_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:41  [ localfetcher#21:29008 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local938339314_0021_m_000000_0
2020-11-19 10:18:41  [ localfetcher#21:29008 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:41  [ EventFetcher for fetching Map Completion Events:29008 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:41  [ pool-66-thread-1:29008 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:41  [ pool-66-thread-1:29008 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:41  [ pool-66-thread-1:29010 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:41  [ pool-66-thread-1:29050 ] - [ INFO ]  Task:attempt_local938339314_0021_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:41  [ pool-66-thread-1:29055 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:41  [ pool-66-thread-1:29055 ] - [ INFO ]  Task attempt_local938339314_0021_r_000000_0 is allowed to commit now
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  Saved output of task 'attempt_local938339314_0021_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local938339314_0021_r_000000
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  Task 'attempt_local938339314_0021_r_000000_0' done.
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  Finishing task: attempt_local938339314_0021_r_000000_0
2020-11-19 10:18:41  [ Thread-618:29071 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:41  [ main:29922 ] - [ INFO ]  Job job_local938339314_0021 running in uber mode : false
2020-11-19 10:18:41  [ main:29922 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:41  [ main:29922 ] - [ INFO ]  Job job_local938339314_0021 completed successfully
2020-11-19 10:18:41  [ main:29923 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=106370
		FILE: Number of bytes written=12052396
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1349614
		HDFS: Number of bytes written=21400
		HDFS: Number of read operations=1353
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=442
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1793064960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:42  [ main:30210 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:42  [ main:30221 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:42  [ main:30226 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:42  [ main:30231 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:42  [ main:30269 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:42  [ main:30286 ] - [ INFO ]  Submitting tokens for job: job_local752712392_0022
2020-11-19 10:18:42  [ main:30316 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:42  [ main:30316 ] - [ INFO ]  Running job: job_local752712392_0022
2020-11-19 10:18:42  [ Thread-648:30317 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:42  [ Thread-648:30317 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:42  [ Thread-648:30317 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:42  [ Thread-648:30325 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]  Starting task: attempt_local752712392_0022_m_000000_0
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30326 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30338 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30418 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30419 ] - [ INFO ]  Task:attempt_local752712392_0022_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30425 ] - [ INFO ]  map
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30425 ] - [ INFO ]  Task 'attempt_local752712392_0022_m_000000_0' done.
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30425 ] - [ INFO ]  Finishing task: attempt_local752712392_0022_m_000000_0
2020-11-19 10:18:42  [ Thread-648:30425 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:42  [ Thread-648:30425 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  Starting task: attempt_local752712392_0022_r_000000_0
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@dd7fb1a
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:42  [ EventFetcher for fetching Map Completion Events:30427 ] - [ INFO ]  attempt_local752712392_0022_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:42  [ localfetcher#22:30427 ] - [ INFO ]  localfetcher#22 about to shuffle output of map attempt_local752712392_0022_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:42  [ localfetcher#22:30428 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local752712392_0022_m_000000_0
2020-11-19 10:18:42  [ localfetcher#22:30428 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:42  [ EventFetcher for fetching Map Completion Events:30428 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:42  [ pool-69-thread-1:30428 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:42  [ pool-69-thread-1:30428 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:42  [ pool-69-thread-1:30429 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:42  [ pool-69-thread-1:30429 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:42  [ pool-69-thread-1:30475 ] - [ INFO ]  Task:attempt_local752712392_0022_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:42  [ pool-69-thread-1:30480 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:42  [ pool-69-thread-1:30480 ] - [ INFO ]  Task attempt_local752712392_0022_r_000000_0 is allowed to commit now
2020-11-19 10:18:42  [ pool-69-thread-1:30498 ] - [ INFO ]  Saved output of task 'attempt_local752712392_0022_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local752712392_0022_r_000000
2020-11-19 10:18:42  [ pool-69-thread-1:30499 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:42  [ pool-69-thread-1:30499 ] - [ INFO ]  Task 'attempt_local752712392_0022_r_000000_0' done.
2020-11-19 10:18:42  [ pool-69-thread-1:30499 ] - [ INFO ]  Finishing task: attempt_local752712392_0022_r_000000_0
2020-11-19 10:18:42  [ Thread-648:30499 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:43  [ main:31318 ] - [ INFO ]  Job job_local752712392_0022 running in uber mode : false
2020-11-19 10:18:43  [ main:31318 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:43  [ main:31318 ] - [ INFO ]  Job job_local752712392_0022 completed successfully
2020-11-19 10:18:43  [ main:31319 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=107562
		FILE: Number of bytes written=12621273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1414020
		HDFS: Number of bytes written=22480
		HDFS: Number of read operations=1421
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=464
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1793064960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:43  [ main:31604 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:43  [ main:31617 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:43  [ main:31622 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:43  [ main:31627 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:43  [ main:31662 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:43  [ main:31679 ] - [ INFO ]  Submitting tokens for job: job_local1095469340_0023
2020-11-19 10:18:43  [ main:31716 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:43  [ main:31716 ] - [ INFO ]  Running job: job_local1095469340_0023
2020-11-19 10:18:43  [ Thread-678:31717 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:43  [ Thread-678:31717 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:43  [ Thread-678:31717 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:43  [ Thread-678:31724 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]  Starting task: attempt_local1095469340_0023_m_000000_0
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31725 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31808 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31809 ] - [ INFO ]  Task:attempt_local1095469340_0023_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31815 ] - [ INFO ]  map
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31815 ] - [ INFO ]  Task 'attempt_local1095469340_0023_m_000000_0' done.
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31815 ] - [ INFO ]  Finishing task: attempt_local1095469340_0023_m_000000_0
2020-11-19 10:18:43  [ Thread-678:31815 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:43  [ Thread-678:31815 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:43  [ pool-72-thread-1:31815 ] - [ INFO ]  Starting task: attempt_local1095469340_0023_r_000000_0
2020-11-19 10:18:43  [ pool-72-thread-1:31815 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6025b510
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:43  [ EventFetcher for fetching Map Completion Events:31816 ] - [ INFO ]  attempt_local1095469340_0023_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:43  [ localfetcher#23:31817 ] - [ INFO ]  localfetcher#23 about to shuffle output of map attempt_local1095469340_0023_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:43  [ localfetcher#23:31817 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1095469340_0023_m_000000_0
2020-11-19 10:18:43  [ localfetcher#23:31817 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:43  [ EventFetcher for fetching Map Completion Events:31817 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:43  [ pool-72-thread-1:31860 ] - [ INFO ]  Task:attempt_local1095469340_0023_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:43  [ pool-72-thread-1:31866 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:43  [ pool-72-thread-1:31866 ] - [ INFO ]  Task attempt_local1095469340_0023_r_000000_0 is allowed to commit now
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  Saved output of task 'attempt_local1095469340_0023_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1095469340_0023_r_000000
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  Task 'attempt_local1095469340_0023_r_000000_0' done.
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  Finishing task: attempt_local1095469340_0023_r_000000_0
2020-11-19 10:18:43  [ Thread-678:31885 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:44  [ main:32720 ] - [ INFO ]  Job job_local1095469340_0023 running in uber mode : false
2020-11-19 10:18:44  [ main:32720 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:44  [ main:32721 ] - [ INFO ]  Job job_local1095469340_0023 completed successfully
2020-11-19 10:18:44  [ main:32722 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=108754
		FILE: Number of bytes written=13193196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1478426
		HDFS: Number of bytes written=23560
		HDFS: Number of read operations=1489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=486
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1822425088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:44  [ main:32984 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:44  [ main:32996 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:45  [ main:33000 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:45  [ main:33006 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:45  [ main:33046 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:45  [ main:33063 ] - [ INFO ]  Submitting tokens for job: job_local1750381313_0024
2020-11-19 10:18:45  [ main:33098 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:45  [ main:33098 ] - [ INFO ]  Running job: job_local1750381313_0024
2020-11-19 10:18:45  [ Thread-708:33098 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:45  [ Thread-708:33099 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:45  [ Thread-708:33099 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:45  [ Thread-708:33106 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  Starting task: attempt_local1750381313_0024_m_000000_0
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33181 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33182 ] - [ INFO ]  Task:attempt_local1750381313_0024_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33189 ] - [ INFO ]  map
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33189 ] - [ INFO ]  Task 'attempt_local1750381313_0024_m_000000_0' done.
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33189 ] - [ INFO ]  Finishing task: attempt_local1750381313_0024_m_000000_0
2020-11-19 10:18:45  [ Thread-708:33189 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:45  [ Thread-708:33189 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:45  [ pool-75-thread-1:33189 ] - [ INFO ]  Starting task: attempt_local1750381313_0024_r_000000_0
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61b4ab20
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:45  [ EventFetcher for fetching Map Completion Events:33190 ] - [ INFO ]  attempt_local1750381313_0024_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:45  [ localfetcher#24:33191 ] - [ INFO ]  localfetcher#24 about to shuffle output of map attempt_local1750381313_0024_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:45  [ localfetcher#24:33191 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1750381313_0024_m_000000_0
2020-11-19 10:18:45  [ localfetcher#24:33191 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:45  [ EventFetcher for fetching Map Completion Events:33192 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:45  [ pool-75-thread-1:33192 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:45  [ pool-75-thread-1:33192 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:45  [ pool-75-thread-1:33236 ] - [ INFO ]  Task:attempt_local1750381313_0024_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:45  [ pool-75-thread-1:33241 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:45  [ pool-75-thread-1:33241 ] - [ INFO ]  Task attempt_local1750381313_0024_r_000000_0 is allowed to commit now
2020-11-19 10:18:45  [ pool-75-thread-1:33257 ] - [ INFO ]  Saved output of task 'attempt_local1750381313_0024_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1750381313_0024_r_000000
2020-11-19 10:18:45  [ pool-75-thread-1:33258 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:45  [ pool-75-thread-1:33258 ] - [ INFO ]  Task 'attempt_local1750381313_0024_r_000000_0' done.
2020-11-19 10:18:45  [ pool-75-thread-1:33258 ] - [ INFO ]  Finishing task: attempt_local1750381313_0024_r_000000_0
2020-11-19 10:18:45  [ Thread-708:33258 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:46  [ main:34099 ] - [ INFO ]  Job job_local1750381313_0024 running in uber mode : false
2020-11-19 10:18:46  [ main:34099 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:46  [ main:34100 ] - [ INFO ]  Job job_local1750381313_0024 completed successfully
2020-11-19 10:18:46  [ main:34100 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=109944
		FILE: Number of bytes written=13765118
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1542832
		HDFS: Number of bytes written=24640
		HDFS: Number of read operations=1557
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=508
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1822425088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:46  [ main:34391 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:46  [ main:34406 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:46  [ main:34411 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:46  [ main:34417 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:46  [ main:34459 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:46  [ main:34476 ] - [ INFO ]  Submitting tokens for job: job_local2132610406_0025
2020-11-19 10:18:46  [ main:34508 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:46  [ main:34508 ] - [ INFO ]  Running job: job_local2132610406_0025
2020-11-19 10:18:46  [ Thread-738:34508 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:46  [ Thread-738:34508 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:46  [ Thread-738:34508 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:46  [ Thread-738:34515 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  Starting task: attempt_local2132610406_0025_m_000000_0
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34588 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34589 ] - [ INFO ]  Task:attempt_local2132610406_0025_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34595 ] - [ INFO ]  map
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34595 ] - [ INFO ]  Task 'attempt_local2132610406_0025_m_000000_0' done.
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34595 ] - [ INFO ]  Finishing task: attempt_local2132610406_0025_m_000000_0
2020-11-19 10:18:46  [ Thread-738:34595 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:46  [ Thread-738:34596 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  Starting task: attempt_local2132610406_0025_r_000000_0
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@188e30
2020-11-19 10:18:46  [ pool-78-thread-1:34597 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:46  [ EventFetcher for fetching Map Completion Events:34597 ] - [ INFO ]  attempt_local2132610406_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:46  [ localfetcher#25:34598 ] - [ INFO ]  localfetcher#25 about to shuffle output of map attempt_local2132610406_0025_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:46  [ localfetcher#25:34598 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local2132610406_0025_m_000000_0
2020-11-19 10:18:46  [ localfetcher#25:34598 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:46  [ EventFetcher for fetching Map Completion Events:34598 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:46  [ pool-78-thread-1:34598 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:46  [ pool-78-thread-1:34598 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:46  [ pool-78-thread-1:34599 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:46  [ pool-78-thread-1:34599 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:46  [ pool-78-thread-1:34651 ] - [ INFO ]  Task:attempt_local2132610406_0025_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:46  [ pool-78-thread-1:34659 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:46  [ pool-78-thread-1:34659 ] - [ INFO ]  Task attempt_local2132610406_0025_r_000000_0 is allowed to commit now
2020-11-19 10:18:46  [ pool-78-thread-1:34676 ] - [ INFO ]  Saved output of task 'attempt_local2132610406_0025_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2132610406_0025_r_000000
2020-11-19 10:18:46  [ pool-78-thread-1:34676 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:46  [ pool-78-thread-1:34677 ] - [ INFO ]  Task 'attempt_local2132610406_0025_r_000000_0' done.
2020-11-19 10:18:46  [ pool-78-thread-1:34677 ] - [ INFO ]  Finishing task: attempt_local2132610406_0025_r_000000_0
2020-11-19 10:18:46  [ Thread-738:34677 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]  Job job_local2132610406_0025 running in uber mode : false
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]  Job job_local2132610406_0025 completed successfully
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=111136
		FILE: Number of bytes written=14337043
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1607238
		HDFS: Number of bytes written=25720
		HDFS: Number of read operations=1625
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=530
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1822425088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:48  [ main:36045 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:48  [ main:36065 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:48  [ main:36070 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:48  [ main:36091 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:48  [ main:36143 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:48  [ main:36162 ] - [ INFO ]  Submitting tokens for job: job_local335205706_0026
2020-11-19 10:18:48  [ main:36199 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:48  [ main:36199 ] - [ INFO ]  Running job: job_local335205706_0026
2020-11-19 10:18:48  [ Thread-768:36199 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:48  [ Thread-768:36199 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:48  [ Thread-768:36199 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:48  [ Thread-768:36210 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36210 ] - [ INFO ]  Starting task: attempt_local335205706_0026_m_000000_0
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36245 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36374 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36375 ] - [ INFO ]  Task:attempt_local335205706_0026_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36385 ] - [ INFO ]  map
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36385 ] - [ INFO ]  Task 'attempt_local335205706_0026_m_000000_0' done.
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36385 ] - [ INFO ]  Finishing task: attempt_local335205706_0026_m_000000_0
2020-11-19 10:18:48  [ Thread-768:36385 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:48  [ Thread-768:36386 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  Starting task: attempt_local335205706_0026_r_000000_0
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54521048
2020-11-19 10:18:48  [ pool-81-thread-1:36387 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:48  [ EventFetcher for fetching Map Completion Events:36387 ] - [ INFO ]  attempt_local335205706_0026_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:48  [ localfetcher#26:36387 ] - [ INFO ]  localfetcher#26 about to shuffle output of map attempt_local335205706_0026_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:48  [ localfetcher#26:36388 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local335205706_0026_m_000000_0
2020-11-19 10:18:48  [ localfetcher#26:36388 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:48  [ EventFetcher for fetching Map Completion Events:36388 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:48  [ pool-81-thread-1:36388 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:48  [ pool-81-thread-1:36388 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:48  [ pool-81-thread-1:36389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:48  [ pool-81-thread-1:36389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:48  [ pool-81-thread-1:36453 ] - [ INFO ]  Task:attempt_local335205706_0026_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:48  [ pool-81-thread-1:36459 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:48  [ pool-81-thread-1:36459 ] - [ INFO ]  Task attempt_local335205706_0026_r_000000_0 is allowed to commit now
2020-11-19 10:18:48  [ pool-81-thread-1:36485 ] - [ INFO ]  Saved output of task 'attempt_local335205706_0026_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local335205706_0026_r_000000
2020-11-19 10:18:48  [ pool-81-thread-1:36486 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:48  [ pool-81-thread-1:36486 ] - [ INFO ]  Task 'attempt_local335205706_0026_r_000000_0' done.
2020-11-19 10:18:48  [ pool-81-thread-1:36486 ] - [ INFO ]  Finishing task: attempt_local335205706_0026_r_000000_0
2020-11-19 10:18:48  [ Thread-768:36486 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:49  [ main:37202 ] - [ INFO ]  Job job_local335205706_0026 running in uber mode : false
2020-11-19 10:18:49  [ main:37202 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:49  [ main:37202 ] - [ INFO ]  Job job_local335205706_0026 completed successfully
2020-11-19 10:18:49  [ main:37203 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=112328
		FILE: Number of bytes written=14905918
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1671644
		HDFS: Number of bytes written=26800
		HDFS: Number of read operations=1693
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=552
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:49  [ main:37495 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:49  [ main:37508 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:49  [ main:37513 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:49  [ main:37525 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:49  [ main:37563 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:49  [ main:37580 ] - [ INFO ]  Submitting tokens for job: job_local1153725832_0027
2020-11-19 10:18:49  [ main:37612 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:49  [ main:37613 ] - [ INFO ]  Running job: job_local1153725832_0027
2020-11-19 10:18:49  [ Thread-798:37613 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:49  [ Thread-798:37613 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:49  [ Thread-798:37613 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:49  [ Thread-798:37620 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]  Starting task: attempt_local1153725832_0027_m_000000_0
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37621 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37629 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37696 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37697 ] - [ INFO ]  Task:attempt_local1153725832_0027_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37702 ] - [ INFO ]  map
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37702 ] - [ INFO ]  Task 'attempt_local1153725832_0027_m_000000_0' done.
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37702 ] - [ INFO ]  Finishing task: attempt_local1153725832_0027_m_000000_0
2020-11-19 10:18:49  [ Thread-798:37703 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:49  [ Thread-798:37703 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:49  [ pool-84-thread-1:37703 ] - [ INFO ]  Starting task: attempt_local1153725832_0027_r_000000_0
2020-11-19 10:18:49  [ pool-84-thread-1:37703 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b30b02e
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:49  [ EventFetcher for fetching Map Completion Events:37704 ] - [ INFO ]  attempt_local1153725832_0027_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:49  [ localfetcher#27:37705 ] - [ INFO ]  localfetcher#27 about to shuffle output of map attempt_local1153725832_0027_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:49  [ localfetcher#27:37705 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1153725832_0027_m_000000_0
2020-11-19 10:18:49  [ localfetcher#27:37705 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:49  [ EventFetcher for fetching Map Completion Events:37705 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:49  [ pool-84-thread-1:37705 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:49  [ pool-84-thread-1:37706 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:49  [ pool-84-thread-1:37706 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:49  [ pool-84-thread-1:37706 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:49  [ pool-84-thread-1:37758 ] - [ INFO ]  Task:attempt_local1153725832_0027_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:49  [ pool-84-thread-1:37763 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:49  [ pool-84-thread-1:37764 ] - [ INFO ]  Task attempt_local1153725832_0027_r_000000_0 is allowed to commit now
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  Saved output of task 'attempt_local1153725832_0027_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1153725832_0027_r_000000
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  Task 'attempt_local1153725832_0027_r_000000_0' done.
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  Finishing task: attempt_local1153725832_0027_r_000000_0
2020-11-19 10:18:49  [ Thread-798:37781 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:50  [ main:38618 ] - [ INFO ]  Job job_local1153725832_0027 running in uber mode : false
2020-11-19 10:18:50  [ main:38618 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:50  [ main:38618 ] - [ INFO ]  Job job_local1153725832_0027 completed successfully
2020-11-19 10:18:50  [ main:38619 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=113518
		FILE: Number of bytes written=15477840
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1736050
		HDFS: Number of bytes written=27880
		HDFS: Number of read operations=1761
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=574
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:50  [ main:38897 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:50  [ main:38908 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:50  [ main:38912 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:50  [ main:38918 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:50  [ main:38955 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:50  [ main:38972 ] - [ INFO ]  Submitting tokens for job: job_local420316057_0028
2020-11-19 10:18:51  [ main:39003 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:51  [ main:39003 ] - [ INFO ]  Running job: job_local420316057_0028
2020-11-19 10:18:51  [ Thread-828:39003 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:51  [ Thread-828:39004 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:51  [ Thread-828:39004 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:51  [ Thread-828:39010 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  Starting task: attempt_local420316057_0028_m_000000_0
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39020 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39095 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39096 ] - [ INFO ]  Task:attempt_local420316057_0028_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39101 ] - [ INFO ]  map
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39101 ] - [ INFO ]  Task 'attempt_local420316057_0028_m_000000_0' done.
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39101 ] - [ INFO ]  Finishing task: attempt_local420316057_0028_m_000000_0
2020-11-19 10:18:51  [ Thread-828:39101 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:51  [ Thread-828:39102 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  Starting task: attempt_local420316057_0028_r_000000_0
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a9c9fd
2020-11-19 10:18:51  [ pool-87-thread-1:39103 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:51  [ EventFetcher for fetching Map Completion Events:39103 ] - [ INFO ]  attempt_local420316057_0028_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:51  [ localfetcher#28:39103 ] - [ INFO ]  localfetcher#28 about to shuffle output of map attempt_local420316057_0028_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:51  [ localfetcher#28:39104 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local420316057_0028_m_000000_0
2020-11-19 10:18:51  [ localfetcher#28:39104 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:51  [ EventFetcher for fetching Map Completion Events:39104 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:51  [ pool-87-thread-1:39104 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:51  [ pool-87-thread-1:39104 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:51  [ pool-87-thread-1:39106 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:51  [ pool-87-thread-1:39106 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:51  [ pool-87-thread-1:39106 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:51  [ pool-87-thread-1:39147 ] - [ INFO ]  Task:attempt_local420316057_0028_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:51  [ pool-87-thread-1:39153 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:51  [ pool-87-thread-1:39153 ] - [ INFO ]  Task attempt_local420316057_0028_r_000000_0 is allowed to commit now
2020-11-19 10:18:51  [ pool-87-thread-1:39169 ] - [ INFO ]  Saved output of task 'attempt_local420316057_0028_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local420316057_0028_r_000000
2020-11-19 10:18:51  [ pool-87-thread-1:39170 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:51  [ pool-87-thread-1:39170 ] - [ INFO ]  Task 'attempt_local420316057_0028_r_000000_0' done.
2020-11-19 10:18:51  [ pool-87-thread-1:39170 ] - [ INFO ]  Finishing task: attempt_local420316057_0028_r_000000_0
2020-11-19 10:18:51  [ Thread-828:39170 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]  Job job_local420316057_0028 running in uber mode : false
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]  Job job_local420316057_0028 completed successfully
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=114710
		FILE: Number of bytes written=16046717
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1800456
		HDFS: Number of bytes written=28960
		HDFS: Number of read operations=1829
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=596
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:52  [ main:40261 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:52  [ main:40272 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:52  [ main:40276 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:52  [ main:40281 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:52  [ main:40321 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:52  [ main:40338 ] - [ INFO ]  Submitting tokens for job: job_local1933719465_0029
2020-11-19 10:18:52  [ main:40370 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:52  [ main:40370 ] - [ INFO ]  Running job: job_local1933719465_0029
2020-11-19 10:18:52  [ Thread-858:40370 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:52  [ Thread-858:40370 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:52  [ Thread-858:40370 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:52  [ Thread-858:40378 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]  Starting task: attempt_local1933719465_0029_m_000000_0
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40379 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40455 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40456 ] - [ INFO ]  Task:attempt_local1933719465_0029_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40462 ] - [ INFO ]  map
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40462 ] - [ INFO ]  Task 'attempt_local1933719465_0029_m_000000_0' done.
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40463 ] - [ INFO ]  Finishing task: attempt_local1933719465_0029_m_000000_0
2020-11-19 10:18:52  [ Thread-858:40463 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:52  [ Thread-858:40463 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:52  [ pool-90-thread-1:40463 ] - [ INFO ]  Starting task: attempt_local1933719465_0029_r_000000_0
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56c2f2ab
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:52  [ EventFetcher for fetching Map Completion Events:40464 ] - [ INFO ]  attempt_local1933719465_0029_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:52  [ localfetcher#29:40465 ] - [ INFO ]  localfetcher#29 about to shuffle output of map attempt_local1933719465_0029_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:52  [ localfetcher#29:40465 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1933719465_0029_m_000000_0
2020-11-19 10:18:52  [ localfetcher#29:40465 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:52  [ EventFetcher for fetching Map Completion Events:40465 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:52  [ pool-90-thread-1:40525 ] - [ INFO ]  Task:attempt_local1933719465_0029_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:52  [ pool-90-thread-1:40531 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:52  [ pool-90-thread-1:40531 ] - [ INFO ]  Task attempt_local1933719465_0029_r_000000_0 is allowed to commit now
2020-11-19 10:18:52  [ pool-90-thread-1:40547 ] - [ INFO ]  Saved output of task 'attempt_local1933719465_0029_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1933719465_0029_r_000000
2020-11-19 10:18:52  [ pool-90-thread-1:40547 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:52  [ pool-90-thread-1:40548 ] - [ INFO ]  Task 'attempt_local1933719465_0029_r_000000_0' done.
2020-11-19 10:18:52  [ pool-90-thread-1:40548 ] - [ INFO ]  Finishing task: attempt_local1933719465_0029_r_000000_0
2020-11-19 10:18:52  [ Thread-858:40548 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:53  [ main:41374 ] - [ INFO ]  Job job_local1933719465_0029 running in uber mode : false
2020-11-19 10:18:53  [ main:41374 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:53  [ main:41375 ] - [ INFO ]  Job job_local1933719465_0029 completed successfully
2020-11-19 10:18:53  [ main:41375 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=115902
		FILE: Number of bytes written=16618640
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1864862
		HDFS: Number of bytes written=30040
		HDFS: Number of read operations=1897
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=618
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:53  [ main:41665 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:53  [ main:41675 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:53  [ main:41679 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:53  [ main:41684 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:53  [ main:41720 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:53  [ main:41737 ] - [ INFO ]  Submitting tokens for job: job_local677201198_0030
2020-11-19 10:18:53  [ main:41770 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:53  [ main:41770 ] - [ INFO ]  Running job: job_local677201198_0030
2020-11-19 10:18:53  [ Thread-888:41770 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:53  [ Thread-888:41771 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:53  [ Thread-888:41771 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:53  [ Thread-888:41779 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41779 ] - [ INFO ]  Starting task: attempt_local677201198_0030_m_000000_0
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41779 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41780 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41780 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41780 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41894 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41894 ] - [ INFO ]  Task:attempt_local677201198_0030_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41901 ] - [ INFO ]  map
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41901 ] - [ INFO ]  Task 'attempt_local677201198_0030_m_000000_0' done.
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41901 ] - [ INFO ]  Finishing task: attempt_local677201198_0030_m_000000_0
2020-11-19 10:18:53  [ Thread-888:41901 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:53  [ Thread-888:41901 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:53  [ pool-93-thread-1:41901 ] - [ INFO ]  Starting task: attempt_local677201198_0030_r_000000_0
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@45976be3
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:53  [ EventFetcher for fetching Map Completion Events:41903 ] - [ INFO ]  attempt_local677201198_0030_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:53  [ localfetcher#30:41903 ] - [ INFO ]  localfetcher#30 about to shuffle output of map attempt_local677201198_0030_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:53  [ localfetcher#30:41904 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local677201198_0030_m_000000_0
2020-11-19 10:18:53  [ localfetcher#30:41904 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:53  [ EventFetcher for fetching Map Completion Events:41904 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:53  [ pool-93-thread-1:41904 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:53  [ pool-93-thread-1:41904 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:53  [ pool-93-thread-1:41953 ] - [ INFO ]  Task:attempt_local677201198_0030_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:53  [ pool-93-thread-1:41959 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:53  [ pool-93-thread-1:41959 ] - [ INFO ]  Task attempt_local677201198_0030_r_000000_0 is allowed to commit now
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  Saved output of task 'attempt_local677201198_0030_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local677201198_0030_r_000000
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  Task 'attempt_local677201198_0030_r_000000_0' done.
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  Finishing task: attempt_local677201198_0030_r_000000_0
2020-11-19 10:18:53  [ Thread-888:41976 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:54  [ main:42774 ] - [ INFO ]  Job job_local677201198_0030 running in uber mode : false
2020-11-19 10:18:54  [ main:42775 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:54  [ main:42775 ] - [ INFO ]  Job job_local677201198_0030 completed successfully
2020-11-19 10:18:54  [ main:42775 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=117092
		FILE: Number of bytes written=17187514
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1929268
		HDFS: Number of bytes written=31120
		HDFS: Number of read operations=1965
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=640
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:55  [ main:43073 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:55  [ main:43084 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:55  [ main:43089 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:55  [ main:43094 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:55  [ main:43136 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:55  [ main:43152 ] - [ INFO ]  Submitting tokens for job: job_local1466756406_0031
2020-11-19 10:18:55  [ main:43184 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:55  [ main:43184 ] - [ INFO ]  Running job: job_local1466756406_0031
2020-11-19 10:18:55  [ Thread-918:43185 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:55  [ Thread-918:43185 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:55  [ Thread-918:43185 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:55  [ Thread-918:43192 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]  Starting task: attempt_local1466756406_0031_m_000000_0
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43193 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43271 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43272 ] - [ INFO ]  Task:attempt_local1466756406_0031_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43279 ] - [ INFO ]  map
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43279 ] - [ INFO ]  Task 'attempt_local1466756406_0031_m_000000_0' done.
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43279 ] - [ INFO ]  Finishing task: attempt_local1466756406_0031_m_000000_0
2020-11-19 10:18:55  [ Thread-918:43279 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:55  [ Thread-918:43279 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:55  [ pool-96-thread-1:43279 ] - [ INFO ]  Starting task: attempt_local1466756406_0031_r_000000_0
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12c36af1
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:55  [ EventFetcher for fetching Map Completion Events:43280 ] - [ INFO ]  attempt_local1466756406_0031_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:55  [ localfetcher#31:43281 ] - [ INFO ]  localfetcher#31 about to shuffle output of map attempt_local1466756406_0031_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:55  [ localfetcher#31:43281 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1466756406_0031_m_000000_0
2020-11-19 10:18:55  [ localfetcher#31:43281 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:55  [ EventFetcher for fetching Map Completion Events:43281 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:55  [ pool-96-thread-1:43325 ] - [ INFO ]  Task:attempt_local1466756406_0031_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:55  [ pool-96-thread-1:43332 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:55  [ pool-96-thread-1:43332 ] - [ INFO ]  Task attempt_local1466756406_0031_r_000000_0 is allowed to commit now
2020-11-19 10:18:55  [ pool-96-thread-1:43348 ] - [ INFO ]  Saved output of task 'attempt_local1466756406_0031_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1466756406_0031_r_000000
2020-11-19 10:18:55  [ pool-96-thread-1:43349 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:55  [ pool-96-thread-1:43349 ] - [ INFO ]  Task 'attempt_local1466756406_0031_r_000000_0' done.
2020-11-19 10:18:55  [ pool-96-thread-1:43349 ] - [ INFO ]  Finishing task: attempt_local1466756406_0031_r_000000_0
2020-11-19 10:18:55  [ Thread-918:43349 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:56  [ main:44189 ] - [ INFO ]  Job job_local1466756406_0031 running in uber mode : false
2020-11-19 10:18:56  [ main:44189 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:56  [ main:44189 ] - [ INFO ]  Job job_local1466756406_0031 completed successfully
2020-11-19 10:18:56  [ main:44190 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=118284
		FILE: Number of bytes written=17759439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1993674
		HDFS: Number of bytes written=32200
		HDFS: Number of read operations=2033
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=662
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:56  [ main:44867 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:56  [ main:44878 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:56  [ main:44883 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:56  [ main:44889 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:56  [ main:44929 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:56  [ main:44946 ] - [ INFO ]  Submitting tokens for job: job_local297105078_0032
2020-11-19 10:18:56  [ main:44978 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:56  [ main:44979 ] - [ INFO ]  Running job: job_local297105078_0032
2020-11-19 10:18:56  [ Thread-948:44979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:56  [ Thread-948:44979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:56  [ Thread-948:44979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:56  [ Thread-948:44988 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]  Starting task: attempt_local297105078_0032_m_000000_0
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44989 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45062 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45063 ] - [ INFO ]  Task:attempt_local297105078_0032_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45071 ] - [ INFO ]  map
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45071 ] - [ INFO ]  Task 'attempt_local297105078_0032_m_000000_0' done.
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45071 ] - [ INFO ]  Finishing task: attempt_local297105078_0032_m_000000_0
2020-11-19 10:18:57  [ Thread-948:45071 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:57  [ Thread-948:45071 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:57  [ pool-99-thread-1:45071 ] - [ INFO ]  Starting task: attempt_local297105078_0032_r_000000_0
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3af3fc30
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:57  [ EventFetcher for fetching Map Completion Events:45073 ] - [ INFO ]  attempt_local297105078_0032_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:57  [ localfetcher#32:45073 ] - [ INFO ]  localfetcher#32 about to shuffle output of map attempt_local297105078_0032_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:57  [ localfetcher#32:45073 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local297105078_0032_m_000000_0
2020-11-19 10:18:57  [ localfetcher#32:45073 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:57  [ EventFetcher for fetching Map Completion Events:45074 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:57  [ pool-99-thread-1:45074 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:57  [ pool-99-thread-1:45074 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:57  [ pool-99-thread-1:45076 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:57  [ pool-99-thread-1:45076 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:57  [ pool-99-thread-1:45116 ] - [ INFO ]  Task:attempt_local297105078_0032_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:57  [ pool-99-thread-1:45122 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:57  [ pool-99-thread-1:45122 ] - [ INFO ]  Task attempt_local297105078_0032_r_000000_0 is allowed to commit now
2020-11-19 10:18:57  [ pool-99-thread-1:45138 ] - [ INFO ]  Saved output of task 'attempt_local297105078_0032_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local297105078_0032_r_000000
2020-11-19 10:18:57  [ pool-99-thread-1:45139 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:57  [ pool-99-thread-1:45139 ] - [ INFO ]  Task 'attempt_local297105078_0032_r_000000_0' done.
2020-11-19 10:18:57  [ pool-99-thread-1:45139 ] - [ INFO ]  Finishing task: attempt_local297105078_0032_r_000000_0
2020-11-19 10:18:57  [ Thread-948:45139 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:57  [ main:45981 ] - [ INFO ]  Job job_local297105078_0032 running in uber mode : false
2020-11-19 10:18:57  [ main:45982 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:57  [ main:45982 ] - [ INFO ]  Job job_local297105078_0032 completed successfully
2020-11-19 10:18:57  [ main:45983 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=119476
		FILE: Number of bytes written=18328314
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2058080
		HDFS: Number of bytes written=33280
		HDFS: Number of read operations=2101
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=684
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:58  [ main:46282 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:58  [ main:46294 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:58  [ main:46298 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:58  [ main:46305 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:58  [ main:46345 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:58  [ main:46361 ] - [ INFO ]  Submitting tokens for job: job_local126845285_0033
2020-11-19 10:18:58  [ main:46392 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:58  [ main:46392 ] - [ INFO ]  Running job: job_local126845285_0033
2020-11-19 10:18:58  [ Thread-978:46392 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:58  [ Thread-978:46392 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:58  [ Thread-978:46392 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:58  [ Thread-978:46399 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46399 ] - [ INFO ]  Starting task: attempt_local126845285_0033_m_000000_0
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46492 ] - [ INFO ]  
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46495 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46496 ] - [ INFO ]  Task:attempt_local126845285_0033_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46502 ] - [ INFO ]  map
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46502 ] - [ INFO ]  Task 'attempt_local126845285_0033_m_000000_0' done.
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46502 ] - [ INFO ]  Finishing task: attempt_local126845285_0033_m_000000_0
2020-11-19 10:18:58  [ Thread-978:46502 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:58  [ Thread-978:46502 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:58  [ pool-102-thread-1:46502 ] - [ INFO ]  Starting task: attempt_local126845285_0033_r_000000_0
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b9e5251
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:58  [ EventFetcher for fetching Map Completion Events:46503 ] - [ INFO ]  attempt_local126845285_0033_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:58  [ localfetcher#33:46504 ] - [ INFO ]  localfetcher#33 about to shuffle output of map attempt_local126845285_0033_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:58  [ localfetcher#33:46504 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local126845285_0033_m_000000_0
2020-11-19 10:18:58  [ localfetcher#33:46504 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:58  [ EventFetcher for fetching Map Completion Events:46505 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:58  [ pool-102-thread-1:46505 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:58  [ pool-102-thread-1:46505 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:58  [ pool-102-thread-1:46507 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:58  [ pool-102-thread-1:46561 ] - [ INFO ]  Task:attempt_local126845285_0033_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:58  [ pool-102-thread-1:46566 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:58  [ pool-102-thread-1:46567 ] - [ INFO ]  Task attempt_local126845285_0033_r_000000_0 is allowed to commit now
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  Saved output of task 'attempt_local126845285_0033_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local126845285_0033_r_000000
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  Task 'attempt_local126845285_0033_r_000000_0' done.
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  Finishing task: attempt_local126845285_0033_r_000000_0
2020-11-19 10:18:58  [ Thread-978:46584 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:59  [ main:47394 ] - [ INFO ]  Job job_local126845285_0033 running in uber mode : false
2020-11-19 10:18:59  [ main:47394 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:59  [ main:47394 ] - [ INFO ]  Job job_local126845285_0033 completed successfully
2020-11-19 10:18:59  [ main:47395 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=120666
		FILE: Number of bytes written=18897188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2122486
		HDFS: Number of bytes written=34360
		HDFS: Number of read operations=2169
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=706
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:59  [ main:47717 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:59  [ main:47727 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:59  [ main:47730 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:59  [ main:47737 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:59  [ main:47772 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:59  [ main:47789 ] - [ INFO ]  Submitting tokens for job: job_local708387464_0034
2020-11-19 10:18:59  [ main:47818 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:59  [ main:47819 ] - [ INFO ]  Running job: job_local708387464_0034
2020-11-19 10:18:59  [ Thread-1008:47819 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:59  [ Thread-1008:47819 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:59  [ Thread-1008:47819 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:59  [ Thread-1008:47826 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]  Starting task: attempt_local708387464_0034_m_000000_0
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47828 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47839 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47896 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47897 ] - [ INFO ]  Task:attempt_local708387464_0034_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47904 ] - [ INFO ]  map
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47904 ] - [ INFO ]  Task 'attempt_local708387464_0034_m_000000_0' done.
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47904 ] - [ INFO ]  Finishing task: attempt_local708387464_0034_m_000000_0
2020-11-19 10:18:59  [ Thread-1008:47904 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:59  [ Thread-1008:47905 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  Starting task: attempt_local708387464_0034_r_000000_0
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53b36b4d
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:59  [ EventFetcher for fetching Map Completion Events:47906 ] - [ INFO ]  attempt_local708387464_0034_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:59  [ localfetcher#34:47906 ] - [ INFO ]  localfetcher#34 about to shuffle output of map attempt_local708387464_0034_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:59  [ localfetcher#34:47906 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local708387464_0034_m_000000_0
2020-11-19 10:18:59  [ localfetcher#34:47906 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:59  [ EventFetcher for fetching Map Completion Events:47907 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:59  [ pool-105-thread-1:47907 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:59  [ pool-105-thread-1:47907 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:59  [ pool-105-thread-1:47907 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:59  [ pool-105-thread-1:47952 ] - [ INFO ]  Task:attempt_local708387464_0034_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:59  [ pool-105-thread-1:47958 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:59  [ pool-105-thread-1:47958 ] - [ INFO ]  Task attempt_local708387464_0034_r_000000_0 is allowed to commit now
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  Saved output of task 'attempt_local708387464_0034_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local708387464_0034_r_000000
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  Task 'attempt_local708387464_0034_r_000000_0' done.
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  Finishing task: attempt_local708387464_0034_r_000000_0
2020-11-19 10:18:59  [ Thread-1008:47976 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:00  [ main:48820 ] - [ INFO ]  Job job_local708387464_0034 running in uber mode : false
2020-11-19 10:19:00  [ main:48820 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:00  [ main:48820 ] - [ INFO ]  Job job_local708387464_0034 completed successfully
2020-11-19 10:19:00  [ main:48821 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=121858
		FILE: Number of bytes written=19466065
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2186892
		HDFS: Number of bytes written=35440
		HDFS: Number of read operations=2237
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=728
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:01  [ main:49105 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:01  [ main:49115 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:01  [ main:49120 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:01  [ main:49125 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:01  [ main:49164 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:01  [ main:49182 ] - [ INFO ]  Submitting tokens for job: job_local566160288_0035
2020-11-19 10:19:01  [ main:49227 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:01  [ main:49227 ] - [ INFO ]  Running job: job_local566160288_0035
2020-11-19 10:19:01  [ Thread-1038:49227 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:01  [ Thread-1038:49227 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:01  [ Thread-1038:49227 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:01  [ Thread-1038:49235 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  Starting task: attempt_local566160288_0035_m_000000_0
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49299 ] - [ INFO ]  
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49301 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49302 ] - [ INFO ]  Task:attempt_local566160288_0035_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49308 ] - [ INFO ]  map
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49308 ] - [ INFO ]  Task 'attempt_local566160288_0035_m_000000_0' done.
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49308 ] - [ INFO ]  Finishing task: attempt_local566160288_0035_m_000000_0
2020-11-19 10:19:01  [ Thread-1038:49308 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:01  [ Thread-1038:49309 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  Starting task: attempt_local566160288_0035_r_000000_0
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b93d762
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:01  [ EventFetcher for fetching Map Completion Events:49310 ] - [ INFO ]  attempt_local566160288_0035_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:01  [ localfetcher#35:49310 ] - [ INFO ]  localfetcher#35 about to shuffle output of map attempt_local566160288_0035_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:01  [ localfetcher#35:49310 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local566160288_0035_m_000000_0
2020-11-19 10:19:01  [ localfetcher#35:49310 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:01  [ EventFetcher for fetching Map Completion Events:49311 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:01  [ pool-108-thread-1:49367 ] - [ INFO ]  Task:attempt_local566160288_0035_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:01  [ pool-108-thread-1:49373 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:01  [ pool-108-thread-1:49373 ] - [ INFO ]  Task attempt_local566160288_0035_r_000000_0 is allowed to commit now
2020-11-19 10:19:01  [ pool-108-thread-1:49393 ] - [ INFO ]  Saved output of task 'attempt_local566160288_0035_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local566160288_0035_r_000000
2020-11-19 10:19:01  [ pool-108-thread-1:49394 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:01  [ pool-108-thread-1:49394 ] - [ INFO ]  Task 'attempt_local566160288_0035_r_000000_0' done.
2020-11-19 10:19:01  [ pool-108-thread-1:49394 ] - [ INFO ]  Finishing task: attempt_local566160288_0035_r_000000_0
2020-11-19 10:19:01  [ Thread-1038:49394 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:02  [ main:50227 ] - [ INFO ]  Job job_local566160288_0035 running in uber mode : false
2020-11-19 10:19:02  [ main:50228 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:02  [ main:50228 ] - [ INFO ]  Job job_local566160288_0035 completed successfully
2020-11-19 10:19:02  [ main:50228 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=123050
		FILE: Number of bytes written=20034940
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2251298
		HDFS: Number of bytes written=36520
		HDFS: Number of read operations=2305
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=750
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:02  [ main:50497 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:02  [ main:50508 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:02  [ main:50512 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:02  [ main:50517 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:02  [ main:50555 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:02  [ main:50572 ] - [ INFO ]  Submitting tokens for job: job_local1343639200_0036
2020-11-19 10:19:02  [ main:50601 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:02  [ main:50602 ] - [ INFO ]  Running job: job_local1343639200_0036
2020-11-19 10:19:02  [ Thread-1068:50602 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:02  [ Thread-1068:50602 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:02  [ Thread-1068:50602 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:02  [ Thread-1068:50609 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]  Starting task: attempt_local1343639200_0036_m_000000_0
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50610 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50617 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50617 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50684 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50685 ] - [ INFO ]  Task:attempt_local1343639200_0036_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50691 ] - [ INFO ]  map
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50691 ] - [ INFO ]  Task 'attempt_local1343639200_0036_m_000000_0' done.
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50691 ] - [ INFO ]  Finishing task: attempt_local1343639200_0036_m_000000_0
2020-11-19 10:19:02  [ Thread-1068:50691 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:02  [ Thread-1068:50692 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  Starting task: attempt_local1343639200_0036_r_000000_0
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4720fd5f
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:02  [ EventFetcher for fetching Map Completion Events:50693 ] - [ INFO ]  attempt_local1343639200_0036_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:02  [ localfetcher#36:50693 ] - [ INFO ]  localfetcher#36 about to shuffle output of map attempt_local1343639200_0036_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:02  [ localfetcher#36:50694 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1343639200_0036_m_000000_0
2020-11-19 10:19:02  [ localfetcher#36:50694 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:02  [ EventFetcher for fetching Map Completion Events:50694 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:02  [ pool-111-thread-1:50694 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:02  [ pool-111-thread-1:50694 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:02  [ pool-111-thread-1:50696 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:02  [ pool-111-thread-1:50696 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:02  [ pool-111-thread-1:50749 ] - [ INFO ]  Task:attempt_local1343639200_0036_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:02  [ pool-111-thread-1:50755 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:02  [ pool-111-thread-1:50755 ] - [ INFO ]  Task attempt_local1343639200_0036_r_000000_0 is allowed to commit now
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  Saved output of task 'attempt_local1343639200_0036_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1343639200_0036_r_000000
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  Task 'attempt_local1343639200_0036_r_000000_0' done.
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  Finishing task: attempt_local1343639200_0036_r_000000_0
2020-11-19 10:19:02  [ Thread-1068:50771 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:03  [ main:51606 ] - [ INFO ]  Job job_local1343639200_0036 running in uber mode : false
2020-11-19 10:19:03  [ main:51607 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:03  [ main:51607 ] - [ INFO ]  Job job_local1343639200_0036 completed successfully
2020-11-19 10:19:03  [ main:51607 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=124240
		FILE: Number of bytes written=20606862
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2315704
		HDFS: Number of bytes written=37600
		HDFS: Number of read operations=2373
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=772
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:04  [ main:52096 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:04  [ main:52107 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:04  [ main:52112 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:04  [ main:52117 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:04  [ main:52155 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:04  [ main:52173 ] - [ INFO ]  Submitting tokens for job: job_local1711682094_0037
2020-11-19 10:19:04  [ main:52202 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:04  [ main:52202 ] - [ INFO ]  Running job: job_local1711682094_0037
2020-11-19 10:19:04  [ Thread-1098:52202 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:04  [ Thread-1098:52202 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:04  [ Thread-1098:52203 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:04  [ Thread-1098:52210 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52210 ] - [ INFO ]  Starting task: attempt_local1711682094_0037_m_000000_0
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52289 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52290 ] - [ INFO ]  Task:attempt_local1711682094_0037_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52296 ] - [ INFO ]  map
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52296 ] - [ INFO ]  Task 'attempt_local1711682094_0037_m_000000_0' done.
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52296 ] - [ INFO ]  Finishing task: attempt_local1711682094_0037_m_000000_0
2020-11-19 10:19:04  [ Thread-1098:52296 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:04  [ Thread-1098:52297 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  Starting task: attempt_local1711682094_0037_r_000000_0
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@727f2737
2020-11-19 10:19:04  [ pool-114-thread-1:52298 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:04  [ EventFetcher for fetching Map Completion Events:52298 ] - [ INFO ]  attempt_local1711682094_0037_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:04  [ localfetcher#37:52299 ] - [ INFO ]  localfetcher#37 about to shuffle output of map attempt_local1711682094_0037_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:04  [ localfetcher#37:52299 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1711682094_0037_m_000000_0
2020-11-19 10:19:04  [ localfetcher#37:52299 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:04  [ EventFetcher for fetching Map Completion Events:52299 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:04  [ pool-114-thread-1:52299 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:04  [ pool-114-thread-1:52299 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:04  [ pool-114-thread-1:52300 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:04  [ pool-114-thread-1:52300 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:04  [ pool-114-thread-1:52345 ] - [ INFO ]  Task:attempt_local1711682094_0037_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:04  [ pool-114-thread-1:52352 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:04  [ pool-114-thread-1:52352 ] - [ INFO ]  Task attempt_local1711682094_0037_r_000000_0 is allowed to commit now
2020-11-19 10:19:04  [ pool-114-thread-1:52370 ] - [ INFO ]  Saved output of task 'attempt_local1711682094_0037_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1711682094_0037_r_000000
2020-11-19 10:19:04  [ pool-114-thread-1:52371 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:04  [ pool-114-thread-1:52371 ] - [ INFO ]  Task 'attempt_local1711682094_0037_r_000000_0' done.
2020-11-19 10:19:04  [ pool-114-thread-1:52371 ] - [ INFO ]  Finishing task: attempt_local1711682094_0037_r_000000_0
2020-11-19 10:19:04  [ Thread-1098:52371 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]  Job job_local1711682094_0037 running in uber mode : false
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]  Job job_local1711682094_0037 completed successfully
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=125432
		FILE: Number of bytes written=21178787
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2380110
		HDFS: Number of bytes written=38680
		HDFS: Number of read operations=2441
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=794
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:05  [ main:53536 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:05  [ main:53547 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:05  [ main:53552 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:05  [ main:53559 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:05  [ main:53599 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:05  [ main:53616 ] - [ INFO ]  Submitting tokens for job: job_local621588039_0038
2020-11-19 10:19:05  [ main:53647 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:05  [ main:53647 ] - [ INFO ]  Running job: job_local621588039_0038
2020-11-19 10:19:05  [ Thread-1128:53647 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:05  [ Thread-1128:53647 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:05  [ Thread-1128:53647 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:05  [ Thread-1128:53655 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53655 ] - [ INFO ]  Starting task: attempt_local621588039_0038_m_000000_0
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53732 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53733 ] - [ INFO ]  Task:attempt_local621588039_0038_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53743 ] - [ INFO ]  map
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53743 ] - [ INFO ]  Task 'attempt_local621588039_0038_m_000000_0' done.
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53743 ] - [ INFO ]  Finishing task: attempt_local621588039_0038_m_000000_0
2020-11-19 10:19:05  [ Thread-1128:53743 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:05  [ Thread-1128:53743 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  Starting task: attempt_local621588039_0038_r_000000_0
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30efd474
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:05  [ EventFetcher for fetching Map Completion Events:53745 ] - [ INFO ]  attempt_local621588039_0038_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:05  [ localfetcher#38:53745 ] - [ INFO ]  localfetcher#38 about to shuffle output of map attempt_local621588039_0038_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:05  [ localfetcher#38:53746 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local621588039_0038_m_000000_0
2020-11-19 10:19:05  [ localfetcher#38:53746 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:05  [ EventFetcher for fetching Map Completion Events:53746 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:05  [ pool-117-thread-1:53746 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:05  [ pool-117-thread-1:53746 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:05  [ pool-117-thread-1:53748 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:05  [ pool-117-thread-1:53748 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:05  [ pool-117-thread-1:53812 ] - [ INFO ]  Task:attempt_local621588039_0038_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:05  [ pool-117-thread-1:53818 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:05  [ pool-117-thread-1:53818 ] - [ INFO ]  Task attempt_local621588039_0038_r_000000_0 is allowed to commit now
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  Saved output of task 'attempt_local621588039_0038_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local621588039_0038_r_000000
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  Task 'attempt_local621588039_0038_r_000000_0' done.
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  Finishing task: attempt_local621588039_0038_r_000000_0
2020-11-19 10:19:05  [ Thread-1128:53837 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:06  [ main:54648 ] - [ INFO ]  Job job_local621588039_0038 running in uber mode : false
2020-11-19 10:19:06  [ main:54648 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:06  [ main:54648 ] - [ INFO ]  Job job_local621588039_0038 completed successfully
2020-11-19 10:19:06  [ main:54649 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=126624
		FILE: Number of bytes written=21747662
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2444516
		HDFS: Number of bytes written=39760
		HDFS: Number of read operations=2509
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=816
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:06  [ main:54932 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:06  [ main:54943 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:06  [ main:54948 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:06  [ main:54953 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:06  [ main:54993 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:07  [ main:55010 ] - [ INFO ]  Submitting tokens for job: job_local677122145_0039
2020-11-19 10:19:07  [ main:55050 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:07  [ main:55050 ] - [ INFO ]  Running job: job_local677122145_0039
2020-11-19 10:19:07  [ Thread-1158:55051 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:07  [ Thread-1158:55051 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:07  [ Thread-1158:55051 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:07  [ Thread-1158:55059 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]  Starting task: attempt_local677122145_0039_m_000000_0
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55060 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55070 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55136 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55136 ] - [ INFO ]  Task:attempt_local677122145_0039_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55143 ] - [ INFO ]  map
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55143 ] - [ INFO ]  Task 'attempt_local677122145_0039_m_000000_0' done.
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55143 ] - [ INFO ]  Finishing task: attempt_local677122145_0039_m_000000_0
2020-11-19 10:19:07  [ Thread-1158:55143 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:07  [ Thread-1158:55143 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  Starting task: attempt_local677122145_0039_r_000000_0
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23663e43
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:07  [ EventFetcher for fetching Map Completion Events:55145 ] - [ INFO ]  attempt_local677122145_0039_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:07  [ localfetcher#39:55146 ] - [ INFO ]  localfetcher#39 about to shuffle output of map attempt_local677122145_0039_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:07  [ localfetcher#39:55146 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local677122145_0039_m_000000_0
2020-11-19 10:19:07  [ localfetcher#39:55146 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:07  [ EventFetcher for fetching Map Completion Events:55146 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:07  [ pool-120-thread-1:55146 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:07  [ pool-120-thread-1:55146 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:07  [ pool-120-thread-1:55147 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:07  [ pool-120-thread-1:55147 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:07  [ pool-120-thread-1:55205 ] - [ INFO ]  Task:attempt_local677122145_0039_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:07  [ pool-120-thread-1:55211 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:07  [ pool-120-thread-1:55211 ] - [ INFO ]  Task attempt_local677122145_0039_r_000000_0 is allowed to commit now
2020-11-19 10:19:07  [ pool-120-thread-1:55230 ] - [ INFO ]  Saved output of task 'attempt_local677122145_0039_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local677122145_0039_r_000000
2020-11-19 10:19:07  [ pool-120-thread-1:55231 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:07  [ pool-120-thread-1:55231 ] - [ INFO ]  Task 'attempt_local677122145_0039_r_000000_0' done.
2020-11-19 10:19:07  [ pool-120-thread-1:55231 ] - [ INFO ]  Finishing task: attempt_local677122145_0039_r_000000_0
2020-11-19 10:19:07  [ Thread-1158:55231 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:08  [ main:56051 ] - [ INFO ]  Job job_local677122145_0039 running in uber mode : false
2020-11-19 10:19:08  [ main:56052 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:08  [ main:56052 ] - [ INFO ]  Job job_local677122145_0039 completed successfully
2020-11-19 10:19:08  [ main:56052 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=127814
		FILE: Number of bytes written=22316536
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2508922
		HDFS: Number of bytes written=40840
		HDFS: Number of read operations=2577
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=838
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:08  [ main:56325 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:08  [ main:56336 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:08  [ main:56341 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:08  [ main:56349 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:08  [ main:56390 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:08  [ main:56407 ] - [ INFO ]  Submitting tokens for job: job_local1982298173_0040
2020-11-19 10:19:08  [ main:56439 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:08  [ main:56439 ] - [ INFO ]  Running job: job_local1982298173_0040
2020-11-19 10:19:08  [ Thread-1188:56439 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:08  [ Thread-1188:56439 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:08  [ Thread-1188:56439 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:08  [ Thread-1188:56446 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56446 ] - [ INFO ]  Starting task: attempt_local1982298173_0040_m_000000_0
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56527 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56528 ] - [ INFO ]  Task:attempt_local1982298173_0040_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56533 ] - [ INFO ]  map
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56533 ] - [ INFO ]  Task 'attempt_local1982298173_0040_m_000000_0' done.
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56533 ] - [ INFO ]  Finishing task: attempt_local1982298173_0040_m_000000_0
2020-11-19 10:19:08  [ Thread-1188:56534 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:08  [ Thread-1188:56534 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  Starting task: attempt_local1982298173_0040_r_000000_0
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@de71f5a
2020-11-19 10:19:08  [ pool-123-thread-1:56535 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:08  [ EventFetcher for fetching Map Completion Events:56535 ] - [ INFO ]  attempt_local1982298173_0040_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:08  [ localfetcher#40:56536 ] - [ INFO ]  localfetcher#40 about to shuffle output of map attempt_local1982298173_0040_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:08  [ localfetcher#40:56536 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1982298173_0040_m_000000_0
2020-11-19 10:19:08  [ localfetcher#40:56536 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:08  [ EventFetcher for fetching Map Completion Events:56536 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:08  [ pool-123-thread-1:56536 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:08  [ pool-123-thread-1:56536 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:08  [ pool-123-thread-1:56537 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:08  [ pool-123-thread-1:56537 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:08  [ pool-123-thread-1:56584 ] - [ INFO ]  Task:attempt_local1982298173_0040_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:08  [ pool-123-thread-1:56589 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:08  [ pool-123-thread-1:56589 ] - [ INFO ]  Task attempt_local1982298173_0040_r_000000_0 is allowed to commit now
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  Saved output of task 'attempt_local1982298173_0040_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1982298173_0040_r_000000
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  Task 'attempt_local1982298173_0040_r_000000_0' done.
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  Finishing task: attempt_local1982298173_0040_r_000000_0
2020-11-19 10:19:08  [ Thread-1188:56606 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]  Job job_local1982298173_0040 running in uber mode : false
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]  Job job_local1982298173_0040 completed successfully
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=129006
		FILE: Number of bytes written=22888461
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2573328
		HDFS: Number of bytes written=41920
		HDFS: Number of read operations=2645
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=860
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:09  [ main:57754 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:09  [ main:57765 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:09  [ main:57770 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:09  [ main:57775 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:09  [ main:57814 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:09  [ main:57831 ] - [ INFO ]  Submitting tokens for job: job_local1559126420_0041
2020-11-19 10:19:09  [ main:57861 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:09  [ main:57861 ] - [ INFO ]  Running job: job_local1559126420_0041
2020-11-19 10:19:09  [ Thread-1218:57861 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:09  [ Thread-1218:57861 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:09  [ Thread-1218:57861 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:09  [ Thread-1218:57870 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57870 ] - [ INFO ]  Starting task: attempt_local1559126420_0041_m_000000_0
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57879 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57947 ] - [ INFO ]  
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57949 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57950 ] - [ INFO ]  Task:attempt_local1559126420_0041_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57956 ] - [ INFO ]  map
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57956 ] - [ INFO ]  Task 'attempt_local1559126420_0041_m_000000_0' done.
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57956 ] - [ INFO ]  Finishing task: attempt_local1559126420_0041_m_000000_0
2020-11-19 10:19:09  [ Thread-1218:57956 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:09  [ Thread-1218:57957 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  Starting task: attempt_local1559126420_0041_r_000000_0
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@536362e9
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:09  [ EventFetcher for fetching Map Completion Events:57958 ] - [ INFO ]  attempt_local1559126420_0041_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:09  [ localfetcher#41:57958 ] - [ INFO ]  localfetcher#41 about to shuffle output of map attempt_local1559126420_0041_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:09  [ localfetcher#41:57959 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1559126420_0041_m_000000_0
2020-11-19 10:19:09  [ localfetcher#41:57959 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:09  [ EventFetcher for fetching Map Completion Events:57959 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:09  [ pool-126-thread-1:57959 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:09  [ pool-126-thread-1:57959 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:09  [ pool-126-thread-1:57960 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:09  [ pool-126-thread-1:57960 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:09  [ pool-126-thread-1:57960 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:10  [ pool-126-thread-1:58021 ] - [ INFO ]  Task:attempt_local1559126420_0041_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:10  [ pool-126-thread-1:58028 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:10  [ pool-126-thread-1:58028 ] - [ INFO ]  Task attempt_local1559126420_0041_r_000000_0 is allowed to commit now
2020-11-19 10:19:10  [ pool-126-thread-1:58044 ] - [ INFO ]  Saved output of task 'attempt_local1559126420_0041_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1559126420_0041_r_000000
2020-11-19 10:19:10  [ pool-126-thread-1:58045 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:10  [ pool-126-thread-1:58045 ] - [ INFO ]  Task 'attempt_local1559126420_0041_r_000000_0' done.
2020-11-19 10:19:10  [ pool-126-thread-1:58045 ] - [ INFO ]  Finishing task: attempt_local1559126420_0041_r_000000_0
2020-11-19 10:19:10  [ Thread-1218:58045 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:10  [ main:58863 ] - [ INFO ]  Job job_local1559126420_0041 running in uber mode : false
2020-11-19 10:19:10  [ main:58863 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:10  [ main:58863 ] - [ INFO ]  Job job_local1559126420_0041 completed successfully
2020-11-19 10:19:10  [ main:58864 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=130198
		FILE: Number of bytes written=23460384
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2637734
		HDFS: Number of bytes written=43000
		HDFS: Number of read operations=2713
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=882
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:11  [ main:59156 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:11  [ main:59167 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:11  [ main:59172 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:11  [ main:59177 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:11  [ main:59216 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:11  [ main:59234 ] - [ INFO ]  Submitting tokens for job: job_local1396890892_0042
2020-11-19 10:19:11  [ main:59265 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:11  [ main:59265 ] - [ INFO ]  Running job: job_local1396890892_0042
2020-11-19 10:19:11  [ Thread-1248:59265 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:11  [ Thread-1248:59265 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:11  [ Thread-1248:59265 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:11  [ Thread-1248:59273 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  Starting task: attempt_local1396890892_0042_m_000000_0
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59348 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59349 ] - [ INFO ]  Task:attempt_local1396890892_0042_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59356 ] - [ INFO ]  map
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59356 ] - [ INFO ]  Task 'attempt_local1396890892_0042_m_000000_0' done.
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59356 ] - [ INFO ]  Finishing task: attempt_local1396890892_0042_m_000000_0
2020-11-19 10:19:11  [ Thread-1248:59357 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:11  [ Thread-1248:59357 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:11  [ pool-129-thread-1:59357 ] - [ INFO ]  Starting task: attempt_local1396890892_0042_r_000000_0
2020-11-19 10:19:11  [ pool-129-thread-1:59357 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23ed2db9
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:11  [ EventFetcher for fetching Map Completion Events:59358 ] - [ INFO ]  attempt_local1396890892_0042_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:11  [ localfetcher#42:59359 ] - [ INFO ]  localfetcher#42 about to shuffle output of map attempt_local1396890892_0042_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:11  [ localfetcher#42:59359 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1396890892_0042_m_000000_0
2020-11-19 10:19:11  [ localfetcher#42:59359 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:11  [ EventFetcher for fetching Map Completion Events:59359 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:11  [ pool-129-thread-1:59359 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:11  [ pool-129-thread-1:59360 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:11  [ pool-129-thread-1:59360 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:11  [ pool-129-thread-1:59360 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:11  [ pool-129-thread-1:59422 ] - [ INFO ]  Task:attempt_local1396890892_0042_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:11  [ pool-129-thread-1:59427 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:11  [ pool-129-thread-1:59427 ] - [ INFO ]  Task attempt_local1396890892_0042_r_000000_0 is allowed to commit now
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  Saved output of task 'attempt_local1396890892_0042_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1396890892_0042_r_000000
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  Task 'attempt_local1396890892_0042_r_000000_0' done.
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  Finishing task: attempt_local1396890892_0042_r_000000_0
2020-11-19 10:19:11  [ Thread-1248:59446 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:12  [ main:60268 ] - [ INFO ]  Job job_local1396890892_0042 running in uber mode : false
2020-11-19 10:19:12  [ main:60268 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:12  [ main:60268 ] - [ INFO ]  Job job_local1396890892_0042 completed successfully
2020-11-19 10:19:12  [ main:60269 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=131388
		FILE: Number of bytes written=24032306
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2702140
		HDFS: Number of bytes written=44080
		HDFS: Number of read operations=2781
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=904
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:12  [ main:60549 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:12  [ main:60560 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:12  [ main:60565 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:12  [ main:60570 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:12  [ main:60609 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:12  [ main:60626 ] - [ INFO ]  Submitting tokens for job: job_local815155349_0043
2020-11-19 10:19:12  [ main:60669 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:12  [ main:60669 ] - [ INFO ]  Running job: job_local815155349_0043
2020-11-19 10:19:12  [ Thread-1278:60670 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:12  [ Thread-1278:60670 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:12  [ Thread-1278:60670 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:12  [ Thread-1278:60677 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60677 ] - [ INFO ]  Starting task: attempt_local815155349_0043_m_000000_0
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60771 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60771 ] - [ INFO ]  Task:attempt_local815155349_0043_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60776 ] - [ INFO ]  map
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60776 ] - [ INFO ]  Task 'attempt_local815155349_0043_m_000000_0' done.
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60776 ] - [ INFO ]  Finishing task: attempt_local815155349_0043_m_000000_0
2020-11-19 10:19:12  [ Thread-1278:60777 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:12  [ Thread-1278:60777 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:12  [ pool-132-thread-1:60777 ] - [ INFO ]  Starting task: attempt_local815155349_0043_r_000000_0
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27af4549
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:12  [ EventFetcher for fetching Map Completion Events:60778 ] - [ INFO ]  attempt_local815155349_0043_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:12  [ localfetcher#43:60782 ] - [ INFO ]  localfetcher#43 about to shuffle output of map attempt_local815155349_0043_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:12  [ localfetcher#43:60782 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local815155349_0043_m_000000_0
2020-11-19 10:19:12  [ localfetcher#43:60782 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:12  [ EventFetcher for fetching Map Completion Events:60782 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:12  [ pool-132-thread-1:60784 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:12  [ pool-132-thread-1:60784 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:12  [ pool-132-thread-1:60786 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:12  [ pool-132-thread-1:60826 ] - [ INFO ]  Task:attempt_local815155349_0043_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:12  [ pool-132-thread-1:60832 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:12  [ pool-132-thread-1:60832 ] - [ INFO ]  Task attempt_local815155349_0043_r_000000_0 is allowed to commit now
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  Saved output of task 'attempt_local815155349_0043_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local815155349_0043_r_000000
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  Task 'attempt_local815155349_0043_r_000000_0' done.
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  Finishing task: attempt_local815155349_0043_r_000000_0
2020-11-19 10:19:12  [ Thread-1278:60849 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]  Job job_local815155349_0043 running in uber mode : false
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]  Job job_local815155349_0043 completed successfully
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=132580
		FILE: Number of bytes written=24601183
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2766546
		HDFS: Number of bytes written=45160
		HDFS: Number of read operations=2849
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=926
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2706898944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:13  [ main:61974 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:13  [ main:61984 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:13  [ main:61989 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:13  [ main:61997 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:14  [ main:62035 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:14  [ main:62052 ] - [ INFO ]  Submitting tokens for job: job_local545838815_0044
2020-11-19 10:19:14  [ main:62084 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:14  [ main:62084 ] - [ INFO ]  Running job: job_local545838815_0044
2020-11-19 10:19:14  [ Thread-1308:62084 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:14  [ Thread-1308:62084 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:14  [ Thread-1308:62085 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:14  [ Thread-1308:62091 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]  Starting task: attempt_local545838815_0044_m_000000_0
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62092 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62176 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62177 ] - [ INFO ]  Task:attempt_local545838815_0044_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62183 ] - [ INFO ]  map
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62183 ] - [ INFO ]  Task 'attempt_local545838815_0044_m_000000_0' done.
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62183 ] - [ INFO ]  Finishing task: attempt_local545838815_0044_m_000000_0
2020-11-19 10:19:14  [ Thread-1308:62183 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:14  [ Thread-1308:62183 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:14  [ pool-135-thread-1:62183 ] - [ INFO ]  Starting task: attempt_local545838815_0044_r_000000_0
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5117456f
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:14  [ EventFetcher for fetching Map Completion Events:62184 ] - [ INFO ]  attempt_local545838815_0044_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:14  [ localfetcher#44:62185 ] - [ INFO ]  localfetcher#44 about to shuffle output of map attempt_local545838815_0044_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:14  [ localfetcher#44:62185 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local545838815_0044_m_000000_0
2020-11-19 10:19:14  [ localfetcher#44:62185 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:14  [ EventFetcher for fetching Map Completion Events:62185 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:14  [ pool-135-thread-1:62242 ] - [ INFO ]  Task:attempt_local545838815_0044_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:14  [ pool-135-thread-1:62247 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:14  [ pool-135-thread-1:62247 ] - [ INFO ]  Task attempt_local545838815_0044_r_000000_0 is allowed to commit now
2020-11-19 10:19:14  [ pool-135-thread-1:62265 ] - [ INFO ]  Saved output of task 'attempt_local545838815_0044_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local545838815_0044_r_000000
2020-11-19 10:19:14  [ pool-135-thread-1:62266 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:14  [ pool-135-thread-1:62266 ] - [ INFO ]  Task 'attempt_local545838815_0044_r_000000_0' done.
2020-11-19 10:19:14  [ pool-135-thread-1:62266 ] - [ INFO ]  Finishing task: attempt_local545838815_0044_r_000000_0
2020-11-19 10:19:14  [ Thread-1308:62266 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]  Job job_local545838815_0044 running in uber mode : false
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]  Job job_local545838815_0044 completed successfully
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=133772
		FILE: Number of bytes written=25170058
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2830952
		HDFS: Number of bytes written=46240
		HDFS: Number of read operations=2917
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=948
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:15  [ main:63367 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:15  [ main:63380 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:15  [ main:63385 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:15  [ main:63389 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:15  [ main:63429 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:15  [ main:63446 ] - [ INFO ]  Submitting tokens for job: job_local812009207_0045
2020-11-19 10:19:15  [ main:63475 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:15  [ main:63476 ] - [ INFO ]  Running job: job_local812009207_0045
2020-11-19 10:19:15  [ Thread-1338:63476 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:15  [ Thread-1338:63476 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:15  [ Thread-1338:63476 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:15  [ Thread-1338:63482 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63482 ] - [ INFO ]  Starting task: attempt_local812009207_0045_m_000000_0
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63490 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63564 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63565 ] - [ INFO ]  Task:attempt_local812009207_0045_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63571 ] - [ INFO ]  map
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63571 ] - [ INFO ]  Task 'attempt_local812009207_0045_m_000000_0' done.
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63571 ] - [ INFO ]  Finishing task: attempt_local812009207_0045_m_000000_0
2020-11-19 10:19:15  [ Thread-1338:63571 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:15  [ Thread-1338:63571 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:15  [ pool-138-thread-1:63571 ] - [ INFO ]  Starting task: attempt_local812009207_0045_r_000000_0
2020-11-19 10:19:15  [ pool-138-thread-1:63571 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cf8d531
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:15  [ EventFetcher for fetching Map Completion Events:63572 ] - [ INFO ]  attempt_local812009207_0045_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:15  [ localfetcher#45:63573 ] - [ INFO ]  localfetcher#45 about to shuffle output of map attempt_local812009207_0045_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:15  [ localfetcher#45:63573 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local812009207_0045_m_000000_0
2020-11-19 10:19:15  [ localfetcher#45:63573 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:15  [ EventFetcher for fetching Map Completion Events:63573 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:15  [ pool-138-thread-1:63628 ] - [ INFO ]  Task:attempt_local812009207_0045_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:15  [ pool-138-thread-1:63634 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:15  [ pool-138-thread-1:63634 ] - [ INFO ]  Task attempt_local812009207_0045_r_000000_0 is allowed to commit now
2020-11-19 10:19:15  [ pool-138-thread-1:63650 ] - [ INFO ]  Saved output of task 'attempt_local812009207_0045_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local812009207_0045_r_000000
2020-11-19 10:19:15  [ pool-138-thread-1:63651 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:15  [ pool-138-thread-1:63651 ] - [ INFO ]  Task 'attempt_local812009207_0045_r_000000_0' done.
2020-11-19 10:19:15  [ pool-138-thread-1:63651 ] - [ INFO ]  Finishing task: attempt_local812009207_0045_r_000000_0
2020-11-19 10:19:15  [ Thread-1338:63651 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:16  [ main:64477 ] - [ INFO ]  Job job_local812009207_0045 running in uber mode : false
2020-11-19 10:19:16  [ main:64477 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:16  [ main:64477 ] - [ INFO ]  Job job_local812009207_0045 completed successfully
2020-11-19 10:19:16  [ main:64478 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=134962
		FILE: Number of bytes written=25738932
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2895358
		HDFS: Number of bytes written=47320
		HDFS: Number of read operations=2985
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=970
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:16  [ main:64748 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:16  [ main:64759 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:16  [ main:64764 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:16  [ main:64770 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:16  [ main:64811 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:16  [ main:64828 ] - [ INFO ]  Submitting tokens for job: job_local1820082500_0046
2020-11-19 10:19:16  [ main:64859 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:16  [ main:64859 ] - [ INFO ]  Running job: job_local1820082500_0046
2020-11-19 10:19:16  [ Thread-1368:64859 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:16  [ Thread-1368:64859 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:16  [ Thread-1368:64859 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:16  [ Thread-1368:64867 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64867 ] - [ INFO ]  Starting task: attempt_local1820082500_0046_m_000000_0
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64867 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64867 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64868 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64868 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64947 ] - [ INFO ]  
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64947 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64948 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64948 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64948 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64949 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64950 ] - [ INFO ]  Task:attempt_local1820082500_0046_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64956 ] - [ INFO ]  map
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64956 ] - [ INFO ]  Task 'attempt_local1820082500_0046_m_000000_0' done.
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64956 ] - [ INFO ]  Finishing task: attempt_local1820082500_0046_m_000000_0
2020-11-19 10:19:16  [ Thread-1368:64956 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:16  [ Thread-1368:64956 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  Starting task: attempt_local1820082500_0046_r_000000_0
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6343ed77
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:16  [ EventFetcher for fetching Map Completion Events:64958 ] - [ INFO ]  attempt_local1820082500_0046_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:16  [ localfetcher#46:64958 ] - [ INFO ]  localfetcher#46 about to shuffle output of map attempt_local1820082500_0046_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:16  [ localfetcher#46:64959 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1820082500_0046_m_000000_0
2020-11-19 10:19:16  [ localfetcher#46:64959 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:16  [ EventFetcher for fetching Map Completion Events:64959 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:16  [ pool-141-thread-1:64959 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:16  [ pool-141-thread-1:64959 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:16  [ pool-141-thread-1:64960 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:16  [ pool-141-thread-1:64960 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:16  [ pool-141-thread-1:64960 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:17  [ pool-141-thread-1:65013 ] - [ INFO ]  Task:attempt_local1820082500_0046_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:17  [ pool-141-thread-1:65019 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:17  [ pool-141-thread-1:65019 ] - [ INFO ]  Task attempt_local1820082500_0046_r_000000_0 is allowed to commit now
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  Saved output of task 'attempt_local1820082500_0046_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1820082500_0046_r_000000
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  Task 'attempt_local1820082500_0046_r_000000_0' done.
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  Finishing task: attempt_local1820082500_0046_r_000000_0
2020-11-19 10:19:17  [ Thread-1368:65049 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:17  [ main:65859 ] - [ INFO ]  Job job_local1820082500_0046 running in uber mode : false
2020-11-19 10:19:17  [ main:65859 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:17  [ main:65859 ] - [ INFO ]  Job job_local1820082500_0046 completed successfully
2020-11-19 10:19:17  [ main:65860 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=136154
		FILE: Number of bytes written=26310857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2959764
		HDFS: Number of bytes written=48400
		HDFS: Number of read operations=3053
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=992
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:18  [ main:66337 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:18  [ main:66349 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:18  [ main:66353 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:18  [ main:66359 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:18  [ main:66398 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:18  [ main:66415 ] - [ INFO ]  Submitting tokens for job: job_local945525481_0047
2020-11-19 10:19:18  [ main:66444 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:18  [ main:66444 ] - [ INFO ]  Running job: job_local945525481_0047
2020-11-19 10:19:18  [ Thread-1398:66444 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:18  [ Thread-1398:66444 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:18  [ Thread-1398:66445 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:18  [ Thread-1398:66452 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]  Starting task: attempt_local945525481_0047_m_000000_0
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66453 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66531 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66532 ] - [ INFO ]  Task:attempt_local945525481_0047_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66538 ] - [ INFO ]  map
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66538 ] - [ INFO ]  Task 'attempt_local945525481_0047_m_000000_0' done.
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66538 ] - [ INFO ]  Finishing task: attempt_local945525481_0047_m_000000_0
2020-11-19 10:19:18  [ Thread-1398:66538 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:18  [ Thread-1398:66538 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:18  [ pool-144-thread-1:66538 ] - [ INFO ]  Starting task: attempt_local945525481_0047_r_000000_0
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f29e0de
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:18  [ EventFetcher for fetching Map Completion Events:66539 ] - [ INFO ]  attempt_local945525481_0047_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:18  [ localfetcher#47:66540 ] - [ INFO ]  localfetcher#47 about to shuffle output of map attempt_local945525481_0047_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:18  [ localfetcher#47:66540 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local945525481_0047_m_000000_0
2020-11-19 10:19:18  [ localfetcher#47:66540 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:18  [ EventFetcher for fetching Map Completion Events:66540 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:18  [ pool-144-thread-1:66581 ] - [ INFO ]  Task:attempt_local945525481_0047_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:18  [ pool-144-thread-1:66587 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:18  [ pool-144-thread-1:66587 ] - [ INFO ]  Task attempt_local945525481_0047_r_000000_0 is allowed to commit now
2020-11-19 10:19:18  [ pool-144-thread-1:66602 ] - [ INFO ]  Saved output of task 'attempt_local945525481_0047_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local945525481_0047_r_000000
2020-11-19 10:19:18  [ pool-144-thread-1:66603 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:18  [ pool-144-thread-1:66603 ] - [ INFO ]  Task 'attempt_local945525481_0047_r_000000_0' done.
2020-11-19 10:19:18  [ pool-144-thread-1:66603 ] - [ INFO ]  Finishing task: attempt_local945525481_0047_r_000000_0
2020-11-19 10:19:18  [ Thread-1398:66603 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:19  [ main:67447 ] - [ INFO ]  Job job_local945525481_0047 running in uber mode : false
2020-11-19 10:19:19  [ main:67448 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:19  [ main:67448 ] - [ INFO ]  Job job_local945525481_0047 completed successfully
2020-11-19 10:19:19  [ main:67448 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=137346
		FILE: Number of bytes written=26879732
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3024170
		HDFS: Number of bytes written=49480
		HDFS: Number of read operations=3121
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1014
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:19  [ main:67855 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:19  [ main:67866 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:19  [ main:67870 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:19  [ main:67876 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:19  [ main:67916 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:19  [ main:67933 ] - [ INFO ]  Submitting tokens for job: job_local1943269184_0048
2020-11-19 10:19:19  [ main:67964 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:19  [ main:67964 ] - [ INFO ]  Running job: job_local1943269184_0048
2020-11-19 10:19:19  [ Thread-1428:67964 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:19  [ Thread-1428:67964 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:19  [ Thread-1428:67964 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:19  [ Thread-1428:67972 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]  Starting task: attempt_local1943269184_0048_m_000000_0
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67973 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67982 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67982 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67982 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67983 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67983 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67983 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68047 ] - [ INFO ]  
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68047 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68047 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68048 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68048 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68049 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68050 ] - [ INFO ]  Task:attempt_local1943269184_0048_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68057 ] - [ INFO ]  map
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68057 ] - [ INFO ]  Task 'attempt_local1943269184_0048_m_000000_0' done.
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68057 ] - [ INFO ]  Finishing task: attempt_local1943269184_0048_m_000000_0
2020-11-19 10:19:20  [ Thread-1428:68057 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:20  [ Thread-1428:68057 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:20  [ pool-147-thread-1:68057 ] - [ INFO ]  Starting task: attempt_local1943269184_0048_r_000000_0
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2bdd98c0
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:20  [ EventFetcher for fetching Map Completion Events:68058 ] - [ INFO ]  attempt_local1943269184_0048_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:20  [ localfetcher#48:68059 ] - [ INFO ]  localfetcher#48 about to shuffle output of map attempt_local1943269184_0048_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:20  [ localfetcher#48:68059 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1943269184_0048_m_000000_0
2020-11-19 10:19:20  [ localfetcher#48:68059 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:20  [ EventFetcher for fetching Map Completion Events:68059 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:20  [ pool-147-thread-1:68116 ] - [ INFO ]  Task:attempt_local1943269184_0048_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:20  [ pool-147-thread-1:68122 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:20  [ pool-147-thread-1:68122 ] - [ INFO ]  Task attempt_local1943269184_0048_r_000000_0 is allowed to commit now
2020-11-19 10:19:20  [ pool-147-thread-1:68138 ] - [ INFO ]  Saved output of task 'attempt_local1943269184_0048_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1943269184_0048_r_000000
2020-11-19 10:19:20  [ pool-147-thread-1:68138 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:20  [ pool-147-thread-1:68139 ] - [ INFO ]  Task 'attempt_local1943269184_0048_r_000000_0' done.
2020-11-19 10:19:20  [ pool-147-thread-1:68139 ] - [ INFO ]  Finishing task: attempt_local1943269184_0048_r_000000_0
2020-11-19 10:19:20  [ Thread-1428:68139 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:20  [ main:68968 ] - [ INFO ]  Job job_local1943269184_0048 running in uber mode : false
2020-11-19 10:19:20  [ main:68968 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:20  [ main:68968 ] - [ INFO ]  Job job_local1943269184_0048 completed successfully
2020-11-19 10:19:20  [ main:68969 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=138536
		FILE: Number of bytes written=27451654
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3088576
		HDFS: Number of bytes written=50560
		HDFS: Number of read operations=3189
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1036
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:21  [ main:69434 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:21  [ main:69446 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:21  [ main:69451 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:21  [ main:69457 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:21  [ main:69499 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:21  [ main:69516 ] - [ INFO ]  Submitting tokens for job: job_local375415053_0049
2020-11-19 10:19:21  [ main:69548 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:21  [ main:69548 ] - [ INFO ]  Running job: job_local375415053_0049
2020-11-19 10:19:21  [ Thread-1458:69548 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:21  [ Thread-1458:69548 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:21  [ Thread-1458:69548 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:21  [ Thread-1458:69558 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69558 ] - [ INFO ]  Starting task: attempt_local375415053_0049_m_000000_0
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69761 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69762 ] - [ INFO ]  Task:attempt_local375415053_0049_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69768 ] - [ INFO ]  map
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69768 ] - [ INFO ]  Task 'attempt_local375415053_0049_m_000000_0' done.
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69768 ] - [ INFO ]  Finishing task: attempt_local375415053_0049_m_000000_0
2020-11-19 10:19:21  [ Thread-1458:69769 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:21  [ Thread-1458:69769 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]  Starting task: attempt_local375415053_0049_r_000000_0
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:21  [ pool-150-thread-1:69770 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@499ee14c
2020-11-19 10:19:21  [ pool-150-thread-1:69770 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:21  [ EventFetcher for fetching Map Completion Events:69770 ] - [ INFO ]  attempt_local375415053_0049_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:21  [ localfetcher#49:69771 ] - [ INFO ]  localfetcher#49 about to shuffle output of map attempt_local375415053_0049_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:21  [ localfetcher#49:69771 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local375415053_0049_m_000000_0
2020-11-19 10:19:21  [ localfetcher#49:69771 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:21  [ EventFetcher for fetching Map Completion Events:69771 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:21  [ pool-150-thread-1:69771 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:21  [ pool-150-thread-1:69771 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:21  [ pool-150-thread-1:69772 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:21  [ pool-150-thread-1:69772 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:21  [ pool-150-thread-1:69812 ] - [ INFO ]  Task:attempt_local375415053_0049_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:21  [ pool-150-thread-1:69818 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:21  [ pool-150-thread-1:69818 ] - [ INFO ]  Task attempt_local375415053_0049_r_000000_0 is allowed to commit now
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  Saved output of task 'attempt_local375415053_0049_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local375415053_0049_r_000000
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  Task 'attempt_local375415053_0049_r_000000_0' done.
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  Finishing task: attempt_local375415053_0049_r_000000_0
2020-11-19 10:19:21  [ Thread-1458:69835 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:22  [ main:70552 ] - [ INFO ]  Job job_local375415053_0049 running in uber mode : false
2020-11-19 10:19:22  [ main:70553 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:22  [ main:70553 ] - [ INFO ]  Job job_local375415053_0049 completed successfully
2020-11-19 10:19:22  [ main:70553 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=139728
		FILE: Number of bytes written=28020531
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3152982
		HDFS: Number of bytes written=51640
		HDFS: Number of read operations=3257
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1058
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:22  [ main:70846 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:22  [ main:70861 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:22  [ main:70866 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:22  [ main:70872 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:22  [ main:70911 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:22  [ main:70928 ] - [ INFO ]  Submitting tokens for job: job_local1436142197_0050
2020-11-19 10:19:22  [ main:70968 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:22  [ main:70968 ] - [ INFO ]  Running job: job_local1436142197_0050
2020-11-19 10:19:22  [ Thread-1488:70968 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:22  [ Thread-1488:70968 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:22  [ Thread-1488:70968 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:22  [ Thread-1488:70975 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]  Starting task: attempt_local1436142197_0050_m_000000_0
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70976 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71049 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71050 ] - [ INFO ]  Task:attempt_local1436142197_0050_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71057 ] - [ INFO ]  map
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71057 ] - [ INFO ]  Task 'attempt_local1436142197_0050_m_000000_0' done.
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71057 ] - [ INFO ]  Finishing task: attempt_local1436142197_0050_m_000000_0
2020-11-19 10:19:23  [ Thread-1488:71057 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:23  [ Thread-1488:71057 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:23  [ pool-153-thread-1:71057 ] - [ INFO ]  Starting task: attempt_local1436142197_0050_r_000000_0
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1456ec6
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:23  [ EventFetcher for fetching Map Completion Events:71058 ] - [ INFO ]  attempt_local1436142197_0050_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:23  [ localfetcher#50:71059 ] - [ INFO ]  localfetcher#50 about to shuffle output of map attempt_local1436142197_0050_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:23  [ localfetcher#50:71059 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1436142197_0050_m_000000_0
2020-11-19 10:19:23  [ localfetcher#50:71059 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:23  [ EventFetcher for fetching Map Completion Events:71059 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:23  [ pool-153-thread-1:71060 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:23  [ pool-153-thread-1:71060 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:23  [ pool-153-thread-1:71060 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:23  [ pool-153-thread-1:71113 ] - [ INFO ]  Task:attempt_local1436142197_0050_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:23  [ pool-153-thread-1:71119 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:23  [ pool-153-thread-1:71119 ] - [ INFO ]  Task attempt_local1436142197_0050_r_000000_0 is allowed to commit now
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  Saved output of task 'attempt_local1436142197_0050_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1436142197_0050_r_000000
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  Task 'attempt_local1436142197_0050_r_000000_0' done.
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  Finishing task: attempt_local1436142197_0050_r_000000_0
2020-11-19 10:19:23  [ Thread-1488:71137 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:23  [ main:71973 ] - [ INFO ]  Job job_local1436142197_0050 running in uber mode : false
2020-11-19 10:19:23  [ main:71973 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:23  [ main:71974 ] - [ INFO ]  Job job_local1436142197_0050 completed successfully
2020-11-19 10:19:23  [ main:71974 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=140920
		FILE: Number of bytes written=28592454
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3217388
		HDFS: Number of bytes written=52720
		HDFS: Number of read operations=3325
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1080
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:24  [ main:72382 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:24  [ main:72392 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:24  [ main:72397 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:24  [ main:72408 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:24  [ main:72452 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:24  [ main:72468 ] - [ INFO ]  Submitting tokens for job: job_local953586171_0051
2020-11-19 10:19:24  [ main:72499 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:24  [ main:72499 ] - [ INFO ]  Running job: job_local953586171_0051
2020-11-19 10:19:24  [ Thread-1518:72499 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:24  [ Thread-1518:72499 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:24  [ Thread-1518:72499 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:24  [ Thread-1518:72506 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72506 ] - [ INFO ]  Starting task: attempt_local953586171_0051_m_000000_0
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72515 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72581 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72582 ] - [ INFO ]  Task:attempt_local953586171_0051_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72589 ] - [ INFO ]  map
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72590 ] - [ INFO ]  Task 'attempt_local953586171_0051_m_000000_0' done.
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72590 ] - [ INFO ]  Finishing task: attempt_local953586171_0051_m_000000_0
2020-11-19 10:19:24  [ Thread-1518:72590 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:24  [ Thread-1518:72590 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:24  [ pool-156-thread-1:72590 ] - [ INFO ]  Starting task: attempt_local953586171_0051_r_000000_0
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67887e5a
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:24  [ EventFetcher for fetching Map Completion Events:72591 ] - [ INFO ]  attempt_local953586171_0051_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:24  [ localfetcher#51:72592 ] - [ INFO ]  localfetcher#51 about to shuffle output of map attempt_local953586171_0051_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:24  [ localfetcher#51:72592 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local953586171_0051_m_000000_0
2020-11-19 10:19:24  [ localfetcher#51:72592 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:24  [ EventFetcher for fetching Map Completion Events:72592 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:24  [ pool-156-thread-1:72639 ] - [ INFO ]  Task:attempt_local953586171_0051_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:24  [ pool-156-thread-1:72646 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:24  [ pool-156-thread-1:72646 ] - [ INFO ]  Task attempt_local953586171_0051_r_000000_0 is allowed to commit now
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  Saved output of task 'attempt_local953586171_0051_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local953586171_0051_r_000000
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  Task 'attempt_local953586171_0051_r_000000_0' done.
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  Finishing task: attempt_local953586171_0051_r_000000_0
2020-11-19 10:19:24  [ Thread-1518:72666 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]  Job job_local953586171_0051 running in uber mode : false
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]  Job job_local953586171_0051 completed successfully
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=142110
		FILE: Number of bytes written=29161328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3281794
		HDFS: Number of bytes written=53800
		HDFS: Number of read operations=3393
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1102
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:25  [ main:73782 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:25  [ main:73793 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:25  [ main:73798 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:25  [ main:73803 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:25  [ main:73843 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:25  [ main:73860 ] - [ INFO ]  Submitting tokens for job: job_local1757105829_0052
2020-11-19 10:19:25  [ main:73890 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:25  [ main:73890 ] - [ INFO ]  Running job: job_local1757105829_0052
2020-11-19 10:19:25  [ Thread-1548:73890 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:25  [ Thread-1548:73890 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:25  [ Thread-1548:73890 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:25  [ Thread-1548:73897 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73897 ] - [ INFO ]  Starting task: attempt_local1757105829_0052_m_000000_0
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73911 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73982 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73983 ] - [ INFO ]  Task:attempt_local1757105829_0052_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73990 ] - [ INFO ]  map
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73990 ] - [ INFO ]  Task 'attempt_local1757105829_0052_m_000000_0' done.
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73990 ] - [ INFO ]  Finishing task: attempt_local1757105829_0052_m_000000_0
2020-11-19 10:19:25  [ Thread-1548:73990 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:25  [ Thread-1548:73990 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:25  [ pool-159-thread-1:73990 ] - [ INFO ]  Starting task: attempt_local1757105829_0052_r_000000_0
2020-11-19 10:19:25  [ pool-159-thread-1:73990 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77fe45be
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:25  [ EventFetcher for fetching Map Completion Events:73991 ] - [ INFO ]  attempt_local1757105829_0052_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:25  [ localfetcher#52:73992 ] - [ INFO ]  localfetcher#52 about to shuffle output of map attempt_local1757105829_0052_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:25  [ localfetcher#52:73992 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1757105829_0052_m_000000_0
2020-11-19 10:19:25  [ localfetcher#52:73992 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:25  [ EventFetcher for fetching Map Completion Events:73992 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:26  [ pool-159-thread-1:74055 ] - [ INFO ]  Task:attempt_local1757105829_0052_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:26  [ pool-159-thread-1:74063 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:26  [ pool-159-thread-1:74063 ] - [ INFO ]  Task attempt_local1757105829_0052_r_000000_0 is allowed to commit now
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  Saved output of task 'attempt_local1757105829_0052_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1757105829_0052_r_000000
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  Task 'attempt_local1757105829_0052_r_000000_0' done.
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  Finishing task: attempt_local1757105829_0052_r_000000_0
2020-11-19 10:19:26  [ Thread-1548:74083 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:26  [ main:74890 ] - [ INFO ]  Job job_local1757105829_0052 running in uber mode : false
2020-11-19 10:19:26  [ main:74890 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:26  [ main:74891 ] - [ INFO ]  Job job_local1757105829_0052 completed successfully
2020-11-19 10:19:26  [ main:74891 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=143302
		FILE: Number of bytes written=29733253
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3346200
		HDFS: Number of bytes written=54880
		HDFS: Number of read operations=3461
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1124
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:27  [ main:75163 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:27  [ main:75176 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:27  [ main:75181 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:27  [ main:75187 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:27  [ main:75227 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:27  [ main:75246 ] - [ INFO ]  Submitting tokens for job: job_local403055273_0053
2020-11-19 10:19:27  [ main:75284 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:27  [ main:75284 ] - [ INFO ]  Running job: job_local403055273_0053
2020-11-19 10:19:27  [ Thread-1578:75285 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:27  [ Thread-1578:75285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:27  [ Thread-1578:75285 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:27  [ Thread-1578:75292 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75292 ] - [ INFO ]  Starting task: attempt_local403055273_0053_m_000000_0
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75292 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75292 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75293 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75293 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75367 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75368 ] - [ INFO ]  Task:attempt_local403055273_0053_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75375 ] - [ INFO ]  map
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75375 ] - [ INFO ]  Task 'attempt_local403055273_0053_m_000000_0' done.
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75375 ] - [ INFO ]  Finishing task: attempt_local403055273_0053_m_000000_0
2020-11-19 10:19:27  [ Thread-1578:75375 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:27  [ Thread-1578:75375 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:27  [ pool-162-thread-1:75375 ] - [ INFO ]  Starting task: attempt_local403055273_0053_r_000000_0
2020-11-19 10:19:27  [ pool-162-thread-1:75375 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ebc9bbf
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:27  [ EventFetcher for fetching Map Completion Events:75376 ] - [ INFO ]  attempt_local403055273_0053_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:27  [ localfetcher#53:75377 ] - [ INFO ]  localfetcher#53 about to shuffle output of map attempt_local403055273_0053_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:27  [ localfetcher#53:75377 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local403055273_0053_m_000000_0
2020-11-19 10:19:27  [ localfetcher#53:75377 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:27  [ EventFetcher for fetching Map Completion Events:75377 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:27  [ pool-162-thread-1:75377 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:27  [ pool-162-thread-1:75377 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:27  [ pool-162-thread-1:75378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:27  [ pool-162-thread-1:75378 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:27  [ pool-162-thread-1:75428 ] - [ INFO ]  Task:attempt_local403055273_0053_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:27  [ pool-162-thread-1:75434 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:27  [ pool-162-thread-1:75434 ] - [ INFO ]  Task attempt_local403055273_0053_r_000000_0 is allowed to commit now
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  Saved output of task 'attempt_local403055273_0053_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local403055273_0053_r_000000
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  Task 'attempt_local403055273_0053_r_000000_0' done.
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  Finishing task: attempt_local403055273_0053_r_000000_0
2020-11-19 10:19:27  [ Thread-1578:75451 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:28  [ main:76288 ] - [ INFO ]  Job job_local403055273_0053 running in uber mode : false
2020-11-19 10:19:28  [ main:76288 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:28  [ main:76288 ] - [ INFO ]  Job job_local403055273_0053 completed successfully
2020-11-19 10:19:28  [ main:76289 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=144494
		FILE: Number of bytes written=30302128
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3410606
		HDFS: Number of bytes written=55960
		HDFS: Number of read operations=3529
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1146
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:28  [ main:76922 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:28  [ main:76945 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:28  [ main:76949 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:28  [ main:76965 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:29  [ main:77017 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:29  [ main:77034 ] - [ INFO ]  Submitting tokens for job: job_local2007103891_0054
2020-11-19 10:19:29  [ main:77065 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:29  [ main:77065 ] - [ INFO ]  Running job: job_local2007103891_0054
2020-11-19 10:19:29  [ Thread-1608:77065 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:29  [ Thread-1608:77065 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:29  [ Thread-1608:77065 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:29  [ Thread-1608:77085 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]  Starting task: attempt_local2007103891_0054_m_000000_0
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77086 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77273 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77274 ] - [ INFO ]  Task:attempt_local2007103891_0054_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77293 ] - [ INFO ]  map
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77293 ] - [ INFO ]  Task 'attempt_local2007103891_0054_m_000000_0' done.
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77293 ] - [ INFO ]  Finishing task: attempt_local2007103891_0054_m_000000_0
2020-11-19 10:19:29  [ Thread-1608:77293 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:29  [ Thread-1608:77293 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  Starting task: attempt_local2007103891_0054_r_000000_0
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59ad20a7
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:29  [ EventFetcher for fetching Map Completion Events:77295 ] - [ INFO ]  attempt_local2007103891_0054_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:29  [ localfetcher#54:77295 ] - [ INFO ]  localfetcher#54 about to shuffle output of map attempt_local2007103891_0054_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:29  [ localfetcher#54:77295 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2007103891_0054_m_000000_0
2020-11-19 10:19:29  [ localfetcher#54:77295 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:29  [ EventFetcher for fetching Map Completion Events:77296 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:29  [ pool-165-thread-1:77296 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:29  [ pool-165-thread-1:77296 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:29  [ pool-165-thread-1:77298 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:29  [ pool-165-thread-1:77427 ] - [ INFO ]  Task:attempt_local2007103891_0054_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:29  [ pool-165-thread-1:77442 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:29  [ pool-165-thread-1:77443 ] - [ INFO ]  Task attempt_local2007103891_0054_r_000000_0 is allowed to commit now
2020-11-19 10:19:29  [ pool-165-thread-1:77488 ] - [ INFO ]  Saved output of task 'attempt_local2007103891_0054_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2007103891_0054_r_000000
2020-11-19 10:19:29  [ pool-165-thread-1:77489 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:29  [ pool-165-thread-1:77489 ] - [ INFO ]  Task 'attempt_local2007103891_0054_r_000000_0' done.
2020-11-19 10:19:29  [ pool-165-thread-1:77489 ] - [ INFO ]  Finishing task: attempt_local2007103891_0054_r_000000_0
2020-11-19 10:19:29  [ Thread-1608:77489 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]  Job job_local2007103891_0054 running in uber mode : false
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]  Job job_local2007103891_0054 completed successfully
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=145684
		FILE: Number of bytes written=30874050
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3475012
		HDFS: Number of bytes written=57040
		HDFS: Number of read operations=3597
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1168
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:30  [ main:78749 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:30  [ main:78770 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:30  [ main:78775 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:30  [ main:78789 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:30  [ main:78840 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:30  [ main:78856 ] - [ INFO ]  Submitting tokens for job: job_local1354142743_0055
2020-11-19 10:19:30  [ main:78889 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:30  [ main:78889 ] - [ INFO ]  Running job: job_local1354142743_0055
2020-11-19 10:19:30  [ Thread-1638:78889 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:30  [ Thread-1638:78889 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:30  [ Thread-1638:78889 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:30  [ Thread-1638:78907 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78907 ] - [ INFO ]  Starting task: attempt_local1354142743_0055_m_000000_0
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79080 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79081 ] - [ INFO ]  Task:attempt_local1354142743_0055_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79095 ] - [ INFO ]  map
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79095 ] - [ INFO ]  Task 'attempt_local1354142743_0055_m_000000_0' done.
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79095 ] - [ INFO ]  Finishing task: attempt_local1354142743_0055_m_000000_0
2020-11-19 10:19:31  [ Thread-1638:79095 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:31  [ Thread-1638:79095 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:31  [ pool-168-thread-1:79095 ] - [ INFO ]  Starting task: attempt_local1354142743_0055_r_000000_0
2020-11-19 10:19:31  [ pool-168-thread-1:79095 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b599e1e
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:31  [ EventFetcher for fetching Map Completion Events:79096 ] - [ INFO ]  attempt_local1354142743_0055_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:31  [ localfetcher#55:79097 ] - [ INFO ]  localfetcher#55 about to shuffle output of map attempt_local1354142743_0055_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:31  [ localfetcher#55:79097 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1354142743_0055_m_000000_0
2020-11-19 10:19:31  [ localfetcher#55:79097 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:31  [ EventFetcher for fetching Map Completion Events:79097 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:31  [ pool-168-thread-1:79201 ] - [ INFO ]  Task:attempt_local1354142743_0055_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:31  [ pool-168-thread-1:79214 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:31  [ pool-168-thread-1:79214 ] - [ INFO ]  Task attempt_local1354142743_0055_r_000000_0 is allowed to commit now
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  Saved output of task 'attempt_local1354142743_0055_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1354142743_0055_r_000000
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  Task 'attempt_local1354142743_0055_r_000000_0' done.
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  Finishing task: attempt_local1354142743_0055_r_000000_0
2020-11-19 10:19:31  [ Thread-1638:79253 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:31  [ main:79890 ] - [ INFO ]  Job job_local1354142743_0055 running in uber mode : false
2020-11-19 10:19:31  [ main:79890 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:31  [ main:79890 ] - [ INFO ]  Job job_local1354142743_0055 completed successfully
2020-11-19 10:19:31  [ main:79891 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=146876
		FILE: Number of bytes written=31445975
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3539418
		HDFS: Number of bytes written=58120
		HDFS: Number of read operations=3665
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1190
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:32  [ main:80301 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:32  [ main:80313 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:32  [ main:80318 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:32  [ main:80323 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:32  [ main:80363 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:32  [ main:80380 ] - [ INFO ]  Submitting tokens for job: job_local2022973440_0056
2020-11-19 10:19:32  [ main:80412 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:32  [ main:80412 ] - [ INFO ]  Running job: job_local2022973440_0056
2020-11-19 10:19:32  [ Thread-1668:80412 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:32  [ Thread-1668:80412 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:32  [ Thread-1668:80412 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:32  [ Thread-1668:80420 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]  Starting task: attempt_local2022973440_0056_m_000000_0
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80421 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80499 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80499 ] - [ INFO ]  Task:attempt_local2022973440_0056_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80505 ] - [ INFO ]  map
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80505 ] - [ INFO ]  Task 'attempt_local2022973440_0056_m_000000_0' done.
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80505 ] - [ INFO ]  Finishing task: attempt_local2022973440_0056_m_000000_0
2020-11-19 10:19:32  [ Thread-1668:80505 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:32  [ Thread-1668:80505 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:32  [ pool-171-thread-1:80505 ] - [ INFO ]  Starting task: attempt_local2022973440_0056_r_000000_0
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ba0a24
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:32  [ EventFetcher for fetching Map Completion Events:80506 ] - [ INFO ]  attempt_local2022973440_0056_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:32  [ localfetcher#56:80507 ] - [ INFO ]  localfetcher#56 about to shuffle output of map attempt_local2022973440_0056_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:32  [ localfetcher#56:80507 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2022973440_0056_m_000000_0
2020-11-19 10:19:32  [ localfetcher#56:80507 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:32  [ EventFetcher for fetching Map Completion Events:80508 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:32  [ pool-171-thread-1:80551 ] - [ INFO ]  Task:attempt_local2022973440_0056_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:32  [ pool-171-thread-1:80558 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:32  [ pool-171-thread-1:80558 ] - [ INFO ]  Task attempt_local2022973440_0056_r_000000_0 is allowed to commit now
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  Saved output of task 'attempt_local2022973440_0056_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2022973440_0056_r_000000
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  Task 'attempt_local2022973440_0056_r_000000_0' done.
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  Finishing task: attempt_local2022973440_0056_r_000000_0
2020-11-19 10:19:32  [ Thread-1668:80576 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]  Job job_local2022973440_0056 running in uber mode : false
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]  Job job_local2022973440_0056 completed successfully
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=148068
		FILE: Number of bytes written=32017898
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3603824
		HDFS: Number of bytes written=59200
		HDFS: Number of read operations=3733
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1212
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:33  [ main:81777 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:33  [ main:81790 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:33  [ main:81795 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:33  [ main:81801 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:33  [ main:81843 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:33  [ main:81860 ] - [ INFO ]  Submitting tokens for job: job_local1963254711_0057
2020-11-19 10:19:33  [ main:81892 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:33  [ main:81892 ] - [ INFO ]  Running job: job_local1963254711_0057
2020-11-19 10:19:33  [ Thread-1698:81892 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:33  [ Thread-1698:81892 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:33  [ Thread-1698:81892 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:33  [ Thread-1698:81899 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  Starting task: attempt_local1963254711_0057_m_000000_0
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81988 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81989 ] - [ INFO ]  Task:attempt_local1963254711_0057_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81995 ] - [ INFO ]  map
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81995 ] - [ INFO ]  Task 'attempt_local1963254711_0057_m_000000_0' done.
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81995 ] - [ INFO ]  Finishing task: attempt_local1963254711_0057_m_000000_0
2020-11-19 10:19:33  [ Thread-1698:81995 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:33  [ Thread-1698:81995 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:33  [ pool-174-thread-1:81995 ] - [ INFO ]  Starting task: attempt_local1963254711_0057_r_000000_0
2020-11-19 10:19:33  [ pool-174-thread-1:81995 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b3cca9d
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:33  [ EventFetcher for fetching Map Completion Events:81996 ] - [ INFO ]  attempt_local1963254711_0057_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:33  [ localfetcher#57:81997 ] - [ INFO ]  localfetcher#57 about to shuffle output of map attempt_local1963254711_0057_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:33  [ localfetcher#57:81997 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1963254711_0057_m_000000_0
2020-11-19 10:19:33  [ localfetcher#57:81997 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:33  [ EventFetcher for fetching Map Completion Events:81997 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:34  [ pool-174-thread-1:82104 ] - [ INFO ]  Task:attempt_local1963254711_0057_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:34  [ pool-174-thread-1:82111 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:34  [ pool-174-thread-1:82111 ] - [ INFO ]  Task attempt_local1963254711_0057_r_000000_0 is allowed to commit now
2020-11-19 10:19:34  [ pool-174-thread-1:82130 ] - [ INFO ]  Saved output of task 'attempt_local1963254711_0057_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1963254711_0057_r_000000
2020-11-19 10:19:34  [ pool-174-thread-1:82131 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:34  [ pool-174-thread-1:82131 ] - [ INFO ]  Task 'attempt_local1963254711_0057_r_000000_0' done.
2020-11-19 10:19:34  [ pool-174-thread-1:82131 ] - [ INFO ]  Finishing task: attempt_local1963254711_0057_r_000000_0
2020-11-19 10:19:34  [ Thread-1698:82131 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:34  [ main:82893 ] - [ INFO ]  Job job_local1963254711_0057 running in uber mode : false
2020-11-19 10:19:34  [ main:82894 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:34  [ main:82894 ] - [ INFO ]  Job job_local1963254711_0057 completed successfully
2020-11-19 10:19:34  [ main:82894 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=149258
		FILE: Number of bytes written=32589820
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3668230
		HDFS: Number of bytes written=60280
		HDFS: Number of read operations=3801
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1234
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:35  [ main:83176 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:35  [ main:83196 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:35  [ main:83201 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:35  [ main:83211 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:35  [ main:83252 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:35  [ main:83268 ] - [ INFO ]  Submitting tokens for job: job_local721628273_0058
2020-11-19 10:19:35  [ main:83298 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:35  [ main:83298 ] - [ INFO ]  Running job: job_local721628273_0058
2020-11-19 10:19:35  [ Thread-1728:83298 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:35  [ Thread-1728:83298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:35  [ Thread-1728:83298 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:35  [ Thread-1728:83310 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]  Starting task: attempt_local721628273_0058_m_000000_0
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83311 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83390 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83391 ] - [ INFO ]  Task:attempt_local721628273_0058_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83397 ] - [ INFO ]  map
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83397 ] - [ INFO ]  Task 'attempt_local721628273_0058_m_000000_0' done.
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83397 ] - [ INFO ]  Finishing task: attempt_local721628273_0058_m_000000_0
2020-11-19 10:19:35  [ Thread-1728:83397 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:35  [ Thread-1728:83397 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:35  [ pool-177-thread-1:83397 ] - [ INFO ]  Starting task: attempt_local721628273_0058_r_000000_0
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23d0a34c
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:35  [ EventFetcher for fetching Map Completion Events:83398 ] - [ INFO ]  attempt_local721628273_0058_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:35  [ localfetcher#58:83399 ] - [ INFO ]  localfetcher#58 about to shuffle output of map attempt_local721628273_0058_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:35  [ localfetcher#58:83399 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local721628273_0058_m_000000_0
2020-11-19 10:19:35  [ localfetcher#58:83399 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:35  [ EventFetcher for fetching Map Completion Events:83399 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:35  [ pool-177-thread-1:83444 ] - [ INFO ]  Task:attempt_local721628273_0058_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:35  [ pool-177-thread-1:83449 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:35  [ pool-177-thread-1:83449 ] - [ INFO ]  Task attempt_local721628273_0058_r_000000_0 is allowed to commit now
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  Saved output of task 'attempt_local721628273_0058_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local721628273_0058_r_000000
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  Task 'attempt_local721628273_0058_r_000000_0' done.
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  Finishing task: attempt_local721628273_0058_r_000000_0
2020-11-19 10:19:35  [ Thread-1728:83471 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:36  [ main:84301 ] - [ INFO ]  Job job_local721628273_0058 running in uber mode : false
2020-11-19 10:19:36  [ main:84301 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:36  [ main:84302 ] - [ INFO ]  Job job_local721628273_0058 completed successfully
2020-11-19 10:19:36  [ main:84302 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=150450
		FILE: Number of bytes written=33158697
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3732636
		HDFS: Number of bytes written=61360
		HDFS: Number of read operations=3869
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1256
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:36  [ main:84592 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:36  [ main:84603 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:36  [ main:84607 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:36  [ main:84612 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:36  [ main:84651 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:36  [ main:84668 ] - [ INFO ]  Submitting tokens for job: job_local1259128178_0059
2020-11-19 10:19:36  [ main:84698 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:36  [ main:84698 ] - [ INFO ]  Running job: job_local1259128178_0059
2020-11-19 10:19:36  [ Thread-1758:84698 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:36  [ Thread-1758:84698 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:36  [ Thread-1758:84698 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:36  [ Thread-1758:84705 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  Starting task: attempt_local1259128178_0059_m_000000_0
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84778 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84779 ] - [ INFO ]  Task:attempt_local1259128178_0059_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84783 ] - [ INFO ]  map
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84783 ] - [ INFO ]  Task 'attempt_local1259128178_0059_m_000000_0' done.
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84783 ] - [ INFO ]  Finishing task: attempt_local1259128178_0059_m_000000_0
2020-11-19 10:19:36  [ Thread-1758:84783 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:36  [ Thread-1758:84784 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  Starting task: attempt_local1259128178_0059_r_000000_0
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33714d38
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:36  [ EventFetcher for fetching Map Completion Events:84785 ] - [ INFO ]  attempt_local1259128178_0059_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:36  [ localfetcher#59:84785 ] - [ INFO ]  localfetcher#59 about to shuffle output of map attempt_local1259128178_0059_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:36  [ localfetcher#59:84785 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1259128178_0059_m_000000_0
2020-11-19 10:19:36  [ localfetcher#59:84785 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:36  [ EventFetcher for fetching Map Completion Events:84786 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:36  [ pool-180-thread-1:84786 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:36  [ pool-180-thread-1:84786 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:36  [ pool-180-thread-1:84788 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:36  [ pool-180-thread-1:84788 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:36  [ pool-180-thread-1:84828 ] - [ INFO ]  Task:attempt_local1259128178_0059_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:36  [ pool-180-thread-1:84833 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:36  [ pool-180-thread-1:84833 ] - [ INFO ]  Task attempt_local1259128178_0059_r_000000_0 is allowed to commit now
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  Saved output of task 'attempt_local1259128178_0059_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1259128178_0059_r_000000
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  Task 'attempt_local1259128178_0059_r_000000_0' done.
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  Finishing task: attempt_local1259128178_0059_r_000000_0
2020-11-19 10:19:36  [ Thread-1758:84848 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:37  [ main:85703 ] - [ INFO ]  Job job_local1259128178_0059 running in uber mode : false
2020-11-19 10:19:37  [ main:85703 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:37  [ main:85703 ] - [ INFO ]  Job job_local1259128178_0059 completed successfully
2020-11-19 10:19:37  [ main:85704 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=151642
		FILE: Number of bytes written=33730620
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3797042
		HDFS: Number of bytes written=62440
		HDFS: Number of read operations=3937
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1278
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:38  [ main:86093 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:38  [ main:86151 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:38  [ main:86155 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:38  [ main:86162 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:38  [ main:86204 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:38  [ main:86221 ] - [ INFO ]  Submitting tokens for job: job_local939927194_0060
2020-11-19 10:19:38  [ main:86250 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:38  [ main:86250 ] - [ INFO ]  Running job: job_local939927194_0060
2020-11-19 10:19:38  [ Thread-1788:86250 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:38  [ Thread-1788:86250 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:38  [ Thread-1788:86250 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:38  [ Thread-1788:86258 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]  Starting task: attempt_local939927194_0060_m_000000_0
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86259 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86344 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86345 ] - [ INFO ]  Task:attempt_local939927194_0060_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86350 ] - [ INFO ]  map
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86350 ] - [ INFO ]  Task 'attempt_local939927194_0060_m_000000_0' done.
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86350 ] - [ INFO ]  Finishing task: attempt_local939927194_0060_m_000000_0
2020-11-19 10:19:38  [ Thread-1788:86350 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:38  [ Thread-1788:86350 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  Starting task: attempt_local939927194_0060_r_000000_0
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5eada6ee
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:38  [ EventFetcher for fetching Map Completion Events:86352 ] - [ INFO ]  attempt_local939927194_0060_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:38  [ localfetcher#60:86352 ] - [ INFO ]  localfetcher#60 about to shuffle output of map attempt_local939927194_0060_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:38  [ localfetcher#60:86352 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local939927194_0060_m_000000_0
2020-11-19 10:19:38  [ localfetcher#60:86352 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:38  [ EventFetcher for fetching Map Completion Events:86353 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:38  [ pool-183-thread-1:86353 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:38  [ pool-183-thread-1:86353 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:38  [ pool-183-thread-1:86411 ] - [ INFO ]  Task:attempt_local939927194_0060_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:38  [ pool-183-thread-1:86416 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:38  [ pool-183-thread-1:86416 ] - [ INFO ]  Task attempt_local939927194_0060_r_000000_0 is allowed to commit now
2020-11-19 10:19:38  [ pool-183-thread-1:86432 ] - [ INFO ]  Saved output of task 'attempt_local939927194_0060_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local939927194_0060_r_000000
2020-11-19 10:19:38  [ pool-183-thread-1:86433 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:38  [ pool-183-thread-1:86433 ] - [ INFO ]  Task 'attempt_local939927194_0060_r_000000_0' done.
2020-11-19 10:19:38  [ pool-183-thread-1:86433 ] - [ INFO ]  Finishing task: attempt_local939927194_0060_r_000000_0
2020-11-19 10:19:38  [ Thread-1788:86433 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]  Job job_local939927194_0060 running in uber mode : false
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]  Job job_local939927194_0060 completed successfully
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=152832
		FILE: Number of bytes written=34299494
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3861448
		HDFS: Number of bytes written=63520
		HDFS: Number of read operations=4005
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1300
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:39  [ main:87543 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:39  [ main:87555 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:39  [ main:87560 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:39  [ main:87567 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:39  [ main:87607 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:39  [ main:87624 ] - [ INFO ]  Submitting tokens for job: job_local956872601_0061
2020-11-19 10:19:39  [ main:87655 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:39  [ main:87655 ] - [ INFO ]  Running job: job_local956872601_0061
2020-11-19 10:19:39  [ Thread-1818:87655 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:39  [ Thread-1818:87655 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:39  [ Thread-1818:87655 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:39  [ Thread-1818:87662 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]  Starting task: attempt_local956872601_0061_m_000000_0
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87663 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87744 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87745 ] - [ INFO ]  Task:attempt_local956872601_0061_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87752 ] - [ INFO ]  map
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87752 ] - [ INFO ]  Task 'attempt_local956872601_0061_m_000000_0' done.
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87752 ] - [ INFO ]  Finishing task: attempt_local956872601_0061_m_000000_0
2020-11-19 10:19:39  [ Thread-1818:87753 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:39  [ Thread-1818:87753 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:39  [ pool-186-thread-1:87753 ] - [ INFO ]  Starting task: attempt_local956872601_0061_r_000000_0
2020-11-19 10:19:39  [ pool-186-thread-1:87753 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a24610e
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:39  [ EventFetcher for fetching Map Completion Events:87754 ] - [ INFO ]  attempt_local956872601_0061_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:39  [ localfetcher#61:87755 ] - [ INFO ]  localfetcher#61 about to shuffle output of map attempt_local956872601_0061_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:39  [ localfetcher#61:87755 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local956872601_0061_m_000000_0
2020-11-19 10:19:39  [ localfetcher#61:87755 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:39  [ EventFetcher for fetching Map Completion Events:87755 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:39  [ pool-186-thread-1:87755 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:39  [ pool-186-thread-1:87755 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:39  [ pool-186-thread-1:87756 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:39  [ pool-186-thread-1:87756 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:39  [ pool-186-thread-1:87816 ] - [ INFO ]  Task:attempt_local956872601_0061_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:39  [ pool-186-thread-1:87822 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:39  [ pool-186-thread-1:87822 ] - [ INFO ]  Task attempt_local956872601_0061_r_000000_0 is allowed to commit now
2020-11-19 10:19:39  [ pool-186-thread-1:87840 ] - [ INFO ]  Saved output of task 'attempt_local956872601_0061_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local956872601_0061_r_000000
2020-11-19 10:19:39  [ pool-186-thread-1:87841 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:39  [ pool-186-thread-1:87841 ] - [ INFO ]  Task 'attempt_local956872601_0061_r_000000_0' done.
2020-11-19 10:19:39  [ pool-186-thread-1:87841 ] - [ INFO ]  Finishing task: attempt_local956872601_0061_r_000000_0
2020-11-19 10:19:39  [ Thread-1818:87841 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]  Job job_local956872601_0061 running in uber mode : false
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]  Job job_local956872601_0061 completed successfully
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=154024
		FILE: Number of bytes written=34868371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3925854
		HDFS: Number of bytes written=64600
		HDFS: Number of read operations=4073
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1322
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:40  [ main:88927 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:40  [ main:88938 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:40  [ main:88943 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:40  [ main:88949 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:40  [ main:88989 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:41  [ main:89006 ] - [ INFO ]  Submitting tokens for job: job_local197268278_0062
2020-11-19 10:19:41  [ main:89038 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:41  [ main:89039 ] - [ INFO ]  Running job: job_local197268278_0062
2020-11-19 10:19:41  [ Thread-1848:89039 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:41  [ Thread-1848:89039 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:41  [ Thread-1848:89039 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:41  [ Thread-1848:89047 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]  Starting task: attempt_local197268278_0062_m_000000_0
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89048 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89130 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89131 ] - [ INFO ]  Task:attempt_local197268278_0062_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89138 ] - [ INFO ]  map
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89138 ] - [ INFO ]  Task 'attempt_local197268278_0062_m_000000_0' done.
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89138 ] - [ INFO ]  Finishing task: attempt_local197268278_0062_m_000000_0
2020-11-19 10:19:41  [ Thread-1848:89138 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:41  [ Thread-1848:89138 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:41  [ pool-189-thread-1:89138 ] - [ INFO ]  Starting task: attempt_local197268278_0062_r_000000_0
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26a6f0a5
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:41  [ EventFetcher for fetching Map Completion Events:89139 ] - [ INFO ]  attempt_local197268278_0062_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:41  [ localfetcher#62:89140 ] - [ INFO ]  localfetcher#62 about to shuffle output of map attempt_local197268278_0062_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:41  [ localfetcher#62:89140 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local197268278_0062_m_000000_0
2020-11-19 10:19:41  [ localfetcher#62:89140 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:41  [ EventFetcher for fetching Map Completion Events:89140 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:41  [ pool-189-thread-1:89201 ] - [ INFO ]  Task:attempt_local197268278_0062_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:41  [ pool-189-thread-1:89207 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:41  [ pool-189-thread-1:89207 ] - [ INFO ]  Task attempt_local197268278_0062_r_000000_0 is allowed to commit now
2020-11-19 10:19:41  [ pool-189-thread-1:89223 ] - [ INFO ]  Saved output of task 'attempt_local197268278_0062_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local197268278_0062_r_000000
2020-11-19 10:19:41  [ pool-189-thread-1:89224 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:41  [ pool-189-thread-1:89224 ] - [ INFO ]  Task 'attempt_local197268278_0062_r_000000_0' done.
2020-11-19 10:19:41  [ pool-189-thread-1:89224 ] - [ INFO ]  Finishing task: attempt_local197268278_0062_r_000000_0
2020-11-19 10:19:41  [ Thread-1848:89224 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:42  [ main:90040 ] - [ INFO ]  Job job_local197268278_0062 running in uber mode : false
2020-11-19 10:19:42  [ main:90040 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:42  [ main:90040 ] - [ INFO ]  Job job_local197268278_0062 completed successfully
2020-11-19 10:19:42  [ main:90041 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=155216
		FILE: Number of bytes written=35437246
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3990260
		HDFS: Number of bytes written=65680
		HDFS: Number of read operations=4141
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1344
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:42  [ main:90324 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:42  [ main:90335 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:42  [ main:90340 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:42  [ main:90346 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:42  [ main:90387 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:42  [ main:90404 ] - [ INFO ]  Submitting tokens for job: job_local670949491_0063
2020-11-19 10:19:42  [ main:90433 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:42  [ main:90433 ] - [ INFO ]  Running job: job_local670949491_0063
2020-11-19 10:19:42  [ Thread-1878:90433 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:42  [ Thread-1878:90433 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:42  [ Thread-1878:90433 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:42  [ Thread-1878:90442 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90442 ] - [ INFO ]  Starting task: attempt_local670949491_0063_m_000000_0
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90442 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90443 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90443 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90443 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90520 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90521 ] - [ INFO ]  Task:attempt_local670949491_0063_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90527 ] - [ INFO ]  map
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90527 ] - [ INFO ]  Task 'attempt_local670949491_0063_m_000000_0' done.
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90527 ] - [ INFO ]  Finishing task: attempt_local670949491_0063_m_000000_0
2020-11-19 10:19:42  [ Thread-1878:90527 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:42  [ Thread-1878:90527 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  Starting task: attempt_local670949491_0063_r_000000_0
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3fff53ed
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:42  [ EventFetcher for fetching Map Completion Events:90529 ] - [ INFO ]  attempt_local670949491_0063_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:42  [ localfetcher#63:90529 ] - [ INFO ]  localfetcher#63 about to shuffle output of map attempt_local670949491_0063_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:42  [ localfetcher#63:90529 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local670949491_0063_m_000000_0
2020-11-19 10:19:42  [ localfetcher#63:90529 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:42  [ EventFetcher for fetching Map Completion Events:90530 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:42  [ pool-192-thread-1:90530 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:42  [ pool-192-thread-1:90530 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:42  [ pool-192-thread-1:90532 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:42  [ pool-192-thread-1:90532 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:42  [ pool-192-thread-1:90574 ] - [ INFO ]  Task:attempt_local670949491_0063_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:42  [ pool-192-thread-1:90580 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:42  [ pool-192-thread-1:90580 ] - [ INFO ]  Task attempt_local670949491_0063_r_000000_0 is allowed to commit now
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  Saved output of task 'attempt_local670949491_0063_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local670949491_0063_r_000000
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  Task 'attempt_local670949491_0063_r_000000_0' done.
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  Finishing task: attempt_local670949491_0063_r_000000_0
2020-11-19 10:19:42  [ Thread-1878:90598 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:43  [ main:91434 ] - [ INFO ]  Job job_local670949491_0063 running in uber mode : false
2020-11-19 10:19:43  [ main:91435 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:43  [ main:91435 ] - [ INFO ]  Job job_local670949491_0063 completed successfully
2020-11-19 10:19:43  [ main:91435 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=156406
		FILE: Number of bytes written=36006120
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4054666
		HDFS: Number of bytes written=66760
		HDFS: Number of read operations=4209
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1366
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:43  [ main:91694 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:43  [ main:91706 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:43  [ main:91710 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:43  [ main:91716 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:43  [ main:91758 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:43  [ main:91775 ] - [ INFO ]  Submitting tokens for job: job_local1689872815_0064
2020-11-19 10:19:43  [ main:91806 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:43  [ main:91806 ] - [ INFO ]  Running job: job_local1689872815_0064
2020-11-19 10:19:43  [ Thread-1908:91806 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:43  [ Thread-1908:91807 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:43  [ Thread-1908:91807 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:43  [ Thread-1908:91814 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]  Starting task: attempt_local1689872815_0064_m_000000_0
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91815 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91885 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91885 ] - [ INFO ]  Task:attempt_local1689872815_0064_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91891 ] - [ INFO ]  map
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91891 ] - [ INFO ]  Task 'attempt_local1689872815_0064_m_000000_0' done.
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91891 ] - [ INFO ]  Finishing task: attempt_local1689872815_0064_m_000000_0
2020-11-19 10:19:43  [ Thread-1908:91891 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:43  [ Thread-1908:91891 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  Starting task: attempt_local1689872815_0064_r_000000_0
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@557ecf69
2020-11-19 10:19:43  [ pool-195-thread-1:91893 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:43  [ EventFetcher for fetching Map Completion Events:91893 ] - [ INFO ]  attempt_local1689872815_0064_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:43  [ localfetcher#64:91894 ] - [ INFO ]  localfetcher#64 about to shuffle output of map attempt_local1689872815_0064_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:43  [ localfetcher#64:91894 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1689872815_0064_m_000000_0
2020-11-19 10:19:43  [ localfetcher#64:91894 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:43  [ EventFetcher for fetching Map Completion Events:91894 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:43  [ pool-195-thread-1:91894 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:43  [ pool-195-thread-1:91894 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:43  [ pool-195-thread-1:91895 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:43  [ pool-195-thread-1:91895 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:43  [ pool-195-thread-1:91949 ] - [ INFO ]  Task:attempt_local1689872815_0064_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:43  [ pool-195-thread-1:91955 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:43  [ pool-195-thread-1:91955 ] - [ INFO ]  Task attempt_local1689872815_0064_r_000000_0 is allowed to commit now
2020-11-19 10:19:43  [ pool-195-thread-1:91971 ] - [ INFO ]  Saved output of task 'attempt_local1689872815_0064_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1689872815_0064_r_000000
2020-11-19 10:19:43  [ pool-195-thread-1:91973 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:43  [ pool-195-thread-1:91973 ] - [ INFO ]  Task 'attempt_local1689872815_0064_r_000000_0' done.
2020-11-19 10:19:43  [ pool-195-thread-1:91973 ] - [ INFO ]  Finishing task: attempt_local1689872815_0064_r_000000_0
2020-11-19 10:19:43  [ Thread-1908:91973 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:44  [ main:92807 ] - [ INFO ]  Job job_local1689872815_0064 running in uber mode : false
2020-11-19 10:19:44  [ main:92807 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:44  [ main:92807 ] - [ INFO ]  Job job_local1689872815_0064 completed successfully
2020-11-19 10:19:44  [ main:92808 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=157598
		FILE: Number of bytes written=36578045
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4119072
		HDFS: Number of bytes written=67840
		HDFS: Number of read operations=4277
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1388
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:45  [ main:93077 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:45  [ main:93092 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:45  [ main:93097 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:45  [ main:93103 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:45  [ main:93141 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:45  [ main:93158 ] - [ INFO ]  Submitting tokens for job: job_local673703084_0065
2020-11-19 10:19:45  [ main:93187 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:45  [ main:93187 ] - [ INFO ]  Running job: job_local673703084_0065
2020-11-19 10:19:45  [ Thread-1938:93187 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:45  [ Thread-1938:93187 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:45  [ Thread-1938:93187 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:45  [ Thread-1938:93194 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93194 ] - [ INFO ]  Starting task: attempt_local673703084_0065_m_000000_0
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93277 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93278 ] - [ INFO ]  Task:attempt_local673703084_0065_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93284 ] - [ INFO ]  map
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93284 ] - [ INFO ]  Task 'attempt_local673703084_0065_m_000000_0' done.
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93284 ] - [ INFO ]  Finishing task: attempt_local673703084_0065_m_000000_0
2020-11-19 10:19:45  [ Thread-1938:93284 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:45  [ Thread-1938:93285 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  Starting task: attempt_local673703084_0065_r_000000_0
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a5749d5
2020-11-19 10:19:45  [ pool-198-thread-1:93286 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:45  [ EventFetcher for fetching Map Completion Events:93286 ] - [ INFO ]  attempt_local673703084_0065_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:45  [ localfetcher#65:93286 ] - [ INFO ]  localfetcher#65 about to shuffle output of map attempt_local673703084_0065_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:45  [ localfetcher#65:93287 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local673703084_0065_m_000000_0
2020-11-19 10:19:45  [ localfetcher#65:93287 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:45  [ EventFetcher for fetching Map Completion Events:93287 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:45  [ pool-198-thread-1:93287 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:45  [ pool-198-thread-1:93287 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:45  [ pool-198-thread-1:93288 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:45  [ pool-198-thread-1:93288 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:45  [ pool-198-thread-1:93331 ] - [ INFO ]  Task:attempt_local673703084_0065_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:45  [ pool-198-thread-1:93336 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:45  [ pool-198-thread-1:93336 ] - [ INFO ]  Task attempt_local673703084_0065_r_000000_0 is allowed to commit now
2020-11-19 10:19:45  [ pool-198-thread-1:93351 ] - [ INFO ]  Saved output of task 'attempt_local673703084_0065_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local673703084_0065_r_000000
2020-11-19 10:19:45  [ pool-198-thread-1:93351 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:45  [ pool-198-thread-1:93352 ] - [ INFO ]  Task 'attempt_local673703084_0065_r_000000_0' done.
2020-11-19 10:19:45  [ pool-198-thread-1:93352 ] - [ INFO ]  Finishing task: attempt_local673703084_0065_r_000000_0
2020-11-19 10:19:45  [ Thread-1938:93352 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:46  [ main:94189 ] - [ INFO ]  Job job_local673703084_0065 running in uber mode : false
2020-11-19 10:19:46  [ main:94189 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:46  [ main:94190 ] - [ INFO ]  Job job_local673703084_0065 completed successfully
2020-11-19 10:19:46  [ main:94190 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=158790
		FILE: Number of bytes written=37146920
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4183478
		HDFS: Number of bytes written=68920
		HDFS: Number of read operations=4345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1410
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:46  [ main:94462 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:46  [ main:94474 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:46  [ main:94479 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:46  [ main:94485 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:46  [ main:94524 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:46  [ main:94541 ] - [ INFO ]  Submitting tokens for job: job_local1171920739_0066
2020-11-19 10:19:46  [ main:94571 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:46  [ main:94571 ] - [ INFO ]  Running job: job_local1171920739_0066
2020-11-19 10:19:46  [ Thread-1968:94572 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:46  [ Thread-1968:94572 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:46  [ Thread-1968:94572 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:46  [ Thread-1968:94578 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  Starting task: attempt_local1171920739_0066_m_000000_0
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94648 ] - [ INFO ]  
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94650 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94651 ] - [ INFO ]  Task:attempt_local1171920739_0066_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94657 ] - [ INFO ]  map
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94657 ] - [ INFO ]  Task 'attempt_local1171920739_0066_m_000000_0' done.
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94657 ] - [ INFO ]  Finishing task: attempt_local1171920739_0066_m_000000_0
2020-11-19 10:19:46  [ Thread-1968:94658 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:46  [ Thread-1968:94658 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:46  [ pool-201-thread-1:94658 ] - [ INFO ]  Starting task: attempt_local1171920739_0066_r_000000_0
2020-11-19 10:19:46  [ pool-201-thread-1:94658 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72c1e677
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:46  [ EventFetcher for fetching Map Completion Events:94659 ] - [ INFO ]  attempt_local1171920739_0066_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:46  [ localfetcher#66:94660 ] - [ INFO ]  localfetcher#66 about to shuffle output of map attempt_local1171920739_0066_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:46  [ localfetcher#66:94660 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1171920739_0066_m_000000_0
2020-11-19 10:19:46  [ localfetcher#66:94660 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:46  [ EventFetcher for fetching Map Completion Events:94660 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:46  [ pool-201-thread-1:94660 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:46  [ pool-201-thread-1:94660 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:46  [ pool-201-thread-1:94661 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:46  [ pool-201-thread-1:94661 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:46  [ pool-201-thread-1:94713 ] - [ INFO ]  Task:attempt_local1171920739_0066_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:46  [ pool-201-thread-1:94719 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:46  [ pool-201-thread-1:94719 ] - [ INFO ]  Task attempt_local1171920739_0066_r_000000_0 is allowed to commit now
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  Saved output of task 'attempt_local1171920739_0066_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1171920739_0066_r_000000
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  Task 'attempt_local1171920739_0066_r_000000_0' done.
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  Finishing task: attempt_local1171920739_0066_r_000000_0
2020-11-19 10:19:46  [ Thread-1968:94735 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:47  [ main:95572 ] - [ INFO ]  Job job_local1171920739_0066 running in uber mode : false
2020-11-19 10:19:47  [ main:95573 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:47  [ main:95573 ] - [ INFO ]  Job job_local1171920739_0066 completed successfully
2020-11-19 10:19:47  [ main:95573 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=159980
		FILE: Number of bytes written=37718842
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4247884
		HDFS: Number of bytes written=70000
		HDFS: Number of read operations=4413
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1432
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:47  [ main:95841 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:47  [ main:95851 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:47  [ main:95856 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:47  [ main:95862 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:47  [ main:95902 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:47  [ main:95919 ] - [ INFO ]  Submitting tokens for job: job_local989508229_0067
2020-11-19 10:19:47  [ main:95949 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:47  [ main:95949 ] - [ INFO ]  Running job: job_local989508229_0067
2020-11-19 10:19:47  [ Thread-1998:95949 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:47  [ Thread-1998:95949 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:47  [ Thread-1998:95949 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:47  [ Thread-1998:95955 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]  Starting task: attempt_local989508229_0067_m_000000_0
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95956 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96028 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96029 ] - [ INFO ]  Task:attempt_local989508229_0067_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96034 ] - [ INFO ]  map
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96034 ] - [ INFO ]  Task 'attempt_local989508229_0067_m_000000_0' done.
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96034 ] - [ INFO ]  Finishing task: attempt_local989508229_0067_m_000000_0
2020-11-19 10:19:48  [ Thread-1998:96034 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:48  [ Thread-1998:96034 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:48  [ pool-204-thread-1:96034 ] - [ INFO ]  Starting task: attempt_local989508229_0067_r_000000_0
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54cb3a59
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:48  [ EventFetcher for fetching Map Completion Events:96035 ] - [ INFO ]  attempt_local989508229_0067_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:48  [ localfetcher#67:96036 ] - [ INFO ]  localfetcher#67 about to shuffle output of map attempt_local989508229_0067_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:48  [ localfetcher#67:96036 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local989508229_0067_m_000000_0
2020-11-19 10:19:48  [ localfetcher#67:96036 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:48  [ EventFetcher for fetching Map Completion Events:96036 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:48  [ pool-204-thread-1:96036 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:48  [ pool-204-thread-1:96037 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:48  [ pool-204-thread-1:96037 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:48  [ pool-204-thread-1:96037 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:48  [ pool-204-thread-1:96079 ] - [ INFO ]  Task:attempt_local989508229_0067_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:48  [ pool-204-thread-1:96084 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:48  [ pool-204-thread-1:96084 ] - [ INFO ]  Task attempt_local989508229_0067_r_000000_0 is allowed to commit now
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  Saved output of task 'attempt_local989508229_0067_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local989508229_0067_r_000000
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  Task 'attempt_local989508229_0067_r_000000_0' done.
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  Finishing task: attempt_local989508229_0067_r_000000_0
2020-11-19 10:19:48  [ Thread-1998:96100 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]  Job job_local989508229_0067 running in uber mode : false
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]  Job job_local989508229_0067 completed successfully
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=161172
		FILE: Number of bytes written=38287719
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4312290
		HDFS: Number of bytes written=71080
		HDFS: Number of read operations=4481
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1454
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:49  [ main:97207 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:49  [ main:97220 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:49  [ main:97224 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:49  [ main:97230 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:49  [ main:97271 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:49  [ main:97289 ] - [ INFO ]  Submitting tokens for job: job_local852729690_0068
2020-11-19 10:19:49  [ main:97319 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:49  [ main:97319 ] - [ INFO ]  Running job: job_local852729690_0068
2020-11-19 10:19:49  [ Thread-2028:97319 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:49  [ Thread-2028:97319 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:49  [ Thread-2028:97320 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:49  [ Thread-2028:97326 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  Starting task: attempt_local852729690_0068_m_000000_0
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97335 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97400 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97401 ] - [ INFO ]  Task:attempt_local852729690_0068_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97407 ] - [ INFO ]  map
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97407 ] - [ INFO ]  Task 'attempt_local852729690_0068_m_000000_0' done.
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97407 ] - [ INFO ]  Finishing task: attempt_local852729690_0068_m_000000_0
2020-11-19 10:19:49  [ Thread-2028:97407 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:49  [ Thread-2028:97407 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:49  [ pool-207-thread-1:97407 ] - [ INFO ]  Starting task: attempt_local852729690_0068_r_000000_0
2020-11-19 10:19:49  [ pool-207-thread-1:97407 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27c822e5
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:49  [ EventFetcher for fetching Map Completion Events:97408 ] - [ INFO ]  attempt_local852729690_0068_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:49  [ localfetcher#68:97409 ] - [ INFO ]  localfetcher#68 about to shuffle output of map attempt_local852729690_0068_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:49  [ localfetcher#68:97409 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local852729690_0068_m_000000_0
2020-11-19 10:19:49  [ localfetcher#68:97409 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:49  [ EventFetcher for fetching Map Completion Events:97409 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:49  [ pool-207-thread-1:97409 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:49  [ pool-207-thread-1:97409 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:49  [ pool-207-thread-1:97410 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:49  [ pool-207-thread-1:97410 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:49  [ pool-207-thread-1:97461 ] - [ INFO ]  Task:attempt_local852729690_0068_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:49  [ pool-207-thread-1:97468 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:49  [ pool-207-thread-1:97468 ] - [ INFO ]  Task attempt_local852729690_0068_r_000000_0 is allowed to commit now
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  Saved output of task 'attempt_local852729690_0068_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local852729690_0068_r_000000
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  Task 'attempt_local852729690_0068_r_000000_0' done.
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  Finishing task: attempt_local852729690_0068_r_000000_0
2020-11-19 10:19:49  [ Thread-2028:97485 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:50  [ main:98323 ] - [ INFO ]  Job job_local852729690_0068 running in uber mode : false
2020-11-19 10:19:50  [ main:98323 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:50  [ main:98324 ] - [ INFO ]  Job job_local852729690_0068 completed successfully
2020-11-19 10:19:50  [ main:98324 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=162364
		FILE: Number of bytes written=38856594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4376696
		HDFS: Number of bytes written=72160
		HDFS: Number of read operations=4549
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1476
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:50  [ main:98632 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:50  [ main:98645 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:50  [ main:98649 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:50  [ main:98654 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:50  [ main:98695 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:50  [ main:98711 ] - [ INFO ]  Submitting tokens for job: job_local2065812434_0069
2020-11-19 10:19:50  [ main:98743 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:50  [ main:98743 ] - [ INFO ]  Running job: job_local2065812434_0069
2020-11-19 10:19:50  [ Thread-2058:98743 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:50  [ Thread-2058:98743 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:50  [ Thread-2058:98743 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:50  [ Thread-2058:98750 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  Starting task: attempt_local2065812434_0069_m_000000_0
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98835 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98836 ] - [ INFO ]  Task:attempt_local2065812434_0069_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98841 ] - [ INFO ]  map
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98841 ] - [ INFO ]  Task 'attempt_local2065812434_0069_m_000000_0' done.
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98841 ] - [ INFO ]  Finishing task: attempt_local2065812434_0069_m_000000_0
2020-11-19 10:19:50  [ Thread-2058:98841 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:50  [ Thread-2058:98842 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  Starting task: attempt_local2065812434_0069_r_000000_0
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55d84354
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:50  [ EventFetcher for fetching Map Completion Events:98843 ] - [ INFO ]  attempt_local2065812434_0069_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:50  [ localfetcher#69:98843 ] - [ INFO ]  localfetcher#69 about to shuffle output of map attempt_local2065812434_0069_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:50  [ localfetcher#69:98843 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2065812434_0069_m_000000_0
2020-11-19 10:19:50  [ localfetcher#69:98844 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:50  [ EventFetcher for fetching Map Completion Events:98844 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:50  [ pool-210-thread-1:98844 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:50  [ pool-210-thread-1:98844 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:50  [ pool-210-thread-1:98845 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:50  [ pool-210-thread-1:98845 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:50  [ pool-210-thread-1:98888 ] - [ INFO ]  Task:attempt_local2065812434_0069_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:50  [ pool-210-thread-1:98893 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:50  [ pool-210-thread-1:98893 ] - [ INFO ]  Task attempt_local2065812434_0069_r_000000_0 is allowed to commit now
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  Saved output of task 'attempt_local2065812434_0069_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2065812434_0069_r_000000
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  Task 'attempt_local2065812434_0069_r_000000_0' done.
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  Finishing task: attempt_local2065812434_0069_r_000000_0
2020-11-19 10:19:50  [ Thread-2058:98910 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]  Job job_local2065812434_0069 running in uber mode : false
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]  Job job_local2065812434_0069 completed successfully
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=163554
		FILE: Number of bytes written=39428516
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4441102
		HDFS: Number of bytes written=73240
		HDFS: Number of read operations=4617
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1498
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:52  [ main:100056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:52  [ main:100069 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:52  [ main:100074 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:52  [ main:100079 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:52  [ main:100119 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:52  [ main:100136 ] - [ INFO ]  Submitting tokens for job: job_local526923166_0070
2020-11-19 10:19:52  [ main:100168 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:52  [ main:100168 ] - [ INFO ]  Running job: job_local526923166_0070
2020-11-19 10:19:52  [ Thread-2088:100168 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:52  [ Thread-2088:100168 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:52  [ Thread-2088:100168 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:52  [ Thread-2088:100175 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  Starting task: attempt_local526923166_0070_m_000000_0
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100251 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100252 ] - [ INFO ]  Task:attempt_local526923166_0070_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100257 ] - [ INFO ]  map
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100257 ] - [ INFO ]  Task 'attempt_local526923166_0070_m_000000_0' done.
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100257 ] - [ INFO ]  Finishing task: attempt_local526923166_0070_m_000000_0
2020-11-19 10:19:52  [ Thread-2088:100258 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:52  [ Thread-2088:100258 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  Starting task: attempt_local526923166_0070_r_000000_0
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@408a8c1
2020-11-19 10:19:52  [ pool-213-thread-1:100259 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:52  [ EventFetcher for fetching Map Completion Events:100259 ] - [ INFO ]  attempt_local526923166_0070_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:52  [ localfetcher#70:100260 ] - [ INFO ]  localfetcher#70 about to shuffle output of map attempt_local526923166_0070_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:52  [ localfetcher#70:100260 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local526923166_0070_m_000000_0
2020-11-19 10:19:52  [ localfetcher#70:100260 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:52  [ EventFetcher for fetching Map Completion Events:100260 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:52  [ pool-213-thread-1:100260 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:52  [ pool-213-thread-1:100260 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:52  [ pool-213-thread-1:100261 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:52  [ pool-213-thread-1:100261 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:52  [ pool-213-thread-1:100261 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:52  [ pool-213-thread-1:100321 ] - [ INFO ]  Task:attempt_local526923166_0070_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:52  [ pool-213-thread-1:100326 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:52  [ pool-213-thread-1:100327 ] - [ INFO ]  Task attempt_local526923166_0070_r_000000_0 is allowed to commit now
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  Saved output of task 'attempt_local526923166_0070_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local526923166_0070_r_000000
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  Task 'attempt_local526923166_0070_r_000000_0' done.
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  Finishing task: attempt_local526923166_0070_r_000000_0
2020-11-19 10:19:52  [ Thread-2088:100343 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:53  [ main:101173 ] - [ INFO ]  Job job_local526923166_0070 running in uber mode : false
2020-11-19 10:19:53  [ main:101173 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:53  [ main:101174 ] - [ INFO ]  Job job_local526923166_0070 completed successfully
2020-11-19 10:19:53  [ main:101174 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=164746
		FILE: Number of bytes written=39997393
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4505508
		HDFS: Number of bytes written=74320
		HDFS: Number of read operations=4685
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1520
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:53  [ main:101665 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:53  [ main:101677 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:53  [ main:101682 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:53  [ main:101687 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:53  [ main:101727 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:53  [ main:101744 ] - [ INFO ]  Submitting tokens for job: job_local1715160703_0071
2020-11-19 10:19:53  [ main:101774 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:53  [ main:101774 ] - [ INFO ]  Running job: job_local1715160703_0071
2020-11-19 10:19:53  [ Thread-2118:101774 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:53  [ Thread-2118:101774 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:53  [ Thread-2118:101774 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:53  [ Thread-2118:101780 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  Starting task: attempt_local1715160703_0071_m_000000_0
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101978 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101979 ] - [ INFO ]  Task:attempt_local1715160703_0071_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101984 ] - [ INFO ]  map
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101985 ] - [ INFO ]  Task 'attempt_local1715160703_0071_m_000000_0' done.
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101985 ] - [ INFO ]  Finishing task: attempt_local1715160703_0071_m_000000_0
2020-11-19 10:19:53  [ Thread-2118:101985 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:53  [ Thread-2118:101985 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:53  [ pool-216-thread-1:101985 ] - [ INFO ]  Starting task: attempt_local1715160703_0071_r_000000_0
2020-11-19 10:19:53  [ pool-216-thread-1:101985 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d281c3a
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:53  [ EventFetcher for fetching Map Completion Events:101986 ] - [ INFO ]  attempt_local1715160703_0071_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:53  [ localfetcher#71:101987 ] - [ INFO ]  localfetcher#71 about to shuffle output of map attempt_local1715160703_0071_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:53  [ localfetcher#71:101987 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1715160703_0071_m_000000_0
2020-11-19 10:19:53  [ localfetcher#71:101987 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:53  [ EventFetcher for fetching Map Completion Events:101987 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:53  [ pool-216-thread-1:101987 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:53  [ pool-216-thread-1:101987 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:53  [ pool-216-thread-1:101988 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:53  [ pool-216-thread-1:101988 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:54  [ pool-216-thread-1:102050 ] - [ INFO ]  Task:attempt_local1715160703_0071_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:54  [ pool-216-thread-1:102056 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:54  [ pool-216-thread-1:102056 ] - [ INFO ]  Task attempt_local1715160703_0071_r_000000_0 is allowed to commit now
2020-11-19 10:19:54  [ pool-216-thread-1:102072 ] - [ INFO ]  Saved output of task 'attempt_local1715160703_0071_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1715160703_0071_r_000000
2020-11-19 10:19:54  [ pool-216-thread-1:102072 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:54  [ pool-216-thread-1:102073 ] - [ INFO ]  Task 'attempt_local1715160703_0071_r_000000_0' done.
2020-11-19 10:19:54  [ pool-216-thread-1:102073 ] - [ INFO ]  Finishing task: attempt_local1715160703_0071_r_000000_0
2020-11-19 10:19:54  [ Thread-2118:102073 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]  Job job_local1715160703_0071 running in uber mode : false
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]  Job job_local1715160703_0071 completed successfully
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=165938
		FILE: Number of bytes written=40569316
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4569914
		HDFS: Number of bytes written=75400
		HDFS: Number of read operations=4753
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1542
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:55  [ main:103086 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:55  [ main:103097 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:55  [ main:103102 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:55  [ main:103109 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:55  [ main:103151 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:55  [ main:103168 ] - [ INFO ]  Submitting tokens for job: job_local1852177960_0072
2020-11-19 10:19:55  [ main:103198 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:55  [ main:103198 ] - [ INFO ]  Running job: job_local1852177960_0072
2020-11-19 10:19:55  [ Thread-2148:103198 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:55  [ Thread-2148:103198 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:55  [ Thread-2148:103198 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:55  [ Thread-2148:103205 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103205 ] - [ INFO ]  Starting task: attempt_local1852177960_0072_m_000000_0
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103205 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103206 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103206 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103206 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103279 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103280 ] - [ INFO ]  Task:attempt_local1852177960_0072_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103286 ] - [ INFO ]  map
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103286 ] - [ INFO ]  Task 'attempt_local1852177960_0072_m_000000_0' done.
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103286 ] - [ INFO ]  Finishing task: attempt_local1852177960_0072_m_000000_0
2020-11-19 10:19:55  [ Thread-2148:103286 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:55  [ Thread-2148:103287 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  Starting task: attempt_local1852177960_0072_r_000000_0
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b394c35
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:55  [ EventFetcher for fetching Map Completion Events:103288 ] - [ INFO ]  attempt_local1852177960_0072_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:55  [ localfetcher#72:103288 ] - [ INFO ]  localfetcher#72 about to shuffle output of map attempt_local1852177960_0072_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:55  [ localfetcher#72:103289 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1852177960_0072_m_000000_0
2020-11-19 10:19:55  [ localfetcher#72:103289 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:55  [ EventFetcher for fetching Map Completion Events:103289 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:55  [ pool-219-thread-1:103289 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:55  [ pool-219-thread-1:103289 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:55  [ pool-219-thread-1:103291 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:55  [ pool-219-thread-1:103291 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:55  [ pool-219-thread-1:103357 ] - [ INFO ]  Task:attempt_local1852177960_0072_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:55  [ pool-219-thread-1:103365 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:55  [ pool-219-thread-1:103365 ] - [ INFO ]  Task attempt_local1852177960_0072_r_000000_0 is allowed to commit now
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  Saved output of task 'attempt_local1852177960_0072_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1852177960_0072_r_000000
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  Task 'attempt_local1852177960_0072_r_000000_0' done.
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  Finishing task: attempt_local1852177960_0072_r_000000_0
2020-11-19 10:19:55  [ Thread-2148:103388 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:56  [ main:104199 ] - [ INFO ]  Job job_local1852177960_0072 running in uber mode : false
2020-11-19 10:19:56  [ main:104199 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:56  [ main:104199 ] - [ INFO ]  Job job_local1852177960_0072 completed successfully
2020-11-19 10:19:56  [ main:104200 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=167128
		FILE: Number of bytes written=41141238
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4634320
		HDFS: Number of bytes written=76480
		HDFS: Number of read operations=4821
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1564
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:56  [ main:104503 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:56  [ main:104515 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:56  [ main:104520 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:56  [ main:104526 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:56  [ main:104567 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:56  [ main:104585 ] - [ INFO ]  Submitting tokens for job: job_local960261656_0073
2020-11-19 10:19:56  [ main:104614 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:56  [ main:104614 ] - [ INFO ]  Running job: job_local960261656_0073
2020-11-19 10:19:56  [ Thread-2178:104614 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:56  [ Thread-2178:104614 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:56  [ Thread-2178:104614 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:56  [ Thread-2178:104621 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]  Starting task: attempt_local960261656_0073_m_000000_0
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104622 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104695 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104696 ] - [ INFO ]  Task:attempt_local960261656_0073_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104701 ] - [ INFO ]  map
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104701 ] - [ INFO ]  Task 'attempt_local960261656_0073_m_000000_0' done.
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104701 ] - [ INFO ]  Finishing task: attempt_local960261656_0073_m_000000_0
2020-11-19 10:19:56  [ Thread-2178:104701 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:56  [ Thread-2178:104702 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  Starting task: attempt_local960261656_0073_r_000000_0
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51d424e6
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:56  [ EventFetcher for fetching Map Completion Events:104703 ] - [ INFO ]  attempt_local960261656_0073_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:56  [ localfetcher#73:104703 ] - [ INFO ]  localfetcher#73 about to shuffle output of map attempt_local960261656_0073_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:56  [ localfetcher#73:104703 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local960261656_0073_m_000000_0
2020-11-19 10:19:56  [ localfetcher#73:104703 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:56  [ EventFetcher for fetching Map Completion Events:104704 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:56  [ pool-222-thread-1:104704 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:56  [ pool-222-thread-1:104704 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:56  [ pool-222-thread-1:104758 ] - [ INFO ]  Task:attempt_local960261656_0073_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:56  [ pool-222-thread-1:104763 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:56  [ pool-222-thread-1:104763 ] - [ INFO ]  Task attempt_local960261656_0073_r_000000_0 is allowed to commit now
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  Saved output of task 'attempt_local960261656_0073_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local960261656_0073_r_000000
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  Task 'attempt_local960261656_0073_r_000000_0' done.
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  Finishing task: attempt_local960261656_0073_r_000000_0
2020-11-19 10:19:56  [ Thread-2178:104782 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]  Job job_local960261656_0073 running in uber mode : false
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]  Job job_local960261656_0073 completed successfully
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=168320
		FILE: Number of bytes written=41710115
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4698726
		HDFS: Number of bytes written=77560
		HDFS: Number of read operations=4889
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1586
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:57  [ main:105895 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:57  [ main:105908 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:57  [ main:105913 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:57  [ main:105924 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:57  [ main:105971 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:57  [ main:105988 ] - [ INFO ]  Submitting tokens for job: job_local1674126219_0074
2020-11-19 10:19:58  [ main:106020 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:58  [ main:106020 ] - [ INFO ]  Running job: job_local1674126219_0074
2020-11-19 10:19:58  [ Thread-2208:106020 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:58  [ Thread-2208:106020 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:58  [ Thread-2208:106020 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:58  [ Thread-2208:106028 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]  Starting task: attempt_local1674126219_0074_m_000000_0
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106029 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106039 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106102 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106103 ] - [ INFO ]  Task:attempt_local1674126219_0074_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106108 ] - [ INFO ]  map
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106108 ] - [ INFO ]  Task 'attempt_local1674126219_0074_m_000000_0' done.
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106108 ] - [ INFO ]  Finishing task: attempt_local1674126219_0074_m_000000_0
2020-11-19 10:19:58  [ Thread-2208:106108 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:58  [ Thread-2208:106109 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:58  [ pool-225-thread-1:106109 ] - [ INFO ]  Starting task: attempt_local1674126219_0074_r_000000_0
2020-11-19 10:19:58  [ pool-225-thread-1:106109 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:58  [ pool-225-thread-1:106109 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:58  [ pool-225-thread-1:106110 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:58  [ pool-225-thread-1:106110 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@86cfb56
2020-11-19 10:19:58  [ pool-225-thread-1:106110 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:58  [ EventFetcher for fetching Map Completion Events:106110 ] - [ INFO ]  attempt_local1674126219_0074_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:58  [ localfetcher#74:106111 ] - [ INFO ]  localfetcher#74 about to shuffle output of map attempt_local1674126219_0074_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:58  [ localfetcher#74:106111 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1674126219_0074_m_000000_0
2020-11-19 10:19:58  [ localfetcher#74:106111 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:58  [ EventFetcher for fetching Map Completion Events:106111 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:58  [ pool-225-thread-1:106112 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:58  [ pool-225-thread-1:106112 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:58  [ pool-225-thread-1:106114 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:58  [ pool-225-thread-1:106114 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:58  [ pool-225-thread-1:106168 ] - [ INFO ]  Task:attempt_local1674126219_0074_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:58  [ pool-225-thread-1:106173 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:58  [ pool-225-thread-1:106173 ] - [ INFO ]  Task attempt_local1674126219_0074_r_000000_0 is allowed to commit now
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  Saved output of task 'attempt_local1674126219_0074_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1674126219_0074_r_000000
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  Task 'attempt_local1674126219_0074_r_000000_0' done.
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  Finishing task: attempt_local1674126219_0074_r_000000_0
2020-11-19 10:19:58  [ Thread-2208:106191 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:59  [ main:107022 ] - [ INFO ]  Job job_local1674126219_0074 running in uber mode : false
2020-11-19 10:19:59  [ main:107022 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:59  [ main:107022 ] - [ INFO ]  Job job_local1674126219_0074 completed successfully
2020-11-19 10:19:59  [ main:107023 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=169512
		FILE: Number of bytes written=42282038
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4763132
		HDFS: Number of bytes written=78640
		HDFS: Number of read operations=4957
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1608
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:59  [ main:107313 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:59  [ main:107323 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:59  [ main:107328 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:59  [ main:107334 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:59  [ main:107373 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:59  [ main:107389 ] - [ INFO ]  Submitting tokens for job: job_local1557998078_0075
2020-11-19 10:19:59  [ main:107419 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:59  [ main:107419 ] - [ INFO ]  Running job: job_local1557998078_0075
2020-11-19 10:19:59  [ Thread-2238:107419 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:59  [ Thread-2238:107419 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:59  [ Thread-2238:107419 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:59  [ Thread-2238:107426 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107426 ] - [ INFO ]  Starting task: attempt_local1557998078_0075_m_000000_0
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107504 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107505 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107506 ] - [ INFO ]  Task:attempt_local1557998078_0075_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107511 ] - [ INFO ]  map
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107511 ] - [ INFO ]  Task 'attempt_local1557998078_0075_m_000000_0' done.
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107511 ] - [ INFO ]  Finishing task: attempt_local1557998078_0075_m_000000_0
2020-11-19 10:19:59  [ Thread-2238:107511 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:59  [ Thread-2238:107512 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  Starting task: attempt_local1557998078_0075_r_000000_0
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30f51aa6
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:59  [ EventFetcher for fetching Map Completion Events:107513 ] - [ INFO ]  attempt_local1557998078_0075_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:59  [ localfetcher#75:107513 ] - [ INFO ]  localfetcher#75 about to shuffle output of map attempt_local1557998078_0075_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:59  [ localfetcher#75:107514 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1557998078_0075_m_000000_0
2020-11-19 10:19:59  [ localfetcher#75:107514 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:59  [ EventFetcher for fetching Map Completion Events:107514 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:59  [ pool-228-thread-1:107514 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:59  [ pool-228-thread-1:107514 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:59  [ pool-228-thread-1:107516 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:59  [ pool-228-thread-1:107572 ] - [ INFO ]  Task:attempt_local1557998078_0075_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:59  [ pool-228-thread-1:107577 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:59  [ pool-228-thread-1:107577 ] - [ INFO ]  Task attempt_local1557998078_0075_r_000000_0 is allowed to commit now
2020-11-19 10:19:59  [ pool-228-thread-1:107595 ] - [ INFO ]  Saved output of task 'attempt_local1557998078_0075_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1557998078_0075_r_000000
2020-11-19 10:19:59  [ pool-228-thread-1:107595 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:59  [ pool-228-thread-1:107596 ] - [ INFO ]  Task 'attempt_local1557998078_0075_r_000000_0' done.
2020-11-19 10:19:59  [ pool-228-thread-1:107596 ] - [ INFO ]  Finishing task: attempt_local1557998078_0075_r_000000_0
2020-11-19 10:19:59  [ Thread-2238:107596 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:00  [ main:108422 ] - [ INFO ]  Job job_local1557998078_0075 running in uber mode : false
2020-11-19 10:20:00  [ main:108422 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:00  [ main:108422 ] - [ INFO ]  Job job_local1557998078_0075 completed successfully
2020-11-19 10:20:00  [ main:108423 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=170702
		FILE: Number of bytes written=42853960
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4827538
		HDFS: Number of bytes written=79720
		HDFS: Number of read operations=5025
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1630
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:00  [ main:108717 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:00  [ main:108729 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:00  [ main:108734 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:00  [ main:108740 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:00  [ main:108781 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:00  [ main:108798 ] - [ INFO ]  Submitting tokens for job: job_local1258752764_0076
2020-11-19 10:20:00  [ main:108828 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:00  [ main:108828 ] - [ INFO ]  Running job: job_local1258752764_0076
2020-11-19 10:20:00  [ Thread-2268:108828 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:00  [ Thread-2268:108828 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:00  [ Thread-2268:108828 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:00  [ Thread-2268:108835 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]  Starting task: attempt_local1258752764_0076_m_000000_0
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108836 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108913 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108914 ] - [ INFO ]  Task:attempt_local1258752764_0076_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108919 ] - [ INFO ]  map
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108919 ] - [ INFO ]  Task 'attempt_local1258752764_0076_m_000000_0' done.
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108919 ] - [ INFO ]  Finishing task: attempt_local1258752764_0076_m_000000_0
2020-11-19 10:20:00  [ Thread-2268:108919 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:00  [ Thread-2268:108919 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:00  [ pool-231-thread-1:108919 ] - [ INFO ]  Starting task: attempt_local1258752764_0076_r_000000_0
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2adf1ff1
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:00  [ EventFetcher for fetching Map Completion Events:108921 ] - [ INFO ]  attempt_local1258752764_0076_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:00  [ localfetcher#76:108921 ] - [ INFO ]  localfetcher#76 about to shuffle output of map attempt_local1258752764_0076_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:00  [ localfetcher#76:108921 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1258752764_0076_m_000000_0
2020-11-19 10:20:00  [ localfetcher#76:108921 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:00  [ EventFetcher for fetching Map Completion Events:108922 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:00  [ pool-231-thread-1:108922 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:00  [ pool-231-thread-1:108922 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:00  [ pool-231-thread-1:108922 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:00  [ pool-231-thread-1:108976 ] - [ INFO ]  Task:attempt_local1258752764_0076_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:00  [ pool-231-thread-1:108981 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:00  [ pool-231-thread-1:108981 ] - [ INFO ]  Task attempt_local1258752764_0076_r_000000_0 is allowed to commit now
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  Saved output of task 'attempt_local1258752764_0076_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1258752764_0076_r_000000
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  Task 'attempt_local1258752764_0076_r_000000_0' done.
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  Finishing task: attempt_local1258752764_0076_r_000000_0
2020-11-19 10:20:00  [ Thread-2268:108997 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:01  [ main:109829 ] - [ INFO ]  Job job_local1258752764_0076 running in uber mode : false
2020-11-19 10:20:01  [ main:109830 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:01  [ main:109830 ] - [ INFO ]  Job job_local1258752764_0076 completed successfully
2020-11-19 10:20:01  [ main:109830 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=171894
		FILE: Number of bytes written=43425885
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4891944
		HDFS: Number of bytes written=80800
		HDFS: Number of read operations=5093
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1652
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:02  [ main:110115 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:02  [ main:110126 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:02  [ main:110131 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:02  [ main:110136 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:02  [ main:110174 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:02  [ main:110190 ] - [ INFO ]  Submitting tokens for job: job_local1861038094_0077
2020-11-19 10:20:02  [ main:110219 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:02  [ main:110219 ] - [ INFO ]  Running job: job_local1861038094_0077
2020-11-19 10:20:02  [ Thread-2298:110219 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:02  [ Thread-2298:110219 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:02  [ Thread-2298:110219 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:02  [ Thread-2298:110226 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]  Starting task: attempt_local1861038094_0077_m_000000_0
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110227 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110299 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110300 ] - [ INFO ]  Task:attempt_local1861038094_0077_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110306 ] - [ INFO ]  map
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110306 ] - [ INFO ]  Task 'attempt_local1861038094_0077_m_000000_0' done.
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110306 ] - [ INFO ]  Finishing task: attempt_local1861038094_0077_m_000000_0
2020-11-19 10:20:02  [ Thread-2298:110306 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:02  [ Thread-2298:110307 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  Starting task: attempt_local1861038094_0077_r_000000_0
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f81baba
2020-11-19 10:20:02  [ pool-234-thread-1:110308 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:02  [ EventFetcher for fetching Map Completion Events:110308 ] - [ INFO ]  attempt_local1861038094_0077_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:02  [ localfetcher#77:110308 ] - [ INFO ]  localfetcher#77 about to shuffle output of map attempt_local1861038094_0077_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:02  [ localfetcher#77:110309 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1861038094_0077_m_000000_0
2020-11-19 10:20:02  [ localfetcher#77:110309 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:02  [ EventFetcher for fetching Map Completion Events:110309 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:02  [ pool-234-thread-1:110309 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:02  [ pool-234-thread-1:110309 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:02  [ pool-234-thread-1:110355 ] - [ INFO ]  Task:attempt_local1861038094_0077_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:02  [ pool-234-thread-1:110360 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:02  [ pool-234-thread-1:110360 ] - [ INFO ]  Task attempt_local1861038094_0077_r_000000_0 is allowed to commit now
2020-11-19 10:20:02  [ pool-234-thread-1:110376 ] - [ INFO ]  Saved output of task 'attempt_local1861038094_0077_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1861038094_0077_r_000000
2020-11-19 10:20:02  [ pool-234-thread-1:110377 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:02  [ pool-234-thread-1:110377 ] - [ INFO ]  Task 'attempt_local1861038094_0077_r_000000_0' done.
2020-11-19 10:20:02  [ pool-234-thread-1:110377 ] - [ INFO ]  Finishing task: attempt_local1861038094_0077_r_000000_0
2020-11-19 10:20:02  [ Thread-2298:110377 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]  Job job_local1861038094_0077 running in uber mode : false
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]  Job job_local1861038094_0077 completed successfully
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=173086
		FILE: Number of bytes written=43997808
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4956350
		HDFS: Number of bytes written=81880
		HDFS: Number of read operations=5161
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1674
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:03  [ main:111474 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:03  [ main:111485 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:03  [ main:111490 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:03  [ main:111495 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:03  [ main:111538 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:03  [ main:111557 ] - [ INFO ]  Submitting tokens for job: job_local732622909_0078
2020-11-19 10:20:03  [ main:111589 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:03  [ main:111589 ] - [ INFO ]  Running job: job_local732622909_0078
2020-11-19 10:20:03  [ Thread-2328:111589 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:03  [ Thread-2328:111589 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:03  [ Thread-2328:111589 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:03  [ Thread-2328:111596 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]  Starting task: attempt_local732622909_0078_m_000000_0
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111597 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111665 ] - [ INFO ]  
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111667 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111668 ] - [ INFO ]  Task:attempt_local732622909_0078_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111675 ] - [ INFO ]  map
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111675 ] - [ INFO ]  Task 'attempt_local732622909_0078_m_000000_0' done.
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111675 ] - [ INFO ]  Finishing task: attempt_local732622909_0078_m_000000_0
2020-11-19 10:20:03  [ Thread-2328:111675 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:03  [ Thread-2328:111675 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:03  [ pool-237-thread-1:111675 ] - [ INFO ]  Starting task: attempt_local732622909_0078_r_000000_0
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2debd373
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:03  [ EventFetcher for fetching Map Completion Events:111676 ] - [ INFO ]  attempt_local732622909_0078_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:03  [ localfetcher#78:111677 ] - [ INFO ]  localfetcher#78 about to shuffle output of map attempt_local732622909_0078_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:03  [ localfetcher#78:111677 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local732622909_0078_m_000000_0
2020-11-19 10:20:03  [ localfetcher#78:111677 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:03  [ EventFetcher for fetching Map Completion Events:111678 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:03  [ pool-237-thread-1:111732 ] - [ INFO ]  Task:attempt_local732622909_0078_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:03  [ pool-237-thread-1:111739 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:03  [ pool-237-thread-1:111739 ] - [ INFO ]  Task attempt_local732622909_0078_r_000000_0 is allowed to commit now
2020-11-19 10:20:03  [ pool-237-thread-1:111754 ] - [ INFO ]  Saved output of task 'attempt_local732622909_0078_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local732622909_0078_r_000000
2020-11-19 10:20:03  [ pool-237-thread-1:111755 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:03  [ pool-237-thread-1:111755 ] - [ INFO ]  Task 'attempt_local732622909_0078_r_000000_0' done.
2020-11-19 10:20:03  [ pool-237-thread-1:111755 ] - [ INFO ]  Finishing task: attempt_local732622909_0078_r_000000_0
2020-11-19 10:20:03  [ Thread-2328:111755 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]  Job job_local732622909_0078 running in uber mode : false
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]  Job job_local732622909_0078 completed successfully
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=174276
		FILE: Number of bytes written=44566682
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5020756
		HDFS: Number of bytes written=82960
		HDFS: Number of read operations=5229
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1696
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2282749952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:04  [ main:112846 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:04  [ main:112856 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:04  [ main:112861 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:04  [ main:112866 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:04  [ main:112909 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:04  [ main:112927 ] - [ INFO ]  Submitting tokens for job: job_local1131422728_0079
2020-11-19 10:20:04  [ main:112957 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:04  [ main:112957 ] - [ INFO ]  Running job: job_local1131422728_0079
2020-11-19 10:20:04  [ Thread-2358:112957 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:04  [ Thread-2358:112957 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:04  [ Thread-2358:112957 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:04  [ Thread-2358:112964 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]  Starting task: attempt_local1131422728_0079_m_000000_0
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112965 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113035 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113035 ] - [ INFO ]  Task:attempt_local1131422728_0079_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113041 ] - [ INFO ]  map
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113042 ] - [ INFO ]  Task 'attempt_local1131422728_0079_m_000000_0' done.
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113042 ] - [ INFO ]  Finishing task: attempt_local1131422728_0079_m_000000_0
2020-11-19 10:20:05  [ Thread-2358:113042 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:05  [ Thread-2358:113042 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:05  [ pool-240-thread-1:113042 ] - [ INFO ]  Starting task: attempt_local1131422728_0079_r_000000_0
2020-11-19 10:20:05  [ pool-240-thread-1:113042 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19bc6416
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:05  [ EventFetcher for fetching Map Completion Events:113043 ] - [ INFO ]  attempt_local1131422728_0079_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:05  [ localfetcher#79:113044 ] - [ INFO ]  localfetcher#79 about to shuffle output of map attempt_local1131422728_0079_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:05  [ localfetcher#79:113044 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1131422728_0079_m_000000_0
2020-11-19 10:20:05  [ localfetcher#79:113044 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:05  [ EventFetcher for fetching Map Completion Events:113044 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:05  [ pool-240-thread-1:113044 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:05  [ pool-240-thread-1:113044 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:05  [ pool-240-thread-1:113045 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:05  [ pool-240-thread-1:113045 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:05  [ pool-240-thread-1:113045 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:05  [ pool-240-thread-1:113098 ] - [ INFO ]  Task:attempt_local1131422728_0079_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:05  [ pool-240-thread-1:113103 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:05  [ pool-240-thread-1:113103 ] - [ INFO ]  Task attempt_local1131422728_0079_r_000000_0 is allowed to commit now
2020-11-19 10:20:05  [ pool-240-thread-1:113120 ] - [ INFO ]  Saved output of task 'attempt_local1131422728_0079_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1131422728_0079_r_000000
2020-11-19 10:20:05  [ pool-240-thread-1:113121 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:05  [ pool-240-thread-1:113121 ] - [ INFO ]  Task 'attempt_local1131422728_0079_r_000000_0' done.
2020-11-19 10:20:05  [ pool-240-thread-1:113121 ] - [ INFO ]  Finishing task: attempt_local1131422728_0079_r_000000_0
2020-11-19 10:20:05  [ Thread-2358:113121 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:05  [ main:113962 ] - [ INFO ]  Job job_local1131422728_0079 running in uber mode : false
2020-11-19 10:20:05  [ main:113962 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:05  [ main:113962 ] - [ INFO ]  Job job_local1131422728_0079 completed successfully
2020-11-19 10:20:05  [ main:113963 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=175468
		FILE: Number of bytes written=45138607
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5085162
		HDFS: Number of bytes written=84040
		HDFS: Number of read operations=5297
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1718
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2282749952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:06  [ main:114215 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:06  [ main:114226 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:06  [ main:114230 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:06  [ main:114235 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:06  [ main:114272 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:06  [ main:114290 ] - [ INFO ]  Submitting tokens for job: job_local473498102_0080
2020-11-19 10:20:06  [ main:114319 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:06  [ main:114319 ] - [ INFO ]  Running job: job_local473498102_0080
2020-11-19 10:20:06  [ Thread-2388:114319 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:06  [ Thread-2388:114319 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:06  [ Thread-2388:114319 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:06  [ Thread-2388:114327 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]  Starting task: attempt_local473498102_0080_m_000000_0
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114328 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114334 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114334 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114400 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114401 ] - [ INFO ]  Task:attempt_local473498102_0080_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114408 ] - [ INFO ]  map
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114408 ] - [ INFO ]  Task 'attempt_local473498102_0080_m_000000_0' done.
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114408 ] - [ INFO ]  Finishing task: attempt_local473498102_0080_m_000000_0
2020-11-19 10:20:06  [ Thread-2388:114408 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:06  [ Thread-2388:114408 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:06  [ pool-243-thread-1:114408 ] - [ INFO ]  Starting task: attempt_local473498102_0080_r_000000_0
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53f64c0b
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:06  [ EventFetcher for fetching Map Completion Events:114409 ] - [ INFO ]  attempt_local473498102_0080_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:06  [ localfetcher#80:114410 ] - [ INFO ]  localfetcher#80 about to shuffle output of map attempt_local473498102_0080_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:06  [ localfetcher#80:114410 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local473498102_0080_m_000000_0
2020-11-19 10:20:06  [ localfetcher#80:114410 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:06  [ EventFetcher for fetching Map Completion Events:114411 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:06  [ pool-243-thread-1:114411 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:06  [ pool-243-thread-1:114411 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:06  [ pool-243-thread-1:114471 ] - [ INFO ]  Task:attempt_local473498102_0080_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:06  [ pool-243-thread-1:114476 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:06  [ pool-243-thread-1:114476 ] - [ INFO ]  Task attempt_local473498102_0080_r_000000_0 is allowed to commit now
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  Saved output of task 'attempt_local473498102_0080_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local473498102_0080_r_000000
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  Task 'attempt_local473498102_0080_r_000000_0' done.
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  Finishing task: attempt_local473498102_0080_r_000000_0
2020-11-19 10:20:06  [ Thread-2388:114497 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:07  [ main:115322 ] - [ INFO ]  Job job_local473498102_0080 running in uber mode : false
2020-11-19 10:20:07  [ main:115322 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:07  [ main:115322 ] - [ INFO ]  Job job_local473498102_0080 completed successfully
2020-11-19 10:20:07  [ main:115323 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=176660
		FILE: Number of bytes written=45707482
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5149568
		HDFS: Number of bytes written=85120
		HDFS: Number of read operations=5365
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1740
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2282749952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:07  [ main:115596 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:07  [ main:115607 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:07  [ main:115612 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:07  [ main:115617 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:07  [ main:115659 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:07  [ main:115676 ] - [ INFO ]  Submitting tokens for job: job_local1925231719_0081
2020-11-19 10:20:07  [ main:115708 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:07  [ main:115708 ] - [ INFO ]  Running job: job_local1925231719_0081
2020-11-19 10:20:07  [ Thread-2418:115708 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:07  [ Thread-2418:115708 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:07  [ Thread-2418:115708 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:07  [ Thread-2418:115716 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  Starting task: attempt_local1925231719_0081_m_000000_0
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115801 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115802 ] - [ INFO ]  Task:attempt_local1925231719_0081_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115807 ] - [ INFO ]  map
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115807 ] - [ INFO ]  Task 'attempt_local1925231719_0081_m_000000_0' done.
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115807 ] - [ INFO ]  Finishing task: attempt_local1925231719_0081_m_000000_0
2020-11-19 10:20:07  [ Thread-2418:115807 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:07  [ Thread-2418:115808 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  Starting task: attempt_local1925231719_0081_r_000000_0
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9162568
2020-11-19 10:20:07  [ pool-246-thread-1:115809 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:07  [ EventFetcher for fetching Map Completion Events:115809 ] - [ INFO ]  attempt_local1925231719_0081_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:07  [ localfetcher#81:115812 ] - [ INFO ]  localfetcher#81 about to shuffle output of map attempt_local1925231719_0081_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:07  [ localfetcher#81:115812 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1925231719_0081_m_000000_0
2020-11-19 10:20:07  [ localfetcher#81:115812 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:07  [ EventFetcher for fetching Map Completion Events:115813 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:07  [ pool-246-thread-1:115813 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:07  [ pool-246-thread-1:115813 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:07  [ pool-246-thread-1:115815 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:07  [ pool-246-thread-1:115815 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:07  [ pool-246-thread-1:115872 ] - [ INFO ]  Task:attempt_local1925231719_0081_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:07  [ pool-246-thread-1:115881 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:07  [ pool-246-thread-1:115881 ] - [ INFO ]  Task attempt_local1925231719_0081_r_000000_0 is allowed to commit now
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  Saved output of task 'attempt_local1925231719_0081_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1925231719_0081_r_000000
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  Task 'attempt_local1925231719_0081_r_000000_0' done.
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  Finishing task: attempt_local1925231719_0081_r_000000_0
2020-11-19 10:20:07  [ Thread-2418:115898 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]  Job job_local1925231719_0081 running in uber mode : false
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]  Job job_local1925231719_0081 completed successfully
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=177850
		FILE: Number of bytes written=46279404
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5213974
		HDFS: Number of bytes written=86200
		HDFS: Number of read operations=5433
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1762
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=2254438400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:08  [ main:116989 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:09  [ main:117000 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:09  [ main:117005 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:09  [ main:117011 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:09  [ main:117055 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:09  [ main:117072 ] - [ INFO ]  Submitting tokens for job: job_local2000796854_0082
2020-11-19 10:20:09  [ main:117104 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:09  [ main:117104 ] - [ INFO ]  Running job: job_local2000796854_0082
2020-11-19 10:20:09  [ Thread-2448:117104 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:09  [ Thread-2448:117104 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:09  [ Thread-2448:117105 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:09  [ Thread-2448:117113 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]  Starting task: attempt_local2000796854_0082_m_000000_0
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117114 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117197 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117198 ] - [ INFO ]  Task:attempt_local2000796854_0082_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117204 ] - [ INFO ]  map
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117204 ] - [ INFO ]  Task 'attempt_local2000796854_0082_m_000000_0' done.
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117204 ] - [ INFO ]  Finishing task: attempt_local2000796854_0082_m_000000_0
2020-11-19 10:20:09  [ Thread-2448:117204 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:09  [ Thread-2448:117204 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:09  [ pool-249-thread-1:117204 ] - [ INFO ]  Starting task: attempt_local2000796854_0082_r_000000_0
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4af6b400
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:09  [ EventFetcher for fetching Map Completion Events:117205 ] - [ INFO ]  attempt_local2000796854_0082_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:09  [ localfetcher#82:117206 ] - [ INFO ]  localfetcher#82 about to shuffle output of map attempt_local2000796854_0082_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:09  [ localfetcher#82:117206 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local2000796854_0082_m_000000_0
2020-11-19 10:20:09  [ localfetcher#82:117206 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:09  [ EventFetcher for fetching Map Completion Events:117207 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:09  [ pool-249-thread-1:117254 ] - [ INFO ]  Task:attempt_local2000796854_0082_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:09  [ pool-249-thread-1:117259 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:09  [ pool-249-thread-1:117259 ] - [ INFO ]  Task attempt_local2000796854_0082_r_000000_0 is allowed to commit now
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  Saved output of task 'attempt_local2000796854_0082_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2000796854_0082_r_000000
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  Task 'attempt_local2000796854_0082_r_000000_0' done.
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  Finishing task: attempt_local2000796854_0082_r_000000_0
2020-11-19 10:20:09  [ Thread-2448:117279 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:10  [ main:118105 ] - [ INFO ]  Job job_local2000796854_0082 running in uber mode : false
2020-11-19 10:20:10  [ main:118106 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:10  [ main:118106 ] - [ INFO ]  Job job_local2000796854_0082 completed successfully
2020-11-19 10:20:10  [ main:118106 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=179042
		FILE: Number of bytes written=46851329
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5278380
		HDFS: Number of bytes written=87280
		HDFS: Number of read operations=5501
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1784
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2226126848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:10  [ main:118406 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:10  [ main:118417 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:10  [ main:118422 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:10  [ main:118428 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:10  [ main:118468 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:10  [ main:118486 ] - [ INFO ]  Submitting tokens for job: job_local1478786048_0083
2020-11-19 10:20:10  [ main:118515 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:10  [ main:118515 ] - [ INFO ]  Running job: job_local1478786048_0083
2020-11-19 10:20:10  [ Thread-2478:118515 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:10  [ Thread-2478:118515 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:10  [ Thread-2478:118515 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:10  [ Thread-2478:118524 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  Starting task: attempt_local1478786048_0083_m_000000_0
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118531 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118531 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118590 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118591 ] - [ INFO ]  Task:attempt_local1478786048_0083_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118597 ] - [ INFO ]  map
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118597 ] - [ INFO ]  Task 'attempt_local1478786048_0083_m_000000_0' done.
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118597 ] - [ INFO ]  Finishing task: attempt_local1478786048_0083_m_000000_0
2020-11-19 10:20:10  [ Thread-2478:118597 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:10  [ Thread-2478:118598 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  Starting task: attempt_local1478786048_0083_r_000000_0
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7cb282e8
2020-11-19 10:20:10  [ pool-252-thread-1:118599 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:10  [ EventFetcher for fetching Map Completion Events:118599 ] - [ INFO ]  attempt_local1478786048_0083_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:10  [ localfetcher#83:118599 ] - [ INFO ]  localfetcher#83 about to shuffle output of map attempt_local1478786048_0083_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:10  [ localfetcher#83:118600 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1478786048_0083_m_000000_0
2020-11-19 10:20:10  [ localfetcher#83:118600 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:10  [ EventFetcher for fetching Map Completion Events:118600 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:10  [ pool-252-thread-1:118600 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:10  [ pool-252-thread-1:118600 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:10  [ pool-252-thread-1:118654 ] - [ INFO ]  Task:attempt_local1478786048_0083_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:10  [ pool-252-thread-1:118661 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:10  [ pool-252-thread-1:118661 ] - [ INFO ]  Task attempt_local1478786048_0083_r_000000_0 is allowed to commit now
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  Saved output of task 'attempt_local1478786048_0083_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1478786048_0083_r_000000
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  Task 'attempt_local1478786048_0083_r_000000_0' done.
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  Finishing task: attempt_local1478786048_0083_r_000000_0
2020-11-19 10:20:10  [ Thread-2478:118677 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]  Job job_local1478786048_0083 running in uber mode : false
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]  Job job_local1478786048_0083 completed successfully
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=180234
		FILE: Number of bytes written=47423252
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5342786
		HDFS: Number of bytes written=88360
		HDFS: Number of read operations=5569
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1806
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2226126848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:11  [ main:119841 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:12  [ main:120292 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:12  [ main:120297 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:12  [ main:120303 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:12  [ main:120344 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:12  [ main:120361 ] - [ INFO ]  Submitting tokens for job: job_local2003526011_0084
2020-11-19 10:20:12  [ main:120391 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:12  [ main:120391 ] - [ INFO ]  Running job: job_local2003526011_0084
2020-11-19 10:20:12  [ Thread-2508:120391 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:12  [ Thread-2508:120392 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:12  [ Thread-2508:120392 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:12  [ Thread-2508:120399 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  Starting task: attempt_local2003526011_0084_m_000000_0
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120477 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120478 ] - [ INFO ]  Task:attempt_local2003526011_0084_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120484 ] - [ INFO ]  map
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120484 ] - [ INFO ]  Task 'attempt_local2003526011_0084_m_000000_0' done.
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120484 ] - [ INFO ]  Finishing task: attempt_local2003526011_0084_m_000000_0
2020-11-19 10:20:12  [ Thread-2508:120484 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:12  [ Thread-2508:120484 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:12  [ pool-255-thread-1:120484 ] - [ INFO ]  Starting task: attempt_local2003526011_0084_r_000000_0
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33fb7763
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:12  [ EventFetcher for fetching Map Completion Events:120485 ] - [ INFO ]  attempt_local2003526011_0084_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:12  [ localfetcher#84:120486 ] - [ INFO ]  localfetcher#84 about to shuffle output of map attempt_local2003526011_0084_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:12  [ localfetcher#84:120486 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2003526011_0084_m_000000_0
2020-11-19 10:20:12  [ localfetcher#84:120486 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:12  [ EventFetcher for fetching Map Completion Events:120486 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:12  [ pool-255-thread-1:120545 ] - [ INFO ]  Task:attempt_local2003526011_0084_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:12  [ pool-255-thread-1:120550 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:12  [ pool-255-thread-1:120550 ] - [ INFO ]  Task attempt_local2003526011_0084_r_000000_0 is allowed to commit now
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  Saved output of task 'attempt_local2003526011_0084_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2003526011_0084_r_000000
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  Task 'attempt_local2003526011_0084_r_000000_0' done.
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  Finishing task: attempt_local2003526011_0084_r_000000_0
2020-11-19 10:20:12  [ Thread-2508:120567 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]  Job job_local2003526011_0084 running in uber mode : false
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]  Job job_local2003526011_0084 completed successfully
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=181424
		FILE: Number of bytes written=47995174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5407192
		HDFS: Number of bytes written=89440
		HDFS: Number of read operations=5637
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1828
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2226126848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:13  [ main:121686 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:13  [ main:121696 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:13  [ main:121700 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:13  [ main:121705 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:13  [ main:121741 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:13  [ main:121757 ] - [ INFO ]  Submitting tokens for job: job_local1852874694_0085
2020-11-19 10:20:13  [ main:121785 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:13  [ main:121786 ] - [ INFO ]  Running job: job_local1852874694_0085
2020-11-19 10:20:13  [ Thread-2538:121786 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:13  [ Thread-2538:121786 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:13  [ Thread-2538:121786 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:13  [ Thread-2538:121794 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121794 ] - [ INFO ]  Starting task: attempt_local1852874694_0085_m_000000_0
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121874 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121875 ] - [ INFO ]  Task:attempt_local1852874694_0085_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121880 ] - [ INFO ]  map
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121880 ] - [ INFO ]  Task 'attempt_local1852874694_0085_m_000000_0' done.
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121880 ] - [ INFO ]  Finishing task: attempt_local1852874694_0085_m_000000_0
2020-11-19 10:20:13  [ Thread-2538:121881 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:13  [ Thread-2538:121881 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  Starting task: attempt_local1852874694_0085_r_000000_0
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3dbdf482
2020-11-19 10:20:13  [ pool-258-thread-1:121882 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:13  [ EventFetcher for fetching Map Completion Events:121882 ] - [ INFO ]  attempt_local1852874694_0085_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:13  [ localfetcher#85:121883 ] - [ INFO ]  localfetcher#85 about to shuffle output of map attempt_local1852874694_0085_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:13  [ localfetcher#85:121883 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1852874694_0085_m_000000_0
2020-11-19 10:20:13  [ localfetcher#85:121883 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:13  [ EventFetcher for fetching Map Completion Events:121883 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:13  [ pool-258-thread-1:121883 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:13  [ pool-258-thread-1:121883 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:13  [ pool-258-thread-1:121884 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:13  [ pool-258-thread-1:121884 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:13  [ pool-258-thread-1:121943 ] - [ INFO ]  Task:attempt_local1852874694_0085_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:13  [ pool-258-thread-1:121949 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:13  [ pool-258-thread-1:121949 ] - [ INFO ]  Task attempt_local1852874694_0085_r_000000_0 is allowed to commit now
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  Saved output of task 'attempt_local1852874694_0085_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1852874694_0085_r_000000
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  Task 'attempt_local1852874694_0085_r_000000_0' done.
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  Finishing task: attempt_local1852874694_0085_r_000000_0
2020-11-19 10:20:13  [ Thread-2538:121966 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:14  [ main:122788 ] - [ INFO ]  Job job_local1852874694_0085 running in uber mode : false
2020-11-19 10:20:14  [ main:122788 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:14  [ main:122788 ] - [ INFO ]  Job job_local1852874694_0085 completed successfully
2020-11-19 10:20:14  [ main:122789 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=182616
		FILE: Number of bytes written=48567099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5471598
		HDFS: Number of bytes written=90520
		HDFS: Number of read operations=5705
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1850
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=2171600896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:15  [ main:123052 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:15  [ main:123062 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:15  [ main:123067 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:15  [ main:123073 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:15  [ main:123121 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:15  [ main:123138 ] - [ INFO ]  Submitting tokens for job: job_local261036237_0086
2020-11-19 10:20:15  [ main:123170 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:15  [ main:123170 ] - [ INFO ]  Running job: job_local261036237_0086
2020-11-19 10:20:15  [ Thread-2568:123170 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:15  [ Thread-2568:123170 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:15  [ Thread-2568:123171 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:15  [ Thread-2568:123190 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123190 ] - [ INFO ]  Starting task: attempt_local261036237_0086_m_000000_0
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123191 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123191 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123191 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123192 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123200 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123317 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123318 ] - [ INFO ]  Task:attempt_local261036237_0086_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123324 ] - [ INFO ]  map
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123324 ] - [ INFO ]  Task 'attempt_local261036237_0086_m_000000_0' done.
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123324 ] - [ INFO ]  Finishing task: attempt_local261036237_0086_m_000000_0
2020-11-19 10:20:15  [ Thread-2568:123324 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:15  [ Thread-2568:123324 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:15  [ pool-261-thread-1:123324 ] - [ INFO ]  Starting task: attempt_local261036237_0086_r_000000_0
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72796177
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:15  [ EventFetcher for fetching Map Completion Events:123325 ] - [ INFO ]  attempt_local261036237_0086_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:15  [ localfetcher#86:123326 ] - [ INFO ]  localfetcher#86 about to shuffle output of map attempt_local261036237_0086_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:15  [ localfetcher#86:123326 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local261036237_0086_m_000000_0
2020-11-19 10:20:15  [ localfetcher#86:123326 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:15  [ EventFetcher for fetching Map Completion Events:123327 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:15  [ pool-261-thread-1:123327 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:15  [ pool-261-thread-1:123327 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:15  [ pool-261-thread-1:123386 ] - [ INFO ]  Task:attempt_local261036237_0086_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:15  [ pool-261-thread-1:123392 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:15  [ pool-261-thread-1:123392 ] - [ INFO ]  Task attempt_local261036237_0086_r_000000_0 is allowed to commit now
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  Saved output of task 'attempt_local261036237_0086_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local261036237_0086_r_000000
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  Task 'attempt_local261036237_0086_r_000000_0' done.
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  Finishing task: attempt_local261036237_0086_r_000000_0
2020-11-19 10:20:15  [ Thread-2568:123412 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:16  [ main:124174 ] - [ INFO ]  Job job_local261036237_0086 running in uber mode : false
2020-11-19 10:20:16  [ main:124175 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:16  [ main:124175 ] - [ INFO ]  Job job_local261036237_0086 completed successfully
2020-11-19 10:20:16  [ main:124175 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=183808
		FILE: Number of bytes written=49135974
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5536004
		HDFS: Number of bytes written=91600
		HDFS: Number of read operations=5773
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1872
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2171600896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:16  [ main:124449 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:16  [ main:124459 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:16  [ main:124464 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:16  [ main:124471 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:16  [ main:124512 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:16  [ main:124529 ] - [ INFO ]  Submitting tokens for job: job_local1445428528_0087
2020-11-19 10:20:16  [ main:124558 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:16  [ main:124558 ] - [ INFO ]  Running job: job_local1445428528_0087
2020-11-19 10:20:16  [ Thread-2598:124558 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:16  [ Thread-2598:124558 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:16  [ Thread-2598:124558 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:16  [ Thread-2598:124566 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]  Starting task: attempt_local1445428528_0087_m_000000_0
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124567 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124645 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124645 ] - [ INFO ]  Task:attempt_local1445428528_0087_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124650 ] - [ INFO ]  map
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124650 ] - [ INFO ]  Task 'attempt_local1445428528_0087_m_000000_0' done.
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124650 ] - [ INFO ]  Finishing task: attempt_local1445428528_0087_m_000000_0
2020-11-19 10:20:16  [ Thread-2598:124650 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:16  [ Thread-2598:124651 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  Starting task: attempt_local1445428528_0087_r_000000_0
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5233c4c2
2020-11-19 10:20:16  [ pool-264-thread-1:124652 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:16  [ EventFetcher for fetching Map Completion Events:124652 ] - [ INFO ]  attempt_local1445428528_0087_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:16  [ localfetcher#87:124653 ] - [ INFO ]  localfetcher#87 about to shuffle output of map attempt_local1445428528_0087_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:16  [ localfetcher#87:124653 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1445428528_0087_m_000000_0
2020-11-19 10:20:16  [ localfetcher#87:124653 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:16  [ EventFetcher for fetching Map Completion Events:124653 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:16  [ pool-264-thread-1:124653 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:16  [ pool-264-thread-1:124653 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:16  [ pool-264-thread-1:124654 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:16  [ pool-264-thread-1:124654 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:16  [ pool-264-thread-1:124654 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:16  [ pool-264-thread-1:124708 ] - [ INFO ]  Task:attempt_local1445428528_0087_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:16  [ pool-264-thread-1:124713 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:16  [ pool-264-thread-1:124713 ] - [ INFO ]  Task attempt_local1445428528_0087_r_000000_0 is allowed to commit now
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  Saved output of task 'attempt_local1445428528_0087_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1445428528_0087_r_000000
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  Task 'attempt_local1445428528_0087_r_000000_0' done.
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  Finishing task: attempt_local1445428528_0087_r_000000_0
2020-11-19 10:20:16  [ Thread-2598:124731 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:17  [ main:125559 ] - [ INFO ]  Job job_local1445428528_0087 running in uber mode : false
2020-11-19 10:20:17  [ main:125559 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:17  [ main:125559 ] - [ INFO ]  Job job_local1445428528_0087 completed successfully
2020-11-19 10:20:17  [ main:125560 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=184998
		FILE: Number of bytes written=49707896
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5600410
		HDFS: Number of bytes written=92680
		HDFS: Number of read operations=5841
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1894
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2171600896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:18  [ main:126383 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:18  [ main:126409 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:18  [ main:126413 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:18  [ main:126426 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:18  [ main:126474 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:18  [ main:126491 ] - [ INFO ]  Submitting tokens for job: job_local1048465810_0088
2020-11-19 10:20:18  [ main:126520 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:18  [ main:126521 ] - [ INFO ]  Running job: job_local1048465810_0088
2020-11-19 10:20:18  [ Thread-2628:126521 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:18  [ Thread-2628:126521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:18  [ Thread-2628:126521 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:18  [ Thread-2628:126536 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  Starting task: attempt_local1048465810_0088_m_000000_0
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126546 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126546 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126546 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126547 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126547 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126547 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126633 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126634 ] - [ INFO ]  Task:attempt_local1048465810_0088_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126640 ] - [ INFO ]  map
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126640 ] - [ INFO ]  Task 'attempt_local1048465810_0088_m_000000_0' done.
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126640 ] - [ INFO ]  Finishing task: attempt_local1048465810_0088_m_000000_0
2020-11-19 10:20:18  [ Thread-2628:126640 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:18  [ Thread-2628:126640 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:18  [ pool-267-thread-1:126640 ] - [ INFO ]  Starting task: attempt_local1048465810_0088_r_000000_0
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68bc0a67
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:18  [ EventFetcher for fetching Map Completion Events:126641 ] - [ INFO ]  attempt_local1048465810_0088_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:18  [ localfetcher#88:126642 ] - [ INFO ]  localfetcher#88 about to shuffle output of map attempt_local1048465810_0088_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:18  [ localfetcher#88:126642 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1048465810_0088_m_000000_0
2020-11-19 10:20:18  [ localfetcher#88:126642 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:18  [ EventFetcher for fetching Map Completion Events:126643 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:18  [ pool-267-thread-1:126691 ] - [ INFO ]  Task:attempt_local1048465810_0088_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:18  [ pool-267-thread-1:126696 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:18  [ pool-267-thread-1:126697 ] - [ INFO ]  Task attempt_local1048465810_0088_r_000000_0 is allowed to commit now
2020-11-19 10:20:18  [ pool-267-thread-1:126715 ] - [ INFO ]  Saved output of task 'attempt_local1048465810_0088_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1048465810_0088_r_000000
2020-11-19 10:20:18  [ pool-267-thread-1:126716 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:18  [ pool-267-thread-1:126716 ] - [ INFO ]  Task 'attempt_local1048465810_0088_r_000000_0' done.
2020-11-19 10:20:18  [ pool-267-thread-1:126716 ] - [ INFO ]  Finishing task: attempt_local1048465810_0088_r_000000_0
2020-11-19 10:20:18  [ Thread-2628:126716 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]  Job job_local1048465810_0088 running in uber mode : false
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]  Job job_local1048465810_0088 completed successfully
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=186190
		FILE: Number of bytes written=50279821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5664816
		HDFS: Number of bytes written=93760
		HDFS: Number of read operations=5909
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1916
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2120220672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:19  [ main:127815 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:19  [ main:127826 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:19  [ main:127831 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:19  [ main:127835 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:19  [ main:127873 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:19  [ main:127891 ] - [ INFO ]  Submitting tokens for job: job_local809445797_0089
2020-11-19 10:20:19  [ main:127919 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:19  [ main:127919 ] - [ INFO ]  Running job: job_local809445797_0089
2020-11-19 10:20:19  [ Thread-2658:127920 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:19  [ Thread-2658:127920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:19  [ Thread-2658:127920 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:19  [ Thread-2658:127927 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127927 ] - [ INFO ]  Starting task: attempt_local809445797_0089_m_000000_0
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128003 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128003 ] - [ INFO ]  Task:attempt_local809445797_0089_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128009 ] - [ INFO ]  map
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128010 ] - [ INFO ]  Task 'attempt_local809445797_0089_m_000000_0' done.
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128010 ] - [ INFO ]  Finishing task: attempt_local809445797_0089_m_000000_0
2020-11-19 10:20:20  [ Thread-2658:128010 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:20  [ Thread-2658:128010 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:20  [ pool-270-thread-1:128010 ] - [ INFO ]  Starting task: attempt_local809445797_0089_r_000000_0
2020-11-19 10:20:20  [ pool-270-thread-1:128010 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57643eab
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:20  [ EventFetcher for fetching Map Completion Events:128011 ] - [ INFO ]  attempt_local809445797_0089_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:20  [ localfetcher#89:128012 ] - [ INFO ]  localfetcher#89 about to shuffle output of map attempt_local809445797_0089_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:20  [ localfetcher#89:128012 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local809445797_0089_m_000000_0
2020-11-19 10:20:20  [ localfetcher#89:128012 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:20  [ EventFetcher for fetching Map Completion Events:128012 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:20  [ pool-270-thread-1:128012 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:20  [ pool-270-thread-1:128012 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:20  [ pool-270-thread-1:128013 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:20  [ pool-270-thread-1:128013 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:20  [ pool-270-thread-1:128059 ] - [ INFO ]  Task:attempt_local809445797_0089_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:20  [ pool-270-thread-1:128064 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:20  [ pool-270-thread-1:128064 ] - [ INFO ]  Task attempt_local809445797_0089_r_000000_0 is allowed to commit now
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  Saved output of task 'attempt_local809445797_0089_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local809445797_0089_r_000000
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  Task 'attempt_local809445797_0089_r_000000_0' done.
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  Finishing task: attempt_local809445797_0089_r_000000_0
2020-11-19 10:20:20  [ Thread-2658:128080 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]  Job job_local809445797_0089 running in uber mode : false
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]  Job job_local809445797_0089 completed successfully
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=187382
		FILE: Number of bytes written=50848696
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5729222
		HDFS: Number of bytes written=94840
		HDFS: Number of read operations=5977
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1938
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2120220672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:21  [ main:129177 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:21  [ main:129188 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:21  [ main:129192 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:21  [ main:129198 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:21  [ main:129241 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:21  [ main:129258 ] - [ INFO ]  Submitting tokens for job: job_local1491281540_0090
2020-11-19 10:20:21  [ main:129289 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:21  [ main:129290 ] - [ INFO ]  Running job: job_local1491281540_0090
2020-11-19 10:20:21  [ Thread-2688:129290 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:21  [ Thread-2688:129290 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:21  [ Thread-2688:129290 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:21  [ Thread-2688:129297 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129297 ] - [ INFO ]  Starting task: attempt_local1491281540_0090_m_000000_0
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129379 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129379 ] - [ INFO ]  Task:attempt_local1491281540_0090_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129385 ] - [ INFO ]  map
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129385 ] - [ INFO ]  Task 'attempt_local1491281540_0090_m_000000_0' done.
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129385 ] - [ INFO ]  Finishing task: attempt_local1491281540_0090_m_000000_0
2020-11-19 10:20:21  [ Thread-2688:129385 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:21  [ Thread-2688:129385 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  Starting task: attempt_local1491281540_0090_r_000000_0
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6bc587ee
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:21  [ EventFetcher for fetching Map Completion Events:129387 ] - [ INFO ]  attempt_local1491281540_0090_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:21  [ localfetcher#90:129387 ] - [ INFO ]  localfetcher#90 about to shuffle output of map attempt_local1491281540_0090_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:21  [ localfetcher#90:129387 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1491281540_0090_m_000000_0
2020-11-19 10:20:21  [ localfetcher#90:129387 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:21  [ EventFetcher for fetching Map Completion Events:129388 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:21  [ pool-273-thread-1:129388 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:21  [ pool-273-thread-1:129388 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:21  [ pool-273-thread-1:129448 ] - [ INFO ]  Task:attempt_local1491281540_0090_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:21  [ pool-273-thread-1:129453 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:21  [ pool-273-thread-1:129453 ] - [ INFO ]  Task attempt_local1491281540_0090_r_000000_0 is allowed to commit now
2020-11-19 10:20:21  [ pool-273-thread-1:129470 ] - [ INFO ]  Saved output of task 'attempt_local1491281540_0090_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1491281540_0090_r_000000
2020-11-19 10:20:21  [ pool-273-thread-1:129471 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:21  [ pool-273-thread-1:129471 ] - [ INFO ]  Task 'attempt_local1491281540_0090_r_000000_0' done.
2020-11-19 10:20:21  [ pool-273-thread-1:129471 ] - [ INFO ]  Finishing task: attempt_local1491281540_0090_r_000000_0
2020-11-19 10:20:21  [ Thread-2688:129471 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]  Job job_local1491281540_0090 running in uber mode : false
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]  Job job_local1491281540_0090 completed successfully
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=188572
		FILE: Number of bytes written=51420618
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5793628
		HDFS: Number of bytes written=95920
		HDFS: Number of read operations=6045
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1960
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2120220672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:22  [ main:130696 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:22  [ main:130712 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:22  [ main:130717 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:22  [ main:130722 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:22  [ main:130762 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:22  [ main:130779 ] - [ INFO ]  Submitting tokens for job: job_local1989001230_0091
2020-11-19 10:20:22  [ main:130807 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:22  [ main:130807 ] - [ INFO ]  Running job: job_local1989001230_0091
2020-11-19 10:20:22  [ Thread-2718:130807 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:22  [ Thread-2718:130807 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:22  [ Thread-2718:130807 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:22  [ Thread-2718:130815 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]  Starting task: attempt_local1989001230_0091_m_000000_0
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130816 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130891 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130891 ] - [ INFO ]  Task:attempt_local1989001230_0091_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130897 ] - [ INFO ]  map
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130897 ] - [ INFO ]  Task 'attempt_local1989001230_0091_m_000000_0' done.
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130897 ] - [ INFO ]  Finishing task: attempt_local1989001230_0091_m_000000_0
2020-11-19 10:20:22  [ Thread-2718:130897 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:22  [ Thread-2718:130897 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:22  [ pool-276-thread-1:130897 ] - [ INFO ]  Starting task: attempt_local1989001230_0091_r_000000_0
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63ad5b8d
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:22  [ EventFetcher for fetching Map Completion Events:130898 ] - [ INFO ]  attempt_local1989001230_0091_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:22  [ localfetcher#91:130899 ] - [ INFO ]  localfetcher#91 about to shuffle output of map attempt_local1989001230_0091_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:22  [ localfetcher#91:130899 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1989001230_0091_m_000000_0
2020-11-19 10:20:22  [ localfetcher#91:130899 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:22  [ EventFetcher for fetching Map Completion Events:130900 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:22  [ pool-276-thread-1:130900 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:22  [ pool-276-thread-1:130900 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:22  [ pool-276-thread-1:130955 ] - [ INFO ]  Task:attempt_local1989001230_0091_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:22  [ pool-276-thread-1:130960 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:22  [ pool-276-thread-1:130960 ] - [ INFO ]  Task attempt_local1989001230_0091_r_000000_0 is allowed to commit now
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  Saved output of task 'attempt_local1989001230_0091_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1989001230_0091_r_000000
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  Task 'attempt_local1989001230_0091_r_000000_0' done.
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  Finishing task: attempt_local1989001230_0091_r_000000_0
2020-11-19 10:20:22  [ Thread-2718:130976 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:23  [ main:131809 ] - [ INFO ]  Job job_local1989001230_0091 running in uber mode : false
2020-11-19 10:20:23  [ main:131809 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:23  [ main:131810 ] - [ INFO ]  Job job_local1989001230_0091 completed successfully
2020-11-19 10:20:23  [ main:131810 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=189764
		FILE: Number of bytes written=51992543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5858034
		HDFS: Number of bytes written=97000
		HDFS: Number of read operations=6113
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1982
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2070937600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:24  [ main:132080 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:24  [ main:132092 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:24  [ main:132097 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:24  [ main:132103 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:24  [ main:132142 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:24  [ main:132159 ] - [ INFO ]  Submitting tokens for job: job_local1676031403_0092
2020-11-19 10:20:24  [ main:132189 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:24  [ main:132189 ] - [ INFO ]  Running job: job_local1676031403_0092
2020-11-19 10:20:24  [ Thread-2748:132190 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:24  [ Thread-2748:132190 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:24  [ Thread-2748:132190 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:24  [ Thread-2748:132199 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  Starting task: attempt_local1676031403_0092_m_000000_0
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132207 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132277 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132277 ] - [ INFO ]  Task:attempt_local1676031403_0092_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132283 ] - [ INFO ]  map
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132283 ] - [ INFO ]  Task 'attempt_local1676031403_0092_m_000000_0' done.
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132283 ] - [ INFO ]  Finishing task: attempt_local1676031403_0092_m_000000_0
2020-11-19 10:20:24  [ Thread-2748:132283 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:24  [ Thread-2748:132283 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  Starting task: attempt_local1676031403_0092_r_000000_0
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2730e8a9
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:24  [ EventFetcher for fetching Map Completion Events:132285 ] - [ INFO ]  attempt_local1676031403_0092_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:24  [ localfetcher#92:132285 ] - [ INFO ]  localfetcher#92 about to shuffle output of map attempt_local1676031403_0092_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:24  [ localfetcher#92:132285 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1676031403_0092_m_000000_0
2020-11-19 10:20:24  [ localfetcher#92:132285 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:24  [ EventFetcher for fetching Map Completion Events:132286 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:24  [ pool-279-thread-1:132286 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:24  [ pool-279-thread-1:132286 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:24  [ pool-279-thread-1:132331 ] - [ INFO ]  Task:attempt_local1676031403_0092_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:24  [ pool-279-thread-1:132336 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:24  [ pool-279-thread-1:132337 ] - [ INFO ]  Task attempt_local1676031403_0092_r_000000_0 is allowed to commit now
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  Saved output of task 'attempt_local1676031403_0092_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1676031403_0092_r_000000
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  Task 'attempt_local1676031403_0092_r_000000_0' done.
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  Finishing task: attempt_local1676031403_0092_r_000000_0
2020-11-19 10:20:24  [ Thread-2748:132354 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:25  [ main:133190 ] - [ INFO ]  Job job_local1676031403_0092 running in uber mode : false
2020-11-19 10:20:25  [ main:133190 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:25  [ main:133191 ] - [ INFO ]  Job job_local1676031403_0092 completed successfully
2020-11-19 10:20:25  [ main:133191 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=190956
		FILE: Number of bytes written=52564466
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5922440
		HDFS: Number of bytes written=98080
		HDFS: Number of read operations=6181
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2004
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2070937600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:25  [ main:133462 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:25  [ main:133473 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:25  [ main:133478 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:25  [ main:133483 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:25  [ main:133525 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:25  [ main:133544 ] - [ INFO ]  Submitting tokens for job: job_local247079369_0093
2020-11-19 10:20:25  [ main:133576 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:25  [ main:133576 ] - [ INFO ]  Running job: job_local247079369_0093
2020-11-19 10:20:25  [ Thread-2778:133576 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:25  [ Thread-2778:133576 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:25  [ Thread-2778:133576 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:25  [ Thread-2778:133583 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]  Starting task: attempt_local247079369_0093_m_000000_0
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133584 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133646 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133647 ] - [ INFO ]  Task:attempt_local247079369_0093_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133654 ] - [ INFO ]  map
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133654 ] - [ INFO ]  Task 'attempt_local247079369_0093_m_000000_0' done.
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133654 ] - [ INFO ]  Finishing task: attempt_local247079369_0093_m_000000_0
2020-11-19 10:20:25  [ Thread-2778:133654 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:25  [ Thread-2778:133654 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:25  [ pool-282-thread-1:133654 ] - [ INFO ]  Starting task: attempt_local247079369_0093_r_000000_0
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e051215
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:25  [ EventFetcher for fetching Map Completion Events:133656 ] - [ INFO ]  attempt_local247079369_0093_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:25  [ localfetcher#93:133656 ] - [ INFO ]  localfetcher#93 about to shuffle output of map attempt_local247079369_0093_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:25  [ localfetcher#93:133656 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local247079369_0093_m_000000_0
2020-11-19 10:20:25  [ localfetcher#93:133656 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:25  [ EventFetcher for fetching Map Completion Events:133657 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:25  [ pool-282-thread-1:133657 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:25  [ pool-282-thread-1:133657 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:25  [ pool-282-thread-1:133657 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:25  [ pool-282-thread-1:133700 ] - [ INFO ]  Task:attempt_local247079369_0093_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:25  [ pool-282-thread-1:133706 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:25  [ pool-282-thread-1:133706 ] - [ INFO ]  Task attempt_local247079369_0093_r_000000_0 is allowed to commit now
2020-11-19 10:20:25  [ pool-282-thread-1:133723 ] - [ INFO ]  Saved output of task 'attempt_local247079369_0093_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local247079369_0093_r_000000
2020-11-19 10:20:25  [ pool-282-thread-1:133724 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:25  [ pool-282-thread-1:133724 ] - [ INFO ]  Task 'attempt_local247079369_0093_r_000000_0' done.
2020-11-19 10:20:25  [ pool-282-thread-1:133724 ] - [ INFO ]  Finishing task: attempt_local247079369_0093_r_000000_0
2020-11-19 10:20:25  [ Thread-2778:133724 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:26  [ main:134576 ] - [ INFO ]  Job job_local247079369_0093 running in uber mode : false
2020-11-19 10:20:26  [ main:134576 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:26  [ main:134576 ] - [ INFO ]  Job job_local247079369_0093 completed successfully
2020-11-19 10:20:26  [ main:134577 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=192146
		FILE: Number of bytes written=53133340
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5986846
		HDFS: Number of bytes written=99160
		HDFS: Number of read operations=6249
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2026
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2070937600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:26  [ main:134882 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:26  [ main:134894 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:26  [ main:134899 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:26  [ main:134904 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:26  [ main:134947 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:26  [ main:134964 ] - [ INFO ]  Submitting tokens for job: job_local808920590_0094
2020-11-19 10:20:26  [ main:134993 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:26  [ main:134993 ] - [ INFO ]  Running job: job_local808920590_0094
2020-11-19 10:20:26  [ Thread-2808:134993 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:26  [ Thread-2808:134993 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:26  [ Thread-2808:134994 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:27  [ Thread-2808:135000 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]  Starting task: attempt_local808920590_0094_m_000000_0
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135001 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135082 ] - [ INFO ]  
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135084 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135085 ] - [ INFO ]  Task:attempt_local808920590_0094_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135091 ] - [ INFO ]  map
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135091 ] - [ INFO ]  Task 'attempt_local808920590_0094_m_000000_0' done.
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135091 ] - [ INFO ]  Finishing task: attempt_local808920590_0094_m_000000_0
2020-11-19 10:20:27  [ Thread-2808:135091 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:27  [ Thread-2808:135091 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:27  [ pool-285-thread-1:135091 ] - [ INFO ]  Starting task: attempt_local808920590_0094_r_000000_0
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@34d20946
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:27  [ EventFetcher for fetching Map Completion Events:135092 ] - [ INFO ]  attempt_local808920590_0094_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:27  [ localfetcher#94:135093 ] - [ INFO ]  localfetcher#94 about to shuffle output of map attempt_local808920590_0094_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:27  [ localfetcher#94:135093 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local808920590_0094_m_000000_0
2020-11-19 10:20:27  [ localfetcher#94:135093 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:27  [ EventFetcher for fetching Map Completion Events:135093 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:27  [ pool-285-thread-1:135093 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:27  [ pool-285-thread-1:135093 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:27  [ pool-285-thread-1:135094 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:27  [ pool-285-thread-1:135094 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:27  [ pool-285-thread-1:135148 ] - [ INFO ]  Task:attempt_local808920590_0094_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:27  [ pool-285-thread-1:135154 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:27  [ pool-285-thread-1:135154 ] - [ INFO ]  Task attempt_local808920590_0094_r_000000_0 is allowed to commit now
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  Saved output of task 'attempt_local808920590_0094_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local808920590_0094_r_000000
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  Task 'attempt_local808920590_0094_r_000000_0' done.
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  Finishing task: attempt_local808920590_0094_r_000000_0
2020-11-19 10:20:27  [ Thread-2808:135173 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:27  [ main:135995 ] - [ INFO ]  Job job_local808920590_0094 running in uber mode : false
2020-11-19 10:20:27  [ main:135995 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:27  [ main:135996 ] - [ INFO ]  Job job_local808920590_0094 completed successfully
2020-11-19 10:20:27  [ main:135996 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=193338
		FILE: Number of bytes written=53702217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6051252
		HDFS: Number of bytes written=100240
		HDFS: Number of read operations=6317
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2048
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:28  [ main:136288 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:28  [ main:136300 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:28  [ main:136305 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:28  [ main:136310 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:28  [ main:136351 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:28  [ main:136368 ] - [ INFO ]  Submitting tokens for job: job_local1789788895_0095
2020-11-19 10:20:28  [ main:136407 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:28  [ main:136407 ] - [ INFO ]  Running job: job_local1789788895_0095
2020-11-19 10:20:28  [ Thread-2838:136407 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:28  [ Thread-2838:136407 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:28  [ Thread-2838:136407 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:28  [ Thread-2838:136416 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]  Starting task: attempt_local1789788895_0095_m_000000_0
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136417 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136503 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136504 ] - [ INFO ]  Task:attempt_local1789788895_0095_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136510 ] - [ INFO ]  map
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136510 ] - [ INFO ]  Task 'attempt_local1789788895_0095_m_000000_0' done.
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136510 ] - [ INFO ]  Finishing task: attempt_local1789788895_0095_m_000000_0
2020-11-19 10:20:28  [ Thread-2838:136510 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:28  [ Thread-2838:136510 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  Starting task: attempt_local1789788895_0095_r_000000_0
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46de3cfc
2020-11-19 10:20:28  [ pool-288-thread-1:136511 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:28  [ EventFetcher for fetching Map Completion Events:136511 ] - [ INFO ]  attempt_local1789788895_0095_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:28  [ localfetcher#95:136511 ] - [ INFO ]  localfetcher#95 about to shuffle output of map attempt_local1789788895_0095_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:28  [ localfetcher#95:136512 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1789788895_0095_m_000000_0
2020-11-19 10:20:28  [ localfetcher#95:136512 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:28  [ EventFetcher for fetching Map Completion Events:136512 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:28  [ pool-288-thread-1:136512 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:28  [ pool-288-thread-1:136512 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:28  [ pool-288-thread-1:136514 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:28  [ pool-288-thread-1:136514 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:28  [ pool-288-thread-1:136568 ] - [ INFO ]  Task:attempt_local1789788895_0095_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:28  [ pool-288-thread-1:136574 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:28  [ pool-288-thread-1:136574 ] - [ INFO ]  Task attempt_local1789788895_0095_r_000000_0 is allowed to commit now
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  Saved output of task 'attempt_local1789788895_0095_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1789788895_0095_r_000000
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  Task 'attempt_local1789788895_0095_r_000000_0' done.
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  Finishing task: attempt_local1789788895_0095_r_000000_0
2020-11-19 10:20:28  [ Thread-2838:136590 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:29  [ main:137409 ] - [ INFO ]  Job job_local1789788895_0095 running in uber mode : false
2020-11-19 10:20:29  [ main:137409 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:29  [ main:137409 ] - [ INFO ]  Job job_local1789788895_0095 completed successfully
2020-11-19 10:20:29  [ main:137410 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=194530
		FILE: Number of bytes written=54274140
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6115658
		HDFS: Number of bytes written=101320
		HDFS: Number of read operations=6385
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2070
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:29  [ main:137677 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:29  [ main:137688 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:29  [ main:137693 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:29  [ main:137697 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:29  [ main:137738 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:29  [ main:137755 ] - [ INFO ]  Submitting tokens for job: job_local1478274252_0096
2020-11-19 10:20:29  [ main:137786 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:29  [ main:137786 ] - [ INFO ]  Running job: job_local1478274252_0096
2020-11-19 10:20:29  [ Thread-2868:137786 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:29  [ Thread-2868:137786 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:29  [ Thread-2868:137786 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:29  [ Thread-2868:137793 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137793 ] - [ INFO ]  Starting task: attempt_local1478274252_0096_m_000000_0
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137876 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137877 ] - [ INFO ]  Task:attempt_local1478274252_0096_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137882 ] - [ INFO ]  map
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137883 ] - [ INFO ]  Task 'attempt_local1478274252_0096_m_000000_0' done.
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137883 ] - [ INFO ]  Finishing task: attempt_local1478274252_0096_m_000000_0
2020-11-19 10:20:29  [ Thread-2868:137883 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:29  [ Thread-2868:137883 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:29  [ pool-291-thread-1:137883 ] - [ INFO ]  Starting task: attempt_local1478274252_0096_r_000000_0
2020-11-19 10:20:29  [ pool-291-thread-1:137883 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ea8b1c9
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:29  [ EventFetcher for fetching Map Completion Events:137884 ] - [ INFO ]  attempt_local1478274252_0096_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:29  [ localfetcher#96:137885 ] - [ INFO ]  localfetcher#96 about to shuffle output of map attempt_local1478274252_0096_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:29  [ localfetcher#96:137885 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1478274252_0096_m_000000_0
2020-11-19 10:20:29  [ localfetcher#96:137885 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:29  [ EventFetcher for fetching Map Completion Events:137885 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:29  [ pool-291-thread-1:137886 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:29  [ pool-291-thread-1:137886 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:29  [ pool-291-thread-1:137943 ] - [ INFO ]  Task:attempt_local1478274252_0096_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:29  [ pool-291-thread-1:137952 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:29  [ pool-291-thread-1:137952 ] - [ INFO ]  Task attempt_local1478274252_0096_r_000000_0 is allowed to commit now
2020-11-19 10:20:29  [ pool-291-thread-1:137968 ] - [ INFO ]  Saved output of task 'attempt_local1478274252_0096_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1478274252_0096_r_000000
2020-11-19 10:20:29  [ pool-291-thread-1:137969 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:29  [ pool-291-thread-1:137969 ] - [ INFO ]  Task 'attempt_local1478274252_0096_r_000000_0' done.
2020-11-19 10:20:29  [ pool-291-thread-1:137969 ] - [ INFO ]  Finishing task: attempt_local1478274252_0096_r_000000_0
2020-11-19 10:20:29  [ Thread-2868:137969 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:30  [ main:138788 ] - [ INFO ]  Job job_local1478274252_0096 running in uber mode : false
2020-11-19 10:20:30  [ main:138788 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:30  [ main:138789 ] - [ INFO ]  Job job_local1478274252_0096 completed successfully
2020-11-19 10:20:30  [ main:138789 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=195720
		FILE: Number of bytes written=54846062
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6180064
		HDFS: Number of bytes written=102400
		HDFS: Number of read operations=6453
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2092
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:31  [ main:139465 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:31  [ main:139475 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:31  [ main:139480 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:31  [ main:139485 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:31  [ main:139526 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:31  [ main:139543 ] - [ INFO ]  Submitting tokens for job: job_local1148258781_0097
2020-11-19 10:20:31  [ main:139572 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:31  [ main:139572 ] - [ INFO ]  Running job: job_local1148258781_0097
2020-11-19 10:20:31  [ Thread-2898:139572 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:31  [ Thread-2898:139572 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:31  [ Thread-2898:139572 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:31  [ Thread-2898:139579 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139579 ] - [ INFO ]  Starting task: attempt_local1148258781_0097_m_000000_0
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139660 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139661 ] - [ INFO ]  Task:attempt_local1148258781_0097_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139667 ] - [ INFO ]  map
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139667 ] - [ INFO ]  Task 'attempt_local1148258781_0097_m_000000_0' done.
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139667 ] - [ INFO ]  Finishing task: attempt_local1148258781_0097_m_000000_0
2020-11-19 10:20:31  [ Thread-2898:139667 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:31  [ Thread-2898:139668 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  Starting task: attempt_local1148258781_0097_r_000000_0
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@443dc3
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:31  [ EventFetcher for fetching Map Completion Events:139669 ] - [ INFO ]  attempt_local1148258781_0097_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:31  [ localfetcher#97:139669 ] - [ INFO ]  localfetcher#97 about to shuffle output of map attempt_local1148258781_0097_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:31  [ localfetcher#97:139669 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1148258781_0097_m_000000_0
2020-11-19 10:20:31  [ localfetcher#97:139669 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:31  [ EventFetcher for fetching Map Completion Events:139670 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:31  [ pool-294-thread-1:139670 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:31  [ pool-294-thread-1:139670 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:31  [ pool-294-thread-1:139714 ] - [ INFO ]  Task:attempt_local1148258781_0097_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:31  [ pool-294-thread-1:139720 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:31  [ pool-294-thread-1:139720 ] - [ INFO ]  Task attempt_local1148258781_0097_r_000000_0 is allowed to commit now
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  Saved output of task 'attempt_local1148258781_0097_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1148258781_0097_r_000000
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  Task 'attempt_local1148258781_0097_r_000000_0' done.
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  Finishing task: attempt_local1148258781_0097_r_000000_0
2020-11-19 10:20:31  [ Thread-2898:139737 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:32  [ main:140572 ] - [ INFO ]  Job job_local1148258781_0097 running in uber mode : false
2020-11-19 10:20:32  [ main:140572 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:32  [ main:140573 ] - [ INFO ]  Job job_local1148258781_0097 completed successfully
2020-11-19 10:20:32  [ main:140573 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=196912
		FILE: Number of bytes written=55417987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6244470
		HDFS: Number of bytes written=103480
		HDFS: Number of read operations=6521
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2114
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1977614336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:32  [ main:140853 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:32  [ main:140864 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:32  [ main:140868 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:32  [ main:140873 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:32  [ main:140915 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:32  [ main:140932 ] - [ INFO ]  Submitting tokens for job: job_local1061958396_0098
2020-11-19 10:20:32  [ main:140960 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:32  [ main:140960 ] - [ INFO ]  Running job: job_local1061958396_0098
2020-11-19 10:20:32  [ Thread-2928:140960 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:32  [ Thread-2928:140960 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:32  [ Thread-2928:140961 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:32  [ Thread-2928:140968 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  Starting task: attempt_local1061958396_0098_m_000000_0
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141051 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141051 ] - [ INFO ]  Task:attempt_local1061958396_0098_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141057 ] - [ INFO ]  map
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141057 ] - [ INFO ]  Task 'attempt_local1061958396_0098_m_000000_0' done.
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141057 ] - [ INFO ]  Finishing task: attempt_local1061958396_0098_m_000000_0
2020-11-19 10:20:33  [ Thread-2928:141057 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:33  [ Thread-2928:141058 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  Starting task: attempt_local1061958396_0098_r_000000_0
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@433fdfdf
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:33  [ EventFetcher for fetching Map Completion Events:141059 ] - [ INFO ]  attempt_local1061958396_0098_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:33  [ localfetcher#98:141059 ] - [ INFO ]  localfetcher#98 about to shuffle output of map attempt_local1061958396_0098_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:33  [ localfetcher#98:141059 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1061958396_0098_m_000000_0
2020-11-19 10:20:33  [ localfetcher#98:141059 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:33  [ EventFetcher for fetching Map Completion Events:141060 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:33  [ pool-297-thread-1:141060 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:33  [ pool-297-thread-1:141060 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:33  [ pool-297-thread-1:141116 ] - [ INFO ]  Task:attempt_local1061958396_0098_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:33  [ pool-297-thread-1:141121 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:33  [ pool-297-thread-1:141121 ] - [ INFO ]  Task attempt_local1061958396_0098_r_000000_0 is allowed to commit now
2020-11-19 10:20:33  [ pool-297-thread-1:141139 ] - [ INFO ]  Saved output of task 'attempt_local1061958396_0098_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1061958396_0098_r_000000
2020-11-19 10:20:33  [ pool-297-thread-1:141140 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:33  [ pool-297-thread-1:141140 ] - [ INFO ]  Task 'attempt_local1061958396_0098_r_000000_0' done.
2020-11-19 10:20:33  [ pool-297-thread-1:141140 ] - [ INFO ]  Finishing task: attempt_local1061958396_0098_r_000000_0
2020-11-19 10:20:33  [ Thread-2928:141140 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]  Job job_local1061958396_0098 running in uber mode : false
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]  Job job_local1061958396_0098 completed successfully
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=198104
		FILE: Number of bytes written=55989910
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6308876
		HDFS: Number of bytes written=104560
		HDFS: Number of read operations=6589
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2136
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1977614336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:34  [ main:142253 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:34  [ main:142264 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:34  [ main:142269 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:34  [ main:142276 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:34  [ main:142318 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:34  [ main:142335 ] - [ INFO ]  Submitting tokens for job: job_local1823907077_0099
2020-11-19 10:20:34  [ main:142366 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:34  [ main:142366 ] - [ INFO ]  Running job: job_local1823907077_0099
2020-11-19 10:20:34  [ Thread-2958:142366 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:34  [ Thread-2958:142366 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:34  [ Thread-2958:142366 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:34  [ Thread-2958:142373 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]  Starting task: attempt_local1823907077_0099_m_000000_0
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142374 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142684 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142685 ] - [ INFO ]  Task:attempt_local1823907077_0099_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142696 ] - [ INFO ]  map
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142696 ] - [ INFO ]  Task 'attempt_local1823907077_0099_m_000000_0' done.
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142696 ] - [ INFO ]  Finishing task: attempt_local1823907077_0099_m_000000_0
2020-11-19 10:20:34  [ Thread-2958:142697 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:34  [ Thread-2958:142697 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  Starting task: attempt_local1823907077_0099_r_000000_0
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ed83bba
2020-11-19 10:20:34  [ pool-300-thread-1:142698 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:34  [ EventFetcher for fetching Map Completion Events:142699 ] - [ INFO ]  attempt_local1823907077_0099_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:34  [ localfetcher#99:142699 ] - [ INFO ]  localfetcher#99 about to shuffle output of map attempt_local1823907077_0099_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:34  [ localfetcher#99:142699 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1823907077_0099_m_000000_0
2020-11-19 10:20:34  [ localfetcher#99:142699 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:34  [ EventFetcher for fetching Map Completion Events:142700 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:34  [ pool-300-thread-1:142700 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:34  [ pool-300-thread-1:142700 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:34  [ pool-300-thread-1:142754 ] - [ INFO ]  Task:attempt_local1823907077_0099_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:34  [ pool-300-thread-1:142759 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:34  [ pool-300-thread-1:142759 ] - [ INFO ]  Task attempt_local1823907077_0099_r_000000_0 is allowed to commit now
2020-11-19 10:20:34  [ pool-300-thread-1:142775 ] - [ INFO ]  Saved output of task 'attempt_local1823907077_0099_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1823907077_0099_r_000000
2020-11-19 10:20:34  [ pool-300-thread-1:142775 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:34  [ pool-300-thread-1:142775 ] - [ INFO ]  Task 'attempt_local1823907077_0099_r_000000_0' done.
2020-11-19 10:20:34  [ pool-300-thread-1:142776 ] - [ INFO ]  Finishing task: attempt_local1823907077_0099_r_000000_0
2020-11-19 10:20:34  [ Thread-2958:142776 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:35  [ main:143368 ] - [ INFO ]  Job job_local1823907077_0099 running in uber mode : false
2020-11-19 10:20:35  [ main:143368 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:35  [ main:143368 ] - [ INFO ]  Job job_local1823907077_0099 completed successfully
2020-11-19 10:20:35  [ main:143369 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=199294
		FILE: Number of bytes written=56561832
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6373282
		HDFS: Number of bytes written=105640
		HDFS: Number of read operations=6657
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2158
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1977614336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:35  [ main:143664 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:35  [ main:143675 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:35  [ main:143680 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:35  [ main:143686 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:35  [ main:143723 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:35  [ main:143740 ] - [ INFO ]  Submitting tokens for job: job_local1542952657_0100
2020-11-19 10:20:35  [ main:143768 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:35  [ main:143768 ] - [ INFO ]  Running job: job_local1542952657_0100
2020-11-19 10:20:35  [ Thread-2988:143768 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:35  [ Thread-2988:143768 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:35  [ Thread-2988:143768 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:35  [ Thread-2988:143776 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  Starting task: attempt_local1542952657_0100_m_000000_0
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143858 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143858 ] - [ INFO ]  Task:attempt_local1542952657_0100_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143864 ] - [ INFO ]  map
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143864 ] - [ INFO ]  Task 'attempt_local1542952657_0100_m_000000_0' done.
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143865 ] - [ INFO ]  Finishing task: attempt_local1542952657_0100_m_000000_0
2020-11-19 10:20:35  [ Thread-2988:143865 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:35  [ Thread-2988:143865 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  Starting task: attempt_local1542952657_0100_r_000000_0
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f44a097
2020-11-19 10:20:35  [ pool-303-thread-1:143866 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:35  [ EventFetcher for fetching Map Completion Events:143866 ] - [ INFO ]  attempt_local1542952657_0100_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:35  [ localfetcher#100:143867 ] - [ INFO ]  localfetcher#100 about to shuffle output of map attempt_local1542952657_0100_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:35  [ localfetcher#100:143867 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1542952657_0100_m_000000_0
2020-11-19 10:20:35  [ localfetcher#100:143867 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:35  [ EventFetcher for fetching Map Completion Events:143867 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:35  [ pool-303-thread-1:143867 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:35  [ pool-303-thread-1:143867 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:35  [ pool-303-thread-1:143868 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:35  [ pool-303-thread-1:143868 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:35  [ pool-303-thread-1:143922 ] - [ INFO ]  Task:attempt_local1542952657_0100_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:35  [ pool-303-thread-1:143928 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:35  [ pool-303-thread-1:143928 ] - [ INFO ]  Task attempt_local1542952657_0100_r_000000_0 is allowed to commit now
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  Saved output of task 'attempt_local1542952657_0100_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1542952657_0100_r_000000
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  Task 'attempt_local1542952657_0100_r_000000_0' done.
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  Finishing task: attempt_local1542952657_0100_r_000000_0
2020-11-19 10:20:35  [ Thread-2988:143947 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]  Job job_local1542952657_0100 running in uber mode : false
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]  Job job_local1542952657_0100 completed successfully
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=200486
		FILE: Number of bytes written=57133757
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6437688
		HDFS: Number of bytes written=106720
		HDFS: Number of read operations=6725
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2180
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1935671296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:37  [ main:145040 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:37  [ main:145055 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:37  [ main:145060 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:37  [ main:145065 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:37  [ main:145107 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:37  [ main:145125 ] - [ INFO ]  Submitting tokens for job: job_local963953789_0101
2020-11-19 10:20:37  [ main:145157 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:37  [ main:145157 ] - [ INFO ]  Running job: job_local963953789_0101
2020-11-19 10:20:37  [ Thread-3018:145157 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:37  [ Thread-3018:145157 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:37  [ Thread-3018:145157 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:37  [ Thread-3018:145164 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145164 ] - [ INFO ]  Starting task: attempt_local963953789_0101_m_000000_0
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145243 ] - [ INFO ]  
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145245 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145246 ] - [ INFO ]  Task:attempt_local963953789_0101_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145253 ] - [ INFO ]  map
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145253 ] - [ INFO ]  Task 'attempt_local963953789_0101_m_000000_0' done.
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145253 ] - [ INFO ]  Finishing task: attempt_local963953789_0101_m_000000_0
2020-11-19 10:20:37  [ Thread-3018:145253 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:37  [ Thread-3018:145253 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:37  [ pool-306-thread-1:145253 ] - [ INFO ]  Starting task: attempt_local963953789_0101_r_000000_0
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@417a3bce
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:37  [ EventFetcher for fetching Map Completion Events:145254 ] - [ INFO ]  attempt_local963953789_0101_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:37  [ localfetcher#101:145255 ] - [ INFO ]  localfetcher#101 about to shuffle output of map attempt_local963953789_0101_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:37  [ localfetcher#101:145255 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local963953789_0101_m_000000_0
2020-11-19 10:20:37  [ localfetcher#101:145255 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:37  [ EventFetcher for fetching Map Completion Events:145255 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:37  [ pool-306-thread-1:145299 ] - [ INFO ]  Task:attempt_local963953789_0101_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:37  [ pool-306-thread-1:145304 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:37  [ pool-306-thread-1:145304 ] - [ INFO ]  Task attempt_local963953789_0101_r_000000_0 is allowed to commit now
2020-11-19 10:20:37  [ pool-306-thread-1:145320 ] - [ INFO ]  Saved output of task 'attempt_local963953789_0101_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local963953789_0101_r_000000
2020-11-19 10:20:37  [ pool-306-thread-1:145321 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:37  [ pool-306-thread-1:145321 ] - [ INFO ]  Task 'attempt_local963953789_0101_r_000000_0' done.
2020-11-19 10:20:37  [ pool-306-thread-1:145321 ] - [ INFO ]  Finishing task: attempt_local963953789_0101_r_000000_0
2020-11-19 10:20:37  [ Thread-3018:145321 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:38  [ main:146157 ] - [ INFO ]  Job job_local963953789_0101 running in uber mode : false
2020-11-19 10:20:38  [ main:146158 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:38  [ main:146158 ] - [ INFO ]  Job job_local963953789_0101 completed successfully
2020-11-19 10:20:38  [ main:146158 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=201678
		FILE: Number of bytes written=57702632
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6502094
		HDFS: Number of bytes written=107800
		HDFS: Number of read operations=6793
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2202
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1935671296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:38  [ main:146326 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:38  [ main:146337 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:38  [ main:146342 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:38  [ main:146348 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:38  [ main:146390 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:38  [ main:146408 ] - [ INFO ]  Submitting tokens for job: job_local385966202_0102
2020-11-19 10:20:38  [ main:146441 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:38  [ main:146441 ] - [ INFO ]  Running job: job_local385966202_0102
2020-11-19 10:20:38  [ Thread-3046:146441 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:38  [ Thread-3046:146441 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:38  [ Thread-3046:146441 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:38  [ Thread-3046:146448 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146448 ] - [ INFO ]  Starting task: attempt_local385966202_0102_m_000000_0
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146448 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146449 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146449 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146449 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/tmp/center.txt:0+180
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146457 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  bufstart = 0; bufend = 122; bufvoid = 104857600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146509 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146510 ] - [ INFO ]  Task:attempt_local385966202_0102_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146516 ] - [ INFO ]  map
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146516 ] - [ INFO ]  Task 'attempt_local385966202_0102_m_000000_0' done.
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146516 ] - [ INFO ]  Finishing task: attempt_local385966202_0102_m_000000_0
2020-11-19 10:20:38  [ Thread-3046:146516 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:38  [ Thread-3046:146516 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:38  [ pool-309-thread-1:146516 ] - [ INFO ]  Starting task: attempt_local385966202_0102_r_000000_0
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b3919dd
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:38  [ EventFetcher for fetching Map Completion Events:146517 ] - [ INFO ]  attempt_local385966202_0102_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:38  [ localfetcher#102:146518 ] - [ INFO ]  localfetcher#102 about to shuffle output of map attempt_local385966202_0102_m_000000_0 decomp: 136 len: 140 to MEMORY
2020-11-19 10:20:38  [ localfetcher#102:146518 ] - [ INFO ]  Read 136 bytes from map-output for attempt_local385966202_0102_m_000000_0
2020-11-19 10:20:38  [ localfetcher#102:146518 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->136
2020-11-19 10:20:38  [ EventFetcher for fetching Map Completion Events:146518 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:38  [ pool-309-thread-1:146519 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:38  [ pool-309-thread-1:146519 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 132 bytes
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merged 1 segments, 136 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 1 files, 140 bytes from disk
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 132 bytes
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:38  [ pool-309-thread-1:146562 ] - [ INFO ]  Task:attempt_local385966202_0102_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:38  [ pool-309-thread-1:146568 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:38  [ pool-309-thread-1:146568 ] - [ INFO ]  Task attempt_local385966202_0102_r_000000_0 is allowed to commit now
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  Saved output of task 'attempt_local385966202_0102_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local385966202_0102_r_000000
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  Task 'attempt_local385966202_0102_r_000000_0' done.
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  Finishing task: attempt_local385966202_0102_r_000000_0
2020-11-19 10:20:38  [ Thread-3046:146586 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:39  [ main:147441 ] - [ INFO ]  Job job_local385966202_0102 running in uber mode : false
2020-11-19 10:20:39  [ main:147442 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:39  [ main:147442 ] - [ INFO ]  Job job_local385966202_0102 completed successfully
2020-11-19 10:20:39  [ main:147442 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=202760
		FILE: Number of bytes written=58271352
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6503894
		HDFS: Number of bytes written=108462
		HDFS: Number of read operations=6851
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2220
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Map output bytes=122
		Map output materialized bytes=140
		Input split bytes=123
		Combine input records=3
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=140
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1935671296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=180
	File Output Format Counters 
		Bytes Written=122
2020-11-19 12:45:20  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 12:45:21  [ main:674 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 12:45:21  [ main:674 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 12:45:21  [ main:1141 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:45:21  [ main:1147 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:45:21  [ main:1170 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:45:21  [ main:1262 ] - [ INFO ]  number of splits:1
2020-11-19 12:45:21  [ main:1338 ] - [ INFO ]  Submitting tokens for job: job_local958852669_0001
2020-11-19 12:45:21  [ main:1435 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:45:21  [ main:1436 ] - [ INFO ]  Running job: job_local958852669_0001
2020-11-19 12:45:21  [ Thread-18:1436 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:45:21  [ Thread-18:1439 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:45:21  [ Thread-18:1440 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:45:21  [ Thread-18:1486 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:45:21  [ LocalJobRunner Map Task Executor #0:1486 ] - [ INFO ]  Starting task: attempt_local958852669_0001_m_000000_0
2020-11-19 12:45:21  [ LocalJobRunner Map Task Executor #0:1501 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:45:21  [ LocalJobRunner Map Task Executor #0:1505 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:45:21  [ LocalJobRunner Map Task Executor #0:1505 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:45:21  [ LocalJobRunner Map Task Executor #0:1507 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:45:22  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:45:22  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:45:22  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:45:22  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:45:22  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:45:22  [ LocalJobRunner Map Task Executor #0:1562 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:45:22  [ main:2440 ] - [ INFO ]  Job job_local958852669_0001 running in uber mode : false
2020-11-19 12:45:22  [ main:2442 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:45:27  [ communication thread:7516 ] - [ INFO ]  map > map
2020-11-19 12:45:28  [ main:8459 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 12:45:30  [ communication thread:10521 ] - [ INFO ]  map > map
2020-11-19 12:45:31  [ main:11470 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 12:45:33  [ communication thread:13525 ] - [ INFO ]  map > map
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14304 ] - [ INFO ]  map > map
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14306 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14306 ] - [ INFO ]  Spilling map output
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14306 ] - [ INFO ]  bufstart = 0; bufend = 351118; bufvoid = 104857600
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14306 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14423 ] - [ INFO ]  Finished spill 0
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14426 ] - [ INFO ]  Task:attempt_local958852669_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14442 ] - [ INFO ]  map
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14442 ] - [ INFO ]  Task 'attempt_local958852669_0001_m_000000_0' done.
2020-11-19 12:45:34  [ LocalJobRunner Map Task Executor #0:14442 ] - [ INFO ]  Finishing task: attempt_local958852669_0001_m_000000_0
2020-11-19 12:45:34  [ Thread-18:14442 ] - [ INFO ]  map task executor complete.
2020-11-19 12:45:34  [ Thread-18:14444 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:45:34  [ pool-6-thread-1:14444 ] - [ INFO ]  Starting task: attempt_local958852669_0001_r_000000_0
2020-11-19 12:45:34  [ pool-6-thread-1:14449 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:45:34  [ pool-6-thread-1:14449 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:45:34  [ pool-6-thread-1:14449 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:45:34  [ pool-6-thread-1:14451 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1fcdb6e0
2020-11-19 12:45:34  [ pool-6-thread-1:14461 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:45:34  [ EventFetcher for fetching Map Completion Events:14462 ] - [ INFO ]  attempt_local958852669_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:45:34  [ main:14476 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 12:45:34  [ localfetcher#1:14484 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local958852669_0001_m_000000_0 decomp: 5552 len: 5556 to MEMORY
2020-11-19 12:45:34  [ localfetcher#1:14488 ] - [ INFO ]  Read 5552 bytes from map-output for attempt_local958852669_0001_m_000000_0
2020-11-19 12:45:34  [ localfetcher#1:14489 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 5552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5552
2020-11-19 12:45:34  [ EventFetcher for fetching Map Completion Events:14490 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:45:34  [ pool-6-thread-1:14491 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:45:34  [ pool-6-thread-1:14491 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:45:34  [ pool-6-thread-1:14499 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:45:34  [ pool-6-thread-1:14499 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:45:34  [ pool-6-thread-1:14504 ] - [ INFO ]  Merged 1 segments, 5552 bytes to disk to satisfy reduce memory limit
2020-11-19 12:45:34  [ pool-6-thread-1:14504 ] - [ INFO ]  Merging 1 files, 5556 bytes from disk
2020-11-19 12:45:34  [ pool-6-thread-1:14504 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:45:34  [ pool-6-thread-1:14504 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:45:34  [ pool-6-thread-1:14505 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:45:34  [ pool-6-thread-1:14505 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:45:34  [ pool-6-thread-1:14525 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 12:45:35  [ pool-6-thread-1:14618 ] - [ INFO ]  Task:attempt_local958852669_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 12:45:35  [ pool-6-thread-1:14625 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:45:35  [ pool-6-thread-1:14625 ] - [ INFO ]  Task attempt_local958852669_0001_r_000000_0 is allowed to commit now
2020-11-19 12:45:35  [ pool-6-thread-1:14646 ] - [ INFO ]  Saved output of task 'attempt_local958852669_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605761120040/_temporary/0/task_local958852669_0001_r_000000
2020-11-19 12:45:35  [ pool-6-thread-1:14646 ] - [ INFO ]  reduce > reduce
2020-11-19 12:45:35  [ pool-6-thread-1:14647 ] - [ INFO ]  Task 'attempt_local958852669_0001_r_000000_0' done.
2020-11-19 12:45:35  [ pool-6-thread-1:14647 ] - [ INFO ]  Finishing task: attempt_local958852669_0001_r_000000_0
2020-11-19 12:45:35  [ Thread-18:14647 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:45:35  [ main:15478 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:45:35  [ main:15479 ] - [ INFO ]  Job job_local958852669_0001 completed successfully
2020-11-19 12:45:35  [ main:15487 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=11476
		FILE: Number of bytes written=583432
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=3664
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=351118
		Map output materialized bytes=5556
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=5556
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=670040064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=3664
2020-11-19 12:45:36  [ main:15847 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 12:45:36  [ main:15860 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:45:36  [ main:15864 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:45:36  [ main:15872 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:45:36  [ main:15913 ] - [ INFO ]  number of splits:1
2020-11-19 12:45:36  [ main:15933 ] - [ INFO ]  Submitting tokens for job: job_local860866_0002
2020-11-19 12:45:36  [ main:15977 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:45:36  [ main:15977 ] - [ INFO ]  Running job: job_local860866_0002
2020-11-19 12:45:36  [ Thread-49:15977 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:45:36  [ Thread-49:15978 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:45:36  [ Thread-49:15978 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:45:36  [ Thread-49:15986 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:15986 ] - [ INFO ]  Starting task: attempt_local860866_0002_m_000000_0
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:15987 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:15987 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:15987 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:15988 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:16032 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:16032 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:16032 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:16032 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:16032 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:45:36  [ LocalJobRunner Map Task Executor #0:16033 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:45:37  [ main:16981 ] - [ INFO ]  Job job_local860866_0002 running in uber mode : false
2020-11-19 12:45:37  [ main:16981 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:45:42  [ communication thread:21992 ] - [ INFO ]  map > map
2020-11-19 12:45:42  [ main:22003 ] - [ INFO ]   map 34% reduce 0%
2020-11-19 12:45:45  [ communication thread:24993 ] - [ INFO ]  map > map
2020-11-19 12:45:45  [ main:25013 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 12:45:48  [ communication thread:27997 ] - [ INFO ]  map > map
2020-11-19 12:45:48  [ main:28026 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28670 ] - [ INFO ]  map > map
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28670 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28670 ] - [ INFO ]  Spilling map output
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28670 ] - [ INFO ]  bufstart = 0; bufend = 354543; bufvoid = 104857600
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28670 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28730 ] - [ INFO ]  Finished spill 0
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28731 ] - [ INFO ]  Task:attempt_local860866_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28753 ] - [ INFO ]  map
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28753 ] - [ INFO ]  Task 'attempt_local860866_0002_m_000000_0' done.
2020-11-19 12:45:49  [ LocalJobRunner Map Task Executor #0:28753 ] - [ INFO ]  Finishing task: attempt_local860866_0002_m_000000_0
2020-11-19 12:45:49  [ Thread-49:28754 ] - [ INFO ]  map task executor complete.
2020-11-19 12:45:49  [ Thread-49:28754 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:45:49  [ pool-9-thread-1:28754 ] - [ INFO ]  Starting task: attempt_local860866_0002_r_000000_0
2020-11-19 12:45:49  [ pool-9-thread-1:28755 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:45:49  [ pool-9-thread-1:28755 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:45:49  [ pool-9-thread-1:28755 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:45:49  [ pool-9-thread-1:28755 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29b0af36
2020-11-19 12:45:49  [ pool-9-thread-1:28756 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:45:49  [ EventFetcher for fetching Map Completion Events:28757 ] - [ INFO ]  attempt_local860866_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:45:49  [ localfetcher#2:28758 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local860866_0002_m_000000_0 decomp: 10655 len: 10659 to MEMORY
2020-11-19 12:45:49  [ localfetcher#2:28758 ] - [ INFO ]  Read 10655 bytes from map-output for attempt_local860866_0002_m_000000_0
2020-11-19 12:45:49  [ localfetcher#2:28758 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 10655, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10655
2020-11-19 12:45:49  [ EventFetcher for fetching Map Completion Events:28759 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:45:49  [ pool-9-thread-1:28759 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:45:49  [ pool-9-thread-1:28759 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:45:49  [ pool-9-thread-1:28760 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:45:49  [ pool-9-thread-1:28760 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:45:49  [ pool-9-thread-1:28761 ] - [ INFO ]  Merged 1 segments, 10655 bytes to disk to satisfy reduce memory limit
2020-11-19 12:45:49  [ pool-9-thread-1:28761 ] - [ INFO ]  Merging 1 files, 10659 bytes from disk
2020-11-19 12:45:49  [ pool-9-thread-1:28762 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:45:49  [ pool-9-thread-1:28762 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:45:49  [ pool-9-thread-1:28762 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:45:49  [ pool-9-thread-1:28762 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:45:49  [ pool-9-thread-1:28850 ] - [ INFO ]  Task:attempt_local860866_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 12:45:49  [ pool-9-thread-1:28861 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:45:49  [ pool-9-thread-1:28861 ] - [ INFO ]  Task attempt_local860866_0002_r_000000_0 is allowed to commit now
2020-11-19 12:45:49  [ pool-9-thread-1:28889 ] - [ INFO ]  Saved output of task 'attempt_local860866_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/item/_temporary/0/task_local860866_0002_r_000000
2020-11-19 12:45:49  [ pool-9-thread-1:28889 ] - [ INFO ]  reduce > reduce
2020-11-19 12:45:49  [ pool-9-thread-1:28889 ] - [ INFO ]  Task 'attempt_local860866_0002_r_000000_0' done.
2020-11-19 12:45:49  [ pool-9-thread-1:28889 ] - [ INFO ]  Finishing task: attempt_local860866_0002_r_000000_0
2020-11-19 12:45:49  [ Thread-49:28890 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:45:49  [ main:29028 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:45:49  [ main:29028 ] - [ INFO ]  Job job_local860866_0002 completed successfully
2020-11-19 12:45:49  [ main:29032 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=44302
		FILE: Number of bytes written=1178577
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7177332
		HDFS: Number of bytes written=21949
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=354543
		Map output materialized bytes=10659
		Input split bytes=112
		Combine input records=90570
		Combine output records=1680
		Reduce input groups=1680
		Reduce shuffle bytes=10659
		Reduce input records=1680
		Reduce output records=1680
		Spilled Records=3360
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=917504000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=7293
2020-11-19 12:46:45  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 12:46:46  [ main:617 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 12:46:46  [ main:618 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 12:46:46  [ main:843 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:46:46  [ main:851 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:46:46  [ main:942 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:46:46  [ main:1023 ] - [ INFO ]  number of splits:1
2020-11-19 12:46:46  [ main:1086 ] - [ INFO ]  Submitting tokens for job: job_local1766063215_0001
2020-11-19 12:46:46  [ main:1186 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:46:46  [ main:1187 ] - [ INFO ]  Running job: job_local1766063215_0001
2020-11-19 12:46:46  [ Thread-18:1187 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:46:46  [ Thread-18:1191 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:46:46  [ Thread-18:1193 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:46:46  [ Thread-18:1228 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1229 ] - [ INFO ]  Starting task: attempt_local1766063215_0001_m_000000_0
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1247 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1251 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1251 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1253 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1312 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1312 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1312 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1312 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1312 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:46:46  [ LocalJobRunner Map Task Executor #0:1315 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:46:47  [ main:2192 ] - [ INFO ]  Job job_local1766063215_0001 running in uber mode : false
2020-11-19 12:46:47  [ main:2193 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:46:52  [ communication thread:7257 ] - [ INFO ]  map > map
2020-11-19 12:46:53  [ main:8208 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 12:46:55  [ communication thread:10258 ] - [ INFO ]  map > map
2020-11-19 12:46:56  [ main:11221 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 12:46:58  [ communication thread:13263 ] - [ INFO ]  map > map
2020-11-19 12:46:59  [ main:14226 ] - [ INFO ]   map 59% reduce 0%
2020-11-19 12:47:00  [ LocalJobRunner Map Task Executor #0:15501 ] - [ INFO ]  map > map
2020-11-19 12:47:00  [ LocalJobRunner Map Task Executor #0:15502 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:47:00  [ LocalJobRunner Map Task Executor #0:15502 ] - [ INFO ]  Spilling map output
2020-11-19 12:47:00  [ LocalJobRunner Map Task Executor #0:15503 ] - [ INFO ]  bufstart = 0; bufend = 351118; bufvoid = 104857600
2020-11-19 12:47:00  [ LocalJobRunner Map Task Executor #0:15503 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:47:01  [ LocalJobRunner Map Task Executor #0:15617 ] - [ INFO ]  Finished spill 0
2020-11-19 12:47:01  [ LocalJobRunner Map Task Executor #0:15620 ] - [ INFO ]  Task:attempt_local1766063215_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 12:47:01  [ LocalJobRunner Map Task Executor #0:15744 ] - [ INFO ]  map
2020-11-19 12:47:01  [ LocalJobRunner Map Task Executor #0:15744 ] - [ INFO ]  Task 'attempt_local1766063215_0001_m_000000_0' done.
2020-11-19 12:47:01  [ LocalJobRunner Map Task Executor #0:15744 ] - [ INFO ]  Finishing task: attempt_local1766063215_0001_m_000000_0
2020-11-19 12:47:01  [ Thread-18:15744 ] - [ INFO ]  map task executor complete.
2020-11-19 12:47:01  [ Thread-18:15746 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:47:01  [ pool-6-thread-1:15746 ] - [ INFO ]  Starting task: attempt_local1766063215_0001_r_000000_0
2020-11-19 12:47:01  [ pool-6-thread-1:15750 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:47:01  [ pool-6-thread-1:15750 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:47:01  [ pool-6-thread-1:15750 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:47:01  [ pool-6-thread-1:15751 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@736a533
2020-11-19 12:47:01  [ pool-6-thread-1:15759 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:47:01  [ EventFetcher for fetching Map Completion Events:15761 ] - [ INFO ]  attempt_local1766063215_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:47:01  [ localfetcher#1:15779 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1766063215_0001_m_000000_0 decomp: 5552 len: 5556 to MEMORY
2020-11-19 12:47:01  [ localfetcher#1:15783 ] - [ INFO ]  Read 5552 bytes from map-output for attempt_local1766063215_0001_m_000000_0
2020-11-19 12:47:01  [ localfetcher#1:15784 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 5552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5552
2020-11-19 12:47:01  [ EventFetcher for fetching Map Completion Events:15785 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:47:01  [ pool-6-thread-1:15786 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:47:01  [ pool-6-thread-1:15786 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:47:01  [ pool-6-thread-1:15790 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:47:01  [ pool-6-thread-1:15791 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:47:01  [ pool-6-thread-1:15795 ] - [ INFO ]  Merged 1 segments, 5552 bytes to disk to satisfy reduce memory limit
2020-11-19 12:47:01  [ pool-6-thread-1:15795 ] - [ INFO ]  Merging 1 files, 5556 bytes from disk
2020-11-19 12:47:01  [ pool-6-thread-1:15796 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:47:01  [ pool-6-thread-1:15796 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:47:01  [ pool-6-thread-1:15796 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:47:01  [ pool-6-thread-1:15796 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:47:01  [ pool-6-thread-1:16025 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 12:47:01  [ main:16233 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 12:47:05  [ pool-6-thread-1:19887 ] - [ INFO ]  Task:attempt_local1766063215_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 12:47:05  [ pool-6-thread-1:20141 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:47:05  [ pool-6-thread-1:20142 ] - [ INFO ]  Task attempt_local1766063215_0001_r_000000_0 is allowed to commit now
2020-11-19 12:47:05  [ pool-6-thread-1:20525 ] - [ INFO ]  Saved output of task 'attempt_local1766063215_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605761205026/_temporary/0/task_local1766063215_0001_r_000000
2020-11-19 12:47:05  [ pool-6-thread-1:20526 ] - [ INFO ]  reduce > reduce
2020-11-19 12:47:05  [ pool-6-thread-1:20526 ] - [ INFO ]  Task 'attempt_local1766063215_0001_r_000000_0' done.
2020-11-19 12:47:05  [ pool-6-thread-1:20526 ] - [ INFO ]  Finishing task: attempt_local1766063215_0001_r_000000_0
2020-11-19 12:47:05  [ Thread-18:20526 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:47:06  [ main:21246 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:47:07  [ main:22249 ] - [ INFO ]  Job job_local1766063215_0001 completed successfully
2020-11-19 12:47:07  [ main:22257 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=11476
		FILE: Number of bytes written=586472
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=3664
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=351118
		Map output materialized bytes=5556
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=5556
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=668467200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=3664
2020-11-19 12:47:07  [ main:22436 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 12:47:07  [ main:22454 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:47:07  [ main:22459 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:47:07  [ main:22512 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:47:08  [ main:22577 ] - [ INFO ]  number of splits:1
2020-11-19 12:47:08  [ main:22597 ] - [ INFO ]  Submitting tokens for job: job_local562084619_0002
2020-11-19 12:47:08  [ main:22641 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:47:08  [ main:22641 ] - [ INFO ]  Running job: job_local562084619_0002
2020-11-19 12:47:08  [ Thread-49:22642 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:47:08  [ Thread-49:22642 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:47:08  [ Thread-49:22642 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:47:08  [ Thread-49:22655 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22655 ] - [ INFO ]  Starting task: attempt_local562084619_0002_m_000000_0
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22656 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22657 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22657 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22658 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22704 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22704 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22704 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22704 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22704 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:47:08  [ LocalJobRunner Map Task Executor #0:22705 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:47:09  [ main:23647 ] - [ INFO ]  Job job_local562084619_0002 running in uber mode : false
2020-11-19 12:47:09  [ main:23647 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:47:14  [ communication thread:28666 ] - [ INFO ]  map > map
2020-11-19 12:47:15  [ main:29662 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 12:47:17  [ communication thread:31671 ] - [ INFO ]  map > map
2020-11-19 12:47:18  [ main:32672 ] - [ INFO ]   map 49% reduce 0%
2020-11-19 12:47:20  [ communication thread:34676 ] - [ INFO ]  map > map
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35132 ] - [ INFO ]  map > map
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35133 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35133 ] - [ INFO ]  Spilling map output
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35133 ] - [ INFO ]  bufstart = 0; bufend = 354543; bufvoid = 104857600
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35133 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35194 ] - [ INFO ]  Finished spill 0
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35195 ] - [ INFO ]  Task:attempt_local562084619_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35252 ] - [ INFO ]  map
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35252 ] - [ INFO ]  Task 'attempt_local562084619_0002_m_000000_0' done.
2020-11-19 12:47:20  [ LocalJobRunner Map Task Executor #0:35252 ] - [ INFO ]  Finishing task: attempt_local562084619_0002_m_000000_0
2020-11-19 12:47:20  [ Thread-49:35252 ] - [ INFO ]  map task executor complete.
2020-11-19 12:47:20  [ Thread-49:35252 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:47:20  [ pool-9-thread-1:35253 ] - [ INFO ]  Starting task: attempt_local562084619_0002_r_000000_0
2020-11-19 12:47:20  [ pool-9-thread-1:35253 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:47:20  [ pool-9-thread-1:35254 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:47:20  [ pool-9-thread-1:35254 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:47:20  [ pool-9-thread-1:35254 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27359f55
2020-11-19 12:47:20  [ pool-9-thread-1:35255 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:47:20  [ EventFetcher for fetching Map Completion Events:35256 ] - [ INFO ]  attempt_local562084619_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:47:20  [ localfetcher#2:35257 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local562084619_0002_m_000000_0 decomp: 10655 len: 10659 to MEMORY
2020-11-19 12:47:20  [ localfetcher#2:35257 ] - [ INFO ]  Read 10655 bytes from map-output for attempt_local562084619_0002_m_000000_0
2020-11-19 12:47:20  [ localfetcher#2:35257 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 10655, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10655
2020-11-19 12:47:20  [ EventFetcher for fetching Map Completion Events:35258 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:47:20  [ pool-9-thread-1:35258 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:47:20  [ pool-9-thread-1:35258 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:47:20  [ pool-9-thread-1:35259 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:47:20  [ pool-9-thread-1:35259 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:47:20  [ pool-9-thread-1:35260 ] - [ INFO ]  Merged 1 segments, 10655 bytes to disk to satisfy reduce memory limit
2020-11-19 12:47:20  [ pool-9-thread-1:35260 ] - [ INFO ]  Merging 1 files, 10659 bytes from disk
2020-11-19 12:47:20  [ pool-9-thread-1:35260 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:47:20  [ pool-9-thread-1:35261 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:47:20  [ pool-9-thread-1:35261 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:47:20  [ pool-9-thread-1:35261 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:47:20  [ pool-9-thread-1:35385 ] - [ INFO ]  Task:attempt_local562084619_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 12:47:20  [ pool-9-thread-1:35398 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:47:20  [ pool-9-thread-1:35398 ] - [ INFO ]  Task attempt_local562084619_0002_r_000000_0 is allowed to commit now
2020-11-19 12:47:20  [ pool-9-thread-1:35432 ] - [ INFO ]  Saved output of task 'attempt_local562084619_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/item/_temporary/0/task_local562084619_0002_r_000000
2020-11-19 12:47:20  [ pool-9-thread-1:35433 ] - [ INFO ]  reduce > reduce
2020-11-19 12:47:20  [ pool-9-thread-1:35433 ] - [ INFO ]  Task 'attempt_local562084619_0002_r_000000_0' done.
2020-11-19 12:47:20  [ pool-9-thread-1:35433 ] - [ INFO ]  Finishing task: attempt_local562084619_0002_r_000000_0
2020-11-19 12:47:20  [ Thread-49:35433 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:47:21  [ main:35676 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:47:21  [ main:35677 ] - [ INFO ]  Job job_local562084619_0002 completed successfully
2020-11-19 12:47:21  [ main:35680 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=44302
		FILE: Number of bytes written=1190765
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7177332
		HDFS: Number of bytes written=21949
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=354543
		Map output materialized bytes=10659
		Input split bytes=112
		Combine input records=90570
		Combine output records=1680
		Reduce input groups=1680
		Reduce shuffle bytes=10659
		Reduce input records=1680
		Reduce output records=1680
		Spilled Records=3360
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=915406848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=7293
2020-11-19 12:49:52  [ main:1 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 12:49:53  [ main:748 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 12:49:53  [ main:748 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 12:49:53  [ main:970 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:49:53  [ main:975 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:49:53  [ main:1007 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:49:54  [ main:1348 ] - [ INFO ]  number of splits:1
2020-11-19 12:49:54  [ main:1417 ] - [ INFO ]  Submitting tokens for job: job_local202421390_0001
2020-11-19 12:49:54  [ main:1505 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:49:54  [ main:1505 ] - [ INFO ]  Running job: job_local202421390_0001
2020-11-19 12:49:54  [ Thread-18:1505 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:49:54  [ Thread-18:1508 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:49:54  [ Thread-18:1510 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:49:54  [ Thread-18:1542 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1543 ] - [ INFO ]  Starting task: attempt_local202421390_0001_m_000000_0
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1564 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1564 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1566 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1621 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1621 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1621 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1621 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1621 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:49:54  [ LocalJobRunner Map Task Executor #0:1624 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:49:55  [ main:2508 ] - [ INFO ]  Job job_local202421390_0001 running in uber mode : false
2020-11-19 12:49:55  [ main:2509 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:50:00  [ communication thread:7571 ] - [ INFO ]  map > map
2020-11-19 12:50:01  [ main:8528 ] - [ INFO ]   map 34% reduce 0%
2020-11-19 12:50:03  [ communication thread:10576 ] - [ INFO ]  map > map
2020-11-19 12:50:04  [ main:11535 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 12:50:06  [ communication thread:13581 ] - [ INFO ]  map > map
2020-11-19 12:50:07  [ main:14543 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14569 ] - [ INFO ]  map > map
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14570 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14571 ] - [ INFO ]  Spilling map output
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14571 ] - [ INFO ]  bufstart = 0; bufend = 351118; bufvoid = 104857600
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14571 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14687 ] - [ INFO ]  Finished spill 0
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14690 ] - [ INFO ]  Task:attempt_local202421390_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14742 ] - [ INFO ]  map
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14742 ] - [ INFO ]  Task 'attempt_local202421390_0001_m_000000_0' done.
2020-11-19 12:50:07  [ LocalJobRunner Map Task Executor #0:14742 ] - [ INFO ]  Finishing task: attempt_local202421390_0001_m_000000_0
2020-11-19 12:50:07  [ Thread-18:14742 ] - [ INFO ]  map task executor complete.
2020-11-19 12:50:07  [ Thread-18:14744 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:50:07  [ pool-6-thread-1:14744 ] - [ INFO ]  Starting task: attempt_local202421390_0001_r_000000_0
2020-11-19 12:50:07  [ pool-6-thread-1:14749 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:50:07  [ pool-6-thread-1:14749 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:50:07  [ pool-6-thread-1:14749 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:50:07  [ pool-6-thread-1:14751 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2aed5477
2020-11-19 12:50:07  [ pool-6-thread-1:14760 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:50:07  [ EventFetcher for fetching Map Completion Events:14761 ] - [ INFO ]  attempt_local202421390_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:50:07  [ localfetcher#1:14783 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local202421390_0001_m_000000_0 decomp: 5552 len: 5556 to MEMORY
2020-11-19 12:50:07  [ localfetcher#1:14787 ] - [ INFO ]  Read 5552 bytes from map-output for attempt_local202421390_0001_m_000000_0
2020-11-19 12:50:07  [ localfetcher#1:14788 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 5552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5552
2020-11-19 12:50:07  [ EventFetcher for fetching Map Completion Events:14789 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:50:07  [ pool-6-thread-1:14790 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:50:07  [ pool-6-thread-1:14790 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:50:07  [ pool-6-thread-1:14794 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:50:07  [ pool-6-thread-1:14794 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:50:07  [ pool-6-thread-1:14799 ] - [ INFO ]  Merged 1 segments, 5552 bytes to disk to satisfy reduce memory limit
2020-11-19 12:50:07  [ pool-6-thread-1:14799 ] - [ INFO ]  Merging 1 files, 5556 bytes from disk
2020-11-19 12:50:07  [ pool-6-thread-1:14800 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:50:07  [ pool-6-thread-1:14800 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:50:07  [ pool-6-thread-1:14800 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:50:07  [ pool-6-thread-1:14800 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:50:07  [ pool-6-thread-1:14822 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 12:50:08  [ pool-6-thread-1:15392 ] - [ INFO ]  Task:attempt_local202421390_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 12:50:08  [ main:15548 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 12:50:08  [ pool-6-thread-1:15557 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:50:08  [ pool-6-thread-1:15558 ] - [ INFO ]  Task attempt_local202421390_0001_r_000000_0 is allowed to commit now
2020-11-19 12:50:08  [ pool-6-thread-1:15640 ] - [ INFO ]  Saved output of task 'attempt_local202421390_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605761392385/_temporary/0/task_local202421390_0001_r_000000
2020-11-19 12:50:08  [ pool-6-thread-1:15640 ] - [ INFO ]  reduce > reduce
2020-11-19 12:50:08  [ pool-6-thread-1:15641 ] - [ INFO ]  Task 'attempt_local202421390_0001_r_000000_0' done.
2020-11-19 12:50:08  [ pool-6-thread-1:15641 ] - [ INFO ]  Finishing task: attempt_local202421390_0001_r_000000_0
2020-11-19 12:50:08  [ Thread-18:15641 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:50:09  [ main:16552 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:50:10  [ main:17557 ] - [ INFO ]  Job job_local202421390_0001 completed successfully
2020-11-19 12:50:10  [ main:17565 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=11476
		FILE: Number of bytes written=583432
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=3664
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=351118
		Map output materialized bytes=5556
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=5556
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=668991488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=3664
2020-11-19 12:50:10  [ main:17995 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 12:50:11  [ main:18246 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:50:11  [ main:18251 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:50:11  [ main:18266 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:50:11  [ main:18312 ] - [ INFO ]  number of splits:1
2020-11-19 12:50:11  [ main:18333 ] - [ INFO ]  Submitting tokens for job: job_local767950120_0002
2020-11-19 12:50:11  [ main:18376 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:50:11  [ main:18376 ] - [ INFO ]  Running job: job_local767950120_0002
2020-11-19 12:50:11  [ Thread-49:18376 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:50:11  [ Thread-49:18377 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:50:11  [ Thread-49:18377 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:50:11  [ Thread-49:18437 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18437 ] - [ INFO ]  Starting task: attempt_local767950120_0002_m_000000_0
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18438 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18438 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18438 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18439 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18481 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18481 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18481 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18481 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18481 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:50:11  [ LocalJobRunner Map Task Executor #0:18482 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:50:12  [ main:19382 ] - [ INFO ]  Job job_local767950120_0002 running in uber mode : false
2020-11-19 12:50:12  [ main:19382 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:50:17  [ communication thread:24447 ] - [ INFO ]  map > map
2020-11-19 12:50:18  [ main:25392 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 12:50:20  [ communication thread:27453 ] - [ INFO ]  map > map
2020-11-19 12:50:21  [ main:28402 ] - [ INFO ]   map 49% reduce 0%
2020-11-19 12:50:23  [ communication thread:30457 ] - [ INFO ]  map > map
2020-11-19 12:50:24  [ main:31410 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31537 ] - [ INFO ]  map > map
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31537 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31537 ] - [ INFO ]  Spilling map output
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31537 ] - [ INFO ]  bufstart = 0; bufend = 354543; bufvoid = 104857600
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31537 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31599 ] - [ INFO ]  Finished spill 0
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31601 ] - [ INFO ]  Task:attempt_local767950120_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31921 ] - [ INFO ]  map
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31921 ] - [ INFO ]  Task 'attempt_local767950120_0002_m_000000_0' done.
2020-11-19 12:50:24  [ LocalJobRunner Map Task Executor #0:31921 ] - [ INFO ]  Finishing task: attempt_local767950120_0002_m_000000_0
2020-11-19 12:50:24  [ Thread-49:31922 ] - [ INFO ]  map task executor complete.
2020-11-19 12:50:24  [ Thread-49:31922 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:50:24  [ pool-9-thread-1:31922 ] - [ INFO ]  Starting task: attempt_local767950120_0002_r_000000_0
2020-11-19 12:50:24  [ pool-9-thread-1:31923 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:50:24  [ pool-9-thread-1:31924 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:50:24  [ pool-9-thread-1:31924 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:50:24  [ pool-9-thread-1:31924 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20c6fe6c
2020-11-19 12:50:24  [ pool-9-thread-1:31925 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:50:24  [ EventFetcher for fetching Map Completion Events:31926 ] - [ INFO ]  attempt_local767950120_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:50:24  [ localfetcher#2:31927 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local767950120_0002_m_000000_0 decomp: 10655 len: 10659 to MEMORY
2020-11-19 12:50:24  [ localfetcher#2:31928 ] - [ INFO ]  Read 10655 bytes from map-output for attempt_local767950120_0002_m_000000_0
2020-11-19 12:50:24  [ localfetcher#2:31928 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 10655, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10655
2020-11-19 12:50:24  [ EventFetcher for fetching Map Completion Events:31928 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:50:24  [ pool-9-thread-1:31928 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:50:24  [ pool-9-thread-1:31928 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:50:24  [ pool-9-thread-1:31929 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:50:24  [ pool-9-thread-1:31929 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:50:24  [ pool-9-thread-1:31931 ] - [ INFO ]  Merged 1 segments, 10655 bytes to disk to satisfy reduce memory limit
2020-11-19 12:50:24  [ pool-9-thread-1:31931 ] - [ INFO ]  Merging 1 files, 10659 bytes from disk
2020-11-19 12:50:24  [ pool-9-thread-1:31931 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:50:24  [ pool-9-thread-1:31931 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:50:24  [ pool-9-thread-1:31932 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:50:24  [ pool-9-thread-1:31932 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:50:25  [ pool-9-thread-1:32301 ] - [ INFO ]  Task:attempt_local767950120_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 12:50:25  [ pool-9-thread-1:32333 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:50:25  [ pool-9-thread-1:32333 ] - [ INFO ]  Task attempt_local767950120_0002_r_000000_0 is allowed to commit now
2020-11-19 12:50:25  [ pool-9-thread-1:32380 ] - [ INFO ]  Saved output of task 'attempt_local767950120_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/item/_temporary/0/task_local767950120_0002_r_000000
2020-11-19 12:50:25  [ pool-9-thread-1:32381 ] - [ INFO ]  reduce > reduce
2020-11-19 12:50:25  [ pool-9-thread-1:32381 ] - [ INFO ]  Task 'attempt_local767950120_0002_r_000000_0' done.
2020-11-19 12:50:25  [ pool-9-thread-1:32381 ] - [ INFO ]  Finishing task: attempt_local767950120_0002_r_000000_0
2020-11-19 12:50:25  [ Thread-49:32381 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:50:25  [ main:32415 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:50:26  [ main:33419 ] - [ INFO ]  Job job_local767950120_0002 completed successfully
2020-11-19 12:50:26  [ main:33423 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=44302
		FILE: Number of bytes written=1187725
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7177332
		HDFS: Number of bytes written=21949
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=354543
		Map output materialized bytes=10659
		Input split bytes=112
		Combine input records=90570
		Combine output records=1680
		Reduce input groups=1680
		Reduce shuffle bytes=10659
		Reduce input records=1680
		Reduce output records=1680
		Spilled Records=3360
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=916455424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=7293
2020-11-19 12:51:25  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 12:51:26  [ main:713 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 12:51:26  [ main:714 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 12:51:26  [ main:939 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:51:26  [ main:945 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:51:26  [ main:1110 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:51:26  [ main:1196 ] - [ INFO ]  number of splits:1
2020-11-19 12:51:26  [ main:1265 ] - [ INFO ]  Submitting tokens for job: job_local1894965536_0001
2020-11-19 12:51:26  [ main:1380 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:51:26  [ main:1380 ] - [ INFO ]  Running job: job_local1894965536_0001
2020-11-19 12:51:26  [ Thread-18:1381 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:51:26  [ Thread-18:1384 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:51:26  [ Thread-18:1386 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:51:26  [ Thread-18:1430 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:51:26  [ LocalJobRunner Map Task Executor #0:1431 ] - [ INFO ]  Starting task: attempt_local1894965536_0001_m_000000_0
2020-11-19 12:51:26  [ LocalJobRunner Map Task Executor #0:1455 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:51:26  [ LocalJobRunner Map Task Executor #0:1460 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:51:26  [ LocalJobRunner Map Task Executor #0:1461 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:51:26  [ LocalJobRunner Map Task Executor #0:1467 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:51:27  [ LocalJobRunner Map Task Executor #0:1524 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:51:27  [ LocalJobRunner Map Task Executor #0:1524 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:51:27  [ LocalJobRunner Map Task Executor #0:1524 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:51:27  [ LocalJobRunner Map Task Executor #0:1524 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:51:27  [ LocalJobRunner Map Task Executor #0:1524 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:51:27  [ LocalJobRunner Map Task Executor #0:1528 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:51:45  [ main:20142 ] - [ INFO ]  Job job_local1894965536_0001 running in uber mode : false
2020-11-19 12:51:59  [ main:34292 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:51:59  [ communication thread:34298 ] - [ INFO ]  map > map
2020-11-19 12:52:02  [ communication thread:37300 ] - [ INFO ]  map > map
2020-11-19 12:52:02  [ main:37302 ] - [ INFO ]   map 24% reduce 0%
2020-11-19 12:52:05  [ communication thread:40302 ] - [ INFO ]  map > map
2020-11-19 12:52:05  [ main:40310 ] - [ INFO ]   map 41% reduce 0%
2020-11-19 12:52:08  [ communication thread:43306 ] - [ INFO ]  map > map
2020-11-19 12:52:08  [ main:43325 ] - [ INFO ]   map 56% reduce 0%
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45197 ] - [ INFO ]  map > map
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45199 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45199 ] - [ INFO ]  Spilling map output
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45199 ] - [ INFO ]  bufstart = 0; bufend = 351118; bufvoid = 104857600
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45199 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45326 ] - [ INFO ]  Finished spill 0
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45330 ] - [ INFO ]  Task:attempt_local1894965536_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45350 ] - [ INFO ]  map
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45350 ] - [ INFO ]  Task 'attempt_local1894965536_0001_m_000000_0' done.
2020-11-19 12:52:10  [ LocalJobRunner Map Task Executor #0:45351 ] - [ INFO ]  Finishing task: attempt_local1894965536_0001_m_000000_0
2020-11-19 12:52:10  [ Thread-18:45351 ] - [ INFO ]  map task executor complete.
2020-11-19 12:52:10  [ Thread-18:45353 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:52:10  [ pool-6-thread-1:45353 ] - [ INFO ]  Starting task: attempt_local1894965536_0001_r_000000_0
2020-11-19 12:52:10  [ pool-6-thread-1:45358 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:52:10  [ pool-6-thread-1:45359 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:52:10  [ pool-6-thread-1:45359 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:52:10  [ pool-6-thread-1:45361 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14685be
2020-11-19 12:52:11  [ pool-6-thread-1:45535 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:52:11  [ EventFetcher for fetching Map Completion Events:45537 ] - [ INFO ]  attempt_local1894965536_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:52:11  [ localfetcher#1:45555 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1894965536_0001_m_000000_0 decomp: 5552 len: 5556 to MEMORY
2020-11-19 12:52:11  [ localfetcher#1:45559 ] - [ INFO ]  Read 5552 bytes from map-output for attempt_local1894965536_0001_m_000000_0
2020-11-19 12:52:11  [ localfetcher#1:45560 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 5552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5552
2020-11-19 12:52:11  [ EventFetcher for fetching Map Completion Events:45561 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:52:11  [ pool-6-thread-1:45561 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:52:11  [ pool-6-thread-1:45561 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:52:11  [ pool-6-thread-1:45566 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:52:11  [ pool-6-thread-1:45566 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:52:11  [ pool-6-thread-1:45569 ] - [ INFO ]  Merged 1 segments, 5552 bytes to disk to satisfy reduce memory limit
2020-11-19 12:52:11  [ pool-6-thread-1:45570 ] - [ INFO ]  Merging 1 files, 5556 bytes from disk
2020-11-19 12:52:11  [ pool-6-thread-1:45570 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:52:11  [ pool-6-thread-1:45570 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:52:11  [ pool-6-thread-1:45571 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 5548 bytes
2020-11-19 12:52:11  [ pool-6-thread-1:45571 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:52:11  [ pool-6-thread-1:45593 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 12:52:11  [ pool-6-thread-1:45712 ] - [ INFO ]  Task:attempt_local1894965536_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 12:52:11  [ pool-6-thread-1:45721 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:52:11  [ pool-6-thread-1:45721 ] - [ INFO ]  Task attempt_local1894965536_0001_r_000000_0 is allowed to commit now
2020-11-19 12:52:11  [ pool-6-thread-1:45751 ] - [ INFO ]  Saved output of task 'attempt_local1894965536_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605761485024/_temporary/0/task_local1894965536_0001_r_000000
2020-11-19 12:52:11  [ pool-6-thread-1:45751 ] - [ INFO ]  reduce > reduce
2020-11-19 12:52:11  [ pool-6-thread-1:45752 ] - [ INFO ]  Task 'attempt_local1894965536_0001_r_000000_0' done.
2020-11-19 12:52:11  [ pool-6-thread-1:45752 ] - [ INFO ]  Finishing task: attempt_local1894965536_0001_r_000000_0
2020-11-19 12:52:11  [ Thread-18:45752 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:52:11  [ main:46333 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:52:11  [ main:46333 ] - [ INFO ]  Job job_local1894965536_0001 completed successfully
2020-11-19 12:52:11  [ main:46342 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=11476
		FILE: Number of bytes written=586472
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=3664
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=351118
		Map output materialized bytes=5556
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=5556
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=665845760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=3664
2020-11-19 12:52:25  [ main:60009 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 12:52:25  [ main:60022 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 12:52:25  [ main:60027 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 12:52:25  [ main:60035 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 12:52:25  [ main:60078 ] - [ INFO ]  number of splits:1
2020-11-19 12:52:25  [ main:60100 ] - [ INFO ]  Submitting tokens for job: job_local93853547_0002
2020-11-19 12:52:25  [ main:60148 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 12:52:25  [ main:60148 ] - [ INFO ]  Running job: job_local93853547_0002
2020-11-19 12:52:25  [ Thread-50:60149 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 12:52:25  [ Thread-50:60150 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:52:25  [ Thread-50:60151 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 12:52:25  [ Thread-50:60159 ] - [ INFO ]  Waiting for map tasks
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60159 ] - [ INFO ]  Starting task: attempt_local93853547_0002_m_000000_0
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60159 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60160 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60160 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60161 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60204 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60204 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60204 ] - [ INFO ]  soft limit at 83886080
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60204 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60204 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 12:52:25  [ LocalJobRunner Map Task Executor #0:60205 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 12:52:44  [ main:78515 ] - [ INFO ]  Job job_local93853547_0002 running in uber mode : false
2020-11-19 12:52:46  [ main:80832 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 12:52:47  [ communication thread:81878 ] - [ INFO ]  map > map
2020-11-19 12:52:53  [ communication thread:87699 ] - [ INFO ]  map > map
2020-11-19 12:52:53  [ main:87700 ] - [ INFO ]   map 27% reduce 0%
2020-11-19 12:52:56  [ communication thread:90702 ] - [ INFO ]  map > map
2020-11-19 12:52:56  [ main:90710 ] - [ INFO ]   map 39% reduce 0%
2020-11-19 12:52:59  [ communication thread:93708 ] - [ INFO ]  map > map
2020-11-19 12:52:59  [ main:93721 ] - [ INFO ]   map 51% reduce 0%
2020-11-19 12:53:01  [ LocalJobRunner Map Task Executor #0:96447 ] - [ INFO ]  map > map
2020-11-19 12:53:01  [ LocalJobRunner Map Task Executor #0:96447 ] - [ INFO ]  Starting flush of map output
2020-11-19 12:53:01  [ LocalJobRunner Map Task Executor #0:96448 ] - [ INFO ]  Spilling map output
2020-11-19 12:53:01  [ LocalJobRunner Map Task Executor #0:96448 ] - [ INFO ]  bufstart = 0; bufend = 354543; bufvoid = 104857600
2020-11-19 12:53:01  [ LocalJobRunner Map Task Executor #0:96448 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 12:53:02  [ LocalJobRunner Map Task Executor #0:96517 ] - [ INFO ]  Finished spill 0
2020-11-19 12:53:02  [ LocalJobRunner Map Task Executor #0:96521 ] - [ INFO ]  Task:attempt_local93853547_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 12:53:02  [ LocalJobRunner Map Task Executor #0:96600 ] - [ INFO ]  map
2020-11-19 12:53:02  [ LocalJobRunner Map Task Executor #0:96600 ] - [ INFO ]  Task 'attempt_local93853547_0002_m_000000_0' done.
2020-11-19 12:53:02  [ LocalJobRunner Map Task Executor #0:96600 ] - [ INFO ]  Finishing task: attempt_local93853547_0002_m_000000_0
2020-11-19 12:53:02  [ Thread-50:96600 ] - [ INFO ]  map task executor complete.
2020-11-19 12:53:02  [ Thread-50:96601 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 12:53:02  [ pool-9-thread-1:96601 ] - [ INFO ]  Starting task: attempt_local93853547_0002_r_000000_0
2020-11-19 12:53:02  [ pool-9-thread-1:96602 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 12:53:02  [ pool-9-thread-1:96603 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 12:53:02  [ pool-9-thread-1:96603 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 12:53:02  [ pool-9-thread-1:96603 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26b3c1fb
2020-11-19 12:53:02  [ pool-9-thread-1:96604 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 12:53:02  [ EventFetcher for fetching Map Completion Events:96605 ] - [ INFO ]  attempt_local93853547_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 12:53:02  [ localfetcher#2:96606 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local93853547_0002_m_000000_0 decomp: 10655 len: 10659 to MEMORY
2020-11-19 12:53:02  [ localfetcher#2:96606 ] - [ INFO ]  Read 10655 bytes from map-output for attempt_local93853547_0002_m_000000_0
2020-11-19 12:53:02  [ localfetcher#2:96606 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 10655, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10655
2020-11-19 12:53:02  [ EventFetcher for fetching Map Completion Events:96607 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 12:53:02  [ pool-9-thread-1:96607 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:53:02  [ pool-9-thread-1:96607 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 12:53:02  [ pool-9-thread-1:96608 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:53:02  [ pool-9-thread-1:96608 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:53:02  [ pool-9-thread-1:96611 ] - [ INFO ]  Merged 1 segments, 10655 bytes to disk to satisfy reduce memory limit
2020-11-19 12:53:02  [ pool-9-thread-1:96611 ] - [ INFO ]  Merging 1 files, 10659 bytes from disk
2020-11-19 12:53:02  [ pool-9-thread-1:96611 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 12:53:02  [ pool-9-thread-1:96611 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 12:53:02  [ pool-9-thread-1:96611 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 10651 bytes
2020-11-19 12:53:02  [ pool-9-thread-1:96612 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:53:02  [ main:96727 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 12:53:02  [ pool-9-thread-1:96998 ] - [ INFO ]  Task:attempt_local93853547_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 12:53:02  [ pool-9-thread-1:97020 ] - [ INFO ]  1 / 1 copied.
2020-11-19 12:53:02  [ pool-9-thread-1:97020 ] - [ INFO ]  Task attempt_local93853547_0002_r_000000_0 is allowed to commit now
2020-11-19 12:53:02  [ pool-9-thread-1:97086 ] - [ INFO ]  Saved output of task 'attempt_local93853547_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/item/_temporary/0/task_local93853547_0002_r_000000
2020-11-19 12:53:02  [ pool-9-thread-1:97087 ] - [ INFO ]  reduce > reduce
2020-11-19 12:53:02  [ pool-9-thread-1:97087 ] - [ INFO ]  Task 'attempt_local93853547_0002_r_000000_0' done.
2020-11-19 12:53:02  [ pool-9-thread-1:97087 ] - [ INFO ]  Finishing task: attempt_local93853547_0002_r_000000_0
2020-11-19 12:53:02  [ Thread-50:97087 ] - [ INFO ]  reduce task executor complete.
2020-11-19 12:53:03  [ main:97732 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 12:53:03  [ main:97733 ] - [ INFO ]  Job job_local93853547_0002 completed successfully
2020-11-19 12:53:03  [ main:97736 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=44302
		FILE: Number of bytes written=1187725
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7177332
		HDFS: Number of bytes written=21949
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=354543
		Map output materialized bytes=10659
		Input split bytes=112
		Combine input records=90570
		Combine output records=1680
		Reduce input groups=1680
		Reduce shuffle bytes=10659
		Reduce input records=1680
		Reduce output records=1680
		Spilled Records=3360
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=1068498944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=7293
2020-11-19 14:00:21  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:00:22  [ main:591 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:00:22  [ main:592 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:00:22  [ main:817 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:00:22  [ main:823 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:00:22  [ main:842 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:00:22  [ main:920 ] - [ INFO ]  number of splits:1
2020-11-19 14:00:22  [ main:985 ] - [ INFO ]  Submitting tokens for job: job_local614651847_0001
2020-11-19 14:00:22  [ main:1082 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:00:22  [ main:1083 ] - [ INFO ]  Running job: job_local614651847_0001
2020-11-19 14:00:22  [ Thread-18:1083 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:00:22  [ Thread-18:1086 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:00:22  [ Thread-18:1088 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:00:23  [ Thread-18:1132 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1133 ] - [ INFO ]  Starting task: attempt_local614651847_0001_m_000000_0
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1150 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:00:23  [ LocalJobRunner Map Task Executor #0:1222 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:00:23  [ main:2085 ] - [ INFO ]  Job job_local614651847_0001 running in uber mode : false
2020-11-19 14:00:23  [ main:2086 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:00:29  [ communication thread:7160 ] - [ INFO ]  map > map
2020-11-19 14:00:30  [ main:8101 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 14:00:32  [ communication thread:10166 ] - [ INFO ]  map > map
2020-11-19 14:00:33  [ main:11103 ] - [ INFO ]   map 44% reduce 0%
2020-11-19 14:00:35  [ communication thread:13167 ] - [ INFO ]  map > map
2020-11-19 14:00:36  [ main:14106 ] - [ INFO ]   map 56% reduce 0%
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14784 ] - [ INFO ]  map > map
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14786 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14786 ] - [ INFO ]  Spilling map output
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14786 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14786 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14923 ] - [ INFO ]  Finished spill 0
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:14926 ] - [ INFO ]  Task:attempt_local614651847_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:15001 ] - [ INFO ]  map
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:15001 ] - [ INFO ]  Task 'attempt_local614651847_0001_m_000000_0' done.
2020-11-19 14:00:36  [ LocalJobRunner Map Task Executor #0:15001 ] - [ INFO ]  Finishing task: attempt_local614651847_0001_m_000000_0
2020-11-19 14:00:36  [ Thread-18:15001 ] - [ INFO ]  map task executor complete.
2020-11-19 14:00:36  [ Thread-18:15002 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:00:36  [ pool-6-thread-1:15003 ] - [ INFO ]  Starting task: attempt_local614651847_0001_r_000000_0
2020-11-19 14:00:36  [ pool-6-thread-1:15008 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:00:36  [ pool-6-thread-1:15008 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:00:36  [ pool-6-thread-1:15008 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:00:36  [ pool-6-thread-1:15010 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@10b2128
2020-11-19 14:00:36  [ pool-6-thread-1:15018 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:00:36  [ EventFetcher for fetching Map Completion Events:15020 ] - [ INFO ]  attempt_local614651847_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:00:36  [ localfetcher#1:15039 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local614651847_0001_m_000000_0 decomp: 541830 len: 541834 to MEMORY
2020-11-19 14:00:36  [ localfetcher#1:15043 ] - [ INFO ]  Read 541830 bytes from map-output for attempt_local614651847_0001_m_000000_0
2020-11-19 14:00:36  [ localfetcher#1:15044 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 541830, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->541830
2020-11-19 14:00:36  [ EventFetcher for fetching Map Completion Events:15044 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:00:36  [ pool-6-thread-1:15045 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:00:36  [ pool-6-thread-1:15045 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:00:36  [ pool-6-thread-1:15049 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:00:36  [ pool-6-thread-1:15049 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:00:36  [ pool-6-thread-1:15055 ] - [ INFO ]  Merged 1 segments, 541830 bytes to disk to satisfy reduce memory limit
2020-11-19 14:00:36  [ pool-6-thread-1:15055 ] - [ INFO ]  Merging 1 files, 541834 bytes from disk
2020-11-19 14:00:36  [ pool-6-thread-1:15056 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:00:36  [ pool-6-thread-1:15056 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:00:36  [ pool-6-thread-1:15056 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:00:36  [ pool-6-thread-1:15056 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:00:37  [ main:15110 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 14:00:37  [ pool-6-thread-1:15118 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:00:37  [ Thread-18:15191 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:00:37  [ Thread-18:15276 ] - [ WARN ]  job_local614651847_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 4
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:73)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:66)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 14:00:38  [ main:16115 ] - [ INFO ]  Job job_local614651847_0001 failed with state FAILED due to: NA
2020-11-19 14:00:38  [ main:16123 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=825728
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=886801
		Map output materialized bytes=541834
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=541834
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=350748672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 14:01:35  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:01:36  [ main:676 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:01:36  [ main:677 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:01:36  [ main:906 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:01:36  [ main:911 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:01:36  [ main:932 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:01:36  [ main:1025 ] - [ INFO ]  number of splits:1
2020-11-19 14:01:36  [ main:1094 ] - [ INFO ]  Submitting tokens for job: job_local411168676_0001
2020-11-19 14:01:36  [ main:1187 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:01:36  [ main:1187 ] - [ INFO ]  Running job: job_local411168676_0001
2020-11-19 14:01:36  [ Thread-18:1188 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:01:36  [ Thread-18:1192 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:01:36  [ Thread-18:1193 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:01:36  [ Thread-18:1246 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1247 ] - [ INFO ]  Starting task: attempt_local411168676_0001_m_000000_0
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1263 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1267 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1267 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1270 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:01:36  [ LocalJobRunner Map Task Executor #0:1324 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:01:37  [ main:2190 ] - [ INFO ]  Job job_local411168676_0001 running in uber mode : false
2020-11-19 14:01:37  [ main:2192 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:01:42  [ communication thread:7272 ] - [ INFO ]  map > map
2020-11-19 14:01:43  [ main:8212 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 14:01:45  [ communication thread:10273 ] - [ INFO ]  map > map
2020-11-19 14:01:46  [ main:11221 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 14:01:48  [ communication thread:13276 ] - [ INFO ]  map > map
2020-11-19 14:01:49  [ main:14227 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14417 ] - [ INFO ]  map > map
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14419 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14419 ] - [ INFO ]  Spilling map output
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14419 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14419 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14572 ] - [ INFO ]  Finished spill 0
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14575 ] - [ INFO ]  Task:attempt_local411168676_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14594 ] - [ INFO ]  map
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14594 ] - [ INFO ]  Task 'attempt_local411168676_0001_m_000000_0' done.
2020-11-19 14:01:50  [ LocalJobRunner Map Task Executor #0:14594 ] - [ INFO ]  Finishing task: attempt_local411168676_0001_m_000000_0
2020-11-19 14:01:50  [ Thread-18:14594 ] - [ INFO ]  map task executor complete.
2020-11-19 14:01:50  [ Thread-18:14596 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:01:50  [ pool-6-thread-1:14596 ] - [ INFO ]  Starting task: attempt_local411168676_0001_r_000000_0
2020-11-19 14:01:50  [ pool-6-thread-1:14601 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:01:50  [ pool-6-thread-1:14601 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:01:50  [ pool-6-thread-1:14601 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:01:50  [ pool-6-thread-1:14603 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6cf8875e
2020-11-19 14:01:50  [ pool-6-thread-1:14612 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:01:50  [ EventFetcher for fetching Map Completion Events:14613 ] - [ INFO ]  attempt_local411168676_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:01:50  [ localfetcher#1:14632 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local411168676_0001_m_000000_0 decomp: 541830 len: 541834 to MEMORY
2020-11-19 14:01:50  [ localfetcher#1:14636 ] - [ INFO ]  Read 541830 bytes from map-output for attempt_local411168676_0001_m_000000_0
2020-11-19 14:01:50  [ localfetcher#1:14637 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 541830, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->541830
2020-11-19 14:01:50  [ EventFetcher for fetching Map Completion Events:14638 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:01:50  [ pool-6-thread-1:14638 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:01:50  [ pool-6-thread-1:14639 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:01:50  [ pool-6-thread-1:14642 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:01:50  [ pool-6-thread-1:14643 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:01:50  [ pool-6-thread-1:14648 ] - [ INFO ]  Merged 1 segments, 541830 bytes to disk to satisfy reduce memory limit
2020-11-19 14:01:50  [ pool-6-thread-1:14648 ] - [ INFO ]  Merging 1 files, 541834 bytes from disk
2020-11-19 14:01:50  [ pool-6-thread-1:14649 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:01:50  [ pool-6-thread-1:14649 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:01:50  [ pool-6-thread-1:14649 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:01:50  [ pool-6-thread-1:14649 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:01:50  [ pool-6-thread-1:14673 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:01:59  [ main:23901 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 14:01:59  [ Thread-18:23921 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:01:59  [ Thread-18:23935 ] - [ WARN ]  job_local411168676_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 4
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:73)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:66)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 14:02:00  [ main:24906 ] - [ INFO ]  Job job_local411168676_0001 failed with state FAILED due to: NA
2020-11-19 14:02:00  [ main:24916 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=825728
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=886801
		Map output materialized bytes=541834
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=541834
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=354418688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 14:03:17  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:03:17  [ main:532 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:03:17  [ main:533 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:03:18  [ main:730 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:03:18  [ main:736 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:03:18  [ main:769 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:03:18  [ main:853 ] - [ INFO ]  number of splits:1
2020-11-19 14:03:18  [ main:915 ] - [ INFO ]  Submitting tokens for job: job_local420196900_0001
2020-11-19 14:03:18  [ main:997 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:03:18  [ main:998 ] - [ INFO ]  Running job: job_local420196900_0001
2020-11-19 14:03:18  [ Thread-18:998 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:03:18  [ Thread-18:1001 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:03:18  [ Thread-18:1002 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:03:18  [ Thread-18:1045 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1046 ] - [ INFO ]  Starting task: attempt_local420196900_0001_m_000000_0
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1060 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1063 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1063 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1065 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1118 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1118 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1119 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1119 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1119 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:03:18  [ LocalJobRunner Map Task Executor #0:1121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:03:19  [ main:2001 ] - [ INFO ]  Job job_local420196900_0001 running in uber mode : false
2020-11-19 14:03:19  [ main:2003 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:03:24  [ communication thread:7068 ] - [ INFO ]  map > map
2020-11-19 14:03:25  [ main:8019 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 14:03:27  [ communication thread:10074 ] - [ INFO ]  map > map
2020-11-19 14:03:28  [ main:11027 ] - [ INFO ]   map 49% reduce 0%
2020-11-19 14:03:30  [ communication thread:13076 ] - [ INFO ]  map > map
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13709 ] - [ INFO ]  map > map
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13711 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13711 ] - [ INFO ]  Spilling map output
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13711 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13711 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13845 ] - [ INFO ]  Finished spill 0
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13848 ] - [ INFO ]  Task:attempt_local420196900_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13868 ] - [ INFO ]  map
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13868 ] - [ INFO ]  Task 'attempt_local420196900_0001_m_000000_0' done.
2020-11-19 14:03:31  [ LocalJobRunner Map Task Executor #0:13869 ] - [ INFO ]  Finishing task: attempt_local420196900_0001_m_000000_0
2020-11-19 14:03:31  [ Thread-18:13869 ] - [ INFO ]  map task executor complete.
2020-11-19 14:03:31  [ Thread-18:13870 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:03:31  [ pool-6-thread-1:13870 ] - [ INFO ]  Starting task: attempt_local420196900_0001_r_000000_0
2020-11-19 14:03:31  [ pool-6-thread-1:13874 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:03:31  [ pool-6-thread-1:13874 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:03:31  [ pool-6-thread-1:13874 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:03:31  [ pool-6-thread-1:13876 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e95ed3d
2020-11-19 14:03:31  [ pool-6-thread-1:13883 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:03:31  [ EventFetcher for fetching Map Completion Events:13884 ] - [ INFO ]  attempt_local420196900_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:03:31  [ localfetcher#1:13901 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local420196900_0001_m_000000_0 decomp: 541830 len: 541834 to MEMORY
2020-11-19 14:03:31  [ localfetcher#1:13904 ] - [ INFO ]  Read 541830 bytes from map-output for attempt_local420196900_0001_m_000000_0
2020-11-19 14:03:31  [ localfetcher#1:13905 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 541830, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->541830
2020-11-19 14:03:31  [ EventFetcher for fetching Map Completion Events:13905 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:03:31  [ pool-6-thread-1:13906 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:03:31  [ pool-6-thread-1:13906 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:03:31  [ pool-6-thread-1:13910 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:03:31  [ pool-6-thread-1:13910 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:03:31  [ pool-6-thread-1:13916 ] - [ INFO ]  Merged 1 segments, 541830 bytes to disk to satisfy reduce memory limit
2020-11-19 14:03:31  [ pool-6-thread-1:13917 ] - [ INFO ]  Merging 1 files, 541834 bytes from disk
2020-11-19 14:03:31  [ pool-6-thread-1:13917 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:03:31  [ pool-6-thread-1:13917 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:03:31  [ pool-6-thread-1:13917 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:03:31  [ pool-6-thread-1:13918 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:03:31  [ pool-6-thread-1:13939 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:03:31  [ main:14035 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 14:03:31  [ pool-6-thread-1:14199 ] - [ INFO ]  Task:attempt_local420196900_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 14:03:31  [ pool-6-thread-1:14211 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:03:31  [ pool-6-thread-1:14211 ] - [ INFO ]  Task attempt_local420196900_0001_r_000000_0 is allowed to commit now
2020-11-19 14:03:31  [ pool-6-thread-1:14245 ] - [ INFO ]  Saved output of task 'attempt_local420196900_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local420196900_0001_r_000000
2020-11-19 14:03:31  [ pool-6-thread-1:14246 ] - [ INFO ]  reduce > reduce
2020-11-19 14:03:31  [ pool-6-thread-1:14246 ] - [ INFO ]  Task 'attempt_local420196900_0001_r_000000_0' done.
2020-11-19 14:03:31  [ pool-6-thread-1:14246 ] - [ INFO ]  Finishing task: attempt_local420196900_0001_r_000000_0
2020-11-19 14:03:31  [ Thread-18:14246 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:03:32  [ main:15039 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 14:03:32  [ main:15040 ] - [ INFO ]  Job job_local420196900_0001 completed successfully
2020-11-19 14:03:32  [ main:15050 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1084032
		FILE: Number of bytes written=2193290
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893776
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=886801
		Map output materialized bytes=541834
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=541834
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=698351616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893776
2020-11-19 14:05:32  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:05:32  [ main:549 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:05:32  [ main:549 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:05:32  [ main:740 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:05:32  [ main:746 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:05:32  [ main:761 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:05:32  [ main:834 ] - [ INFO ]  number of splits:1
2020-11-19 14:05:33  [ main:898 ] - [ INFO ]  Submitting tokens for job: job_local759321330_0001
2020-11-19 14:05:33  [ main:977 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:05:33  [ main:978 ] - [ INFO ]  Running job: job_local759321330_0001
2020-11-19 14:05:33  [ Thread-18:978 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:05:33  [ Thread-18:981 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:05:33  [ Thread-18:982 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:05:33  [ Thread-18:1021 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1021 ] - [ INFO ]  Starting task: attempt_local759321330_0001_m_000000_0
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1035 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1039 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1039 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1041 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:05:33  [ LocalJobRunner Map Task Executor #0:1087 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:05:34  [ main:1982 ] - [ INFO ]  Job job_local759321330_0001 running in uber mode : false
2020-11-19 14:05:34  [ main:1984 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:05:39  [ communication thread:7045 ] - [ INFO ]  map > map
2020-11-19 14:05:40  [ main:8002 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 14:05:42  [ communication thread:10048 ] - [ INFO ]  map > map
2020-11-19 14:05:43  [ main:11006 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 14:05:45  [ communication thread:13050 ] - [ INFO ]  map > map
2020-11-19 14:05:46  [ main:14017 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14333 ] - [ INFO ]  map > map
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14335 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14335 ] - [ INFO ]  Spilling map output
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14335 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14335 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14498 ] - [ INFO ]  Finished spill 0
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14500 ] - [ INFO ]  Task:attempt_local759321330_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14525 ] - [ INFO ]  map
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14525 ] - [ INFO ]  Task 'attempt_local759321330_0001_m_000000_0' done.
2020-11-19 14:05:46  [ LocalJobRunner Map Task Executor #0:14525 ] - [ INFO ]  Finishing task: attempt_local759321330_0001_m_000000_0
2020-11-19 14:05:46  [ Thread-18:14525 ] - [ INFO ]  map task executor complete.
2020-11-19 14:05:46  [ Thread-18:14527 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:05:46  [ pool-6-thread-1:14527 ] - [ INFO ]  Starting task: attempt_local759321330_0001_r_000000_0
2020-11-19 14:05:46  [ pool-6-thread-1:14531 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:05:46  [ pool-6-thread-1:14532 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:05:46  [ pool-6-thread-1:14532 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:05:46  [ pool-6-thread-1:14533 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26a3bacf
2020-11-19 14:05:46  [ pool-6-thread-1:14541 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:05:46  [ EventFetcher for fetching Map Completion Events:14542 ] - [ INFO ]  attempt_local759321330_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:05:46  [ localfetcher#1:14559 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local759321330_0001_m_000000_0 decomp: 541830 len: 541834 to MEMORY
2020-11-19 14:05:46  [ localfetcher#1:14563 ] - [ INFO ]  Read 541830 bytes from map-output for attempt_local759321330_0001_m_000000_0
2020-11-19 14:05:46  [ localfetcher#1:14564 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 541830, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->541830
2020-11-19 14:05:46  [ EventFetcher for fetching Map Completion Events:14565 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:05:46  [ pool-6-thread-1:14565 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:05:46  [ pool-6-thread-1:14565 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:05:46  [ pool-6-thread-1:14569 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:05:46  [ pool-6-thread-1:14569 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:05:46  [ pool-6-thread-1:14576 ] - [ INFO ]  Merged 1 segments, 541830 bytes to disk to satisfy reduce memory limit
2020-11-19 14:05:46  [ pool-6-thread-1:14576 ] - [ INFO ]  Merging 1 files, 541834 bytes from disk
2020-11-19 14:05:46  [ pool-6-thread-1:14576 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:05:46  [ pool-6-thread-1:14576 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:05:46  [ pool-6-thread-1:14577 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:05:46  [ pool-6-thread-1:14577 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:05:46  [ pool-6-thread-1:14600 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:05:46  [ pool-6-thread-1:14840 ] - [ INFO ]  Task:attempt_local759321330_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 14:05:46  [ pool-6-thread-1:14851 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:05:46  [ pool-6-thread-1:14852 ] - [ INFO ]  Task attempt_local759321330_0001_r_000000_0 is allowed to commit now
2020-11-19 14:05:47  [ pool-6-thread-1:14896 ] - [ INFO ]  Saved output of task 'attempt_local759321330_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local759321330_0001_r_000000
2020-11-19 14:05:47  [ pool-6-thread-1:14896 ] - [ INFO ]  reduce > reduce
2020-11-19 14:05:47  [ pool-6-thread-1:14896 ] - [ INFO ]  Task 'attempt_local759321330_0001_r_000000_0' done.
2020-11-19 14:05:47  [ pool-6-thread-1:14897 ] - [ INFO ]  Finishing task: attempt_local759321330_0001_r_000000_0
2020-11-19 14:05:47  [ Thread-18:14897 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:05:47  [ main:15018 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 14:05:47  [ main:15019 ] - [ INFO ]  Job job_local759321330_0001 completed successfully
2020-11-19 14:05:47  [ main:15028 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1084032
		FILE: Number of bytes written=2193290
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893776
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=886801
		Map output materialized bytes=541834
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=541834
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=695205888
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893776
2020-11-19 14:17:33  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:17:34  [ main:677 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:17:34  [ main:677 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:17:34  [ main:890 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:17:34  [ main:896 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:17:34  [ main:911 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:17:34  [ main:991 ] - [ INFO ]  number of splits:1
2020-11-19 14:17:34  [ main:1054 ] - [ INFO ]  Submitting tokens for job: job_local1795287370_0001
2020-11-19 14:17:34  [ main:1159 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:17:34  [ main:1159 ] - [ INFO ]  Running job: job_local1795287370_0001
2020-11-19 14:17:34  [ Thread-18:1160 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:17:34  [ Thread-18:1163 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:17:34  [ Thread-18:1165 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:17:34  [ Thread-18:1209 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  Starting task: attempt_local1795287370_0001_m_000000_0
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1227 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1286 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1286 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:17:34  [ LocalJobRunner Map Task Executor #0:1289 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:18:09  [ main:35556 ] - [ INFO ]  Job job_local1795287370_0001 running in uber mode : false
2020-11-19 14:18:20  [ main:46553 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:19:24  [ communication thread:110679 ] - [ INFO ]  map > map
2020-11-19 14:19:27  [ communication thread:113681 ] - [ INFO ]  map > map
2020-11-19 14:19:28  [ main:114682 ] - [ INFO ]   map 27% reduce 0%
2020-11-19 14:19:30  [ communication thread:116687 ] - [ INFO ]  map > map
2020-11-19 14:19:30  [ main:116688 ] - [ INFO ]   map 41% reduce 0%
2020-11-19 14:19:33  [ communication thread:119690 ] - [ INFO ]  map > map
2020-11-19 14:19:33  [ main:119698 ] - [ INFO ]   map 56% reduce 0%
2020-11-19 14:19:34  [ LocalJobRunner Map Task Executor #0:121454 ] - [ INFO ]  map > map
2020-11-19 14:19:34  [ LocalJobRunner Map Task Executor #0:121459 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:19:34  [ LocalJobRunner Map Task Executor #0:121459 ] - [ INFO ]  Spilling map output
2020-11-19 14:19:34  [ LocalJobRunner Map Task Executor #0:121459 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:19:34  [ LocalJobRunner Map Task Executor #0:121459 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:19:55  [ communication thread:142054 ] - [ INFO ]  map > sort
2020-11-19 14:20:40  [ main:187378 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 14:20:40  [ communication thread:187378 ] - [ INFO ]  map > sort
2020-11-19 14:21:39  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:21:40  [ main:637 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:21:40  [ main:638 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:21:40  [ main:843 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:21:40  [ main:850 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:21:40  [ main:881 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:21:40  [ main:958 ] - [ INFO ]  number of splits:1
2020-11-19 14:21:40  [ main:1016 ] - [ INFO ]  Submitting tokens for job: job_local1948389481_0001
2020-11-19 14:21:40  [ main:1110 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:21:40  [ main:1110 ] - [ INFO ]  Running job: job_local1948389481_0001
2020-11-19 14:21:40  [ Thread-18:1111 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:21:40  [ Thread-18:1115 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:21:40  [ Thread-18:1116 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:21:41  [ Thread-18:1161 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1161 ] - [ INFO ]  Starting task: attempt_local1948389481_0001_m_000000_0
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1179 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1184 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1184 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1240 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1240 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1240 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1240 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1240 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:21:41  [ LocalJobRunner Map Task Executor #0:1245 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:21:49  [ main:9886 ] - [ INFO ]  Job job_local1948389481_0001 running in uber mode : false
2020-11-19 14:21:57  [ main:17951 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:22:01  [ communication thread:21606 ] - [ INFO ]  map > map
2020-11-19 14:22:04  [ communication thread:24611 ] - [ INFO ]  map > map
2020-11-19 14:22:05  [ main:25611 ] - [ INFO ]   map 27% reduce 0%
2020-11-19 14:22:07  [ communication thread:27614 ] - [ INFO ]  map > map
2020-11-19 14:22:07  [ main:27618 ] - [ INFO ]   map 41% reduce 0%
2020-11-19 14:22:10  [ communication thread:30619 ] - [ INFO ]  map > map
2020-11-19 14:22:10  [ main:30626 ] - [ INFO ]   map 59% reduce 0%
2020-11-19 14:22:12  [ LocalJobRunner Map Task Executor #0:32240 ] - [ INFO ]  map > map
2020-11-19 14:22:12  [ LocalJobRunner Map Task Executor #0:32244 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:22:12  [ LocalJobRunner Map Task Executor #0:32244 ] - [ INFO ]  Spilling map output
2020-11-19 14:22:12  [ LocalJobRunner Map Task Executor #0:32244 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:22:12  [ LocalJobRunner Map Task Executor #0:32245 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:22:23  [ communication thread:43743 ] - [ INFO ]  map > sort
2020-11-19 14:22:55  [ main:75173 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 14:22:55  [ communication thread:75173 ] - [ INFO ]  map > sort
2020-11-19 14:22:55  [ LocalJobRunner Map Task Executor #0:75236 ] - [ INFO ]  Finished spill 0
2020-11-19 14:22:55  [ LocalJobRunner Map Task Executor #0:75239 ] - [ INFO ]  Task:attempt_local1948389481_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:22:55  [ LocalJobRunner Map Task Executor #0:75253 ] - [ INFO ]  map
2020-11-19 14:22:55  [ LocalJobRunner Map Task Executor #0:75253 ] - [ INFO ]  Task 'attempt_local1948389481_0001_m_000000_0' done.
2020-11-19 14:22:55  [ LocalJobRunner Map Task Executor #0:75254 ] - [ INFO ]  Finishing task: attempt_local1948389481_0001_m_000000_0
2020-11-19 14:22:55  [ Thread-18:75254 ] - [ INFO ]  map task executor complete.
2020-11-19 14:22:55  [ Thread-18:75255 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:22:55  [ pool-6-thread-1:75256 ] - [ INFO ]  Starting task: attempt_local1948389481_0001_r_000000_0
2020-11-19 14:22:55  [ pool-6-thread-1:75260 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:22:55  [ pool-6-thread-1:75261 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:22:55  [ pool-6-thread-1:75261 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:22:55  [ pool-6-thread-1:75262 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@624f96d8
2020-11-19 14:22:55  [ pool-6-thread-1:75271 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:22:55  [ EventFetcher for fetching Map Completion Events:75273 ] - [ INFO ]  attempt_local1948389481_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:22:55  [ localfetcher#1:75292 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1948389481_0001_m_000000_0 decomp: 541830 len: 541834 to MEMORY
2020-11-19 14:22:55  [ localfetcher#1:75296 ] - [ INFO ]  Read 541830 bytes from map-output for attempt_local1948389481_0001_m_000000_0
2020-11-19 14:22:55  [ localfetcher#1:75297 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 541830, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->541830
2020-11-19 14:22:55  [ EventFetcher for fetching Map Completion Events:75298 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:22:55  [ pool-6-thread-1:75299 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:22:55  [ pool-6-thread-1:75299 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:22:55  [ pool-6-thread-1:75303 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:22:55  [ pool-6-thread-1:75303 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:22:55  [ pool-6-thread-1:75309 ] - [ INFO ]  Merged 1 segments, 541830 bytes to disk to satisfy reduce memory limit
2020-11-19 14:22:55  [ pool-6-thread-1:75309 ] - [ INFO ]  Merging 1 files, 541834 bytes from disk
2020-11-19 14:22:55  [ pool-6-thread-1:75310 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:22:55  [ pool-6-thread-1:75310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:22:55  [ pool-6-thread-1:75310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 541824 bytes
2020-11-19 14:22:55  [ pool-6-thread-1:75310 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:22:55  [ pool-6-thread-1:75333 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:23:18  [ main:98776 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 14:23:18  [ Thread-18:98970 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:24:36  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:24:36  [ main:654 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:24:36  [ main:654 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:24:37  [ main:856 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:24:37  [ main:860 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:24:37  [ main:874 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:24:37  [ main:943 ] - [ INFO ]  number of splits:1
2020-11-19 14:24:37  [ main:1008 ] - [ INFO ]  Submitting tokens for job: job_local1622172655_0001
2020-11-19 14:24:37  [ main:1109 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:24:37  [ main:1110 ] - [ INFO ]  Running job: job_local1622172655_0001
2020-11-19 14:24:37  [ Thread-18:1110 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:24:37  [ Thread-18:1114 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:24:37  [ Thread-18:1116 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:24:37  [ Thread-18:1158 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  Starting task: attempt_local1622172655_0001_m_000000_0
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1178 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1185 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1186 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:24:37  [ LocalJobRunner Map Task Executor #0:1313 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:24:38  [ main:2115 ] - [ INFO ]  Job job_local1622172655_0001 running in uber mode : false
2020-11-19 14:24:38  [ main:2116 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:24:43  [ communication thread:7187 ] - [ INFO ]  map > map
2020-11-19 14:24:44  [ main:8134 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 14:24:46  [ communication thread:10192 ] - [ INFO ]  map > map
2020-11-19 14:24:47  [ main:11144 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 14:24:49  [ communication thread:13197 ] - [ INFO ]  map > map
2020-11-19 14:24:50  [ LocalJobRunner Map Task Executor #0:13952 ] - [ INFO ]  map > map
2020-11-19 14:24:50  [ LocalJobRunner Map Task Executor #0:13954 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:24:50  [ LocalJobRunner Map Task Executor #0:13954 ] - [ INFO ]  Spilling map output
2020-11-19 14:24:50  [ LocalJobRunner Map Task Executor #0:13954 ] - [ INFO ]  bufstart = 0; bufend = 886801; bufvoid = 104857600
2020-11-19 14:24:50  [ LocalJobRunner Map Task Executor #0:13954 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:25:52  [ main:76745 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 14:25:52  [ communication thread:76746 ] - [ INFO ]  map > sort
2020-11-19 14:27:17  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:27:17  [ main:701 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:27:17  [ main:702 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:27:18  [ main:941 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:27:18  [ main:947 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:27:18  [ main:961 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:27:18  [ main:1044 ] - [ INFO ]  number of splits:1
2020-11-19 14:27:18  [ main:1114 ] - [ INFO ]  Submitting tokens for job: job_local2080174168_0001
2020-11-19 14:27:18  [ main:1225 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:27:18  [ main:1226 ] - [ INFO ]  Running job: job_local2080174168_0001
2020-11-19 14:27:18  [ Thread-18:1227 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:27:18  [ Thread-18:1231 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:27:18  [ Thread-18:1232 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:27:18  [ Thread-18:1278 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1279 ] - [ INFO ]  Starting task: attempt_local2080174168_0001_m_000000_0
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1296 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1300 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1301 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1303 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1355 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1355 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1355 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1355 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1356 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1358 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:27:18  [ LocalJobRunner Map Task Executor #0:1538 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:27:18  [ Thread-18:1547 ] - [ INFO ]  map task executor complete.
2020-11-19 14:27:18  [ Thread-18:1557 ] - [ WARN ]  job_local2080174168_0001
java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixMapper.map(UserItemScoreMatrixMapReduceJob.java:54)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixMapper.map(UserItemScoreMatrixMapReduceJob.java:35)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 14:27:19  [ main:2230 ] - [ INFO ]  Job job_local2080174168_0001 running in uber mode : false
2020-11-19 14:27:19  [ main:2232 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:27:19  [ main:2234 ] - [ INFO ]  Job job_local2080174168_0001 failed with state FAILED due to: NA
2020-11-19 14:27:19  [ main:2238 ] - [ INFO ]  Counters: 0
2020-11-19 14:27:38  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:27:38  [ main:704 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:27:38  [ main:704 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:27:39  [ main:924 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:27:39  [ main:931 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:27:39  [ main:946 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:27:39  [ main:1025 ] - [ INFO ]  number of splits:1
2020-11-19 14:27:39  [ main:1087 ] - [ INFO ]  Submitting tokens for job: job_local1632616300_0001
2020-11-19 14:27:39  [ main:1182 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:27:39  [ main:1183 ] - [ INFO ]  Running job: job_local1632616300_0001
2020-11-19 14:27:39  [ Thread-18:1184 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:27:39  [ Thread-18:1187 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:27:39  [ Thread-18:1189 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:27:39  [ Thread-18:1236 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  Starting task: attempt_local1632616300_0001_m_000000_0
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1262 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1262 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1265 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:27:39  [ LocalJobRunner Map Task Executor #0:1319 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:27:40  [ main:2187 ] - [ INFO ]  Job job_local1632616300_0001 running in uber mode : false
2020-11-19 14:27:40  [ main:2189 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:27:45  [ communication thread:7268 ] - [ INFO ]  map > map
2020-11-19 14:27:46  [ main:8204 ] - [ INFO ]   map 34% reduce 0%
2020-11-19 14:27:48  [ communication thread:10274 ] - [ INFO ]  map > map
2020-11-19 14:27:49  [ main:11210 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 14:27:51  [ communication thread:13279 ] - [ INFO ]  map > map
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13802 ] - [ INFO ]  map > map
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13807 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13807 ] - [ INFO ]  Spilling map output
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13807 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13807 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13930 ] - [ INFO ]  Finished spill 0
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13934 ] - [ INFO ]  Task:attempt_local1632616300_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13975 ] - [ INFO ]  map
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13976 ] - [ INFO ]  Task 'attempt_local1632616300_0001_m_000000_0' done.
2020-11-19 14:27:52  [ LocalJobRunner Map Task Executor #0:13976 ] - [ INFO ]  Finishing task: attempt_local1632616300_0001_m_000000_0
2020-11-19 14:27:52  [ Thread-18:13976 ] - [ INFO ]  map task executor complete.
2020-11-19 14:27:52  [ Thread-18:13978 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:27:52  [ pool-6-thread-1:13978 ] - [ INFO ]  Starting task: attempt_local1632616300_0001_r_000000_0
2020-11-19 14:27:52  [ pool-6-thread-1:13982 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:27:52  [ pool-6-thread-1:13983 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:27:52  [ pool-6-thread-1:13983 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:27:52  [ pool-6-thread-1:13985 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2fff2e34
2020-11-19 14:27:52  [ pool-6-thread-1:13993 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:27:52  [ EventFetcher for fetching Map Completion Events:13994 ] - [ INFO ]  attempt_local1632616300_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:27:52  [ localfetcher#1:14013 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1632616300_0001_m_000000_0 decomp: 619852 len: 619856 to MEMORY
2020-11-19 14:27:52  [ localfetcher#1:14018 ] - [ INFO ]  Read 619852 bytes from map-output for attempt_local1632616300_0001_m_000000_0
2020-11-19 14:27:52  [ localfetcher#1:14019 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 619852, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->619852
2020-11-19 14:27:52  [ EventFetcher for fetching Map Completion Events:14020 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:27:52  [ pool-6-thread-1:14021 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:27:52  [ pool-6-thread-1:14021 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:27:52  [ pool-6-thread-1:14025 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:27:52  [ pool-6-thread-1:14025 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 619844 bytes
2020-11-19 14:27:52  [ pool-6-thread-1:14031 ] - [ INFO ]  Merged 1 segments, 619852 bytes to disk to satisfy reduce memory limit
2020-11-19 14:27:52  [ pool-6-thread-1:14032 ] - [ INFO ]  Merging 1 files, 619856 bytes from disk
2020-11-19 14:27:52  [ pool-6-thread-1:14032 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:27:52  [ pool-6-thread-1:14032 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:27:52  [ pool-6-thread-1:14032 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 619844 bytes
2020-11-19 14:27:52  [ pool-6-thread-1:14033 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:27:52  [ pool-6-thread-1:14060 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:28:04  [ main:26303 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 14:28:08  [ communication thread:30398 ] - [ INFO ]  reduce > reduce
2020-11-19 14:28:09  [ main:31401 ] - [ INFO ]   map 100% reduce 67%
2020-11-19 14:28:10  [ pool-6-thread-1:32401 ] - [ INFO ]  Task:attempt_local1632616300_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 14:28:10  [ pool-6-thread-1:32431 ] - [ INFO ]  reduce > reduce
2020-11-19 14:28:10  [ pool-6-thread-1:32431 ] - [ INFO ]  Task attempt_local1632616300_0001_r_000000_0 is allowed to commit now
2020-11-19 14:28:10  [ pool-6-thread-1:32692 ] - [ INFO ]  Saved output of task 'attempt_local1632616300_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1632616300_0001_r_000000
2020-11-19 14:28:10  [ pool-6-thread-1:32693 ] - [ INFO ]  reduce > reduce
2020-11-19 14:28:10  [ pool-6-thread-1:32693 ] - [ INFO ]  Task 'attempt_local1632616300_0001_r_000000_0' done.
2020-11-19 14:28:10  [ pool-6-thread-1:32693 ] - [ INFO ]  Finishing task: attempt_local1632616300_0001_r_000000_0
2020-11-19 14:28:10  [ Thread-18:32693 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:28:11  [ main:33409 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 14:28:11  [ main:33410 ] - [ INFO ]  Job job_local1632616300_0001 completed successfully
2020-11-19 14:28:11  [ main:33421 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1240076
		FILE: Number of bytes written=2430456
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893258
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=619856
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=619856
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=714604544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893258
2020-11-19 14:28:15  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:28:16  [ main:702 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:28:16  [ main:703 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:28:16  [ main:923 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:28:16  [ main:928 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:28:16  [ main:947 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:28:16  [ main:1021 ] - [ INFO ]  number of splits:1
2020-11-19 14:28:16  [ main:1085 ] - [ INFO ]  Submitting tokens for job: job_local1653172336_0001
2020-11-19 14:28:16  [ main:1187 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:28:16  [ main:1188 ] - [ INFO ]  Running job: job_local1653172336_0001
2020-11-19 14:28:16  [ Thread-18:1189 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:28:16  [ Thread-18:1192 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:28:16  [ Thread-18:1194 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:28:16  [ Thread-18:1248 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:28:16  [ LocalJobRunner Map Task Executor #0:1248 ] - [ INFO ]  Starting task: attempt_local1653172336_0001_m_000000_0
2020-11-19 14:28:16  [ LocalJobRunner Map Task Executor #0:1272 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1277 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1278 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1281 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1342 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1342 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1342 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1342 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1342 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:28:17  [ LocalJobRunner Map Task Executor #0:1348 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:28:17  [ main:2195 ] - [ INFO ]  Job job_local1653172336_0001 running in uber mode : false
2020-11-19 14:28:17  [ main:2197 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:28:23  [ communication thread:7285 ] - [ INFO ]  map > map
2020-11-19 14:28:23  [ main:8214 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 14:28:26  [ communication thread:10287 ] - [ INFO ]  map > map
2020-11-19 14:28:26  [ main:11227 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 14:28:29  [ communication thread:13293 ] - [ INFO ]  map > map
2020-11-19 14:28:29  [ LocalJobRunner Map Task Executor #0:14049 ] - [ INFO ]  map > map
2020-11-19 14:28:29  [ LocalJobRunner Map Task Executor #0:14054 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:28:29  [ LocalJobRunner Map Task Executor #0:14054 ] - [ INFO ]  Spilling map output
2020-11-19 14:28:29  [ LocalJobRunner Map Task Executor #0:14054 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 14:28:29  [ LocalJobRunner Map Task Executor #0:14054 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:28:35  [ main:20198 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 14:28:35  [ communication thread:20198 ] - [ INFO ]  map > sort
2020-11-19 14:28:51  [ main:35547 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 14:28:53  [ communication thread:38102 ] - [ INFO ]  map > sort
2020-11-19 14:29:25  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:29:26  [ main:603 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:29:26  [ main:604 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:29:26  [ main:821 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:29:26  [ main:826 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:29:26  [ main:839 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:29:26  [ main:907 ] - [ INFO ]  number of splits:1
2020-11-19 14:29:26  [ main:970 ] - [ INFO ]  Submitting tokens for job: job_local403724825_0001
2020-11-19 14:29:26  [ main:1069 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:29:26  [ main:1070 ] - [ INFO ]  Running job: job_local403724825_0001
2020-11-19 14:29:26  [ Thread-18:1070 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:29:26  [ Thread-18:1074 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:29:26  [ Thread-18:1075 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:29:26  [ Thread-18:1117 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:29:26  [ LocalJobRunner Map Task Executor #0:1117 ] - [ INFO ]  Starting task: attempt_local403724825_0001_m_000000_0
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1140 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1145 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1146 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1148 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1203 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1204 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1204 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1204 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1204 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:29:27  [ LocalJobRunner Map Task Executor #0:1205 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:29:27  [ main:2074 ] - [ INFO ]  Job job_local403724825_0001 running in uber mode : false
2020-11-19 14:29:27  [ main:2075 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:29:37  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:29:38  [ main:730 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:29:38  [ main:730 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:29:38  [ main:948 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:29:38  [ main:954 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:29:38  [ main:975 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:29:38  [ main:1062 ] - [ INFO ]  number of splits:1
2020-11-19 14:29:38  [ main:1130 ] - [ INFO ]  Submitting tokens for job: job_local1876333407_0001
2020-11-19 14:29:38  [ main:1235 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:29:38  [ main:1235 ] - [ INFO ]  Running job: job_local1876333407_0001
2020-11-19 14:29:38  [ Thread-18:1236 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:29:38  [ Thread-18:1240 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:29:38  [ Thread-18:1241 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:29:38  [ Thread-18:1289 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1290 ] - [ INFO ]  Starting task: attempt_local1876333407_0001_m_000000_0
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1311 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1319 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:29:38  [ LocalJobRunner Map Task Executor #0:1377 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:29:39  [ main:2240 ] - [ INFO ]  Job job_local1876333407_0001 running in uber mode : false
2020-11-19 14:29:39  [ main:2242 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:29:44  [ communication thread:7319 ] - [ INFO ]  map > map
2020-11-19 14:29:45  [ main:8254 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 14:29:47  [ communication thread:10325 ] - [ INFO ]  map > map
2020-11-19 14:29:48  [ main:11263 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 14:29:50  [ communication thread:13331 ] - [ INFO ]  map > map
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14010 ] - [ INFO ]  map > map
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14014 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14015 ] - [ INFO ]  Spilling map output
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14015 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14015 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14112 ] - [ INFO ]  Finished spill 0
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14115 ] - [ INFO ]  Task:attempt_local1876333407_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14133 ] - [ INFO ]  map
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14133 ] - [ INFO ]  Task 'attempt_local1876333407_0001_m_000000_0' done.
2020-11-19 14:29:51  [ LocalJobRunner Map Task Executor #0:14134 ] - [ INFO ]  Finishing task: attempt_local1876333407_0001_m_000000_0
2020-11-19 14:29:51  [ Thread-18:14134 ] - [ INFO ]  map task executor complete.
2020-11-19 14:29:51  [ Thread-18:14136 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:29:51  [ pool-6-thread-1:14137 ] - [ INFO ]  Starting task: attempt_local1876333407_0001_r_000000_0
2020-11-19 14:29:51  [ pool-6-thread-1:14142 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:29:51  [ pool-6-thread-1:14142 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:29:51  [ pool-6-thread-1:14142 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:29:51  [ pool-6-thread-1:14144 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b09ec0c
2020-11-19 14:29:51  [ pool-6-thread-1:14153 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:29:51  [ EventFetcher for fetching Map Completion Events:14154 ] - [ INFO ]  attempt_local1876333407_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:29:51  [ localfetcher#1:14172 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1876333407_0001_m_000000_0 decomp: 1079105 len: 1079109 to MEMORY
2020-11-19 14:29:51  [ localfetcher#1:14177 ] - [ INFO ]  Read 1079105 bytes from map-output for attempt_local1876333407_0001_m_000000_0
2020-11-19 14:29:51  [ localfetcher#1:14178 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 1079105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1079105
2020-11-19 14:29:51  [ EventFetcher for fetching Map Completion Events:14179 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:29:51  [ pool-6-thread-1:14179 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:29:51  [ pool-6-thread-1:14179 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:29:51  [ pool-6-thread-1:14183 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:29:51  [ pool-6-thread-1:14183 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 14:29:51  [ pool-6-thread-1:14217 ] - [ INFO ]  Merged 1 segments, 1079105 bytes to disk to satisfy reduce memory limit
2020-11-19 14:29:51  [ pool-6-thread-1:14217 ] - [ INFO ]  Merging 1 files, 1079109 bytes from disk
2020-11-19 14:29:51  [ pool-6-thread-1:14218 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:29:51  [ pool-6-thread-1:14218 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:29:51  [ pool-6-thread-1:14218 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 14:29:51  [ pool-6-thread-1:14218 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:29:51  [ pool-6-thread-1:14239 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:29:51  [ main:14276 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 14:29:51  [ pool-6-thread-1:14487 ] - [ INFO ]  Task:attempt_local1876333407_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 14:29:51  [ pool-6-thread-1:14496 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:29:51  [ pool-6-thread-1:14496 ] - [ INFO ]  Task attempt_local1876333407_0001_r_000000_0 is allowed to commit now
2020-11-19 14:29:52  [ pool-6-thread-1:14520 ] - [ INFO ]  Saved output of task 'attempt_local1876333407_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1876333407_0001_r_000000
2020-11-19 14:29:52  [ pool-6-thread-1:14521 ] - [ INFO ]  reduce > reduce
2020-11-19 14:29:52  [ pool-6-thread-1:14521 ] - [ INFO ]  Task 'attempt_local1876333407_0001_r_000000_0' done.
2020-11-19 14:29:52  [ pool-6-thread-1:14521 ] - [ INFO ]  Finishing task: attempt_local1876333407_0001_r_000000_0
2020-11-19 14:29:52  [ Thread-18:14521 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:29:52  [ main:15281 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 14:29:52  [ main:15282 ] - [ INFO ]  Job job_local1876333407_0001 completed successfully
2020-11-19 14:29:52  [ main:15294 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2158582
		FILE: Number of bytes written=3807199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893258
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=1079109
		Input split bytes=112
		Combine input records=0
		Combine output records=0
		Reduce input groups=943
		Reduce shuffle bytes=1079109
		Reduce input records=90570
		Reduce output records=943
		Spilled Records=181140
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=713555968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893258
2020-11-19 14:50:15  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:50:16  [ main:1009 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:50:16  [ main:1010 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:50:16  [ main:1239 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:50:16  [ main:1245 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:50:16  [ main:1388 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:50:17  [ main:1468 ] - [ INFO ]  number of splits:1
2020-11-19 14:50:17  [ main:1528 ] - [ INFO ]  Submitting tokens for job: job_local1483385524_0001
2020-11-19 14:50:17  [ main:1612 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:50:17  [ main:1612 ] - [ INFO ]  Running job: job_local1483385524_0001
2020-11-19 14:50:17  [ Thread-18:1613 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:50:17  [ Thread-18:1615 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:50:17  [ Thread-18:1616 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:50:17  [ Thread-18:1782 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1782 ] - [ INFO ]  Starting task: attempt_local1483385524_0001_m_000000_0
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1799 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1805 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1805 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1807 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/word_count/test.txt:0+59
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1857 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1857 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1857 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1857 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1858 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:1859 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2011 ] - [ INFO ]  
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2012 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2013 ] - [ INFO ]  Spilling map output
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2013 ] - [ INFO ]  bufstart = 0; bufend = 163; bufvoid = 104857600
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2013 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2019 ] - [ INFO ]  Finished spill 0
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2021 ] - [ INFO ]  Task:attempt_local1483385524_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2036 ] - [ INFO ]  map
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2036 ] - [ INFO ]  Task 'attempt_local1483385524_0001_m_000000_0' done.
2020-11-19 14:50:17  [ LocalJobRunner Map Task Executor #0:2036 ] - [ INFO ]  Finishing task: attempt_local1483385524_0001_m_000000_0
2020-11-19 14:50:17  [ Thread-18:2036 ] - [ INFO ]  map task executor complete.
2020-11-19 14:50:17  [ Thread-18:2038 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:50:17  [ pool-6-thread-1:2038 ] - [ INFO ]  Starting task: attempt_local1483385524_0001_r_000000_0
2020-11-19 14:50:17  [ pool-6-thread-1:2041 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:50:17  [ pool-6-thread-1:2042 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:50:17  [ pool-6-thread-1:2042 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:50:17  [ pool-6-thread-1:2043 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1359da15
2020-11-19 14:50:17  [ pool-6-thread-1:2050 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:50:17  [ EventFetcher for fetching Map Completion Events:2052 ] - [ INFO ]  attempt_local1483385524_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:50:17  [ localfetcher#1:2069 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1483385524_0001_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-19 14:50:17  [ localfetcher#1:2072 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local1483385524_0001_m_000000_0
2020-11-19 14:50:17  [ localfetcher#1:2073 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-19 14:50:17  [ EventFetcher for fetching Map Completion Events:2074 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:50:17  [ pool-6-thread-1:2074 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:50:17  [ pool-6-thread-1:2075 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:50:17  [ pool-6-thread-1:2078 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:50:17  [ pool-6-thread-1:2078 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-19 14:50:17  [ pool-6-thread-1:2079 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-19 14:50:17  [ pool-6-thread-1:2080 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-19 14:50:17  [ pool-6-thread-1:2080 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:50:17  [ pool-6-thread-1:2080 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:50:17  [ pool-6-thread-1:2080 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-19 14:50:17  [ pool-6-thread-1:2081 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:50:17  [ pool-6-thread-1:2119 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:50:17  [ pool-6-thread-1:2322 ] - [ INFO ]  Task:attempt_local1483385524_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 14:50:17  [ pool-6-thread-1:2335 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:50:17  [ pool-6-thread-1:2335 ] - [ INFO ]  Task attempt_local1483385524_0001_r_000000_0 is allowed to commit now
2020-11-19 14:50:17  [ pool-6-thread-1:2365 ] - [ INFO ]  Saved output of task 'attempt_local1483385524_0001_r_000000_0' to hdfs://master:9000/user/root/mr/word_count/output/result/_temporary/0/task_local1483385524_0001_r_000000
2020-11-19 14:50:17  [ pool-6-thread-1:2365 ] - [ INFO ]  reduce > reduce
2020-11-19 14:50:17  [ pool-6-thread-1:2365 ] - [ INFO ]  Task 'attempt_local1483385524_0001_r_000000_0' done.
2020-11-19 14:50:17  [ pool-6-thread-1:2365 ] - [ INFO ]  Finishing task: attempt_local1483385524_0001_r_000000_0
2020-11-19 14:50:17  [ Thread-18:2366 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:50:18  [ main:2617 ] - [ INFO ]  Job job_local1483385524_0001 running in uber mode : false
2020-11-19 14:50:18  [ main:2619 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 14:50:18  [ main:2619 ] - [ INFO ]  Job job_local1483385524_0001 completed successfully
2020-11-19 14:50:18  [ main:2627 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=818
		FILE: Number of bytes written=568907
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=118
		HDFS: Number of bytes written=54
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=13
		Map output records=26
		Map output bytes=163
		Map output materialized bytes=221
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=221
		Reduce input records=26
		Reduce output records=12
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=59
	File Output Format Counters 
		Bytes Written=54
2020-11-19 14:51:38  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:51:39  [ main:603 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:51:39  [ main:604 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:51:39  [ main:803 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:51:39  [ main:807 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:51:39  [ main:819 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:51:39  [ main:963 ] - [ INFO ]  number of splits:1
2020-11-19 14:51:39  [ main:1022 ] - [ INFO ]  Submitting tokens for job: job_local1368586669_0001
2020-11-19 14:51:39  [ main:1102 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:51:39  [ main:1103 ] - [ INFO ]  Running job: job_local1368586669_0001
2020-11-19 14:51:39  [ Thread-18:1103 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:51:39  [ Thread-18:1106 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:51:39  [ Thread-18:1107 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:51:40  [ Thread-18:1814 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1814 ] - [ INFO ]  Starting task: attempt_local1368586669_0001_m_000000_0
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1830 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1834 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1835 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1837 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/word_count/test.txt:0+59
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1886 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1886 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1886 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1886 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1886 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:1889 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2078 ] - [ INFO ]  
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2079 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2080 ] - [ INFO ]  Spilling map output
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2080 ] - [ INFO ]  bufstart = 0; bufend = 163; bufvoid = 104857600
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2080 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2089 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2090 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26214292(104857168)
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2090 ] - [ INFO ]  Spilling map output
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2090 ] - [ INFO ]  bufstart = 0; bufend = 163; bufvoid = 104857600
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2090 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
2020-11-19 14:51:40  [ LocalJobRunner Map Task Executor #0:2091 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@a36618b
java.io.IOException: wrong value class: class org.apache.hadoop.io.LongWritable is not class org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.IFile$Writer.append(IFile.java:194)
	at org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1350)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner$OutputConverter.write(Task.java:1667)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.satan.hadoop.mr.WordCountMapReduceJob$WordCountCombiner.reduce(WordCountMapReduceJob.java:53)
	at com.satan.hadoop.mr.WordCountMapReduceJob$WordCountCombiner.reduce(WordCountMapReduceJob.java:45)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 14:51:40  [ Thread-18:2093 ] - [ INFO ]  map task executor complete.
2020-11-19 14:51:40  [ main:2107 ] - [ INFO ]  Job job_local1368586669_0001 running in uber mode : false
2020-11-19 14:51:40  [ main:2109 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:51:40  [ Thread-18:2114 ] - [ WARN ]  job_local1368586669_0001
java.lang.Exception: java.io.IOException: wrong value class: class org.apache.hadoop.io.LongWritable is not class org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: wrong value class: class org.apache.hadoop.io.LongWritable is not class org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.IFile$Writer.append(IFile.java:194)
	at org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1350)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner$OutputConverter.write(Task.java:1667)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.satan.hadoop.mr.WordCountMapReduceJob$WordCountCombiner.reduce(WordCountMapReduceJob.java:53)
	at com.satan.hadoop.mr.WordCountMapReduceJob$WordCountCombiner.reduce(WordCountMapReduceJob.java:45)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 14:51:41  [ main:3113 ] - [ INFO ]  Job job_local1368586669_0001 failed with state FAILED due to: NA
2020-11-19 14:51:41  [ main:3118 ] - [ INFO ]  Counters: 11
	Map-Reduce Framework
		Map input records=13
		Map output records=26
		Map output bytes=163
		Map output materialized bytes=0
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
	File Input Format Counters 
		Bytes Read=59
2020-11-19 14:52:58  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 14:52:58  [ main:750 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 14:52:58  [ main:751 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 14:52:59  [ main:970 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 14:52:59  [ main:976 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 14:52:59  [ main:996 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 14:52:59  [ main:1106 ] - [ INFO ]  number of splits:1
2020-11-19 14:52:59  [ main:1173 ] - [ INFO ]  Submitting tokens for job: job_local1737178716_0001
2020-11-19 14:52:59  [ main:1276 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 14:52:59  [ main:1277 ] - [ INFO ]  Running job: job_local1737178716_0001
2020-11-19 14:52:59  [ Thread-18:1277 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 14:52:59  [ Thread-18:1280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:52:59  [ Thread-18:1282 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 14:52:59  [ Thread-18:1330 ] - [ INFO ]  Waiting for map tasks
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1331 ] - [ INFO ]  Starting task: attempt_local1737178716_0001_m_000000_0
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1351 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1356 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1357 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1360 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/word_count/test.txt:0+59
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1425 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1425 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1425 ] - [ INFO ]  soft limit at 83886080
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1425 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1425 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1432 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1563 ] - [ INFO ]  
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1564 ] - [ INFO ]  Starting flush of map output
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1564 ] - [ INFO ]  Spilling map output
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1564 ] - [ INFO ]  bufstart = 0; bufend = 163; bufvoid = 104857600
2020-11-19 14:52:59  [ LocalJobRunner Map Task Executor #0:1564 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
2020-11-19 14:53:06  [ main:8283 ] - [ INFO ]  Job job_local1737178716_0001 running in uber mode : false
2020-11-19 14:53:15  [ main:17062 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 14:53:17  [ LocalJobRunner Map Task Executor #0:19539 ] - [ INFO ]  Finished spill 0
2020-11-19 14:53:17  [ LocalJobRunner Map Task Executor #0:19543 ] - [ INFO ]  Task:attempt_local1737178716_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 14:53:17  [ communication thread:19544 ] - [ INFO ]  map
2020-11-19 14:53:17  [ LocalJobRunner Map Task Executor #0:19573 ] - [ INFO ]  map
2020-11-19 14:53:17  [ LocalJobRunner Map Task Executor #0:19573 ] - [ INFO ]  Task 'attempt_local1737178716_0001_m_000000_0' done.
2020-11-19 14:53:17  [ LocalJobRunner Map Task Executor #0:19574 ] - [ INFO ]  Finishing task: attempt_local1737178716_0001_m_000000_0
2020-11-19 14:53:17  [ Thread-18:19574 ] - [ INFO ]  map task executor complete.
2020-11-19 14:53:17  [ Thread-18:19575 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 14:53:17  [ pool-6-thread-1:19576 ] - [ INFO ]  Starting task: attempt_local1737178716_0001_r_000000_0
2020-11-19 14:53:17  [ pool-6-thread-1:19580 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 14:53:17  [ pool-6-thread-1:19580 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 14:53:17  [ pool-6-thread-1:19580 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 14:53:17  [ pool-6-thread-1:19582 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41da400
2020-11-19 14:53:17  [ pool-6-thread-1:19590 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 14:53:17  [ EventFetcher for fetching Map Completion Events:19591 ] - [ INFO ]  attempt_local1737178716_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 14:53:17  [ localfetcher#1:19611 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1737178716_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2020-11-19 14:53:17  [ localfetcher#1:19615 ] - [ INFO ]  Read 104 bytes from map-output for attempt_local1737178716_0001_m_000000_0
2020-11-19 14:53:17  [ localfetcher#1:19615 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->104
2020-11-19 14:53:17  [ EventFetcher for fetching Map Completion Events:19616 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 14:53:17  [ pool-6-thread-1:19617 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:53:17  [ pool-6-thread-1:19617 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 14:53:17  [ pool-6-thread-1:19621 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:53:17  [ pool-6-thread-1:19622 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 100 bytes
2020-11-19 14:53:17  [ pool-6-thread-1:19622 ] - [ INFO ]  Merged 1 segments, 104 bytes to disk to satisfy reduce memory limit
2020-11-19 14:53:17  [ pool-6-thread-1:19623 ] - [ INFO ]  Merging 1 files, 108 bytes from disk
2020-11-19 14:53:17  [ pool-6-thread-1:19623 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 14:53:17  [ pool-6-thread-1:19623 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 14:53:17  [ pool-6-thread-1:19623 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 100 bytes
2020-11-19 14:53:17  [ pool-6-thread-1:19624 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:53:17  [ pool-6-thread-1:19645 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 14:53:17  [ pool-6-thread-1:19895 ] - [ INFO ]  Task:attempt_local1737178716_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 14:53:17  [ pool-6-thread-1:19901 ] - [ INFO ]  1 / 1 copied.
2020-11-19 14:53:17  [ pool-6-thread-1:19902 ] - [ INFO ]  Task attempt_local1737178716_0001_r_000000_0 is allowed to commit now
2020-11-19 14:53:18  [ pool-6-thread-1:19928 ] - [ INFO ]  Saved output of task 'attempt_local1737178716_0001_r_000000_0' to hdfs://master:9000/user/root/mr/word_count/output/result/_temporary/0/task_local1737178716_0001_r_000000
2020-11-19 14:53:18  [ pool-6-thread-1:19929 ] - [ INFO ]  reduce > reduce
2020-11-19 14:53:18  [ pool-6-thread-1:19929 ] - [ INFO ]  Task 'attempt_local1737178716_0001_r_000000_0' done.
2020-11-19 14:53:18  [ pool-6-thread-1:19929 ] - [ INFO ]  Finishing task: attempt_local1737178716_0001_r_000000_0
2020-11-19 14:53:18  [ Thread-18:19929 ] - [ INFO ]  reduce task executor complete.
2020-11-19 14:53:18  [ main:20544 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 14:53:18  [ main:20545 ] - [ INFO ]  Job job_local1737178716_0001 completed successfully
2020-11-19 14:53:18  [ main:20555 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=592
		FILE: Number of bytes written=569476
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=118
		HDFS: Number of bytes written=54
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=13
		Map output records=26
		Map output bytes=163
		Map output materialized bytes=108
		Input split bytes=121
		Combine input records=26
		Combine output records=12
		Reduce input groups=12
		Reduce shuffle bytes=108
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=634388480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=59
	File Output Format Counters 
		Bytes Written=54
2020-11-19 15:17:42  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:17:43  [ main:846 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:17:43  [ main:847 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:17:43  [ main:1083 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:17:43  [ main:1089 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:17:43  [ main:1157 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:17:43  [ main:1249 ] - [ INFO ]  number of splits:1
2020-11-19 15:17:43  [ main:1313 ] - [ INFO ]  Submitting tokens for job: job_local1047221781_0001
2020-11-19 15:17:43  [ main:1405 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:17:43  [ main:1405 ] - [ INFO ]  Running job: job_local1047221781_0001
2020-11-19 15:17:43  [ Thread-18:1406 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:17:43  [ Thread-18:1410 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:17:43  [ Thread-18:1412 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:17:43  [ Thread-18:1509 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1510 ] - [ INFO ]  Starting task: attempt_local1047221781_0001_m_000000_0
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1528 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1534 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1535 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1538 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1588 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1588 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1588 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1588 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1588 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:17:43  [ LocalJobRunner Map Task Executor #0:1602 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:17:44  [ main:2410 ] - [ INFO ]  Job job_local1047221781_0001 running in uber mode : false
2020-11-19 15:17:44  [ main:2411 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:17:49  [ communication thread:7538 ] - [ INFO ]  map > map
2020-11-19 15:17:50  [ main:8430 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 15:17:52  [ communication thread:10539 ] - [ INFO ]  map > map
2020-11-19 15:17:53  [ main:11445 ] - [ INFO ]   map 44% reduce 0%
2020-11-19 15:17:55  [ communication thread:13546 ] - [ INFO ]  map > map
2020-11-19 15:17:56  [ main:14450 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:17:56  [ LocalJobRunner Map Task Executor #0:14567 ] - [ INFO ]  map > map
2020-11-19 15:17:56  [ LocalJobRunner Map Task Executor #0:14572 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:17:56  [ LocalJobRunner Map Task Executor #0:14572 ] - [ INFO ]  Spilling map output
2020-11-19 15:17:56  [ LocalJobRunner Map Task Executor #0:14572 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:17:56  [ LocalJobRunner Map Task Executor #0:14572 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:18:00  [ communication thread:18139 ] - [ INFO ]  map > sort
2020-11-19 15:18:04  [ main:22327 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 15:18:05  [ communication thread:22914 ] - [ INFO ]  map > sort
2020-11-19 15:18:14  [ LocalJobRunner Map Task Executor #0:32479 ] - [ INFO ]  Finished spill 0
2020-11-19 15:18:14  [ LocalJobRunner Map Task Executor #0:32482 ] - [ INFO ]  Task:attempt_local1047221781_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:18:14  [ LocalJobRunner Map Task Executor #0:32541 ] - [ INFO ]  map
2020-11-19 15:18:14  [ LocalJobRunner Map Task Executor #0:32541 ] - [ INFO ]  Task 'attempt_local1047221781_0001_m_000000_0' done.
2020-11-19 15:18:14  [ LocalJobRunner Map Task Executor #0:32542 ] - [ INFO ]  Finishing task: attempt_local1047221781_0001_m_000000_0
2020-11-19 15:18:14  [ Thread-18:32542 ] - [ INFO ]  map task executor complete.
2020-11-19 15:18:14  [ Thread-18:32544 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:18:14  [ pool-6-thread-1:32544 ] - [ INFO ]  Starting task: attempt_local1047221781_0001_r_000000_0
2020-11-19 15:18:14  [ pool-6-thread-1:32550 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:18:14  [ pool-6-thread-1:32550 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:18:14  [ pool-6-thread-1:32550 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:18:14  [ pool-6-thread-1:32552 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42feea57
2020-11-19 15:18:14  [ pool-6-thread-1:32562 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:18:14  [ EventFetcher for fetching Map Completion Events:32563 ] - [ INFO ]  attempt_local1047221781_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:18:14  [ localfetcher#1:32583 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1047221781_0001_m_000000_0 decomp: 11746 len: 11750 to MEMORY
2020-11-19 15:18:14  [ localfetcher#1:32586 ] - [ INFO ]  Read 11746 bytes from map-output for attempt_local1047221781_0001_m_000000_0
2020-11-19 15:18:14  [ localfetcher#1:32587 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 11746, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11746
2020-11-19 15:18:14  [ EventFetcher for fetching Map Completion Events:32588 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:18:14  [ pool-6-thread-1:32589 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:18:14  [ pool-6-thread-1:32589 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:18:14  [ pool-6-thread-1:32593 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:18:14  [ pool-6-thread-1:32593 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 11740 bytes
2020-11-19 15:18:14  [ pool-6-thread-1:32597 ] - [ INFO ]  Merged 1 segments, 11746 bytes to disk to satisfy reduce memory limit
2020-11-19 15:18:14  [ pool-6-thread-1:32597 ] - [ INFO ]  Merging 1 files, 11750 bytes from disk
2020-11-19 15:18:14  [ pool-6-thread-1:32597 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:18:14  [ pool-6-thread-1:32597 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:18:14  [ pool-6-thread-1:32598 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 11740 bytes
2020-11-19 15:18:14  [ pool-6-thread-1:32598 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:18:14  [ pool-6-thread-1:32649 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:18:15  [ main:33438 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:18:20  [ pool-6-thread-1:37882 ] - [ INFO ]  Task:attempt_local1047221781_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:18:20  [ pool-6-thread-1:37920 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:18:20  [ pool-6-thread-1:37920 ] - [ INFO ]  Task attempt_local1047221781_0001_r_000000_0 is allowed to commit now
2020-11-19 15:18:20  [ pool-6-thread-1:38186 ] - [ INFO ]  Saved output of task 'attempt_local1047221781_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1047221781_0001_r_000000
2020-11-19 15:18:20  [ pool-6-thread-1:38187 ] - [ INFO ]  reduce > reduce
2020-11-19 15:18:20  [ pool-6-thread-1:38187 ] - [ INFO ]  Task 'attempt_local1047221781_0001_r_000000_0' done.
2020-11-19 15:18:20  [ pool-6-thread-1:38187 ] - [ INFO ]  Finishing task: attempt_local1047221781_0001_r_000000_0
2020-11-19 15:18:20  [ Thread-18:38187 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:18:20  [ main:38442 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:18:21  [ main:39446 ] - [ INFO ]  Job job_local1047221781_0001 completed successfully
2020-11-19 15:18:21  [ main:39458 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=23864
		FILE: Number of bytes written=606138
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893258
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=11750
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=11750
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=707788800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893258
2020-11-19 15:21:20  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:21:20  [ main:595 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:21:20  [ main:596 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:21:20  [ main:800 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:21:20  [ main:805 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:21:20  [ main:856 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:21:21  [ main:1003 ] - [ INFO ]  number of splits:1
2020-11-19 15:21:21  [ main:1073 ] - [ INFO ]  Submitting tokens for job: job_local763199540_0001
2020-11-19 15:21:21  [ main:1173 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:21:21  [ main:1174 ] - [ INFO ]  Running job: job_local763199540_0001
2020-11-19 15:21:21  [ Thread-18:1174 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:21:21  [ Thread-18:1177 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:21:21  [ Thread-18:1178 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:21:21  [ Thread-18:1220 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1220 ] - [ INFO ]  Starting task: attempt_local763199540_0001_m_000000_0
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1234 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1238 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1238 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1241 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1287 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:21:21  [ LocalJobRunner Map Task Executor #0:1289 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:21:22  [ main:2179 ] - [ INFO ]  Job job_local763199540_0001 running in uber mode : false
2020-11-19 15:21:22  [ main:2181 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:21:27  [ communication thread:7248 ] - [ INFO ]  map > map
2020-11-19 15:21:28  [ main:8195 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:21:30  [ communication thread:10250 ] - [ INFO ]  map > map
2020-11-19 15:21:31  [ main:11198 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:21:33  [ communication thread:13255 ] - [ INFO ]  map > map
2020-11-19 15:21:34  [ main:14204 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14773 ] - [ INFO ]  map > map
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14775 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14775 ] - [ INFO ]  Spilling map output
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14775 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14775 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14879 ] - [ INFO ]  Finished spill 0
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14882 ] - [ INFO ]  Task:attempt_local763199540_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14916 ] - [ INFO ]  map
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14916 ] - [ INFO ]  Task 'attempt_local763199540_0001_m_000000_0' done.
2020-11-19 15:21:34  [ LocalJobRunner Map Task Executor #0:14916 ] - [ INFO ]  Finishing task: attempt_local763199540_0001_m_000000_0
2020-11-19 15:21:34  [ Thread-18:14916 ] - [ INFO ]  map task executor complete.
2020-11-19 15:21:34  [ Thread-18:14918 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:21:34  [ pool-6-thread-1:14918 ] - [ INFO ]  Starting task: attempt_local763199540_0001_r_000000_0
2020-11-19 15:21:34  [ pool-6-thread-1:14922 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:21:34  [ pool-6-thread-1:14923 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:21:34  [ pool-6-thread-1:14923 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:21:34  [ pool-6-thread-1:14924 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d220b93
2020-11-19 15:21:35  [ pool-6-thread-1:14932 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:21:35  [ EventFetcher for fetching Map Completion Events:14934 ] - [ INFO ]  attempt_local763199540_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:21:35  [ localfetcher#1:14951 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local763199540_0001_m_000000_0 decomp: 11746 len: 11750 to MEMORY
2020-11-19 15:21:35  [ localfetcher#1:14954 ] - [ INFO ]  Read 11746 bytes from map-output for attempt_local763199540_0001_m_000000_0
2020-11-19 15:21:35  [ localfetcher#1:14955 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 11746, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11746
2020-11-19 15:21:35  [ EventFetcher for fetching Map Completion Events:14956 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:21:35  [ pool-6-thread-1:14956 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:21:35  [ pool-6-thread-1:14956 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:21:35  [ pool-6-thread-1:14960 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:21:35  [ pool-6-thread-1:14960 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 11740 bytes
2020-11-19 15:21:35  [ pool-6-thread-1:14964 ] - [ INFO ]  Merged 1 segments, 11746 bytes to disk to satisfy reduce memory limit
2020-11-19 15:21:35  [ pool-6-thread-1:14964 ] - [ INFO ]  Merging 1 files, 11750 bytes from disk
2020-11-19 15:21:35  [ pool-6-thread-1:14965 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:21:35  [ pool-6-thread-1:14965 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:21:35  [ pool-6-thread-1:14965 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 11740 bytes
2020-11-19 15:21:35  [ pool-6-thread-1:14965 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:21:35  [ pool-6-thread-1:15004 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:21:35  [ main:15205 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:21:36  [ pool-6-thread-1:16569 ] - [ INFO ]  Task:attempt_local763199540_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:21:36  [ pool-6-thread-1:16588 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:21:36  [ pool-6-thread-1:16588 ] - [ INFO ]  Task attempt_local763199540_0001_r_000000_0 is allowed to commit now
2020-11-19 15:21:36  [ pool-6-thread-1:16659 ] - [ INFO ]  Saved output of task 'attempt_local763199540_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local763199540_0001_r_000000
2020-11-19 15:21:36  [ pool-6-thread-1:16660 ] - [ INFO ]  reduce > reduce
2020-11-19 15:21:36  [ pool-6-thread-1:16660 ] - [ INFO ]  Task 'attempt_local763199540_0001_r_000000_0' done.
2020-11-19 15:21:36  [ pool-6-thread-1:16660 ] - [ INFO ]  Finishing task: attempt_local763199540_0001_r_000000_0
2020-11-19 15:21:36  [ Thread-18:16660 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:21:37  [ main:17212 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:21:37  [ main:17213 ] - [ INFO ]  Job job_local763199540_0001 completed successfully
2020-11-19 15:21:37  [ main:17222 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=23864
		FILE: Number of bytes written=603094
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893258
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=11750
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=11750
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=699400192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893258
2020-11-19 15:22:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:22:54  [ main:932 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:22:54  [ main:933 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:22:56  [ main:2314 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:22:56  [ main:2319 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:22:56  [ main:2346 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:22:56  [ main:2454 ] - [ INFO ]  number of splits:1
2020-11-19 15:22:56  [ main:2513 ] - [ INFO ]  Submitting tokens for job: job_local1427256162_0001
2020-11-19 15:22:56  [ main:2594 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:22:56  [ main:2594 ] - [ INFO ]  Running job: job_local1427256162_0001
2020-11-19 15:22:56  [ Thread-18:2595 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:22:56  [ Thread-18:2598 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:22:56  [ Thread-18:2599 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:22:56  [ Thread-18:2819 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2819 ] - [ INFO ]  Starting task: attempt_local1427256162_0001_m_000000_0
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2834 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2838 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2838 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2841 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2893 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2894 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2894 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2894 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2894 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:22:56  [ LocalJobRunner Map Task Executor #0:2896 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:22:57  [ main:3598 ] - [ INFO ]  Job job_local1427256162_0001 running in uber mode : false
2020-11-19 15:22:57  [ main:3600 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:23:05  [ communication thread:11849 ] - [ INFO ]  map > map
2020-11-19 15:23:06  [ main:12629 ] - [ INFO ]   map 27% reduce 0%
2020-11-19 15:23:08  [ communication thread:14850 ] - [ INFO ]  map > map
2020-11-19 15:23:09  [ main:15639 ] - [ INFO ]   map 39% reduce 0%
2020-11-19 15:23:11  [ communication thread:17854 ] - [ INFO ]  map > map
2020-11-19 15:23:12  [ main:18648 ] - [ INFO ]   map 54% reduce 0%
2020-11-19 15:23:14  [ communication thread:20859 ] - [ INFO ]  map > map
2020-11-19 15:23:15  [ main:21659 ] - [ INFO ]   map 66% reduce 0%
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23852 ] - [ INFO ]  map > map
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23854 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23855 ] - [ INFO ]  Spilling map output
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23855 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23855 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:23:17  [ communication thread:23863 ] - [ INFO ]  map > sort
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23987 ] - [ INFO ]  Finished spill 0
2020-11-19 15:23:17  [ LocalJobRunner Map Task Executor #0:23990 ] - [ INFO ]  Task:attempt_local1427256162_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:23:18  [ main:24670 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 15:23:19  [ LocalJobRunner Map Task Executor #0:26130 ] - [ INFO ]  map
2020-11-19 15:23:19  [ LocalJobRunner Map Task Executor #0:26130 ] - [ INFO ]  Task 'attempt_local1427256162_0001_m_000000_0' done.
2020-11-19 15:23:19  [ LocalJobRunner Map Task Executor #0:26130 ] - [ INFO ]  Finishing task: attempt_local1427256162_0001_m_000000_0
2020-11-19 15:23:19  [ Thread-18:26130 ] - [ INFO ]  map task executor complete.
2020-11-19 15:23:19  [ Thread-18:26133 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:23:19  [ pool-6-thread-1:26133 ] - [ INFO ]  Starting task: attempt_local1427256162_0001_r_000000_0
2020-11-19 15:23:19  [ pool-6-thread-1:26138 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:23:19  [ pool-6-thread-1:26139 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:23:19  [ pool-6-thread-1:26139 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:23:19  [ pool-6-thread-1:26140 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b271405
2020-11-19 15:23:20  [ pool-6-thread-1:26564 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:23:20  [ EventFetcher for fetching Map Completion Events:26566 ] - [ INFO ]  attempt_local1427256162_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:23:20  [ localfetcher#1:26585 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1427256162_0001_m_000000_0 decomp: 11746 len: 11750 to MEMORY
2020-11-19 15:23:20  [ localfetcher#1:26589 ] - [ INFO ]  Read 11746 bytes from map-output for attempt_local1427256162_0001_m_000000_0
2020-11-19 15:23:20  [ localfetcher#1:26590 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 11746, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11746
2020-11-19 15:23:20  [ EventFetcher for fetching Map Completion Events:26591 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:23:20  [ pool-6-thread-1:26592 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:23:20  [ pool-6-thread-1:26592 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:23:20  [ pool-6-thread-1:26596 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:23:20  [ pool-6-thread-1:26597 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 11740 bytes
2020-11-19 15:23:20  [ pool-6-thread-1:26601 ] - [ INFO ]  Merged 1 segments, 11746 bytes to disk to satisfy reduce memory limit
2020-11-19 15:23:20  [ pool-6-thread-1:26601 ] - [ INFO ]  Merging 1 files, 11750 bytes from disk
2020-11-19 15:23:20  [ pool-6-thread-1:26601 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:23:20  [ pool-6-thread-1:26601 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:23:20  [ pool-6-thread-1:26602 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 11740 bytes
2020-11-19 15:23:20  [ pool-6-thread-1:26602 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:23:20  [ pool-6-thread-1:26627 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:23:20  [ main:26679 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:23:25  [ communication thread:32145 ] - [ INFO ]  reduce > reduce
2020-11-19 15:23:26  [ main:32697 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:23:46  [ pool-6-thread-1:52206 ] - [ INFO ]  Task:attempt_local1427256162_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:23:46  [ pool-6-thread-1:52224 ] - [ INFO ]  reduce > reduce
2020-11-19 15:23:46  [ pool-6-thread-1:52224 ] - [ INFO ]  Task attempt_local1427256162_0001_r_000000_0 is allowed to commit now
2020-11-19 15:23:46  [ pool-6-thread-1:52350 ] - [ INFO ]  Saved output of task 'attempt_local1427256162_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1427256162_0001_r_000000
2020-11-19 15:23:46  [ pool-6-thread-1:52351 ] - [ INFO ]  reduce > reduce
2020-11-19 15:23:46  [ pool-6-thread-1:52351 ] - [ INFO ]  Task 'attempt_local1427256162_0001_r_000000_0' done.
2020-11-19 15:23:46  [ pool-6-thread-1:52351 ] - [ INFO ]  Finishing task: attempt_local1427256162_0001_r_000000_0
2020-11-19 15:23:46  [ Thread-18:52351 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:23:46  [ main:52756 ] - [ INFO ]  Job job_local1427256162_0001 completed successfully
2020-11-19 15:23:46  [ main:52767 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=23864
		FILE: Number of bytes written=606138
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=893258
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=11750
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=11750
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=591921152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=893258
2020-11-19 15:24:35  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:24:35  [ main:652 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:24:35  [ main:653 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:24:36  [ main:863 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:24:36  [ main:869 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:24:36  [ main:885 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:24:36  [ main:1159 ] - [ INFO ]  number of splits:1
2020-11-19 15:24:36  [ main:1219 ] - [ INFO ]  Submitting tokens for job: job_local1885219168_0001
2020-11-19 15:24:36  [ main:1308 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:24:36  [ main:1308 ] - [ INFO ]  Running job: job_local1885219168_0001
2020-11-19 15:24:36  [ Thread-18:1309 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:24:36  [ Thread-18:1312 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:24:36  [ Thread-18:1313 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:24:36  [ Thread-18:1421 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1421 ] - [ INFO ]  Starting task: attempt_local1885219168_0001_m_000000_0
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1438 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1441 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1442 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1444 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1496 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1496 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1496 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1496 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1496 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:24:36  [ LocalJobRunner Map Task Executor #0:1498 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:24:37  [ main:2312 ] - [ INFO ]  Job job_local1885219168_0001 running in uber mode : false
2020-11-19 15:24:37  [ main:2314 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:24:42  [ communication thread:7450 ] - [ INFO ]  map > map
2020-11-19 15:24:43  [ main:8328 ] - [ INFO ]   map 27% reduce 0%
2020-11-19 15:24:45  [ communication thread:10452 ] - [ INFO ]  map > map
2020-11-19 15:24:46  [ main:11333 ] - [ INFO ]   map 37% reduce 0%
2020-11-19 15:24:48  [ communication thread:13454 ] - [ INFO ]  map > map
2020-11-19 15:24:49  [ main:14344 ] - [ INFO ]   map 54% reduce 0%
2020-11-19 15:24:50  [ LocalJobRunner Map Task Executor #0:15741 ] - [ INFO ]  map > map
2020-11-19 15:24:50  [ LocalJobRunner Map Task Executor #0:15743 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:24:50  [ LocalJobRunner Map Task Executor #0:15743 ] - [ INFO ]  Spilling map output
2020-11-19 15:24:50  [ LocalJobRunner Map Task Executor #0:15743 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:24:50  [ LocalJobRunner Map Task Executor #0:15743 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:24:51  [ LocalJobRunner Map Task Executor #0:15830 ] - [ INFO ]  Finished spill 0
2020-11-19 15:24:51  [ LocalJobRunner Map Task Executor #0:15833 ] - [ INFO ]  Task:attempt_local1885219168_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:24:51  [ LocalJobRunner Map Task Executor #0:15911 ] - [ INFO ]  map
2020-11-19 15:24:51  [ LocalJobRunner Map Task Executor #0:15911 ] - [ INFO ]  Task 'attempt_local1885219168_0001_m_000000_0' done.
2020-11-19 15:24:51  [ LocalJobRunner Map Task Executor #0:15911 ] - [ INFO ]  Finishing task: attempt_local1885219168_0001_m_000000_0
2020-11-19 15:24:51  [ Thread-18:15911 ] - [ INFO ]  map task executor complete.
2020-11-19 15:24:51  [ Thread-18:15914 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:24:51  [ pool-6-thread-1:15914 ] - [ INFO ]  Starting task: attempt_local1885219168_0001_r_000000_0
2020-11-19 15:24:51  [ pool-6-thread-1:15920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:24:51  [ pool-6-thread-1:15920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:24:51  [ pool-6-thread-1:15920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:24:51  [ pool-6-thread-1:15922 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6cd6b1b1
2020-11-19 15:24:51  [ pool-6-thread-1:15932 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:24:51  [ EventFetcher for fetching Map Completion Events:15933 ] - [ INFO ]  attempt_local1885219168_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:24:51  [ localfetcher#1:15955 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1885219168_0001_m_000000_0 decomp: 1079105 len: 1079109 to MEMORY
2020-11-19 15:24:51  [ localfetcher#1:15960 ] - [ INFO ]  Read 1079105 bytes from map-output for attempt_local1885219168_0001_m_000000_0
2020-11-19 15:24:51  [ localfetcher#1:15961 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 1079105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1079105
2020-11-19 15:24:51  [ EventFetcher for fetching Map Completion Events:15961 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:24:51  [ pool-6-thread-1:15962 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:24:51  [ pool-6-thread-1:15962 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:24:51  [ pool-6-thread-1:15970 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:24:51  [ pool-6-thread-1:15970 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 15:24:51  [ pool-6-thread-1:16002 ] - [ INFO ]  Merged 1 segments, 1079105 bytes to disk to satisfy reduce memory limit
2020-11-19 15:24:51  [ pool-6-thread-1:16002 ] - [ INFO ]  Merging 1 files, 1079109 bytes from disk
2020-11-19 15:24:51  [ pool-6-thread-1:16003 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:24:51  [ pool-6-thread-1:16003 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:24:51  [ pool-6-thread-1:16003 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 15:24:51  [ pool-6-thread-1:16003 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:24:51  [ pool-6-thread-1:16042 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:24:51  [ main:16349 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:24:56  [ pool-6-thread-1:21142 ] - [ INFO ]  Task:attempt_local1885219168_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:24:56  [ pool-6-thread-1:21154 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:24:56  [ pool-6-thread-1:21155 ] - [ INFO ]  Task attempt_local1885219168_0001_r_000000_0 is allowed to commit now
2020-11-19 15:24:56  [ pool-6-thread-1:21317 ] - [ INFO ]  Saved output of task 'attempt_local1885219168_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1885219168_0001_r_000000
2020-11-19 15:24:56  [ pool-6-thread-1:21318 ] - [ INFO ]  reduce > reduce
2020-11-19 15:24:56  [ pool-6-thread-1:21318 ] - [ INFO ]  Task 'attempt_local1885219168_0001_r_000000_0' done.
2020-11-19 15:24:56  [ pool-6-thread-1:21318 ] - [ INFO ]  Finishing task: attempt_local1885219168_0001_r_000000_0
2020-11-19 15:24:56  [ Thread-18:21318 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:24:56  [ main:21361 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:24:57  [ main:22365 ] - [ INFO ]  Job job_local1885219168_0001 completed successfully
2020-11-19 15:24:57  [ main:22376 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2158582
		FILE: Number of bytes written=3807199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=892913
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=1079109
		Input split bytes=112
		Combine input records=0
		Combine output records=0
		Reduce input groups=943
		Reduce shuffle bytes=1079109
		Reduce input records=90570
		Reduce output records=943
		Spilled Records=181140
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=665321472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=892913
2020-11-19 15:25:45  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:25:45  [ main:596 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:25:45  [ main:596 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:25:45  [ main:816 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:25:45  [ main:821 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:25:45  [ main:833 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:25:46  [ main:908 ] - [ INFO ]  number of splits:1
2020-11-19 15:25:46  [ main:969 ] - [ INFO ]  Submitting tokens for job: job_local1627740637_0001
2020-11-19 15:25:46  [ main:1054 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:25:46  [ main:1054 ] - [ INFO ]  Running job: job_local1627740637_0001
2020-11-19 15:25:46  [ Thread-18:1055 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:25:46  [ Thread-18:1058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:25:46  [ Thread-18:1059 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:25:46  [ Thread-18:1107 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1108 ] - [ INFO ]  Starting task: attempt_local1627740637_0001_m_000000_0
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1123 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1127 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1127 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1130 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1181 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1182 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1182 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1182 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1182 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:25:46  [ LocalJobRunner Map Task Executor #0:1183 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:25:47  [ main:2058 ] - [ INFO ]  Job job_local1627740637_0001 running in uber mode : false
2020-11-19 15:25:47  [ main:2060 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:25:52  [ communication thread:7133 ] - [ INFO ]  map > map
2020-11-19 15:25:53  [ main:8079 ] - [ INFO ]   map 10% reduce 0%
2020-11-19 15:25:55  [ communication thread:10135 ] - [ INFO ]  map > map
2020-11-19 15:25:56  [ main:11094 ] - [ INFO ]   map 12% reduce 0%
2020-11-19 15:25:58  [ communication thread:13137 ] - [ INFO ]  map > map
2020-11-19 15:25:59  [ main:14103 ] - [ INFO ]   map 20% reduce 0%
2020-11-19 15:26:01  [ communication thread:16142 ] - [ INFO ]  map > map
2020-11-19 15:26:02  [ main:17116 ] - [ INFO ]   map 22% reduce 0%
2020-11-19 15:26:04  [ communication thread:19144 ] - [ INFO ]  map > map
2020-11-19 15:26:05  [ main:20126 ] - [ INFO ]   map 24% reduce 0%
2020-11-19 15:26:07  [ communication thread:22149 ] - [ INFO ]  map > map
2020-11-19 15:26:08  [ main:23133 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 15:26:10  [ communication thread:25154 ] - [ INFO ]  map > map
2020-11-19 15:26:11  [ main:26141 ] - [ INFO ]   map 34% reduce 0%
2020-11-19 15:26:13  [ communication thread:28158 ] - [ INFO ]  map > map
2020-11-19 15:26:14  [ main:29149 ] - [ INFO ]   map 44% reduce 0%
2020-11-19 15:26:16  [ communication thread:31158 ] - [ INFO ]  map > map
2020-11-19 15:26:17  [ main:32158 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:26:19  [ communication thread:34159 ] - [ INFO ]  map > map
2020-11-19 15:26:19  [ main:34159 ] - [ INFO ]   map 49% reduce 0%
2020-11-19 15:26:22  [ communication thread:37161 ] - [ INFO ]  map > map
2020-11-19 15:26:22  [ main:37173 ] - [ INFO ]   map 51% reduce 0%
2020-11-19 15:26:25  [ communication thread:40164 ] - [ INFO ]  map > map
2020-11-19 15:26:31  [ communication thread:46169 ] - [ INFO ]  map > map
2020-11-19 15:26:31  [ main:46202 ] - [ INFO ]   map 56% reduce 0%
2020-11-19 15:26:37  [ communication thread:52173 ] - [ INFO ]  map > map
2020-11-19 15:26:37  [ main:52210 ] - [ INFO ]   map 59% reduce 0%
2020-11-19 15:26:46  [ communication thread:61183 ] - [ INFO ]  map > map
2020-11-19 15:26:46  [ main:61238 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:26:55  [ communication thread:70190 ] - [ INFO ]  map > map
2020-11-19 15:26:55  [ main:70256 ] - [ INFO ]   map 66% reduce 0%
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:70913 ] - [ INFO ]  map > map
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:70916 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:70916 ] - [ INFO ]  Spilling map output
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:70916 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:70916 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:71003 ] - [ INFO ]  Finished spill 0
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:71006 ] - [ INFO ]  Task:attempt_local1627740637_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:71029 ] - [ INFO ]  map
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:71029 ] - [ INFO ]  Task 'attempt_local1627740637_0001_m_000000_0' done.
2020-11-19 15:26:56  [ LocalJobRunner Map Task Executor #0:71029 ] - [ INFO ]  Finishing task: attempt_local1627740637_0001_m_000000_0
2020-11-19 15:26:56  [ Thread-18:71029 ] - [ INFO ]  map task executor complete.
2020-11-19 15:26:56  [ Thread-18:71032 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:26:56  [ pool-6-thread-1:71032 ] - [ INFO ]  Starting task: attempt_local1627740637_0001_r_000000_0
2020-11-19 15:26:56  [ pool-6-thread-1:71037 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:26:56  [ pool-6-thread-1:71037 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:26:56  [ pool-6-thread-1:71038 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:26:56  [ pool-6-thread-1:71039 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22da8a69
2020-11-19 15:26:56  [ pool-6-thread-1:71049 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:26:56  [ EventFetcher for fetching Map Completion Events:71051 ] - [ INFO ]  attempt_local1627740637_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:26:56  [ localfetcher#1:71074 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1627740637_0001_m_000000_0 decomp: 1079105 len: 1079109 to MEMORY
2020-11-19 15:26:56  [ localfetcher#1:71079 ] - [ INFO ]  Read 1079105 bytes from map-output for attempt_local1627740637_0001_m_000000_0
2020-11-19 15:26:56  [ localfetcher#1:71079 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 1079105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1079105
2020-11-19 15:26:56  [ EventFetcher for fetching Map Completion Events:71080 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:26:56  [ pool-6-thread-1:71081 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:26:56  [ pool-6-thread-1:71081 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:26:56  [ pool-6-thread-1:71085 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:26:56  [ pool-6-thread-1:71085 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 15:26:56  [ pool-6-thread-1:71115 ] - [ INFO ]  Merged 1 segments, 1079105 bytes to disk to satisfy reduce memory limit
2020-11-19 15:26:56  [ pool-6-thread-1:71116 ] - [ INFO ]  Merging 1 files, 1079109 bytes from disk
2020-11-19 15:26:56  [ pool-6-thread-1:71116 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:26:56  [ pool-6-thread-1:71116 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:26:56  [ pool-6-thread-1:71117 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 15:26:56  [ pool-6-thread-1:71117 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:26:56  [ pool-6-thread-1:71143 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:26:56  [ main:71257 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:26:59  [ pool-6-thread-1:74360 ] - [ INFO ]  Task:attempt_local1627740637_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:26:59  [ pool-6-thread-1:74383 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:26:59  [ pool-6-thread-1:74384 ] - [ INFO ]  Task attempt_local1627740637_0001_r_000000_0 is allowed to commit now
2020-11-19 15:26:59  [ pool-6-thread-1:74468 ] - [ INFO ]  Saved output of task 'attempt_local1627740637_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1627740637_0001_r_000000
2020-11-19 15:26:59  [ pool-6-thread-1:74469 ] - [ INFO ]  reduce > reduce
2020-11-19 15:26:59  [ pool-6-thread-1:74469 ] - [ INFO ]  Task 'attempt_local1627740637_0001_r_000000_0' done.
2020-11-19 15:26:59  [ pool-6-thread-1:74469 ] - [ INFO ]  Finishing task: attempt_local1627740637_0001_r_000000_0
2020-11-19 15:26:59  [ Thread-18:74469 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:27:00  [ main:75268 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:27:01  [ main:76273 ] - [ INFO ]  Job job_local1627740637_0001 completed successfully
2020-11-19 15:27:01  [ main:76283 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2158582
		FILE: Number of bytes written=3807199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=892913
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=1079109
		Input split bytes=112
		Combine input records=0
		Combine output records=0
		Reduce input groups=943
		Reduce shuffle bytes=1079109
		Reduce input records=90570
		Reduce output records=943
		Spilled Records=181140
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=666894336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=892913
2020-11-19 15:27:27  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:27:27  [ main:647 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:27:27  [ main:647 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:27:28  [ main:839 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:27:28  [ main:844 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:27:28  [ main:940 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:27:28  [ main:1028 ] - [ INFO ]  number of splits:1
2020-11-19 15:27:28  [ main:1094 ] - [ INFO ]  Submitting tokens for job: job_local261066269_0001
2020-11-19 15:27:28  [ main:1187 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:27:28  [ main:1188 ] - [ INFO ]  Running job: job_local261066269_0001
2020-11-19 15:27:28  [ Thread-18:1188 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:27:28  [ Thread-18:1191 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:27:28  [ Thread-18:1193 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:27:28  [ Thread-18:1301 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1302 ] - [ INFO ]  Starting task: attempt_local261066269_0001_m_000000_0
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1320 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1323 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:27:28  [ LocalJobRunner Map Task Executor #0:1377 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:27:29  [ main:2190 ] - [ INFO ]  Job job_local261066269_0001 running in uber mode : false
2020-11-19 15:27:29  [ main:2191 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:27:34  [ communication thread:7332 ] - [ INFO ]  map > map
2020-11-19 15:27:35  [ main:8208 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 15:27:37  [ communication thread:10337 ] - [ INFO ]  map > map
2020-11-19 15:27:38  [ main:11217 ] - [ INFO ]   map 44% reduce 0%
2020-11-19 15:27:40  [ communication thread:13341 ] - [ INFO ]  map > map
2020-11-19 15:27:41  [ main:14230 ] - [ INFO ]   map 59% reduce 0%
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:14924 ] - [ INFO ]  map > map
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:14926 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:14926 ] - [ INFO ]  Spilling map output
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:14926 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:14926 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:15011 ] - [ INFO ]  Finished spill 0
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:15013 ] - [ INFO ]  Task:attempt_local261066269_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:15086 ] - [ INFO ]  map
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:15086 ] - [ INFO ]  Task 'attempt_local261066269_0001_m_000000_0' done.
2020-11-19 15:27:42  [ LocalJobRunner Map Task Executor #0:15086 ] - [ INFO ]  Finishing task: attempt_local261066269_0001_m_000000_0
2020-11-19 15:27:42  [ Thread-18:15086 ] - [ INFO ]  map task executor complete.
2020-11-19 15:27:42  [ Thread-18:15089 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:27:42  [ pool-6-thread-1:15089 ] - [ INFO ]  Starting task: attempt_local261066269_0001_r_000000_0
2020-11-19 15:27:42  [ pool-6-thread-1:15094 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:27:42  [ pool-6-thread-1:15095 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:27:42  [ pool-6-thread-1:15095 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:27:42  [ pool-6-thread-1:15097 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@481923d9
2020-11-19 15:27:42  [ pool-6-thread-1:15107 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:27:42  [ EventFetcher for fetching Map Completion Events:15109 ] - [ INFO ]  attempt_local261066269_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:27:42  [ localfetcher#1:15134 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local261066269_0001_m_000000_0 decomp: 1079105 len: 1079109 to MEMORY
2020-11-19 15:27:42  [ localfetcher#1:15138 ] - [ INFO ]  Read 1079105 bytes from map-output for attempt_local261066269_0001_m_000000_0
2020-11-19 15:27:42  [ localfetcher#1:15139 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 1079105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1079105
2020-11-19 15:27:42  [ EventFetcher for fetching Map Completion Events:15140 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:27:42  [ pool-6-thread-1:15141 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:27:42  [ pool-6-thread-1:15141 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:27:42  [ pool-6-thread-1:15146 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:27:42  [ pool-6-thread-1:15146 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 15:27:42  [ pool-6-thread-1:15184 ] - [ INFO ]  Merged 1 segments, 1079105 bytes to disk to satisfy reduce memory limit
2020-11-19 15:27:42  [ pool-6-thread-1:15184 ] - [ INFO ]  Merging 1 files, 1079109 bytes from disk
2020-11-19 15:27:42  [ pool-6-thread-1:15185 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:27:42  [ pool-6-thread-1:15185 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:27:42  [ pool-6-thread-1:15185 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1079099 bytes
2020-11-19 15:27:42  [ pool-6-thread-1:15185 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:27:42  [ main:15234 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:27:42  [ pool-6-thread-1:15274 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:27:48  [ communication thread:21100 ] - [ INFO ]  reduce > reduce
2020-11-19 15:27:48  [ main:21251 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:27:48  [ pool-6-thread-1:21728 ] - [ INFO ]  Task:attempt_local261066269_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:27:48  [ pool-6-thread-1:21761 ] - [ INFO ]  reduce > reduce
2020-11-19 15:27:48  [ pool-6-thread-1:21762 ] - [ INFO ]  Task attempt_local261066269_0001_r_000000_0 is allowed to commit now
2020-11-19 15:27:49  [ pool-6-thread-1:21817 ] - [ INFO ]  Saved output of task 'attempt_local261066269_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local261066269_0001_r_000000
2020-11-19 15:27:49  [ pool-6-thread-1:21818 ] - [ INFO ]  reduce > reduce
2020-11-19 15:27:49  [ pool-6-thread-1:21818 ] - [ INFO ]  Task 'attempt_local261066269_0001_r_000000_0' done.
2020-11-19 15:27:49  [ pool-6-thread-1:21818 ] - [ INFO ]  Finishing task: attempt_local261066269_0001_r_000000_0
2020-11-19 15:27:49  [ Thread-18:21818 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:27:50  [ main:23258 ] - [ INFO ]  Job job_local261066269_0001 completed successfully
2020-11-19 15:27:50  [ main:23269 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2158582
		FILE: Number of bytes written=3804159
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=892913
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=1079109
		Input split bytes=112
		Combine input records=0
		Combine output records=0
		Reduce input groups=943
		Reduce shuffle bytes=1079109
		Reduce input records=90570
		Reduce output records=943
		Spilled Records=181140
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=665845760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=892913
2020-11-19 15:32:47  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:32:48  [ main:717 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:32:48  [ main:717 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:32:48  [ main:921 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:32:48  [ main:926 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:32:48  [ main:956 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:32:48  [ main:1115 ] - [ INFO ]  number of splits:1
2020-11-19 15:32:48  [ main:1182 ] - [ INFO ]  Submitting tokens for job: job_local495043230_0001
2020-11-19 15:32:48  [ main:1278 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:32:48  [ main:1279 ] - [ INFO ]  Running job: job_local495043230_0001
2020-11-19 15:32:48  [ Thread-18:1280 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:32:48  [ Thread-18:1283 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:32:48  [ Thread-18:1284 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:32:48  [ Thread-18:1354 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:32:48  [ LocalJobRunner Map Task Executor #0:1354 ] - [ INFO ]  Starting task: attempt_local495043230_0001_m_000000_0
2020-11-19 15:32:48  [ LocalJobRunner Map Task Executor #0:1369 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:32:48  [ LocalJobRunner Map Task Executor #0:1373 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:32:48  [ LocalJobRunner Map Task Executor #0:1373 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:32:48  [ LocalJobRunner Map Task Executor #0:1376 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:32:49  [ LocalJobRunner Map Task Executor #0:1433 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:32:49  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:32:49  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:32:49  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:32:49  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:32:49  [ LocalJobRunner Map Task Executor #0:1436 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:32:49  [ main:2282 ] - [ INFO ]  Job job_local495043230_0001 running in uber mode : false
2020-11-19 15:32:49  [ main:2283 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:32:54  [ communication thread:7383 ] - [ INFO ]  map > map
2020-11-19 15:32:55  [ main:8295 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 15:32:57  [ communication thread:10388 ] - [ INFO ]  map > map
2020-11-19 15:32:58  [ main:11309 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:33:00  [ communication thread:13391 ] - [ INFO ]  map > map
2020-11-19 15:33:01  [ main:14317 ] - [ INFO ]   map 59% reduce 0%
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14476 ] - [ INFO ]  map > map
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14478 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14478 ] - [ INFO ]  Spilling map output
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14478 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14478 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14594 ] - [ INFO ]  Finished spill 0
2020-11-19 15:33:02  [ LocalJobRunner Map Task Executor #0:14597 ] - [ INFO ]  Task:attempt_local495043230_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:33:03  [ LocalJobRunner Map Task Executor #0:15671 ] - [ INFO ]  map
2020-11-19 15:33:03  [ LocalJobRunner Map Task Executor #0:15671 ] - [ INFO ]  Task 'attempt_local495043230_0001_m_000000_0' done.
2020-11-19 15:33:03  [ LocalJobRunner Map Task Executor #0:15671 ] - [ INFO ]  Finishing task: attempt_local495043230_0001_m_000000_0
2020-11-19 15:33:03  [ Thread-18:15671 ] - [ INFO ]  map task executor complete.
2020-11-19 15:33:03  [ Thread-18:15674 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:33:03  [ pool-6-thread-1:15674 ] - [ INFO ]  Starting task: attempt_local495043230_0001_r_000000_0
2020-11-19 15:33:03  [ pool-6-thread-1:15679 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:33:03  [ pool-6-thread-1:15679 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:33:03  [ pool-6-thread-1:15679 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:33:03  [ pool-6-thread-1:15681 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46039e33
2020-11-19 15:33:03  [ pool-6-thread-1:15690 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:33:03  [ EventFetcher for fetching Map Completion Events:15692 ] - [ INFO ]  attempt_local495043230_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:33:03  [ localfetcher#1:15711 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local495043230_0001_m_000000_0 decomp: 543870 len: 543874 to MEMORY
2020-11-19 15:33:03  [ localfetcher#1:15715 ] - [ INFO ]  Read 543870 bytes from map-output for attempt_local495043230_0001_m_000000_0
2020-11-19 15:33:03  [ localfetcher#1:15716 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 543870, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->543870
2020-11-19 15:33:03  [ EventFetcher for fetching Map Completion Events:15717 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:33:03  [ pool-6-thread-1:15717 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:33:03  [ pool-6-thread-1:15717 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:33:03  [ pool-6-thread-1:15721 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:33:03  [ pool-6-thread-1:15721 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 543862 bytes
2020-11-19 15:33:03  [ pool-6-thread-1:15727 ] - [ INFO ]  Merged 1 segments, 543870 bytes to disk to satisfy reduce memory limit
2020-11-19 15:33:03  [ pool-6-thread-1:15727 ] - [ INFO ]  Merging 1 files, 543874 bytes from disk
2020-11-19 15:33:03  [ pool-6-thread-1:15728 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:33:03  [ pool-6-thread-1:15728 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:33:03  [ pool-6-thread-1:15728 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 543862 bytes
2020-11-19 15:33:03  [ pool-6-thread-1:15728 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:33:03  [ pool-6-thread-1:15772 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:33:03  [ main:16321 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:33:08  [ pool-6-thread-1:20994 ] - [ INFO ]  Task:attempt_local495043230_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:33:08  [ pool-6-thread-1:21014 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:33:08  [ pool-6-thread-1:21014 ] - [ INFO ]  Task attempt_local495043230_0001_r_000000_0 is allowed to commit now
2020-11-19 15:33:08  [ pool-6-thread-1:21052 ] - [ INFO ]  Saved output of task 'attempt_local495043230_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local495043230_0001_r_000000
2020-11-19 15:33:08  [ pool-6-thread-1:21053 ] - [ INFO ]  reduce > reduce
2020-11-19 15:33:08  [ pool-6-thread-1:21053 ] - [ INFO ]  Task 'attempt_local495043230_0001_r_000000_0' done.
2020-11-19 15:33:08  [ pool-6-thread-1:21053 ] - [ INFO ]  Finishing task: attempt_local495043230_0001_r_000000_0
2020-11-19 15:33:08  [ Thread-18:21054 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:33:08  [ main:21342 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:33:08  [ main:21343 ] - [ INFO ]  Job job_local495043230_0001 completed successfully
2020-11-19 15:33:08  [ main:21354 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088112
		FILE: Number of bytes written=2199466
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=896429
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=543874
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=543874
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=704643072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=896429
2020-11-19 15:35:30  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:35:31  [ main:666 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:35:31  [ main:667 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:35:31  [ main:887 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:35:31  [ main:893 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:35:31  [ main:908 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:35:31  [ main:1003 ] - [ INFO ]  number of splits:1
2020-11-19 15:35:31  [ main:1080 ] - [ INFO ]  Submitting tokens for job: job_local1160680196_0001
2020-11-19 15:35:31  [ main:1188 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:35:31  [ main:1189 ] - [ INFO ]  Running job: job_local1160680196_0001
2020-11-19 15:35:31  [ Thread-18:1189 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:35:31  [ Thread-18:1193 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:35:31  [ Thread-18:1194 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:35:31  [ Thread-18:1234 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1235 ] - [ INFO ]  Starting task: attempt_local1160680196_0001_m_000000_0
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1252 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1256 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1259 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:35:31  [ LocalJobRunner Map Task Executor #0:1320 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:35:32  [ main:2194 ] - [ INFO ]  Job job_local1160680196_0001 running in uber mode : false
2020-11-19 15:35:32  [ main:2196 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:35:37  [ communication thread:7262 ] - [ INFO ]  map > map
2020-11-19 15:35:38  [ main:8214 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:35:40  [ communication thread:10268 ] - [ INFO ]  map > map
2020-11-19 15:35:41  [ main:11219 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:35:43  [ communication thread:13270 ] - [ INFO ]  map > map
2020-11-19 15:35:44  [ LocalJobRunner Map Task Executor #0:13956 ] - [ INFO ]  map > map
2020-11-19 15:35:44  [ LocalJobRunner Map Task Executor #0:13958 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:35:44  [ LocalJobRunner Map Task Executor #0:13958 ] - [ INFO ]  Spilling map output
2020-11-19 15:35:44  [ LocalJobRunner Map Task Executor #0:13958 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:35:44  [ LocalJobRunner Map Task Executor #0:13958 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:35:57  [ main:27379 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:35:57  [ communication thread:27379 ] - [ INFO ]  map > sort
2020-11-19 15:36:46  [ communication thread:76207 ] - [ INFO ]  map > sort
2020-11-19 15:36:46  [ main:76207 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 15:40:13  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:40:14  [ main:584 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:40:14  [ main:584 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:40:14  [ main:780 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:40:14  [ main:786 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:40:14  [ main:799 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:40:14  [ main:874 ] - [ INFO ]  number of splits:1
2020-11-19 15:40:14  [ main:937 ] - [ INFO ]  Submitting tokens for job: job_local1656231743_0001
2020-11-19 15:40:14  [ main:1026 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:40:14  [ main:1027 ] - [ INFO ]  Running job: job_local1656231743_0001
2020-11-19 15:40:14  [ Thread-18:1027 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:40:14  [ Thread-18:1029 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:40:14  [ Thread-18:1031 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:40:15  [ Thread-18:1064 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1064 ] - [ INFO ]  Starting task: attempt_local1656231743_0001_m_000000_0
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1079 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1083 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1083 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:40:15  [ LocalJobRunner Map Task Executor #0:1139 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:40:15  [ main:2031 ] - [ INFO ]  Job job_local1656231743_0001 running in uber mode : false
2020-11-19 15:40:15  [ main:2033 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:40:21  [ communication thread:7089 ] - [ INFO ]  map > map
2020-11-19 15:40:22  [ main:8059 ] - [ INFO ]   map 27% reduce 0%
2020-11-19 15:40:24  [ communication thread:10093 ] - [ INFO ]  map > map
2020-11-19 15:40:25  [ main:11062 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:40:27  [ communication thread:13099 ] - [ INFO ]  map > map
2020-11-19 15:40:27  [ LocalJobRunner Map Task Executor #0:13807 ] - [ INFO ]  map > map
2020-11-19 15:40:27  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:40:27  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  Spilling map output
2020-11-19 15:40:27  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:40:27  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:40:28  [ main:14068 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:40:29  [ LocalJobRunner Map Task Executor #0:15430 ] - [ INFO ]  Finished spill 0
2020-11-19 15:40:29  [ LocalJobRunner Map Task Executor #0:15433 ] - [ INFO ]  Task:attempt_local1656231743_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:40:29  [ LocalJobRunner Map Task Executor #0:15455 ] - [ INFO ]  map
2020-11-19 15:40:29  [ LocalJobRunner Map Task Executor #0:15455 ] - [ INFO ]  Task 'attempt_local1656231743_0001_m_000000_0' done.
2020-11-19 15:40:29  [ LocalJobRunner Map Task Executor #0:15455 ] - [ INFO ]  Finishing task: attempt_local1656231743_0001_m_000000_0
2020-11-19 15:40:29  [ Thread-18:15455 ] - [ INFO ]  map task executor complete.
2020-11-19 15:40:29  [ Thread-18:15458 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:40:29  [ pool-6-thread-1:15458 ] - [ INFO ]  Starting task: attempt_local1656231743_0001_r_000000_0
2020-11-19 15:40:29  [ pool-6-thread-1:15463 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:40:29  [ pool-6-thread-1:15464 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:40:29  [ pool-6-thread-1:15464 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:40:29  [ pool-6-thread-1:15465 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35d566b8
2020-11-19 15:40:29  [ pool-6-thread-1:15474 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:40:29  [ EventFetcher for fetching Map Completion Events:15476 ] - [ INFO ]  attempt_local1656231743_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:40:29  [ localfetcher#1:15502 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1656231743_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:40:29  [ localfetcher#1:15530 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1656231743_0001_m_000000_0
2020-11-19 15:40:29  [ localfetcher#1:15531 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:40:29  [ EventFetcher for fetching Map Completion Events:15532 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:40:29  [ pool-6-thread-1:15532 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:40:29  [ pool-6-thread-1:15533 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:40:29  [ pool-6-thread-1:15537 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:40:29  [ pool-6-thread-1:15537 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:40:29  [ pool-6-thread-1:15568 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:40:29  [ pool-6-thread-1:15568 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:40:29  [ pool-6-thread-1:15569 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:40:29  [ pool-6-thread-1:15569 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:40:29  [ pool-6-thread-1:15569 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:40:29  [ pool-6-thread-1:15569 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:40:29  [ pool-6-thread-1:15590 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:40:29  [ Thread-18:15702 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:40:29  [ Thread-18:15712 ] - [ WARN ]  job_local1656231743_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 5
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:84)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:74)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 15:40:30  [ main:16074 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:40:30  [ main:16075 ] - [ INFO ]  Job job_local1656231743_0001 failed with state FAILED due to: NA
2020-11-19 15:40:30  [ main:16086 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=31034440
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=30748996
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=429391872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 15:40:51  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:40:51  [ main:755 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:40:51  [ main:755 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:40:52  [ main:979 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:40:52  [ main:985 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:40:52  [ main:1001 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:40:52  [ main:1083 ] - [ INFO ]  number of splits:1
2020-11-19 15:40:52  [ main:1155 ] - [ INFO ]  Submitting tokens for job: job_local1463251000_0001
2020-11-19 15:40:52  [ main:1245 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:40:52  [ main:1246 ] - [ INFO ]  Running job: job_local1463251000_0001
2020-11-19 15:40:52  [ Thread-18:1246 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:40:52  [ Thread-18:1250 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:40:52  [ Thread-18:1251 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:40:52  [ Thread-18:1306 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1306 ] - [ INFO ]  Starting task: attempt_local1463251000_0001_m_000000_0
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1321 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1325 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1325 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1328 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1374 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1374 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1374 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1374 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1374 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:40:52  [ LocalJobRunner Map Task Executor #0:1385 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:40:53  [ main:2248 ] - [ INFO ]  Job job_local1463251000_0001 running in uber mode : false
2020-11-19 15:40:53  [ main:2249 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:40:58  [ communication thread:7331 ] - [ INFO ]  map > map
2020-11-19 15:40:59  [ main:8275 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:41:01  [ communication thread:10332 ] - [ INFO ]  map > map
2020-11-19 15:41:02  [ main:11283 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:41:04  [ communication thread:13334 ] - [ INFO ]  map > map
2020-11-19 15:41:05  [ LocalJobRunner Map Task Executor #0:14067 ] - [ INFO ]  map > map
2020-11-19 15:41:05  [ LocalJobRunner Map Task Executor #0:14072 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:41:05  [ LocalJobRunner Map Task Executor #0:14073 ] - [ INFO ]  Spilling map output
2020-11-19 15:41:05  [ LocalJobRunner Map Task Executor #0:14073 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:41:05  [ LocalJobRunner Map Task Executor #0:14073 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:41:09  [ main:18501 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:41:09  [ communication thread:18501 ] - [ INFO ]  map > sort
2020-11-19 15:41:15  [ main:24710 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 15:41:15  [ communication thread:24710 ] - [ INFO ]  map > sort
2020-11-19 15:41:17  [ LocalJobRunner Map Task Executor #0:26334 ] - [ INFO ]  Finished spill 0
2020-11-19 15:41:17  [ LocalJobRunner Map Task Executor #0:26339 ] - [ INFO ]  Task:attempt_local1463251000_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:41:17  [ LocalJobRunner Map Task Executor #0:26357 ] - [ INFO ]  map
2020-11-19 15:41:17  [ LocalJobRunner Map Task Executor #0:26357 ] - [ INFO ]  Task 'attempt_local1463251000_0001_m_000000_0' done.
2020-11-19 15:41:17  [ LocalJobRunner Map Task Executor #0:26357 ] - [ INFO ]  Finishing task: attempt_local1463251000_0001_m_000000_0
2020-11-19 15:41:17  [ Thread-18:26357 ] - [ INFO ]  map task executor complete.
2020-11-19 15:41:17  [ Thread-18:26359 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:41:17  [ pool-6-thread-1:26359 ] - [ INFO ]  Starting task: attempt_local1463251000_0001_r_000000_0
2020-11-19 15:41:17  [ pool-6-thread-1:26363 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:41:17  [ pool-6-thread-1:26364 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:41:17  [ pool-6-thread-1:26364 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:41:17  [ pool-6-thread-1:26365 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6636c10
2020-11-19 15:41:17  [ pool-6-thread-1:26374 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:41:17  [ EventFetcher for fetching Map Completion Events:26375 ] - [ INFO ]  attempt_local1463251000_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:41:17  [ localfetcher#1:26395 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1463251000_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:41:17  [ localfetcher#1:26419 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1463251000_0001_m_000000_0
2020-11-19 15:41:17  [ localfetcher#1:26420 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:41:17  [ EventFetcher for fetching Map Completion Events:26421 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:41:17  [ pool-6-thread-1:26422 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:41:17  [ pool-6-thread-1:26422 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:41:17  [ pool-6-thread-1:26426 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:41:17  [ pool-6-thread-1:26426 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:41:17  [ pool-6-thread-1:26456 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:41:17  [ pool-6-thread-1:26457 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:41:17  [ pool-6-thread-1:26457 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:41:17  [ pool-6-thread-1:26457 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:41:17  [ pool-6-thread-1:26458 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:41:17  [ pool-6-thread-1:26458 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:41:17  [ pool-6-thread-1:26482 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:41:40  [ main:49373 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:41:43  [ Thread-18:51968 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:41:43  [ Thread-18:52021 ] - [ WARN ]  job_local1463251000_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 5
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:84)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:74)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 15:41:43  [ communication thread:52379 ] - [ INFO ]  reduce > reduce
2020-11-19 15:41:43  [ main:52630 ] - [ INFO ]   map 100% reduce 67%
2020-11-19 15:41:43  [ main:52631 ] - [ INFO ]  Job job_local1463251000_0001 failed with state FAILED due to: NA
2020-11-19 15:41:43  [ main:52644 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=30757552
		FILE: Number of bytes written=92817876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=1207
		HDFS: Number of read operations=20
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=2
		Reduce shuffle bytes=30748996
		Reduce input records=2
		Reduce output records=1
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=828375040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=1207
2020-11-19 15:42:17  [ main:1 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:42:18  [ main:578 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:42:18  [ main:579 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:42:18  [ main:784 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:42:18  [ main:790 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:42:18  [ main:802 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:42:18  [ main:869 ] - [ INFO ]  number of splits:1
2020-11-19 15:42:18  [ main:933 ] - [ INFO ]  Submitting tokens for job: job_local1780352442_0001
2020-11-19 15:42:19  [ main:1032 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:42:19  [ main:1032 ] - [ INFO ]  Running job: job_local1780352442_0001
2020-11-19 15:42:19  [ Thread-18:1032 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:42:19  [ Thread-18:1036 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:42:19  [ Thread-18:1037 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:42:19  [ Thread-18:1077 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1077 ] - [ INFO ]  Starting task: attempt_local1780352442_0001_m_000000_0
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1094 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1098 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1098 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1101 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1153 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1153 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1153 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1153 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1153 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:42:19  [ LocalJobRunner Map Task Executor #0:1156 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:42:20  [ main:2037 ] - [ INFO ]  Job job_local1780352442_0001 running in uber mode : false
2020-11-19 15:42:20  [ main:2038 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:42:25  [ communication thread:7103 ] - [ INFO ]  map > map
2020-11-19 15:42:26  [ main:8056 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:42:28  [ communication thread:10106 ] - [ INFO ]  map > map
2020-11-19 15:42:29  [ main:11063 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:42:31  [ communication thread:13109 ] - [ INFO ]  map > map
2020-11-19 15:42:31  [ LocalJobRunner Map Task Executor #0:13801 ] - [ INFO ]  map > map
2020-11-19 15:42:31  [ LocalJobRunner Map Task Executor #0:13804 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:42:31  [ LocalJobRunner Map Task Executor #0:13804 ] - [ INFO ]  Spilling map output
2020-11-19 15:42:31  [ LocalJobRunner Map Task Executor #0:13804 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:42:31  [ LocalJobRunner Map Task Executor #0:13804 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:42:32  [ main:14073 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:42:33  [ LocalJobRunner Map Task Executor #0:15388 ] - [ INFO ]  Finished spill 0
2020-11-19 15:42:33  [ LocalJobRunner Map Task Executor #0:15392 ] - [ INFO ]  Task:attempt_local1780352442_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:42:33  [ LocalJobRunner Map Task Executor #0:15411 ] - [ INFO ]  map
2020-11-19 15:42:33  [ LocalJobRunner Map Task Executor #0:15412 ] - [ INFO ]  Task 'attempt_local1780352442_0001_m_000000_0' done.
2020-11-19 15:42:33  [ LocalJobRunner Map Task Executor #0:15412 ] - [ INFO ]  Finishing task: attempt_local1780352442_0001_m_000000_0
2020-11-19 15:42:33  [ Thread-18:15412 ] - [ INFO ]  map task executor complete.
2020-11-19 15:42:33  [ Thread-18:15414 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:42:33  [ pool-6-thread-1:15415 ] - [ INFO ]  Starting task: attempt_local1780352442_0001_r_000000_0
2020-11-19 15:42:33  [ pool-6-thread-1:15420 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:42:33  [ pool-6-thread-1:15420 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:42:33  [ pool-6-thread-1:15420 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:42:33  [ pool-6-thread-1:15422 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c67e61
2020-11-19 15:42:33  [ pool-6-thread-1:15431 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:42:33  [ EventFetcher for fetching Map Completion Events:15433 ] - [ INFO ]  attempt_local1780352442_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:42:33  [ localfetcher#1:15456 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1780352442_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:42:33  [ localfetcher#1:15483 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1780352442_0001_m_000000_0
2020-11-19 15:42:33  [ localfetcher#1:15484 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:42:33  [ EventFetcher for fetching Map Completion Events:15485 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:42:33  [ pool-6-thread-1:15485 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:42:33  [ pool-6-thread-1:15485 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:42:33  [ pool-6-thread-1:15489 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:42:33  [ pool-6-thread-1:15489 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:42:33  [ pool-6-thread-1:15520 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:42:33  [ pool-6-thread-1:15521 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:42:33  [ pool-6-thread-1:15521 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:42:33  [ pool-6-thread-1:15521 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:42:33  [ pool-6-thread-1:15522 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:42:33  [ pool-6-thread-1:15522 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:42:33  [ pool-6-thread-1:15546 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:42:33  [ Thread-18:15643 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:42:33  [ Thread-18:15656 ] - [ WARN ]  job_local1780352442_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 5
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:83)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:74)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 15:42:34  [ main:16076 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:42:34  [ main:16078 ] - [ INFO ]  Job job_local1780352442_0001 failed with state FAILED due to: NA
2020-11-19 15:42:34  [ main:16089 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=31034440
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=30748996
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=422051840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 15:42:56  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:42:57  [ main:556 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:42:57  [ main:557 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:42:57  [ main:761 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:42:57  [ main:766 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:42:57  [ main:780 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:42:57  [ main:846 ] - [ INFO ]  number of splits:1
2020-11-19 15:42:57  [ main:906 ] - [ INFO ]  Submitting tokens for job: job_local1294316235_0001
2020-11-19 15:42:57  [ main:994 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:42:57  [ main:995 ] - [ INFO ]  Running job: job_local1294316235_0001
2020-11-19 15:42:57  [ Thread-18:995 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:42:57  [ Thread-18:998 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:42:57  [ Thread-18:1000 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:42:57  [ Thread-18:1041 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1042 ] - [ INFO ]  Starting task: attempt_local1294316235_0001_m_000000_0
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1057 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1061 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1062 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1064 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1115 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1115 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1115 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1115 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1115 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:42:57  [ LocalJobRunner Map Task Executor #0:1117 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:42:58  [ main:1998 ] - [ INFO ]  Job job_local1294316235_0001 running in uber mode : false
2020-11-19 15:42:58  [ main:1999 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:43:03  [ communication thread:7071 ] - [ INFO ]  map > map
2020-11-19 15:43:04  [ main:8008 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:43:06  [ communication thread:10076 ] - [ INFO ]  map > map
2020-11-19 15:43:07  [ main:11014 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:43:09  [ communication thread:13079 ] - [ INFO ]  map > map
2020-11-19 15:43:10  [ LocalJobRunner Map Task Executor #0:13807 ] - [ INFO ]  map > map
2020-11-19 15:43:10  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:43:10  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  Spilling map output
2020-11-19 15:43:10  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:43:10  [ LocalJobRunner Map Task Executor #0:13809 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:43:10  [ main:14019 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:43:12  [ LocalJobRunner Map Task Executor #0:15364 ] - [ INFO ]  Finished spill 0
2020-11-19 15:43:12  [ LocalJobRunner Map Task Executor #0:15369 ] - [ INFO ]  Task:attempt_local1294316235_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:43:12  [ LocalJobRunner Map Task Executor #0:15407 ] - [ INFO ]  map
2020-11-19 15:43:12  [ LocalJobRunner Map Task Executor #0:15407 ] - [ INFO ]  Task 'attempt_local1294316235_0001_m_000000_0' done.
2020-11-19 15:43:12  [ LocalJobRunner Map Task Executor #0:15407 ] - [ INFO ]  Finishing task: attempt_local1294316235_0001_m_000000_0
2020-11-19 15:43:12  [ Thread-18:15407 ] - [ INFO ]  map task executor complete.
2020-11-19 15:43:12  [ Thread-18:15409 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:43:12  [ pool-6-thread-1:15410 ] - [ INFO ]  Starting task: attempt_local1294316235_0001_r_000000_0
2020-11-19 15:43:12  [ pool-6-thread-1:15415 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:43:12  [ pool-6-thread-1:15415 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:43:12  [ pool-6-thread-1:15415 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:43:12  [ pool-6-thread-1:15417 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fa81a42
2020-11-19 15:43:12  [ pool-6-thread-1:15426 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:43:12  [ EventFetcher for fetching Map Completion Events:15428 ] - [ INFO ]  attempt_local1294316235_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:43:12  [ localfetcher#1:15452 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1294316235_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:43:12  [ localfetcher#1:15478 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1294316235_0001_m_000000_0
2020-11-19 15:43:12  [ localfetcher#1:15479 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:43:12  [ EventFetcher for fetching Map Completion Events:15480 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:43:12  [ pool-6-thread-1:15480 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:43:12  [ pool-6-thread-1:15480 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:43:12  [ pool-6-thread-1:15484 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:43:12  [ pool-6-thread-1:15484 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:43:12  [ pool-6-thread-1:15516 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:43:12  [ pool-6-thread-1:15516 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:43:12  [ pool-6-thread-1:15517 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:43:12  [ pool-6-thread-1:15517 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:43:12  [ pool-6-thread-1:15517 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:43:12  [ pool-6-thread-1:15517 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:43:12  [ pool-6-thread-1:15547 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:43:12  [ Thread-18:15659 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:43:12  [ Thread-18:15669 ] - [ WARN ]  job_local1294316235_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 5
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:84)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:74)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 15:43:12  [ main:16024 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:43:12  [ main:16026 ] - [ INFO ]  Job job_local1294316235_0001 failed with state FAILED due to: NA
2020-11-19 15:43:12  [ main:16037 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=31034440
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=30748996
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=432013312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 15:43:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:43:54  [ main:569 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:43:54  [ main:570 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:43:54  [ main:774 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:43:54  [ main:780 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:43:54  [ main:796 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:43:54  [ main:869 ] - [ INFO ]  number of splits:1
2020-11-19 15:43:54  [ main:928 ] - [ INFO ]  Submitting tokens for job: job_local2070784846_0001
2020-11-19 15:43:54  [ main:1008 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:43:54  [ main:1009 ] - [ INFO ]  Running job: job_local2070784846_0001
2020-11-19 15:43:54  [ Thread-18:1009 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:43:54  [ Thread-18:1012 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:43:54  [ Thread-18:1013 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:43:54  [ Thread-18:1059 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1059 ] - [ INFO ]  Starting task: attempt_local2070784846_0001_m_000000_0
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1075 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1079 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1080 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1082 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:43:54  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:43:55  [ main:2014 ] - [ INFO ]  Job job_local2070784846_0001 running in uber mode : false
2020-11-19 15:43:55  [ main:2016 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:44:00  [ communication thread:7089 ] - [ INFO ]  map > map
2020-11-19 15:44:01  [ main:8032 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:44:03  [ communication thread:10094 ] - [ INFO ]  map > map
2020-11-19 15:44:04  [ main:11040 ] - [ INFO ]   map 44% reduce 0%
2020-11-19 15:44:06  [ communication thread:13098 ] - [ INFO ]  map > map
2020-11-19 15:44:07  [ main:14052 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:44:07  [ LocalJobRunner Map Task Executor #0:14122 ] - [ INFO ]  map > map
2020-11-19 15:44:07  [ LocalJobRunner Map Task Executor #0:14124 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:44:07  [ LocalJobRunner Map Task Executor #0:14124 ] - [ INFO ]  Spilling map output
2020-11-19 15:44:07  [ LocalJobRunner Map Task Executor #0:14124 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:44:07  [ LocalJobRunner Map Task Executor #0:14124 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:44:09  [ LocalJobRunner Map Task Executor #0:15665 ] - [ INFO ]  Finished spill 0
2020-11-19 15:44:09  [ LocalJobRunner Map Task Executor #0:15670 ] - [ INFO ]  Task:attempt_local2070784846_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:44:09  [ LocalJobRunner Map Task Executor #0:15686 ] - [ INFO ]  map
2020-11-19 15:44:09  [ LocalJobRunner Map Task Executor #0:15686 ] - [ INFO ]  Task 'attempt_local2070784846_0001_m_000000_0' done.
2020-11-19 15:44:09  [ LocalJobRunner Map Task Executor #0:15687 ] - [ INFO ]  Finishing task: attempt_local2070784846_0001_m_000000_0
2020-11-19 15:44:09  [ Thread-18:15687 ] - [ INFO ]  map task executor complete.
2020-11-19 15:44:09  [ Thread-18:15689 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:44:09  [ pool-6-thread-1:15689 ] - [ INFO ]  Starting task: attempt_local2070784846_0001_r_000000_0
2020-11-19 15:44:09  [ pool-6-thread-1:15695 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:44:09  [ pool-6-thread-1:15695 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:44:09  [ pool-6-thread-1:15695 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:44:09  [ pool-6-thread-1:15697 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19ee9645
2020-11-19 15:44:09  [ pool-6-thread-1:15706 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:44:09  [ EventFetcher for fetching Map Completion Events:15707 ] - [ INFO ]  attempt_local2070784846_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:44:09  [ localfetcher#1:15730 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2070784846_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:44:09  [ localfetcher#1:15757 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local2070784846_0001_m_000000_0
2020-11-19 15:44:09  [ localfetcher#1:15758 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:44:09  [ EventFetcher for fetching Map Completion Events:15759 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:44:09  [ pool-6-thread-1:15759 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:44:09  [ pool-6-thread-1:15760 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:44:09  [ pool-6-thread-1:15763 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:44:09  [ pool-6-thread-1:15764 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:44:09  [ pool-6-thread-1:15794 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:44:09  [ pool-6-thread-1:15795 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:44:09  [ pool-6-thread-1:15795 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:44:09  [ pool-6-thread-1:15795 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:44:09  [ pool-6-thread-1:15795 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:44:09  [ pool-6-thread-1:15796 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:44:09  [ pool-6-thread-1:15816 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:44:09  [ Thread-18:15928 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:44:09  [ Thread-18:15939 ] - [ WARN ]  job_local2070784846_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 5
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:84)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:74)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 15:44:09  [ main:16057 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:44:09  [ main:16059 ] - [ INFO ]  Job job_local2070784846_0001 failed with state FAILED due to: NA
2020-11-19 15:44:09  [ main:16069 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=31034440
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=30748996
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=425721856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 15:45:37  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:45:38  [ main:545 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:45:38  [ main:546 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:45:38  [ main:757 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:45:38  [ main:762 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:45:38  [ main:776 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:45:38  [ main:845 ] - [ INFO ]  number of splits:1
2020-11-19 15:45:38  [ main:905 ] - [ INFO ]  Submitting tokens for job: job_local710596491_0001
2020-11-19 15:45:38  [ main:991 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:45:38  [ main:992 ] - [ INFO ]  Running job: job_local710596491_0001
2020-11-19 15:45:38  [ Thread-18:992 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:45:38  [ Thread-18:995 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:45:38  [ Thread-18:996 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:45:38  [ Thread-18:1034 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1034 ] - [ INFO ]  Starting task: attempt_local710596491_0001_m_000000_0
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1049 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1053 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1054 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1056 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:45:38  [ LocalJobRunner Map Task Executor #0:1110 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:45:39  [ main:1997 ] - [ INFO ]  Job job_local710596491_0001 running in uber mode : false
2020-11-19 15:45:39  [ main:1998 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:45:44  [ communication thread:7063 ] - [ INFO ]  map > map
2020-11-19 15:45:45  [ main:8011 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 15:45:47  [ communication thread:10068 ] - [ INFO ]  map > map
2020-11-19 15:45:48  [ main:11019 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:45:50  [ communication thread:13070 ] - [ INFO ]  map > map
2020-11-19 15:45:51  [ LocalJobRunner Map Task Executor #0:13715 ] - [ INFO ]  map > map
2020-11-19 15:45:51  [ LocalJobRunner Map Task Executor #0:13717 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:45:51  [ LocalJobRunner Map Task Executor #0:13717 ] - [ INFO ]  Spilling map output
2020-11-19 15:45:51  [ LocalJobRunner Map Task Executor #0:13717 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:45:51  [ LocalJobRunner Map Task Executor #0:13717 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:45:51  [ main:14026 ] - [ INFO ]   map 63% reduce 0%
2020-11-19 15:45:53  [ LocalJobRunner Map Task Executor #0:15232 ] - [ INFO ]  Finished spill 0
2020-11-19 15:45:53  [ LocalJobRunner Map Task Executor #0:15238 ] - [ INFO ]  Task:attempt_local710596491_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:45:53  [ LocalJobRunner Map Task Executor #0:15255 ] - [ INFO ]  map
2020-11-19 15:45:53  [ LocalJobRunner Map Task Executor #0:15255 ] - [ INFO ]  Task 'attempt_local710596491_0001_m_000000_0' done.
2020-11-19 15:45:53  [ LocalJobRunner Map Task Executor #0:15255 ] - [ INFO ]  Finishing task: attempt_local710596491_0001_m_000000_0
2020-11-19 15:45:53  [ Thread-18:15255 ] - [ INFO ]  map task executor complete.
2020-11-19 15:45:53  [ Thread-18:15258 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:45:53  [ pool-6-thread-1:15258 ] - [ INFO ]  Starting task: attempt_local710596491_0001_r_000000_0
2020-11-19 15:45:53  [ pool-6-thread-1:15263 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:45:53  [ pool-6-thread-1:15263 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:45:53  [ pool-6-thread-1:15263 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:45:53  [ pool-6-thread-1:15265 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5935768d
2020-11-19 15:45:53  [ pool-6-thread-1:15273 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:45:53  [ EventFetcher for fetching Map Completion Events:15274 ] - [ INFO ]  attempt_local710596491_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:45:53  [ localfetcher#1:15295 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local710596491_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:45:53  [ localfetcher#1:15323 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local710596491_0001_m_000000_0
2020-11-19 15:45:53  [ localfetcher#1:15324 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:45:53  [ EventFetcher for fetching Map Completion Events:15325 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:45:53  [ pool-6-thread-1:15325 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:45:53  [ pool-6-thread-1:15325 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:45:53  [ pool-6-thread-1:15330 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:45:53  [ pool-6-thread-1:15330 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:45:53  [ pool-6-thread-1:15362 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:45:53  [ pool-6-thread-1:15362 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:45:53  [ pool-6-thread-1:15363 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:45:53  [ pool-6-thread-1:15363 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:45:53  [ pool-6-thread-1:15363 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:45:53  [ pool-6-thread-1:15363 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:45:53  [ pool-6-thread-1:15383 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:45:53  [ Thread-18:15494 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:45:53  [ Thread-18:15504 ] - [ WARN ]  job_local710596491_0001
java.lang.Exception: java.lang.IllegalStateException: Duplicate key 5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IllegalStateException: Duplicate key 5
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1254)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:86)
	at com.satan.hadoop.cf.userCF.UserItemScoreMatrixMapReduceJob$UserItemScoreMatrixReducer.reduce(UserItemScoreMatrixMapReduceJob.java:74)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 15:45:53  [ main:16036 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:45:53  [ main:16036 ] - [ INFO ]  Job job_local710596491_0001 failed with state FAILED due to: NA
2020-11-19 15:45:53  [ main:16048 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166
		FILE: Number of bytes written=31032918
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1796165
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=0
		Reduce shuffle bytes=30748996
		Reduce input records=0
		Reduce output records=0
		Spilled Records=943
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=420478976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=0
2020-11-19 15:47:44  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:47:44  [ main:563 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:47:44  [ main:564 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:47:45  [ main:769 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:47:45  [ main:773 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:47:45  [ main:787 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:47:45  [ main:869 ] - [ INFO ]  number of splits:1
2020-11-19 15:47:45  [ main:939 ] - [ INFO ]  Submitting tokens for job: job_local1429132830_0001
2020-11-19 15:47:45  [ main:1038 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:47:45  [ main:1039 ] - [ INFO ]  Running job: job_local1429132830_0001
2020-11-19 15:47:45  [ Thread-18:1039 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:47:45  [ Thread-18:1042 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:47:45  [ Thread-18:1043 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:47:45  [ Thread-18:1084 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1085 ] - [ INFO ]  Starting task: attempt_local1429132830_0001_m_000000_0
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1100 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1104 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1104 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1106 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:47:45  [ LocalJobRunner Map Task Executor #0:1160 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:47:46  [ main:2041 ] - [ INFO ]  Job job_local1429132830_0001 running in uber mode : false
2020-11-19 15:47:46  [ main:2043 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:47:51  [ communication thread:7113 ] - [ INFO ]  map > map
2020-11-19 15:47:52  [ main:8056 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 15:47:54  [ communication thread:10117 ] - [ INFO ]  map > map
2020-11-19 15:47:55  [ main:11067 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 15:47:57  [ communication thread:13122 ] - [ INFO ]  map > map
2020-11-19 15:47:58  [ LocalJobRunner Map Task Executor #0:13816 ] - [ INFO ]  map > map
2020-11-19 15:47:58  [ LocalJobRunner Map Task Executor #0:13818 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:47:58  [ LocalJobRunner Map Task Executor #0:13818 ] - [ INFO ]  Spilling map output
2020-11-19 15:47:58  [ LocalJobRunner Map Task Executor #0:13818 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 15:47:58  [ LocalJobRunner Map Task Executor #0:13818 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 15:47:58  [ main:14073 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 15:47:59  [ LocalJobRunner Map Task Executor #0:15370 ] - [ INFO ]  Finished spill 0
2020-11-19 15:47:59  [ LocalJobRunner Map Task Executor #0:15374 ] - [ INFO ]  Task:attempt_local1429132830_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:47:59  [ LocalJobRunner Map Task Executor #0:15388 ] - [ INFO ]  map
2020-11-19 15:47:59  [ LocalJobRunner Map Task Executor #0:15389 ] - [ INFO ]  Task 'attempt_local1429132830_0001_m_000000_0' done.
2020-11-19 15:47:59  [ LocalJobRunner Map Task Executor #0:15389 ] - [ INFO ]  Finishing task: attempt_local1429132830_0001_m_000000_0
2020-11-19 15:47:59  [ Thread-18:15389 ] - [ INFO ]  map task executor complete.
2020-11-19 15:47:59  [ Thread-18:15391 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:47:59  [ pool-6-thread-1:15391 ] - [ INFO ]  Starting task: attempt_local1429132830_0001_r_000000_0
2020-11-19 15:47:59  [ pool-6-thread-1:15396 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:47:59  [ pool-6-thread-1:15397 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:47:59  [ pool-6-thread-1:15397 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:47:59  [ pool-6-thread-1:15398 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67786bcb
2020-11-19 15:47:59  [ pool-6-thread-1:15407 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:47:59  [ EventFetcher for fetching Map Completion Events:15409 ] - [ INFO ]  attempt_local1429132830_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:47:59  [ localfetcher#1:15433 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1429132830_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 15:47:59  [ localfetcher#1:15458 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1429132830_0001_m_000000_0
2020-11-19 15:47:59  [ localfetcher#1:15459 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 15:47:59  [ EventFetcher for fetching Map Completion Events:15460 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:47:59  [ pool-6-thread-1:15461 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:47:59  [ pool-6-thread-1:15461 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:47:59  [ pool-6-thread-1:15465 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:47:59  [ pool-6-thread-1:15465 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:47:59  [ pool-6-thread-1:15496 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 15:47:59  [ pool-6-thread-1:15496 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 15:47:59  [ pool-6-thread-1:15497 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:47:59  [ pool-6-thread-1:15497 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:47:59  [ pool-6-thread-1:15497 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 15:47:59  [ pool-6-thread-1:15497 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:47:59  [ pool-6-thread-1:15517 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:48:00  [ main:16080 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:48:01  [ pool-6-thread-1:17017 ] - [ INFO ]  Task:attempt_local1429132830_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:48:01  [ pool-6-thread-1:17024 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:48:01  [ pool-6-thread-1:17024 ] - [ INFO ]  Task attempt_local1429132830_0001_r_000000_0 is allowed to commit now
2020-11-19 15:48:01  [ pool-6-thread-1:17048 ] - [ INFO ]  Saved output of task 'attempt_local1429132830_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1429132830_0001_r_000000
2020-11-19 15:48:01  [ pool-6-thread-1:17049 ] - [ INFO ]  reduce > reduce
2020-11-19 15:48:01  [ pool-6-thread-1:17049 ] - [ INFO ]  Task 'attempt_local1429132830_0001_r_000000_0' done.
2020-11-19 15:48:01  [ pool-6-thread-1:17049 ] - [ INFO ]  Finishing task: attempt_local1429132830_0001_r_000000_0
2020-11-19 15:48:01  [ Thread-18:17049 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:48:01  [ main:17081 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:48:02  [ main:18087 ] - [ INFO ]  Job job_local1429132830_0001 completed successfully
2020-11-19 15:48:02  [ main:18099 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61498356
		FILE: Number of bytes written=92817876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=1776501
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=30748996
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=40
		Total committed heap usage (bytes)=1256718336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=1776501
2020-11-19 15:56:35  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 15:56:36  [ main:1247 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 15:56:36  [ main:1248 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 15:56:37  [ main:1731 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:56:37  [ main:1735 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:56:37  [ main:1767 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:56:37  [ main:2128 ] - [ INFO ]  number of splits:1
2020-11-19 15:56:37  [ main:2187 ] - [ INFO ]  Submitting tokens for job: job_local1164361617_0001
2020-11-19 15:56:37  [ main:2275 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:56:37  [ main:2276 ] - [ INFO ]  Running job: job_local1164361617_0001
2020-11-19 15:56:37  [ Thread-18:2276 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:56:37  [ Thread-18:2279 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:37  [ Thread-18:2280 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:56:38  [ Thread-18:2702 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2702 ] - [ INFO ]  Starting task: attempt_local1164361617_0001_m_000000_0
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2719 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2723 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2723 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2725 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2775 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2775 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2775 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2775 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2775 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:56:38  [ LocalJobRunner Map Task Executor #0:2777 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:56:38  [ main:3282 ] - [ INFO ]  Job job_local1164361617_0001 running in uber mode : false
2020-11-19 15:56:38  [ main:3284 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4675 ] - [ INFO ]  
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4677 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4677 ] - [ INFO ]  Spilling map output
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4677 ] - [ INFO ]  bufstart = 0; bufend = 19473; bufvoid = 104857600
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4677 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213096(104852384); length = 1301/6553600
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4686 ] - [ INFO ]  Finished spill 0
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4689 ] - [ INFO ]  Task:attempt_local1164361617_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4848 ] - [ INFO ]  map
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4848 ] - [ INFO ]  Task 'attempt_local1164361617_0001_m_000000_0' done.
2020-11-19 15:56:40  [ LocalJobRunner Map Task Executor #0:4848 ] - [ INFO ]  Finishing task: attempt_local1164361617_0001_m_000000_0
2020-11-19 15:56:40  [ Thread-18:4849 ] - [ INFO ]  map task executor complete.
2020-11-19 15:56:40  [ Thread-18:4851 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:56:40  [ pool-6-thread-1:4851 ] - [ INFO ]  Starting task: attempt_local1164361617_0001_r_000000_0
2020-11-19 15:56:40  [ pool-6-thread-1:4856 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:40  [ pool-6-thread-1:4856 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:40  [ pool-6-thread-1:4856 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:40  [ pool-6-thread-1:4858 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4a4cfece
2020-11-19 15:56:40  [ pool-6-thread-1:4866 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:56:40  [ EventFetcher for fetching Map Completion Events:4868 ] - [ INFO ]  attempt_local1164361617_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:56:40  [ localfetcher#1:4889 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1164361617_0001_m_000000_0 decomp: 20127 len: 20131 to MEMORY
2020-11-19 15:56:40  [ localfetcher#1:4893 ] - [ INFO ]  Read 20127 bytes from map-output for attempt_local1164361617_0001_m_000000_0
2020-11-19 15:56:40  [ localfetcher#1:4894 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20127, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20127
2020-11-19 15:56:40  [ EventFetcher for fetching Map Completion Events:4895 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:56:40  [ pool-6-thread-1:4895 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:40  [ pool-6-thread-1:4895 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:56:40  [ pool-6-thread-1:4899 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:40  [ pool-6-thread-1:4900 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20123 bytes
2020-11-19 15:56:40  [ pool-6-thread-1:4902 ] - [ INFO ]  Merged 1 segments, 20127 bytes to disk to satisfy reduce memory limit
2020-11-19 15:56:40  [ pool-6-thread-1:4902 ] - [ INFO ]  Merging 1 files, 20131 bytes from disk
2020-11-19 15:56:40  [ pool-6-thread-1:4902 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:56:40  [ pool-6-thread-1:4903 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:40  [ pool-6-thread-1:4903 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20123 bytes
2020-11-19 15:56:40  [ pool-6-thread-1:4903 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:40  [ pool-6-thread-1:4924 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 15:56:40  [ pool-6-thread-1:5257 ] - [ INFO ]  Task:attempt_local1164361617_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 15:56:40  [ pool-6-thread-1:5285 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:40  [ pool-6-thread-1:5285 ] - [ INFO ]  Task attempt_local1164361617_0001_r_000000_0 is allowed to commit now
2020-11-19 15:56:40  [ main:5293 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 15:56:41  [ pool-6-thread-1:6173 ] - [ INFO ]  Saved output of task 'attempt_local1164361617_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1164361617_0001_r_000000
2020-11-19 15:56:41  [ pool-6-thread-1:6174 ] - [ INFO ]  reduce > reduce
2020-11-19 15:56:41  [ pool-6-thread-1:6174 ] - [ INFO ]  Task 'attempt_local1164361617_0001_r_000000_0' done.
2020-11-19 15:56:41  [ pool-6-thread-1:6174 ] - [ INFO ]  Finishing task: attempt_local1164361617_0001_r_000000_0
2020-11-19 15:56:41  [ Thread-18:6174 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:56:41  [ main:6298 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:56:44  [ main:9307 ] - [ INFO ]  Job job_local1164361617_0001 completed successfully
2020-11-19 15:56:44  [ main:9317 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=40644
		FILE: Number of bytes written=628583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=186
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=326
		Map output bytes=19473
		Map output materialized bytes=20131
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20131
		Reduce input records=326
		Reduce output records=3
		Spilled Records=652
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=572522496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=186
2020-11-19 15:56:46  [ main:11236 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 15:56:46  [ main:11266 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:56:46  [ main:11272 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:56:47  [ main:11626 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:56:47  [ main:11716 ] - [ INFO ]  number of splits:1
2020-11-19 15:56:47  [ main:11736 ] - [ INFO ]  Submitting tokens for job: job_local2008856568_0002
2020-11-19 15:56:47  [ main:11776 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:56:47  [ main:11776 ] - [ INFO ]  Running job: job_local2008856568_0002
2020-11-19 15:56:47  [ Thread-48:11776 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:56:47  [ Thread-48:11776 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:47  [ Thread-48:11777 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:56:47  [ Thread-48:11918 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11919 ] - [ INFO ]  Starting task: attempt_local2008856568_0002_m_000000_0
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11919 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11921 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11961 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11961 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11961 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11961 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11962 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:56:47  [ LocalJobRunner Map Task Executor #0:11963 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:56:48  [ main:12776 ] - [ INFO ]  Job job_local2008856568_0002 running in uber mode : false
2020-11-19 15:56:48  [ main:12777 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12816 ] - [ INFO ]  
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12816 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12816 ] - [ INFO ]  Spilling map output
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12816 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12816 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12822 ] - [ INFO ]  Finished spill 0
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12823 ] - [ INFO ]  Task:attempt_local2008856568_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12894 ] - [ INFO ]  map
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12894 ] - [ INFO ]  Task 'attempt_local2008856568_0002_m_000000_0' done.
2020-11-19 15:56:48  [ LocalJobRunner Map Task Executor #0:12894 ] - [ INFO ]  Finishing task: attempt_local2008856568_0002_m_000000_0
2020-11-19 15:56:48  [ Thread-48:12894 ] - [ INFO ]  map task executor complete.
2020-11-19 15:56:48  [ Thread-48:12895 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:56:48  [ pool-9-thread-1:12895 ] - [ INFO ]  Starting task: attempt_local2008856568_0002_r_000000_0
2020-11-19 15:56:48  [ pool-9-thread-1:12897 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:48  [ pool-9-thread-1:12897 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:48  [ pool-9-thread-1:12897 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:48  [ pool-9-thread-1:12897 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@550b986e
2020-11-19 15:56:48  [ pool-9-thread-1:12898 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:56:48  [ EventFetcher for fetching Map Completion Events:12898 ] - [ INFO ]  attempt_local2008856568_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:56:48  [ localfetcher#2:12900 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local2008856568_0002_m_000000_0 decomp: 188 len: 192 to MEMORY
2020-11-19 15:56:48  [ localfetcher#2:12900 ] - [ INFO ]  Read 188 bytes from map-output for attempt_local2008856568_0002_m_000000_0
2020-11-19 15:56:48  [ localfetcher#2:12900 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 188, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->188
2020-11-19 15:56:48  [ EventFetcher for fetching Map Completion Events:12901 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:56:48  [ pool-9-thread-1:12901 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:48  [ pool-9-thread-1:12901 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:56:48  [ pool-9-thread-1:12902 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:48  [ pool-9-thread-1:12903 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 184 bytes
2020-11-19 15:56:48  [ pool-9-thread-1:12903 ] - [ INFO ]  Merged 1 segments, 188 bytes to disk to satisfy reduce memory limit
2020-11-19 15:56:48  [ pool-9-thread-1:12904 ] - [ INFO ]  Merging 1 files, 192 bytes from disk
2020-11-19 15:56:48  [ pool-9-thread-1:12904 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:56:48  [ pool-9-thread-1:12904 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:48  [ pool-9-thread-1:12904 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 184 bytes
2020-11-19 15:56:48  [ pool-9-thread-1:12904 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:48  [ pool-9-thread-1:13170 ] - [ INFO ]  Task:attempt_local2008856568_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 15:56:48  [ pool-9-thread-1:13221 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:48  [ pool-9-thread-1:13221 ] - [ INFO ]  Task attempt_local2008856568_0002_r_000000_0 is allowed to commit now
2020-11-19 15:56:48  [ pool-9-thread-1:13271 ] - [ INFO ]  Saved output of task 'attempt_local2008856568_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2008856568_0002_r_000000
2020-11-19 15:56:48  [ pool-9-thread-1:13272 ] - [ INFO ]  reduce > reduce
2020-11-19 15:56:48  [ pool-9-thread-1:13272 ] - [ INFO ]  Task 'attempt_local2008856568_0002_r_000000_0' done.
2020-11-19 15:56:48  [ pool-9-thread-1:13272 ] - [ INFO ]  Finishing task: attempt_local2008856568_0002_r_000000_0
2020-11-19 15:56:48  [ Thread-48:13272 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:56:49  [ main:13780 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:56:49  [ main:13781 ] - [ INFO ]  Job job_local2008856568_0002 completed successfully
2020-11-19 15:56:49  [ main:13785 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=81704
		FILE: Number of bytes written=1220432
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125956
		HDFS: Number of bytes written=926
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=192
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=192
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=783286272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=182
2020-11-19 15:56:51  [ main:16290 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 15:56:51  [ main:16323 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:56:51  [ main:16328 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:56:51  [ main:16335 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:56:51  [ main:16399 ] - [ INFO ]  number of splits:1
2020-11-19 15:56:51  [ main:16420 ] - [ INFO ]  Submitting tokens for job: job_local812332821_0003
2020-11-19 15:56:52  [ main:16461 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:56:52  [ main:16461 ] - [ INFO ]  Running job: job_local812332821_0003
2020-11-19 15:56:52  [ Thread-78:16461 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:56:52  [ Thread-78:16462 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:52  [ Thread-78:16462 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:56:52  [ Thread-78:16488 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16488 ] - [ INFO ]  Starting task: attempt_local812332821_0003_m_000000_0
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16489 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16489 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16489 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16490 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16531 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16531 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16531 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16532 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16532 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16533 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16799 ] - [ INFO ]  
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16799 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16799 ] - [ INFO ]  Spilling map output
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16799 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16799 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16804 ] - [ INFO ]  Finished spill 0
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16805 ] - [ INFO ]  Task:attempt_local812332821_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16830 ] - [ INFO ]  map
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16831 ] - [ INFO ]  Task 'attempt_local812332821_0003_m_000000_0' done.
2020-11-19 15:56:52  [ LocalJobRunner Map Task Executor #0:16831 ] - [ INFO ]  Finishing task: attempt_local812332821_0003_m_000000_0
2020-11-19 15:56:52  [ Thread-78:16831 ] - [ INFO ]  map task executor complete.
2020-11-19 15:56:52  [ Thread-78:16832 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:56:52  [ pool-12-thread-1:16832 ] - [ INFO ]  Starting task: attempt_local812332821_0003_r_000000_0
2020-11-19 15:56:52  [ pool-12-thread-1:16833 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:52  [ pool-12-thread-1:16833 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:52  [ pool-12-thread-1:16833 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:52  [ pool-12-thread-1:16834 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d4c77a1
2020-11-19 15:56:52  [ pool-12-thread-1:16834 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:56:52  [ EventFetcher for fetching Map Completion Events:16834 ] - [ INFO ]  attempt_local812332821_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:56:52  [ localfetcher#3:16836 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local812332821_0003_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 15:56:52  [ localfetcher#3:16836 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local812332821_0003_m_000000_0
2020-11-19 15:56:52  [ localfetcher#3:16836 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 15:56:52  [ EventFetcher for fetching Map Completion Events:16837 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:56:52  [ pool-12-thread-1:16837 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:52  [ pool-12-thread-1:16837 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:56:52  [ pool-12-thread-1:16838 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:52  [ pool-12-thread-1:16838 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 15:56:52  [ pool-12-thread-1:16839 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 15:56:52  [ pool-12-thread-1:16839 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 15:56:52  [ pool-12-thread-1:16839 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:56:52  [ pool-12-thread-1:16839 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:52  [ pool-12-thread-1:16839 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 15:56:52  [ pool-12-thread-1:16839 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:52  [ pool-12-thread-1:17112 ] - [ INFO ]  Task:attempt_local812332821_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 15:56:52  [ pool-12-thread-1:17199 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:52  [ pool-12-thread-1:17200 ] - [ INFO ]  Task attempt_local812332821_0003_r_000000_0 is allowed to commit now
2020-11-19 15:56:52  [ pool-12-thread-1:17424 ] - [ INFO ]  Saved output of task 'attempt_local812332821_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local812332821_0003_r_000000
2020-11-19 15:56:52  [ pool-12-thread-1:17426 ] - [ INFO ]  reduce > reduce
2020-11-19 15:56:52  [ pool-12-thread-1:17426 ] - [ INFO ]  Task 'attempt_local812332821_0003_r_000000_0' done.
2020-11-19 15:56:52  [ pool-12-thread-1:17426 ] - [ INFO ]  Finishing task: attempt_local812332821_0003_r_000000_0
2020-11-19 15:56:52  [ Thread-78:17426 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:56:53  [ main:17465 ] - [ INFO ]  Job job_local812332821_0003 running in uber mode : false
2020-11-19 15:56:53  [ main:17466 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:56:54  [ main:18467 ] - [ INFO ]  Job job_local812332821_0003 completed successfully
2020-11-19 15:56:54  [ main:18471 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=82898
		FILE: Number of bytes written=1789312
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190390
		HDFS: Number of bytes written=2019
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=44
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=994050048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=183
2020-11-19 15:56:56  [ main:20481 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 15:56:56  [ main:20759 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:56:56  [ main:20764 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:56:56  [ main:20888 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:56:56  [ main:20938 ] - [ INFO ]  number of splits:1
2020-11-19 15:56:56  [ main:20956 ] - [ INFO ]  Submitting tokens for job: job_local1764732700_0004
2020-11-19 15:56:56  [ main:20998 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:56:56  [ main:20998 ] - [ INFO ]  Running job: job_local1764732700_0004
2020-11-19 15:56:56  [ Thread-108:20998 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:56:56  [ Thread-108:20999 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:56  [ Thread-108:20999 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:56:56  [ Thread-108:21018 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21018 ] - [ INFO ]  Starting task: attempt_local1764732700_0004_m_000000_0
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21019 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21020 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21020 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21020 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21066 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21066 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21066 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21066 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21066 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:56:56  [ LocalJobRunner Map Task Executor #0:21066 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:56:57  [ main:22002 ] - [ INFO ]  Job job_local1764732700_0004 running in uber mode : false
2020-11-19 15:56:57  [ main:22003 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22046 ] - [ INFO ]  
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22046 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22046 ] - [ INFO ]  Spilling map output
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22046 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22046 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22050 ] - [ INFO ]  Finished spill 0
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22051 ] - [ INFO ]  Task:attempt_local1764732700_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22066 ] - [ INFO ]  map
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22066 ] - [ INFO ]  Task 'attempt_local1764732700_0004_m_000000_0' done.
2020-11-19 15:56:57  [ LocalJobRunner Map Task Executor #0:22066 ] - [ INFO ]  Finishing task: attempt_local1764732700_0004_m_000000_0
2020-11-19 15:56:57  [ Thread-108:22067 ] - [ INFO ]  map task executor complete.
2020-11-19 15:56:57  [ Thread-108:22067 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:56:57  [ pool-15-thread-1:22067 ] - [ INFO ]  Starting task: attempt_local1764732700_0004_r_000000_0
2020-11-19 15:56:57  [ pool-15-thread-1:22068 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:57  [ pool-15-thread-1:22069 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:57  [ pool-15-thread-1:22069 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:57  [ pool-15-thread-1:22069 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44c1de16
2020-11-19 15:56:57  [ pool-15-thread-1:22070 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:56:57  [ EventFetcher for fetching Map Completion Events:22070 ] - [ INFO ]  attempt_local1764732700_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:56:57  [ localfetcher#4:22071 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1764732700_0004_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 15:56:57  [ localfetcher#4:22071 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1764732700_0004_m_000000_0
2020-11-19 15:56:57  [ localfetcher#4:22071 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 15:56:57  [ EventFetcher for fetching Map Completion Events:22072 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:56:57  [ pool-15-thread-1:22072 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:57  [ pool-15-thread-1:22072 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:56:57  [ pool-15-thread-1:22073 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:57  [ pool-15-thread-1:22073 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 15:56:57  [ pool-15-thread-1:22073 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 15:56:57  [ pool-15-thread-1:22074 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 15:56:57  [ pool-15-thread-1:22074 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:56:57  [ pool-15-thread-1:22074 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:57  [ pool-15-thread-1:22074 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 15:56:57  [ pool-15-thread-1:22074 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:58  [ pool-15-thread-1:22523 ] - [ INFO ]  Task:attempt_local1764732700_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 15:56:58  [ pool-15-thread-1:22562 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:58  [ pool-15-thread-1:22562 ] - [ INFO ]  Task attempt_local1764732700_0004_r_000000_0 is allowed to commit now
2020-11-19 15:56:58  [ pool-15-thread-1:22619 ] - [ INFO ]  Saved output of task 'attempt_local1764732700_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1764732700_0004_r_000000
2020-11-19 15:56:58  [ pool-15-thread-1:22620 ] - [ INFO ]  reduce > reduce
2020-11-19 15:56:58  [ pool-15-thread-1:22620 ] - [ INFO ]  Task 'attempt_local1764732700_0004_r_000000_0' done.
2020-11-19 15:56:58  [ pool-15-thread-1:22620 ] - [ INFO ]  Finishing task: attempt_local1764732700_0004_r_000000_0
2020-11-19 15:56:58  [ Thread-108:22620 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:56:58  [ main:23008 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:56:58  [ main:23009 ] - [ INFO ]  Job job_local1764732700_0004 completed successfully
2020-11-19 15:56:58  [ main:23012 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84102
		FILE: Number of bytes written=2361243
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254824
		HDFS: Number of bytes written=3114
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=66
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1244659712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 15:56:59  [ main:23687 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 15:56:59  [ main:23713 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:56:59  [ main:23718 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:56:59  [ main:23739 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:56:59  [ main:23803 ] - [ INFO ]  number of splits:1
2020-11-19 15:56:59  [ main:23823 ] - [ INFO ]  Submitting tokens for job: job_local125793273_0005
2020-11-19 15:56:59  [ main:23862 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:56:59  [ main:23862 ] - [ INFO ]  Running job: job_local125793273_0005
2020-11-19 15:56:59  [ Thread-138:23862 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:56:59  [ Thread-138:23862 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:59  [ Thread-138:23862 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:56:59  [ Thread-138:23888 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23889 ] - [ INFO ]  Starting task: attempt_local125793273_0005_m_000000_0
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23890 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23890 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23890 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23890 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23931 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23931 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23931 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23931 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23931 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:23931 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24100 ] - [ INFO ]  
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24100 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24100 ] - [ INFO ]  Spilling map output
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24100 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24100 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24104 ] - [ INFO ]  Finished spill 0
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24105 ] - [ INFO ]  Task:attempt_local125793273_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24113 ] - [ INFO ]  map
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24113 ] - [ INFO ]  Task 'attempt_local125793273_0005_m_000000_0' done.
2020-11-19 15:56:59  [ LocalJobRunner Map Task Executor #0:24113 ] - [ INFO ]  Finishing task: attempt_local125793273_0005_m_000000_0
2020-11-19 15:56:59  [ Thread-138:24113 ] - [ INFO ]  map task executor complete.
2020-11-19 15:56:59  [ Thread-138:24114 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:56:59  [ pool-18-thread-1:24114 ] - [ INFO ]  Starting task: attempt_local125793273_0005_r_000000_0
2020-11-19 15:56:59  [ pool-18-thread-1:24115 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:56:59  [ pool-18-thread-1:24115 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:56:59  [ pool-18-thread-1:24115 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:56:59  [ pool-18-thread-1:24115 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63173196
2020-11-19 15:56:59  [ pool-18-thread-1:24115 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:56:59  [ EventFetcher for fetching Map Completion Events:24116 ] - [ INFO ]  attempt_local125793273_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:56:59  [ localfetcher#5:24116 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local125793273_0005_m_000000_0 decomp: 192 len: 196 to MEMORY
2020-11-19 15:56:59  [ localfetcher#5:24117 ] - [ INFO ]  Read 192 bytes from map-output for attempt_local125793273_0005_m_000000_0
2020-11-19 15:56:59  [ localfetcher#5:24117 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2020-11-19 15:56:59  [ EventFetcher for fetching Map Completion Events:24117 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:56:59  [ pool-18-thread-1:24117 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:59  [ pool-18-thread-1:24117 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:56:59  [ pool-18-thread-1:24118 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:59  [ pool-18-thread-1:24118 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 15:56:59  [ pool-18-thread-1:24119 ] - [ INFO ]  Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2020-11-19 15:56:59  [ pool-18-thread-1:24119 ] - [ INFO ]  Merging 1 files, 196 bytes from disk
2020-11-19 15:56:59  [ pool-18-thread-1:24119 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:56:59  [ pool-18-thread-1:24119 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:56:59  [ pool-18-thread-1:24119 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 15:56:59  [ pool-18-thread-1:24119 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:59  [ pool-18-thread-1:24183 ] - [ INFO ]  Task:attempt_local125793273_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 15:56:59  [ pool-18-thread-1:24190 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:56:59  [ pool-18-thread-1:24190 ] - [ INFO ]  Task attempt_local125793273_0005_r_000000_0 is allowed to commit now
2020-11-19 15:56:59  [ pool-18-thread-1:24281 ] - [ INFO ]  Saved output of task 'attempt_local125793273_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local125793273_0005_r_000000
2020-11-19 15:56:59  [ pool-18-thread-1:24282 ] - [ INFO ]  reduce > reduce
2020-11-19 15:56:59  [ pool-18-thread-1:24282 ] - [ INFO ]  Task 'attempt_local125793273_0005_r_000000_0' done.
2020-11-19 15:56:59  [ pool-18-thread-1:24282 ] - [ INFO ]  Finishing task: attempt_local125793273_0005_r_000000_0
2020-11-19 15:56:59  [ Thread-138:24282 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:57:00  [ main:24862 ] - [ INFO ]  Job job_local125793273_0005 running in uber mode : false
2020-11-19 15:57:00  [ main:24863 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:57:00  [ main:24863 ] - [ INFO ]  Job job_local125793273_0005 completed successfully
2020-11-19 15:57:00  [ main:24865 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85302
		FILE: Number of bytes written=2930122
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319236
		HDFS: Number of bytes written=4193
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=88
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=196
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=196
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455423488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 15:57:03  [ main:27941 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 15:57:03  [ main:27956 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 15:57:03  [ main:27960 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 15:57:03  [ main:27976 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 15:57:03  [ main:28100 ] - [ INFO ]  number of splits:1
2020-11-19 15:57:03  [ main:28118 ] - [ INFO ]  Submitting tokens for job: job_local290734419_0006
2020-11-19 15:57:03  [ main:28166 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 15:57:03  [ main:28166 ] - [ INFO ]  Running job: job_local290734419_0006
2020-11-19 15:57:03  [ Thread-168:28166 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 15:57:03  [ Thread-168:28166 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:57:03  [ Thread-168:28166 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 15:57:03  [ Thread-168:28196 ] - [ INFO ]  Waiting for map tasks
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28197 ] - [ INFO ]  Starting task: attempt_local290734419_0006_m_000000_0
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28197 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28198 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28198 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28198 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28242 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28242 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28242 ] - [ INFO ]  soft limit at 83886080
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28242 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28242 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 15:57:03  [ LocalJobRunner Map Task Executor #0:28242 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28506 ] - [ INFO ]  
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28506 ] - [ INFO ]  Starting flush of map output
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28506 ] - [ INFO ]  Spilling map output
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28506 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28506 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28510 ] - [ INFO ]  Finished spill 0
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28511 ] - [ INFO ]  Task:attempt_local290734419_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28521 ] - [ INFO ]  map
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28521 ] - [ INFO ]  Task 'attempt_local290734419_0006_m_000000_0' done.
2020-11-19 15:57:04  [ LocalJobRunner Map Task Executor #0:28521 ] - [ INFO ]  Finishing task: attempt_local290734419_0006_m_000000_0
2020-11-19 15:57:04  [ Thread-168:28521 ] - [ INFO ]  map task executor complete.
2020-11-19 15:57:04  [ Thread-168:28522 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 15:57:04  [ pool-21-thread-1:28522 ] - [ INFO ]  Starting task: attempt_local290734419_0006_r_000000_0
2020-11-19 15:57:04  [ pool-21-thread-1:28522 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 15:57:04  [ pool-21-thread-1:28523 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 15:57:04  [ pool-21-thread-1:28523 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 15:57:04  [ pool-21-thread-1:28523 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@792eee01
2020-11-19 15:57:04  [ pool-21-thread-1:28523 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 15:57:04  [ EventFetcher for fetching Map Completion Events:28523 ] - [ INFO ]  attempt_local290734419_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 15:57:04  [ localfetcher#6:28524 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local290734419_0006_m_000000_0 decomp: 192 len: 196 to MEMORY
2020-11-19 15:57:04  [ localfetcher#6:28524 ] - [ INFO ]  Read 192 bytes from map-output for attempt_local290734419_0006_m_000000_0
2020-11-19 15:57:04  [ localfetcher#6:28524 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2020-11-19 15:57:04  [ EventFetcher for fetching Map Completion Events:28525 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 15:57:04  [ pool-21-thread-1:28525 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:57:04  [ pool-21-thread-1:28525 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 15:57:04  [ pool-21-thread-1:28526 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:57:04  [ pool-21-thread-1:28526 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 15:57:04  [ pool-21-thread-1:28526 ] - [ INFO ]  Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2020-11-19 15:57:04  [ pool-21-thread-1:28527 ] - [ INFO ]  Merging 1 files, 196 bytes from disk
2020-11-19 15:57:04  [ pool-21-thread-1:28527 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 15:57:04  [ pool-21-thread-1:28527 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 15:57:04  [ pool-21-thread-1:28527 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 15:57:04  [ pool-21-thread-1:28527 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:57:04  [ pool-21-thread-1:28652 ] - [ INFO ]  Task:attempt_local290734419_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 15:57:04  [ pool-21-thread-1:28659 ] - [ INFO ]  1 / 1 copied.
2020-11-19 15:57:04  [ pool-21-thread-1:28660 ] - [ INFO ]  Task attempt_local290734419_0006_r_000000_0 is allowed to commit now
2020-11-19 15:57:04  [ pool-21-thread-1:28766 ] - [ INFO ]  Saved output of task 'attempt_local290734419_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local290734419_0006_r_000000
2020-11-19 15:57:04  [ pool-21-thread-1:28767 ] - [ INFO ]  reduce > reduce
2020-11-19 15:57:04  [ pool-21-thread-1:28767 ] - [ INFO ]  Task 'attempt_local290734419_0006_r_000000_0' done.
2020-11-19 15:57:04  [ pool-21-thread-1:28767 ] - [ INFO ]  Finishing task: attempt_local290734419_0006_r_000000_0
2020-11-19 15:57:04  [ Thread-168:28767 ] - [ INFO ]  reduce task executor complete.
2020-11-19 15:57:04  [ main:29166 ] - [ INFO ]  Job job_local290734419_0006 running in uber mode : false
2020-11-19 15:57:04  [ main:29166 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 15:57:04  [ main:29167 ] - [ INFO ]  Job job_local290734419_0006 completed successfully
2020-11-19 15:57:04  [ main:29169 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86500
		FILE: Number of bytes written=3499000
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383634
		HDFS: Number of bytes written=5267
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=110
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=196
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=196
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1657798656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:27:00  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:27:00  [ main:534 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:27:00  [ main:534 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:27:01  [ main:718 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:01  [ main:722 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:01  [ main:737 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:01  [ main:819 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:01  [ main:881 ] - [ INFO ]  Submitting tokens for job: job_local1343839319_0001
2020-11-19 16:27:01  [ main:972 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:01  [ main:973 ] - [ INFO ]  Running job: job_local1343839319_0001
2020-11-19 16:27:01  [ Thread-18:973 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:01  [ Thread-18:977 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:01  [ Thread-18:978 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:01  [ Thread-18:1020 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1021 ] - [ INFO ]  Starting task: attempt_local1343839319_0001_m_000000_0
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1036 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1040 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1040 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1042 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1097 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1097 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1097 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1097 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1097 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1099 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1210 ] - [ INFO ]  
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1211 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1211 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1211 ] - [ INFO ]  bufstart = 0; bufend = 18766; bufvoid = 104857600
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1211 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213144(104852576); length = 1253/6553600
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1220 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1223 ] - [ INFO ]  Task:attempt_local1343839319_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1238 ] - [ INFO ]  map
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1238 ] - [ INFO ]  Task 'attempt_local1343839319_0001_m_000000_0' done.
2020-11-19 16:27:01  [ LocalJobRunner Map Task Executor #0:1238 ] - [ INFO ]  Finishing task: attempt_local1343839319_0001_m_000000_0
2020-11-19 16:27:01  [ Thread-18:1238 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:01  [ Thread-18:1240 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:01  [ pool-6-thread-1:1240 ] - [ INFO ]  Starting task: attempt_local1343839319_0001_r_000000_0
2020-11-19 16:27:01  [ pool-6-thread-1:1244 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:01  [ pool-6-thread-1:1244 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:01  [ pool-6-thread-1:1244 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:01  [ pool-6-thread-1:1245 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@70b73847
2020-11-19 16:27:01  [ pool-6-thread-1:1253 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:01  [ EventFetcher for fetching Map Completion Events:1254 ] - [ INFO ]  attempt_local1343839319_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:01  [ localfetcher#1:1272 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1343839319_0001_m_000000_0 decomp: 19396 len: 19400 to MEMORY
2020-11-19 16:27:01  [ localfetcher#1:1276 ] - [ INFO ]  Read 19396 bytes from map-output for attempt_local1343839319_0001_m_000000_0
2020-11-19 16:27:01  [ localfetcher#1:1277 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 19396, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19396
2020-11-19 16:27:01  [ EventFetcher for fetching Map Completion Events:1277 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:01  [ pool-6-thread-1:1278 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:01  [ pool-6-thread-1:1278 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:01  [ pool-6-thread-1:1282 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:01  [ pool-6-thread-1:1282 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 19392 bytes
2020-11-19 16:27:01  [ pool-6-thread-1:1284 ] - [ INFO ]  Merged 1 segments, 19396 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:01  [ pool-6-thread-1:1285 ] - [ INFO ]  Merging 1 files, 19400 bytes from disk
2020-11-19 16:27:01  [ pool-6-thread-1:1285 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:01  [ pool-6-thread-1:1285 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:01  [ pool-6-thread-1:1286 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 19392 bytes
2020-11-19 16:27:01  [ pool-6-thread-1:1286 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:01  [ pool-6-thread-1:1304 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:27:01  [ pool-6-thread-1:1460 ] - [ INFO ]  Task:attempt_local1343839319_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:01  [ pool-6-thread-1:1476 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:01  [ pool-6-thread-1:1477 ] - [ INFO ]  Task attempt_local1343839319_0001_r_000000_0 is allowed to commit now
2020-11-19 16:27:01  [ pool-6-thread-1:1530 ] - [ INFO ]  Saved output of task 'attempt_local1343839319_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1343839319_0001_r_000000
2020-11-19 16:27:01  [ pool-6-thread-1:1531 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:01  [ pool-6-thread-1:1531 ] - [ INFO ]  Task 'attempt_local1343839319_0001_r_000000_0' done.
2020-11-19 16:27:01  [ pool-6-thread-1:1531 ] - [ INFO ]  Finishing task: attempt_local1343839319_0001_r_000000_0
2020-11-19 16:27:01  [ Thread-18:1531 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:02  [ main:1977 ] - [ INFO ]  Job job_local1343839319_0001 running in uber mode : false
2020-11-19 16:27:02  [ main:1977 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:02  [ main:1978 ] - [ INFO ]  Job job_local1343839319_0001 completed successfully
2020-11-19 16:27:02  [ main:1985 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=39182
		FILE: Number of bytes written=626390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=177
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=314
		Map output bytes=18766
		Map output materialized bytes=19400
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=19400
		Reduce input records=314
		Reduce output records=3
		Spilled Records=628
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=177
2020-11-19 16:27:02  [ main:2155 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:02  [ main:2169 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:02  [ main:2174 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:02  [ main:2189 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:02  [ main:2233 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:02  [ main:2253 ] - [ INFO ]  Submitting tokens for job: job_local1158302380_0002
2020-11-19 16:27:02  [ main:2300 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:02  [ main:2300 ] - [ INFO ]  Running job: job_local1158302380_0002
2020-11-19 16:27:02  [ Thread-48:2300 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:02  [ Thread-48:2300 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:02  [ Thread-48:2300 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:02  [ Thread-48:2307 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2308 ] - [ INFO ]  Starting task: attempt_local1158302380_0002_m_000000_0
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2308 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2308 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2308 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2310 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2353 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2353 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2353 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2353 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2353 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:02  [ LocalJobRunner Map Task Executor #0:2354 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2707 ] - [ INFO ]  
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2708 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2708 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2708 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2708 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2715 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2717 ] - [ INFO ]  Task:attempt_local1158302380_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2732 ] - [ INFO ]  map
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2732 ] - [ INFO ]  Task 'attempt_local1158302380_0002_m_000000_0' done.
2020-11-19 16:27:03  [ LocalJobRunner Map Task Executor #0:2732 ] - [ INFO ]  Finishing task: attempt_local1158302380_0002_m_000000_0
2020-11-19 16:27:03  [ Thread-48:2732 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:03  [ Thread-48:2733 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:03  [ pool-9-thread-1:2733 ] - [ INFO ]  Starting task: attempt_local1158302380_0002_r_000000_0
2020-11-19 16:27:03  [ pool-9-thread-1:2734 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:03  [ pool-9-thread-1:2734 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:03  [ pool-9-thread-1:2734 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:03  [ pool-9-thread-1:2734 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6837619d
2020-11-19 16:27:03  [ pool-9-thread-1:2735 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:03  [ EventFetcher for fetching Map Completion Events:2735 ] - [ INFO ]  attempt_local1158302380_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:03  [ localfetcher#2:2736 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1158302380_0002_m_000000_0 decomp: 192 len: 196 to MEMORY
2020-11-19 16:27:03  [ localfetcher#2:2736 ] - [ INFO ]  Read 192 bytes from map-output for attempt_local1158302380_0002_m_000000_0
2020-11-19 16:27:03  [ localfetcher#2:2737 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2020-11-19 16:27:03  [ EventFetcher for fetching Map Completion Events:2737 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:03  [ pool-9-thread-1:2737 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:03  [ pool-9-thread-1:2738 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:03  [ pool-9-thread-1:2739 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:03  [ pool-9-thread-1:2739 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:27:03  [ pool-9-thread-1:2739 ] - [ INFO ]  Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:03  [ pool-9-thread-1:2739 ] - [ INFO ]  Merging 1 files, 196 bytes from disk
2020-11-19 16:27:03  [ pool-9-thread-1:2739 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:03  [ pool-9-thread-1:2739 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:03  [ pool-9-thread-1:2740 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:27:03  [ pool-9-thread-1:2740 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:03  [ pool-9-thread-1:2990 ] - [ INFO ]  Task:attempt_local1158302380_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:03  [ pool-9-thread-1:2998 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:03  [ pool-9-thread-1:2998 ] - [ INFO ]  Task attempt_local1158302380_0002_r_000000_0 is allowed to commit now
2020-11-19 16:27:03  [ pool-9-thread-1:3026 ] - [ INFO ]  Saved output of task 'attempt_local1158302380_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1158302380_0002_r_000000
2020-11-19 16:27:03  [ pool-9-thread-1:3027 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:03  [ pool-9-thread-1:3027 ] - [ INFO ]  Task 'attempt_local1158302380_0002_r_000000_0' done.
2020-11-19 16:27:03  [ pool-9-thread-1:3027 ] - [ INFO ]  Finishing task: attempt_local1158302380_0002_r_000000_0
2020-11-19 16:27:03  [ Thread-48:3027 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:03  [ main:3301 ] - [ INFO ]  Job job_local1158302380_0002 running in uber mode : false
2020-11-19 16:27:03  [ main:3301 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:03  [ main:3301 ] - [ INFO ]  Job job_local1158302380_0002 completed successfully
2020-11-19 16:27:03  [ main:3303 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=78788
		FILE: Number of bytes written=1217520
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125920
		HDFS: Number of bytes written=888
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=196
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=196
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:04  [ main:3608 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:04  [ main:3623 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:04  [ main:3627 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:04  [ main:3633 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:04  [ main:3672 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:04  [ main:3694 ] - [ INFO ]  Submitting tokens for job: job_local1396450615_0003
2020-11-19 16:27:04  [ main:3742 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:04  [ main:3742 ] - [ INFO ]  Running job: job_local1396450615_0003
2020-11-19 16:27:04  [ Thread-78:3742 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:04  [ Thread-78:3742 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:04  [ Thread-78:3742 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:04  [ Thread-78:3750 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3750 ] - [ INFO ]  Starting task: attempt_local1396450615_0003_m_000000_0
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3751 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3751 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3751 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3752 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3768 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3768 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3768 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3768 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3768 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3769 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3853 ] - [ INFO ]  
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3853 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3853 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3853 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3853 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3858 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3859 ] - [ INFO ]  Task:attempt_local1396450615_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3866 ] - [ INFO ]  map
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3866 ] - [ INFO ]  Task 'attempt_local1396450615_0003_m_000000_0' done.
2020-11-19 16:27:04  [ LocalJobRunner Map Task Executor #0:3866 ] - [ INFO ]  Finishing task: attempt_local1396450615_0003_m_000000_0
2020-11-19 16:27:04  [ Thread-78:3866 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:04  [ Thread-78:3867 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:04  [ pool-12-thread-1:3867 ] - [ INFO ]  Starting task: attempt_local1396450615_0003_r_000000_0
2020-11-19 16:27:04  [ pool-12-thread-1:3868 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:04  [ pool-12-thread-1:3868 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:04  [ pool-12-thread-1:3868 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:04  [ pool-12-thread-1:3868 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a3a926a
2020-11-19 16:27:04  [ pool-12-thread-1:3868 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:04  [ EventFetcher for fetching Map Completion Events:3869 ] - [ INFO ]  attempt_local1396450615_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:04  [ localfetcher#3:3870 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local1396450615_0003_m_000000_0 decomp: 195 len: 199 to MEMORY
2020-11-19 16:27:04  [ localfetcher#3:3870 ] - [ INFO ]  Read 195 bytes from map-output for attempt_local1396450615_0003_m_000000_0
2020-11-19 16:27:04  [ localfetcher#3:3870 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 195, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->195
2020-11-19 16:27:04  [ EventFetcher for fetching Map Completion Events:3870 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:04  [ pool-12-thread-1:3871 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:04  [ pool-12-thread-1:3871 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:04  [ pool-12-thread-1:3872 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:04  [ pool-12-thread-1:3872 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 191 bytes
2020-11-19 16:27:04  [ pool-12-thread-1:3872 ] - [ INFO ]  Merged 1 segments, 195 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:04  [ pool-12-thread-1:3872 ] - [ INFO ]  Merging 1 files, 199 bytes from disk
2020-11-19 16:27:04  [ pool-12-thread-1:3872 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:04  [ pool-12-thread-1:3872 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:04  [ pool-12-thread-1:3873 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 191 bytes
2020-11-19 16:27:04  [ pool-12-thread-1:3873 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:04  [ pool-12-thread-1:3917 ] - [ INFO ]  Task:attempt_local1396450615_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:04  [ pool-12-thread-1:3924 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:04  [ pool-12-thread-1:3924 ] - [ INFO ]  Task attempt_local1396450615_0003_r_000000_0 is allowed to commit now
2020-11-19 16:27:04  [ pool-12-thread-1:3948 ] - [ INFO ]  Saved output of task 'attempt_local1396450615_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1396450615_0003_r_000000
2020-11-19 16:27:04  [ pool-12-thread-1:3949 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:04  [ pool-12-thread-1:3949 ] - [ INFO ]  Task 'attempt_local1396450615_0003_r_000000_0' done.
2020-11-19 16:27:04  [ pool-12-thread-1:3949 ] - [ INFO ]  Finishing task: attempt_local1396450615_0003_r_000000_0
2020-11-19 16:27:04  [ Thread-78:3949 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:05  [ main:4747 ] - [ INFO ]  Job job_local1396450615_0003 running in uber mode : false
2020-11-19 16:27:05  [ main:4747 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:05  [ main:4748 ] - [ INFO ]  Job job_local1396450615_0003 completed successfully
2020-11-19 16:27:05  [ main:4750 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=79992
		FILE: Number of bytes written=1789455
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190320
		HDFS: Number of bytes written=1967
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=199
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=199
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=907018240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:27:06  [ main:6082 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:06  [ main:6098 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:06  [ main:6103 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:06  [ main:6109 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:06  [ main:6152 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:06  [ main:6171 ] - [ INFO ]  Submitting tokens for job: job_local1618112352_0004
2020-11-19 16:27:06  [ main:6210 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:06  [ main:6210 ] - [ INFO ]  Running job: job_local1618112352_0004
2020-11-19 16:27:06  [ Thread-108:6210 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:06  [ Thread-108:6210 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:06  [ Thread-108:6210 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:06  [ Thread-108:6217 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6218 ] - [ INFO ]  Starting task: attempt_local1618112352_0004_m_000000_0
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6218 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6219 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6219 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6219 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6477 ] - [ INFO ]  
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6477 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6477 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6477 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6477 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6481 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6483 ] - [ INFO ]  Task:attempt_local1618112352_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6489 ] - [ INFO ]  map
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6489 ] - [ INFO ]  Task 'attempt_local1618112352_0004_m_000000_0' done.
2020-11-19 16:27:06  [ LocalJobRunner Map Task Executor #0:6489 ] - [ INFO ]  Finishing task: attempt_local1618112352_0004_m_000000_0
2020-11-19 16:27:06  [ Thread-108:6489 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:06  [ Thread-108:6490 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:06  [ pool-15-thread-1:6490 ] - [ INFO ]  Starting task: attempt_local1618112352_0004_r_000000_0
2020-11-19 16:27:06  [ pool-15-thread-1:6491 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:06  [ pool-15-thread-1:6491 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:06  [ pool-15-thread-1:6491 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:06  [ pool-15-thread-1:6491 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56a37a15
2020-11-19 16:27:06  [ pool-15-thread-1:6491 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:06  [ EventFetcher for fetching Map Completion Events:6492 ] - [ INFO ]  attempt_local1618112352_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:06  [ localfetcher#4:6493 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1618112352_0004_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:06  [ localfetcher#4:6493 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1618112352_0004_m_000000_0
2020-11-19 16:27:06  [ localfetcher#4:6493 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:06  [ EventFetcher for fetching Map Completion Events:6493 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:06  [ pool-15-thread-1:6494 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:06  [ pool-15-thread-1:6494 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:06  [ pool-15-thread-1:6494 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:06  [ pool-15-thread-1:6495 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:06  [ pool-15-thread-1:6495 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:06  [ pool-15-thread-1:6495 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:06  [ pool-15-thread-1:6495 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:06  [ pool-15-thread-1:6495 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:06  [ pool-15-thread-1:6496 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:06  [ pool-15-thread-1:6496 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:06  [ pool-15-thread-1:6550 ] - [ INFO ]  Task:attempt_local1618112352_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:07  [ pool-15-thread-1:6557 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:07  [ pool-15-thread-1:6557 ] - [ INFO ]  Task attempt_local1618112352_0004_r_000000_0 is allowed to commit now
2020-11-19 16:27:07  [ pool-15-thread-1:6576 ] - [ INFO ]  Saved output of task 'attempt_local1618112352_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1618112352_0004_r_000000
2020-11-19 16:27:07  [ pool-15-thread-1:6577 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:07  [ pool-15-thread-1:6577 ] - [ INFO ]  Task 'attempt_local1618112352_0004_r_000000_0' done.
2020-11-19 16:27:07  [ pool-15-thread-1:6577 ] - [ INFO ]  Finishing task: attempt_local1618112352_0004_r_000000_0
2020-11-19 16:27:07  [ Thread-108:6578 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:07  [ main:7214 ] - [ INFO ]  Job job_local1618112352_0004 running in uber mode : false
2020-11-19 16:27:07  [ main:7214 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:07  [ main:7214 ] - [ INFO ]  Job job_local1618112352_0004 completed successfully
2020-11-19 16:27:07  [ main:7216 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=81198
		FILE: Number of bytes written=2361387
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254718
		HDFS: Number of bytes written=3042
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=165
		Total committed heap usage (bytes)=1049624576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:08  [ main:7588 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:08  [ main:7600 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:08  [ main:7605 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:08  [ main:7612 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:08  [ main:7649 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:08  [ main:7669 ] - [ INFO ]  Submitting tokens for job: job_local79768964_0005
2020-11-19 16:27:08  [ main:7709 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:08  [ main:7709 ] - [ INFO ]  Running job: job_local79768964_0005
2020-11-19 16:27:08  [ Thread-138:7709 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:08  [ Thread-138:7709 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:08  [ Thread-138:7709 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:08  [ Thread-138:7717 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7717 ] - [ INFO ]  Starting task: attempt_local79768964_0005_m_000000_0
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7717 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7717 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7717 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7718 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7730 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7730 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7798 ] - [ INFO ]  
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7798 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7798 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7798 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7798 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7802 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7803 ] - [ INFO ]  Task:attempt_local79768964_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7808 ] - [ INFO ]  map
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7808 ] - [ INFO ]  Task 'attempt_local79768964_0005_m_000000_0' done.
2020-11-19 16:27:08  [ LocalJobRunner Map Task Executor #0:7808 ] - [ INFO ]  Finishing task: attempt_local79768964_0005_m_000000_0
2020-11-19 16:27:08  [ Thread-138:7809 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:08  [ Thread-138:7809 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:08  [ pool-18-thread-1:7809 ] - [ INFO ]  Starting task: attempt_local79768964_0005_r_000000_0
2020-11-19 16:27:08  [ pool-18-thread-1:7810 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:08  [ pool-18-thread-1:7810 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:08  [ pool-18-thread-1:7810 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:08  [ pool-18-thread-1:7810 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3678b7ec
2020-11-19 16:27:08  [ pool-18-thread-1:7810 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:08  [ EventFetcher for fetching Map Completion Events:7811 ] - [ INFO ]  attempt_local79768964_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:08  [ localfetcher#5:7811 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local79768964_0005_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:08  [ localfetcher#5:7812 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local79768964_0005_m_000000_0
2020-11-19 16:27:08  [ localfetcher#5:7812 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:08  [ EventFetcher for fetching Map Completion Events:7812 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:08  [ pool-18-thread-1:7812 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:08  [ pool-18-thread-1:7812 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:08  [ pool-18-thread-1:7813 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:08  [ pool-18-thread-1:7814 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:08  [ pool-18-thread-1:7869 ] - [ INFO ]  Task:attempt_local79768964_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:08  [ pool-18-thread-1:7874 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:08  [ pool-18-thread-1:7874 ] - [ INFO ]  Task attempt_local79768964_0005_r_000000_0 is allowed to commit now
2020-11-19 16:27:08  [ pool-18-thread-1:7892 ] - [ INFO ]  Saved output of task 'attempt_local79768964_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local79768964_0005_r_000000
2020-11-19 16:27:08  [ pool-18-thread-1:7893 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:08  [ pool-18-thread-1:7893 ] - [ INFO ]  Task 'attempt_local79768964_0005_r_000000_0' done.
2020-11-19 16:27:08  [ pool-18-thread-1:7893 ] - [ INFO ]  Finishing task: attempt_local79768964_0005_r_000000_0
2020-11-19 16:27:08  [ Thread-138:7893 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:09  [ main:8714 ] - [ INFO ]  Job job_local79768964_0005 running in uber mode : false
2020-11-19 16:27:09  [ main:8714 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:09  [ main:8714 ] - [ INFO ]  Job job_local79768964_0005 completed successfully
2020-11-19 16:27:09  [ main:8717 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=82392
		FILE: Number of bytes written=2927209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319122
		HDFS: Number of bytes written=4122
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=90
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1049624576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:09  [ main:9001 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:09  [ main:9011 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:09  [ main:9015 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:09  [ main:9022 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:09  [ main:9057 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:09  [ main:9075 ] - [ INFO ]  Submitting tokens for job: job_local1920042309_0006
2020-11-19 16:27:09  [ main:9115 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:09  [ main:9115 ] - [ INFO ]  Running job: job_local1920042309_0006
2020-11-19 16:27:09  [ Thread-168:9115 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:09  [ Thread-168:9115 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:09  [ Thread-168:9116 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:09  [ Thread-168:9124 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9124 ] - [ INFO ]  Starting task: attempt_local1920042309_0006_m_000000_0
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9125 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9125 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9125 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9126 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9137 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9137 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9137 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9137 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9137 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9138 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9452 ] - [ INFO ]  
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9452 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9452 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9452 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9452 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9456 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9456 ] - [ INFO ]  Task:attempt_local1920042309_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9462 ] - [ INFO ]  map
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9462 ] - [ INFO ]  Task 'attempt_local1920042309_0006_m_000000_0' done.
2020-11-19 16:27:09  [ LocalJobRunner Map Task Executor #0:9462 ] - [ INFO ]  Finishing task: attempt_local1920042309_0006_m_000000_0
2020-11-19 16:27:09  [ Thread-168:9463 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:09  [ Thread-168:9463 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:09  [ pool-21-thread-1:9463 ] - [ INFO ]  Starting task: attempt_local1920042309_0006_r_000000_0
2020-11-19 16:27:09  [ pool-21-thread-1:9464 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:09  [ pool-21-thread-1:9464 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:09  [ pool-21-thread-1:9464 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:09  [ pool-21-thread-1:9464 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@702e6dca
2020-11-19 16:27:09  [ pool-21-thread-1:9465 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:09  [ EventFetcher for fetching Map Completion Events:9465 ] - [ INFO ]  attempt_local1920042309_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:09  [ localfetcher#6:9466 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local1920042309_0006_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:09  [ localfetcher#6:9466 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1920042309_0006_m_000000_0
2020-11-19 16:27:09  [ localfetcher#6:9466 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:09  [ EventFetcher for fetching Map Completion Events:9467 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:09  [ pool-21-thread-1:9467 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:09  [ pool-21-thread-1:9467 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:09  [ pool-21-thread-1:9468 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:09  [ pool-21-thread-1:9468 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:09  [ pool-21-thread-1:9468 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:09  [ pool-21-thread-1:9468 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:09  [ pool-21-thread-1:9468 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:09  [ pool-21-thread-1:9468 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:09  [ pool-21-thread-1:9469 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:09  [ pool-21-thread-1:9469 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:09  [ pool-21-thread-1:9513 ] - [ INFO ]  Task:attempt_local1920042309_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:09  [ pool-21-thread-1:9519 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:09  [ pool-21-thread-1:9519 ] - [ INFO ]  Task attempt_local1920042309_0006_r_000000_0 is allowed to commit now
2020-11-19 16:27:09  [ pool-21-thread-1:9536 ] - [ INFO ]  Saved output of task 'attempt_local1920042309_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1920042309_0006_r_000000
2020-11-19 16:27:09  [ pool-21-thread-1:9536 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:09  [ pool-21-thread-1:9536 ] - [ INFO ]  Task 'attempt_local1920042309_0006_r_000000_0' done.
2020-11-19 16:27:09  [ pool-21-thread-1:9536 ] - [ INFO ]  Finishing task: attempt_local1920042309_0006_r_000000_0
2020-11-19 16:27:09  [ Thread-168:9536 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:10  [ main:10117 ] - [ INFO ]  Job job_local1920042309_0006 running in uber mode : false
2020-11-19 16:27:10  [ main:10118 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:10  [ main:10118 ] - [ INFO ]  Job job_local1920042309_0006 completed successfully
2020-11-19 16:27:10  [ main:10121 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=83586
		FILE: Number of bytes written=3499135
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383528
		HDFS: Number of bytes written=5200
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1049624576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:10  [ main:10441 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:10  [ main:10451 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:10  [ main:10455 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:10  [ main:10462 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:10  [ main:10499 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:10  [ main:10517 ] - [ INFO ]  Submitting tokens for job: job_local1528934779_0007
2020-11-19 16:27:10  [ main:10555 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:10  [ main:10555 ] - [ INFO ]  Running job: job_local1528934779_0007
2020-11-19 16:27:10  [ Thread-198:10555 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:10  [ Thread-198:10555 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:11  [ Thread-198:10556 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:11  [ Thread-198:10566 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10566 ] - [ INFO ]  Starting task: attempt_local1528934779_0007_m_000000_0
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10566 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10567 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10567 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10567 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10598 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10598 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10598 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10598 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10598 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10599 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10682 ] - [ INFO ]  
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10682 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10682 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10682 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10682 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10687 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10688 ] - [ INFO ]  Task:attempt_local1528934779_0007_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10694 ] - [ INFO ]  map
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10694 ] - [ INFO ]  Task 'attempt_local1528934779_0007_m_000000_0' done.
2020-11-19 16:27:11  [ LocalJobRunner Map Task Executor #0:10694 ] - [ INFO ]  Finishing task: attempt_local1528934779_0007_m_000000_0
2020-11-19 16:27:11  [ Thread-198:10694 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:11  [ Thread-198:10695 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:11  [ pool-24-thread-1:10695 ] - [ INFO ]  Starting task: attempt_local1528934779_0007_r_000000_0
2020-11-19 16:27:11  [ pool-24-thread-1:10695 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:11  [ pool-24-thread-1:10696 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:11  [ pool-24-thread-1:10696 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:11  [ pool-24-thread-1:10696 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f70a07d
2020-11-19 16:27:11  [ pool-24-thread-1:10696 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:11  [ EventFetcher for fetching Map Completion Events:10696 ] - [ INFO ]  attempt_local1528934779_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:11  [ localfetcher#7:10697 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local1528934779_0007_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:11  [ localfetcher#7:10697 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1528934779_0007_m_000000_0
2020-11-19 16:27:11  [ localfetcher#7:10697 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:11  [ EventFetcher for fetching Map Completion Events:10697 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:11  [ pool-24-thread-1:10698 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:11  [ pool-24-thread-1:10698 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:11  [ pool-24-thread-1:10698 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:11  [ pool-24-thread-1:10698 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:11  [ pool-24-thread-1:10699 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:11  [ pool-24-thread-1:10699 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:11  [ pool-24-thread-1:10699 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:11  [ pool-24-thread-1:10699 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:11  [ pool-24-thread-1:10699 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:11  [ pool-24-thread-1:10699 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:11  [ pool-24-thread-1:10802 ] - [ INFO ]  Task:attempt_local1528934779_0007_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:11  [ pool-24-thread-1:10809 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:11  [ pool-24-thread-1:10809 ] - [ INFO ]  Task attempt_local1528934779_0007_r_000000_0 is allowed to commit now
2020-11-19 16:27:11  [ pool-24-thread-1:10825 ] - [ INFO ]  Saved output of task 'attempt_local1528934779_0007_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1528934779_0007_r_000000
2020-11-19 16:27:11  [ pool-24-thread-1:10826 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:11  [ pool-24-thread-1:10826 ] - [ INFO ]  Task 'attempt_local1528934779_0007_r_000000_0' done.
2020-11-19 16:27:11  [ pool-24-thread-1:10826 ] - [ INFO ]  Finishing task: attempt_local1528934779_0007_r_000000_0
2020-11-19 16:27:11  [ Thread-198:10826 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:12  [ main:11557 ] - [ INFO ]  Job job_local1528934779_0007 running in uber mode : false
2020-11-19 16:27:12  [ main:11558 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:12  [ main:11558 ] - [ INFO ]  Job job_local1528934779_0007 completed successfully
2020-11-19 16:27:12  [ main:11560 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84784
		FILE: Number of bytes written=4071059
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=447918
		HDFS: Number of bytes written=6271
		HDFS: Number of read operations=401
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=134
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1260388352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:12  [ main:11871 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:12  [ main:11886 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:12  [ main:11947 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:12  [ main:11953 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:12  [ main:11990 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:12  [ main:12009 ] - [ INFO ]  Submitting tokens for job: job_local788647404_0008
2020-11-19 16:27:12  [ main:12049 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:12  [ main:12049 ] - [ INFO ]  Running job: job_local788647404_0008
2020-11-19 16:27:12  [ Thread-228:12049 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:12  [ Thread-228:12049 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:12  [ Thread-228:12049 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:12  [ Thread-228:12058 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12058 ] - [ INFO ]  Starting task: attempt_local788647404_0008_m_000000_0
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12059 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12070 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12070 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12070 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12070 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12070 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12070 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12155 ] - [ INFO ]  
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12155 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12155 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12155 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12155 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12158 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12159 ] - [ INFO ]  Task:attempt_local788647404_0008_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12165 ] - [ INFO ]  map
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12166 ] - [ INFO ]  Task 'attempt_local788647404_0008_m_000000_0' done.
2020-11-19 16:27:12  [ LocalJobRunner Map Task Executor #0:12166 ] - [ INFO ]  Finishing task: attempt_local788647404_0008_m_000000_0
2020-11-19 16:27:12  [ Thread-228:12166 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:12  [ Thread-228:12166 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:12  [ pool-27-thread-1:12166 ] - [ INFO ]  Starting task: attempt_local788647404_0008_r_000000_0
2020-11-19 16:27:12  [ pool-27-thread-1:12167 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:12  [ pool-27-thread-1:12167 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:12  [ pool-27-thread-1:12167 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:12  [ pool-27-thread-1:12167 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16eea23c
2020-11-19 16:27:12  [ pool-27-thread-1:12167 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:12  [ EventFetcher for fetching Map Completion Events:12167 ] - [ INFO ]  attempt_local788647404_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:12  [ localfetcher#8:12168 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local788647404_0008_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:12  [ localfetcher#8:12168 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local788647404_0008_m_000000_0
2020-11-19 16:27:12  [ localfetcher#8:12168 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:12  [ EventFetcher for fetching Map Completion Events:12168 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:12  [ pool-27-thread-1:12169 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:12  [ pool-27-thread-1:12169 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:12  [ pool-27-thread-1:12169 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:12  [ pool-27-thread-1:12169 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:12  [ pool-27-thread-1:12170 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:12  [ pool-27-thread-1:12170 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:12  [ pool-27-thread-1:12170 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:12  [ pool-27-thread-1:12170 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:12  [ pool-27-thread-1:12170 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:12  [ pool-27-thread-1:12170 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:12  [ pool-27-thread-1:12229 ] - [ INFO ]  Task:attempt_local788647404_0008_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:12  [ pool-27-thread-1:12236 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:12  [ pool-27-thread-1:12236 ] - [ INFO ]  Task attempt_local788647404_0008_r_000000_0 is allowed to commit now
2020-11-19 16:27:12  [ pool-27-thread-1:12257 ] - [ INFO ]  Saved output of task 'attempt_local788647404_0008_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local788647404_0008_r_000000
2020-11-19 16:27:12  [ pool-27-thread-1:12257 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:12  [ pool-27-thread-1:12257 ] - [ INFO ]  Task 'attempt_local788647404_0008_r_000000_0' done.
2020-11-19 16:27:12  [ pool-27-thread-1:12257 ] - [ INFO ]  Finishing task: attempt_local788647404_0008_r_000000_0
2020-11-19 16:27:12  [ Thread-228:12257 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:13  [ main:13051 ] - [ INFO ]  Job job_local788647404_0008 running in uber mode : false
2020-11-19 16:27:13  [ main:13051 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:13  [ main:13051 ] - [ INFO ]  Job job_local788647404_0008 completed successfully
2020-11-19 16:27:13  [ main:13053 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85984
		FILE: Number of bytes written=4639942
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=512328
		HDFS: Number of bytes written=7354
		HDFS: Number of read operations=469
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=156
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=886046720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:13  [ main:13337 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:13  [ main:13351 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:13  [ main:13355 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:13  [ main:13364 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:13  [ main:13401 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:13  [ main:13418 ] - [ INFO ]  Submitting tokens for job: job_local930005805_0009
2020-11-19 16:27:13  [ main:13455 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:13  [ main:13455 ] - [ INFO ]  Running job: job_local930005805_0009
2020-11-19 16:27:13  [ Thread-258:13455 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:13  [ Thread-258:13455 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:13  [ Thread-258:13455 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:13  [ Thread-258:13463 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13463 ] - [ INFO ]  Starting task: attempt_local930005805_0009_m_000000_0
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13463 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13464 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13464 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13464 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13471 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13471 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13471 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13471 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13471 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:13  [ LocalJobRunner Map Task Executor #0:13472 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13560 ] - [ INFO ]  
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13561 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13561 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13561 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13561 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13564 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13566 ] - [ INFO ]  Task:attempt_local930005805_0009_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13572 ] - [ INFO ]  map
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13573 ] - [ INFO ]  Task 'attempt_local930005805_0009_m_000000_0' done.
2020-11-19 16:27:14  [ LocalJobRunner Map Task Executor #0:13573 ] - [ INFO ]  Finishing task: attempt_local930005805_0009_m_000000_0
2020-11-19 16:27:14  [ Thread-258:13573 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:14  [ Thread-258:13573 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:14  [ pool-30-thread-1:13573 ] - [ INFO ]  Starting task: attempt_local930005805_0009_r_000000_0
2020-11-19 16:27:14  [ pool-30-thread-1:13574 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:14  [ pool-30-thread-1:13574 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:14  [ pool-30-thread-1:13574 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:14  [ pool-30-thread-1:13574 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2beb5098
2020-11-19 16:27:14  [ pool-30-thread-1:13574 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:14  [ EventFetcher for fetching Map Completion Events:13574 ] - [ INFO ]  attempt_local930005805_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:14  [ localfetcher#9:13575 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local930005805_0009_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:14  [ localfetcher#9:13575 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local930005805_0009_m_000000_0
2020-11-19 16:27:14  [ localfetcher#9:13575 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:14  [ EventFetcher for fetching Map Completion Events:13575 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:14  [ pool-30-thread-1:13576 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:14  [ pool-30-thread-1:13576 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:14  [ pool-30-thread-1:13577 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:14  [ pool-30-thread-1:13577 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:14  [ pool-30-thread-1:13577 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:14  [ pool-30-thread-1:13577 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:14  [ pool-30-thread-1:13577 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:14  [ pool-30-thread-1:13577 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:14  [ pool-30-thread-1:13578 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:14  [ pool-30-thread-1:13578 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:14  [ pool-30-thread-1:13620 ] - [ INFO ]  Task:attempt_local930005805_0009_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:14  [ pool-30-thread-1:13625 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:14  [ pool-30-thread-1:13625 ] - [ INFO ]  Task attempt_local930005805_0009_r_000000_0 is allowed to commit now
2020-11-19 16:27:14  [ pool-30-thread-1:13643 ] - [ INFO ]  Saved output of task 'attempt_local930005805_0009_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local930005805_0009_r_000000
2020-11-19 16:27:14  [ pool-30-thread-1:13644 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:14  [ pool-30-thread-1:13644 ] - [ INFO ]  Task 'attempt_local930005805_0009_r_000000_0' done.
2020-11-19 16:27:14  [ pool-30-thread-1:13644 ] - [ INFO ]  Finishing task: attempt_local930005805_0009_r_000000_0
2020-11-19 16:27:14  [ Thread-258:13644 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:14  [ main:14456 ] - [ INFO ]  Job job_local930005805_0009 running in uber mode : false
2020-11-19 16:27:14  [ main:14456 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:14  [ main:14456 ] - [ INFO ]  Job job_local930005805_0009 completed successfully
2020-11-19 16:27:14  [ main:14457 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=87180
		FILE: Number of bytes written=5208813
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=576720
		HDFS: Number of bytes written=8424
		HDFS: Number of read operations=537
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=178
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1071644672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:15  [ main:14804 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:15  [ main:14819 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:15  [ main:14824 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:15  [ main:14830 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:15  [ main:14873 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:15  [ main:14893 ] - [ INFO ]  Submitting tokens for job: job_local1166193341_0010
2020-11-19 16:27:15  [ main:14937 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:15  [ main:14937 ] - [ INFO ]  Running job: job_local1166193341_0010
2020-11-19 16:27:15  [ Thread-288:14938 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:15  [ Thread-288:14938 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:15  [ Thread-288:14938 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:15  [ Thread-288:14947 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14947 ] - [ INFO ]  Starting task: attempt_local1166193341_0010_m_000000_0
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14947 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14948 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14948 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14948 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14958 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14958 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14958 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14958 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14958 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:14958 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15031 ] - [ INFO ]  
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15031 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15031 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15031 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15031 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15034 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15035 ] - [ INFO ]  Task:attempt_local1166193341_0010_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15041 ] - [ INFO ]  map
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15041 ] - [ INFO ]  Task 'attempt_local1166193341_0010_m_000000_0' done.
2020-11-19 16:27:15  [ LocalJobRunner Map Task Executor #0:15041 ] - [ INFO ]  Finishing task: attempt_local1166193341_0010_m_000000_0
2020-11-19 16:27:15  [ Thread-288:15041 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:15  [ Thread-288:15042 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:15  [ pool-33-thread-1:15042 ] - [ INFO ]  Starting task: attempt_local1166193341_0010_r_000000_0
2020-11-19 16:27:15  [ pool-33-thread-1:15042 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:15  [ pool-33-thread-1:15042 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:15  [ pool-33-thread-1:15042 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:15  [ pool-33-thread-1:15042 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a9ff27d
2020-11-19 16:27:15  [ pool-33-thread-1:15043 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:15  [ EventFetcher for fetching Map Completion Events:15043 ] - [ INFO ]  attempt_local1166193341_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:15  [ localfetcher#10:15044 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1166193341_0010_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:15  [ localfetcher#10:15044 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1166193341_0010_m_000000_0
2020-11-19 16:27:15  [ localfetcher#10:15044 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:15  [ EventFetcher for fetching Map Completion Events:15044 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:15  [ pool-33-thread-1:15044 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:15  [ pool-33-thread-1:15044 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:15  [ pool-33-thread-1:15045 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:15  [ pool-33-thread-1:15045 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:15  [ pool-33-thread-1:15045 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:15  [ pool-33-thread-1:15046 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:15  [ pool-33-thread-1:15046 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:15  [ pool-33-thread-1:15046 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:15  [ pool-33-thread-1:15046 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:15  [ pool-33-thread-1:15046 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:15  [ pool-33-thread-1:15090 ] - [ INFO ]  Task:attempt_local1166193341_0010_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:15  [ pool-33-thread-1:15096 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:15  [ pool-33-thread-1:15096 ] - [ INFO ]  Task attempt_local1166193341_0010_r_000000_0 is allowed to commit now
2020-11-19 16:27:15  [ pool-33-thread-1:15119 ] - [ INFO ]  Saved output of task 'attempt_local1166193341_0010_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1166193341_0010_r_000000
2020-11-19 16:27:15  [ pool-33-thread-1:15120 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:15  [ pool-33-thread-1:15120 ] - [ INFO ]  Task 'attempt_local1166193341_0010_r_000000_0' done.
2020-11-19 16:27:15  [ pool-33-thread-1:15120 ] - [ INFO ]  Finishing task: attempt_local1166193341_0010_r_000000_0
2020-11-19 16:27:15  [ Thread-288:15120 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:16  [ main:15938 ] - [ INFO ]  Job job_local1166193341_0010 running in uber mode : false
2020-11-19 16:27:16  [ main:15939 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:16  [ main:15939 ] - [ INFO ]  Job job_local1166193341_0010 completed successfully
2020-11-19 16:27:16  [ main:15941 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=88374
		FILE: Number of bytes written=5780739
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=641122
		HDFS: Number of bytes written=9502
		HDFS: Number of read operations=605
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=200
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1072693248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:17  [ main:17022 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:17  [ main:17038 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:17  [ main:17042 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:17  [ main:17050 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:17  [ main:17091 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:17  [ main:17108 ] - [ INFO ]  Submitting tokens for job: job_local1783691694_0011
2020-11-19 16:27:17  [ main:17143 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:17  [ main:17143 ] - [ INFO ]  Running job: job_local1783691694_0011
2020-11-19 16:27:17  [ Thread-318:17143 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:17  [ Thread-318:17143 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:17  [ Thread-318:17143 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:17  [ Thread-318:17152 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17152 ] - [ INFO ]  Starting task: attempt_local1783691694_0011_m_000000_0
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17153 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17153 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17153 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17154 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17163 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17163 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17163 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17163 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17163 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17163 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17298 ] - [ INFO ]  
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17298 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17298 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17298 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17298 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17301 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17302 ] - [ INFO ]  Task:attempt_local1783691694_0011_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17400 ] - [ INFO ]  map
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17400 ] - [ INFO ]  Task 'attempt_local1783691694_0011_m_000000_0' done.
2020-11-19 16:27:17  [ LocalJobRunner Map Task Executor #0:17400 ] - [ INFO ]  Finishing task: attempt_local1783691694_0011_m_000000_0
2020-11-19 16:27:17  [ Thread-318:17400 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:17  [ Thread-318:17401 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:17  [ pool-36-thread-1:17401 ] - [ INFO ]  Starting task: attempt_local1783691694_0011_r_000000_0
2020-11-19 16:27:17  [ pool-36-thread-1:17401 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:17  [ pool-36-thread-1:17401 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:17  [ pool-36-thread-1:17401 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:17  [ pool-36-thread-1:17401 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63d3892b
2020-11-19 16:27:17  [ pool-36-thread-1:17402 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:17  [ EventFetcher for fetching Map Completion Events:17402 ] - [ INFO ]  attempt_local1783691694_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:17  [ localfetcher#11:17403 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local1783691694_0011_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:17  [ localfetcher#11:17403 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1783691694_0011_m_000000_0
2020-11-19 16:27:17  [ localfetcher#11:17403 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:17  [ EventFetcher for fetching Map Completion Events:17404 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:17  [ pool-36-thread-1:17404 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:17  [ pool-36-thread-1:17405 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:17  [ pool-36-thread-1:17406 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:17  [ pool-36-thread-1:17406 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:17  [ pool-36-thread-1:17406 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:17  [ pool-36-thread-1:17406 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:17  [ pool-36-thread-1:17406 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:17  [ pool-36-thread-1:17407 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:17  [ pool-36-thread-1:17407 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:17  [ pool-36-thread-1:17407 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:18  [ pool-36-thread-1:17782 ] - [ INFO ]  Task:attempt_local1783691694_0011_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:18  [ pool-36-thread-1:17793 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:18  [ pool-36-thread-1:17793 ] - [ INFO ]  Task attempt_local1783691694_0011_r_000000_0 is allowed to commit now
2020-11-19 16:27:18  [ pool-36-thread-1:17825 ] - [ INFO ]  Saved output of task 'attempt_local1783691694_0011_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1783691694_0011_r_000000
2020-11-19 16:27:18  [ pool-36-thread-1:17825 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:18  [ pool-36-thread-1:17825 ] - [ INFO ]  Task 'attempt_local1783691694_0011_r_000000_0' done.
2020-11-19 16:27:18  [ pool-36-thread-1:17825 ] - [ INFO ]  Finishing task: attempt_local1783691694_0011_r_000000_0
2020-11-19 16:27:18  [ Thread-318:17825 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:18  [ main:18147 ] - [ INFO ]  Job job_local1783691694_0011 running in uber mode : false
2020-11-19 16:27:18  [ main:18147 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:18  [ main:18147 ] - [ INFO ]  Job job_local1783691694_0011 completed successfully
2020-11-19 16:27:18  [ main:18148 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=89572
		FILE: Number of bytes written=6352663
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=705512
		HDFS: Number of bytes written=10573
		HDFS: Number of read operations=673
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=222
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1202716672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:19  [ main:18745 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:19  [ main:18757 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:19  [ main:18762 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:19  [ main:18767 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:19  [ main:18803 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:19  [ main:18821 ] - [ INFO ]  Submitting tokens for job: job_local1089251610_0012
2020-11-19 16:27:19  [ main:18856 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:19  [ main:18856 ] - [ INFO ]  Running job: job_local1089251610_0012
2020-11-19 16:27:19  [ Thread-348:18856 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:19  [ Thread-348:18856 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:19  [ Thread-348:18856 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:19  [ Thread-348:18869 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18869 ] - [ INFO ]  Starting task: attempt_local1089251610_0012_m_000000_0
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18869 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18869 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18869 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18870 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18905 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18905 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18905 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18905 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18905 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18905 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18982 ] - [ INFO ]  
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18982 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18982 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18982 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18982 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18986 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18987 ] - [ INFO ]  Task:attempt_local1089251610_0012_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18993 ] - [ INFO ]  map
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18993 ] - [ INFO ]  Task 'attempt_local1089251610_0012_m_000000_0' done.
2020-11-19 16:27:19  [ LocalJobRunner Map Task Executor #0:18993 ] - [ INFO ]  Finishing task: attempt_local1089251610_0012_m_000000_0
2020-11-19 16:27:19  [ Thread-348:18993 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:19  [ Thread-348:18993 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:19  [ pool-39-thread-1:18993 ] - [ INFO ]  Starting task: attempt_local1089251610_0012_r_000000_0
2020-11-19 16:27:19  [ pool-39-thread-1:18994 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:19  [ pool-39-thread-1:18994 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:19  [ pool-39-thread-1:18994 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:19  [ pool-39-thread-1:18994 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51c2d22e
2020-11-19 16:27:19  [ pool-39-thread-1:18994 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:19  [ EventFetcher for fetching Map Completion Events:18995 ] - [ INFO ]  attempt_local1089251610_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:19  [ localfetcher#12:18995 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local1089251610_0012_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:19  [ localfetcher#12:18995 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1089251610_0012_m_000000_0
2020-11-19 16:27:19  [ localfetcher#12:18996 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:19  [ EventFetcher for fetching Map Completion Events:18996 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:19  [ pool-39-thread-1:18996 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:19  [ pool-39-thread-1:18996 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:19  [ pool-39-thread-1:18997 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:19  [ pool-39-thread-1:18997 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:19  [ pool-39-thread-1:18997 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:19  [ pool-39-thread-1:18998 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:19  [ pool-39-thread-1:18998 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:19  [ pool-39-thread-1:18998 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:19  [ pool-39-thread-1:18998 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:19  [ pool-39-thread-1:18998 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:19  [ pool-39-thread-1:19052 ] - [ INFO ]  Task:attempt_local1089251610_0012_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:19  [ pool-39-thread-1:19058 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:19  [ pool-39-thread-1:19058 ] - [ INFO ]  Task attempt_local1089251610_0012_r_000000_0 is allowed to commit now
2020-11-19 16:27:19  [ pool-39-thread-1:19078 ] - [ INFO ]  Saved output of task 'attempt_local1089251610_0012_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1089251610_0012_r_000000
2020-11-19 16:27:19  [ pool-39-thread-1:19079 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:19  [ pool-39-thread-1:19079 ] - [ INFO ]  Task 'attempt_local1089251610_0012_r_000000_0' done.
2020-11-19 16:27:19  [ pool-39-thread-1:19079 ] - [ INFO ]  Finishing task: attempt_local1089251610_0012_r_000000_0
2020-11-19 16:27:19  [ Thread-348:19079 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:20  [ main:19859 ] - [ INFO ]  Job job_local1089251610_0012 running in uber mode : false
2020-11-19 16:27:20  [ main:19860 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:20  [ main:19860 ] - [ INFO ]  Job job_local1089251610_0012 completed successfully
2020-11-19 16:27:20  [ main:19861 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=90772
		FILE: Number of bytes written=6924598
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=769922
		HDFS: Number of bytes written=11656
		HDFS: Number of read operations=741
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=244
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1202716672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:20  [ main:20194 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:20  [ main:20205 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:20  [ main:20209 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:20  [ main:20217 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:20  [ main:20263 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:20  [ main:20283 ] - [ INFO ]  Submitting tokens for job: job_local492642133_0013
2020-11-19 16:27:20  [ main:20330 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:20  [ main:20330 ] - [ INFO ]  Running job: job_local492642133_0013
2020-11-19 16:27:20  [ Thread-378:20330 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:20  [ Thread-378:20331 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:20  [ Thread-378:20331 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:20  [ Thread-378:20337 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20337 ] - [ INFO ]  Starting task: attempt_local492642133_0013_m_000000_0
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20338 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20338 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20338 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20339 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20346 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20346 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20346 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20346 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20346 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20346 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20428 ] - [ INFO ]  
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20428 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20428 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20428 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20428 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20432 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20433 ] - [ INFO ]  Task:attempt_local492642133_0013_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20440 ] - [ INFO ]  map
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20440 ] - [ INFO ]  Task 'attempt_local492642133_0013_m_000000_0' done.
2020-11-19 16:27:20  [ LocalJobRunner Map Task Executor #0:20440 ] - [ INFO ]  Finishing task: attempt_local492642133_0013_m_000000_0
2020-11-19 16:27:20  [ Thread-378:20440 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:20  [ Thread-378:20441 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:20  [ pool-42-thread-1:20441 ] - [ INFO ]  Starting task: attempt_local492642133_0013_r_000000_0
2020-11-19 16:27:20  [ pool-42-thread-1:20442 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:20  [ pool-42-thread-1:20442 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:20  [ pool-42-thread-1:20442 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:20  [ pool-42-thread-1:20442 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7384685b
2020-11-19 16:27:20  [ pool-42-thread-1:20442 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:20  [ EventFetcher for fetching Map Completion Events:20443 ] - [ INFO ]  attempt_local492642133_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:20  [ localfetcher#13:20443 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local492642133_0013_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:20  [ localfetcher#13:20443 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local492642133_0013_m_000000_0
2020-11-19 16:27:20  [ localfetcher#13:20444 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:20  [ EventFetcher for fetching Map Completion Events:20444 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:20  [ pool-42-thread-1:20444 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:20  [ pool-42-thread-1:20444 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:20  [ pool-42-thread-1:20445 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:20  [ pool-42-thread-1:20445 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:20  [ pool-42-thread-1:20446 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:20  [ pool-42-thread-1:20446 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:20  [ pool-42-thread-1:20446 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:20  [ pool-42-thread-1:20446 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:20  [ pool-42-thread-1:20446 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:20  [ pool-42-thread-1:20446 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:20  [ pool-42-thread-1:20505 ] - [ INFO ]  Task:attempt_local492642133_0013_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:20  [ pool-42-thread-1:20511 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:20  [ pool-42-thread-1:20511 ] - [ INFO ]  Task attempt_local492642133_0013_r_000000_0 is allowed to commit now
2020-11-19 16:27:20  [ pool-42-thread-1:20527 ] - [ INFO ]  Saved output of task 'attempt_local492642133_0013_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local492642133_0013_r_000000
2020-11-19 16:27:20  [ pool-42-thread-1:20528 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:20  [ pool-42-thread-1:20528 ] - [ INFO ]  Task 'attempt_local492642133_0013_r_000000_0' done.
2020-11-19 16:27:20  [ pool-42-thread-1:20528 ] - [ INFO ]  Finishing task: attempt_local492642133_0013_r_000000_0
2020-11-19 16:27:20  [ Thread-378:20528 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:21  [ main:21331 ] - [ INFO ]  Job job_local492642133_0013 running in uber mode : false
2020-11-19 16:27:21  [ main:21331 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:21  [ main:21332 ] - [ INFO ]  Job job_local492642133_0013 completed successfully
2020-11-19 16:27:21  [ main:21333 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=91968
		FILE: Number of bytes written=7493473
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=834314
		HDFS: Number of bytes written=12726
		HDFS: Number of read operations=809
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=266
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1222639616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:22  [ main:21593 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:22  [ main:21604 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:22  [ main:21608 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:22  [ main:21614 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:22  [ main:21651 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:22  [ main:21669 ] - [ INFO ]  Submitting tokens for job: job_local968884222_0014
2020-11-19 16:27:22  [ main:21706 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:22  [ main:21706 ] - [ INFO ]  Running job: job_local968884222_0014
2020-11-19 16:27:22  [ Thread-408:21706 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:22  [ Thread-408:21706 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:22  [ Thread-408:21706 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:22  [ Thread-408:21714 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21714 ] - [ INFO ]  Starting task: attempt_local968884222_0014_m_000000_0
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21714 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21714 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21714 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21715 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21724 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21724 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21724 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21724 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21724 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21725 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21804 ] - [ INFO ]  
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21804 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21804 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21804 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21804 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21806 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21807 ] - [ INFO ]  Task:attempt_local968884222_0014_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21814 ] - [ INFO ]  map
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21814 ] - [ INFO ]  Task 'attempt_local968884222_0014_m_000000_0' done.
2020-11-19 16:27:22  [ LocalJobRunner Map Task Executor #0:21814 ] - [ INFO ]  Finishing task: attempt_local968884222_0014_m_000000_0
2020-11-19 16:27:22  [ Thread-408:21814 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:22  [ Thread-408:21814 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:22  [ pool-45-thread-1:21814 ] - [ INFO ]  Starting task: attempt_local968884222_0014_r_000000_0
2020-11-19 16:27:22  [ pool-45-thread-1:21815 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:22  [ pool-45-thread-1:21815 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:22  [ pool-45-thread-1:21815 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:22  [ pool-45-thread-1:21815 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@60c4a17b
2020-11-19 16:27:22  [ pool-45-thread-1:21815 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:22  [ EventFetcher for fetching Map Completion Events:21816 ] - [ INFO ]  attempt_local968884222_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:22  [ localfetcher#14:21816 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local968884222_0014_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:22  [ localfetcher#14:21816 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local968884222_0014_m_000000_0
2020-11-19 16:27:22  [ localfetcher#14:21816 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:22  [ EventFetcher for fetching Map Completion Events:21817 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:22  [ pool-45-thread-1:21817 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:22  [ pool-45-thread-1:21817 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:22  [ pool-45-thread-1:21818 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:22  [ pool-45-thread-1:21819 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:22  [ pool-45-thread-1:21864 ] - [ INFO ]  Task:attempt_local968884222_0014_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:22  [ pool-45-thread-1:21871 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:22  [ pool-45-thread-1:21871 ] - [ INFO ]  Task attempt_local968884222_0014_r_000000_0 is allowed to commit now
2020-11-19 16:27:22  [ pool-45-thread-1:21889 ] - [ INFO ]  Saved output of task 'attempt_local968884222_0014_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local968884222_0014_r_000000
2020-11-19 16:27:22  [ pool-45-thread-1:21889 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:22  [ pool-45-thread-1:21890 ] - [ INFO ]  Task 'attempt_local968884222_0014_r_000000_0' done.
2020-11-19 16:27:22  [ pool-45-thread-1:21890 ] - [ INFO ]  Finishing task: attempt_local968884222_0014_r_000000_0
2020-11-19 16:27:22  [ Thread-408:21890 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:23  [ main:22707 ] - [ INFO ]  Job job_local968884222_0014 running in uber mode : false
2020-11-19 16:27:23  [ main:22707 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:23  [ main:22707 ] - [ INFO ]  Job job_local968884222_0014 completed successfully
2020-11-19 16:27:23  [ main:22709 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=93162
		FILE: Number of bytes written=8062355
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=898716
		HDFS: Number of bytes written=13804
		HDFS: Number of read operations=877
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=288
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1222639616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:23  [ main:23131 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:23  [ main:23141 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:23  [ main:23145 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:23  [ main:23151 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:23  [ main:23189 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:23  [ main:23209 ] - [ INFO ]  Submitting tokens for job: job_local731125044_0015
2020-11-19 16:27:23  [ main:23249 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:23  [ main:23249 ] - [ INFO ]  Running job: job_local731125044_0015
2020-11-19 16:27:23  [ Thread-438:23249 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:23  [ Thread-438:23249 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:23  [ Thread-438:23249 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:23  [ Thread-438:23259 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23259 ] - [ INFO ]  Starting task: attempt_local731125044_0015_m_000000_0
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23259 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23259 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23259 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23260 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23269 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23269 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23269 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23269 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23269 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23269 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23335 ] - [ INFO ]  
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23336 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23336 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23336 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23336 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23339 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23339 ] - [ INFO ]  Task:attempt_local731125044_0015_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23345 ] - [ INFO ]  map
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23345 ] - [ INFO ]  Task 'attempt_local731125044_0015_m_000000_0' done.
2020-11-19 16:27:23  [ LocalJobRunner Map Task Executor #0:23345 ] - [ INFO ]  Finishing task: attempt_local731125044_0015_m_000000_0
2020-11-19 16:27:23  [ Thread-438:23345 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:23  [ Thread-438:23345 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:23  [ pool-48-thread-1:23346 ] - [ INFO ]  Starting task: attempt_local731125044_0015_r_000000_0
2020-11-19 16:27:23  [ pool-48-thread-1:23346 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:23  [ pool-48-thread-1:23346 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:23  [ pool-48-thread-1:23346 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:23  [ pool-48-thread-1:23346 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4079aa98
2020-11-19 16:27:23  [ pool-48-thread-1:23346 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:23  [ EventFetcher for fetching Map Completion Events:23347 ] - [ INFO ]  attempt_local731125044_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:23  [ localfetcher#15:23347 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local731125044_0015_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:23  [ localfetcher#15:23347 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local731125044_0015_m_000000_0
2020-11-19 16:27:23  [ localfetcher#15:23347 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:23  [ EventFetcher for fetching Map Completion Events:23348 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:23  [ pool-48-thread-1:23348 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:23  [ pool-48-thread-1:23348 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:23  [ pool-48-thread-1:23348 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:23  [ pool-48-thread-1:23348 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:23  [ pool-48-thread-1:23349 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:23  [ pool-48-thread-1:23349 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:23  [ pool-48-thread-1:23349 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:23  [ pool-48-thread-1:23349 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:23  [ pool-48-thread-1:23349 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:23  [ pool-48-thread-1:23349 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:23  [ pool-48-thread-1:23404 ] - [ INFO ]  Task:attempt_local731125044_0015_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:23  [ pool-48-thread-1:23409 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:23  [ pool-48-thread-1:23409 ] - [ INFO ]  Task attempt_local731125044_0015_r_000000_0 is allowed to commit now
2020-11-19 16:27:23  [ pool-48-thread-1:23428 ] - [ INFO ]  Saved output of task 'attempt_local731125044_0015_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local731125044_0015_r_000000
2020-11-19 16:27:23  [ pool-48-thread-1:23428 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:23  [ pool-48-thread-1:23428 ] - [ INFO ]  Task 'attempt_local731125044_0015_r_000000_0' done.
2020-11-19 16:27:23  [ pool-48-thread-1:23428 ] - [ INFO ]  Finishing task: attempt_local731125044_0015_r_000000_0
2020-11-19 16:27:23  [ Thread-438:23428 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:24  [ main:24251 ] - [ INFO ]  Job job_local731125044_0015 running in uber mode : false
2020-11-19 16:27:24  [ main:24251 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:24  [ main:24251 ] - [ INFO ]  Job job_local731125044_0015 completed successfully
2020-11-19 16:27:24  [ main:24252 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=94360
		FILE: Number of bytes written=8631235
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=963106
		HDFS: Number of bytes written=14875
		HDFS: Number of read operations=945
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=310
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1349517312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:25  [ main:25308 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:25  [ main:25326 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:25  [ main:25331 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:25  [ main:25338 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:25  [ main:25380 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:25  [ main:25397 ] - [ INFO ]  Submitting tokens for job: job_local312034766_0016
2020-11-19 16:27:25  [ main:25431 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:25  [ main:25432 ] - [ INFO ]  Running job: job_local312034766_0016
2020-11-19 16:27:25  [ Thread-468:25432 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:25  [ Thread-468:25432 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:25  [ Thread-468:25432 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:25  [ Thread-468:25441 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25441 ] - [ INFO ]  Starting task: attempt_local312034766_0016_m_000000_0
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25442 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25442 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25442 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25443 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25453 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25453 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25453 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25453 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25453 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25453 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25541 ] - [ INFO ]  
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25541 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25541 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25541 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25541 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25543 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25544 ] - [ INFO ]  Task:attempt_local312034766_0016_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25551 ] - [ INFO ]  map
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25551 ] - [ INFO ]  Task 'attempt_local312034766_0016_m_000000_0' done.
2020-11-19 16:27:25  [ LocalJobRunner Map Task Executor #0:25551 ] - [ INFO ]  Finishing task: attempt_local312034766_0016_m_000000_0
2020-11-19 16:27:25  [ Thread-468:25551 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:25  [ Thread-468:25552 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:25  [ pool-51-thread-1:25552 ] - [ INFO ]  Starting task: attempt_local312034766_0016_r_000000_0
2020-11-19 16:27:25  [ pool-51-thread-1:25552 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:25  [ pool-51-thread-1:25552 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:25  [ pool-51-thread-1:25552 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:25  [ pool-51-thread-1:25553 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@570eca28
2020-11-19 16:27:25  [ pool-51-thread-1:25553 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:25  [ EventFetcher for fetching Map Completion Events:25553 ] - [ INFO ]  attempt_local312034766_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:25  [ localfetcher#16:25554 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local312034766_0016_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:25  [ localfetcher#16:25554 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local312034766_0016_m_000000_0
2020-11-19 16:27:25  [ localfetcher#16:25554 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:25  [ EventFetcher for fetching Map Completion Events:25554 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:25  [ pool-51-thread-1:25555 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:25  [ pool-51-thread-1:25555 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:25  [ pool-51-thread-1:25555 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:25  [ pool-51-thread-1:25555 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:26  [ pool-51-thread-1:25556 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:26  [ pool-51-thread-1:25556 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:26  [ pool-51-thread-1:25556 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:26  [ pool-51-thread-1:25556 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:26  [ pool-51-thread-1:25556 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:26  [ pool-51-thread-1:25556 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:26  [ pool-51-thread-1:25620 ] - [ INFO ]  Task:attempt_local312034766_0016_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:26  [ pool-51-thread-1:25626 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:26  [ pool-51-thread-1:25626 ] - [ INFO ]  Task attempt_local312034766_0016_r_000000_0 is allowed to commit now
2020-11-19 16:27:26  [ pool-51-thread-1:25644 ] - [ INFO ]  Saved output of task 'attempt_local312034766_0016_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local312034766_0016_r_000000
2020-11-19 16:27:26  [ pool-51-thread-1:25645 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:26  [ pool-51-thread-1:25645 ] - [ INFO ]  Task 'attempt_local312034766_0016_r_000000_0' done.
2020-11-19 16:27:26  [ pool-51-thread-1:25645 ] - [ INFO ]  Finishing task: attempt_local312034766_0016_r_000000_0
2020-11-19 16:27:26  [ Thread-468:25645 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:26  [ main:26432 ] - [ INFO ]  Job job_local312034766_0016 running in uber mode : false
2020-11-19 16:27:26  [ main:26432 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:26  [ main:26432 ] - [ INFO ]  Job job_local312034766_0016 completed successfully
2020-11-19 16:27:26  [ main:26433 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=95560
		FILE: Number of bytes written=9200122
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1027516
		HDFS: Number of bytes written=15958
		HDFS: Number of read operations=1013
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=332
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1349517312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:27  [ main:26691 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:27  [ main:26704 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:27  [ main:26708 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:27  [ main:26713 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:27  [ main:26750 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:27  [ main:26768 ] - [ INFO ]  Submitting tokens for job: job_local858013005_0017
2020-11-19 16:27:27  [ main:26810 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:27  [ main:26810 ] - [ INFO ]  Running job: job_local858013005_0017
2020-11-19 16:27:27  [ Thread-498:26810 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:27  [ Thread-498:26810 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:27  [ Thread-498:26811 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:27  [ Thread-498:26818 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26818 ] - [ INFO ]  Starting task: attempt_local858013005_0017_m_000000_0
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26819 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26819 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26819 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26819 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26829 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26829 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26829 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26829 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26829 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26830 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26908 ] - [ INFO ]  
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26908 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26908 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26908 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26908 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26910 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26911 ] - [ INFO ]  Task:attempt_local858013005_0017_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26917 ] - [ INFO ]  map
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26917 ] - [ INFO ]  Task 'attempt_local858013005_0017_m_000000_0' done.
2020-11-19 16:27:27  [ LocalJobRunner Map Task Executor #0:26917 ] - [ INFO ]  Finishing task: attempt_local858013005_0017_m_000000_0
2020-11-19 16:27:27  [ Thread-498:26918 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:27  [ Thread-498:26918 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:27  [ pool-54-thread-1:26918 ] - [ INFO ]  Starting task: attempt_local858013005_0017_r_000000_0
2020-11-19 16:27:27  [ pool-54-thread-1:26918 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:27  [ pool-54-thread-1:26919 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:27  [ pool-54-thread-1:26919 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:27  [ pool-54-thread-1:26919 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1774785d
2020-11-19 16:27:27  [ pool-54-thread-1:26919 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:27  [ EventFetcher for fetching Map Completion Events:26919 ] - [ INFO ]  attempt_local858013005_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:27  [ localfetcher#17:26920 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local858013005_0017_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:27  [ localfetcher#17:26920 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local858013005_0017_m_000000_0
2020-11-19 16:27:27  [ localfetcher#17:26920 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:27  [ EventFetcher for fetching Map Completion Events:26920 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:27  [ pool-54-thread-1:26921 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:27  [ pool-54-thread-1:26921 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:27  [ pool-54-thread-1:26921 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:27  [ pool-54-thread-1:26922 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:27  [ pool-54-thread-1:26984 ] - [ INFO ]  Task:attempt_local858013005_0017_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:27  [ pool-54-thread-1:26990 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:27  [ pool-54-thread-1:26990 ] - [ INFO ]  Task attempt_local858013005_0017_r_000000_0 is allowed to commit now
2020-11-19 16:27:27  [ pool-54-thread-1:27008 ] - [ INFO ]  Saved output of task 'attempt_local858013005_0017_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local858013005_0017_r_000000
2020-11-19 16:27:27  [ pool-54-thread-1:27008 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:27  [ pool-54-thread-1:27009 ] - [ INFO ]  Task 'attempt_local858013005_0017_r_000000_0' done.
2020-11-19 16:27:27  [ pool-54-thread-1:27009 ] - [ INFO ]  Finishing task: attempt_local858013005_0017_r_000000_0
2020-11-19 16:27:27  [ Thread-498:27009 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:28  [ main:27813 ] - [ INFO ]  Job job_local858013005_0017 running in uber mode : false
2020-11-19 16:27:28  [ main:27813 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:28  [ main:27813 ] - [ INFO ]  Job job_local858013005_0017 completed successfully
2020-11-19 16:27:28  [ main:27814 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=96756
		FILE: Number of bytes written=9768997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1091908
		HDFS: Number of bytes written=17028
		HDFS: Number of read operations=1081
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=354
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1373634560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:28  [ main:28193 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:28  [ main:28210 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:28  [ main:28214 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:28  [ main:28221 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:28  [ main:28262 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:28  [ main:28279 ] - [ INFO ]  Submitting tokens for job: job_local396498710_0018
2020-11-19 16:27:28  [ main:28313 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:28  [ main:28313 ] - [ INFO ]  Running job: job_local396498710_0018
2020-11-19 16:27:28  [ Thread-528:28314 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:28  [ Thread-528:28314 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:28  [ Thread-528:28314 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:28  [ Thread-528:28322 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28322 ] - [ INFO ]  Starting task: attempt_local396498710_0018_m_000000_0
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28323 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28323 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28323 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28324 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28332 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28332 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28332 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28332 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28332 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28332 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28401 ] - [ INFO ]  
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28401 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28401 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28401 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28401 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28403 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28404 ] - [ INFO ]  Task:attempt_local396498710_0018_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28412 ] - [ INFO ]  map
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28412 ] - [ INFO ]  Task 'attempt_local396498710_0018_m_000000_0' done.
2020-11-19 16:27:28  [ LocalJobRunner Map Task Executor #0:28412 ] - [ INFO ]  Finishing task: attempt_local396498710_0018_m_000000_0
2020-11-19 16:27:28  [ Thread-528:28412 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:28  [ Thread-528:28412 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:28  [ pool-57-thread-1:28412 ] - [ INFO ]  Starting task: attempt_local396498710_0018_r_000000_0
2020-11-19 16:27:28  [ pool-57-thread-1:28413 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:28  [ pool-57-thread-1:28413 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:28  [ pool-57-thread-1:28413 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:28  [ pool-57-thread-1:28413 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44196bbf
2020-11-19 16:27:28  [ pool-57-thread-1:28413 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:28  [ EventFetcher for fetching Map Completion Events:28413 ] - [ INFO ]  attempt_local396498710_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:28  [ localfetcher#18:28414 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local396498710_0018_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:28  [ localfetcher#18:28414 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local396498710_0018_m_000000_0
2020-11-19 16:27:28  [ localfetcher#18:28414 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:28  [ EventFetcher for fetching Map Completion Events:28415 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:28  [ pool-57-thread-1:28415 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:28  [ pool-57-thread-1:28415 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:28  [ pool-57-thread-1:28416 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:28  [ pool-57-thread-1:28416 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:28  [ pool-57-thread-1:28416 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:28  [ pool-57-thread-1:28417 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:28  [ pool-57-thread-1:28417 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:28  [ pool-57-thread-1:28417 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:28  [ pool-57-thread-1:28417 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:28  [ pool-57-thread-1:28417 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:28  [ pool-57-thread-1:28480 ] - [ INFO ]  Task:attempt_local396498710_0018_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:28  [ pool-57-thread-1:28486 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:28  [ pool-57-thread-1:28486 ] - [ INFO ]  Task attempt_local396498710_0018_r_000000_0 is allowed to commit now
2020-11-19 16:27:28  [ pool-57-thread-1:28505 ] - [ INFO ]  Saved output of task 'attempt_local396498710_0018_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local396498710_0018_r_000000
2020-11-19 16:27:28  [ pool-57-thread-1:28506 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:28  [ pool-57-thread-1:28506 ] - [ INFO ]  Task 'attempt_local396498710_0018_r_000000_0' done.
2020-11-19 16:27:28  [ pool-57-thread-1:28506 ] - [ INFO ]  Finishing task: attempt_local396498710_0018_r_000000_0
2020-11-19 16:27:28  [ Thread-528:28506 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:29  [ main:29314 ] - [ INFO ]  Job job_local396498710_0018 running in uber mode : false
2020-11-19 16:27:29  [ main:29315 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:29  [ main:29315 ] - [ INFO ]  Job job_local396498710_0018 completed successfully
2020-11-19 16:27:29  [ main:29316 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=97950
		FILE: Number of bytes written=10337879
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1156310
		HDFS: Number of bytes written=18106
		HDFS: Number of read operations=1149
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=376
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1373634560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:30  [ main:29773 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:30  [ main:29786 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:30  [ main:29791 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:30  [ main:29799 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:30  [ main:29844 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:30  [ main:29862 ] - [ INFO ]  Submitting tokens for job: job_local1020265790_0019
2020-11-19 16:27:30  [ main:29896 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:30  [ main:29896 ] - [ INFO ]  Running job: job_local1020265790_0019
2020-11-19 16:27:30  [ Thread-558:29897 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:30  [ Thread-558:29897 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:30  [ Thread-558:29897 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:30  [ Thread-558:29906 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29906 ] - [ INFO ]  Starting task: attempt_local1020265790_0019_m_000000_0
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29906 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29907 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29907 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29907 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29916 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29917 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29917 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29917 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29917 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:29917 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30001 ] - [ INFO ]  
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30001 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30001 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30001 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30001 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30003 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30004 ] - [ INFO ]  Task:attempt_local1020265790_0019_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30012 ] - [ INFO ]  map
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30012 ] - [ INFO ]  Task 'attempt_local1020265790_0019_m_000000_0' done.
2020-11-19 16:27:30  [ LocalJobRunner Map Task Executor #0:30012 ] - [ INFO ]  Finishing task: attempt_local1020265790_0019_m_000000_0
2020-11-19 16:27:30  [ Thread-558:30012 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:30  [ Thread-558:30012 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:30  [ pool-60-thread-1:30012 ] - [ INFO ]  Starting task: attempt_local1020265790_0019_r_000000_0
2020-11-19 16:27:30  [ pool-60-thread-1:30013 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:30  [ pool-60-thread-1:30013 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:30  [ pool-60-thread-1:30013 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:30  [ pool-60-thread-1:30013 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77cff7de
2020-11-19 16:27:30  [ pool-60-thread-1:30014 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:30  [ EventFetcher for fetching Map Completion Events:30014 ] - [ INFO ]  attempt_local1020265790_0019_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:30  [ localfetcher#19:30015 ] - [ INFO ]  localfetcher#19 about to shuffle output of map attempt_local1020265790_0019_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:30  [ localfetcher#19:30015 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1020265790_0019_m_000000_0
2020-11-19 16:27:30  [ localfetcher#19:30015 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:30  [ EventFetcher for fetching Map Completion Events:30015 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:30  [ pool-60-thread-1:30016 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:30  [ pool-60-thread-1:30016 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:30  [ pool-60-thread-1:30017 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:30  [ pool-60-thread-1:30018 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:30  [ pool-60-thread-1:30070 ] - [ INFO ]  Task:attempt_local1020265790_0019_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:30  [ pool-60-thread-1:30077 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:30  [ pool-60-thread-1:30077 ] - [ INFO ]  Task attempt_local1020265790_0019_r_000000_0 is allowed to commit now
2020-11-19 16:27:30  [ pool-60-thread-1:30103 ] - [ INFO ]  Saved output of task 'attempt_local1020265790_0019_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1020265790_0019_r_000000
2020-11-19 16:27:30  [ pool-60-thread-1:30103 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:30  [ pool-60-thread-1:30103 ] - [ INFO ]  Task 'attempt_local1020265790_0019_r_000000_0' done.
2020-11-19 16:27:30  [ pool-60-thread-1:30103 ] - [ INFO ]  Finishing task: attempt_local1020265790_0019_r_000000_0
2020-11-19 16:27:30  [ Thread-558:30103 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:31  [ main:30901 ] - [ INFO ]  Job job_local1020265790_0019 running in uber mode : false
2020-11-19 16:27:31  [ main:30901 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:31  [ main:30902 ] - [ INFO ]  Job job_local1020265790_0019 completed successfully
2020-11-19 16:27:31  [ main:30903 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=99148
		FILE: Number of bytes written=10909807
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1220700
		HDFS: Number of bytes written=19177
		HDFS: Number of read operations=1217
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=398
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1482686464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:31  [ main:31209 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:31  [ main:31220 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:31  [ main:31225 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:31  [ main:31230 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:31  [ main:31268 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:31  [ main:31285 ] - [ INFO ]  Submitting tokens for job: job_local271846268_0020
2020-11-19 16:27:31  [ main:31320 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:31  [ main:31320 ] - [ INFO ]  Running job: job_local271846268_0020
2020-11-19 16:27:31  [ Thread-588:31320 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:31  [ Thread-588:31321 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:31  [ Thread-588:31321 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:31  [ Thread-588:31328 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31328 ] - [ INFO ]  Starting task: attempt_local271846268_0020_m_000000_0
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31329 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31329 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31329 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31330 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31337 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31337 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31337 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31337 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31337 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31337 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31420 ] - [ INFO ]  
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31420 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31420 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31420 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31420 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31423 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31423 ] - [ INFO ]  Task:attempt_local271846268_0020_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31429 ] - [ INFO ]  map
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31429 ] - [ INFO ]  Task 'attempt_local271846268_0020_m_000000_0' done.
2020-11-19 16:27:31  [ LocalJobRunner Map Task Executor #0:31429 ] - [ INFO ]  Finishing task: attempt_local271846268_0020_m_000000_0
2020-11-19 16:27:31  [ Thread-588:31429 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:31  [ Thread-588:31429 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:31  [ pool-63-thread-1:31429 ] - [ INFO ]  Starting task: attempt_local271846268_0020_r_000000_0
2020-11-19 16:27:31  [ pool-63-thread-1:31430 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:31  [ pool-63-thread-1:31430 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:31  [ pool-63-thread-1:31430 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:31  [ pool-63-thread-1:31430 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ad66b73
2020-11-19 16:27:31  [ pool-63-thread-1:31430 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:31  [ EventFetcher for fetching Map Completion Events:31431 ] - [ INFO ]  attempt_local271846268_0020_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:31  [ localfetcher#20:31431 ] - [ INFO ]  localfetcher#20 about to shuffle output of map attempt_local271846268_0020_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:31  [ localfetcher#20:31431 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local271846268_0020_m_000000_0
2020-11-19 16:27:31  [ localfetcher#20:31431 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:31  [ EventFetcher for fetching Map Completion Events:31432 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:31  [ pool-63-thread-1:31432 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:31  [ pool-63-thread-1:31432 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:31  [ pool-63-thread-1:31432 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:31  [ pool-63-thread-1:31433 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:31  [ pool-63-thread-1:31479 ] - [ INFO ]  Task:attempt_local271846268_0020_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:31  [ pool-63-thread-1:31486 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:31  [ pool-63-thread-1:31486 ] - [ INFO ]  Task attempt_local271846268_0020_r_000000_0 is allowed to commit now
2020-11-19 16:27:31  [ pool-63-thread-1:31504 ] - [ INFO ]  Saved output of task 'attempt_local271846268_0020_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local271846268_0020_r_000000
2020-11-19 16:27:31  [ pool-63-thread-1:31504 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:31  [ pool-63-thread-1:31504 ] - [ INFO ]  Task 'attempt_local271846268_0020_r_000000_0' done.
2020-11-19 16:27:31  [ pool-63-thread-1:31504 ] - [ INFO ]  Finishing task: attempt_local271846268_0020_r_000000_0
2020-11-19 16:27:31  [ Thread-588:31504 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:32  [ main:32325 ] - [ INFO ]  Job job_local271846268_0020 running in uber mode : false
2020-11-19 16:27:32  [ main:32325 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:32  [ main:32325 ] - [ INFO ]  Job job_local271846268_0020 completed successfully
2020-11-19 16:27:32  [ main:32326 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=100348
		FILE: Number of bytes written=11478694
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1285110
		HDFS: Number of bytes written=20260
		HDFS: Number of read operations=1285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=420
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1482686464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:33  [ main:32599 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:33  [ main:32612 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:33  [ main:32616 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:33  [ main:32628 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:33  [ main:32662 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:33  [ main:32680 ] - [ INFO ]  Submitting tokens for job: job_local124952742_0021
2020-11-19 16:27:33  [ main:32717 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:33  [ main:32717 ] - [ INFO ]  Running job: job_local124952742_0021
2020-11-19 16:27:33  [ Thread-618:32717 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:33  [ Thread-618:32717 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:33  [ Thread-618:32717 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:33  [ Thread-618:32726 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32726 ] - [ INFO ]  Starting task: attempt_local124952742_0021_m_000000_0
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32727 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32727 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32727 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32727 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32787 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32788 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32788 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32788 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32788 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32788 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32872 ] - [ INFO ]  
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32872 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32872 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32872 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32872 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32875 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32876 ] - [ INFO ]  Task:attempt_local124952742_0021_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32882 ] - [ INFO ]  map
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32882 ] - [ INFO ]  Task 'attempt_local124952742_0021_m_000000_0' done.
2020-11-19 16:27:33  [ LocalJobRunner Map Task Executor #0:32882 ] - [ INFO ]  Finishing task: attempt_local124952742_0021_m_000000_0
2020-11-19 16:27:33  [ Thread-618:32882 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:33  [ Thread-618:32882 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:33  [ pool-66-thread-1:32882 ] - [ INFO ]  Starting task: attempt_local124952742_0021_r_000000_0
2020-11-19 16:27:33  [ pool-66-thread-1:32883 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:33  [ pool-66-thread-1:32883 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:33  [ pool-66-thread-1:32883 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:33  [ pool-66-thread-1:32883 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5d06a888
2020-11-19 16:27:33  [ pool-66-thread-1:32883 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:33  [ EventFetcher for fetching Map Completion Events:32884 ] - [ INFO ]  attempt_local124952742_0021_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:33  [ localfetcher#21:32885 ] - [ INFO ]  localfetcher#21 about to shuffle output of map attempt_local124952742_0021_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:33  [ localfetcher#21:32885 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local124952742_0021_m_000000_0
2020-11-19 16:27:33  [ localfetcher#21:32885 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:33  [ EventFetcher for fetching Map Completion Events:32885 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:33  [ pool-66-thread-1:32886 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:33  [ pool-66-thread-1:32886 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:33  [ pool-66-thread-1:32887 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:33  [ pool-66-thread-1:32887 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:33  [ pool-66-thread-1:32888 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:33  [ pool-66-thread-1:32888 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:33  [ pool-66-thread-1:32888 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:33  [ pool-66-thread-1:32888 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:33  [ pool-66-thread-1:32888 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:33  [ pool-66-thread-1:32888 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:33  [ pool-66-thread-1:32932 ] - [ INFO ]  Task:attempt_local124952742_0021_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:33  [ pool-66-thread-1:32937 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:33  [ pool-66-thread-1:32938 ] - [ INFO ]  Task attempt_local124952742_0021_r_000000_0 is allowed to commit now
2020-11-19 16:27:33  [ pool-66-thread-1:32953 ] - [ INFO ]  Saved output of task 'attempt_local124952742_0021_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local124952742_0021_r_000000
2020-11-19 16:27:33  [ pool-66-thread-1:32954 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:33  [ pool-66-thread-1:32954 ] - [ INFO ]  Task 'attempt_local124952742_0021_r_000000_0' done.
2020-11-19 16:27:33  [ pool-66-thread-1:32954 ] - [ INFO ]  Finishing task: attempt_local124952742_0021_r_000000_0
2020-11-19 16:27:33  [ Thread-618:32954 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:34  [ main:33718 ] - [ INFO ]  Job job_local124952742_0021 running in uber mode : false
2020-11-19 16:27:34  [ main:33718 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:34  [ main:33719 ] - [ INFO ]  Job job_local124952742_0021 completed successfully
2020-11-19 16:27:34  [ main:33719 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=101544
		FILE: Number of bytes written=12047569
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1349502
		HDFS: Number of bytes written=21330
		HDFS: Number of read operations=1353
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=442
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1482686464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:34  [ main:34219 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:34  [ main:34231 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:34  [ main:34236 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:34  [ main:34249 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:34  [ main:34293 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:34  [ main:34310 ] - [ INFO ]  Submitting tokens for job: job_local1883577007_0022
2020-11-19 16:27:34  [ main:34345 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:34  [ main:34345 ] - [ INFO ]  Running job: job_local1883577007_0022
2020-11-19 16:27:34  [ Thread-648:34345 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:34  [ Thread-648:34345 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:34  [ Thread-648:34345 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:34  [ Thread-648:34358 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34358 ] - [ INFO ]  Starting task: attempt_local1883577007_0022_m_000000_0
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34358 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34358 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34358 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34359 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34367 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34367 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34367 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34367 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34367 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34367 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34473 ] - [ INFO ]  
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34473 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34473 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34473 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34473 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34475 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34476 ] - [ INFO ]  Task:attempt_local1883577007_0022_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34484 ] - [ INFO ]  map
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34485 ] - [ INFO ]  Task 'attempt_local1883577007_0022_m_000000_0' done.
2020-11-19 16:27:34  [ LocalJobRunner Map Task Executor #0:34485 ] - [ INFO ]  Finishing task: attempt_local1883577007_0022_m_000000_0
2020-11-19 16:27:34  [ Thread-648:34485 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:34  [ Thread-648:34485 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:34  [ pool-69-thread-1:34485 ] - [ INFO ]  Starting task: attempt_local1883577007_0022_r_000000_0
2020-11-19 16:27:34  [ pool-69-thread-1:34486 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:34  [ pool-69-thread-1:34486 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:34  [ pool-69-thread-1:34486 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:34  [ pool-69-thread-1:34486 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@137916ca
2020-11-19 16:27:34  [ pool-69-thread-1:34486 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:34  [ EventFetcher for fetching Map Completion Events:34486 ] - [ INFO ]  attempt_local1883577007_0022_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:34  [ localfetcher#22:34487 ] - [ INFO ]  localfetcher#22 about to shuffle output of map attempt_local1883577007_0022_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:34  [ localfetcher#22:34487 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1883577007_0022_m_000000_0
2020-11-19 16:27:34  [ localfetcher#22:34487 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:34  [ EventFetcher for fetching Map Completion Events:34488 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:34  [ pool-69-thread-1:34488 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:34  [ pool-69-thread-1:34488 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:34  [ pool-69-thread-1:34489 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:34  [ pool-69-thread-1:34489 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:34  [ pool-69-thread-1:34489 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:34  [ pool-69-thread-1:34490 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:34  [ pool-69-thread-1:34490 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:34  [ pool-69-thread-1:34490 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:34  [ pool-69-thread-1:34490 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:34  [ pool-69-thread-1:34490 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:34  [ pool-69-thread-1:34552 ] - [ INFO ]  Task:attempt_local1883577007_0022_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:35  [ pool-69-thread-1:34558 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:35  [ pool-69-thread-1:34558 ] - [ INFO ]  Task attempt_local1883577007_0022_r_000000_0 is allowed to commit now
2020-11-19 16:27:35  [ pool-69-thread-1:34578 ] - [ INFO ]  Saved output of task 'attempt_local1883577007_0022_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1883577007_0022_r_000000
2020-11-19 16:27:35  [ pool-69-thread-1:34578 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:35  [ pool-69-thread-1:34578 ] - [ INFO ]  Task 'attempt_local1883577007_0022_r_000000_0' done.
2020-11-19 16:27:35  [ pool-69-thread-1:34578 ] - [ INFO ]  Finishing task: attempt_local1883577007_0022_r_000000_0
2020-11-19 16:27:35  [ Thread-648:34579 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:35  [ main:35345 ] - [ INFO ]  Job job_local1883577007_0022 running in uber mode : false
2020-11-19 16:27:35  [ main:35346 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:35  [ main:35346 ] - [ INFO ]  Job job_local1883577007_0022 completed successfully
2020-11-19 16:27:35  [ main:35347 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=102738
		FILE: Number of bytes written=12619499
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1413904
		HDFS: Number of bytes written=22408
		HDFS: Number of read operations=1421
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=464
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:36  [ main:35648 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:36  [ main:35660 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:36  [ main:35665 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:36  [ main:35671 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:36  [ main:35712 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:36  [ main:35730 ] - [ INFO ]  Submitting tokens for job: job_local1694718699_0023
2020-11-19 16:27:36  [ main:35766 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:36  [ main:35766 ] - [ INFO ]  Running job: job_local1694718699_0023
2020-11-19 16:27:36  [ Thread-678:35766 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:36  [ Thread-678:35766 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:36  [ Thread-678:35766 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:36  [ Thread-678:35774 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35774 ] - [ INFO ]  Starting task: attempt_local1694718699_0023_m_000000_0
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35774 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35774 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35774 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35774 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35783 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35783 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35783 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35783 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35783 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35784 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35866 ] - [ INFO ]  
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35866 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35866 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35866 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35866 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35868 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35869 ] - [ INFO ]  Task:attempt_local1694718699_0023_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35875 ] - [ INFO ]  map
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35875 ] - [ INFO ]  Task 'attempt_local1694718699_0023_m_000000_0' done.
2020-11-19 16:27:36  [ LocalJobRunner Map Task Executor #0:35875 ] - [ INFO ]  Finishing task: attempt_local1694718699_0023_m_000000_0
2020-11-19 16:27:36  [ Thread-678:35875 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:36  [ Thread-678:35876 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:36  [ pool-72-thread-1:35876 ] - [ INFO ]  Starting task: attempt_local1694718699_0023_r_000000_0
2020-11-19 16:27:36  [ pool-72-thread-1:35876 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:36  [ pool-72-thread-1:35876 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:36  [ pool-72-thread-1:35876 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:36  [ pool-72-thread-1:35876 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a6ca3c3
2020-11-19 16:27:36  [ pool-72-thread-1:35877 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:36  [ EventFetcher for fetching Map Completion Events:35877 ] - [ INFO ]  attempt_local1694718699_0023_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:36  [ localfetcher#23:35878 ] - [ INFO ]  localfetcher#23 about to shuffle output of map attempt_local1694718699_0023_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:36  [ localfetcher#23:35878 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1694718699_0023_m_000000_0
2020-11-19 16:27:36  [ localfetcher#23:35878 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:36  [ EventFetcher for fetching Map Completion Events:35878 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:36  [ pool-72-thread-1:35879 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:36  [ pool-72-thread-1:35879 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:36  [ pool-72-thread-1:35879 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:36  [ pool-72-thread-1:35879 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:36  [ pool-72-thread-1:35880 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:36  [ pool-72-thread-1:35880 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:36  [ pool-72-thread-1:35880 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:36  [ pool-72-thread-1:35880 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:36  [ pool-72-thread-1:35880 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:36  [ pool-72-thread-1:35880 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:36  [ pool-72-thread-1:35926 ] - [ INFO ]  Task:attempt_local1694718699_0023_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:36  [ pool-72-thread-1:35931 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:36  [ pool-72-thread-1:35931 ] - [ INFO ]  Task attempt_local1694718699_0023_r_000000_0 is allowed to commit now
2020-11-19 16:27:36  [ pool-72-thread-1:35948 ] - [ INFO ]  Saved output of task 'attempt_local1694718699_0023_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1694718699_0023_r_000000
2020-11-19 16:27:36  [ pool-72-thread-1:35948 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:36  [ pool-72-thread-1:35948 ] - [ INFO ]  Task 'attempt_local1694718699_0023_r_000000_0' done.
2020-11-19 16:27:36  [ pool-72-thread-1:35948 ] - [ INFO ]  Finishing task: attempt_local1694718699_0023_r_000000_0
2020-11-19 16:27:36  [ Thread-678:35948 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:37  [ main:36767 ] - [ INFO ]  Job job_local1694718699_0023 running in uber mode : false
2020-11-19 16:27:37  [ main:36767 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:37  [ main:36767 ] - [ INFO ]  Job job_local1694718699_0023 completed successfully
2020-11-19 16:27:37  [ main:36768 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=103936
		FILE: Number of bytes written=13191427
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1478294
		HDFS: Number of bytes written=23479
		HDFS: Number of read operations=1489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=486
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:37  [ main:37054 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:37  [ main:37066 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:37  [ main:37070 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:37  [ main:37076 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:37  [ main:37115 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:37  [ main:37133 ] - [ INFO ]  Submitting tokens for job: job_local1789502536_0024
2020-11-19 16:27:37  [ main:37169 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:37  [ main:37170 ] - [ INFO ]  Running job: job_local1789502536_0024
2020-11-19 16:27:37  [ Thread-708:37170 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:37  [ Thread-708:37170 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:37  [ Thread-708:37170 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:37  [ Thread-708:37177 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37177 ] - [ INFO ]  Starting task: attempt_local1789502536_0024_m_000000_0
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37177 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37177 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37177 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37178 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37187 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37187 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37187 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37187 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37187 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37188 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37255 ] - [ INFO ]  
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37255 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37255 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37255 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37255 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37257 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37258 ] - [ INFO ]  Task:attempt_local1789502536_0024_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37264 ] - [ INFO ]  map
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37265 ] - [ INFO ]  Task 'attempt_local1789502536_0024_m_000000_0' done.
2020-11-19 16:27:37  [ LocalJobRunner Map Task Executor #0:37265 ] - [ INFO ]  Finishing task: attempt_local1789502536_0024_m_000000_0
2020-11-19 16:27:37  [ Thread-708:37265 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:37  [ Thread-708:37265 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:37  [ pool-75-thread-1:37265 ] - [ INFO ]  Starting task: attempt_local1789502536_0024_r_000000_0
2020-11-19 16:27:37  [ pool-75-thread-1:37266 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:37  [ pool-75-thread-1:37266 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:37  [ pool-75-thread-1:37266 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:37  [ pool-75-thread-1:37266 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6acd7f91
2020-11-19 16:27:37  [ pool-75-thread-1:37266 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:37  [ EventFetcher for fetching Map Completion Events:37266 ] - [ INFO ]  attempt_local1789502536_0024_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:37  [ localfetcher#24:37267 ] - [ INFO ]  localfetcher#24 about to shuffle output of map attempt_local1789502536_0024_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:37  [ localfetcher#24:37267 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1789502536_0024_m_000000_0
2020-11-19 16:27:37  [ localfetcher#24:37267 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:37  [ EventFetcher for fetching Map Completion Events:37267 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:37  [ pool-75-thread-1:37268 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:37  [ pool-75-thread-1:37268 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:37  [ pool-75-thread-1:37268 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:37  [ pool-75-thread-1:37268 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:37  [ pool-75-thread-1:37269 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:37  [ pool-75-thread-1:37269 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:37  [ pool-75-thread-1:37269 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:37  [ pool-75-thread-1:37269 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:37  [ pool-75-thread-1:37269 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:37  [ pool-75-thread-1:37269 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:37  [ pool-75-thread-1:37335 ] - [ INFO ]  Task:attempt_local1789502536_0024_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:37  [ pool-75-thread-1:37343 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:37  [ pool-75-thread-1:37343 ] - [ INFO ]  Task attempt_local1789502536_0024_r_000000_0 is allowed to commit now
2020-11-19 16:27:37  [ pool-75-thread-1:37360 ] - [ INFO ]  Saved output of task 'attempt_local1789502536_0024_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1789502536_0024_r_000000
2020-11-19 16:27:37  [ pool-75-thread-1:37360 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:37  [ pool-75-thread-1:37360 ] - [ INFO ]  Task 'attempt_local1789502536_0024_r_000000_0' done.
2020-11-19 16:27:37  [ pool-75-thread-1:37361 ] - [ INFO ]  Finishing task: attempt_local1789502536_0024_r_000000_0
2020-11-19 16:27:37  [ Thread-708:37361 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:38  [ main:38174 ] - [ INFO ]  Job job_local1789502536_0024 running in uber mode : false
2020-11-19 16:27:38  [ main:38174 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:38  [ main:38174 ] - [ INFO ]  Job job_local1789502536_0024 completed successfully
2020-11-19 16:27:38  [ main:38175 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=105136
		FILE: Number of bytes written=13763362
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1542704
		HDFS: Number of bytes written=24562
		HDFS: Number of read operations=1557
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=508
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1587544064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:38  [ main:38450 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:38  [ main:38465 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:38  [ main:38469 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:38  [ main:38475 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:38  [ main:38510 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:38  [ main:38527 ] - [ INFO ]  Submitting tokens for job: job_local791417121_0025
2020-11-19 16:27:39  [ main:38561 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:39  [ main:38561 ] - [ INFO ]  Running job: job_local791417121_0025
2020-11-19 16:27:39  [ Thread-738:38561 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:39  [ Thread-738:38562 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:39  [ Thread-738:38562 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:39  [ Thread-738:38568 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38568 ] - [ INFO ]  Starting task: attempt_local791417121_0025_m_000000_0
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38568 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38568 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38568 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38568 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38576 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38576 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38576 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38576 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38576 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38576 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38634 ] - [ INFO ]  
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38634 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38634 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38634 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38634 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38638 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38639 ] - [ INFO ]  Task:attempt_local791417121_0025_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38645 ] - [ INFO ]  map
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38645 ] - [ INFO ]  Task 'attempt_local791417121_0025_m_000000_0' done.
2020-11-19 16:27:39  [ LocalJobRunner Map Task Executor #0:38645 ] - [ INFO ]  Finishing task: attempt_local791417121_0025_m_000000_0
2020-11-19 16:27:39  [ Thread-738:38645 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:39  [ Thread-738:38646 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:39  [ pool-78-thread-1:38646 ] - [ INFO ]  Starting task: attempt_local791417121_0025_r_000000_0
2020-11-19 16:27:39  [ pool-78-thread-1:38646 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:39  [ pool-78-thread-1:38647 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:39  [ pool-78-thread-1:38647 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:39  [ pool-78-thread-1:38647 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@689b37aa
2020-11-19 16:27:39  [ pool-78-thread-1:38647 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:39  [ EventFetcher for fetching Map Completion Events:38647 ] - [ INFO ]  attempt_local791417121_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:39  [ localfetcher#25:38648 ] - [ INFO ]  localfetcher#25 about to shuffle output of map attempt_local791417121_0025_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:39  [ localfetcher#25:38648 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local791417121_0025_m_000000_0
2020-11-19 16:27:39  [ localfetcher#25:38648 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:39  [ EventFetcher for fetching Map Completion Events:38649 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:39  [ pool-78-thread-1:38649 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:39  [ pool-78-thread-1:38649 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:39  [ pool-78-thread-1:38650 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:39  [ pool-78-thread-1:38650 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:39  [ pool-78-thread-1:38650 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:39  [ pool-78-thread-1:38650 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:39  [ pool-78-thread-1:38650 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:39  [ pool-78-thread-1:38650 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:39  [ pool-78-thread-1:38651 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:39  [ pool-78-thread-1:38651 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:39  [ pool-78-thread-1:38694 ] - [ INFO ]  Task:attempt_local791417121_0025_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:39  [ pool-78-thread-1:38700 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:39  [ pool-78-thread-1:38700 ] - [ INFO ]  Task attempt_local791417121_0025_r_000000_0 is allowed to commit now
2020-11-19 16:27:39  [ pool-78-thread-1:38716 ] - [ INFO ]  Saved output of task 'attempt_local791417121_0025_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local791417121_0025_r_000000
2020-11-19 16:27:39  [ pool-78-thread-1:38716 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:39  [ pool-78-thread-1:38716 ] - [ INFO ]  Task 'attempt_local791417121_0025_r_000000_0' done.
2020-11-19 16:27:39  [ pool-78-thread-1:38716 ] - [ INFO ]  Finishing task: attempt_local791417121_0025_r_000000_0
2020-11-19 16:27:39  [ Thread-738:38716 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:40  [ main:39566 ] - [ INFO ]  Job job_local791417121_0025 running in uber mode : false
2020-11-19 16:27:40  [ main:39566 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:40  [ main:39566 ] - [ INFO ]  Job job_local791417121_0025 completed successfully
2020-11-19 16:27:40  [ main:39567 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=106332
		FILE: Number of bytes written=14332237
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1607096
		HDFS: Number of bytes written=25632
		HDFS: Number of read operations=1625
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=530
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1587544064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:40  [ main:39838 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:40  [ main:39850 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:40  [ main:39855 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:40  [ main:39861 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:40  [ main:39906 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:40  [ main:39927 ] - [ INFO ]  Submitting tokens for job: job_local885578737_0026
2020-11-19 16:27:40  [ main:39962 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:40  [ main:39962 ] - [ INFO ]  Running job: job_local885578737_0026
2020-11-19 16:27:40  [ Thread-768:39963 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:40  [ Thread-768:39963 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:40  [ Thread-768:39963 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:40  [ Thread-768:39971 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39971 ] - [ INFO ]  Starting task: attempt_local885578737_0026_m_000000_0
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39971 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39972 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39972 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39972 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39983 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39983 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39983 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39983 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39983 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:39983 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40048 ] - [ INFO ]  
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40048 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40048 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40048 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40048 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40052 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40053 ] - [ INFO ]  Task:attempt_local885578737_0026_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40058 ] - [ INFO ]  map
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40058 ] - [ INFO ]  Task 'attempt_local885578737_0026_m_000000_0' done.
2020-11-19 16:27:40  [ LocalJobRunner Map Task Executor #0:40058 ] - [ INFO ]  Finishing task: attempt_local885578737_0026_m_000000_0
2020-11-19 16:27:40  [ Thread-768:40059 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:40  [ Thread-768:40059 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:40  [ pool-81-thread-1:40059 ] - [ INFO ]  Starting task: attempt_local885578737_0026_r_000000_0
2020-11-19 16:27:40  [ pool-81-thread-1:40059 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:40  [ pool-81-thread-1:40059 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:40  [ pool-81-thread-1:40059 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:40  [ pool-81-thread-1:40059 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a299da0
2020-11-19 16:27:40  [ pool-81-thread-1:40060 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:40  [ EventFetcher for fetching Map Completion Events:40060 ] - [ INFO ]  attempt_local885578737_0026_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:40  [ localfetcher#26:40061 ] - [ INFO ]  localfetcher#26 about to shuffle output of map attempt_local885578737_0026_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:40  [ localfetcher#26:40061 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local885578737_0026_m_000000_0
2020-11-19 16:27:40  [ localfetcher#26:40061 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:40  [ EventFetcher for fetching Map Completion Events:40061 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:40  [ pool-81-thread-1:40061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:40  [ pool-81-thread-1:40061 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:40  [ pool-81-thread-1:40062 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:40  [ pool-81-thread-1:40062 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:40  [ pool-81-thread-1:40063 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:40  [ pool-81-thread-1:40063 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:40  [ pool-81-thread-1:40063 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:40  [ pool-81-thread-1:40063 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:40  [ pool-81-thread-1:40063 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:40  [ pool-81-thread-1:40063 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:40  [ pool-81-thread-1:40109 ] - [ INFO ]  Task:attempt_local885578737_0026_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:40  [ pool-81-thread-1:40116 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:40  [ pool-81-thread-1:40116 ] - [ INFO ]  Task attempt_local885578737_0026_r_000000_0 is allowed to commit now
2020-11-19 16:27:40  [ pool-81-thread-1:40133 ] - [ INFO ]  Saved output of task 'attempt_local885578737_0026_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local885578737_0026_r_000000
2020-11-19 16:27:40  [ pool-81-thread-1:40133 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:40  [ pool-81-thread-1:40133 ] - [ INFO ]  Task 'attempt_local885578737_0026_r_000000_0' done.
2020-11-19 16:27:40  [ pool-81-thread-1:40133 ] - [ INFO ]  Finishing task: attempt_local885578737_0026_r_000000_0
2020-11-19 16:27:40  [ Thread-768:40133 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:41  [ main:40963 ] - [ INFO ]  Job job_local885578737_0026 running in uber mode : false
2020-11-19 16:27:41  [ main:40963 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:41  [ main:40963 ] - [ INFO ]  Job job_local885578737_0026 completed successfully
2020-11-19 16:27:41  [ main:40965 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=107526
		FILE: Number of bytes written=14901119
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1671498
		HDFS: Number of bytes written=26710
		HDFS: Number of read operations=1693
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=552
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1587544064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:41  [ main:41223 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:41  [ main:41235 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:41  [ main:41239 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:41  [ main:41246 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:41  [ main:41283 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:41  [ main:41303 ] - [ INFO ]  Submitting tokens for job: job_local829059009_0027
2020-11-19 16:27:41  [ main:41357 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:41  [ main:41357 ] - [ INFO ]  Running job: job_local829059009_0027
2020-11-19 16:27:41  [ Thread-798:41357 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:41  [ Thread-798:41357 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:41  [ Thread-798:41358 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:41  [ Thread-798:41365 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41365 ] - [ INFO ]  Starting task: attempt_local829059009_0027_m_000000_0
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41365 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41365 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41365 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41366 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41375 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41375 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41375 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41375 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41375 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41375 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41453 ] - [ INFO ]  
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41453 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41453 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41453 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41453 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41455 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41456 ] - [ INFO ]  Task:attempt_local829059009_0027_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41462 ] - [ INFO ]  map
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41462 ] - [ INFO ]  Task 'attempt_local829059009_0027_m_000000_0' done.
2020-11-19 16:27:41  [ LocalJobRunner Map Task Executor #0:41462 ] - [ INFO ]  Finishing task: attempt_local829059009_0027_m_000000_0
2020-11-19 16:27:41  [ Thread-798:41462 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:41  [ Thread-798:41462 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:41  [ pool-84-thread-1:41462 ] - [ INFO ]  Starting task: attempt_local829059009_0027_r_000000_0
2020-11-19 16:27:41  [ pool-84-thread-1:41463 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:41  [ pool-84-thread-1:41463 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:41  [ pool-84-thread-1:41463 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:41  [ pool-84-thread-1:41463 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d1dc106
2020-11-19 16:27:41  [ pool-84-thread-1:41463 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:41  [ EventFetcher for fetching Map Completion Events:41463 ] - [ INFO ]  attempt_local829059009_0027_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:41  [ localfetcher#27:41464 ] - [ INFO ]  localfetcher#27 about to shuffle output of map attempt_local829059009_0027_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:41  [ localfetcher#27:41464 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local829059009_0027_m_000000_0
2020-11-19 16:27:41  [ localfetcher#27:41464 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:41  [ EventFetcher for fetching Map Completion Events:41464 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:41  [ pool-84-thread-1:41465 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:41  [ pool-84-thread-1:41465 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:41  [ pool-84-thread-1:41465 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:41  [ pool-84-thread-1:41465 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:41  [ pool-84-thread-1:41466 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:41  [ pool-84-thread-1:41466 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:41  [ pool-84-thread-1:41466 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:41  [ pool-84-thread-1:41466 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:41  [ pool-84-thread-1:41466 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:41  [ pool-84-thread-1:41466 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:41  [ pool-84-thread-1:41506 ] - [ INFO ]  Task:attempt_local829059009_0027_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:41  [ pool-84-thread-1:41511 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:41  [ pool-84-thread-1:41511 ] - [ INFO ]  Task attempt_local829059009_0027_r_000000_0 is allowed to commit now
2020-11-19 16:27:41  [ pool-84-thread-1:41527 ] - [ INFO ]  Saved output of task 'attempt_local829059009_0027_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local829059009_0027_r_000000
2020-11-19 16:27:41  [ pool-84-thread-1:41528 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:41  [ pool-84-thread-1:41528 ] - [ INFO ]  Task 'attempt_local829059009_0027_r_000000_0' done.
2020-11-19 16:27:41  [ pool-84-thread-1:41528 ] - [ INFO ]  Finishing task: attempt_local829059009_0027_r_000000_0
2020-11-19 16:27:41  [ Thread-798:41528 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:42  [ main:42360 ] - [ INFO ]  Job job_local829059009_0027 running in uber mode : false
2020-11-19 16:27:42  [ main:42360 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:42  [ main:42360 ] - [ INFO ]  Job job_local829059009_0027 completed successfully
2020-11-19 16:27:42  [ main:42361 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=108724
		FILE: Number of bytes written=15469999
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1735888
		HDFS: Number of bytes written=27781
		HDFS: Number of read operations=1761
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=574
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1607467008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:43  [ main:42655 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:43  [ main:42666 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:43  [ main:42671 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:43  [ main:42677 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:43  [ main:42716 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:43  [ main:42733 ] - [ INFO ]  Submitting tokens for job: job_local1455151613_0028
2020-11-19 16:27:43  [ main:42763 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:43  [ main:42763 ] - [ INFO ]  Running job: job_local1455151613_0028
2020-11-19 16:27:43  [ Thread-828:42763 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:43  [ Thread-828:42763 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:43  [ Thread-828:42763 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:43  [ Thread-828:42771 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42771 ] - [ INFO ]  Starting task: attempt_local1455151613_0028_m_000000_0
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42771 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42772 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42772 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42772 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42779 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42779 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42779 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42779 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42779 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42780 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42875 ] - [ INFO ]  
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42875 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42875 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42875 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42875 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42877 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42878 ] - [ INFO ]  Task:attempt_local1455151613_0028_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42884 ] - [ INFO ]  map
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42884 ] - [ INFO ]  Task 'attempt_local1455151613_0028_m_000000_0' done.
2020-11-19 16:27:43  [ LocalJobRunner Map Task Executor #0:42884 ] - [ INFO ]  Finishing task: attempt_local1455151613_0028_m_000000_0
2020-11-19 16:27:43  [ Thread-828:42885 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:43  [ Thread-828:42885 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:43  [ pool-87-thread-1:42885 ] - [ INFO ]  Starting task: attempt_local1455151613_0028_r_000000_0
2020-11-19 16:27:43  [ pool-87-thread-1:42885 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:43  [ pool-87-thread-1:42886 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:43  [ pool-87-thread-1:42886 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:43  [ pool-87-thread-1:42886 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55f12fa
2020-11-19 16:27:43  [ pool-87-thread-1:42886 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:43  [ EventFetcher for fetching Map Completion Events:42886 ] - [ INFO ]  attempt_local1455151613_0028_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:43  [ localfetcher#28:42887 ] - [ INFO ]  localfetcher#28 about to shuffle output of map attempt_local1455151613_0028_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:43  [ localfetcher#28:42887 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1455151613_0028_m_000000_0
2020-11-19 16:27:43  [ localfetcher#28:42887 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:43  [ EventFetcher for fetching Map Completion Events:42887 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:43  [ pool-87-thread-1:42888 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:43  [ pool-87-thread-1:42888 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:43  [ pool-87-thread-1:42888 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:43  [ pool-87-thread-1:42888 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:43  [ pool-87-thread-1:42889 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:43  [ pool-87-thread-1:42889 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:43  [ pool-87-thread-1:42889 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:43  [ pool-87-thread-1:42889 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:43  [ pool-87-thread-1:42889 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:43  [ pool-87-thread-1:42889 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:43  [ pool-87-thread-1:42947 ] - [ INFO ]  Task:attempt_local1455151613_0028_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:43  [ pool-87-thread-1:42953 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:43  [ pool-87-thread-1:42954 ] - [ INFO ]  Task attempt_local1455151613_0028_r_000000_0 is allowed to commit now
2020-11-19 16:27:43  [ pool-87-thread-1:42972 ] - [ INFO ]  Saved output of task 'attempt_local1455151613_0028_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1455151613_0028_r_000000
2020-11-19 16:27:43  [ pool-87-thread-1:42973 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:43  [ pool-87-thread-1:42973 ] - [ INFO ]  Task 'attempt_local1455151613_0028_r_000000_0' done.
2020-11-19 16:27:43  [ pool-87-thread-1:42973 ] - [ INFO ]  Finishing task: attempt_local1455151613_0028_r_000000_0
2020-11-19 16:27:43  [ Thread-828:42973 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:44  [ main:43764 ] - [ INFO ]  Job job_local1455151613_0028 running in uber mode : false
2020-11-19 16:27:44  [ main:43764 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:44  [ main:43765 ] - [ INFO ]  Job job_local1455151613_0028 completed successfully
2020-11-19 16:27:44  [ main:43765 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=109924
		FILE: Number of bytes written=16041934
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1800298
		HDFS: Number of bytes written=28864
		HDFS: Number of read operations=1829
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=596
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1607467008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:44  [ main:44052 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:44  [ main:44064 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:44  [ main:44069 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:44  [ main:44075 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:44  [ main:44119 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:44  [ main:44136 ] - [ INFO ]  Submitting tokens for job: job_local1179629978_0029
2020-11-19 16:27:44  [ main:44166 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:44  [ main:44166 ] - [ INFO ]  Running job: job_local1179629978_0029
2020-11-19 16:27:44  [ Thread-858:44166 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:44  [ Thread-858:44166 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:44  [ Thread-858:44166 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:44  [ Thread-858:44174 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44174 ] - [ INFO ]  Starting task: attempt_local1179629978_0029_m_000000_0
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44175 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44175 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44175 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44176 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44184 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44184 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44184 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44184 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44184 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44184 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44259 ] - [ INFO ]  
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44259 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44259 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44259 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44259 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44262 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44263 ] - [ INFO ]  Task:attempt_local1179629978_0029_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44270 ] - [ INFO ]  map
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44270 ] - [ INFO ]  Task 'attempt_local1179629978_0029_m_000000_0' done.
2020-11-19 16:27:44  [ LocalJobRunner Map Task Executor #0:44270 ] - [ INFO ]  Finishing task: attempt_local1179629978_0029_m_000000_0
2020-11-19 16:27:44  [ Thread-858:44270 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:44  [ Thread-858:44271 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:44  [ pool-90-thread-1:44271 ] - [ INFO ]  Starting task: attempt_local1179629978_0029_r_000000_0
2020-11-19 16:27:44  [ pool-90-thread-1:44271 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:44  [ pool-90-thread-1:44271 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:44  [ pool-90-thread-1:44271 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:44  [ pool-90-thread-1:44271 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@793006a5
2020-11-19 16:27:44  [ pool-90-thread-1:44271 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:44  [ EventFetcher for fetching Map Completion Events:44272 ] - [ INFO ]  attempt_local1179629978_0029_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:44  [ localfetcher#29:44272 ] - [ INFO ]  localfetcher#29 about to shuffle output of map attempt_local1179629978_0029_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:44  [ localfetcher#29:44272 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1179629978_0029_m_000000_0
2020-11-19 16:27:44  [ localfetcher#29:44272 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:44  [ EventFetcher for fetching Map Completion Events:44273 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:44  [ pool-90-thread-1:44273 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:44  [ pool-90-thread-1:44273 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:44  [ pool-90-thread-1:44274 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:44  [ pool-90-thread-1:44338 ] - [ INFO ]  Task:attempt_local1179629978_0029_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:44  [ pool-90-thread-1:44344 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:44  [ pool-90-thread-1:44344 ] - [ INFO ]  Task attempt_local1179629978_0029_r_000000_0 is allowed to commit now
2020-11-19 16:27:44  [ pool-90-thread-1:44361 ] - [ INFO ]  Saved output of task 'attempt_local1179629978_0029_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1179629978_0029_r_000000
2020-11-19 16:27:44  [ pool-90-thread-1:44362 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:44  [ pool-90-thread-1:44362 ] - [ INFO ]  Task 'attempt_local1179629978_0029_r_000000_0' done.
2020-11-19 16:27:44  [ pool-90-thread-1:44362 ] - [ INFO ]  Finishing task: attempt_local1179629978_0029_r_000000_0
2020-11-19 16:27:44  [ Thread-858:44362 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:45  [ main:45169 ] - [ INFO ]  Job job_local1179629978_0029 running in uber mode : false
2020-11-19 16:27:45  [ main:45169 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:45  [ main:45169 ] - [ INFO ]  Job job_local1179629978_0029 completed successfully
2020-11-19 16:27:45  [ main:45170 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=111120
		FILE: Number of bytes written=16613857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1864690
		HDFS: Number of bytes written=29934
		HDFS: Number of read operations=1897
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=618
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1607467008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:46  [ main:45675 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:46  [ main:45693 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:46  [ main:45699 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:46  [ main:45706 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:46  [ main:45749 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:46  [ main:45766 ] - [ INFO ]  Submitting tokens for job: job_local1586482119_0030
2020-11-19 16:27:46  [ main:45800 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:46  [ main:45800 ] - [ INFO ]  Running job: job_local1586482119_0030
2020-11-19 16:27:46  [ Thread-888:45800 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:46  [ Thread-888:45800 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:46  [ Thread-888:45800 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:46  [ Thread-888:45808 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45808 ] - [ INFO ]  Starting task: attempt_local1586482119_0030_m_000000_0
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45808 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45808 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45808 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45809 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45818 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45818 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45818 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45818 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45818 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45818 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45899 ] - [ INFO ]  
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45899 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45899 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45899 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45899 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45901 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45902 ] - [ INFO ]  Task:attempt_local1586482119_0030_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45909 ] - [ INFO ]  map
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45909 ] - [ INFO ]  Task 'attempt_local1586482119_0030_m_000000_0' done.
2020-11-19 16:27:46  [ LocalJobRunner Map Task Executor #0:45909 ] - [ INFO ]  Finishing task: attempt_local1586482119_0030_m_000000_0
2020-11-19 16:27:46  [ Thread-888:45910 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:46  [ Thread-888:45910 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:46  [ pool-93-thread-1:45910 ] - [ INFO ]  Starting task: attempt_local1586482119_0030_r_000000_0
2020-11-19 16:27:46  [ pool-93-thread-1:45910 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:46  [ pool-93-thread-1:45911 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:46  [ pool-93-thread-1:45911 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:46  [ pool-93-thread-1:45911 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f85358
2020-11-19 16:27:46  [ pool-93-thread-1:45911 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:46  [ EventFetcher for fetching Map Completion Events:45911 ] - [ INFO ]  attempt_local1586482119_0030_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:46  [ localfetcher#30:45912 ] - [ INFO ]  localfetcher#30 about to shuffle output of map attempt_local1586482119_0030_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:46  [ localfetcher#30:45912 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1586482119_0030_m_000000_0
2020-11-19 16:27:46  [ localfetcher#30:45912 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:46  [ EventFetcher for fetching Map Completion Events:45913 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:46  [ pool-93-thread-1:45913 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:46  [ pool-93-thread-1:45913 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:46  [ pool-93-thread-1:45914 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:46  [ pool-93-thread-1:45914 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:46  [ pool-93-thread-1:45914 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:46  [ pool-93-thread-1:45914 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:46  [ pool-93-thread-1:45914 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:46  [ pool-93-thread-1:45914 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:46  [ pool-93-thread-1:45915 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:46  [ pool-93-thread-1:45915 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:46  [ pool-93-thread-1:45959 ] - [ INFO ]  Task:attempt_local1586482119_0030_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:46  [ pool-93-thread-1:45966 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:46  [ pool-93-thread-1:45966 ] - [ INFO ]  Task attempt_local1586482119_0030_r_000000_0 is allowed to commit now
2020-11-19 16:27:46  [ pool-93-thread-1:45981 ] - [ INFO ]  Saved output of task 'attempt_local1586482119_0030_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1586482119_0030_r_000000
2020-11-19 16:27:46  [ pool-93-thread-1:45981 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:46  [ pool-93-thread-1:45981 ] - [ INFO ]  Task 'attempt_local1586482119_0030_r_000000_0' done.
2020-11-19 16:27:46  [ pool-93-thread-1:45981 ] - [ INFO ]  Finishing task: attempt_local1586482119_0030_r_000000_0
2020-11-19 16:27:46  [ Thread-888:45981 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:47  [ main:46804 ] - [ INFO ]  Job job_local1586482119_0030 running in uber mode : false
2020-11-19 16:27:47  [ main:46804 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:47  [ main:46805 ] - [ INFO ]  Job job_local1586482119_0030 completed successfully
2020-11-19 16:27:47  [ main:46806 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=112314
		FILE: Number of bytes written=17185787
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1929092
		HDFS: Number of bytes written=31012
		HDFS: Number of read operations=1965
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=640
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1652555776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:47  [ main:47115 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:47  [ main:47127 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:47  [ main:47132 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:47  [ main:47137 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:47  [ main:47177 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:47  [ main:47193 ] - [ INFO ]  Submitting tokens for job: job_local860258348_0031
2020-11-19 16:27:47  [ main:47224 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:47  [ main:47224 ] - [ INFO ]  Running job: job_local860258348_0031
2020-11-19 16:27:47  [ Thread-918:47224 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:47  [ Thread-918:47224 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:47  [ Thread-918:47224 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:47  [ Thread-918:47231 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47231 ] - [ INFO ]  Starting task: attempt_local860258348_0031_m_000000_0
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47231 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47231 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47232 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47232 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47239 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47239 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47239 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47239 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47239 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47239 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47323 ] - [ INFO ]  
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47324 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47324 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47324 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47324 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47327 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47328 ] - [ INFO ]  Task:attempt_local860258348_0031_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47335 ] - [ INFO ]  map
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47336 ] - [ INFO ]  Task 'attempt_local860258348_0031_m_000000_0' done.
2020-11-19 16:27:47  [ LocalJobRunner Map Task Executor #0:47336 ] - [ INFO ]  Finishing task: attempt_local860258348_0031_m_000000_0
2020-11-19 16:27:47  [ Thread-918:47336 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:47  [ Thread-918:47336 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:47  [ pool-96-thread-1:47336 ] - [ INFO ]  Starting task: attempt_local860258348_0031_r_000000_0
2020-11-19 16:27:47  [ pool-96-thread-1:47337 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:47  [ pool-96-thread-1:47337 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:47  [ pool-96-thread-1:47337 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:47  [ pool-96-thread-1:47337 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6ea1a33
2020-11-19 16:27:47  [ pool-96-thread-1:47337 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:47  [ EventFetcher for fetching Map Completion Events:47337 ] - [ INFO ]  attempt_local860258348_0031_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:47  [ localfetcher#31:47338 ] - [ INFO ]  localfetcher#31 about to shuffle output of map attempt_local860258348_0031_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:47  [ localfetcher#31:47338 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local860258348_0031_m_000000_0
2020-11-19 16:27:47  [ localfetcher#31:47338 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:47  [ EventFetcher for fetching Map Completion Events:47339 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:47  [ pool-96-thread-1:47339 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:47  [ pool-96-thread-1:47339 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:47  [ pool-96-thread-1:47340 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:47  [ pool-96-thread-1:47340 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:47  [ pool-96-thread-1:47341 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:47  [ pool-96-thread-1:47341 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:47  [ pool-96-thread-1:47341 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:47  [ pool-96-thread-1:47341 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:47  [ pool-96-thread-1:47341 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:47  [ pool-96-thread-1:47341 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:47  [ pool-96-thread-1:47392 ] - [ INFO ]  Task:attempt_local860258348_0031_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:47  [ pool-96-thread-1:47398 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:47  [ pool-96-thread-1:47398 ] - [ INFO ]  Task attempt_local860258348_0031_r_000000_0 is allowed to commit now
2020-11-19 16:27:47  [ pool-96-thread-1:47414 ] - [ INFO ]  Saved output of task 'attempt_local860258348_0031_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local860258348_0031_r_000000
2020-11-19 16:27:47  [ pool-96-thread-1:47415 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:47  [ pool-96-thread-1:47415 ] - [ INFO ]  Task 'attempt_local860258348_0031_r_000000_0' done.
2020-11-19 16:27:47  [ pool-96-thread-1:47415 ] - [ INFO ]  Finishing task: attempt_local860258348_0031_r_000000_0
2020-11-19 16:27:47  [ Thread-918:47415 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:48  [ main:48229 ] - [ INFO ]  Job job_local860258348_0031 running in uber mode : false
2020-11-19 16:27:48  [ main:48229 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:48  [ main:48229 ] - [ INFO ]  Job job_local860258348_0031 completed successfully
2020-11-19 16:27:48  [ main:48230 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=113512
		FILE: Number of bytes written=17754667
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1993482
		HDFS: Number of bytes written=32083
		HDFS: Number of read operations=2033
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=662
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1652555776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:48  [ main:48548 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:49  [ main:48562 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:49  [ main:48566 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:49  [ main:48571 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:49  [ main:48612 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:49  [ main:48629 ] - [ INFO ]  Submitting tokens for job: job_local242501052_0032
2020-11-19 16:27:49  [ main:48662 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:49  [ main:48662 ] - [ INFO ]  Running job: job_local242501052_0032
2020-11-19 16:27:49  [ Thread-948:48662 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:49  [ Thread-948:48662 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:49  [ Thread-948:48662 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:49  [ Thread-948:48670 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48670 ] - [ INFO ]  Starting task: attempt_local242501052_0032_m_000000_0
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48670 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48671 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48671 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48671 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48678 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48678 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48678 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48678 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48678 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48678 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48759 ] - [ INFO ]  
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48759 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48759 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48759 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48759 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48761 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48762 ] - [ INFO ]  Task:attempt_local242501052_0032_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48768 ] - [ INFO ]  map
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48768 ] - [ INFO ]  Task 'attempt_local242501052_0032_m_000000_0' done.
2020-11-19 16:27:49  [ LocalJobRunner Map Task Executor #0:48768 ] - [ INFO ]  Finishing task: attempt_local242501052_0032_m_000000_0
2020-11-19 16:27:49  [ Thread-948:48768 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:49  [ Thread-948:48768 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:49  [ pool-99-thread-1:48768 ] - [ INFO ]  Starting task: attempt_local242501052_0032_r_000000_0
2020-11-19 16:27:49  [ pool-99-thread-1:48769 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:49  [ pool-99-thread-1:48769 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:49  [ pool-99-thread-1:48769 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:49  [ pool-99-thread-1:48769 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@407835
2020-11-19 16:27:49  [ pool-99-thread-1:48769 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:49  [ EventFetcher for fetching Map Completion Events:48769 ] - [ INFO ]  attempt_local242501052_0032_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:49  [ localfetcher#32:48770 ] - [ INFO ]  localfetcher#32 about to shuffle output of map attempt_local242501052_0032_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:49  [ localfetcher#32:48770 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local242501052_0032_m_000000_0
2020-11-19 16:27:49  [ localfetcher#32:48770 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:49  [ EventFetcher for fetching Map Completion Events:48771 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:49  [ pool-99-thread-1:48771 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:49  [ pool-99-thread-1:48771 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:49  [ pool-99-thread-1:48772 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:49  [ pool-99-thread-1:48772 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:49  [ pool-99-thread-1:48772 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:49  [ pool-99-thread-1:48772 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:49  [ pool-99-thread-1:48772 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:49  [ pool-99-thread-1:48772 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:49  [ pool-99-thread-1:48773 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:49  [ pool-99-thread-1:48773 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:49  [ pool-99-thread-1:48818 ] - [ INFO ]  Task:attempt_local242501052_0032_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:49  [ pool-99-thread-1:48824 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:49  [ pool-99-thread-1:48824 ] - [ INFO ]  Task attempt_local242501052_0032_r_000000_0 is allowed to commit now
2020-11-19 16:27:49  [ pool-99-thread-1:48842 ] - [ INFO ]  Saved output of task 'attempt_local242501052_0032_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local242501052_0032_r_000000
2020-11-19 16:27:49  [ pool-99-thread-1:48842 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:49  [ pool-99-thread-1:48842 ] - [ INFO ]  Task 'attempt_local242501052_0032_r_000000_0' done.
2020-11-19 16:27:49  [ pool-99-thread-1:48842 ] - [ INFO ]  Finishing task: attempt_local242501052_0032_r_000000_0
2020-11-19 16:27:49  [ Thread-948:48842 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:50  [ main:49663 ] - [ INFO ]  Job job_local242501052_0032 running in uber mode : false
2020-11-19 16:27:50  [ main:49664 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:50  [ main:49664 ] - [ INFO ]  Job job_local242501052_0032 completed successfully
2020-11-19 16:27:50  [ main:49665 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=114712
		FILE: Number of bytes written=18323554
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2057892
		HDFS: Number of bytes written=33166
		HDFS: Number of read operations=2101
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=684
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1652555776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:50  [ main:50090 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:50  [ main:50105 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:50  [ main:50109 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:50  [ main:50117 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:50  [ main:50158 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:50  [ main:50175 ] - [ INFO ]  Submitting tokens for job: job_local368512406_0033
2020-11-19 16:27:50  [ main:50211 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:50  [ main:50211 ] - [ INFO ]  Running job: job_local368512406_0033
2020-11-19 16:27:50  [ Thread-978:50211 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:50  [ Thread-978:50211 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:50  [ Thread-978:50211 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:50  [ Thread-978:50219 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50219 ] - [ INFO ]  Starting task: attempt_local368512406_0033_m_000000_0
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50220 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50220 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50220 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50220 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50229 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50229 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50229 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50229 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50229 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50230 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50390 ] - [ INFO ]  
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50390 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50390 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50390 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50390 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50392 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50393 ] - [ INFO ]  Task:attempt_local368512406_0033_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50398 ] - [ INFO ]  map
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50398 ] - [ INFO ]  Task 'attempt_local368512406_0033_m_000000_0' done.
2020-11-19 16:27:50  [ LocalJobRunner Map Task Executor #0:50399 ] - [ INFO ]  Finishing task: attempt_local368512406_0033_m_000000_0
2020-11-19 16:27:50  [ Thread-978:50399 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:50  [ Thread-978:50399 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:50  [ pool-102-thread-1:50399 ] - [ INFO ]  Starting task: attempt_local368512406_0033_r_000000_0
2020-11-19 16:27:50  [ pool-102-thread-1:50399 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:50  [ pool-102-thread-1:50400 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:50  [ pool-102-thread-1:50400 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:50  [ pool-102-thread-1:50400 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4a1f4b3f
2020-11-19 16:27:50  [ pool-102-thread-1:50400 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:50  [ EventFetcher for fetching Map Completion Events:50400 ] - [ INFO ]  attempt_local368512406_0033_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:50  [ localfetcher#33:50401 ] - [ INFO ]  localfetcher#33 about to shuffle output of map attempt_local368512406_0033_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:50  [ localfetcher#33:50401 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local368512406_0033_m_000000_0
2020-11-19 16:27:50  [ localfetcher#33:50401 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:50  [ EventFetcher for fetching Map Completion Events:50401 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:50  [ pool-102-thread-1:50402 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:50  [ pool-102-thread-1:50402 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:50  [ pool-102-thread-1:50402 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:50  [ pool-102-thread-1:50403 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:50  [ pool-102-thread-1:50456 ] - [ INFO ]  Task:attempt_local368512406_0033_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:50  [ pool-102-thread-1:50463 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:50  [ pool-102-thread-1:50463 ] - [ INFO ]  Task attempt_local368512406_0033_r_000000_0 is allowed to commit now
2020-11-19 16:27:50  [ pool-102-thread-1:50479 ] - [ INFO ]  Saved output of task 'attempt_local368512406_0033_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local368512406_0033_r_000000
2020-11-19 16:27:50  [ pool-102-thread-1:50480 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:50  [ pool-102-thread-1:50480 ] - [ INFO ]  Task 'attempt_local368512406_0033_r_000000_0' done.
2020-11-19 16:27:50  [ pool-102-thread-1:50480 ] - [ INFO ]  Finishing task: attempt_local368512406_0033_r_000000_0
2020-11-19 16:27:50  [ Thread-978:50480 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:51  [ main:51215 ] - [ INFO ]  Job job_local368512406_0033 running in uber mode : false
2020-11-19 16:27:51  [ main:51216 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:51  [ main:51216 ] - [ INFO ]  Job job_local368512406_0033 completed successfully
2020-11-19 16:27:51  [ main:51217 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=115908
		FILE: Number of bytes written=18892429
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2122284
		HDFS: Number of bytes written=34236
		HDFS: Number of read operations=2169
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=706
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1659895808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:51  [ main:51526 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:51  [ main:51537 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:51  [ main:51542 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:51  [ main:51548 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:52  [ main:51583 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:52  [ main:51600 ] - [ INFO ]  Submitting tokens for job: job_local1871745071_0034
2020-11-19 16:27:52  [ main:51632 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:52  [ main:51632 ] - [ INFO ]  Running job: job_local1871745071_0034
2020-11-19 16:27:52  [ Thread-1008:51633 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:52  [ Thread-1008:51633 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:52  [ Thread-1008:51633 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:52  [ Thread-1008:51640 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51640 ] - [ INFO ]  Starting task: attempt_local1871745071_0034_m_000000_0
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51640 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51640 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51640 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51641 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51649 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51649 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51649 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51649 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51649 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51649 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51710 ] - [ INFO ]  
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51710 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51710 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51710 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51710 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51712 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51713 ] - [ INFO ]  Task:attempt_local1871745071_0034_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51719 ] - [ INFO ]  map
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51719 ] - [ INFO ]  Task 'attempt_local1871745071_0034_m_000000_0' done.
2020-11-19 16:27:52  [ LocalJobRunner Map Task Executor #0:51719 ] - [ INFO ]  Finishing task: attempt_local1871745071_0034_m_000000_0
2020-11-19 16:27:52  [ Thread-1008:51719 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:52  [ Thread-1008:51719 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:52  [ pool-105-thread-1:51719 ] - [ INFO ]  Starting task: attempt_local1871745071_0034_r_000000_0
2020-11-19 16:27:52  [ pool-105-thread-1:51720 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:52  [ pool-105-thread-1:51720 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:52  [ pool-105-thread-1:51720 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:52  [ pool-105-thread-1:51720 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20eedb89
2020-11-19 16:27:52  [ pool-105-thread-1:51720 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:52  [ EventFetcher for fetching Map Completion Events:51721 ] - [ INFO ]  attempt_local1871745071_0034_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:52  [ localfetcher#34:51721 ] - [ INFO ]  localfetcher#34 about to shuffle output of map attempt_local1871745071_0034_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:27:52  [ localfetcher#34:51722 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1871745071_0034_m_000000_0
2020-11-19 16:27:52  [ localfetcher#34:51722 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:27:52  [ EventFetcher for fetching Map Completion Events:51722 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:52  [ pool-105-thread-1:51722 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:52  [ pool-105-thread-1:51722 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:52  [ pool-105-thread-1:51723 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:52  [ pool-105-thread-1:51723 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:52  [ pool-105-thread-1:51724 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:52  [ pool-105-thread-1:51724 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:27:52  [ pool-105-thread-1:51724 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:52  [ pool-105-thread-1:51724 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:52  [ pool-105-thread-1:51724 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:27:52  [ pool-105-thread-1:51724 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:52  [ pool-105-thread-1:51784 ] - [ INFO ]  Task:attempt_local1871745071_0034_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:52  [ pool-105-thread-1:51793 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:52  [ pool-105-thread-1:51793 ] - [ INFO ]  Task attempt_local1871745071_0034_r_000000_0 is allowed to commit now
2020-11-19 16:27:52  [ pool-105-thread-1:51813 ] - [ INFO ]  Saved output of task 'attempt_local1871745071_0034_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1871745071_0034_r_000000
2020-11-19 16:27:52  [ pool-105-thread-1:51813 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:52  [ pool-105-thread-1:51813 ] - [ INFO ]  Task 'attempt_local1871745071_0034_r_000000_0' done.
2020-11-19 16:27:52  [ pool-105-thread-1:51813 ] - [ INFO ]  Finishing task: attempt_local1871745071_0034_r_000000_0
2020-11-19 16:27:52  [ Thread-1008:51813 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:53  [ main:52634 ] - [ INFO ]  Job job_local1871745071_0034 running in uber mode : false
2020-11-19 16:27:53  [ main:52634 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:53  [ main:52635 ] - [ INFO ]  Job job_local1871745071_0034 completed successfully
2020-11-19 16:27:53  [ main:52636 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=117102
		FILE: Number of bytes written=19464359
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2186686
		HDFS: Number of bytes written=35314
		HDFS: Number of read operations=2237
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=728
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1659895808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:54  [ main:53962 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:54  [ main:53973 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:54  [ main:53977 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:54  [ main:53983 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:54  [ main:54026 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:54  [ main:54043 ] - [ INFO ]  Submitting tokens for job: job_local1122932350_0035
2020-11-19 16:27:54  [ main:54076 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:54  [ main:54076 ] - [ INFO ]  Running job: job_local1122932350_0035
2020-11-19 16:27:54  [ Thread-1038:54076 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:54  [ Thread-1038:54077 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:54  [ Thread-1038:54077 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:54  [ Thread-1038:54090 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54090 ] - [ INFO ]  Starting task: attempt_local1122932350_0035_m_000000_0
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54090 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54091 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54091 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54091 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54100 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54100 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54100 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54100 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54100 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54100 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54364 ] - [ INFO ]  
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54364 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54364 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54364 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54364 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54366 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54367 ] - [ INFO ]  Task:attempt_local1122932350_0035_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54373 ] - [ INFO ]  map
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54373 ] - [ INFO ]  Task 'attempt_local1122932350_0035_m_000000_0' done.
2020-11-19 16:27:54  [ LocalJobRunner Map Task Executor #0:54373 ] - [ INFO ]  Finishing task: attempt_local1122932350_0035_m_000000_0
2020-11-19 16:27:54  [ Thread-1038:54373 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:54  [ Thread-1038:54373 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:54  [ pool-108-thread-1:54373 ] - [ INFO ]  Starting task: attempt_local1122932350_0035_r_000000_0
2020-11-19 16:27:54  [ pool-108-thread-1:54374 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:54  [ pool-108-thread-1:54374 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:54  [ pool-108-thread-1:54374 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:54  [ pool-108-thread-1:54374 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f09e6
2020-11-19 16:27:54  [ pool-108-thread-1:54374 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:54  [ EventFetcher for fetching Map Completion Events:54375 ] - [ INFO ]  attempt_local1122932350_0035_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:54  [ localfetcher#35:54376 ] - [ INFO ]  localfetcher#35 about to shuffle output of map attempt_local1122932350_0035_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:27:54  [ localfetcher#35:54376 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1122932350_0035_m_000000_0
2020-11-19 16:27:54  [ localfetcher#35:54376 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:27:54  [ EventFetcher for fetching Map Completion Events:54376 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:54  [ pool-108-thread-1:54376 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:54  [ pool-108-thread-1:54376 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:54  [ pool-108-thread-1:54377 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:54  [ pool-108-thread-1:54377 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:54  [ pool-108-thread-1:54378 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:54  [ pool-108-thread-1:54378 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:27:54  [ pool-108-thread-1:54378 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:54  [ pool-108-thread-1:54378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:54  [ pool-108-thread-1:54378 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:27:54  [ pool-108-thread-1:54378 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:54  [ pool-108-thread-1:54420 ] - [ INFO ]  Task:attempt_local1122932350_0035_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:54  [ pool-108-thread-1:54425 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:54  [ pool-108-thread-1:54425 ] - [ INFO ]  Task attempt_local1122932350_0035_r_000000_0 is allowed to commit now
2020-11-19 16:27:54  [ pool-108-thread-1:54441 ] - [ INFO ]  Saved output of task 'attempt_local1122932350_0035_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1122932350_0035_r_000000
2020-11-19 16:27:54  [ pool-108-thread-1:54441 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:54  [ pool-108-thread-1:54441 ] - [ INFO ]  Task 'attempt_local1122932350_0035_r_000000_0' done.
2020-11-19 16:27:54  [ pool-108-thread-1:54441 ] - [ INFO ]  Finishing task: attempt_local1122932350_0035_r_000000_0
2020-11-19 16:27:54  [ Thread-1038:54441 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:55  [ main:55081 ] - [ INFO ]  Job job_local1122932350_0035 running in uber mode : false
2020-11-19 16:27:55  [ main:55081 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:55  [ main:55081 ] - [ INFO ]  Job job_local1122932350_0035 completed successfully
2020-11-19 16:27:55  [ main:55082 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=118300
		FILE: Number of bytes written=20036287
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2251076
		HDFS: Number of bytes written=36385
		HDFS: Number of read operations=2305
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=750
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1659895808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:27:55  [ main:55451 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:55  [ main:55463 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:55  [ main:55467 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:55  [ main:55493 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:55  [ main:55540 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:56  [ main:55559 ] - [ INFO ]  Submitting tokens for job: job_local117156066_0036
2020-11-19 16:27:56  [ main:55594 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:56  [ main:55595 ] - [ INFO ]  Running job: job_local117156066_0036
2020-11-19 16:27:56  [ Thread-1068:55595 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:56  [ Thread-1068:55595 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:56  [ Thread-1068:55595 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:56  [ Thread-1068:55614 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55615 ] - [ INFO ]  Starting task: attempt_local117156066_0036_m_000000_0
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55615 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55615 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55615 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55615 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55625 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55625 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55625 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55625 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55625 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55625 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55875 ] - [ INFO ]  
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55875 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55875 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55875 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55875 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55878 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55878 ] - [ INFO ]  Task:attempt_local117156066_0036_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55884 ] - [ INFO ]  map
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55884 ] - [ INFO ]  Task 'attempt_local117156066_0036_m_000000_0' done.
2020-11-19 16:27:56  [ LocalJobRunner Map Task Executor #0:55884 ] - [ INFO ]  Finishing task: attempt_local117156066_0036_m_000000_0
2020-11-19 16:27:56  [ Thread-1068:55884 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:56  [ Thread-1068:55884 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:56  [ pool-111-thread-1:55884 ] - [ INFO ]  Starting task: attempt_local117156066_0036_r_000000_0
2020-11-19 16:27:56  [ pool-111-thread-1:55885 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:56  [ pool-111-thread-1:55885 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:56  [ pool-111-thread-1:55885 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:56  [ pool-111-thread-1:55885 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e507c5
2020-11-19 16:27:56  [ pool-111-thread-1:55885 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:56  [ EventFetcher for fetching Map Completion Events:55885 ] - [ INFO ]  attempt_local117156066_0036_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:56  [ localfetcher#36:55886 ] - [ INFO ]  localfetcher#36 about to shuffle output of map attempt_local117156066_0036_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:27:56  [ localfetcher#36:55886 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local117156066_0036_m_000000_0
2020-11-19 16:27:56  [ localfetcher#36:55886 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:27:56  [ EventFetcher for fetching Map Completion Events:55886 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:56  [ pool-111-thread-1:55886 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:56  [ pool-111-thread-1:55887 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:56  [ pool-111-thread-1:55887 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:56  [ pool-111-thread-1:55887 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:56  [ pool-111-thread-1:55888 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:56  [ pool-111-thread-1:55888 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:27:56  [ pool-111-thread-1:55888 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:56  [ pool-111-thread-1:55888 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:56  [ pool-111-thread-1:55888 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:27:56  [ pool-111-thread-1:55888 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:56  [ pool-111-thread-1:55942 ] - [ INFO ]  Task:attempt_local117156066_0036_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:56  [ pool-111-thread-1:55949 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:56  [ pool-111-thread-1:55949 ] - [ INFO ]  Task attempt_local117156066_0036_r_000000_0 is allowed to commit now
2020-11-19 16:27:56  [ pool-111-thread-1:55967 ] - [ INFO ]  Saved output of task 'attempt_local117156066_0036_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local117156066_0036_r_000000
2020-11-19 16:27:56  [ pool-111-thread-1:55968 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:56  [ pool-111-thread-1:55968 ] - [ INFO ]  Task 'attempt_local117156066_0036_r_000000_0' done.
2020-11-19 16:27:56  [ pool-111-thread-1:55968 ] - [ INFO ]  Finishing task: attempt_local117156066_0036_r_000000_0
2020-11-19 16:27:56  [ Thread-1068:55968 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:57  [ main:56599 ] - [ INFO ]  Job job_local117156066_0036 running in uber mode : false
2020-11-19 16:27:57  [ main:56599 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:57  [ main:56599 ] - [ INFO ]  Job job_local117156066_0036 completed successfully
2020-11-19 16:27:57  [ main:56600 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=119500
		FILE: Number of bytes written=20605174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2315486
		HDFS: Number of bytes written=37468
		HDFS: Number of read operations=2373
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=772
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1605369856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:27:57  [ main:57223 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:57  [ main:57242 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:57  [ main:57246 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:57  [ main:57251 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:57  [ main:57299 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:57  [ main:57316 ] - [ INFO ]  Submitting tokens for job: job_local1457565951_0037
2020-11-19 16:27:57  [ main:57351 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:57  [ main:57351 ] - [ INFO ]  Running job: job_local1457565951_0037
2020-11-19 16:27:57  [ Thread-1098:57351 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:57  [ Thread-1098:57352 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:57  [ Thread-1098:57352 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:57  [ Thread-1098:57395 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57395 ] - [ INFO ]  Starting task: attempt_local1457565951_0037_m_000000_0
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57395 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57396 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57396 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57396 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57405 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57405 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57405 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57405 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57405 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57405 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57508 ] - [ INFO ]  
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57508 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57508 ] - [ INFO ]  Spilling map output
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57508 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57508 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57510 ] - [ INFO ]  Finished spill 0
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57510 ] - [ INFO ]  Task:attempt_local1457565951_0037_m_000000_0 is done. And is in the process of committing
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57519 ] - [ INFO ]  map
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57519 ] - [ INFO ]  Task 'attempt_local1457565951_0037_m_000000_0' done.
2020-11-19 16:27:57  [ LocalJobRunner Map Task Executor #0:57519 ] - [ INFO ]  Finishing task: attempt_local1457565951_0037_m_000000_0
2020-11-19 16:27:57  [ Thread-1098:57519 ] - [ INFO ]  map task executor complete.
2020-11-19 16:27:57  [ Thread-1098:57520 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:27:57  [ pool-114-thread-1:57520 ] - [ INFO ]  Starting task: attempt_local1457565951_0037_r_000000_0
2020-11-19 16:27:57  [ pool-114-thread-1:57520 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:57  [ pool-114-thread-1:57520 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:57  [ pool-114-thread-1:57520 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:57  [ pool-114-thread-1:57520 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22ce4f8e
2020-11-19 16:27:57  [ pool-114-thread-1:57520 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:27:57  [ EventFetcher for fetching Map Completion Events:57521 ] - [ INFO ]  attempt_local1457565951_0037_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:27:57  [ localfetcher#37:57521 ] - [ INFO ]  localfetcher#37 about to shuffle output of map attempt_local1457565951_0037_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:27:57  [ localfetcher#37:57521 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1457565951_0037_m_000000_0
2020-11-19 16:27:57  [ localfetcher#37:57521 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:27:57  [ EventFetcher for fetching Map Completion Events:57522 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:27:57  [ pool-114-thread-1:57522 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:57  [ pool-114-thread-1:57522 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:27:57  [ pool-114-thread-1:57523 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:58  [ pool-114-thread-1:57600 ] - [ INFO ]  Task:attempt_local1457565951_0037_r_000000_0 is done. And is in the process of committing
2020-11-19 16:27:58  [ pool-114-thread-1:57610 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:27:58  [ pool-114-thread-1:57610 ] - [ INFO ]  Task attempt_local1457565951_0037_r_000000_0 is allowed to commit now
2020-11-19 16:27:58  [ pool-114-thread-1:57631 ] - [ INFO ]  Saved output of task 'attempt_local1457565951_0037_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1457565951_0037_r_000000
2020-11-19 16:27:58  [ pool-114-thread-1:57632 ] - [ INFO ]  reduce > reduce
2020-11-19 16:27:58  [ pool-114-thread-1:57632 ] - [ INFO ]  Task 'attempt_local1457565951_0037_r_000000_0' done.
2020-11-19 16:27:58  [ pool-114-thread-1:57632 ] - [ INFO ]  Finishing task: attempt_local1457565951_0037_r_000000_0
2020-11-19 16:27:58  [ Thread-1098:57632 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:27:58  [ main:58355 ] - [ INFO ]  Job job_local1457565951_0037 running in uber mode : false
2020-11-19 16:27:58  [ main:58355 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:27:58  [ main:58355 ] - [ INFO ]  Job job_local1457565951_0037 completed successfully
2020-11-19 16:27:58  [ main:58355 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=120696
		FILE: Number of bytes written=21177097
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2379878
		HDFS: Number of bytes written=38538
		HDFS: Number of read operations=2441
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=794
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1605369856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:27:59  [ main:59242 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:27:59  [ main:59291 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:27:59  [ main:59296 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:27:59  [ main:59314 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:27:59  [ main:59380 ] - [ INFO ]  number of splits:1
2020-11-19 16:27:59  [ main:59398 ] - [ INFO ]  Submitting tokens for job: job_local1665060440_0038
2020-11-19 16:27:59  [ main:59432 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:27:59  [ main:59432 ] - [ INFO ]  Running job: job_local1665060440_0038
2020-11-19 16:27:59  [ Thread-1128:59432 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:27:59  [ Thread-1128:59432 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:59  [ Thread-1128:59432 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:27:59  [ Thread-1128:59450 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59450 ] - [ INFO ]  Starting task: attempt_local1665060440_0038_m_000000_0
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59451 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59451 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59451 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59451 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59459 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59459 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59459 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59459 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59459 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:27:59  [ LocalJobRunner Map Task Executor #0:59460 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59639 ] - [ INFO ]  
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59639 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59639 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59639 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59639 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59641 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59641 ] - [ INFO ]  Task:attempt_local1665060440_0038_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59675 ] - [ INFO ]  map
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59675 ] - [ INFO ]  Task 'attempt_local1665060440_0038_m_000000_0' done.
2020-11-19 16:28:00  [ LocalJobRunner Map Task Executor #0:59676 ] - [ INFO ]  Finishing task: attempt_local1665060440_0038_m_000000_0
2020-11-19 16:28:00  [ Thread-1128:59676 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:00  [ Thread-1128:59676 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:00  [ pool-117-thread-1:59676 ] - [ INFO ]  Starting task: attempt_local1665060440_0038_r_000000_0
2020-11-19 16:28:00  [ pool-117-thread-1:59677 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:00  [ pool-117-thread-1:59677 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:00  [ pool-117-thread-1:59677 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:00  [ pool-117-thread-1:59677 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e1d3ae4
2020-11-19 16:28:00  [ pool-117-thread-1:59677 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:00  [ EventFetcher for fetching Map Completion Events:59678 ] - [ INFO ]  attempt_local1665060440_0038_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:00  [ localfetcher#38:59679 ] - [ INFO ]  localfetcher#38 about to shuffle output of map attempt_local1665060440_0038_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:00  [ localfetcher#38:59679 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1665060440_0038_m_000000_0
2020-11-19 16:28:00  [ localfetcher#38:59679 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:00  [ EventFetcher for fetching Map Completion Events:59679 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:00  [ pool-117-thread-1:59680 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:00  [ pool-117-thread-1:59680 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:00  [ pool-117-thread-1:59681 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:00  [ pool-117-thread-1:59681 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:00  [ pool-117-thread-1:59682 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:00  [ pool-117-thread-1:59682 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:00  [ pool-117-thread-1:59682 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:00  [ pool-117-thread-1:59682 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:00  [ pool-117-thread-1:59682 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:00  [ pool-117-thread-1:59682 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:00  [ pool-117-thread-1:59824 ] - [ INFO ]  Task:attempt_local1665060440_0038_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:00  [ pool-117-thread-1:59881 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:00  [ pool-117-thread-1:59881 ] - [ INFO ]  Task attempt_local1665060440_0038_r_000000_0 is allowed to commit now
2020-11-19 16:28:00  [ pool-117-thread-1:59981 ] - [ INFO ]  Saved output of task 'attempt_local1665060440_0038_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1665060440_0038_r_000000
2020-11-19 16:28:00  [ pool-117-thread-1:59981 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:00  [ pool-117-thread-1:59981 ] - [ INFO ]  Task 'attempt_local1665060440_0038_r_000000_0' done.
2020-11-19 16:28:00  [ pool-117-thread-1:59981 ] - [ INFO ]  Finishing task: attempt_local1665060440_0038_r_000000_0
2020-11-19 16:28:00  [ Thread-1128:59981 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:00  [ main:60433 ] - [ INFO ]  Job job_local1665060440_0038 running in uber mode : false
2020-11-19 16:28:00  [ main:60433 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:00  [ main:60433 ] - [ INFO ]  Job job_local1665060440_0038 completed successfully
2020-11-19 16:28:00  [ main:60434 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=121890
		FILE: Number of bytes written=21749027
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2444280
		HDFS: Number of bytes written=39616
		HDFS: Number of read operations=2509
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=816
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1605369856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:02  [ main:61909 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:02  [ main:61925 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:02  [ main:61930 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:02  [ main:61942 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:02  [ main:61998 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:02  [ main:62016 ] - [ INFO ]  Submitting tokens for job: job_local628370894_0039
2020-11-19 16:28:02  [ main:62049 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:02  [ main:62049 ] - [ INFO ]  Running job: job_local628370894_0039
2020-11-19 16:28:02  [ Thread-1158:62050 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:02  [ Thread-1158:62050 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:02  [ Thread-1158:62050 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:02  [ Thread-1158:62070 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62070 ] - [ INFO ]  Starting task: attempt_local628370894_0039_m_000000_0
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62070 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62071 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62071 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62071 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62084 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62084 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62084 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62084 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62084 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62084 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62363 ] - [ INFO ]  
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62363 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62363 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62363 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62363 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62365 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62366 ] - [ INFO ]  Task:attempt_local628370894_0039_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62418 ] - [ INFO ]  map
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62418 ] - [ INFO ]  Task 'attempt_local628370894_0039_m_000000_0' done.
2020-11-19 16:28:02  [ LocalJobRunner Map Task Executor #0:62418 ] - [ INFO ]  Finishing task: attempt_local628370894_0039_m_000000_0
2020-11-19 16:28:02  [ Thread-1158:62418 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:02  [ Thread-1158:62419 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:02  [ pool-120-thread-1:62419 ] - [ INFO ]  Starting task: attempt_local628370894_0039_r_000000_0
2020-11-19 16:28:02  [ pool-120-thread-1:62419 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:02  [ pool-120-thread-1:62420 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:02  [ pool-120-thread-1:62420 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:02  [ pool-120-thread-1:62420 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@888baff
2020-11-19 16:28:02  [ pool-120-thread-1:62421 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:02  [ EventFetcher for fetching Map Completion Events:62421 ] - [ INFO ]  attempt_local628370894_0039_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:02  [ localfetcher#39:62422 ] - [ INFO ]  localfetcher#39 about to shuffle output of map attempt_local628370894_0039_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:02  [ localfetcher#39:62422 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local628370894_0039_m_000000_0
2020-11-19 16:28:02  [ localfetcher#39:62422 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:02  [ EventFetcher for fetching Map Completion Events:62422 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:02  [ pool-120-thread-1:62422 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:02  [ pool-120-thread-1:62422 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:02  [ pool-120-thread-1:62423 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:02  [ pool-120-thread-1:62423 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:02  [ pool-120-thread-1:62424 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:02  [ pool-120-thread-1:62424 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:02  [ pool-120-thread-1:62424 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:02  [ pool-120-thread-1:62424 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:02  [ pool-120-thread-1:62424 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:02  [ pool-120-thread-1:62424 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:03  [ pool-120-thread-1:62717 ] - [ INFO ]  Task:attempt_local628370894_0039_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:03  [ pool-120-thread-1:62753 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:03  [ pool-120-thread-1:62753 ] - [ INFO ]  Task attempt_local628370894_0039_r_000000_0 is allowed to commit now
2020-11-19 16:28:03  [ main:63054 ] - [ INFO ]  Job job_local628370894_0039 running in uber mode : false
2020-11-19 16:28:03  [ main:63055 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 16:28:03  [ pool-120-thread-1:63167 ] - [ INFO ]  Saved output of task 'attempt_local628370894_0039_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local628370894_0039_r_000000
2020-11-19 16:28:03  [ pool-120-thread-1:63167 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:03  [ pool-120-thread-1:63167 ] - [ INFO ]  Task 'attempt_local628370894_0039_r_000000_0' done.
2020-11-19 16:28:03  [ pool-120-thread-1:63167 ] - [ INFO ]  Finishing task: attempt_local628370894_0039_r_000000_0
2020-11-19 16:28:03  [ Thread-1158:63167 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:04  [ main:64058 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:04  [ main:64058 ] - [ INFO ]  Job job_local628370894_0039 completed successfully
2020-11-19 16:28:04  [ main:64058 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=123088
		FILE: Number of bytes written=22317907
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2508670
		HDFS: Number of bytes written=40687
		HDFS: Number of read operations=2577
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=838
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1565523968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:05  [ main:65087 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:05  [ main:65104 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:05  [ main:65109 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:05  [ main:65132 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:05  [ main:65204 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:05  [ main:65224 ] - [ INFO ]  Submitting tokens for job: job_local1643968433_0040
2020-11-19 16:28:05  [ main:65259 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:05  [ main:65259 ] - [ INFO ]  Running job: job_local1643968433_0040
2020-11-19 16:28:05  [ Thread-1188:65259 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:05  [ Thread-1188:65259 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:05  [ Thread-1188:65259 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:05  [ Thread-1188:65271 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65271 ] - [ INFO ]  Starting task: attempt_local1643968433_0040_m_000000_0
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65271 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65271 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65271 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65272 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65280 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65280 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65280 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65280 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65280 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65280 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65497 ] - [ INFO ]  
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65497 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65497 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65497 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65497 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65499 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65500 ] - [ INFO ]  Task:attempt_local1643968433_0040_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65508 ] - [ INFO ]  map
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65508 ] - [ INFO ]  Task 'attempt_local1643968433_0040_m_000000_0' done.
2020-11-19 16:28:05  [ LocalJobRunner Map Task Executor #0:65508 ] - [ INFO ]  Finishing task: attempt_local1643968433_0040_m_000000_0
2020-11-19 16:28:05  [ Thread-1188:65508 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:05  [ Thread-1188:65508 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:05  [ pool-123-thread-1:65509 ] - [ INFO ]  Starting task: attempt_local1643968433_0040_r_000000_0
2020-11-19 16:28:05  [ pool-123-thread-1:65509 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:05  [ pool-123-thread-1:65509 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:05  [ pool-123-thread-1:65509 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:05  [ pool-123-thread-1:65509 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@536362e9
2020-11-19 16:28:05  [ pool-123-thread-1:65510 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:05  [ EventFetcher for fetching Map Completion Events:65510 ] - [ INFO ]  attempt_local1643968433_0040_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:05  [ localfetcher#40:65511 ] - [ INFO ]  localfetcher#40 about to shuffle output of map attempt_local1643968433_0040_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:05  [ localfetcher#40:65511 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1643968433_0040_m_000000_0
2020-11-19 16:28:05  [ localfetcher#40:65511 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:05  [ EventFetcher for fetching Map Completion Events:65511 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:05  [ pool-123-thread-1:65512 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:05  [ pool-123-thread-1:65512 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:05  [ pool-123-thread-1:65512 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:05  [ pool-123-thread-1:65513 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:05  [ pool-123-thread-1:65513 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:05  [ pool-123-thread-1:65513 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:05  [ pool-123-thread-1:65513 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:05  [ pool-123-thread-1:65513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:05  [ pool-123-thread-1:65513 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:05  [ pool-123-thread-1:65514 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:06  [ pool-123-thread-1:65585 ] - [ INFO ]  Task:attempt_local1643968433_0040_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:06  [ pool-123-thread-1:65591 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:06  [ pool-123-thread-1:65591 ] - [ INFO ]  Task attempt_local1643968433_0040_r_000000_0 is allowed to commit now
2020-11-19 16:28:06  [ pool-123-thread-1:65618 ] - [ INFO ]  Saved output of task 'attempt_local1643968433_0040_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1643968433_0040_r_000000
2020-11-19 16:28:06  [ pool-123-thread-1:65618 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:06  [ pool-123-thread-1:65619 ] - [ INFO ]  Task 'attempt_local1643968433_0040_r_000000_0' done.
2020-11-19 16:28:06  [ pool-123-thread-1:65619 ] - [ INFO ]  Finishing task: attempt_local1643968433_0040_r_000000_0
2020-11-19 16:28:06  [ Thread-1188:65619 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:06  [ main:66259 ] - [ INFO ]  Job job_local1643968433_0040 running in uber mode : false
2020-11-19 16:28:06  [ main:66259 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:06  [ main:66260 ] - [ INFO ]  Job job_local1643968433_0040 completed successfully
2020-11-19 16:28:06  [ main:66260 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=124288
		FILE: Number of bytes written=22889842
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2573080
		HDFS: Number of bytes written=41770
		HDFS: Number of read operations=2645
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=860
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1565523968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:09  [ main:68868 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:09  [ main:68890 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:09  [ main:68895 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:09  [ main:68908 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:09  [ main:68961 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:09  [ main:68982 ] - [ INFO ]  Submitting tokens for job: job_local1986018140_0041
2020-11-19 16:28:09  [ main:69026 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:09  [ main:69026 ] - [ INFO ]  Running job: job_local1986018140_0041
2020-11-19 16:28:09  [ Thread-1218:69026 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:09  [ Thread-1218:69026 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:09  [ Thread-1218:69026 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:09  [ Thread-1218:69061 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69061 ] - [ INFO ]  Starting task: attempt_local1986018140_0041_m_000000_0
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69061 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69061 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69061 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69062 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69073 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69073 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69073 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69073 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69073 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:09  [ LocalJobRunner Map Task Executor #0:69073 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:10  [ main:70027 ] - [ INFO ]  Job job_local1986018140_0041 running in uber mode : false
2020-11-19 16:28:10  [ main:70027 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71073 ] - [ INFO ]  
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71073 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71073 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71073 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71073 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71075 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71076 ] - [ INFO ]  Task:attempt_local1986018140_0041_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71095 ] - [ INFO ]  map
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71095 ] - [ INFO ]  Task 'attempt_local1986018140_0041_m_000000_0' done.
2020-11-19 16:28:11  [ LocalJobRunner Map Task Executor #0:71095 ] - [ INFO ]  Finishing task: attempt_local1986018140_0041_m_000000_0
2020-11-19 16:28:11  [ Thread-1218:71095 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:11  [ Thread-1218:71095 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:11  [ pool-126-thread-1:71096 ] - [ INFO ]  Starting task: attempt_local1986018140_0041_r_000000_0
2020-11-19 16:28:11  [ pool-126-thread-1:71096 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:11  [ pool-126-thread-1:71096 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:11  [ pool-126-thread-1:71096 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:11  [ pool-126-thread-1:71096 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b70dafb
2020-11-19 16:28:11  [ pool-126-thread-1:71096 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:11  [ EventFetcher for fetching Map Completion Events:71096 ] - [ INFO ]  attempt_local1986018140_0041_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:11  [ localfetcher#41:71097 ] - [ INFO ]  localfetcher#41 about to shuffle output of map attempt_local1986018140_0041_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:11  [ localfetcher#41:71097 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1986018140_0041_m_000000_0
2020-11-19 16:28:11  [ localfetcher#41:71097 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:11  [ EventFetcher for fetching Map Completion Events:71097 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:11  [ pool-126-thread-1:71097 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:11  [ pool-126-thread-1:71097 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:11  [ pool-126-thread-1:71098 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:11  [ pool-126-thread-1:71098 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:11  [ pool-126-thread-1:71098 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:11  [ pool-126-thread-1:71099 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:11  [ pool-126-thread-1:71099 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:11  [ pool-126-thread-1:71099 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:11  [ pool-126-thread-1:71099 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:11  [ pool-126-thread-1:71099 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:11  [ pool-126-thread-1:71254 ] - [ INFO ]  Task:attempt_local1986018140_0041_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:11  [ pool-126-thread-1:71268 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:11  [ pool-126-thread-1:71268 ] - [ INFO ]  Task attempt_local1986018140_0041_r_000000_0 is allowed to commit now
2020-11-19 16:28:11  [ pool-126-thread-1:71303 ] - [ INFO ]  Saved output of task 'attempt_local1986018140_0041_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1986018140_0041_r_000000
2020-11-19 16:28:11  [ pool-126-thread-1:71303 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:11  [ pool-126-thread-1:71303 ] - [ INFO ]  Task 'attempt_local1986018140_0041_r_000000_0' done.
2020-11-19 16:28:11  [ pool-126-thread-1:71303 ] - [ INFO ]  Finishing task: attempt_local1986018140_0041_r_000000_0
2020-11-19 16:28:11  [ Thread-1218:71303 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:12  [ main:72045 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:12  [ main:72045 ] - [ INFO ]  Job job_local1986018140_0041 completed successfully
2020-11-19 16:28:12  [ main:72046 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=125484
		FILE: Number of bytes written=23461765
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2637472
		HDFS: Number of bytes written=42840
		HDFS: Number of read operations=2713
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=882
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1565523968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:12  [ main:72426 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:12  [ main:72446 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:12  [ main:72461 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:12  [ main:72466 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:12  [ main:72532 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:13  [ main:72559 ] - [ INFO ]  Submitting tokens for job: job_local1978730455_0042
2020-11-19 16:28:13  [ main:72611 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:13  [ main:72611 ] - [ INFO ]  Running job: job_local1978730455_0042
2020-11-19 16:28:13  [ Thread-1248:72612 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:13  [ Thread-1248:72612 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:13  [ Thread-1248:72612 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:13  [ Thread-1248:72619 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72619 ] - [ INFO ]  Starting task: attempt_local1978730455_0042_m_000000_0
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72619 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72620 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72620 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72620 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72632 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72632 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72632 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72632 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72632 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72633 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72714 ] - [ INFO ]  
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72714 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72714 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72714 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72714 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72716 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72717 ] - [ INFO ]  Task:attempt_local1978730455_0042_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72726 ] - [ INFO ]  map
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72726 ] - [ INFO ]  Task 'attempt_local1978730455_0042_m_000000_0' done.
2020-11-19 16:28:13  [ LocalJobRunner Map Task Executor #0:72726 ] - [ INFO ]  Finishing task: attempt_local1978730455_0042_m_000000_0
2020-11-19 16:28:13  [ Thread-1248:72726 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:13  [ Thread-1248:72727 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:13  [ pool-129-thread-1:72727 ] - [ INFO ]  Starting task: attempt_local1978730455_0042_r_000000_0
2020-11-19 16:28:13  [ pool-129-thread-1:72727 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:13  [ pool-129-thread-1:72727 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:13  [ pool-129-thread-1:72727 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:13  [ pool-129-thread-1:72727 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32d16ee5
2020-11-19 16:28:13  [ pool-129-thread-1:72728 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:13  [ EventFetcher for fetching Map Completion Events:72728 ] - [ INFO ]  attempt_local1978730455_0042_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:13  [ localfetcher#42:72729 ] - [ INFO ]  localfetcher#42 about to shuffle output of map attempt_local1978730455_0042_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:13  [ localfetcher#42:72729 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1978730455_0042_m_000000_0
2020-11-19 16:28:13  [ localfetcher#42:72729 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:13  [ EventFetcher for fetching Map Completion Events:72730 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:13  [ pool-129-thread-1:72730 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:13  [ pool-129-thread-1:72730 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:13  [ pool-129-thread-1:72731 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:13  [ pool-129-thread-1:72731 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:13  [ pool-129-thread-1:72731 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:13  [ pool-129-thread-1:72731 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:13  [ pool-129-thread-1:72731 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:13  [ pool-129-thread-1:72731 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:13  [ pool-129-thread-1:72732 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:13  [ pool-129-thread-1:72732 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:13  [ pool-129-thread-1:72801 ] - [ INFO ]  Task:attempt_local1978730455_0042_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:13  [ pool-129-thread-1:72811 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:13  [ pool-129-thread-1:72811 ] - [ INFO ]  Task attempt_local1978730455_0042_r_000000_0 is allowed to commit now
2020-11-19 16:28:13  [ pool-129-thread-1:72830 ] - [ INFO ]  Saved output of task 'attempt_local1978730455_0042_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1978730455_0042_r_000000
2020-11-19 16:28:13  [ pool-129-thread-1:72831 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:13  [ pool-129-thread-1:72831 ] - [ INFO ]  Task 'attempt_local1978730455_0042_r_000000_0' done.
2020-11-19 16:28:13  [ pool-129-thread-1:72831 ] - [ INFO ]  Finishing task: attempt_local1978730455_0042_r_000000_0
2020-11-19 16:28:13  [ Thread-1248:72831 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:14  [ main:73615 ] - [ INFO ]  Job job_local1978730455_0042 running in uber mode : false
2020-11-19 16:28:14  [ main:73615 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:14  [ main:73615 ] - [ INFO ]  Job job_local1978730455_0042 completed successfully
2020-11-19 16:28:14  [ main:73616 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=126678
		FILE: Number of bytes written=24033695
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2701874
		HDFS: Number of bytes written=43918
		HDFS: Number of read operations=2781
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=904
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1527775232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:14  [ main:73942 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:14  [ main:73958 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:14  [ main:73962 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:14  [ main:73969 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:14  [ main:74006 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:14  [ main:74024 ] - [ INFO ]  Submitting tokens for job: job_local737054923_0043
2020-11-19 16:28:14  [ main:74059 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:14  [ main:74059 ] - [ INFO ]  Running job: job_local737054923_0043
2020-11-19 16:28:14  [ Thread-1278:74059 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:14  [ Thread-1278:74059 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:14  [ Thread-1278:74059 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:14  [ Thread-1278:74066 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74066 ] - [ INFO ]  Starting task: attempt_local737054923_0043_m_000000_0
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74066 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74066 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74066 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74067 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74074 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74074 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74074 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74074 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74074 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74075 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74149 ] - [ INFO ]  
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74149 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74149 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74149 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74149 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74151 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74151 ] - [ INFO ]  Task:attempt_local737054923_0043_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74157 ] - [ INFO ]  map
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74158 ] - [ INFO ]  Task 'attempt_local737054923_0043_m_000000_0' done.
2020-11-19 16:28:14  [ LocalJobRunner Map Task Executor #0:74158 ] - [ INFO ]  Finishing task: attempt_local737054923_0043_m_000000_0
2020-11-19 16:28:14  [ Thread-1278:74158 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:14  [ Thread-1278:74158 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:14  [ pool-132-thread-1:74158 ] - [ INFO ]  Starting task: attempt_local737054923_0043_r_000000_0
2020-11-19 16:28:14  [ pool-132-thread-1:74158 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:14  [ pool-132-thread-1:74159 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:14  [ pool-132-thread-1:74159 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:14  [ pool-132-thread-1:74159 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@18b86860
2020-11-19 16:28:14  [ pool-132-thread-1:74159 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:14  [ EventFetcher for fetching Map Completion Events:74159 ] - [ INFO ]  attempt_local737054923_0043_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:14  [ localfetcher#43:74160 ] - [ INFO ]  localfetcher#43 about to shuffle output of map attempt_local737054923_0043_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:14  [ localfetcher#43:74160 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local737054923_0043_m_000000_0
2020-11-19 16:28:14  [ localfetcher#43:74160 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:14  [ EventFetcher for fetching Map Completion Events:74160 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:14  [ pool-132-thread-1:74161 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:14  [ pool-132-thread-1:74161 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:14  [ pool-132-thread-1:74162 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:14  [ pool-132-thread-1:74162 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:14  [ pool-132-thread-1:74162 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:14  [ pool-132-thread-1:74163 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:14  [ pool-132-thread-1:74163 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:14  [ pool-132-thread-1:74163 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:14  [ pool-132-thread-1:74163 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:14  [ pool-132-thread-1:74163 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:14  [ pool-132-thread-1:74207 ] - [ INFO ]  Task:attempt_local737054923_0043_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:14  [ pool-132-thread-1:74215 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:14  [ pool-132-thread-1:74215 ] - [ INFO ]  Task attempt_local737054923_0043_r_000000_0 is allowed to commit now
2020-11-19 16:28:14  [ pool-132-thread-1:74232 ] - [ INFO ]  Saved output of task 'attempt_local737054923_0043_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local737054923_0043_r_000000
2020-11-19 16:28:14  [ pool-132-thread-1:74233 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:14  [ pool-132-thread-1:74233 ] - [ INFO ]  Task 'attempt_local737054923_0043_r_000000_0' done.
2020-11-19 16:28:14  [ pool-132-thread-1:74233 ] - [ INFO ]  Finishing task: attempt_local737054923_0043_r_000000_0
2020-11-19 16:28:14  [ Thread-1278:74233 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:15  [ main:75063 ] - [ INFO ]  Job job_local737054923_0043 running in uber mode : false
2020-11-19 16:28:15  [ main:75064 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:15  [ main:75064 ] - [ INFO ]  Job job_local737054923_0043 completed successfully
2020-11-19 16:28:15  [ main:75064 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=127876
		FILE: Number of bytes written=24602575
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2766264
		HDFS: Number of bytes written=44989
		HDFS: Number of read operations=2849
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=926
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1527775232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:15  [ main:75353 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:15  [ main:75366 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:15  [ main:75371 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:15  [ main:75378 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:15  [ main:75419 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:15  [ main:75436 ] - [ INFO ]  Submitting tokens for job: job_local1152957799_0044
2020-11-19 16:28:15  [ main:75471 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:15  [ main:75471 ] - [ INFO ]  Running job: job_local1152957799_0044
2020-11-19 16:28:15  [ Thread-1308:75471 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:15  [ Thread-1308:75471 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:15  [ Thread-1308:75471 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:15  [ Thread-1308:75478 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75478 ] - [ INFO ]  Starting task: attempt_local1152957799_0044_m_000000_0
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75478 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75478 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75478 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75479 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75487 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75487 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75487 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75487 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75487 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:15  [ LocalJobRunner Map Task Executor #0:75488 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75594 ] - [ INFO ]  
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75594 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75594 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75594 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75594 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75597 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75598 ] - [ INFO ]  Task:attempt_local1152957799_0044_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75605 ] - [ INFO ]  map
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75605 ] - [ INFO ]  Task 'attempt_local1152957799_0044_m_000000_0' done.
2020-11-19 16:28:16  [ LocalJobRunner Map Task Executor #0:75605 ] - [ INFO ]  Finishing task: attempt_local1152957799_0044_m_000000_0
2020-11-19 16:28:16  [ Thread-1308:75605 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:16  [ Thread-1308:75606 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:16  [ pool-135-thread-1:75606 ] - [ INFO ]  Starting task: attempt_local1152957799_0044_r_000000_0
2020-11-19 16:28:16  [ pool-135-thread-1:75606 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:16  [ pool-135-thread-1:75607 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:16  [ pool-135-thread-1:75607 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:16  [ pool-135-thread-1:75607 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ce46458
2020-11-19 16:28:16  [ pool-135-thread-1:75607 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:16  [ EventFetcher for fetching Map Completion Events:75607 ] - [ INFO ]  attempt_local1152957799_0044_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:16  [ localfetcher#44:75608 ] - [ INFO ]  localfetcher#44 about to shuffle output of map attempt_local1152957799_0044_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:16  [ localfetcher#44:75608 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1152957799_0044_m_000000_0
2020-11-19 16:28:16  [ localfetcher#44:75608 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:16  [ EventFetcher for fetching Map Completion Events:75608 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:16  [ pool-135-thread-1:75608 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:16  [ pool-135-thread-1:75608 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:16  [ pool-135-thread-1:75609 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:16  [ pool-135-thread-1:75609 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:16  [ pool-135-thread-1:75609 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:16  [ pool-135-thread-1:75610 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:16  [ pool-135-thread-1:75610 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:16  [ pool-135-thread-1:75610 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:16  [ pool-135-thread-1:75610 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:16  [ pool-135-thread-1:75610 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:16  [ pool-135-thread-1:75661 ] - [ INFO ]  Task:attempt_local1152957799_0044_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:16  [ pool-135-thread-1:75666 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:16  [ pool-135-thread-1:75666 ] - [ INFO ]  Task attempt_local1152957799_0044_r_000000_0 is allowed to commit now
2020-11-19 16:28:16  [ pool-135-thread-1:75684 ] - [ INFO ]  Saved output of task 'attempt_local1152957799_0044_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1152957799_0044_r_000000
2020-11-19 16:28:16  [ pool-135-thread-1:75684 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:16  [ pool-135-thread-1:75684 ] - [ INFO ]  Task 'attempt_local1152957799_0044_r_000000_0' done.
2020-11-19 16:28:16  [ pool-135-thread-1:75684 ] - [ INFO ]  Finishing task: attempt_local1152957799_0044_r_000000_0
2020-11-19 16:28:16  [ Thread-1308:75684 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:16  [ main:76475 ] - [ INFO ]  Job job_local1152957799_0044 running in uber mode : false
2020-11-19 16:28:16  [ main:76475 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:16  [ main:76476 ] - [ INFO ]  Job job_local1152957799_0044 completed successfully
2020-11-19 16:28:16  [ main:76476 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=129076
		FILE: Number of bytes written=25174510
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2830674
		HDFS: Number of bytes written=46072
		HDFS: Number of read operations=2917
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=948
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1527775232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:17  [ main:76764 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:17  [ main:76776 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:17  [ main:76781 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:17  [ main:76786 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:17  [ main:76824 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:17  [ main:76841 ] - [ INFO ]  Submitting tokens for job: job_local1902244677_0045
2020-11-19 16:28:17  [ main:76875 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:17  [ main:76875 ] - [ INFO ]  Running job: job_local1902244677_0045
2020-11-19 16:28:17  [ Thread-1338:76875 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:17  [ Thread-1338:76875 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:17  [ Thread-1338:76875 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:17  [ Thread-1338:76892 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76892 ] - [ INFO ]  Starting task: attempt_local1902244677_0045_m_000000_0
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76893 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76893 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76893 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76894 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76902 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76903 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76903 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76903 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76903 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:76903 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77031 ] - [ INFO ]  
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77031 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77031 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77031 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77031 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77033 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77034 ] - [ INFO ]  Task:attempt_local1902244677_0045_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77041 ] - [ INFO ]  map
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77041 ] - [ INFO ]  Task 'attempt_local1902244677_0045_m_000000_0' done.
2020-11-19 16:28:17  [ LocalJobRunner Map Task Executor #0:77041 ] - [ INFO ]  Finishing task: attempt_local1902244677_0045_m_000000_0
2020-11-19 16:28:17  [ Thread-1338:77041 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:17  [ Thread-1338:77042 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:17  [ pool-138-thread-1:77042 ] - [ INFO ]  Starting task: attempt_local1902244677_0045_r_000000_0
2020-11-19 16:28:17  [ pool-138-thread-1:77042 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:17  [ pool-138-thread-1:77042 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:17  [ pool-138-thread-1:77042 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:17  [ pool-138-thread-1:77042 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7eeab0b1
2020-11-19 16:28:17  [ pool-138-thread-1:77043 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:17  [ EventFetcher for fetching Map Completion Events:77043 ] - [ INFO ]  attempt_local1902244677_0045_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:17  [ localfetcher#45:77044 ] - [ INFO ]  localfetcher#45 about to shuffle output of map attempt_local1902244677_0045_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:17  [ localfetcher#45:77044 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1902244677_0045_m_000000_0
2020-11-19 16:28:17  [ localfetcher#45:77044 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:17  [ EventFetcher for fetching Map Completion Events:77044 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:17  [ pool-138-thread-1:77044 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:17  [ pool-138-thread-1:77044 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:17  [ pool-138-thread-1:77045 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:17  [ pool-138-thread-1:77045 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:17  [ pool-138-thread-1:77045 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:17  [ pool-138-thread-1:77046 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:17  [ pool-138-thread-1:77046 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:17  [ pool-138-thread-1:77046 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:17  [ pool-138-thread-1:77046 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:17  [ pool-138-thread-1:77046 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:17  [ pool-138-thread-1:77135 ] - [ INFO ]  Task:attempt_local1902244677_0045_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:17  [ pool-138-thread-1:77145 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:17  [ pool-138-thread-1:77145 ] - [ INFO ]  Task attempt_local1902244677_0045_r_000000_0 is allowed to commit now
2020-11-19 16:28:17  [ pool-138-thread-1:77193 ] - [ INFO ]  Saved output of task 'attempt_local1902244677_0045_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1902244677_0045_r_000000
2020-11-19 16:28:17  [ pool-138-thread-1:77194 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:17  [ pool-138-thread-1:77194 ] - [ INFO ]  Task 'attempt_local1902244677_0045_r_000000_0' done.
2020-11-19 16:28:17  [ pool-138-thread-1:77194 ] - [ INFO ]  Finishing task: attempt_local1902244677_0045_r_000000_0
2020-11-19 16:28:17  [ Thread-1338:77194 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:18  [ main:77875 ] - [ INFO ]  Job job_local1902244677_0045 running in uber mode : false
2020-11-19 16:28:18  [ main:77876 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:18  [ main:77876 ] - [ INFO ]  Job job_local1902244677_0045 completed successfully
2020-11-19 16:28:18  [ main:77876 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=130272
		FILE: Number of bytes written=25746433
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2895066
		HDFS: Number of bytes written=47142
		HDFS: Number of read operations=2985
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=970
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1491075072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:18  [ main:78148 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:18  [ main:78159 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:18  [ main:78163 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:18  [ main:78168 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:18  [ main:78207 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:18  [ main:78225 ] - [ INFO ]  Submitting tokens for job: job_local1863407059_0046
2020-11-19 16:28:18  [ main:78258 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:18  [ main:78258 ] - [ INFO ]  Running job: job_local1863407059_0046
2020-11-19 16:28:18  [ Thread-1368:78258 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:18  [ Thread-1368:78259 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:18  [ Thread-1368:78259 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:18  [ Thread-1368:78266 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78266 ] - [ INFO ]  Starting task: attempt_local1863407059_0046_m_000000_0
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78266 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78266 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78266 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78266 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78274 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78274 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78274 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78274 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78274 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78274 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78335 ] - [ INFO ]  
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78335 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78335 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78335 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78335 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78337 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78338 ] - [ INFO ]  Task:attempt_local1863407059_0046_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78349 ] - [ INFO ]  map
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78349 ] - [ INFO ]  Task 'attempt_local1863407059_0046_m_000000_0' done.
2020-11-19 16:28:18  [ LocalJobRunner Map Task Executor #0:78350 ] - [ INFO ]  Finishing task: attempt_local1863407059_0046_m_000000_0
2020-11-19 16:28:18  [ Thread-1368:78350 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:18  [ Thread-1368:78350 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:18  [ pool-141-thread-1:78350 ] - [ INFO ]  Starting task: attempt_local1863407059_0046_r_000000_0
2020-11-19 16:28:18  [ pool-141-thread-1:78351 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:18  [ pool-141-thread-1:78351 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:18  [ pool-141-thread-1:78351 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:18  [ pool-141-thread-1:78351 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f29e0de
2020-11-19 16:28:18  [ pool-141-thread-1:78351 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:18  [ EventFetcher for fetching Map Completion Events:78352 ] - [ INFO ]  attempt_local1863407059_0046_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:18  [ localfetcher#46:78353 ] - [ INFO ]  localfetcher#46 about to shuffle output of map attempt_local1863407059_0046_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:18  [ localfetcher#46:78353 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1863407059_0046_m_000000_0
2020-11-19 16:28:18  [ localfetcher#46:78353 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:18  [ EventFetcher for fetching Map Completion Events:78353 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:18  [ pool-141-thread-1:78354 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:18  [ pool-141-thread-1:78354 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:18  [ pool-141-thread-1:78354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:18  [ pool-141-thread-1:78354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:18  [ pool-141-thread-1:78355 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:18  [ pool-141-thread-1:78355 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:18  [ pool-141-thread-1:78355 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:18  [ pool-141-thread-1:78355 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:18  [ pool-141-thread-1:78355 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:18  [ pool-141-thread-1:78355 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:18  [ pool-141-thread-1:78428 ] - [ INFO ]  Task:attempt_local1863407059_0046_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:18  [ pool-141-thread-1:78432 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:18  [ pool-141-thread-1:78432 ] - [ INFO ]  Task attempt_local1863407059_0046_r_000000_0 is allowed to commit now
2020-11-19 16:28:18  [ pool-141-thread-1:78454 ] - [ INFO ]  Saved output of task 'attempt_local1863407059_0046_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1863407059_0046_r_000000
2020-11-19 16:28:18  [ pool-141-thread-1:78454 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:18  [ pool-141-thread-1:78454 ] - [ INFO ]  Task 'attempt_local1863407059_0046_r_000000_0' done.
2020-11-19 16:28:18  [ pool-141-thread-1:78454 ] - [ INFO ]  Finishing task: attempt_local1863407059_0046_r_000000_0
2020-11-19 16:28:18  [ Thread-1368:78454 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:19  [ main:79264 ] - [ INFO ]  Job job_local1863407059_0046 running in uber mode : false
2020-11-19 16:28:19  [ main:79264 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:19  [ main:79264 ] - [ INFO ]  Job job_local1863407059_0046 completed successfully
2020-11-19 16:28:19  [ main:79265 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=131466
		FILE: Number of bytes written=26318363
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2959468
		HDFS: Number of bytes written=48220
		HDFS: Number of read operations=3053
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=992
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1491075072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:20  [ main:79571 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:20  [ main:79583 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:20  [ main:79588 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:20  [ main:79594 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:20  [ main:79634 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:20  [ main:79651 ] - [ INFO ]  Submitting tokens for job: job_local178748430_0047
2020-11-19 16:28:20  [ main:79685 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:20  [ main:79685 ] - [ INFO ]  Running job: job_local178748430_0047
2020-11-19 16:28:20  [ Thread-1398:79685 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:20  [ Thread-1398:79685 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:20  [ Thread-1398:79685 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:20  [ Thread-1398:79696 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79696 ] - [ INFO ]  Starting task: attempt_local178748430_0047_m_000000_0
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79697 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79697 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79697 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79706 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79706 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79706 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79706 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79706 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79707 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79780 ] - [ INFO ]  
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79780 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79780 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79780 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79780 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79783 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79784 ] - [ INFO ]  Task:attempt_local178748430_0047_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79789 ] - [ INFO ]  map
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79789 ] - [ INFO ]  Task 'attempt_local178748430_0047_m_000000_0' done.
2020-11-19 16:28:20  [ LocalJobRunner Map Task Executor #0:79790 ] - [ INFO ]  Finishing task: attempt_local178748430_0047_m_000000_0
2020-11-19 16:28:20  [ Thread-1398:79790 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:20  [ Thread-1398:79790 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:20  [ pool-144-thread-1:79790 ] - [ INFO ]  Starting task: attempt_local178748430_0047_r_000000_0
2020-11-19 16:28:20  [ pool-144-thread-1:79790 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:20  [ pool-144-thread-1:79790 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:20  [ pool-144-thread-1:79790 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:20  [ pool-144-thread-1:79790 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@43c5fdef
2020-11-19 16:28:20  [ pool-144-thread-1:79791 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:20  [ EventFetcher for fetching Map Completion Events:79791 ] - [ INFO ]  attempt_local178748430_0047_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:20  [ localfetcher#47:79792 ] - [ INFO ]  localfetcher#47 about to shuffle output of map attempt_local178748430_0047_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:20  [ localfetcher#47:79792 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local178748430_0047_m_000000_0
2020-11-19 16:28:20  [ localfetcher#47:79792 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:20  [ EventFetcher for fetching Map Completion Events:79792 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:20  [ pool-144-thread-1:79792 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:20  [ pool-144-thread-1:79792 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:20  [ pool-144-thread-1:79793 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:20  [ pool-144-thread-1:79793 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:20  [ pool-144-thread-1:79794 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:20  [ pool-144-thread-1:79794 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:20  [ pool-144-thread-1:79794 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:20  [ pool-144-thread-1:79794 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:20  [ pool-144-thread-1:79794 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:20  [ pool-144-thread-1:79794 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:20  [ pool-144-thread-1:79856 ] - [ INFO ]  Task:attempt_local178748430_0047_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:20  [ pool-144-thread-1:79864 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:20  [ pool-144-thread-1:79864 ] - [ INFO ]  Task attempt_local178748430_0047_r_000000_0 is allowed to commit now
2020-11-19 16:28:20  [ pool-144-thread-1:79890 ] - [ INFO ]  Saved output of task 'attempt_local178748430_0047_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local178748430_0047_r_000000
2020-11-19 16:28:20  [ pool-144-thread-1:79890 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:20  [ pool-144-thread-1:79890 ] - [ INFO ]  Task 'attempt_local178748430_0047_r_000000_0' done.
2020-11-19 16:28:20  [ pool-144-thread-1:79890 ] - [ INFO ]  Finishing task: attempt_local178748430_0047_r_000000_0
2020-11-19 16:28:20  [ Thread-1398:79891 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:21  [ main:80689 ] - [ INFO ]  Job job_local178748430_0047 running in uber mode : false
2020-11-19 16:28:21  [ main:80689 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:21  [ main:80689 ] - [ INFO ]  Job job_local178748430_0047 completed successfully
2020-11-19 16:28:21  [ main:80690 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=132664
		FILE: Number of bytes written=26887243
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3023858
		HDFS: Number of bytes written=49291
		HDFS: Number of read operations=3121
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1014
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1456472064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:21  [ main:81056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:21  [ main:81068 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:21  [ main:81073 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:21  [ main:81080 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:21  [ main:81120 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:21  [ main:81137 ] - [ INFO ]  Submitting tokens for job: job_local1137396089_0048
2020-11-19 16:28:21  [ main:81167 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:21  [ main:81167 ] - [ INFO ]  Running job: job_local1137396089_0048
2020-11-19 16:28:21  [ Thread-1428:81167 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:21  [ Thread-1428:81167 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:21  [ Thread-1428:81167 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:21  [ Thread-1428:81175 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81175 ] - [ INFO ]  Starting task: attempt_local1137396089_0048_m_000000_0
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81175 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81176 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81176 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81176 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81184 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81184 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81184 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81184 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81184 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81184 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81266 ] - [ INFO ]  
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81266 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81266 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81266 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81266 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81268 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81269 ] - [ INFO ]  Task:attempt_local1137396089_0048_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81276 ] - [ INFO ]  map
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81276 ] - [ INFO ]  Task 'attempt_local1137396089_0048_m_000000_0' done.
2020-11-19 16:28:21  [ LocalJobRunner Map Task Executor #0:81276 ] - [ INFO ]  Finishing task: attempt_local1137396089_0048_m_000000_0
2020-11-19 16:28:21  [ Thread-1428:81276 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:21  [ Thread-1428:81276 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:21  [ pool-147-thread-1:81276 ] - [ INFO ]  Starting task: attempt_local1137396089_0048_r_000000_0
2020-11-19 16:28:21  [ pool-147-thread-1:81276 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:21  [ pool-147-thread-1:81277 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:21  [ pool-147-thread-1:81277 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:21  [ pool-147-thread-1:81277 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1aa4c4d3
2020-11-19 16:28:21  [ pool-147-thread-1:81277 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:21  [ EventFetcher for fetching Map Completion Events:81277 ] - [ INFO ]  attempt_local1137396089_0048_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:21  [ localfetcher#48:81278 ] - [ INFO ]  localfetcher#48 about to shuffle output of map attempt_local1137396089_0048_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:21  [ localfetcher#48:81278 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1137396089_0048_m_000000_0
2020-11-19 16:28:21  [ localfetcher#48:81278 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:21  [ EventFetcher for fetching Map Completion Events:81278 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:21  [ pool-147-thread-1:81278 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:21  [ pool-147-thread-1:81278 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:21  [ pool-147-thread-1:81280 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:21  [ pool-147-thread-1:81280 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:21  [ pool-147-thread-1:81280 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:21  [ pool-147-thread-1:81280 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:21  [ pool-147-thread-1:81281 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:21  [ pool-147-thread-1:81281 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:21  [ pool-147-thread-1:81281 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:21  [ pool-147-thread-1:81281 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:21  [ pool-147-thread-1:81339 ] - [ INFO ]  Task:attempt_local1137396089_0048_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:21  [ pool-147-thread-1:81345 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:21  [ pool-147-thread-1:81345 ] - [ INFO ]  Task attempt_local1137396089_0048_r_000000_0 is allowed to commit now
2020-11-19 16:28:21  [ pool-147-thread-1:81365 ] - [ INFO ]  Saved output of task 'attempt_local1137396089_0048_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1137396089_0048_r_000000
2020-11-19 16:28:21  [ pool-147-thread-1:81365 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:21  [ pool-147-thread-1:81365 ] - [ INFO ]  Task 'attempt_local1137396089_0048_r_000000_0' done.
2020-11-19 16:28:21  [ pool-147-thread-1:81365 ] - [ INFO ]  Finishing task: attempt_local1137396089_0048_r_000000_0
2020-11-19 16:28:21  [ Thread-1428:81365 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:22  [ main:82168 ] - [ INFO ]  Job job_local1137396089_0048 running in uber mode : false
2020-11-19 16:28:22  [ main:82169 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:22  [ main:82169 ] - [ INFO ]  Job job_local1137396089_0048 completed successfully
2020-11-19 16:28:22  [ main:82169 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=133864
		FILE: Number of bytes written=27459178
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3088268
		HDFS: Number of bytes written=50374
		HDFS: Number of read operations=3189
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1036
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1456472064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:22  [ main:82481 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:22  [ main:82492 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:22  [ main:82496 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:22  [ main:82502 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:22  [ main:82538 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:22  [ main:82554 ] - [ INFO ]  Submitting tokens for job: job_local1275106347_0049
2020-11-19 16:28:23  [ main:82586 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:23  [ main:82586 ] - [ INFO ]  Running job: job_local1275106347_0049
2020-11-19 16:28:23  [ Thread-1458:82587 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:23  [ Thread-1458:82587 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:23  [ Thread-1458:82587 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:23  [ Thread-1458:82596 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82596 ] - [ INFO ]  Starting task: attempt_local1275106347_0049_m_000000_0
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82596 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82596 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82596 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82597 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82604 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82604 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82604 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82604 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82604 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82605 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82687 ] - [ INFO ]  
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82687 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82687 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82687 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82687 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82970 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82972 ] - [ INFO ]  Task:attempt_local1275106347_0049_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82978 ] - [ INFO ]  map
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82978 ] - [ INFO ]  Task 'attempt_local1275106347_0049_m_000000_0' done.
2020-11-19 16:28:23  [ LocalJobRunner Map Task Executor #0:82978 ] - [ INFO ]  Finishing task: attempt_local1275106347_0049_m_000000_0
2020-11-19 16:28:23  [ Thread-1458:82978 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:23  [ Thread-1458:82978 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:23  [ pool-150-thread-1:82978 ] - [ INFO ]  Starting task: attempt_local1275106347_0049_r_000000_0
2020-11-19 16:28:23  [ pool-150-thread-1:82978 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:23  [ pool-150-thread-1:82979 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:23  [ pool-150-thread-1:82979 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:23  [ pool-150-thread-1:82979 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44a44f4d
2020-11-19 16:28:23  [ pool-150-thread-1:82979 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:23  [ EventFetcher for fetching Map Completion Events:82979 ] - [ INFO ]  attempt_local1275106347_0049_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:23  [ localfetcher#49:82980 ] - [ INFO ]  localfetcher#49 about to shuffle output of map attempt_local1275106347_0049_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:23  [ localfetcher#49:82980 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1275106347_0049_m_000000_0
2020-11-19 16:28:23  [ localfetcher#49:82980 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:23  [ EventFetcher for fetching Map Completion Events:82980 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:23  [ pool-150-thread-1:82980 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:23  [ pool-150-thread-1:82980 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:23  [ pool-150-thread-1:82981 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:23  [ pool-150-thread-1:82981 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:23  [ pool-150-thread-1:82982 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:23  [ pool-150-thread-1:82982 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:23  [ pool-150-thread-1:82982 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:23  [ pool-150-thread-1:82982 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:23  [ pool-150-thread-1:82982 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:23  [ pool-150-thread-1:82982 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:23  [ pool-150-thread-1:83038 ] - [ INFO ]  Task:attempt_local1275106347_0049_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:23  [ pool-150-thread-1:83044 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:23  [ pool-150-thread-1:83044 ] - [ INFO ]  Task attempt_local1275106347_0049_r_000000_0 is allowed to commit now
2020-11-19 16:28:23  [ pool-150-thread-1:83060 ] - [ INFO ]  Saved output of task 'attempt_local1275106347_0049_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1275106347_0049_r_000000
2020-11-19 16:28:23  [ pool-150-thread-1:83061 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:23  [ pool-150-thread-1:83061 ] - [ INFO ]  Task 'attempt_local1275106347_0049_r_000000_0' done.
2020-11-19 16:28:23  [ pool-150-thread-1:83061 ] - [ INFO ]  Finishing task: attempt_local1275106347_0049_r_000000_0
2020-11-19 16:28:23  [ Thread-1458:83061 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:24  [ main:83589 ] - [ INFO ]  Job job_local1275106347_0049 running in uber mode : false
2020-11-19 16:28:24  [ main:83589 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:24  [ main:83590 ] - [ INFO ]  Job job_local1275106347_0049 completed successfully
2020-11-19 16:28:24  [ main:83590 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=135060
		FILE: Number of bytes written=28031101
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3152660
		HDFS: Number of bytes written=51444
		HDFS: Number of read operations=3257
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1058
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=280
		Total committed heap usage (bytes)=2206203904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:24  [ main:84166 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:24  [ main:84187 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:24  [ main:84193 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:24  [ main:84199 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:24  [ main:84242 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:24  [ main:84258 ] - [ INFO ]  Submitting tokens for job: job_local376695157_0050
2020-11-19 16:28:24  [ main:84291 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:24  [ main:84292 ] - [ INFO ]  Running job: job_local376695157_0050
2020-11-19 16:28:24  [ Thread-1488:84292 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:24  [ Thread-1488:84292 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:24  [ Thread-1488:84292 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:24  [ Thread-1488:84299 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84299 ] - [ INFO ]  Starting task: attempt_local376695157_0050_m_000000_0
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84299 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84299 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84299 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84299 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84308 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84308 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84308 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84308 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84308 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84308 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84399 ] - [ INFO ]  
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84399 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84399 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84399 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84399 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84401 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84401 ] - [ INFO ]  Task:attempt_local376695157_0050_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84408 ] - [ INFO ]  map
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84408 ] - [ INFO ]  Task 'attempt_local376695157_0050_m_000000_0' done.
2020-11-19 16:28:24  [ LocalJobRunner Map Task Executor #0:84408 ] - [ INFO ]  Finishing task: attempt_local376695157_0050_m_000000_0
2020-11-19 16:28:24  [ Thread-1488:84408 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:24  [ Thread-1488:84409 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:24  [ pool-153-thread-1:84409 ] - [ INFO ]  Starting task: attempt_local376695157_0050_r_000000_0
2020-11-19 16:28:24  [ pool-153-thread-1:84409 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:24  [ pool-153-thread-1:84409 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:24  [ pool-153-thread-1:84409 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:24  [ pool-153-thread-1:84409 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b37b2eb
2020-11-19 16:28:24  [ pool-153-thread-1:84409 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:24  [ EventFetcher for fetching Map Completion Events:84410 ] - [ INFO ]  attempt_local376695157_0050_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:24  [ localfetcher#50:84410 ] - [ INFO ]  localfetcher#50 about to shuffle output of map attempt_local376695157_0050_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:24  [ localfetcher#50:84410 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local376695157_0050_m_000000_0
2020-11-19 16:28:24  [ localfetcher#50:84411 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:24  [ EventFetcher for fetching Map Completion Events:84411 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:24  [ pool-153-thread-1:84411 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:24  [ pool-153-thread-1:84411 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:24  [ pool-153-thread-1:84412 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:24  [ pool-153-thread-1:84467 ] - [ INFO ]  Task:attempt_local376695157_0050_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:24  [ pool-153-thread-1:84473 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:24  [ pool-153-thread-1:84473 ] - [ INFO ]  Task attempt_local376695157_0050_r_000000_0 is allowed to commit now
2020-11-19 16:28:24  [ pool-153-thread-1:84494 ] - [ INFO ]  Saved output of task 'attempt_local376695157_0050_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local376695157_0050_r_000000
2020-11-19 16:28:24  [ pool-153-thread-1:84494 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:24  [ pool-153-thread-1:84494 ] - [ INFO ]  Task 'attempt_local376695157_0050_r_000000_0' done.
2020-11-19 16:28:24  [ pool-153-thread-1:84494 ] - [ INFO ]  Finishing task: attempt_local376695157_0050_r_000000_0
2020-11-19 16:28:24  [ Thread-1488:84494 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:25  [ main:85295 ] - [ INFO ]  Job job_local376695157_0050 running in uber mode : false
2020-11-19 16:28:25  [ main:85295 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:25  [ main:85295 ] - [ INFO ]  Job job_local376695157_0050 completed successfully
2020-11-19 16:28:25  [ main:85296 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=136254
		FILE: Number of bytes written=28599983
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3217062
		HDFS: Number of bytes written=52522
		HDFS: Number of read operations=3325
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1080
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2206203904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:26  [ main:85624 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:26  [ main:85637 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:26  [ main:85642 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:26  [ main:85647 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:26  [ main:85685 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:26  [ main:85702 ] - [ INFO ]  Submitting tokens for job: job_local44148255_0051
2020-11-19 16:28:26  [ main:85734 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:26  [ main:85734 ] - [ INFO ]  Running job: job_local44148255_0051
2020-11-19 16:28:26  [ Thread-1518:85734 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:26  [ Thread-1518:85734 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:26  [ Thread-1518:85734 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:26  [ Thread-1518:85740 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85740 ] - [ INFO ]  Starting task: attempt_local44148255_0051_m_000000_0
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85741 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85741 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85741 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85741 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85748 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85748 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85748 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85748 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85748 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85748 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85828 ] - [ INFO ]  
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85828 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85828 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85828 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85828 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85830 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85831 ] - [ INFO ]  Task:attempt_local44148255_0051_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85836 ] - [ INFO ]  map
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85836 ] - [ INFO ]  Task 'attempt_local44148255_0051_m_000000_0' done.
2020-11-19 16:28:26  [ LocalJobRunner Map Task Executor #0:85836 ] - [ INFO ]  Finishing task: attempt_local44148255_0051_m_000000_0
2020-11-19 16:28:26  [ Thread-1518:85836 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:26  [ Thread-1518:85837 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:26  [ pool-156-thread-1:85837 ] - [ INFO ]  Starting task: attempt_local44148255_0051_r_000000_0
2020-11-19 16:28:26  [ pool-156-thread-1:85837 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:26  [ pool-156-thread-1:85837 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:26  [ pool-156-thread-1:85837 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:26  [ pool-156-thread-1:85837 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64046a71
2020-11-19 16:28:26  [ pool-156-thread-1:85838 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:26  [ EventFetcher for fetching Map Completion Events:85838 ] - [ INFO ]  attempt_local44148255_0051_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:26  [ localfetcher#51:85838 ] - [ INFO ]  localfetcher#51 about to shuffle output of map attempt_local44148255_0051_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:26  [ localfetcher#51:85839 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local44148255_0051_m_000000_0
2020-11-19 16:28:26  [ localfetcher#51:85839 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:26  [ EventFetcher for fetching Map Completion Events:85839 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:26  [ pool-156-thread-1:85839 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:26  [ pool-156-thread-1:85839 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:26  [ pool-156-thread-1:85840 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:26  [ pool-156-thread-1:85840 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:26  [ pool-156-thread-1:85840 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:26  [ pool-156-thread-1:85841 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:26  [ pool-156-thread-1:85841 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:26  [ pool-156-thread-1:85841 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:26  [ pool-156-thread-1:85841 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:26  [ pool-156-thread-1:85841 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:26  [ pool-156-thread-1:85890 ] - [ INFO ]  Task:attempt_local44148255_0051_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:26  [ pool-156-thread-1:85896 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:26  [ pool-156-thread-1:85896 ] - [ INFO ]  Task attempt_local44148255_0051_r_000000_0 is allowed to commit now
2020-11-19 16:28:26  [ pool-156-thread-1:85913 ] - [ INFO ]  Saved output of task 'attempt_local44148255_0051_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local44148255_0051_r_000000
2020-11-19 16:28:26  [ pool-156-thread-1:85913 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:26  [ pool-156-thread-1:85913 ] - [ INFO ]  Task 'attempt_local44148255_0051_r_000000_0' done.
2020-11-19 16:28:26  [ pool-156-thread-1:85913 ] - [ INFO ]  Finishing task: attempt_local44148255_0051_r_000000_0
2020-11-19 16:28:26  [ Thread-1518:85913 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:27  [ main:86735 ] - [ INFO ]  Job job_local44148255_0051 running in uber mode : false
2020-11-19 16:28:27  [ main:86735 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:27  [ main:86735 ] - [ INFO ]  Job job_local44148255_0051 completed successfully
2020-11-19 16:28:27  [ main:86736 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=137452
		FILE: Number of bytes written=29165815
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3281452
		HDFS: Number of bytes written=53593
		HDFS: Number of read operations=3393
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1102
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2206203904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:27  [ main:87038 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:27  [ main:87048 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:27  [ main:87053 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:27  [ main:87058 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:27  [ main:87099 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:27  [ main:87116 ] - [ INFO ]  Submitting tokens for job: job_local998652284_0052
2020-11-19 16:28:27  [ main:87145 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:27  [ main:87145 ] - [ INFO ]  Running job: job_local998652284_0052
2020-11-19 16:28:27  [ Thread-1548:87145 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:27  [ Thread-1548:87145 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:27  [ Thread-1548:87145 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:27  [ Thread-1548:87153 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87153 ] - [ INFO ]  Starting task: attempt_local998652284_0052_m_000000_0
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87154 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87154 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87154 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87155 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87164 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87164 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87164 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87164 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87164 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87164 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87244 ] - [ INFO ]  
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87244 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87244 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87244 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87244 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87246 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87247 ] - [ INFO ]  Task:attempt_local998652284_0052_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87253 ] - [ INFO ]  map
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87253 ] - [ INFO ]  Task 'attempt_local998652284_0052_m_000000_0' done.
2020-11-19 16:28:27  [ LocalJobRunner Map Task Executor #0:87253 ] - [ INFO ]  Finishing task: attempt_local998652284_0052_m_000000_0
2020-11-19 16:28:27  [ Thread-1548:87253 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:27  [ Thread-1548:87254 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:27  [ pool-159-thread-1:87254 ] - [ INFO ]  Starting task: attempt_local998652284_0052_r_000000_0
2020-11-19 16:28:27  [ pool-159-thread-1:87254 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:27  [ pool-159-thread-1:87254 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:27  [ pool-159-thread-1:87254 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:27  [ pool-159-thread-1:87254 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a9e248e
2020-11-19 16:28:27  [ pool-159-thread-1:87255 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:27  [ EventFetcher for fetching Map Completion Events:87255 ] - [ INFO ]  attempt_local998652284_0052_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:27  [ localfetcher#52:87256 ] - [ INFO ]  localfetcher#52 about to shuffle output of map attempt_local998652284_0052_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:27  [ localfetcher#52:87256 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local998652284_0052_m_000000_0
2020-11-19 16:28:27  [ localfetcher#52:87256 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:27  [ EventFetcher for fetching Map Completion Events:87256 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:27  [ pool-159-thread-1:87256 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:27  [ pool-159-thread-1:87257 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:27  [ pool-159-thread-1:87257 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:27  [ pool-159-thread-1:87257 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:27  [ pool-159-thread-1:87258 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:27  [ pool-159-thread-1:87258 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:27  [ pool-159-thread-1:87258 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:27  [ pool-159-thread-1:87258 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:27  [ pool-159-thread-1:87258 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:27  [ pool-159-thread-1:87258 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:27  [ pool-159-thread-1:87304 ] - [ INFO ]  Task:attempt_local998652284_0052_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:27  [ pool-159-thread-1:87310 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:27  [ pool-159-thread-1:87310 ] - [ INFO ]  Task attempt_local998652284_0052_r_000000_0 is allowed to commit now
2020-11-19 16:28:27  [ pool-159-thread-1:87329 ] - [ INFO ]  Saved output of task 'attempt_local998652284_0052_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local998652284_0052_r_000000
2020-11-19 16:28:27  [ pool-159-thread-1:87330 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:27  [ pool-159-thread-1:87330 ] - [ INFO ]  Task 'attempt_local998652284_0052_r_000000_0' done.
2020-11-19 16:28:27  [ pool-159-thread-1:87330 ] - [ INFO ]  Finishing task: attempt_local998652284_0052_r_000000_0
2020-11-19 16:28:27  [ Thread-1548:87330 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:28  [ main:88147 ] - [ INFO ]  Job job_local998652284_0052 running in uber mode : false
2020-11-19 16:28:28  [ main:88147 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:28  [ main:88148 ] - [ INFO ]  Job job_local998652284_0052 completed successfully
2020-11-19 16:28:28  [ main:88148 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=138652
		FILE: Number of bytes written=29734702
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3345862
		HDFS: Number of bytes written=54676
		HDFS: Number of read operations=3461
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1124
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2237661184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:28  [ main:88448 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:28  [ main:88460 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:28  [ main:88464 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:28  [ main:88470 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:28  [ main:88513 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:28  [ main:88530 ] - [ INFO ]  Submitting tokens for job: job_local79615303_0053
2020-11-19 16:28:29  [ main:88562 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:29  [ main:88562 ] - [ INFO ]  Running job: job_local79615303_0053
2020-11-19 16:28:29  [ Thread-1578:88562 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:29  [ Thread-1578:88562 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:29  [ Thread-1578:88563 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:29  [ Thread-1578:88571 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88571 ] - [ INFO ]  Starting task: attempt_local79615303_0053_m_000000_0
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88572 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88572 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88572 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88572 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88580 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88580 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88580 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88580 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88580 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88581 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88672 ] - [ INFO ]  
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88672 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88672 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88672 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88672 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88674 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88675 ] - [ INFO ]  Task:attempt_local79615303_0053_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88681 ] - [ INFO ]  map
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88681 ] - [ INFO ]  Task 'attempt_local79615303_0053_m_000000_0' done.
2020-11-19 16:28:29  [ LocalJobRunner Map Task Executor #0:88681 ] - [ INFO ]  Finishing task: attempt_local79615303_0053_m_000000_0
2020-11-19 16:28:29  [ Thread-1578:88681 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:29  [ Thread-1578:88682 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:29  [ pool-162-thread-1:88682 ] - [ INFO ]  Starting task: attempt_local79615303_0053_r_000000_0
2020-11-19 16:28:29  [ pool-162-thread-1:88682 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:29  [ pool-162-thread-1:88682 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:29  [ pool-162-thread-1:88682 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:29  [ pool-162-thread-1:88682 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f83a86b
2020-11-19 16:28:29  [ pool-162-thread-1:88683 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:29  [ EventFetcher for fetching Map Completion Events:88683 ] - [ INFO ]  attempt_local79615303_0053_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:29  [ localfetcher#53:88684 ] - [ INFO ]  localfetcher#53 about to shuffle output of map attempt_local79615303_0053_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:29  [ localfetcher#53:88684 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local79615303_0053_m_000000_0
2020-11-19 16:28:29  [ localfetcher#53:88684 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:29  [ EventFetcher for fetching Map Completion Events:88684 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:29  [ pool-162-thread-1:88684 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:29  [ pool-162-thread-1:88684 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:29  [ pool-162-thread-1:88685 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:29  [ pool-162-thread-1:88685 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:29  [ pool-162-thread-1:88685 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:29  [ pool-162-thread-1:88686 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:29  [ pool-162-thread-1:88686 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:29  [ pool-162-thread-1:88686 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:29  [ pool-162-thread-1:88686 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:29  [ pool-162-thread-1:88686 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:29  [ pool-162-thread-1:88732 ] - [ INFO ]  Task:attempt_local79615303_0053_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:29  [ pool-162-thread-1:88742 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:29  [ pool-162-thread-1:88742 ] - [ INFO ]  Task attempt_local79615303_0053_r_000000_0 is allowed to commit now
2020-11-19 16:28:29  [ pool-162-thread-1:88761 ] - [ INFO ]  Saved output of task 'attempt_local79615303_0053_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local79615303_0053_r_000000
2020-11-19 16:28:29  [ pool-162-thread-1:88761 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:29  [ pool-162-thread-1:88761 ] - [ INFO ]  Task 'attempt_local79615303_0053_r_000000_0' done.
2020-11-19 16:28:29  [ pool-162-thread-1:88761 ] - [ INFO ]  Finishing task: attempt_local79615303_0053_r_000000_0
2020-11-19 16:28:29  [ Thread-1578:88761 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:30  [ main:89565 ] - [ INFO ]  Job job_local79615303_0053 running in uber mode : false
2020-11-19 16:28:30  [ main:89566 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:30  [ main:89566 ] - [ INFO ]  Job job_local79615303_0053 completed successfully
2020-11-19 16:28:30  [ main:89567 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=139848
		FILE: Number of bytes written=30300529
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3410254
		HDFS: Number of bytes written=55746
		HDFS: Number of read operations=3529
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1146
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2237661184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:30  [ main:89879 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:30  [ main:89888 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:30  [ main:89892 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:30  [ main:89897 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:30  [ main:89936 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:30  [ main:89952 ] - [ INFO ]  Submitting tokens for job: job_local575721899_0054
2020-11-19 16:28:30  [ main:89986 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:30  [ main:89986 ] - [ INFO ]  Running job: job_local575721899_0054
2020-11-19 16:28:30  [ Thread-1608:89986 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:30  [ Thread-1608:89986 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:30  [ Thread-1608:89986 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:30  [ Thread-1608:89995 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:89995 ] - [ INFO ]  Starting task: attempt_local575721899_0054_m_000000_0
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:89995 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:89995 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:89995 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:89996 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90003 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90003 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90003 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90003 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90003 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90003 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90127 ] - [ INFO ]  
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90127 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90127 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90127 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90127 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90129 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90129 ] - [ INFO ]  Task:attempt_local575721899_0054_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90135 ] - [ INFO ]  map
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90135 ] - [ INFO ]  Task 'attempt_local575721899_0054_m_000000_0' done.
2020-11-19 16:28:30  [ LocalJobRunner Map Task Executor #0:90135 ] - [ INFO ]  Finishing task: attempt_local575721899_0054_m_000000_0
2020-11-19 16:28:30  [ Thread-1608:90135 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:30  [ Thread-1608:90136 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:30  [ pool-165-thread-1:90136 ] - [ INFO ]  Starting task: attempt_local575721899_0054_r_000000_0
2020-11-19 16:28:30  [ pool-165-thread-1:90136 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:30  [ pool-165-thread-1:90136 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:30  [ pool-165-thread-1:90136 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:30  [ pool-165-thread-1:90136 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54afae5e
2020-11-19 16:28:30  [ pool-165-thread-1:90137 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:30  [ EventFetcher for fetching Map Completion Events:90137 ] - [ INFO ]  attempt_local575721899_0054_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:30  [ localfetcher#54:90138 ] - [ INFO ]  localfetcher#54 about to shuffle output of map attempt_local575721899_0054_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:30  [ localfetcher#54:90138 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local575721899_0054_m_000000_0
2020-11-19 16:28:30  [ localfetcher#54:90138 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:30  [ EventFetcher for fetching Map Completion Events:90138 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:30  [ pool-165-thread-1:90138 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:30  [ pool-165-thread-1:90138 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:30  [ pool-165-thread-1:90139 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:30  [ pool-165-thread-1:90139 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:30  [ pool-165-thread-1:90139 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:30  [ pool-165-thread-1:90139 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:30  [ pool-165-thread-1:90140 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:30  [ pool-165-thread-1:90140 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:30  [ pool-165-thread-1:90140 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:30  [ pool-165-thread-1:90140 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:30  [ pool-165-thread-1:90197 ] - [ INFO ]  Task:attempt_local575721899_0054_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:30  [ pool-165-thread-1:90205 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:30  [ pool-165-thread-1:90205 ] - [ INFO ]  Task attempt_local575721899_0054_r_000000_0 is allowed to commit now
2020-11-19 16:28:30  [ pool-165-thread-1:90222 ] - [ INFO ]  Saved output of task 'attempt_local575721899_0054_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local575721899_0054_r_000000
2020-11-19 16:28:30  [ pool-165-thread-1:90222 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:30  [ pool-165-thread-1:90222 ] - [ INFO ]  Task 'attempt_local575721899_0054_r_000000_0' done.
2020-11-19 16:28:30  [ pool-165-thread-1:90222 ] - [ INFO ]  Finishing task: attempt_local575721899_0054_r_000000_0
2020-11-19 16:28:30  [ Thread-1608:90222 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:31  [ main:90991 ] - [ INFO ]  Job job_local575721899_0054 running in uber mode : false
2020-11-19 16:28:31  [ main:90991 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:31  [ main:90991 ] - [ INFO ]  Job job_local575721899_0054 completed successfully
2020-11-19 16:28:31  [ main:90992 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=141042
		FILE: Number of bytes written=30869411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3474656
		HDFS: Number of bytes written=56824
		HDFS: Number of read operations=3597
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1168
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2237661184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:31  [ main:91291 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:31  [ main:91306 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:31  [ main:91310 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:31  [ main:91316 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:31  [ main:91356 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:31  [ main:91373 ] - [ INFO ]  Submitting tokens for job: job_local103894755_0055
2020-11-19 16:28:31  [ main:91408 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:31  [ main:91408 ] - [ INFO ]  Running job: job_local103894755_0055
2020-11-19 16:28:31  [ Thread-1638:91409 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:31  [ Thread-1638:91409 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:31  [ Thread-1638:91409 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:31  [ Thread-1638:91417 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91417 ] - [ INFO ]  Starting task: attempt_local103894755_0055_m_000000_0
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91417 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91417 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91417 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91418 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91428 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91428 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91428 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91428 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91428 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91428 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91512 ] - [ INFO ]  
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91513 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91513 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91513 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91513 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91514 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91515 ] - [ INFO ]  Task:attempt_local103894755_0055_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91521 ] - [ INFO ]  map
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91521 ] - [ INFO ]  Task 'attempt_local103894755_0055_m_000000_0' done.
2020-11-19 16:28:31  [ LocalJobRunner Map Task Executor #0:91521 ] - [ INFO ]  Finishing task: attempt_local103894755_0055_m_000000_0
2020-11-19 16:28:31  [ Thread-1638:91521 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:31  [ Thread-1638:91521 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:31  [ pool-168-thread-1:91521 ] - [ INFO ]  Starting task: attempt_local103894755_0055_r_000000_0
2020-11-19 16:28:31  [ pool-168-thread-1:91522 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:31  [ pool-168-thread-1:91522 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:31  [ pool-168-thread-1:91522 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:31  [ pool-168-thread-1:91522 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30f434c7
2020-11-19 16:28:31  [ pool-168-thread-1:91522 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:31  [ EventFetcher for fetching Map Completion Events:91522 ] - [ INFO ]  attempt_local103894755_0055_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:31  [ localfetcher#55:91523 ] - [ INFO ]  localfetcher#55 about to shuffle output of map attempt_local103894755_0055_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:31  [ localfetcher#55:91523 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local103894755_0055_m_000000_0
2020-11-19 16:28:31  [ localfetcher#55:91523 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:31  [ EventFetcher for fetching Map Completion Events:91523 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:31  [ pool-168-thread-1:91524 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:31  [ pool-168-thread-1:91524 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:31  [ pool-168-thread-1:91524 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:31  [ pool-168-thread-1:91524 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:31  [ pool-168-thread-1:91525 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:31  [ pool-168-thread-1:91525 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:31  [ pool-168-thread-1:91525 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:31  [ pool-168-thread-1:91525 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:31  [ pool-168-thread-1:91525 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:31  [ pool-168-thread-1:91525 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:32  [ pool-168-thread-1:91576 ] - [ INFO ]  Task:attempt_local103894755_0055_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:32  [ pool-168-thread-1:91582 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:32  [ pool-168-thread-1:91582 ] - [ INFO ]  Task attempt_local103894755_0055_r_000000_0 is allowed to commit now
2020-11-19 16:28:32  [ pool-168-thread-1:91602 ] - [ INFO ]  Saved output of task 'attempt_local103894755_0055_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local103894755_0055_r_000000
2020-11-19 16:28:32  [ pool-168-thread-1:91602 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:32  [ pool-168-thread-1:91602 ] - [ INFO ]  Task 'attempt_local103894755_0055_r_000000_0' done.
2020-11-19 16:28:32  [ pool-168-thread-1:91602 ] - [ INFO ]  Finishing task: attempt_local103894755_0055_r_000000_0
2020-11-19 16:28:32  [ Thread-1638:91602 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:32  [ main:92411 ] - [ INFO ]  Job job_local103894755_0055 running in uber mode : false
2020-11-19 16:28:32  [ main:92411 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:32  [ main:92411 ] - [ INFO ]  Job job_local103894755_0055 completed successfully
2020-11-19 16:28:32  [ main:92411 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=142240
		FILE: Number of bytes written=31438291
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3539046
		HDFS: Number of bytes written=57895
		HDFS: Number of read operations=3665
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1190
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2236612608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:33  [ main:92825 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:33  [ main:92853 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:33  [ main:92858 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:33  [ main:92864 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:33  [ main:92911 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:33  [ main:92929 ] - [ INFO ]  Submitting tokens for job: job_local77605924_0056
2020-11-19 16:28:33  [ main:92961 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:33  [ main:92961 ] - [ INFO ]  Running job: job_local77605924_0056
2020-11-19 16:28:33  [ Thread-1668:92962 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:33  [ Thread-1668:92962 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:33  [ Thread-1668:92962 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:33  [ Thread-1668:92969 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92969 ] - [ INFO ]  Starting task: attempt_local77605924_0056_m_000000_0
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92969 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92969 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92969 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92970 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92977 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92977 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92977 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92977 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92977 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:92977 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93062 ] - [ INFO ]  
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93062 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93062 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93062 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93062 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93064 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93065 ] - [ INFO ]  Task:attempt_local77605924_0056_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93074 ] - [ INFO ]  map
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93074 ] - [ INFO ]  Task 'attempt_local77605924_0056_m_000000_0' done.
2020-11-19 16:28:33  [ LocalJobRunner Map Task Executor #0:93074 ] - [ INFO ]  Finishing task: attempt_local77605924_0056_m_000000_0
2020-11-19 16:28:33  [ Thread-1668:93074 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:33  [ Thread-1668:93074 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:33  [ pool-171-thread-1:93074 ] - [ INFO ]  Starting task: attempt_local77605924_0056_r_000000_0
2020-11-19 16:28:33  [ pool-171-thread-1:93075 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:33  [ pool-171-thread-1:93075 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:33  [ pool-171-thread-1:93075 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:33  [ pool-171-thread-1:93075 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ce0527f
2020-11-19 16:28:33  [ pool-171-thread-1:93075 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:33  [ EventFetcher for fetching Map Completion Events:93075 ] - [ INFO ]  attempt_local77605924_0056_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:33  [ localfetcher#56:93076 ] - [ INFO ]  localfetcher#56 about to shuffle output of map attempt_local77605924_0056_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:33  [ localfetcher#56:93076 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local77605924_0056_m_000000_0
2020-11-19 16:28:33  [ localfetcher#56:93076 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:33  [ EventFetcher for fetching Map Completion Events:93076 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:33  [ pool-171-thread-1:93077 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:33  [ pool-171-thread-1:93077 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:33  [ pool-171-thread-1:93077 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:33  [ pool-171-thread-1:93077 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:33  [ pool-171-thread-1:93078 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:33  [ pool-171-thread-1:93078 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:33  [ pool-171-thread-1:93078 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:33  [ pool-171-thread-1:93078 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:33  [ pool-171-thread-1:93078 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:33  [ pool-171-thread-1:93078 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:33  [ pool-171-thread-1:93133 ] - [ INFO ]  Task:attempt_local77605924_0056_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:33  [ pool-171-thread-1:93139 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:33  [ pool-171-thread-1:93139 ] - [ INFO ]  Task attempt_local77605924_0056_r_000000_0 is allowed to commit now
2020-11-19 16:28:33  [ pool-171-thread-1:93162 ] - [ INFO ]  Saved output of task 'attempt_local77605924_0056_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local77605924_0056_r_000000
2020-11-19 16:28:33  [ pool-171-thread-1:93162 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:33  [ pool-171-thread-1:93162 ] - [ INFO ]  Task 'attempt_local77605924_0056_r_000000_0' done.
2020-11-19 16:28:33  [ pool-171-thread-1:93163 ] - [ INFO ]  Finishing task: attempt_local77605924_0056_r_000000_0
2020-11-19 16:28:33  [ Thread-1668:93163 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:34  [ main:93966 ] - [ INFO ]  Job job_local77605924_0056 running in uber mode : false
2020-11-19 16:28:34  [ main:93967 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:34  [ main:93967 ] - [ INFO ]  Job job_local77605924_0056 completed successfully
2020-11-19 16:28:34  [ main:93967 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=143440
		FILE: Number of bytes written=32004130
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3603456
		HDFS: Number of bytes written=58978
		HDFS: Number of read operations=3733
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1212
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2236612608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:34  [ main:94404 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:34  [ main:94417 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:34  [ main:94421 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:34  [ main:94427 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:34  [ main:94474 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:34  [ main:94492 ] - [ INFO ]  Submitting tokens for job: job_local547384488_0057
2020-11-19 16:28:34  [ main:94526 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:34  [ main:94526 ] - [ INFO ]  Running job: job_local547384488_0057
2020-11-19 16:28:34  [ Thread-1698:94526 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:34  [ Thread-1698:94526 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:34  [ Thread-1698:94526 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:34  [ Thread-1698:94533 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94533 ] - [ INFO ]  Starting task: attempt_local547384488_0057_m_000000_0
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94533 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94533 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94533 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94534 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94541 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94541 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94541 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94541 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94541 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:34  [ LocalJobRunner Map Task Executor #0:94542 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94642 ] - [ INFO ]  
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94642 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94642 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94642 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94642 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94645 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94646 ] - [ INFO ]  Task:attempt_local547384488_0057_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94651 ] - [ INFO ]  map
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94651 ] - [ INFO ]  Task 'attempt_local547384488_0057_m_000000_0' done.
2020-11-19 16:28:35  [ LocalJobRunner Map Task Executor #0:94651 ] - [ INFO ]  Finishing task: attempt_local547384488_0057_m_000000_0
2020-11-19 16:28:35  [ Thread-1698:94651 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:35  [ Thread-1698:94651 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:35  [ pool-174-thread-1:94651 ] - [ INFO ]  Starting task: attempt_local547384488_0057_r_000000_0
2020-11-19 16:28:35  [ pool-174-thread-1:94652 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:35  [ pool-174-thread-1:94652 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:35  [ pool-174-thread-1:94652 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:35  [ pool-174-thread-1:94652 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1524fb44
2020-11-19 16:28:35  [ pool-174-thread-1:94652 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:35  [ EventFetcher for fetching Map Completion Events:94652 ] - [ INFO ]  attempt_local547384488_0057_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:35  [ localfetcher#57:94653 ] - [ INFO ]  localfetcher#57 about to shuffle output of map attempt_local547384488_0057_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:35  [ localfetcher#57:94653 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local547384488_0057_m_000000_0
2020-11-19 16:28:35  [ localfetcher#57:94653 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:35  [ EventFetcher for fetching Map Completion Events:94653 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:35  [ pool-174-thread-1:94654 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:35  [ pool-174-thread-1:94654 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:35  [ pool-174-thread-1:94655 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:35  [ pool-174-thread-1:94655 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:35  [ pool-174-thread-1:94655 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:35  [ pool-174-thread-1:94656 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:35  [ pool-174-thread-1:94656 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:35  [ pool-174-thread-1:94656 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:35  [ pool-174-thread-1:94656 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:35  [ pool-174-thread-1:94656 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:35  [ pool-174-thread-1:94725 ] - [ INFO ]  Task:attempt_local547384488_0057_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:35  [ pool-174-thread-1:94730 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:35  [ pool-174-thread-1:94731 ] - [ INFO ]  Task attempt_local547384488_0057_r_000000_0 is allowed to commit now
2020-11-19 16:28:35  [ pool-174-thread-1:94748 ] - [ INFO ]  Saved output of task 'attempt_local547384488_0057_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local547384488_0057_r_000000
2020-11-19 16:28:35  [ pool-174-thread-1:94748 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:35  [ pool-174-thread-1:94748 ] - [ INFO ]  Task 'attempt_local547384488_0057_r_000000_0' done.
2020-11-19 16:28:35  [ pool-174-thread-1:94748 ] - [ INFO ]  Finishing task: attempt_local547384488_0057_r_000000_0
2020-11-19 16:28:35  [ Thread-1698:94748 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:35  [ main:95529 ] - [ INFO ]  Job job_local547384488_0057 running in uber mode : false
2020-11-19 16:28:35  [ main:95530 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:35  [ main:95530 ] - [ INFO ]  Job job_local547384488_0057 completed successfully
2020-11-19 16:28:35  [ main:95530 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=144636
		FILE: Number of bytes written=32573005
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3667848
		HDFS: Number of bytes written=60048
		HDFS: Number of read operations=3801
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1234
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2236612608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:36  [ main:95848 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:36  [ main:95859 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:36  [ main:95864 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:36  [ main:95870 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:36  [ main:95909 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:36  [ main:95927 ] - [ INFO ]  Submitting tokens for job: job_local1104505294_0058
2020-11-19 16:28:36  [ main:95962 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:36  [ main:95962 ] - [ INFO ]  Running job: job_local1104505294_0058
2020-11-19 16:28:36  [ Thread-1728:95962 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:36  [ Thread-1728:95962 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:36  [ Thread-1728:95962 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:36  [ Thread-1728:95970 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95970 ] - [ INFO ]  Starting task: attempt_local1104505294_0058_m_000000_0
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95971 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95971 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95971 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95971 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95980 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95980 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95980 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95980 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95980 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:95981 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96060 ] - [ INFO ]  
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96060 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96060 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96060 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96060 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96063 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96063 ] - [ INFO ]  Task:attempt_local1104505294_0058_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96068 ] - [ INFO ]  map
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96068 ] - [ INFO ]  Task 'attempt_local1104505294_0058_m_000000_0' done.
2020-11-19 16:28:36  [ LocalJobRunner Map Task Executor #0:96068 ] - [ INFO ]  Finishing task: attempt_local1104505294_0058_m_000000_0
2020-11-19 16:28:36  [ Thread-1728:96068 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:36  [ Thread-1728:96069 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:36  [ pool-177-thread-1:96069 ] - [ INFO ]  Starting task: attempt_local1104505294_0058_r_000000_0
2020-11-19 16:28:36  [ pool-177-thread-1:96069 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:36  [ pool-177-thread-1:96069 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:36  [ pool-177-thread-1:96069 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:36  [ pool-177-thread-1:96069 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e5e0461
2020-11-19 16:28:36  [ pool-177-thread-1:96069 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:36  [ EventFetcher for fetching Map Completion Events:96070 ] - [ INFO ]  attempt_local1104505294_0058_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:36  [ localfetcher#58:96070 ] - [ INFO ]  localfetcher#58 about to shuffle output of map attempt_local1104505294_0058_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:36  [ localfetcher#58:96070 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1104505294_0058_m_000000_0
2020-11-19 16:28:36  [ localfetcher#58:96070 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:36  [ EventFetcher for fetching Map Completion Events:96071 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:36  [ pool-177-thread-1:96071 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:36  [ pool-177-thread-1:96071 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:36  [ pool-177-thread-1:96072 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:36  [ pool-177-thread-1:96072 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:36  [ pool-177-thread-1:96073 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:36  [ pool-177-thread-1:96073 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:36  [ pool-177-thread-1:96073 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:36  [ pool-177-thread-1:96073 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:36  [ pool-177-thread-1:96073 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:36  [ pool-177-thread-1:96073 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:36  [ pool-177-thread-1:96120 ] - [ INFO ]  Task:attempt_local1104505294_0058_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:36  [ pool-177-thread-1:96126 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:36  [ pool-177-thread-1:96126 ] - [ INFO ]  Task attempt_local1104505294_0058_r_000000_0 is allowed to commit now
2020-11-19 16:28:36  [ pool-177-thread-1:96143 ] - [ INFO ]  Saved output of task 'attempt_local1104505294_0058_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1104505294_0058_r_000000
2020-11-19 16:28:36  [ pool-177-thread-1:96143 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:36  [ pool-177-thread-1:96143 ] - [ INFO ]  Task 'attempt_local1104505294_0058_r_000000_0' done.
2020-11-19 16:28:36  [ pool-177-thread-1:96143 ] - [ INFO ]  Finishing task: attempt_local1104505294_0058_r_000000_0
2020-11-19 16:28:36  [ Thread-1728:96143 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:37  [ main:96966 ] - [ INFO ]  Job job_local1104505294_0058 running in uber mode : false
2020-11-19 16:28:37  [ main:96967 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:37  [ main:96967 ] - [ INFO ]  Job job_local1104505294_0058 completed successfully
2020-11-19 16:28:37  [ main:96967 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=145830
		FILE: Number of bytes written=33144935
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3732250
		HDFS: Number of bytes written=61126
		HDFS: Number of read operations=3869
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1256
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2407530496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:38  [ main:97614 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:38  [ main:97632 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:38  [ main:97639 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:38  [ main:97644 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:38  [ main:97683 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:38  [ main:97700 ] - [ INFO ]  Submitting tokens for job: job_local1034138480_0059
2020-11-19 16:28:38  [ main:97734 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:38  [ main:97734 ] - [ INFO ]  Running job: job_local1034138480_0059
2020-11-19 16:28:38  [ Thread-1758:97734 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:38  [ Thread-1758:97734 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:38  [ Thread-1758:97734 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:38  [ Thread-1758:97741 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97741 ] - [ INFO ]  Starting task: attempt_local1034138480_0059_m_000000_0
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97741 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97741 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97741 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97742 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97749 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97749 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97749 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97749 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97749 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97749 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97822 ] - [ INFO ]  
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97822 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97822 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97822 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97822 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97824 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97825 ] - [ INFO ]  Task:attempt_local1034138480_0059_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97832 ] - [ INFO ]  map
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97832 ] - [ INFO ]  Task 'attempt_local1034138480_0059_m_000000_0' done.
2020-11-19 16:28:38  [ LocalJobRunner Map Task Executor #0:97832 ] - [ INFO ]  Finishing task: attempt_local1034138480_0059_m_000000_0
2020-11-19 16:28:38  [ Thread-1758:97832 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:38  [ Thread-1758:97832 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:38  [ pool-180-thread-1:97833 ] - [ INFO ]  Starting task: attempt_local1034138480_0059_r_000000_0
2020-11-19 16:28:38  [ pool-180-thread-1:97833 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:38  [ pool-180-thread-1:97833 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:38  [ pool-180-thread-1:97833 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:38  [ pool-180-thread-1:97833 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c193f03
2020-11-19 16:28:38  [ pool-180-thread-1:97833 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:38  [ EventFetcher for fetching Map Completion Events:97834 ] - [ INFO ]  attempt_local1034138480_0059_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:38  [ localfetcher#59:97834 ] - [ INFO ]  localfetcher#59 about to shuffle output of map attempt_local1034138480_0059_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:38  [ localfetcher#59:97834 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1034138480_0059_m_000000_0
2020-11-19 16:28:38  [ localfetcher#59:97834 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:38  [ EventFetcher for fetching Map Completion Events:97835 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:38  [ pool-180-thread-1:97835 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:38  [ pool-180-thread-1:97835 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:38  [ pool-180-thread-1:97836 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:38  [ pool-180-thread-1:97836 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:38  [ pool-180-thread-1:97836 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:38  [ pool-180-thread-1:97836 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:38  [ pool-180-thread-1:97836 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:38  [ pool-180-thread-1:97836 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:38  [ pool-180-thread-1:97837 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:38  [ pool-180-thread-1:97837 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:38  [ pool-180-thread-1:97879 ] - [ INFO ]  Task:attempt_local1034138480_0059_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:38  [ pool-180-thread-1:97885 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:38  [ pool-180-thread-1:97885 ] - [ INFO ]  Task attempt_local1034138480_0059_r_000000_0 is allowed to commit now
2020-11-19 16:28:38  [ pool-180-thread-1:97902 ] - [ INFO ]  Saved output of task 'attempt_local1034138480_0059_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1034138480_0059_r_000000
2020-11-19 16:28:38  [ pool-180-thread-1:97903 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:38  [ pool-180-thread-1:97903 ] - [ INFO ]  Task 'attempt_local1034138480_0059_r_000000_0' done.
2020-11-19 16:28:38  [ pool-180-thread-1:97903 ] - [ INFO ]  Finishing task: attempt_local1034138480_0059_r_000000_0
2020-11-19 16:28:38  [ Thread-1758:97903 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:39  [ main:98734 ] - [ INFO ]  Job job_local1034138480_0059 running in uber mode : false
2020-11-19 16:28:39  [ main:98735 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:39  [ main:98735 ] - [ INFO ]  Job job_local1034138480_0059 completed successfully
2020-11-19 16:28:39  [ main:98735 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=147028
		FILE: Number of bytes written=33716863
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3796640
		HDFS: Number of bytes written=62197
		HDFS: Number of read operations=3937
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1278
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2407530496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:39  [ main:99080 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:39  [ main:99096 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:39  [ main:99100 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:39  [ main:99105 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:39  [ main:99143 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:39  [ main:99161 ] - [ INFO ]  Submitting tokens for job: job_local360010467_0060
2020-11-19 16:28:39  [ main:99191 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:39  [ main:99191 ] - [ INFO ]  Running job: job_local360010467_0060
2020-11-19 16:28:39  [ Thread-1788:99191 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:39  [ Thread-1788:99191 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:39  [ Thread-1788:99191 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:39  [ Thread-1788:99201 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99201 ] - [ INFO ]  Starting task: attempt_local360010467_0060_m_000000_0
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99201 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99202 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99202 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99202 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99211 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99211 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99211 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99211 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99211 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99211 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99292 ] - [ INFO ]  
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99292 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99292 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99292 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99292 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99295 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99296 ] - [ INFO ]  Task:attempt_local360010467_0060_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99302 ] - [ INFO ]  map
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99302 ] - [ INFO ]  Task 'attempt_local360010467_0060_m_000000_0' done.
2020-11-19 16:28:39  [ LocalJobRunner Map Task Executor #0:99302 ] - [ INFO ]  Finishing task: attempt_local360010467_0060_m_000000_0
2020-11-19 16:28:39  [ Thread-1788:99302 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:39  [ Thread-1788:99303 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:39  [ pool-183-thread-1:99303 ] - [ INFO ]  Starting task: attempt_local360010467_0060_r_000000_0
2020-11-19 16:28:39  [ pool-183-thread-1:99303 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:39  [ pool-183-thread-1:99303 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:39  [ pool-183-thread-1:99303 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:39  [ pool-183-thread-1:99303 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5d8c66ed
2020-11-19 16:28:39  [ pool-183-thread-1:99303 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:39  [ EventFetcher for fetching Map Completion Events:99304 ] - [ INFO ]  attempt_local360010467_0060_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:39  [ localfetcher#60:99304 ] - [ INFO ]  localfetcher#60 about to shuffle output of map attempt_local360010467_0060_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:39  [ localfetcher#60:99304 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local360010467_0060_m_000000_0
2020-11-19 16:28:39  [ localfetcher#60:99304 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:39  [ EventFetcher for fetching Map Completion Events:99305 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:39  [ pool-183-thread-1:99305 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:39  [ pool-183-thread-1:99305 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:39  [ pool-183-thread-1:99305 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:39  [ pool-183-thread-1:99306 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:39  [ pool-183-thread-1:99359 ] - [ INFO ]  Task:attempt_local360010467_0060_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:39  [ pool-183-thread-1:99364 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:39  [ pool-183-thread-1:99364 ] - [ INFO ]  Task attempt_local360010467_0060_r_000000_0 is allowed to commit now
2020-11-19 16:28:39  [ pool-183-thread-1:99380 ] - [ INFO ]  Saved output of task 'attempt_local360010467_0060_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local360010467_0060_r_000000
2020-11-19 16:28:39  [ pool-183-thread-1:99380 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:39  [ pool-183-thread-1:99380 ] - [ INFO ]  Task 'attempt_local360010467_0060_r_000000_0' done.
2020-11-19 16:28:39  [ pool-183-thread-1:99380 ] - [ INFO ]  Finishing task: attempt_local360010467_0060_r_000000_0
2020-11-19 16:28:39  [ Thread-1788:99380 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:40  [ main:100195 ] - [ INFO ]  Job job_local360010467_0060 running in uber mode : false
2020-11-19 16:28:40  [ main:100195 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:40  [ main:100195 ] - [ INFO ]  Job job_local360010467_0060 completed successfully
2020-11-19 16:28:40  [ main:100196 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=148228
		FILE: Number of bytes written=34285750
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3861050
		HDFS: Number of bytes written=63280
		HDFS: Number of read operations=4005
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1300
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2407530496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:40  [ main:100484 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:40  [ main:100495 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:40  [ main:100499 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:40  [ main:100507 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:40  [ main:100545 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:41  [ main:100563 ] - [ INFO ]  Submitting tokens for job: job_local1120429507_0061
2020-11-19 16:28:41  [ main:100603 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:41  [ Thread-1818:100603 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:41  [ main:100603 ] - [ INFO ]  Running job: job_local1120429507_0061
2020-11-19 16:28:41  [ Thread-1818:100603 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:41  [ Thread-1818:100603 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:41  [ Thread-1818:100611 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100611 ] - [ INFO ]  Starting task: attempt_local1120429507_0061_m_000000_0
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100611 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100611 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100611 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100612 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100621 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100622 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100622 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100622 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100622 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100622 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100701 ] - [ INFO ]  
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100701 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100701 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100701 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100701 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100705 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100706 ] - [ INFO ]  Task:attempt_local1120429507_0061_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100712 ] - [ INFO ]  map
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100712 ] - [ INFO ]  Task 'attempt_local1120429507_0061_m_000000_0' done.
2020-11-19 16:28:41  [ LocalJobRunner Map Task Executor #0:100712 ] - [ INFO ]  Finishing task: attempt_local1120429507_0061_m_000000_0
2020-11-19 16:28:41  [ Thread-1818:100712 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:41  [ Thread-1818:100712 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:41  [ pool-186-thread-1:100712 ] - [ INFO ]  Starting task: attempt_local1120429507_0061_r_000000_0
2020-11-19 16:28:41  [ pool-186-thread-1:100713 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:41  [ pool-186-thread-1:100713 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:41  [ pool-186-thread-1:100713 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:41  [ pool-186-thread-1:100713 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2db4b448
2020-11-19 16:28:41  [ pool-186-thread-1:100713 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:41  [ EventFetcher for fetching Map Completion Events:100714 ] - [ INFO ]  attempt_local1120429507_0061_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:41  [ localfetcher#61:100714 ] - [ INFO ]  localfetcher#61 about to shuffle output of map attempt_local1120429507_0061_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:41  [ localfetcher#61:100715 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1120429507_0061_m_000000_0
2020-11-19 16:28:41  [ localfetcher#61:100715 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:41  [ EventFetcher for fetching Map Completion Events:100715 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:41  [ pool-186-thread-1:100715 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:41  [ pool-186-thread-1:100715 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:41  [ pool-186-thread-1:100716 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:41  [ pool-186-thread-1:100716 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:41  [ pool-186-thread-1:100717 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:41  [ pool-186-thread-1:100717 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:41  [ pool-186-thread-1:100717 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:41  [ pool-186-thread-1:100717 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:41  [ pool-186-thread-1:100717 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:41  [ pool-186-thread-1:100717 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:41  [ pool-186-thread-1:100780 ] - [ INFO ]  Task:attempt_local1120429507_0061_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:41  [ pool-186-thread-1:100790 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:41  [ pool-186-thread-1:100790 ] - [ INFO ]  Task attempt_local1120429507_0061_r_000000_0 is allowed to commit now
2020-11-19 16:28:41  [ pool-186-thread-1:100828 ] - [ INFO ]  Saved output of task 'attempt_local1120429507_0061_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1120429507_0061_r_000000
2020-11-19 16:28:41  [ pool-186-thread-1:100828 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:41  [ pool-186-thread-1:100828 ] - [ INFO ]  Task 'attempt_local1120429507_0061_r_000000_0' done.
2020-11-19 16:28:41  [ pool-186-thread-1:100828 ] - [ INFO ]  Finishing task: attempt_local1120429507_0061_r_000000_0
2020-11-19 16:28:41  [ Thread-1818:100829 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:42  [ main:101608 ] - [ INFO ]  Job job_local1120429507_0061 running in uber mode : false
2020-11-19 16:28:42  [ main:101609 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:42  [ main:101609 ] - [ INFO ]  Job job_local1120429507_0061 completed successfully
2020-11-19 16:28:42  [ main:101609 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=149424
		FILE: Number of bytes written=34857673
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3925442
		HDFS: Number of bytes written=64350
		HDFS: Number of read operations=4073
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1322
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2430599168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:42  [ main:101912 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:42  [ main:101922 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:42  [ main:101926 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:42  [ main:101932 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:42  [ main:101971 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:42  [ main:101989 ] - [ INFO ]  Submitting tokens for job: job_local119018268_0062
2020-11-19 16:28:42  [ main:102022 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:42  [ main:102023 ] - [ INFO ]  Running job: job_local119018268_0062
2020-11-19 16:28:42  [ Thread-1848:102023 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:42  [ Thread-1848:102023 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:42  [ Thread-1848:102023 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:42  [ Thread-1848:102032 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102032 ] - [ INFO ]  Starting task: attempt_local119018268_0062_m_000000_0
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102032 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102032 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102032 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102032 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102040 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102040 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102040 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102040 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102040 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102040 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102108 ] - [ INFO ]  
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102108 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102108 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102108 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102108 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102110 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102110 ] - [ INFO ]  Task:attempt_local119018268_0062_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102121 ] - [ INFO ]  map
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102121 ] - [ INFO ]  Task 'attempt_local119018268_0062_m_000000_0' done.
2020-11-19 16:28:42  [ LocalJobRunner Map Task Executor #0:102121 ] - [ INFO ]  Finishing task: attempt_local119018268_0062_m_000000_0
2020-11-19 16:28:42  [ Thread-1848:102121 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:42  [ Thread-1848:102121 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:42  [ pool-189-thread-1:102121 ] - [ INFO ]  Starting task: attempt_local119018268_0062_r_000000_0
2020-11-19 16:28:42  [ pool-189-thread-1:102121 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:42  [ pool-189-thread-1:102121 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:42  [ pool-189-thread-1:102121 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:42  [ pool-189-thread-1:102121 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21ca16e6
2020-11-19 16:28:42  [ pool-189-thread-1:102122 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:42  [ EventFetcher for fetching Map Completion Events:102122 ] - [ INFO ]  attempt_local119018268_0062_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:42  [ localfetcher#62:102122 ] - [ INFO ]  localfetcher#62 about to shuffle output of map attempt_local119018268_0062_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:42  [ localfetcher#62:102122 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local119018268_0062_m_000000_0
2020-11-19 16:28:42  [ localfetcher#62:102122 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:42  [ EventFetcher for fetching Map Completion Events:102123 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:42  [ pool-189-thread-1:102123 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:42  [ pool-189-thread-1:102123 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:42  [ pool-189-thread-1:102123 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:42  [ pool-189-thread-1:102123 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:42  [ pool-189-thread-1:102124 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:42  [ pool-189-thread-1:102124 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:42  [ pool-189-thread-1:102124 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:42  [ pool-189-thread-1:102124 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:42  [ pool-189-thread-1:102124 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:42  [ pool-189-thread-1:102124 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:42  [ pool-189-thread-1:102174 ] - [ INFO ]  Task:attempt_local119018268_0062_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:42  [ pool-189-thread-1:102179 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:42  [ pool-189-thread-1:102179 ] - [ INFO ]  Task attempt_local119018268_0062_r_000000_0 is allowed to commit now
2020-11-19 16:28:42  [ pool-189-thread-1:102194 ] - [ INFO ]  Saved output of task 'attempt_local119018268_0062_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local119018268_0062_r_000000
2020-11-19 16:28:42  [ pool-189-thread-1:102195 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:42  [ pool-189-thread-1:102195 ] - [ INFO ]  Task 'attempt_local119018268_0062_r_000000_0' done.
2020-11-19 16:28:42  [ pool-189-thread-1:102195 ] - [ INFO ]  Finishing task: attempt_local119018268_0062_r_000000_0
2020-11-19 16:28:42  [ Thread-1848:102195 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:43  [ main:103025 ] - [ INFO ]  Job job_local119018268_0062 running in uber mode : false
2020-11-19 16:28:43  [ main:103025 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:43  [ main:103025 ] - [ INFO ]  Job job_local119018268_0062 completed successfully
2020-11-19 16:28:43  [ main:103026 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=150618
		FILE: Number of bytes written=35426555
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3989844
		HDFS: Number of bytes written=65428
		HDFS: Number of read operations=4141
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1344
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2430599168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:43  [ main:103347 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:43  [ main:103361 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:43  [ main:103365 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:43  [ main:103371 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:43  [ main:103413 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:43  [ main:103433 ] - [ INFO ]  Submitting tokens for job: job_local1377655949_0063
2020-11-19 16:28:43  [ main:103468 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:43  [ main:103468 ] - [ INFO ]  Running job: job_local1377655949_0063
2020-11-19 16:28:43  [ Thread-1878:103468 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:43  [ Thread-1878:103468 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:43  [ Thread-1878:103468 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:43  [ Thread-1878:103477 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103477 ] - [ INFO ]  Starting task: attempt_local1377655949_0063_m_000000_0
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103477 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103477 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103477 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103477 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103486 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103486 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103486 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103486 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103486 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:43  [ LocalJobRunner Map Task Executor #0:103486 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103579 ] - [ INFO ]  
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103579 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103579 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103579 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103579 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103582 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103583 ] - [ INFO ]  Task:attempt_local1377655949_0063_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103593 ] - [ INFO ]  map
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103593 ] - [ INFO ]  Task 'attempt_local1377655949_0063_m_000000_0' done.
2020-11-19 16:28:44  [ LocalJobRunner Map Task Executor #0:103593 ] - [ INFO ]  Finishing task: attempt_local1377655949_0063_m_000000_0
2020-11-19 16:28:44  [ Thread-1878:103594 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:44  [ Thread-1878:103594 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:44  [ pool-192-thread-1:103594 ] - [ INFO ]  Starting task: attempt_local1377655949_0063_r_000000_0
2020-11-19 16:28:44  [ pool-192-thread-1:103594 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:44  [ pool-192-thread-1:103594 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:44  [ pool-192-thread-1:103594 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:44  [ pool-192-thread-1:103594 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@253c5624
2020-11-19 16:28:44  [ pool-192-thread-1:103595 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:44  [ EventFetcher for fetching Map Completion Events:103595 ] - [ INFO ]  attempt_local1377655949_0063_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:44  [ localfetcher#63:103595 ] - [ INFO ]  localfetcher#63 about to shuffle output of map attempt_local1377655949_0063_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:44  [ localfetcher#63:103596 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1377655949_0063_m_000000_0
2020-11-19 16:28:44  [ localfetcher#63:103596 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:44  [ EventFetcher for fetching Map Completion Events:103596 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:44  [ pool-192-thread-1:103596 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:44  [ pool-192-thread-1:103596 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:44  [ pool-192-thread-1:103597 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:44  [ pool-192-thread-1:103597 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:44  [ pool-192-thread-1:103597 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:44  [ pool-192-thread-1:103598 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:44  [ pool-192-thread-1:103598 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:44  [ pool-192-thread-1:103598 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:44  [ pool-192-thread-1:103598 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:44  [ pool-192-thread-1:103598 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:44  [ pool-192-thread-1:103676 ] - [ INFO ]  Task:attempt_local1377655949_0063_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:44  [ pool-192-thread-1:103682 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:44  [ pool-192-thread-1:103682 ] - [ INFO ]  Task attempt_local1377655949_0063_r_000000_0 is allowed to commit now
2020-11-19 16:28:44  [ pool-192-thread-1:103708 ] - [ INFO ]  Saved output of task 'attempt_local1377655949_0063_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1377655949_0063_r_000000
2020-11-19 16:28:44  [ pool-192-thread-1:103708 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:44  [ pool-192-thread-1:103708 ] - [ INFO ]  Task 'attempt_local1377655949_0063_r_000000_0' done.
2020-11-19 16:28:44  [ pool-192-thread-1:103708 ] - [ INFO ]  Finishing task: attempt_local1377655949_0063_r_000000_0
2020-11-19 16:28:44  [ Thread-1878:103708 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:44  [ main:104468 ] - [ INFO ]  Job job_local1377655949_0063 running in uber mode : false
2020-11-19 16:28:44  [ main:104468 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:44  [ main:104469 ] - [ INFO ]  Job job_local1377655949_0063 completed successfully
2020-11-19 16:28:44  [ main:104469 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=151816
		FILE: Number of bytes written=35998483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4054234
		HDFS: Number of bytes written=66499
		HDFS: Number of read operations=4209
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1366
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2430599168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:45  [ main:105115 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:45  [ main:105127 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:45  [ main:105132 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:45  [ main:105138 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:45  [ main:105176 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:45  [ main:105194 ] - [ INFO ]  Submitting tokens for job: job_local2081088466_0064
2020-11-19 16:28:45  [ main:105232 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:45  [ main:105232 ] - [ INFO ]  Running job: job_local2081088466_0064
2020-11-19 16:28:45  [ Thread-1908:105232 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:45  [ Thread-1908:105232 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:45  [ Thread-1908:105232 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:45  [ Thread-1908:105240 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105240 ] - [ INFO ]  Starting task: attempt_local2081088466_0064_m_000000_0
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105240 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105240 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105240 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105241 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105251 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105251 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105251 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105251 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105251 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105251 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105313 ] - [ INFO ]  
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105313 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105313 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105313 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105313 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105315 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105315 ] - [ INFO ]  Task:attempt_local2081088466_0064_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105321 ] - [ INFO ]  map
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105321 ] - [ INFO ]  Task 'attempt_local2081088466_0064_m_000000_0' done.
2020-11-19 16:28:45  [ LocalJobRunner Map Task Executor #0:105321 ] - [ INFO ]  Finishing task: attempt_local2081088466_0064_m_000000_0
2020-11-19 16:28:45  [ Thread-1908:105321 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:45  [ Thread-1908:105321 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:45  [ pool-195-thread-1:105321 ] - [ INFO ]  Starting task: attempt_local2081088466_0064_r_000000_0
2020-11-19 16:28:45  [ pool-195-thread-1:105322 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:45  [ pool-195-thread-1:105322 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:45  [ pool-195-thread-1:105322 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:45  [ pool-195-thread-1:105322 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4dd33a77
2020-11-19 16:28:45  [ pool-195-thread-1:105322 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:45  [ EventFetcher for fetching Map Completion Events:105322 ] - [ INFO ]  attempt_local2081088466_0064_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:45  [ localfetcher#64:105323 ] - [ INFO ]  localfetcher#64 about to shuffle output of map attempt_local2081088466_0064_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:45  [ localfetcher#64:105323 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local2081088466_0064_m_000000_0
2020-11-19 16:28:45  [ localfetcher#64:105323 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:45  [ EventFetcher for fetching Map Completion Events:105323 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:45  [ pool-195-thread-1:105323 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:45  [ pool-195-thread-1:105323 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:45  [ pool-195-thread-1:105324 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:45  [ pool-195-thread-1:105324 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:45  [ pool-195-thread-1:105324 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:45  [ pool-195-thread-1:105325 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:45  [ pool-195-thread-1:105325 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:45  [ pool-195-thread-1:105325 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:45  [ pool-195-thread-1:105325 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:45  [ pool-195-thread-1:105325 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:45  [ pool-195-thread-1:105366 ] - [ INFO ]  Task:attempt_local2081088466_0064_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:45  [ pool-195-thread-1:105371 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:45  [ pool-195-thread-1:105372 ] - [ INFO ]  Task attempt_local2081088466_0064_r_000000_0 is allowed to commit now
2020-11-19 16:28:45  [ pool-195-thread-1:105389 ] - [ INFO ]  Saved output of task 'attempt_local2081088466_0064_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2081088466_0064_r_000000
2020-11-19 16:28:45  [ pool-195-thread-1:105391 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:45  [ pool-195-thread-1:105391 ] - [ INFO ]  Task 'attempt_local2081088466_0064_r_000000_0' done.
2020-11-19 16:28:45  [ pool-195-thread-1:105391 ] - [ INFO ]  Finishing task: attempt_local2081088466_0064_r_000000_0
2020-11-19 16:28:45  [ Thread-1908:105391 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:46  [ main:106232 ] - [ INFO ]  Job job_local2081088466_0064 running in uber mode : false
2020-11-19 16:28:46  [ main:106233 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:46  [ main:106233 ] - [ INFO ]  Job job_local2081088466_0064 completed successfully
2020-11-19 16:28:46  [ main:106234 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=153016
		FILE: Number of bytes written=36570418
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4118644
		HDFS: Number of bytes written=67582
		HDFS: Number of read operations=4277
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1388
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2581594112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:46  [ main:106522 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:46  [ main:106533 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:46  [ main:106538 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:46  [ main:106543 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:47  [ main:106585 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:47  [ main:106602 ] - [ INFO ]  Submitting tokens for job: job_local749358388_0065
2020-11-19 16:28:47  [ main:106638 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:47  [ main:106638 ] - [ INFO ]  Running job: job_local749358388_0065
2020-11-19 16:28:47  [ Thread-1938:106638 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:47  [ Thread-1938:106638 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:47  [ Thread-1938:106638 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:47  [ Thread-1938:106645 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106646 ] - [ INFO ]  Starting task: attempt_local749358388_0065_m_000000_0
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106646 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106646 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106646 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106646 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106654 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106654 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106654 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106654 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106654 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106654 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106732 ] - [ INFO ]  
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106732 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106732 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106732 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106732 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106734 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106735 ] - [ INFO ]  Task:attempt_local749358388_0065_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106741 ] - [ INFO ]  map
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106741 ] - [ INFO ]  Task 'attempt_local749358388_0065_m_000000_0' done.
2020-11-19 16:28:47  [ LocalJobRunner Map Task Executor #0:106741 ] - [ INFO ]  Finishing task: attempt_local749358388_0065_m_000000_0
2020-11-19 16:28:47  [ Thread-1938:106741 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:47  [ Thread-1938:106741 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:47  [ pool-198-thread-1:106741 ] - [ INFO ]  Starting task: attempt_local749358388_0065_r_000000_0
2020-11-19 16:28:47  [ pool-198-thread-1:106742 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:47  [ pool-198-thread-1:106742 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:47  [ pool-198-thread-1:106742 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:47  [ pool-198-thread-1:106742 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e134fc
2020-11-19 16:28:47  [ pool-198-thread-1:106742 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:47  [ EventFetcher for fetching Map Completion Events:106742 ] - [ INFO ]  attempt_local749358388_0065_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:47  [ localfetcher#65:106743 ] - [ INFO ]  localfetcher#65 about to shuffle output of map attempt_local749358388_0065_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:47  [ localfetcher#65:106743 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local749358388_0065_m_000000_0
2020-11-19 16:28:47  [ localfetcher#65:106743 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:47  [ EventFetcher for fetching Map Completion Events:106743 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:47  [ pool-198-thread-1:106743 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:47  [ pool-198-thread-1:106743 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:47  [ pool-198-thread-1:106744 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:47  [ pool-198-thread-1:106744 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:47  [ pool-198-thread-1:106744 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:47  [ pool-198-thread-1:106744 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:47  [ pool-198-thread-1:106744 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:47  [ pool-198-thread-1:106744 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:47  [ pool-198-thread-1:106745 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:47  [ pool-198-thread-1:106745 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:47  [ pool-198-thread-1:106797 ] - [ INFO ]  Task:attempt_local749358388_0065_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:47  [ pool-198-thread-1:106804 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:47  [ pool-198-thread-1:106804 ] - [ INFO ]  Task attempt_local749358388_0065_r_000000_0 is allowed to commit now
2020-11-19 16:28:47  [ pool-198-thread-1:106820 ] - [ INFO ]  Saved output of task 'attempt_local749358388_0065_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local749358388_0065_r_000000
2020-11-19 16:28:47  [ pool-198-thread-1:106820 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:47  [ pool-198-thread-1:106820 ] - [ INFO ]  Task 'attempt_local749358388_0065_r_000000_0' done.
2020-11-19 16:28:47  [ pool-198-thread-1:106820 ] - [ INFO ]  Finishing task: attempt_local749358388_0065_r_000000_0
2020-11-19 16:28:47  [ Thread-1938:106820 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:48  [ main:107641 ] - [ INFO ]  Job job_local749358388_0065 running in uber mode : false
2020-11-19 16:28:48  [ main:107641 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:48  [ main:107641 ] - [ INFO ]  Job job_local749358388_0065 completed successfully
2020-11-19 16:28:48  [ main:107642 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=154212
		FILE: Number of bytes written=37139293
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4183036
		HDFS: Number of bytes written=68652
		HDFS: Number of read operations=4345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1410
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2581594112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:48  [ main:107940 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:48  [ main:107952 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:48  [ main:107957 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:48  [ main:107963 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:48  [ main:108006 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:48  [ main:108024 ] - [ INFO ]  Submitting tokens for job: job_local1264836417_0066
2020-11-19 16:28:48  [ main:108058 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:48  [ main:108058 ] - [ INFO ]  Running job: job_local1264836417_0066
2020-11-19 16:28:48  [ Thread-1968:108058 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:48  [ Thread-1968:108058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:48  [ Thread-1968:108058 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:48  [ Thread-1968:108065 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108065 ] - [ INFO ]  Starting task: attempt_local1264836417_0066_m_000000_0
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108066 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108066 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108066 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108066 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108074 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108074 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108074 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108074 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108074 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108074 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108144 ] - [ INFO ]  
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108144 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108144 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108144 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108144 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108146 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108147 ] - [ INFO ]  Task:attempt_local1264836417_0066_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108153 ] - [ INFO ]  map
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108153 ] - [ INFO ]  Task 'attempt_local1264836417_0066_m_000000_0' done.
2020-11-19 16:28:48  [ LocalJobRunner Map Task Executor #0:108153 ] - [ INFO ]  Finishing task: attempt_local1264836417_0066_m_000000_0
2020-11-19 16:28:48  [ Thread-1968:108153 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:48  [ Thread-1968:108154 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:48  [ pool-201-thread-1:108154 ] - [ INFO ]  Starting task: attempt_local1264836417_0066_r_000000_0
2020-11-19 16:28:48  [ pool-201-thread-1:108154 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:48  [ pool-201-thread-1:108154 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:48  [ pool-201-thread-1:108154 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:48  [ pool-201-thread-1:108154 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@e6a9257
2020-11-19 16:28:48  [ pool-201-thread-1:108155 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:48  [ EventFetcher for fetching Map Completion Events:108155 ] - [ INFO ]  attempt_local1264836417_0066_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:48  [ localfetcher#66:108156 ] - [ INFO ]  localfetcher#66 about to shuffle output of map attempt_local1264836417_0066_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:48  [ localfetcher#66:108156 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1264836417_0066_m_000000_0
2020-11-19 16:28:48  [ localfetcher#66:108156 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:48  [ EventFetcher for fetching Map Completion Events:108156 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:48  [ pool-201-thread-1:108156 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:48  [ pool-201-thread-1:108156 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:48  [ pool-201-thread-1:108157 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:48  [ pool-201-thread-1:108157 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:48  [ pool-201-thread-1:108158 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:48  [ pool-201-thread-1:108158 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:48  [ pool-201-thread-1:108158 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:48  [ pool-201-thread-1:108158 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:48  [ pool-201-thread-1:108158 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:48  [ pool-201-thread-1:108158 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:48  [ pool-201-thread-1:108216 ] - [ INFO ]  Task:attempt_local1264836417_0066_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:48  [ pool-201-thread-1:108222 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:48  [ pool-201-thread-1:108222 ] - [ INFO ]  Task attempt_local1264836417_0066_r_000000_0 is allowed to commit now
2020-11-19 16:28:48  [ pool-201-thread-1:108244 ] - [ INFO ]  Saved output of task 'attempt_local1264836417_0066_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1264836417_0066_r_000000
2020-11-19 16:28:48  [ pool-201-thread-1:108244 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:48  [ pool-201-thread-1:108244 ] - [ INFO ]  Task 'attempt_local1264836417_0066_r_000000_0' done.
2020-11-19 16:28:48  [ pool-201-thread-1:108244 ] - [ INFO ]  Finishing task: attempt_local1264836417_0066_r_000000_0
2020-11-19 16:28:48  [ Thread-1968:108244 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:49  [ main:109058 ] - [ INFO ]  Job job_local1264836417_0066 running in uber mode : false
2020-11-19 16:28:49  [ main:109058 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:49  [ main:109058 ] - [ INFO ]  Job job_local1264836417_0066 completed successfully
2020-11-19 16:28:49  [ main:109059 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=155406
		FILE: Number of bytes written=37711223
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4247438
		HDFS: Number of bytes written=69730
		HDFS: Number of read operations=4413
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1432
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2581594112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:49  [ main:109345 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:49  [ main:109361 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:49  [ main:109366 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:49  [ main:109373 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:49  [ main:109416 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:49  [ main:109433 ] - [ INFO ]  Submitting tokens for job: job_local1685636580_0067
2020-11-19 16:28:49  [ main:109469 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:49  [ main:109469 ] - [ INFO ]  Running job: job_local1685636580_0067
2020-11-19 16:28:49  [ Thread-1998:109470 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:49  [ Thread-1998:109470 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:49  [ Thread-1998:109470 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:49  [ Thread-1998:109480 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:49  [ LocalJobRunner Map Task Executor #0:109480 ] - [ INFO ]  Starting task: attempt_local1685636580_0067_m_000000_0
2020-11-19 16:28:49  [ LocalJobRunner Map Task Executor #0:109480 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:49  [ LocalJobRunner Map Task Executor #0:109480 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:49  [ LocalJobRunner Map Task Executor #0:109480 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:49  [ LocalJobRunner Map Task Executor #0:109481 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109578 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109578 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109578 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109578 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109578 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109578 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109661 ] - [ INFO ]  
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109661 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109661 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109661 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109661 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109663 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109663 ] - [ INFO ]  Task:attempt_local1685636580_0067_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109673 ] - [ INFO ]  map
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109673 ] - [ INFO ]  Task 'attempt_local1685636580_0067_m_000000_0' done.
2020-11-19 16:28:50  [ LocalJobRunner Map Task Executor #0:109673 ] - [ INFO ]  Finishing task: attempt_local1685636580_0067_m_000000_0
2020-11-19 16:28:50  [ Thread-1998:109673 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:50  [ Thread-1998:109673 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:50  [ pool-204-thread-1:109673 ] - [ INFO ]  Starting task: attempt_local1685636580_0067_r_000000_0
2020-11-19 16:28:50  [ pool-204-thread-1:109674 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:50  [ pool-204-thread-1:109674 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:50  [ pool-204-thread-1:109674 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:50  [ pool-204-thread-1:109674 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d71e2ac
2020-11-19 16:28:50  [ pool-204-thread-1:109674 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:50  [ EventFetcher for fetching Map Completion Events:109674 ] - [ INFO ]  attempt_local1685636580_0067_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:50  [ localfetcher#67:109675 ] - [ INFO ]  localfetcher#67 about to shuffle output of map attempt_local1685636580_0067_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:50  [ localfetcher#67:109675 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1685636580_0067_m_000000_0
2020-11-19 16:28:50  [ localfetcher#67:109675 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:50  [ EventFetcher for fetching Map Completion Events:109675 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:50  [ pool-204-thread-1:109675 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:50  [ pool-204-thread-1:109675 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:50  [ pool-204-thread-1:109676 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:50  [ pool-204-thread-1:109676 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:50  [ pool-204-thread-1:109676 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:50  [ pool-204-thread-1:109676 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:50  [ pool-204-thread-1:109676 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:50  [ pool-204-thread-1:109677 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:50  [ pool-204-thread-1:109677 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:50  [ pool-204-thread-1:109677 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:50  [ pool-204-thread-1:109734 ] - [ INFO ]  Task:attempt_local1685636580_0067_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:50  [ pool-204-thread-1:109740 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:50  [ pool-204-thread-1:109740 ] - [ INFO ]  Task attempt_local1685636580_0067_r_000000_0 is allowed to commit now
2020-11-19 16:28:50  [ pool-204-thread-1:109756 ] - [ INFO ]  Saved output of task 'attempt_local1685636580_0067_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1685636580_0067_r_000000
2020-11-19 16:28:50  [ pool-204-thread-1:109756 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:50  [ pool-204-thread-1:109756 ] - [ INFO ]  Task 'attempt_local1685636580_0067_r_000000_0' done.
2020-11-19 16:28:50  [ pool-204-thread-1:109756 ] - [ INFO ]  Finishing task: attempt_local1685636580_0067_r_000000_0
2020-11-19 16:28:50  [ Thread-1998:109756 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:50  [ main:110473 ] - [ INFO ]  Job job_local1685636580_0067 running in uber mode : false
2020-11-19 16:28:50  [ main:110473 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:50  [ main:110473 ] - [ INFO ]  Job job_local1685636580_0067 completed successfully
2020-11-19 16:28:50  [ main:110474 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=156604
		FILE: Number of bytes written=38283151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4311828
		HDFS: Number of bytes written=70801
		HDFS: Number of read operations=4481
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1454
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2581594112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:51  [ main:110766 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:51  [ main:110775 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:51  [ main:110779 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:51  [ main:110785 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:51  [ main:110824 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:51  [ main:110845 ] - [ INFO ]  Submitting tokens for job: job_local1298609072_0068
2020-11-19 16:28:51  [ main:110890 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:51  [ main:110891 ] - [ INFO ]  Running job: job_local1298609072_0068
2020-11-19 16:28:51  [ Thread-2028:110891 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:51  [ Thread-2028:110891 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:51  [ Thread-2028:110891 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:51  [ Thread-2028:110900 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110900 ] - [ INFO ]  Starting task: attempt_local1298609072_0068_m_000000_0
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110900 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110900 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110900 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110901 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110908 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110908 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110908 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110908 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110908 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110908 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110986 ] - [ INFO ]  
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110986 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110986 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110986 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110986 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110988 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110989 ] - [ INFO ]  Task:attempt_local1298609072_0068_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110994 ] - [ INFO ]  map
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110994 ] - [ INFO ]  Task 'attempt_local1298609072_0068_m_000000_0' done.
2020-11-19 16:28:51  [ LocalJobRunner Map Task Executor #0:110994 ] - [ INFO ]  Finishing task: attempt_local1298609072_0068_m_000000_0
2020-11-19 16:28:51  [ Thread-2028:110994 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:51  [ Thread-2028:110994 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:51  [ pool-207-thread-1:110994 ] - [ INFO ]  Starting task: attempt_local1298609072_0068_r_000000_0
2020-11-19 16:28:51  [ pool-207-thread-1:110995 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:51  [ pool-207-thread-1:110995 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:51  [ pool-207-thread-1:110995 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:51  [ pool-207-thread-1:110995 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42010651
2020-11-19 16:28:51  [ pool-207-thread-1:110995 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:51  [ EventFetcher for fetching Map Completion Events:110995 ] - [ INFO ]  attempt_local1298609072_0068_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:51  [ localfetcher#68:110996 ] - [ INFO ]  localfetcher#68 about to shuffle output of map attempt_local1298609072_0068_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:51  [ localfetcher#68:110996 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1298609072_0068_m_000000_0
2020-11-19 16:28:51  [ localfetcher#68:110996 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:51  [ EventFetcher for fetching Map Completion Events:110996 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:51  [ pool-207-thread-1:110996 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:51  [ pool-207-thread-1:110996 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:51  [ pool-207-thread-1:110997 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:51  [ pool-207-thread-1:110998 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:51  [ pool-207-thread-1:111056 ] - [ INFO ]  Task:attempt_local1298609072_0068_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:51  [ pool-207-thread-1:111061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:51  [ pool-207-thread-1:111061 ] - [ INFO ]  Task attempt_local1298609072_0068_r_000000_0 is allowed to commit now
2020-11-19 16:28:51  [ pool-207-thread-1:111076 ] - [ INFO ]  Saved output of task 'attempt_local1298609072_0068_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1298609072_0068_r_000000
2020-11-19 16:28:51  [ pool-207-thread-1:111077 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:51  [ pool-207-thread-1:111077 ] - [ INFO ]  Task 'attempt_local1298609072_0068_r_000000_0' done.
2020-11-19 16:28:51  [ pool-207-thread-1:111077 ] - [ INFO ]  Finishing task: attempt_local1298609072_0068_r_000000_0
2020-11-19 16:28:51  [ Thread-2028:111077 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:52  [ main:111894 ] - [ INFO ]  Job job_local1298609072_0068 running in uber mode : false
2020-11-19 16:28:52  [ main:111894 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:52  [ main:111894 ] - [ INFO ]  Job job_local1298609072_0068 completed successfully
2020-11-19 16:28:52  [ main:111895 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=157804
		FILE: Number of bytes written=38855086
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4376238
		HDFS: Number of bytes written=71884
		HDFS: Number of read operations=4549
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1476
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2588934144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:52  [ main:112463 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:52  [ main:112474 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:52  [ main:112479 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:52  [ main:112487 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:52  [ main:112529 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:52  [ main:112548 ] - [ INFO ]  Submitting tokens for job: job_local826512246_0069
2020-11-19 16:28:53  [ main:112583 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:53  [ main:112583 ] - [ INFO ]  Running job: job_local826512246_0069
2020-11-19 16:28:53  [ Thread-2058:112583 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:53  [ Thread-2058:112584 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:53  [ Thread-2058:112584 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:53  [ Thread-2058:112591 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112591 ] - [ INFO ]  Starting task: attempt_local826512246_0069_m_000000_0
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112591 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112591 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112591 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112592 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112601 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112601 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112601 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112601 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112601 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112601 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112671 ] - [ INFO ]  
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112671 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112671 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112671 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112671 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112672 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112673 ] - [ INFO ]  Task:attempt_local826512246_0069_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112679 ] - [ INFO ]  map
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112679 ] - [ INFO ]  Task 'attempt_local826512246_0069_m_000000_0' done.
2020-11-19 16:28:53  [ LocalJobRunner Map Task Executor #0:112679 ] - [ INFO ]  Finishing task: attempt_local826512246_0069_m_000000_0
2020-11-19 16:28:53  [ Thread-2058:112679 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:53  [ Thread-2058:112679 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:53  [ pool-210-thread-1:112679 ] - [ INFO ]  Starting task: attempt_local826512246_0069_r_000000_0
2020-11-19 16:28:53  [ pool-210-thread-1:112680 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:53  [ pool-210-thread-1:112680 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:53  [ pool-210-thread-1:112680 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:53  [ pool-210-thread-1:112680 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@37f7f952
2020-11-19 16:28:53  [ pool-210-thread-1:112680 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:53  [ EventFetcher for fetching Map Completion Events:112680 ] - [ INFO ]  attempt_local826512246_0069_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:53  [ localfetcher#69:112681 ] - [ INFO ]  localfetcher#69 about to shuffle output of map attempt_local826512246_0069_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:53  [ localfetcher#69:112681 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local826512246_0069_m_000000_0
2020-11-19 16:28:53  [ localfetcher#69:112681 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:53  [ EventFetcher for fetching Map Completion Events:112681 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:53  [ pool-210-thread-1:112681 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:53  [ pool-210-thread-1:112681 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:53  [ pool-210-thread-1:112682 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:53  [ pool-210-thread-1:112730 ] - [ INFO ]  Task:attempt_local826512246_0069_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:53  [ pool-210-thread-1:112737 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:53  [ pool-210-thread-1:112738 ] - [ INFO ]  Task attempt_local826512246_0069_r_000000_0 is allowed to commit now
2020-11-19 16:28:53  [ pool-210-thread-1:112753 ] - [ INFO ]  Saved output of task 'attempt_local826512246_0069_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local826512246_0069_r_000000
2020-11-19 16:28:53  [ pool-210-thread-1:112753 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:53  [ pool-210-thread-1:112753 ] - [ INFO ]  Task 'attempt_local826512246_0069_r_000000_0' done.
2020-11-19 16:28:53  [ pool-210-thread-1:112753 ] - [ INFO ]  Finishing task: attempt_local826512246_0069_r_000000_0
2020-11-19 16:28:53  [ Thread-2058:112753 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:54  [ main:113584 ] - [ INFO ]  Job job_local826512246_0069 running in uber mode : false
2020-11-19 16:28:54  [ main:113584 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:54  [ main:113584 ] - [ INFO ]  Job job_local826512246_0069 completed successfully
2020-11-19 16:28:54  [ main:113584 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=159000
		FILE: Number of bytes written=39423961
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4440630
		HDFS: Number of bytes written=72954
		HDFS: Number of read operations=4617
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1498
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2588934144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:28:54  [ main:113899 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:54  [ main:113912 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:54  [ main:113916 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:54  [ main:113922 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:54  [ main:113962 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:54  [ main:113979 ] - [ INFO ]  Submitting tokens for job: job_local639824_0070
2020-11-19 16:28:54  [ main:114013 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:54  [ main:114013 ] - [ INFO ]  Running job: job_local639824_0070
2020-11-19 16:28:54  [ Thread-2088:114013 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:54  [ Thread-2088:114014 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:54  [ Thread-2088:114014 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:54  [ Thread-2088:114021 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114021 ] - [ INFO ]  Starting task: attempt_local639824_0070_m_000000_0
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114021 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114022 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114022 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114022 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114029 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114029 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114029 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114029 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114029 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114030 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114115 ] - [ INFO ]  
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114115 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114115 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114115 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114115 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114117 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114118 ] - [ INFO ]  Task:attempt_local639824_0070_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114124 ] - [ INFO ]  map
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114124 ] - [ INFO ]  Task 'attempt_local639824_0070_m_000000_0' done.
2020-11-19 16:28:54  [ LocalJobRunner Map Task Executor #0:114124 ] - [ INFO ]  Finishing task: attempt_local639824_0070_m_000000_0
2020-11-19 16:28:54  [ Thread-2088:114124 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:54  [ Thread-2088:114125 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:54  [ pool-213-thread-1:114125 ] - [ INFO ]  Starting task: attempt_local639824_0070_r_000000_0
2020-11-19 16:28:54  [ pool-213-thread-1:114125 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:54  [ pool-213-thread-1:114125 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:54  [ pool-213-thread-1:114125 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:54  [ pool-213-thread-1:114125 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5d5c2bb9
2020-11-19 16:28:54  [ pool-213-thread-1:114126 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:54  [ EventFetcher for fetching Map Completion Events:114126 ] - [ INFO ]  attempt_local639824_0070_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:54  [ localfetcher#70:114127 ] - [ INFO ]  localfetcher#70 about to shuffle output of map attempt_local639824_0070_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:28:54  [ localfetcher#70:114127 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local639824_0070_m_000000_0
2020-11-19 16:28:54  [ localfetcher#70:114127 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:28:54  [ EventFetcher for fetching Map Completion Events:114127 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:54  [ pool-213-thread-1:114127 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:54  [ pool-213-thread-1:114127 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:54  [ pool-213-thread-1:114128 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:54  [ pool-213-thread-1:114128 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:54  [ pool-213-thread-1:114128 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:54  [ pool-213-thread-1:114129 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:28:54  [ pool-213-thread-1:114129 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:54  [ pool-213-thread-1:114129 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:54  [ pool-213-thread-1:114129 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:28:54  [ pool-213-thread-1:114129 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:54  [ pool-213-thread-1:114187 ] - [ INFO ]  Task:attempt_local639824_0070_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:54  [ pool-213-thread-1:114193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:54  [ pool-213-thread-1:114193 ] - [ INFO ]  Task attempt_local639824_0070_r_000000_0 is allowed to commit now
2020-11-19 16:28:54  [ pool-213-thread-1:114219 ] - [ INFO ]  Saved output of task 'attempt_local639824_0070_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local639824_0070_r_000000
2020-11-19 16:28:54  [ pool-213-thread-1:114219 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:54  [ pool-213-thread-1:114219 ] - [ INFO ]  Task 'attempt_local639824_0070_r_000000_0' done.
2020-11-19 16:28:54  [ pool-213-thread-1:114219 ] - [ INFO ]  Finishing task: attempt_local639824_0070_r_000000_0
2020-11-19 16:28:54  [ Thread-2088:114219 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:55  [ main:115016 ] - [ INFO ]  Job job_local639824_0070 running in uber mode : false
2020-11-19 16:28:55  [ main:115017 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:55  [ main:115017 ] - [ INFO ]  Job job_local639824_0070 completed successfully
2020-11-19 16:28:55  [ main:115017 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=160194
		FILE: Number of bytes written=39983699
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4505032
		HDFS: Number of bytes written=74032
		HDFS: Number of read operations=4685
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1520
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2588934144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:55  [ main:115332 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:55  [ main:115346 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:55  [ main:115351 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:55  [ main:115357 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:55  [ main:115394 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:55  [ main:115412 ] - [ INFO ]  Submitting tokens for job: job_local301733500_0071
2020-11-19 16:28:55  [ main:115446 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:55  [ main:115446 ] - [ INFO ]  Running job: job_local301733500_0071
2020-11-19 16:28:55  [ Thread-2118:115446 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:55  [ Thread-2118:115446 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:55  [ Thread-2118:115446 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:55  [ Thread-2118:115453 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115453 ] - [ INFO ]  Starting task: attempt_local301733500_0071_m_000000_0
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115453 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115453 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115454 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115454 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115466 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115466 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115466 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115466 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115466 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115466 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115548 ] - [ INFO ]  
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115548 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115548 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115548 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115548 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115551 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:55  [ LocalJobRunner Map Task Executor #0:115551 ] - [ INFO ]  Task:attempt_local301733500_0071_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:56  [ LocalJobRunner Map Task Executor #0:115558 ] - [ INFO ]  map
2020-11-19 16:28:56  [ LocalJobRunner Map Task Executor #0:115558 ] - [ INFO ]  Task 'attempt_local301733500_0071_m_000000_0' done.
2020-11-19 16:28:56  [ LocalJobRunner Map Task Executor #0:115558 ] - [ INFO ]  Finishing task: attempt_local301733500_0071_m_000000_0
2020-11-19 16:28:56  [ Thread-2118:115558 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:56  [ Thread-2118:115558 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:56  [ pool-216-thread-1:115558 ] - [ INFO ]  Starting task: attempt_local301733500_0071_r_000000_0
2020-11-19 16:28:56  [ pool-216-thread-1:115559 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:56  [ pool-216-thread-1:115559 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:56  [ pool-216-thread-1:115559 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:56  [ pool-216-thread-1:115559 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1fac366c
2020-11-19 16:28:56  [ pool-216-thread-1:115559 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:56  [ EventFetcher for fetching Map Completion Events:115560 ] - [ INFO ]  attempt_local301733500_0071_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:56  [ localfetcher#71:115560 ] - [ INFO ]  localfetcher#71 about to shuffle output of map attempt_local301733500_0071_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:28:56  [ localfetcher#71:115560 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local301733500_0071_m_000000_0
2020-11-19 16:28:56  [ localfetcher#71:115560 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:28:56  [ EventFetcher for fetching Map Completion Events:115561 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:56  [ pool-216-thread-1:115561 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:56  [ pool-216-thread-1:115561 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:28:56  [ pool-216-thread-1:115562 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:56  [ pool-216-thread-1:115607 ] - [ INFO ]  Task:attempt_local301733500_0071_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:56  [ pool-216-thread-1:115612 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:56  [ pool-216-thread-1:115612 ] - [ INFO ]  Task attempt_local301733500_0071_r_000000_0 is allowed to commit now
2020-11-19 16:28:56  [ pool-216-thread-1:115629 ] - [ INFO ]  Saved output of task 'attempt_local301733500_0071_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local301733500_0071_r_000000
2020-11-19 16:28:56  [ pool-216-thread-1:115629 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:56  [ pool-216-thread-1:115629 ] - [ INFO ]  Task 'attempt_local301733500_0071_r_000000_0' done.
2020-11-19 16:28:56  [ pool-216-thread-1:115630 ] - [ INFO ]  Finishing task: attempt_local301733500_0071_r_000000_0
2020-11-19 16:28:56  [ Thread-2118:115630 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:56  [ main:116448 ] - [ INFO ]  Job job_local301733500_0071 running in uber mode : false
2020-11-19 16:28:56  [ main:116449 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:56  [ main:116449 ] - [ INFO ]  Job job_local301733500_0071 completed successfully
2020-11-19 16:28:56  [ main:116450 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=161392
		FILE: Number of bytes written=40552579
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4569422
		HDFS: Number of bytes written=75103
		HDFS: Number of read operations=4753
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1542
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2588934144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:28:57  [ main:116756 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:57  [ main:116767 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:57  [ main:116772 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:57  [ main:116779 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:57  [ main:116821 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:57  [ main:116839 ] - [ INFO ]  Submitting tokens for job: job_local335749525_0072
2020-11-19 16:28:57  [ main:116872 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:57  [ main:116872 ] - [ INFO ]  Running job: job_local335749525_0072
2020-11-19 16:28:57  [ Thread-2148:116872 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:57  [ Thread-2148:116872 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:57  [ Thread-2148:116872 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:57  [ Thread-2148:116880 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116883 ] - [ INFO ]  Starting task: attempt_local335749525_0072_m_000000_0
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116883 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116883 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116883 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116883 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116891 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116891 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116891 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116891 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116891 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116891 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]  
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116976 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:116977 ] - [ INFO ]  Task:attempt_local335749525_0072_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:117002 ] - [ INFO ]  map
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:117002 ] - [ INFO ]  Task 'attempt_local335749525_0072_m_000000_0' done.
2020-11-19 16:28:57  [ LocalJobRunner Map Task Executor #0:117002 ] - [ INFO ]  Finishing task: attempt_local335749525_0072_m_000000_0
2020-11-19 16:28:57  [ Thread-2148:117002 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:57  [ Thread-2148:117002 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:57  [ pool-219-thread-1:117002 ] - [ INFO ]  Starting task: attempt_local335749525_0072_r_000000_0
2020-11-19 16:28:57  [ pool-219-thread-1:117003 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:57  [ pool-219-thread-1:117003 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:57  [ pool-219-thread-1:117003 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:57  [ pool-219-thread-1:117003 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22b59940
2020-11-19 16:28:57  [ pool-219-thread-1:117003 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:57  [ EventFetcher for fetching Map Completion Events:117003 ] - [ INFO ]  attempt_local335749525_0072_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:57  [ localfetcher#72:117004 ] - [ INFO ]  localfetcher#72 about to shuffle output of map attempt_local335749525_0072_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:28:57  [ localfetcher#72:117004 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local335749525_0072_m_000000_0
2020-11-19 16:28:57  [ localfetcher#72:117004 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:28:57  [ EventFetcher for fetching Map Completion Events:117005 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:57  [ pool-219-thread-1:117005 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:57  [ pool-219-thread-1:117005 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:57  [ pool-219-thread-1:117006 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:57  [ pool-219-thread-1:117006 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:57  [ pool-219-thread-1:117006 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:57  [ pool-219-thread-1:117007 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:28:57  [ pool-219-thread-1:117007 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:57  [ pool-219-thread-1:117007 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:57  [ pool-219-thread-1:117007 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:28:57  [ pool-219-thread-1:117007 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:57  [ pool-219-thread-1:117065 ] - [ INFO ]  Task:attempt_local335749525_0072_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:57  [ pool-219-thread-1:117070 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:57  [ pool-219-thread-1:117070 ] - [ INFO ]  Task attempt_local335749525_0072_r_000000_0 is allowed to commit now
2020-11-19 16:28:57  [ pool-219-thread-1:117087 ] - [ INFO ]  Saved output of task 'attempt_local335749525_0072_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local335749525_0072_r_000000
2020-11-19 16:28:57  [ pool-219-thread-1:117087 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:57  [ pool-219-thread-1:117087 ] - [ INFO ]  Task 'attempt_local335749525_0072_r_000000_0' done.
2020-11-19 16:28:57  [ pool-219-thread-1:117087 ] - [ INFO ]  Finishing task: attempt_local335749525_0072_r_000000_0
2020-11-19 16:28:57  [ Thread-2148:117087 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:58  [ main:117876 ] - [ INFO ]  Job job_local335749525_0072 running in uber mode : false
2020-11-19 16:28:58  [ main:117876 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:58  [ main:117876 ] - [ INFO ]  Job job_local335749525_0072 completed successfully
2020-11-19 16:28:58  [ main:117877 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=162592
		FILE: Number of bytes written=41121466
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4633832
		HDFS: Number of bytes written=76186
		HDFS: Number of read operations=4821
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1564
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2710568960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:28:58  [ main:118164 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:28:58  [ main:118175 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:28:58  [ main:118179 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:28:58  [ main:118184 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:28:58  [ main:118224 ] - [ INFO ]  number of splits:1
2020-11-19 16:28:58  [ main:118241 ] - [ INFO ]  Submitting tokens for job: job_local2144250435_0073
2020-11-19 16:28:58  [ main:118269 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:28:58  [ main:118269 ] - [ INFO ]  Running job: job_local2144250435_0073
2020-11-19 16:28:58  [ Thread-2178:118270 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:28:58  [ Thread-2178:118270 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:58  [ Thread-2178:118270 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:28:58  [ Thread-2178:118277 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118277 ] - [ INFO ]  Starting task: attempt_local2144250435_0073_m_000000_0
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118277 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118277 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118277 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118278 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118286 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118286 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118286 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118286 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118286 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118286 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118378 ] - [ INFO ]  
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118378 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118378 ] - [ INFO ]  Spilling map output
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118378 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118378 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118380 ] - [ INFO ]  Finished spill 0
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118381 ] - [ INFO ]  Task:attempt_local2144250435_0073_m_000000_0 is done. And is in the process of committing
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118387 ] - [ INFO ]  map
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118387 ] - [ INFO ]  Task 'attempt_local2144250435_0073_m_000000_0' done.
2020-11-19 16:28:58  [ LocalJobRunner Map Task Executor #0:118387 ] - [ INFO ]  Finishing task: attempt_local2144250435_0073_m_000000_0
2020-11-19 16:28:58  [ Thread-2178:118387 ] - [ INFO ]  map task executor complete.
2020-11-19 16:28:58  [ Thread-2178:118387 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:28:58  [ pool-222-thread-1:118387 ] - [ INFO ]  Starting task: attempt_local2144250435_0073_r_000000_0
2020-11-19 16:28:58  [ pool-222-thread-1:118388 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:28:58  [ pool-222-thread-1:118388 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:28:58  [ pool-222-thread-1:118388 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:28:58  [ pool-222-thread-1:118388 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b00f966
2020-11-19 16:28:58  [ pool-222-thread-1:118388 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:28:58  [ EventFetcher for fetching Map Completion Events:118388 ] - [ INFO ]  attempt_local2144250435_0073_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:28:58  [ localfetcher#73:118389 ] - [ INFO ]  localfetcher#73 about to shuffle output of map attempt_local2144250435_0073_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:28:58  [ localfetcher#73:118389 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local2144250435_0073_m_000000_0
2020-11-19 16:28:58  [ localfetcher#73:118389 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:28:58  [ EventFetcher for fetching Map Completion Events:118390 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:28:58  [ pool-222-thread-1:118390 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:58  [ pool-222-thread-1:118390 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:28:58  [ pool-222-thread-1:118390 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:28:58  [ pool-222-thread-1:118391 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:58  [ pool-222-thread-1:118475 ] - [ INFO ]  Task:attempt_local2144250435_0073_r_000000_0 is done. And is in the process of committing
2020-11-19 16:28:58  [ pool-222-thread-1:118480 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:28:58  [ pool-222-thread-1:118480 ] - [ INFO ]  Task attempt_local2144250435_0073_r_000000_0 is allowed to commit now
2020-11-19 16:28:58  [ pool-222-thread-1:118496 ] - [ INFO ]  Saved output of task 'attempt_local2144250435_0073_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2144250435_0073_r_000000
2020-11-19 16:28:58  [ pool-222-thread-1:118496 ] - [ INFO ]  reduce > reduce
2020-11-19 16:28:58  [ pool-222-thread-1:118496 ] - [ INFO ]  Task 'attempt_local2144250435_0073_r_000000_0' done.
2020-11-19 16:28:58  [ pool-222-thread-1:118496 ] - [ INFO ]  Finishing task: attempt_local2144250435_0073_r_000000_0
2020-11-19 16:28:58  [ Thread-2178:118496 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:28:59  [ main:119273 ] - [ INFO ]  Job job_local2144250435_0073 running in uber mode : false
2020-11-19 16:28:59  [ main:119273 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:28:59  [ main:119273 ] - [ INFO ]  Job job_local2144250435_0073 completed successfully
2020-11-19 16:28:59  [ main:119274 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=163788
		FILE: Number of bytes written=41693389
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4698224
		HDFS: Number of bytes written=77256
		HDFS: Number of read operations=4889
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1586
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2710568960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:29:00  [ main:119559 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:29:00  [ main:119572 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:29:00  [ main:119576 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:29:00  [ main:119582 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:29:00  [ main:119619 ] - [ INFO ]  number of splits:1
2020-11-19 16:29:00  [ main:119636 ] - [ INFO ]  Submitting tokens for job: job_local1332854696_0074
2020-11-19 16:29:00  [ main:119667 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:29:00  [ main:119667 ] - [ INFO ]  Running job: job_local1332854696_0074
2020-11-19 16:29:00  [ Thread-2208:119667 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:29:00  [ Thread-2208:119667 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:00  [ Thread-2208:119667 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:29:00  [ Thread-2208:119675 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119675 ] - [ INFO ]  Starting task: attempt_local1332854696_0074_m_000000_0
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119675 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119675 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119675 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119675 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119683 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119684 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119684 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119684 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119684 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119684 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119764 ] - [ INFO ]  
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119765 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119765 ] - [ INFO ]  Spilling map output
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119765 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119765 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119766 ] - [ INFO ]  Finished spill 0
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119767 ] - [ INFO ]  Task:attempt_local1332854696_0074_m_000000_0 is done. And is in the process of committing
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119774 ] - [ INFO ]  map
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119774 ] - [ INFO ]  Task 'attempt_local1332854696_0074_m_000000_0' done.
2020-11-19 16:29:00  [ LocalJobRunner Map Task Executor #0:119774 ] - [ INFO ]  Finishing task: attempt_local1332854696_0074_m_000000_0
2020-11-19 16:29:00  [ Thread-2208:119774 ] - [ INFO ]  map task executor complete.
2020-11-19 16:29:00  [ Thread-2208:119774 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:29:00  [ pool-225-thread-1:119774 ] - [ INFO ]  Starting task: attempt_local1332854696_0074_r_000000_0
2020-11-19 16:29:00  [ pool-225-thread-1:119775 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:00  [ pool-225-thread-1:119775 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:00  [ pool-225-thread-1:119775 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:00  [ pool-225-thread-1:119775 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71e9ea1
2020-11-19 16:29:00  [ pool-225-thread-1:119775 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:29:00  [ EventFetcher for fetching Map Completion Events:119776 ] - [ INFO ]  attempt_local1332854696_0074_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:29:00  [ localfetcher#74:119777 ] - [ INFO ]  localfetcher#74 about to shuffle output of map attempt_local1332854696_0074_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:29:00  [ localfetcher#74:119777 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1332854696_0074_m_000000_0
2020-11-19 16:29:00  [ localfetcher#74:119777 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:29:00  [ EventFetcher for fetching Map Completion Events:119777 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:29:00  [ pool-225-thread-1:119777 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:00  [ pool-225-thread-1:119777 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:29:00  [ pool-225-thread-1:119778 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:00  [ pool-225-thread-1:119778 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:29:00  [ pool-225-thread-1:119779 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:29:00  [ pool-225-thread-1:119779 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:29:00  [ pool-225-thread-1:119779 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:29:00  [ pool-225-thread-1:119779 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:00  [ pool-225-thread-1:119779 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:29:00  [ pool-225-thread-1:119779 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:00  [ pool-225-thread-1:119834 ] - [ INFO ]  Task:attempt_local1332854696_0074_r_000000_0 is done. And is in the process of committing
2020-11-19 16:29:00  [ pool-225-thread-1:119841 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:00  [ pool-225-thread-1:119841 ] - [ INFO ]  Task attempt_local1332854696_0074_r_000000_0 is allowed to commit now
2020-11-19 16:29:00  [ pool-225-thread-1:119858 ] - [ INFO ]  Saved output of task 'attempt_local1332854696_0074_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1332854696_0074_r_000000
2020-11-19 16:29:00  [ pool-225-thread-1:119858 ] - [ INFO ]  reduce > reduce
2020-11-19 16:29:00  [ pool-225-thread-1:119858 ] - [ INFO ]  Task 'attempt_local1332854696_0074_r_000000_0' done.
2020-11-19 16:29:00  [ pool-225-thread-1:119858 ] - [ INFO ]  Finishing task: attempt_local1332854696_0074_r_000000_0
2020-11-19 16:29:00  [ Thread-2208:119858 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:29:01  [ main:120671 ] - [ INFO ]  Job job_local1332854696_0074 running in uber mode : false
2020-11-19 16:29:01  [ main:120671 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:29:01  [ main:120671 ] - [ INFO ]  Job job_local1332854696_0074 completed successfully
2020-11-19 16:29:01  [ main:120672 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=164982
		FILE: Number of bytes written=42265319
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4762626
		HDFS: Number of bytes written=78334
		HDFS: Number of read operations=4957
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1608
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2710568960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:29:01  [ main:121121 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:29:01  [ main:121137 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:29:01  [ main:121142 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:29:01  [ main:121149 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:29:01  [ main:121199 ] - [ INFO ]  number of splits:1
2020-11-19 16:29:01  [ main:121216 ] - [ INFO ]  Submitting tokens for job: job_local1142738285_0075
2020-11-19 16:29:01  [ main:121248 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:29:01  [ main:121248 ] - [ INFO ]  Running job: job_local1142738285_0075
2020-11-19 16:29:01  [ Thread-2238:121248 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:29:01  [ Thread-2238:121248 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:01  [ Thread-2238:121248 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:29:01  [ Thread-2238:121255 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121255 ] - [ INFO ]  Starting task: attempt_local1142738285_0075_m_000000_0
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121255 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121255 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121255 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121256 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121272 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121272 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121272 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121272 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121272 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121272 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121365 ] - [ INFO ]  
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121365 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121365 ] - [ INFO ]  Spilling map output
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121365 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121365 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121368 ] - [ INFO ]  Finished spill 0
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121369 ] - [ INFO ]  Task:attempt_local1142738285_0075_m_000000_0 is done. And is in the process of committing
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121374 ] - [ INFO ]  map
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121374 ] - [ INFO ]  Task 'attempt_local1142738285_0075_m_000000_0' done.
2020-11-19 16:29:01  [ LocalJobRunner Map Task Executor #0:121374 ] - [ INFO ]  Finishing task: attempt_local1142738285_0075_m_000000_0
2020-11-19 16:29:01  [ Thread-2238:121375 ] - [ INFO ]  map task executor complete.
2020-11-19 16:29:01  [ Thread-2238:121375 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:29:01  [ pool-228-thread-1:121375 ] - [ INFO ]  Starting task: attempt_local1142738285_0075_r_000000_0
2020-11-19 16:29:01  [ pool-228-thread-1:121375 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:01  [ pool-228-thread-1:121375 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:01  [ pool-228-thread-1:121375 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:01  [ pool-228-thread-1:121375 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@8729441
2020-11-19 16:29:01  [ pool-228-thread-1:121376 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:29:01  [ EventFetcher for fetching Map Completion Events:121376 ] - [ INFO ]  attempt_local1142738285_0075_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:29:01  [ localfetcher#75:121377 ] - [ INFO ]  localfetcher#75 about to shuffle output of map attempt_local1142738285_0075_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:29:01  [ localfetcher#75:121377 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1142738285_0075_m_000000_0
2020-11-19 16:29:01  [ localfetcher#75:121377 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:29:01  [ EventFetcher for fetching Map Completion Events:121377 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:29:01  [ pool-228-thread-1:121377 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:01  [ pool-228-thread-1:121377 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:29:01  [ pool-228-thread-1:121378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:01  [ pool-228-thread-1:121378 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:29:01  [ pool-228-thread-1:121378 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:29:01  [ pool-228-thread-1:121378 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:29:01  [ pool-228-thread-1:121378 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:29:01  [ pool-228-thread-1:121378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:01  [ pool-228-thread-1:121379 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:29:01  [ pool-228-thread-1:121379 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:01  [ pool-228-thread-1:121456 ] - [ INFO ]  Task:attempt_local1142738285_0075_r_000000_0 is done. And is in the process of committing
2020-11-19 16:29:01  [ pool-228-thread-1:121465 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:01  [ pool-228-thread-1:121465 ] - [ INFO ]  Task attempt_local1142738285_0075_r_000000_0 is allowed to commit now
2020-11-19 16:29:01  [ pool-228-thread-1:121484 ] - [ INFO ]  Saved output of task 'attempt_local1142738285_0075_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1142738285_0075_r_000000
2020-11-19 16:29:01  [ pool-228-thread-1:121485 ] - [ INFO ]  reduce > reduce
2020-11-19 16:29:01  [ pool-228-thread-1:121485 ] - [ INFO ]  Task 'attempt_local1142738285_0075_r_000000_0' done.
2020-11-19 16:29:01  [ pool-228-thread-1:121485 ] - [ INFO ]  Finishing task: attempt_local1142738285_0075_r_000000_0
2020-11-19 16:29:01  [ Thread-2238:121485 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:29:02  [ main:122248 ] - [ INFO ]  Job job_local1142738285_0075 running in uber mode : false
2020-11-19 16:29:02  [ main:122249 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:29:02  [ main:122249 ] - [ INFO ]  Job job_local1142738285_0075 completed successfully
2020-11-19 16:29:02  [ main:122249 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=166180
		FILE: Number of bytes written=42837247
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4827016
		HDFS: Number of bytes written=79405
		HDFS: Number of read operations=5025
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1630
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2710568960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 16:29:02  [ main:122547 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:29:03  [ main:122559 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:29:03  [ main:122563 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:29:03  [ main:122570 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:29:03  [ main:122606 ] - [ INFO ]  number of splits:1
2020-11-19 16:29:03  [ main:122624 ] - [ INFO ]  Submitting tokens for job: job_local2062453989_0076
2020-11-19 16:29:03  [ main:122663 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:29:03  [ main:122663 ] - [ INFO ]  Running job: job_local2062453989_0076
2020-11-19 16:29:03  [ Thread-2268:122663 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:29:03  [ Thread-2268:122663 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:03  [ Thread-2268:122663 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:29:03  [ Thread-2268:122671 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122671 ] - [ INFO ]  Starting task: attempt_local2062453989_0076_m_000000_0
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122671 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122671 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122671 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122671 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122681 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122681 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122681 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122681 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122681 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122681 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122756 ] - [ INFO ]  
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122756 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122756 ] - [ INFO ]  Spilling map output
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122756 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122756 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122758 ] - [ INFO ]  Finished spill 0
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122759 ] - [ INFO ]  Task:attempt_local2062453989_0076_m_000000_0 is done. And is in the process of committing
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122764 ] - [ INFO ]  map
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122764 ] - [ INFO ]  Task 'attempt_local2062453989_0076_m_000000_0' done.
2020-11-19 16:29:03  [ LocalJobRunner Map Task Executor #0:122764 ] - [ INFO ]  Finishing task: attempt_local2062453989_0076_m_000000_0
2020-11-19 16:29:03  [ Thread-2268:122764 ] - [ INFO ]  map task executor complete.
2020-11-19 16:29:03  [ Thread-2268:122765 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:29:03  [ pool-231-thread-1:122765 ] - [ INFO ]  Starting task: attempt_local2062453989_0076_r_000000_0
2020-11-19 16:29:03  [ pool-231-thread-1:122765 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:03  [ pool-231-thread-1:122765 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:03  [ pool-231-thread-1:122765 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:03  [ pool-231-thread-1:122765 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@307fe2b2
2020-11-19 16:29:03  [ pool-231-thread-1:122765 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:29:03  [ EventFetcher for fetching Map Completion Events:122766 ] - [ INFO ]  attempt_local2062453989_0076_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:29:03  [ localfetcher#76:122766 ] - [ INFO ]  localfetcher#76 about to shuffle output of map attempt_local2062453989_0076_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 16:29:03  [ localfetcher#76:122766 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local2062453989_0076_m_000000_0
2020-11-19 16:29:03  [ localfetcher#76:122767 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 16:29:03  [ EventFetcher for fetching Map Completion Events:122767 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:29:03  [ pool-231-thread-1:122767 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:03  [ pool-231-thread-1:122767 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 16:29:03  [ pool-231-thread-1:122768 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:03  [ pool-231-thread-1:122824 ] - [ INFO ]  Task:attempt_local2062453989_0076_r_000000_0 is done. And is in the process of committing
2020-11-19 16:29:03  [ pool-231-thread-1:122830 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:03  [ pool-231-thread-1:122830 ] - [ INFO ]  Task attempt_local2062453989_0076_r_000000_0 is allowed to commit now
2020-11-19 16:29:03  [ pool-231-thread-1:122848 ] - [ INFO ]  Saved output of task 'attempt_local2062453989_0076_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2062453989_0076_r_000000
2020-11-19 16:29:03  [ pool-231-thread-1:122848 ] - [ INFO ]  reduce > reduce
2020-11-19 16:29:03  [ pool-231-thread-1:122848 ] - [ INFO ]  Task 'attempt_local2062453989_0076_r_000000_0' done.
2020-11-19 16:29:03  [ pool-231-thread-1:122848 ] - [ INFO ]  Finishing task: attempt_local2062453989_0076_r_000000_0
2020-11-19 16:29:03  [ Thread-2268:122848 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:29:04  [ main:123664 ] - [ INFO ]  Job job_local2062453989_0076 running in uber mode : false
2020-11-19 16:29:04  [ main:123664 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:29:04  [ main:123664 ] - [ INFO ]  Job job_local2062453989_0076 completed successfully
2020-11-19 16:29:04  [ main:123664 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=167380
		FILE: Number of bytes written=43409182
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4891426
		HDFS: Number of bytes written=80488
		HDFS: Number of read operations=5093
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1652
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=2646605824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:29:04  [ main:124056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:29:04  [ main:124068 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:29:04  [ main:124073 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:29:04  [ main:124079 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:29:04  [ main:124123 ] - [ INFO ]  number of splits:1
2020-11-19 16:29:04  [ main:124140 ] - [ INFO ]  Submitting tokens for job: job_local617547836_0077
2020-11-19 16:29:04  [ main:124171 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:29:04  [ main:124171 ] - [ INFO ]  Running job: job_local617547836_0077
2020-11-19 16:29:04  [ Thread-2298:124171 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:29:04  [ Thread-2298:124171 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:04  [ Thread-2298:124172 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:29:04  [ Thread-2298:124185 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124186 ] - [ INFO ]  Starting task: attempt_local617547836_0077_m_000000_0
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124186 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124186 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124186 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124187 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124195 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124195 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124195 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124195 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124195 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124195 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124274 ] - [ INFO ]  
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124274 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124274 ] - [ INFO ]  Spilling map output
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124274 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124274 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124275 ] - [ INFO ]  Finished spill 0
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124276 ] - [ INFO ]  Task:attempt_local617547836_0077_m_000000_0 is done. And is in the process of committing
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124281 ] - [ INFO ]  map
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124281 ] - [ INFO ]  Task 'attempt_local617547836_0077_m_000000_0' done.
2020-11-19 16:29:04  [ LocalJobRunner Map Task Executor #0:124281 ] - [ INFO ]  Finishing task: attempt_local617547836_0077_m_000000_0
2020-11-19 16:29:04  [ Thread-2298:124281 ] - [ INFO ]  map task executor complete.
2020-11-19 16:29:04  [ Thread-2298:124282 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:29:04  [ pool-234-thread-1:124282 ] - [ INFO ]  Starting task: attempt_local617547836_0077_r_000000_0
2020-11-19 16:29:04  [ pool-234-thread-1:124282 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:04  [ pool-234-thread-1:124282 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:04  [ pool-234-thread-1:124282 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:04  [ pool-234-thread-1:124282 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5cff5f93
2020-11-19 16:29:04  [ pool-234-thread-1:124283 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:29:04  [ EventFetcher for fetching Map Completion Events:124283 ] - [ INFO ]  attempt_local617547836_0077_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:29:04  [ localfetcher#77:124284 ] - [ INFO ]  localfetcher#77 about to shuffle output of map attempt_local617547836_0077_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:29:04  [ localfetcher#77:124284 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local617547836_0077_m_000000_0
2020-11-19 16:29:04  [ localfetcher#77:124284 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:29:04  [ EventFetcher for fetching Map Completion Events:124284 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:29:04  [ pool-234-thread-1:124284 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:04  [ pool-234-thread-1:124284 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:29:04  [ pool-234-thread-1:124285 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:04  [ pool-234-thread-1:124285 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:29:04  [ pool-234-thread-1:124285 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:29:04  [ pool-234-thread-1:124285 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:29:04  [ pool-234-thread-1:124285 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:29:04  [ pool-234-thread-1:124286 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:04  [ pool-234-thread-1:124286 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:29:04  [ pool-234-thread-1:124286 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:04  [ pool-234-thread-1:124326 ] - [ INFO ]  Task:attempt_local617547836_0077_r_000000_0 is done. And is in the process of committing
2020-11-19 16:29:04  [ pool-234-thread-1:124333 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:04  [ pool-234-thread-1:124333 ] - [ INFO ]  Task attempt_local617547836_0077_r_000000_0 is allowed to commit now
2020-11-19 16:29:04  [ pool-234-thread-1:124356 ] - [ INFO ]  Saved output of task 'attempt_local617547836_0077_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local617547836_0077_r_000000
2020-11-19 16:29:04  [ pool-234-thread-1:124356 ] - [ INFO ]  reduce > reduce
2020-11-19 16:29:04  [ pool-234-thread-1:124356 ] - [ INFO ]  Task 'attempt_local617547836_0077_r_000000_0' done.
2020-11-19 16:29:04  [ pool-234-thread-1:124356 ] - [ INFO ]  Finishing task: attempt_local617547836_0077_r_000000_0
2020-11-19 16:29:04  [ Thread-2298:124356 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:29:05  [ main:125173 ] - [ INFO ]  Job job_local617547836_0077 running in uber mode : false
2020-11-19 16:29:05  [ main:125174 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:29:05  [ main:125174 ] - [ INFO ]  Job job_local617547836_0077 completed successfully
2020-11-19 16:29:05  [ main:125175 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=168576
		FILE: Number of bytes written=43978057
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4955818
		HDFS: Number of bytes written=81558
		HDFS: Number of read operations=5161
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1674
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2646605824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:29:06  [ main:125618 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:29:06  [ main:125626 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:29:06  [ main:125630 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:29:06  [ main:125638 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:29:06  [ main:125675 ] - [ INFO ]  number of splits:1
2020-11-19 16:29:06  [ main:125692 ] - [ INFO ]  Submitting tokens for job: job_local832296409_0078
2020-11-19 16:29:06  [ main:125720 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:29:06  [ main:125720 ] - [ INFO ]  Running job: job_local832296409_0078
2020-11-19 16:29:06  [ Thread-2328:125720 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:29:06  [ Thread-2328:125720 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:06  [ Thread-2328:125720 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:29:06  [ Thread-2328:125734 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125734 ] - [ INFO ]  Starting task: attempt_local832296409_0078_m_000000_0
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125735 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125735 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125735 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125736 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125744 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125744 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125744 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125744 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125744 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125744 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125847 ] - [ INFO ]  
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125847 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125847 ] - [ INFO ]  Spilling map output
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125847 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125847 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125849 ] - [ INFO ]  Finished spill 0
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125850 ] - [ INFO ]  Task:attempt_local832296409_0078_m_000000_0 is done. And is in the process of committing
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125856 ] - [ INFO ]  map
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125856 ] - [ INFO ]  Task 'attempt_local832296409_0078_m_000000_0' done.
2020-11-19 16:29:06  [ LocalJobRunner Map Task Executor #0:125856 ] - [ INFO ]  Finishing task: attempt_local832296409_0078_m_000000_0
2020-11-19 16:29:06  [ Thread-2328:125856 ] - [ INFO ]  map task executor complete.
2020-11-19 16:29:06  [ Thread-2328:125857 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:29:06  [ pool-237-thread-1:125857 ] - [ INFO ]  Starting task: attempt_local832296409_0078_r_000000_0
2020-11-19 16:29:06  [ pool-237-thread-1:125857 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:06  [ pool-237-thread-1:125858 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:06  [ pool-237-thread-1:125858 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:06  [ pool-237-thread-1:125858 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4dace6f
2020-11-19 16:29:06  [ pool-237-thread-1:125858 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:29:06  [ EventFetcher for fetching Map Completion Events:125858 ] - [ INFO ]  attempt_local832296409_0078_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:29:06  [ localfetcher#78:125859 ] - [ INFO ]  localfetcher#78 about to shuffle output of map attempt_local832296409_0078_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:29:06  [ localfetcher#78:125859 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local832296409_0078_m_000000_0
2020-11-19 16:29:06  [ localfetcher#78:125859 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:29:06  [ EventFetcher for fetching Map Completion Events:125860 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:29:06  [ pool-237-thread-1:125860 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:06  [ pool-237-thread-1:125860 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:29:06  [ pool-237-thread-1:125861 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:06  [ pool-237-thread-1:125861 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:29:06  [ pool-237-thread-1:125861 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:29:06  [ pool-237-thread-1:125862 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:29:06  [ pool-237-thread-1:125862 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:29:06  [ pool-237-thread-1:125862 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:06  [ pool-237-thread-1:125862 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:29:06  [ pool-237-thread-1:125862 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:06  [ pool-237-thread-1:125912 ] - [ INFO ]  Task:attempt_local832296409_0078_r_000000_0 is done. And is in the process of committing
2020-11-19 16:29:06  [ pool-237-thread-1:125917 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:06  [ pool-237-thread-1:125917 ] - [ INFO ]  Task attempt_local832296409_0078_r_000000_0 is allowed to commit now
2020-11-19 16:29:06  [ pool-237-thread-1:125933 ] - [ INFO ]  Saved output of task 'attempt_local832296409_0078_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local832296409_0078_r_000000
2020-11-19 16:29:06  [ pool-237-thread-1:125934 ] - [ INFO ]  reduce > reduce
2020-11-19 16:29:06  [ pool-237-thread-1:125934 ] - [ INFO ]  Task 'attempt_local832296409_0078_r_000000_0' done.
2020-11-19 16:29:06  [ pool-237-thread-1:125934 ] - [ INFO ]  Finishing task: attempt_local832296409_0078_r_000000_0
2020-11-19 16:29:06  [ Thread-2328:125934 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:29:07  [ main:126721 ] - [ INFO ]  Job job_local832296409_0078 running in uber mode : false
2020-11-19 16:29:07  [ main:126721 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:29:07  [ main:126721 ] - [ INFO ]  Job job_local832296409_0078 completed successfully
2020-11-19 16:29:07  [ main:126722 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=169770
		FILE: Number of bytes written=44546939
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5020220
		HDFS: Number of bytes written=82636
		HDFS: Number of read operations=5229
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1696
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2646605824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 16:29:07  [ main:127005 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:29:07  [ main:127017 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:29:07  [ main:127022 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:29:07  [ main:127035 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:29:07  [ main:127078 ] - [ INFO ]  number of splits:1
2020-11-19 16:29:07  [ main:127095 ] - [ INFO ]  Submitting tokens for job: job_local671900297_0079
2020-11-19 16:29:07  [ main:127129 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:29:07  [ main:127129 ] - [ INFO ]  Running job: job_local671900297_0079
2020-11-19 16:29:07  [ Thread-2358:127129 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:29:07  [ Thread-2358:127129 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:07  [ Thread-2358:127129 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:29:07  [ Thread-2358:127137 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127137 ] - [ INFO ]  Starting task: attempt_local671900297_0079_m_000000_0
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127138 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127138 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127138 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127138 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127269 ] - [ INFO ]  
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127269 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127269 ] - [ INFO ]  Spilling map output
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127269 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127269 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127271 ] - [ INFO ]  Finished spill 0
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127271 ] - [ INFO ]  Task:attempt_local671900297_0079_m_000000_0 is done. And is in the process of committing
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127277 ] - [ INFO ]  map
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127277 ] - [ INFO ]  Task 'attempt_local671900297_0079_m_000000_0' done.
2020-11-19 16:29:07  [ LocalJobRunner Map Task Executor #0:127277 ] - [ INFO ]  Finishing task: attempt_local671900297_0079_m_000000_0
2020-11-19 16:29:07  [ Thread-2358:127278 ] - [ INFO ]  map task executor complete.
2020-11-19 16:29:07  [ Thread-2358:127278 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:29:07  [ pool-240-thread-1:127278 ] - [ INFO ]  Starting task: attempt_local671900297_0079_r_000000_0
2020-11-19 16:29:07  [ pool-240-thread-1:127278 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:29:07  [ pool-240-thread-1:127278 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:29:07  [ pool-240-thread-1:127278 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:29:07  [ pool-240-thread-1:127278 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f5657c9
2020-11-19 16:29:07  [ pool-240-thread-1:127278 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:29:07  [ EventFetcher for fetching Map Completion Events:127279 ] - [ INFO ]  attempt_local671900297_0079_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:29:07  [ localfetcher#79:127279 ] - [ INFO ]  localfetcher#79 about to shuffle output of map attempt_local671900297_0079_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:29:07  [ localfetcher#79:127279 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local671900297_0079_m_000000_0
2020-11-19 16:29:07  [ localfetcher#79:127279 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:29:07  [ EventFetcher for fetching Map Completion Events:127279 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:29:07  [ pool-240-thread-1:127280 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:07  [ pool-240-thread-1:127280 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:29:07  [ pool-240-thread-1:127280 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:07  [ pool-240-thread-1:127280 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:29:07  [ pool-240-thread-1:127281 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:29:07  [ pool-240-thread-1:127281 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:29:07  [ pool-240-thread-1:127281 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:29:07  [ pool-240-thread-1:127281 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:29:07  [ pool-240-thread-1:127281 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:29:07  [ pool-240-thread-1:127281 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:07  [ pool-240-thread-1:127343 ] - [ INFO ]  Task:attempt_local671900297_0079_r_000000_0 is done. And is in the process of committing
2020-11-19 16:29:07  [ pool-240-thread-1:127350 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:29:07  [ pool-240-thread-1:127350 ] - [ INFO ]  Task attempt_local671900297_0079_r_000000_0 is allowed to commit now
2020-11-19 16:29:07  [ pool-240-thread-1:127365 ] - [ INFO ]  Saved output of task 'attempt_local671900297_0079_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local671900297_0079_r_000000
2020-11-19 16:29:07  [ pool-240-thread-1:127366 ] - [ INFO ]  reduce > reduce
2020-11-19 16:29:07  [ pool-240-thread-1:127366 ] - [ INFO ]  Task 'attempt_local671900297_0079_r_000000_0' done.
2020-11-19 16:29:07  [ pool-240-thread-1:127366 ] - [ INFO ]  Finishing task: attempt_local671900297_0079_r_000000_0
2020-11-19 16:29:07  [ Thread-2358:127366 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:31:19  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:32:45  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:32:45  [ main:791 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:32:45  [ main:792 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:32:46  [ main:1040 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:32:46  [ main:1047 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:32:46  [ main:1083 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:32:46  [ main:1193 ] - [ INFO ]  number of splits:1
2020-11-19 16:32:46  [ main:1290 ] - [ INFO ]  Submitting tokens for job: job_local623027788_0001
2020-11-19 16:32:46  [ main:1435 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:32:46  [ main:1436 ] - [ INFO ]  Running job: job_local623027788_0001
2020-11-19 16:32:46  [ Thread-18:1436 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:32:46  [ Thread-18:1442 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:46  [ Thread-18:1445 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:32:46  [ Thread-18:1566 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1567 ] - [ INFO ]  Starting task: attempt_local623027788_0001_m_000000_0
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1593 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1600 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1601 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1605 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1686 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1686 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1686 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1686 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1687 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1689 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1802 ] - [ INFO ]  
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1804 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1804 ] - [ INFO ]  Spilling map output
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1804 ] - [ INFO ]  bufstart = 0; bufend = 19767; bufvoid = 104857600
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1804 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213076(104852304); length = 1321/6553600
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1814 ] - [ INFO ]  Finished spill 0
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1819 ] - [ INFO ]  Task:attempt_local623027788_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1833 ] - [ INFO ]  map
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1833 ] - [ INFO ]  Task 'attempt_local623027788_0001_m_000000_0' done.
2020-11-19 16:32:46  [ LocalJobRunner Map Task Executor #0:1833 ] - [ INFO ]  Finishing task: attempt_local623027788_0001_m_000000_0
2020-11-19 16:32:46  [ Thread-18:1833 ] - [ INFO ]  map task executor complete.
2020-11-19 16:32:46  [ Thread-18:1835 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:32:46  [ pool-6-thread-1:1836 ] - [ INFO ]  Starting task: attempt_local623027788_0001_r_000000_0
2020-11-19 16:32:47  [ pool-6-thread-1:1842 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:47  [ pool-6-thread-1:1843 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:47  [ pool-6-thread-1:1843 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:47  [ pool-6-thread-1:1845 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@40e8e60
2020-11-19 16:32:47  [ pool-6-thread-1:1857 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:32:47  [ EventFetcher for fetching Map Completion Events:1859 ] - [ INFO ]  attempt_local623027788_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:32:47  [ localfetcher#1:1886 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local623027788_0001_m_000000_0 decomp: 20431 len: 20435 to MEMORY
2020-11-19 16:32:47  [ localfetcher#1:1891 ] - [ INFO ]  Read 20431 bytes from map-output for attempt_local623027788_0001_m_000000_0
2020-11-19 16:32:47  [ localfetcher#1:1892 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20431, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20431
2020-11-19 16:32:47  [ EventFetcher for fetching Map Completion Events:1893 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:32:47  [ pool-6-thread-1:1894 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:47  [ pool-6-thread-1:1894 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:32:47  [ pool-6-thread-1:1899 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:47  [ pool-6-thread-1:1900 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20427 bytes
2020-11-19 16:32:47  [ pool-6-thread-1:1902 ] - [ INFO ]  Merged 1 segments, 20431 bytes to disk to satisfy reduce memory limit
2020-11-19 16:32:47  [ pool-6-thread-1:1903 ] - [ INFO ]  Merging 1 files, 20435 bytes from disk
2020-11-19 16:32:47  [ pool-6-thread-1:1903 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:32:47  [ pool-6-thread-1:1903 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:47  [ pool-6-thread-1:1904 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20427 bytes
2020-11-19 16:32:47  [ pool-6-thread-1:1904 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:47  [ pool-6-thread-1:1930 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:32:47  [ pool-6-thread-1:2152 ] - [ INFO ]  Task:attempt_local623027788_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 16:32:47  [ pool-6-thread-1:2176 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:47  [ pool-6-thread-1:2176 ] - [ INFO ]  Task attempt_local623027788_0001_r_000000_0 is allowed to commit now
2020-11-19 16:32:47  [ main:2439 ] - [ INFO ]  Job job_local623027788_0001 running in uber mode : false
2020-11-19 16:32:47  [ main:2440 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 16:32:47  [ pool-6-thread-1:2461 ] - [ INFO ]  Saved output of task 'attempt_local623027788_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local623027788_0001_r_000000
2020-11-19 16:32:47  [ pool-6-thread-1:2461 ] - [ INFO ]  reduce > reduce
2020-11-19 16:32:47  [ pool-6-thread-1:2461 ] - [ INFO ]  Task 'attempt_local623027788_0001_r_000000_0' done.
2020-11-19 16:32:47  [ pool-6-thread-1:2461 ] - [ INFO ]  Finishing task: attempt_local623027788_0001_r_000000_0
2020-11-19 16:32:47  [ Thread-18:2461 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:32:48  [ main:3444 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:32:48  [ main:3445 ] - [ INFO ]  Job job_local623027788_0001 completed successfully
2020-11-19 16:32:48  [ main:3454 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=41252
		FILE: Number of bytes written=626463
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=179
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=331
		Map output bytes=19767
		Map output materialized bytes=20435
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20435
		Reduce input records=331
		Reduce output records=3
		Spilled Records=662
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:32:48  [ main:3664 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:32:48  [ main:3680 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:32:48  [ main:3686 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:32:48  [ main:3697 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:32:48  [ main:3755 ] - [ INFO ]  number of splits:1
2020-11-19 16:32:48  [ main:3786 ] - [ INFO ]  Submitting tokens for job: job_local1995922692_0002
2020-11-19 16:32:49  [ main:3848 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:32:49  [ main:3848 ] - [ INFO ]  Running job: job_local1995922692_0002
2020-11-19 16:32:49  [ Thread-48:3848 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:32:49  [ Thread-48:3849 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:49  [ Thread-48:3849 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:32:49  [ Thread-48:3858 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3859 ] - [ INFO ]  Starting task: attempt_local1995922692_0002_m_000000_0
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3860 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3860 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3860 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3861 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3919 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3919 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3919 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3919 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:3920 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4061 ] - [ INFO ]  
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4062 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4062 ] - [ INFO ]  Spilling map output
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4062 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4062 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4070 ] - [ INFO ]  Finished spill 0
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4072 ] - [ INFO ]  Task:attempt_local1995922692_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4079 ] - [ INFO ]  map
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4079 ] - [ INFO ]  Task 'attempt_local1995922692_0002_m_000000_0' done.
2020-11-19 16:32:49  [ LocalJobRunner Map Task Executor #0:4079 ] - [ INFO ]  Finishing task: attempt_local1995922692_0002_m_000000_0
2020-11-19 16:32:49  [ Thread-48:4079 ] - [ INFO ]  map task executor complete.
2020-11-19 16:32:49  [ Thread-48:4080 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:32:49  [ pool-9-thread-1:4080 ] - [ INFO ]  Starting task: attempt_local1995922692_0002_r_000000_0
2020-11-19 16:32:49  [ pool-9-thread-1:4082 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:49  [ pool-9-thread-1:4083 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:49  [ pool-9-thread-1:4083 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:49  [ pool-9-thread-1:4083 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@75d9ca5e
2020-11-19 16:32:49  [ pool-9-thread-1:4084 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:32:49  [ EventFetcher for fetching Map Completion Events:4084 ] - [ INFO ]  attempt_local1995922692_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:32:49  [ localfetcher#2:4086 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1995922692_0002_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:32:49  [ localfetcher#2:4086 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1995922692_0002_m_000000_0
2020-11-19 16:32:49  [ localfetcher#2:4086 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:32:49  [ EventFetcher for fetching Map Completion Events:4087 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:32:49  [ pool-9-thread-1:4088 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:49  [ pool-9-thread-1:4088 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:32:49  [ pool-9-thread-1:4089 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:49  [ pool-9-thread-1:4089 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:32:49  [ pool-9-thread-1:4090 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:32:49  [ pool-9-thread-1:4090 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:32:49  [ pool-9-thread-1:4090 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:32:49  [ pool-9-thread-1:4090 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:49  [ pool-9-thread-1:4091 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:32:49  [ pool-9-thread-1:4091 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:49  [ pool-9-thread-1:4168 ] - [ INFO ]  Task:attempt_local1995922692_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 16:32:49  [ pool-9-thread-1:4175 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:49  [ pool-9-thread-1:4175 ] - [ INFO ]  Task attempt_local1995922692_0002_r_000000_0 is allowed to commit now
2020-11-19 16:32:49  [ pool-9-thread-1:4196 ] - [ INFO ]  Saved output of task 'attempt_local1995922692_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1995922692_0002_r_000000
2020-11-19 16:32:49  [ pool-9-thread-1:4197 ] - [ INFO ]  reduce > reduce
2020-11-19 16:32:49  [ pool-9-thread-1:4197 ] - [ INFO ]  Task 'attempt_local1995922692_0002_r_000000_0' done.
2020-11-19 16:32:49  [ pool-9-thread-1:4197 ] - [ INFO ]  Finishing task: attempt_local1995922692_0002_r_000000_0
2020-11-19 16:32:49  [ Thread-48:4197 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:32:50  [ main:4852 ] - [ INFO ]  Job job_local1995922692_0002 running in uber mode : false
2020-11-19 16:32:50  [ main:4853 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:32:50  [ main:4853 ] - [ INFO ]  Job job_local1995922692_0002 completed successfully
2020-11-19 16:32:50  [ main:4859 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=82926
		FILE: Number of bytes written=1218625
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125928
		HDFS: Number of bytes written=898
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=182
2020-11-19 16:32:50  [ main:5234 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:32:50  [ main:5250 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:32:50  [ main:5257 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:32:50  [ main:5264 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:32:50  [ main:5317 ] - [ INFO ]  number of splits:1
2020-11-19 16:32:50  [ main:5352 ] - [ INFO ]  Submitting tokens for job: job_local1468267628_0003
2020-11-19 16:32:50  [ main:5425 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:32:50  [ main:5425 ] - [ INFO ]  Running job: job_local1468267628_0003
2020-11-19 16:32:50  [ Thread-78:5426 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:32:50  [ Thread-78:5426 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:50  [ Thread-78:5427 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:32:50  [ Thread-78:5435 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5435 ] - [ INFO ]  Starting task: attempt_local1468267628_0003_m_000000_0
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5436 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5437 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5437 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5438 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5463 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5463 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5463 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5463 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5463 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5464 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5584 ] - [ INFO ]  
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5584 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5584 ] - [ INFO ]  Spilling map output
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5584 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5585 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5590 ] - [ INFO ]  Finished spill 0
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5592 ] - [ INFO ]  Task:attempt_local1468267628_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5600 ] - [ INFO ]  map
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5600 ] - [ INFO ]  Task 'attempt_local1468267628_0003_m_000000_0' done.
2020-11-19 16:32:50  [ LocalJobRunner Map Task Executor #0:5600 ] - [ INFO ]  Finishing task: attempt_local1468267628_0003_m_000000_0
2020-11-19 16:32:50  [ Thread-78:5601 ] - [ INFO ]  map task executor complete.
2020-11-19 16:32:50  [ Thread-78:5601 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:32:50  [ pool-12-thread-1:5601 ] - [ INFO ]  Starting task: attempt_local1468267628_0003_r_000000_0
2020-11-19 16:32:50  [ pool-12-thread-1:5603 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:50  [ pool-12-thread-1:5603 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:50  [ pool-12-thread-1:5603 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:50  [ pool-12-thread-1:5603 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@79089f25
2020-11-19 16:32:50  [ pool-12-thread-1:5604 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:32:50  [ EventFetcher for fetching Map Completion Events:5604 ] - [ INFO ]  attempt_local1468267628_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:32:50  [ localfetcher#3:5610 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local1468267628_0003_m_000000_0 decomp: 192 len: 196 to MEMORY
2020-11-19 16:32:50  [ localfetcher#3:5611 ] - [ INFO ]  Read 192 bytes from map-output for attempt_local1468267628_0003_m_000000_0
2020-11-19 16:32:50  [ localfetcher#3:5611 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2020-11-19 16:32:50  [ EventFetcher for fetching Map Completion Events:5611 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:32:50  [ pool-12-thread-1:5612 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:50  [ pool-12-thread-1:5612 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:32:50  [ pool-12-thread-1:5613 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:50  [ pool-12-thread-1:5613 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:32:50  [ pool-12-thread-1:5614 ] - [ INFO ]  Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2020-11-19 16:32:50  [ pool-12-thread-1:5614 ] - [ INFO ]  Merging 1 files, 196 bytes from disk
2020-11-19 16:32:50  [ pool-12-thread-1:5614 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:32:50  [ pool-12-thread-1:5614 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:50  [ pool-12-thread-1:5614 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:32:50  [ pool-12-thread-1:5615 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:50  [ pool-12-thread-1:5689 ] - [ INFO ]  Task:attempt_local1468267628_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 16:32:50  [ pool-12-thread-1:5698 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:50  [ pool-12-thread-1:5698 ] - [ INFO ]  Task attempt_local1468267628_0003_r_000000_0 is allowed to commit now
2020-11-19 16:32:50  [ pool-12-thread-1:5716 ] - [ INFO ]  Saved output of task 'attempt_local1468267628_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1468267628_0003_r_000000
2020-11-19 16:32:50  [ pool-12-thread-1:5717 ] - [ INFO ]  reduce > reduce
2020-11-19 16:32:50  [ pool-12-thread-1:5717 ] - [ INFO ]  Task 'attempt_local1468267628_0003_r_000000_0' done.
2020-11-19 16:32:50  [ pool-12-thread-1:5717 ] - [ INFO ]  Finishing task: attempt_local1468267628_0003_r_000000_0
2020-11-19 16:32:50  [ Thread-78:5717 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:32:51  [ main:6428 ] - [ INFO ]  Job job_local1468267628_0003 running in uber mode : false
2020-11-19 16:32:51  [ main:6428 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:32:51  [ main:6428 ] - [ INFO ]  Job job_local1468267628_0003 completed successfully
2020-11-19 16:32:51  [ main:6431 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84122
		FILE: Number of bytes written=1790550
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190348
		HDFS: Number of bytes written=1987
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=196
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=196
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=924844032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:32:51  [ main:6753 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:32:51  [ main:6766 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:32:51  [ main:6772 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:32:51  [ main:6779 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:32:51  [ main:6828 ] - [ INFO ]  number of splits:1
2020-11-19 16:32:52  [ main:6854 ] - [ INFO ]  Submitting tokens for job: job_local725772488_0004
2020-11-19 16:32:52  [ main:6910 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:32:52  [ main:6911 ] - [ INFO ]  Running job: job_local725772488_0004
2020-11-19 16:32:52  [ Thread-108:6911 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:32:52  [ Thread-108:6911 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:52  [ Thread-108:6911 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:32:52  [ Thread-108:6923 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6923 ] - [ INFO ]  Starting task: attempt_local725772488_0004_m_000000_0
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6924 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6924 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6924 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6925 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6984 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6984 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6984 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6984 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6984 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:6985 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7083 ] - [ INFO ]  
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7083 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7083 ] - [ INFO ]  Spilling map output
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7083 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7083 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7086 ] - [ INFO ]  Finished spill 0
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7088 ] - [ INFO ]  Task:attempt_local725772488_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7096 ] - [ INFO ]  map
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7096 ] - [ INFO ]  Task 'attempt_local725772488_0004_m_000000_0' done.
2020-11-19 16:32:52  [ LocalJobRunner Map Task Executor #0:7096 ] - [ INFO ]  Finishing task: attempt_local725772488_0004_m_000000_0
2020-11-19 16:32:52  [ Thread-108:7096 ] - [ INFO ]  map task executor complete.
2020-11-19 16:32:52  [ Thread-108:7097 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:32:52  [ pool-15-thread-1:7097 ] - [ INFO ]  Starting task: attempt_local725772488_0004_r_000000_0
2020-11-19 16:32:52  [ pool-15-thread-1:7099 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:32:52  [ pool-15-thread-1:7099 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:32:52  [ pool-15-thread-1:7099 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:32:52  [ pool-15-thread-1:7099 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ca3b856
2020-11-19 16:32:52  [ pool-15-thread-1:7099 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:32:52  [ EventFetcher for fetching Map Completion Events:7100 ] - [ INFO ]  attempt_local725772488_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:32:52  [ localfetcher#4:7101 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local725772488_0004_m_000000_0 decomp: 192 len: 196 to MEMORY
2020-11-19 16:32:52  [ localfetcher#4:7101 ] - [ INFO ]  Read 192 bytes from map-output for attempt_local725772488_0004_m_000000_0
2020-11-19 16:32:52  [ localfetcher#4:7101 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2020-11-19 16:32:52  [ EventFetcher for fetching Map Completion Events:7102 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:32:52  [ pool-15-thread-1:7102 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:52  [ pool-15-thread-1:7102 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:32:52  [ pool-15-thread-1:7103 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:52  [ pool-15-thread-1:7104 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:32:52  [ pool-15-thread-1:7104 ] - [ INFO ]  Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2020-11-19 16:32:52  [ pool-15-thread-1:7104 ] - [ INFO ]  Merging 1 files, 196 bytes from disk
2020-11-19 16:32:52  [ pool-15-thread-1:7104 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:32:52  [ pool-15-thread-1:7105 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:32:52  [ pool-15-thread-1:7105 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:32:52  [ pool-15-thread-1:7105 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:52  [ pool-15-thread-1:7153 ] - [ INFO ]  Task:attempt_local725772488_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 16:32:52  [ pool-15-thread-1:7167 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:32:52  [ pool-15-thread-1:7167 ] - [ INFO ]  Task attempt_local725772488_0004_r_000000_0 is allowed to commit now
2020-11-19 16:32:52  [ pool-15-thread-1:7193 ] - [ INFO ]  Saved output of task 'attempt_local725772488_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local725772488_0004_r_000000
2020-11-19 16:32:52  [ pool-15-thread-1:7194 ] - [ INFO ]  reduce > reduce
2020-11-19 16:32:52  [ pool-15-thread-1:7194 ] - [ INFO ]  Task 'attempt_local725772488_0004_r_000000_0' done.
2020-11-19 16:32:52  [ pool-15-thread-1:7194 ] - [ INFO ]  Finishing task: attempt_local725772488_0004_r_000000_0
2020-11-19 16:32:52  [ Thread-108:7194 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:32:53  [ main:7911 ] - [ INFO ]  Job job_local725772488_0004 running in uber mode : false
2020-11-19 16:32:53  [ main:7912 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:32:53  [ main:7912 ] - [ INFO ]  Job job_local725772488_0004 completed successfully
2020-11-19 16:32:53  [ main:7915 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85320
		FILE: Number of bytes written=2359428
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254750
		HDFS: Number of bytes written=3061
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=196
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=196
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1150287872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:34:58  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:34:59  [ main:546 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:34:59  [ main:546 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:34:59  [ main:723 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:34:59  [ main:728 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:34:59  [ main:740 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:34:59  [ main:810 ] - [ INFO ]  number of splits:1
2020-11-19 16:34:59  [ main:864 ] - [ INFO ]  Submitting tokens for job: job_local399658977_0001
2020-11-19 16:34:59  [ main:939 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:34:59  [ main:939 ] - [ INFO ]  Running job: job_local399658977_0001
2020-11-19 16:34:59  [ Thread-18:940 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:34:59  [ Thread-18:942 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:34:59  [ Thread-18:943 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:34:59  [ Thread-18:980 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:981 ] - [ INFO ]  Starting task: attempt_local399658977_0001_m_000000_0
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:994 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:998 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:998 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1000 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1047 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1047 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1047 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1047 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1047 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1049 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1149 ] - [ INFO ]  
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1151 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1151 ] - [ INFO ]  Spilling map output
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1151 ] - [ INFO ]  bufstart = 0; bufend = 19293; bufvoid = 104857600
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1151 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213108(104852432); length = 1289/6553600
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  Finished spill 0
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1161 ] - [ INFO ]  Task:attempt_local399658977_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1172 ] - [ INFO ]  map
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1172 ] - [ INFO ]  Task 'attempt_local399658977_0001_m_000000_0' done.
2020-11-19 16:34:59  [ LocalJobRunner Map Task Executor #0:1173 ] - [ INFO ]  Finishing task: attempt_local399658977_0001_m_000000_0
2020-11-19 16:34:59  [ Thread-18:1173 ] - [ INFO ]  map task executor complete.
2020-11-19 16:34:59  [ Thread-18:1175 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:34:59  [ pool-6-thread-1:1175 ] - [ INFO ]  Starting task: attempt_local399658977_0001_r_000000_0
2020-11-19 16:34:59  [ pool-6-thread-1:1178 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:34:59  [ pool-6-thread-1:1179 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:34:59  [ pool-6-thread-1:1179 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:34:59  [ pool-6-thread-1:1180 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7bb5f89b
2020-11-19 16:34:59  [ pool-6-thread-1:1187 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:34:59  [ EventFetcher for fetching Map Completion Events:1189 ] - [ INFO ]  attempt_local399658977_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:34:59  [ localfetcher#1:1207 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local399658977_0001_m_000000_0 decomp: 19941 len: 19945 to MEMORY
2020-11-19 16:34:59  [ localfetcher#1:1210 ] - [ INFO ]  Read 19941 bytes from map-output for attempt_local399658977_0001_m_000000_0
2020-11-19 16:34:59  [ localfetcher#1:1211 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 19941, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19941
2020-11-19 16:34:59  [ EventFetcher for fetching Map Completion Events:1212 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:34:59  [ pool-6-thread-1:1212 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:34:59  [ pool-6-thread-1:1212 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:34:59  [ pool-6-thread-1:1216 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:34:59  [ pool-6-thread-1:1217 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 19937 bytes
2020-11-19 16:34:59  [ pool-6-thread-1:1219 ] - [ INFO ]  Merged 1 segments, 19941 bytes to disk to satisfy reduce memory limit
2020-11-19 16:34:59  [ pool-6-thread-1:1219 ] - [ INFO ]  Merging 1 files, 19945 bytes from disk
2020-11-19 16:34:59  [ pool-6-thread-1:1219 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:34:59  [ pool-6-thread-1:1219 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:34:59  [ pool-6-thread-1:1220 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 19937 bytes
2020-11-19 16:34:59  [ pool-6-thread-1:1220 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:34:59  [ pool-6-thread-1:1241 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:35:00  [ pool-6-thread-1:1582 ] - [ INFO ]  Task:attempt_local399658977_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 16:35:00  [ pool-6-thread-1:1589 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:00  [ pool-6-thread-1:1589 ] - [ INFO ]  Task attempt_local399658977_0001_r_000000_0 is allowed to commit now
2020-11-19 16:35:00  [ pool-6-thread-1:1615 ] - [ INFO ]  Saved output of task 'attempt_local399658977_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local399658977_0001_r_000000
2020-11-19 16:35:00  [ pool-6-thread-1:1615 ] - [ INFO ]  reduce > reduce
2020-11-19 16:35:00  [ pool-6-thread-1:1615 ] - [ INFO ]  Task 'attempt_local399658977_0001_r_000000_0' done.
2020-11-19 16:35:00  [ pool-6-thread-1:1616 ] - [ INFO ]  Finishing task: attempt_local399658977_0001_r_000000_0
2020-11-19 16:35:00  [ Thread-18:1616 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:35:00  [ main:1943 ] - [ INFO ]  Job job_local399658977_0001 running in uber mode : false
2020-11-19 16:35:00  [ main:1944 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:35:00  [ main:1945 ] - [ INFO ]  Job job_local399658977_0001 completed successfully
2020-11-19 16:35:00  [ main:1951 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=40272
		FILE: Number of bytes written=624993
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=180
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=323
		Map output bytes=19293
		Map output materialized bytes=19945
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=19945
		Reduce input records=323
		Reduce output records=3
		Spilled Records=646
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=631242752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 16:35:00  [ main:2084 ] - [ INFO ]   0 
2020-11-19 16:35:00  [ main:2087 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:35:00  [ main:2098 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:35:00  [ main:2102 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:35:00  [ main:2157 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:35:00  [ main:2200 ] - [ INFO ]  number of splits:1
2020-11-19 16:35:00  [ main:2223 ] - [ INFO ]  Submitting tokens for job: job_local309029756_0002
2020-11-19 16:35:00  [ main:2270 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:35:00  [ Thread-48:2270 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:35:00  [ main:2270 ] - [ INFO ]  Running job: job_local309029756_0002
2020-11-19 16:35:00  [ Thread-48:2271 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:00  [ Thread-48:2271 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:35:00  [ Thread-48:2282 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2282 ] - [ INFO ]  Starting task: attempt_local309029756_0002_m_000000_0
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2283 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2283 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2283 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2284 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2328 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2328 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2328 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2328 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2328 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2329 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2442 ] - [ INFO ]  
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2442 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2442 ] - [ INFO ]  Spilling map output
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2442 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2442 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2449 ] - [ INFO ]  Finished spill 0
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2450 ] - [ INFO ]  Task:attempt_local309029756_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2459 ] - [ INFO ]  map
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2459 ] - [ INFO ]  Task 'attempt_local309029756_0002_m_000000_0' done.
2020-11-19 16:35:00  [ LocalJobRunner Map Task Executor #0:2459 ] - [ INFO ]  Finishing task: attempt_local309029756_0002_m_000000_0
2020-11-19 16:35:00  [ Thread-48:2459 ] - [ INFO ]  map task executor complete.
2020-11-19 16:35:00  [ Thread-48:2460 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:35:00  [ pool-9-thread-1:2460 ] - [ INFO ]  Starting task: attempt_local309029756_0002_r_000000_0
2020-11-19 16:35:00  [ pool-9-thread-1:2461 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:00  [ pool-9-thread-1:2461 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:35:00  [ pool-9-thread-1:2461 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:35:00  [ pool-9-thread-1:2461 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@386126d4
2020-11-19 16:35:00  [ pool-9-thread-1:2462 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:35:00  [ EventFetcher for fetching Map Completion Events:2462 ] - [ INFO ]  attempt_local309029756_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:35:00  [ localfetcher#2:2463 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local309029756_0002_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 16:35:00  [ localfetcher#2:2463 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local309029756_0002_m_000000_0
2020-11-19 16:35:00  [ localfetcher#2:2463 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 16:35:00  [ EventFetcher for fetching Map Completion Events:2463 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:35:00  [ pool-9-thread-1:2464 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:00  [ pool-9-thread-1:2464 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:35:00  [ pool-9-thread-1:2465 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:35:00  [ pool-9-thread-1:2465 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 16:35:00  [ pool-9-thread-1:2465 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 16:35:00  [ pool-9-thread-1:2465 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 16:35:00  [ pool-9-thread-1:2465 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:35:00  [ pool-9-thread-1:2465 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:35:00  [ pool-9-thread-1:2466 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 16:35:00  [ pool-9-thread-1:2466 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:01  [ pool-9-thread-1:2542 ] - [ INFO ]  Task:attempt_local309029756_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 16:35:01  [ pool-9-thread-1:2554 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:01  [ pool-9-thread-1:2554 ] - [ INFO ]  Task attempt_local309029756_0002_r_000000_0 is allowed to commit now
2020-11-19 16:35:01  [ pool-9-thread-1:2584 ] - [ INFO ]  Saved output of task 'attempt_local309029756_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local309029756_0002_r_000000
2020-11-19 16:35:01  [ pool-9-thread-1:2585 ] - [ INFO ]  reduce > reduce
2020-11-19 16:35:01  [ pool-9-thread-1:2585 ] - [ INFO ]  Task 'attempt_local309029756_0002_r_000000_0' done.
2020-11-19 16:35:01  [ pool-9-thread-1:2585 ] - [ INFO ]  Finishing task: attempt_local309029756_0002_r_000000_0
2020-11-19 16:35:01  [ Thread-48:2585 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:35:01  [ main:3272 ] - [ INFO ]  Job job_local309029756_0002 running in uber mode : false
2020-11-19 16:35:01  [ main:3273 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:35:01  [ main:3273 ] - [ INFO ]  Job job_local309029756_0002 completed successfully
2020-11-19 16:35:01  [ main:3275 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=80964
		FILE: Number of bytes written=1213614
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125932
		HDFS: Number of bytes written=899
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=842006528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:35:02  [ main:4053 ] - [ INFO ]   1 
2020-11-19 16:35:02  [ main:4055 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:35:02  [ main:4068 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:35:02  [ main:4073 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:35:02  [ main:4079 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:35:02  [ main:4127 ] - [ INFO ]  number of splits:1
2020-11-19 16:35:02  [ main:4150 ] - [ INFO ]  Submitting tokens for job: job_local733534907_0003
2020-11-19 16:35:02  [ main:4197 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:35:02  [ main:4198 ] - [ INFO ]  Running job: job_local733534907_0003
2020-11-19 16:35:02  [ Thread-78:4198 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:35:02  [ Thread-78:4198 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:02  [ Thread-78:4199 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:35:02  [ Thread-78:4211 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4211 ] - [ INFO ]  Starting task: attempt_local733534907_0003_m_000000_0
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4212 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4212 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4212 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4213 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4228 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4228 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4228 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4228 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4228 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:35:02  [ LocalJobRunner Map Task Executor #0:4229 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4627 ] - [ INFO ]  
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4627 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4627 ] - [ INFO ]  Spilling map output
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4627 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4627 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4632 ] - [ INFO ]  Finished spill 0
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4633 ] - [ INFO ]  Task:attempt_local733534907_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4642 ] - [ INFO ]  map
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4642 ] - [ INFO ]  Task 'attempt_local733534907_0003_m_000000_0' done.
2020-11-19 16:35:03  [ LocalJobRunner Map Task Executor #0:4642 ] - [ INFO ]  Finishing task: attempt_local733534907_0003_m_000000_0
2020-11-19 16:35:03  [ Thread-78:4642 ] - [ INFO ]  map task executor complete.
2020-11-19 16:35:03  [ Thread-78:4643 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:35:03  [ pool-12-thread-1:4643 ] - [ INFO ]  Starting task: attempt_local733534907_0003_r_000000_0
2020-11-19 16:35:03  [ pool-12-thread-1:4643 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:03  [ pool-12-thread-1:4644 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:35:03  [ pool-12-thread-1:4644 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:35:03  [ pool-12-thread-1:4644 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@492f8d1f
2020-11-19 16:35:03  [ pool-12-thread-1:4644 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:35:03  [ EventFetcher for fetching Map Completion Events:4645 ] - [ INFO ]  attempt_local733534907_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:35:03  [ localfetcher#3:4645 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local733534907_0003_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 16:35:03  [ localfetcher#3:4646 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local733534907_0003_m_000000_0
2020-11-19 16:35:03  [ localfetcher#3:4646 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 16:35:03  [ EventFetcher for fetching Map Completion Events:4646 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:35:03  [ pool-12-thread-1:4646 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:03  [ pool-12-thread-1:4646 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:35:03  [ pool-12-thread-1:4648 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:35:03  [ pool-12-thread-1:4648 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 16:35:03  [ pool-12-thread-1:4648 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 16:35:03  [ pool-12-thread-1:4649 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 16:35:03  [ pool-12-thread-1:4649 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:35:03  [ pool-12-thread-1:4649 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:35:03  [ pool-12-thread-1:4649 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 16:35:03  [ pool-12-thread-1:4649 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:03  [ pool-12-thread-1:4712 ] - [ INFO ]  Task:attempt_local733534907_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 16:35:03  [ pool-12-thread-1:4725 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:03  [ pool-12-thread-1:4725 ] - [ INFO ]  Task attempt_local733534907_0003_r_000000_0 is allowed to commit now
2020-11-19 16:35:03  [ pool-12-thread-1:4762 ] - [ INFO ]  Saved output of task 'attempt_local733534907_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local733534907_0003_r_000000
2020-11-19 16:35:03  [ pool-12-thread-1:4763 ] - [ INFO ]  reduce > reduce
2020-11-19 16:35:03  [ pool-12-thread-1:4763 ] - [ INFO ]  Task 'attempt_local733534907_0003_r_000000_0' done.
2020-11-19 16:35:03  [ pool-12-thread-1:4764 ] - [ INFO ]  Finishing task: attempt_local733534907_0003_r_000000_0
2020-11-19 16:35:03  [ Thread-78:4764 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:35:03  [ main:5201 ] - [ INFO ]  Job job_local733534907_0003 running in uber mode : false
2020-11-19 16:35:03  [ main:5201 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:35:03  [ main:5202 ] - [ INFO ]  Job job_local733534907_0003 completed successfully
2020-11-19 16:35:03  [ main:5206 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=82154
		FILE: Number of bytes written=1782484
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190330
		HDFS: Number of bytes written=1973
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=44
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=926416896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:35:04  [ main:5897 ] - [ INFO ]   2 
2020-11-19 16:35:04  [ main:5899 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:35:04  [ main:5914 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:35:04  [ main:5920 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:35:04  [ main:5932 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:35:04  [ main:5978 ] - [ INFO ]  number of splits:1
2020-11-19 16:35:04  [ main:5998 ] - [ INFO ]  Submitting tokens for job: job_local200374048_0004
2020-11-19 16:35:04  [ main:6040 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:35:04  [ main:6041 ] - [ INFO ]  Running job: job_local200374048_0004
2020-11-19 16:35:04  [ Thread-108:6041 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:35:04  [ Thread-108:6041 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:04  [ Thread-108:6041 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:35:04  [ Thread-108:6051 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6051 ] - [ INFO ]  Starting task: attempt_local200374048_0004_m_000000_0
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6052 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6052 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6052 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6053 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6065 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6065 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6065 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6065 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6065 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6066 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6182 ] - [ INFO ]  
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6182 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6182 ] - [ INFO ]  Spilling map output
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6182 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6182 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6324 ] - [ INFO ]  Finished spill 0
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6326 ] - [ INFO ]  Task:attempt_local200374048_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6336 ] - [ INFO ]  map
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6336 ] - [ INFO ]  Task 'attempt_local200374048_0004_m_000000_0' done.
2020-11-19 16:35:04  [ LocalJobRunner Map Task Executor #0:6337 ] - [ INFO ]  Finishing task: attempt_local200374048_0004_m_000000_0
2020-11-19 16:35:04  [ Thread-108:6337 ] - [ INFO ]  map task executor complete.
2020-11-19 16:35:04  [ Thread-108:6337 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:35:04  [ pool-15-thread-1:6337 ] - [ INFO ]  Starting task: attempt_local200374048_0004_r_000000_0
2020-11-19 16:35:04  [ pool-15-thread-1:6338 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:35:04  [ pool-15-thread-1:6338 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:35:04  [ pool-15-thread-1:6338 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:35:04  [ pool-15-thread-1:6339 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@183906df
2020-11-19 16:35:04  [ pool-15-thread-1:6339 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:35:04  [ EventFetcher for fetching Map Completion Events:6339 ] - [ INFO ]  attempt_local200374048_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:35:04  [ localfetcher#4:6340 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local200374048_0004_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 16:35:04  [ localfetcher#4:6340 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local200374048_0004_m_000000_0
2020-11-19 16:35:04  [ localfetcher#4:6340 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 16:35:04  [ EventFetcher for fetching Map Completion Events:6341 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:35:04  [ pool-15-thread-1:6341 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:04  [ pool-15-thread-1:6341 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:35:04  [ pool-15-thread-1:6342 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:35:04  [ pool-15-thread-1:6342 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 16:35:04  [ pool-15-thread-1:6343 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 16:35:04  [ pool-15-thread-1:6343 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 16:35:04  [ pool-15-thread-1:6343 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:35:04  [ pool-15-thread-1:6343 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:35:04  [ pool-15-thread-1:6343 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 16:35:04  [ pool-15-thread-1:6343 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:04  [ pool-15-thread-1:6434 ] - [ INFO ]  Task:attempt_local200374048_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 16:35:04  [ pool-15-thread-1:6441 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:35:04  [ pool-15-thread-1:6441 ] - [ INFO ]  Task attempt_local200374048_0004_r_000000_0 is allowed to commit now
2020-11-19 16:35:04  [ pool-15-thread-1:6462 ] - [ INFO ]  Saved output of task 'attempt_local200374048_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local200374048_0004_r_000000
2020-11-19 16:35:04  [ pool-15-thread-1:6463 ] - [ INFO ]  reduce > reduce
2020-11-19 16:35:04  [ pool-15-thread-1:6463 ] - [ INFO ]  Task 'attempt_local200374048_0004_r_000000_0' done.
2020-11-19 16:35:04  [ pool-15-thread-1:6463 ] - [ INFO ]  Finishing task: attempt_local200374048_0004_r_000000_0
2020-11-19 16:35:04  [ Thread-108:6463 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:35:05  [ main:7043 ] - [ INFO ]  Job job_local200374048_0004 running in uber mode : false
2020-11-19 16:35:05  [ main:7044 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:35:05  [ main:7044 ] - [ INFO ]  Job job_local200374048_0004 completed successfully
2020-11-19 16:35:05  [ main:7047 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=83344
		FILE: Number of bytes written=2351354
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254726
		HDFS: Number of bytes written=3047
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=66
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		Total committed heap usage (bytes)=1477443584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=179
2020-11-19 16:48:59  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:49:00  [ main:1460 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:49:00  [ main:1461 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:49:00  [ main:1848 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:00  [ main:1857 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:00  [ main:1884 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:01  [ main:2036 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:01  [ main:2154 ] - [ INFO ]  Submitting tokens for job: job_local1748877320_0001
2020-11-19 16:49:01  [ main:2319 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:01  [ main:2320 ] - [ INFO ]  Running job: job_local1748877320_0001
2020-11-19 16:49:01  [ Thread-18:2321 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:01  [ Thread-18:2327 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:01  [ Thread-18:2329 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:01  [ Thread-18:2407 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2408 ] - [ INFO ]  Starting task: attempt_local1748877320_0001_m_000000_0
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2441 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2451 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2451 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2456 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2534 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2535 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2535 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2535 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2535 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2539 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2868 ] - [ INFO ]  
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2870 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2870 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2870 ] - [ INFO ]  bufstart = 0; bufend = 19474; bufvoid = 104857600
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2870 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213096(104852384); length = 1301/6553600
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2883 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2888 ] - [ INFO ]  Task:attempt_local1748877320_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2915 ] - [ INFO ]  map
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2915 ] - [ INFO ]  Task 'attempt_local1748877320_0001_m_000000_0' done.
2020-11-19 16:49:01  [ LocalJobRunner Map Task Executor #0:2916 ] - [ INFO ]  Finishing task: attempt_local1748877320_0001_m_000000_0
2020-11-19 16:49:01  [ Thread-18:2916 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:01  [ Thread-18:2919 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:01  [ pool-6-thread-1:2919 ] - [ INFO ]  Starting task: attempt_local1748877320_0001_r_000000_0
2020-11-19 16:49:02  [ pool-6-thread-1:2927 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:02  [ pool-6-thread-1:2928 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:02  [ pool-6-thread-1:2928 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:02  [ pool-6-thread-1:2932 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4654bc7b
2020-11-19 16:49:02  [ pool-6-thread-1:2948 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:02  [ EventFetcher for fetching Map Completion Events:2951 ] - [ INFO ]  attempt_local1748877320_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:02  [ localfetcher#1:2982 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1748877320_0001_m_000000_0 decomp: 20128 len: 20132 to MEMORY
2020-11-19 16:49:02  [ localfetcher#1:2989 ] - [ INFO ]  Read 20128 bytes from map-output for attempt_local1748877320_0001_m_000000_0
2020-11-19 16:49:02  [ localfetcher#1:2990 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20128, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20128
2020-11-19 16:49:02  [ EventFetcher for fetching Map Completion Events:2991 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:02  [ pool-6-thread-1:2992 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:02  [ pool-6-thread-1:2992 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:02  [ pool-6-thread-1:3000 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:02  [ pool-6-thread-1:3001 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20124 bytes
2020-11-19 16:49:02  [ pool-6-thread-1:3004 ] - [ INFO ]  Merged 1 segments, 20128 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:02  [ pool-6-thread-1:3005 ] - [ INFO ]  Merging 1 files, 20132 bytes from disk
2020-11-19 16:49:02  [ pool-6-thread-1:3005 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:02  [ pool-6-thread-1:3005 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:02  [ pool-6-thread-1:3006 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20124 bytes
2020-11-19 16:49:02  [ pool-6-thread-1:3006 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:02  [ pool-6-thread-1:3038 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:49:02  [ pool-6-thread-1:3305 ] - [ INFO ]  Task:attempt_local1748877320_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 16:49:02  [ pool-6-thread-1:3316 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:02  [ pool-6-thread-1:3317 ] - [ INFO ]  Task attempt_local1748877320_0001_r_000000_0 is allowed to commit now
2020-11-19 16:49:02  [ main:3324 ] - [ INFO ]  Job job_local1748877320_0001 running in uber mode : false
2020-11-19 16:49:02  [ main:3326 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 16:49:02  [ pool-6-thread-1:3373 ] - [ INFO ]  Saved output of task 'attempt_local1748877320_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1748877320_0001_r_000000
2020-11-19 16:49:02  [ pool-6-thread-1:3373 ] - [ INFO ]  reduce > reduce
2020-11-19 16:49:02  [ pool-6-thread-1:3373 ] - [ INFO ]  Task 'attempt_local1748877320_0001_r_000000_0' done.
2020-11-19 16:49:02  [ pool-6-thread-1:3374 ] - [ INFO ]  Finishing task: attempt_local1748877320_0001_r_000000_0
2020-11-19 16:49:02  [ Thread-18:3374 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:49:03  [ main:4329 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:49:03  [ main:4330 ] - [ INFO ]  Job job_local1748877320_0001 completed successfully
2020-11-19 16:49:03  [ main:4340 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=40646
		FILE: Number of bytes written=628586
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=177
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=326
		Map output bytes=19474
		Map output materialized bytes=20132
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20132
		Reduce input records=326
		Reduce output records=3
		Spilled Records=652
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=577765376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=177
2020-11-19 16:49:03  [ main:4533 ] - [ INFO ]   0 
2020-11-19 16:49:03  [ main:4538 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:49:03  [ main:4561 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:03  [ main:4569 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:03  [ main:4582 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:03  [ main:4657 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:03  [ main:4691 ] - [ INFO ]  Submitting tokens for job: job_local2028260289_0002
2020-11-19 16:49:03  [ main:4778 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:03  [ main:4778 ] - [ INFO ]  Running job: job_local2028260289_0002
2020-11-19 16:49:03  [ Thread-48:4781 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:03  [ Thread-48:4782 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:03  [ Thread-48:4782 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:03  [ Thread-48:4794 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4795 ] - [ INFO ]  Starting task: attempt_local2028260289_0002_m_000000_0
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4796 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4797 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4797 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4798 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4868 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4869 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4869 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4869 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4869 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:03  [ LocalJobRunner Map Task Executor #0:4871 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:04  [ main:5779 ] - [ INFO ]  Job job_local2028260289_0002 running in uber mode : false
2020-11-19 16:49:04  [ main:5780 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6088 ] - [ INFO ]  
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6088 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6089 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6089 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6089 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6097 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6099 ] - [ INFO ]  Task:attempt_local2028260289_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6113 ] - [ INFO ]  map
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6113 ] - [ INFO ]  Task 'attempt_local2028260289_0002_m_000000_0' done.
2020-11-19 16:49:05  [ LocalJobRunner Map Task Executor #0:6113 ] - [ INFO ]  Finishing task: attempt_local2028260289_0002_m_000000_0
2020-11-19 16:49:05  [ Thread-48:6113 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:05  [ Thread-48:6114 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:05  [ pool-9-thread-1:6114 ] - [ INFO ]  Starting task: attempt_local2028260289_0002_r_000000_0
2020-11-19 16:49:05  [ pool-9-thread-1:6115 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:05  [ pool-9-thread-1:6116 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:05  [ pool-9-thread-1:6116 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:05  [ pool-9-thread-1:6116 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e76d09f
2020-11-19 16:49:05  [ pool-9-thread-1:6116 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:05  [ EventFetcher for fetching Map Completion Events:6117 ] - [ INFO ]  attempt_local2028260289_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:05  [ localfetcher#2:6119 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local2028260289_0002_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 16:49:05  [ localfetcher#2:6119 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local2028260289_0002_m_000000_0
2020-11-19 16:49:05  [ localfetcher#2:6119 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 16:49:05  [ EventFetcher for fetching Map Completion Events:6120 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:05  [ pool-9-thread-1:6120 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:05  [ pool-9-thread-1:6120 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:05  [ pool-9-thread-1:6121 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:05  [ pool-9-thread-1:6122 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:49:05  [ pool-9-thread-1:6122 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:05  [ pool-9-thread-1:6123 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 16:49:05  [ pool-9-thread-1:6123 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:05  [ pool-9-thread-1:6123 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:05  [ pool-9-thread-1:6123 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 16:49:05  [ pool-9-thread-1:6124 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:05  [ pool-9-thread-1:6268 ] - [ INFO ]  Task:attempt_local2028260289_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 16:49:05  [ pool-9-thread-1:6293 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:05  [ pool-9-thread-1:6294 ] - [ INFO ]  Task attempt_local2028260289_0002_r_000000_0 is allowed to commit now
2020-11-19 16:49:05  [ pool-9-thread-1:6394 ] - [ INFO ]  Saved output of task 'attempt_local2028260289_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2028260289_0002_r_000000
2020-11-19 16:49:05  [ pool-9-thread-1:6394 ] - [ INFO ]  reduce > reduce
2020-11-19 16:49:05  [ pool-9-thread-1:6395 ] - [ INFO ]  Task 'attempt_local2028260289_0002_r_000000_0' done.
2020-11-19 16:49:05  [ pool-9-thread-1:6395 ] - [ INFO ]  Finishing task: attempt_local2028260289_0002_r_000000_0
2020-11-19 16:49:05  [ Thread-48:6395 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:49:05  [ main:6780 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:49:05  [ main:6780 ] - [ INFO ]  Job job_local2028260289_0002 completed successfully
2020-11-19 16:49:05  [ main:6786 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=81710
		FILE: Number of bytes written=1220439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125920
		HDFS: Number of bytes written=884
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=788529152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=176
2020-11-19 16:49:06  [ main:7619 ] - [ INFO ]   1 
2020-11-19 16:49:06  [ main:7621 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:49:06  [ main:7641 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:06  [ main:7647 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:06  [ main:7661 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:06  [ main:7723 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:06  [ main:7757 ] - [ INFO ]  Submitting tokens for job: job_local1959186182_0003
2020-11-19 16:49:06  [ main:7831 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:06  [ main:7832 ] - [ INFO ]  Running job: job_local1959186182_0003
2020-11-19 16:49:06  [ Thread-78:7832 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:06  [ Thread-78:7832 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:06  [ Thread-78:7833 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:06  [ Thread-78:7872 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:06  [ LocalJobRunner Map Task Executor #0:7872 ] - [ INFO ]  Starting task: attempt_local1959186182_0003_m_000000_0
2020-11-19 16:49:06  [ LocalJobRunner Map Task Executor #0:7873 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:06  [ LocalJobRunner Map Task Executor #0:7874 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:06  [ LocalJobRunner Map Task Executor #0:7874 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:06  [ LocalJobRunner Map Task Executor #0:7875 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:7939 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:7939 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:7939 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:7939 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:7939 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:7941 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8206 ] - [ INFO ]  
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8206 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8206 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8206 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8206 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8216 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8218 ] - [ INFO ]  Task:attempt_local1959186182_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8228 ] - [ INFO ]  map
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8228 ] - [ INFO ]  Task 'attempt_local1959186182_0003_m_000000_0' done.
2020-11-19 16:49:07  [ LocalJobRunner Map Task Executor #0:8228 ] - [ INFO ]  Finishing task: attempt_local1959186182_0003_m_000000_0
2020-11-19 16:49:07  [ Thread-78:8229 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:07  [ Thread-78:8230 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:07  [ pool-12-thread-1:8230 ] - [ INFO ]  Starting task: attempt_local1959186182_0003_r_000000_0
2020-11-19 16:49:07  [ pool-12-thread-1:8231 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:07  [ pool-12-thread-1:8232 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:07  [ pool-12-thread-1:8232 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:07  [ pool-12-thread-1:8232 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33dd7c42
2020-11-19 16:49:07  [ pool-12-thread-1:8232 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:07  [ EventFetcher for fetching Map Completion Events:8233 ] - [ INFO ]  attempt_local1959186182_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:07  [ localfetcher#3:8234 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local1959186182_0003_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:49:07  [ localfetcher#3:8235 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local1959186182_0003_m_000000_0
2020-11-19 16:49:07  [ localfetcher#3:8235 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:49:07  [ EventFetcher for fetching Map Completion Events:8235 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:07  [ pool-12-thread-1:8236 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:07  [ pool-12-thread-1:8236 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:07  [ pool-12-thread-1:8237 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:07  [ pool-12-thread-1:8237 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:49:07  [ pool-12-thread-1:8238 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:07  [ pool-12-thread-1:8238 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:49:07  [ pool-12-thread-1:8238 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:07  [ pool-12-thread-1:8238 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:07  [ pool-12-thread-1:8239 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:49:07  [ pool-12-thread-1:8239 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:07  [ pool-12-thread-1:8384 ] - [ INFO ]  Task:attempt_local1959186182_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 16:49:07  [ pool-12-thread-1:8400 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:07  [ pool-12-thread-1:8400 ] - [ INFO ]  Task attempt_local1959186182_0003_r_000000_0 is allowed to commit now
2020-11-19 16:49:07  [ pool-12-thread-1:8476 ] - [ INFO ]  Saved output of task 'attempt_local1959186182_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1959186182_0003_r_000000
2020-11-19 16:49:07  [ pool-12-thread-1:8477 ] - [ INFO ]  reduce > reduce
2020-11-19 16:49:07  [ pool-12-thread-1:8477 ] - [ INFO ]  Task 'attempt_local1959186182_0003_r_000000_0' done.
2020-11-19 16:49:07  [ pool-12-thread-1:8477 ] - [ INFO ]  Finishing task: attempt_local1959186182_0003_r_000000_0
2020-11-19 16:49:07  [ Thread-78:8477 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:49:07  [ main:8836 ] - [ INFO ]  Job job_local1959186182_0003 running in uber mode : false
2020-11-19 16:49:07  [ main:8836 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:49:08  [ main:9837 ] - [ INFO ]  Job job_local1959186182_0003 completed successfully
2020-11-19 16:49:08  [ main:9840 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=82904
		FILE: Number of bytes written=1792365
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190288
		HDFS: Number of bytes written=1941
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=999292928
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=177
2020-11-19 16:49:09  [ main:10431 ] - [ INFO ]   2 
2020-11-19 16:49:09  [ main:10432 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:49:09  [ main:10460 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:09  [ main:10466 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:09  [ main:10478 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:09  [ main:10531 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:09  [ main:10567 ] - [ INFO ]  Submitting tokens for job: job_local146640949_0004
2020-11-19 16:49:09  [ main:10651 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:09  [ Thread-108:10651 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:09  [ main:10651 ] - [ INFO ]  Running job: job_local146640949_0004
2020-11-19 16:49:09  [ Thread-108:10652 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:09  [ Thread-108:10652 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:09  [ Thread-108:10667 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10667 ] - [ INFO ]  Starting task: attempt_local146640949_0004_m_000000_0
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10668 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10669 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10669 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10669 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10731 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10731 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10731 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10731 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10731 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:09  [ LocalJobRunner Map Task Executor #0:10732 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11335 ] - [ INFO ]  
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11335 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11335 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11336 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11336 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11341 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11343 ] - [ INFO ]  Task:attempt_local146640949_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11352 ] - [ INFO ]  map
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11352 ] - [ INFO ]  Task 'attempt_local146640949_0004_m_000000_0' done.
2020-11-19 16:49:10  [ LocalJobRunner Map Task Executor #0:11353 ] - [ INFO ]  Finishing task: attempt_local146640949_0004_m_000000_0
2020-11-19 16:49:10  [ Thread-108:11353 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:10  [ Thread-108:11353 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:10  [ pool-15-thread-1:11354 ] - [ INFO ]  Starting task: attempt_local146640949_0004_r_000000_0
2020-11-19 16:49:10  [ pool-15-thread-1:11355 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:10  [ pool-15-thread-1:11355 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:10  [ pool-15-thread-1:11355 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:10  [ pool-15-thread-1:11355 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49e4c5ff
2020-11-19 16:49:10  [ pool-15-thread-1:11356 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:10  [ EventFetcher for fetching Map Completion Events:11356 ] - [ INFO ]  attempt_local146640949_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:10  [ localfetcher#4:11358 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local146640949_0004_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 16:49:10  [ localfetcher#4:11358 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local146640949_0004_m_000000_0
2020-11-19 16:49:10  [ localfetcher#4:11359 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 16:49:10  [ EventFetcher for fetching Map Completion Events:11359 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:10  [ pool-15-thread-1:11360 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:10  [ pool-15-thread-1:11360 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:10  [ pool-15-thread-1:11361 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:10  [ pool-15-thread-1:11361 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:49:10  [ pool-15-thread-1:11362 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:10  [ pool-15-thread-1:11363 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 16:49:10  [ pool-15-thread-1:11363 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:10  [ pool-15-thread-1:11363 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:10  [ pool-15-thread-1:11363 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 16:49:10  [ pool-15-thread-1:11363 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:10  [ pool-15-thread-1:11451 ] - [ INFO ]  Task:attempt_local146640949_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 16:49:10  [ pool-15-thread-1:11470 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:10  [ pool-15-thread-1:11470 ] - [ INFO ]  Task attempt_local146640949_0004_r_000000_0 is allowed to commit now
2020-11-19 16:49:10  [ pool-15-thread-1:11525 ] - [ INFO ]  Saved output of task 'attempt_local146640949_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local146640949_0004_r_000000
2020-11-19 16:49:10  [ pool-15-thread-1:11526 ] - [ INFO ]  reduce > reduce
2020-11-19 16:49:10  [ pool-15-thread-1:11526 ] - [ INFO ]  Task 'attempt_local146640949_0004_r_000000_0' done.
2020-11-19 16:49:10  [ pool-15-thread-1:11526 ] - [ INFO ]  Finishing task: attempt_local146640949_0004_r_000000_0
2020-11-19 16:49:10  [ Thread-108:11526 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:49:10  [ main:11655 ] - [ INFO ]  Job job_local146640949_0004 running in uber mode : false
2020-11-19 16:49:10  [ main:11656 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:49:11  [ main:12658 ] - [ INFO ]  Job job_local146640949_0004 completed successfully
2020-11-19 16:49:11  [ main:12661 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84102
		FILE: Number of bytes written=2361241
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254662
		HDFS: Number of bytes written=3002
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1255145472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=176
2020-11-19 16:49:12  [ main:13297 ] - [ INFO ]   3 
2020-11-19 16:49:12  [ main:13298 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:49:13  [ main:14166 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:13  [ main:14171 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:13  [ main:14181 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:13  [ main:14238 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:13  [ main:14267 ] - [ INFO ]  Submitting tokens for job: job_local1552023991_0005
2020-11-19 16:49:13  [ main:14329 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:13  [ main:14329 ] - [ INFO ]  Running job: job_local1552023991_0005
2020-11-19 16:49:13  [ Thread-138:14330 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:13  [ Thread-138:14330 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:13  [ Thread-138:14330 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:13  [ Thread-138:14406 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14407 ] - [ INFO ]  Starting task: attempt_local1552023991_0005_m_000000_0
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14407 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14408 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14408 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14408 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14475 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14475 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14475 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14475 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14475 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14476 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14631 ] - [ INFO ]  
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14631 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14632 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14632 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14632 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14635 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14637 ] - [ INFO ]  Task:attempt_local1552023991_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14652 ] - [ INFO ]  map
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14653 ] - [ INFO ]  Task 'attempt_local1552023991_0005_m_000000_0' done.
2020-11-19 16:49:13  [ LocalJobRunner Map Task Executor #0:14653 ] - [ INFO ]  Finishing task: attempt_local1552023991_0005_m_000000_0
2020-11-19 16:49:13  [ Thread-138:14653 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:13  [ Thread-138:14654 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:13  [ pool-18-thread-1:14654 ] - [ INFO ]  Starting task: attempt_local1552023991_0005_r_000000_0
2020-11-19 16:49:13  [ pool-18-thread-1:14655 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:13  [ pool-18-thread-1:14655 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:13  [ pool-18-thread-1:14655 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:13  [ pool-18-thread-1:14655 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c3fead4
2020-11-19 16:49:13  [ pool-18-thread-1:14656 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:13  [ EventFetcher for fetching Map Completion Events:14656 ] - [ INFO ]  attempt_local1552023991_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:13  [ localfetcher#5:14657 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local1552023991_0005_m_000000_0 decomp: 192 len: 196 to MEMORY
2020-11-19 16:49:13  [ localfetcher#5:14658 ] - [ INFO ]  Read 192 bytes from map-output for attempt_local1552023991_0005_m_000000_0
2020-11-19 16:49:13  [ localfetcher#5:14658 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2020-11-19 16:49:13  [ EventFetcher for fetching Map Completion Events:14658 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:13  [ pool-18-thread-1:14659 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:13  [ pool-18-thread-1:14659 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:13  [ pool-18-thread-1:14660 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:13  [ pool-18-thread-1:14660 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:49:13  [ pool-18-thread-1:14661 ] - [ INFO ]  Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:13  [ pool-18-thread-1:14661 ] - [ INFO ]  Merging 1 files, 196 bytes from disk
2020-11-19 16:49:13  [ pool-18-thread-1:14661 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:13  [ pool-18-thread-1:14661 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:13  [ pool-18-thread-1:14662 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-19 16:49:13  [ pool-18-thread-1:14662 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:14  [ pool-18-thread-1:14950 ] - [ INFO ]  Task:attempt_local1552023991_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 16:49:14  [ pool-18-thread-1:14960 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:14  [ pool-18-thread-1:14960 ] - [ INFO ]  Task attempt_local1552023991_0005_r_000000_0 is allowed to commit now
2020-11-19 16:49:14  [ pool-18-thread-1:15222 ] - [ INFO ]  Saved output of task 'attempt_local1552023991_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1552023991_0005_r_000000
2020-11-19 16:49:14  [ pool-18-thread-1:15222 ] - [ INFO ]  reduce > reduce
2020-11-19 16:49:14  [ pool-18-thread-1:15222 ] - [ INFO ]  Task 'attempt_local1552023991_0005_r_000000_0' done.
2020-11-19 16:49:14  [ pool-18-thread-1:15222 ] - [ INFO ]  Finishing task: attempt_local1552023991_0005_r_000000_0
2020-11-19 16:49:14  [ Thread-138:15222 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:49:14  [ main:15330 ] - [ INFO ]  Job job_local1552023991_0005 running in uber mode : false
2020-11-19 16:49:14  [ main:15330 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:49:15  [ main:16332 ] - [ INFO ]  Job job_local1552023991_0005 completed successfully
2020-11-19 16:49:15  [ main:16334 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85298
		FILE: Number of bytes written=2933166
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319030
		HDFS: Number of bytes written=4059
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=90
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=196
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=196
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1465909248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=177
2020-11-19 16:49:16  [ main:17021 ] - [ INFO ]   4 
2020-11-19 16:49:16  [ main:17022 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 16:49:16  [ main:17041 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:16  [ main:17047 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:16  [ main:17063 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:16  [ main:17155 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:16  [ main:17183 ] - [ INFO ]  Submitting tokens for job: job_local895392217_0006
2020-11-19 16:49:16  [ main:17252 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:16  [ main:17253 ] - [ INFO ]  Running job: job_local895392217_0006
2020-11-19 16:49:16  [ Thread-168:17253 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:16  [ Thread-168:17254 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:16  [ Thread-168:17254 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:16  [ Thread-168:17291 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17291 ] - [ INFO ]  Starting task: attempt_local895392217_0006_m_000000_0
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17292 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17292 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17292 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17293 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17351 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17351 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17351 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17351 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17351 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17351 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17653 ] - [ INFO ]  
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17653 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17653 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17653 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17653 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17657 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17658 ] - [ INFO ]  Task:attempt_local895392217_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17686 ] - [ INFO ]  map
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17686 ] - [ INFO ]  Task 'attempt_local895392217_0006_m_000000_0' done.
2020-11-19 16:49:16  [ LocalJobRunner Map Task Executor #0:17686 ] - [ INFO ]  Finishing task: attempt_local895392217_0006_m_000000_0
2020-11-19 16:49:16  [ Thread-168:17687 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:16  [ Thread-168:17687 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:16  [ pool-21-thread-1:17688 ] - [ INFO ]  Starting task: attempt_local895392217_0006_r_000000_0
2020-11-19 16:49:16  [ pool-21-thread-1:17689 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:16  [ pool-21-thread-1:17689 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:16  [ pool-21-thread-1:17689 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:16  [ pool-21-thread-1:17689 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e0c8082
2020-11-19 16:49:16  [ pool-21-thread-1:17689 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:16  [ EventFetcher for fetching Map Completion Events:17690 ] - [ INFO ]  attempt_local895392217_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:16  [ localfetcher#6:17691 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local895392217_0006_m_000000_0 decomp: 193 len: 197 to MEMORY
2020-11-19 16:49:16  [ localfetcher#6:17692 ] - [ INFO ]  Read 193 bytes from map-output for attempt_local895392217_0006_m_000000_0
2020-11-19 16:49:16  [ localfetcher#6:17692 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 193, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->193
2020-11-19 16:49:16  [ EventFetcher for fetching Map Completion Events:17692 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:16  [ pool-21-thread-1:17693 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:16  [ pool-21-thread-1:17693 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:16  [ pool-21-thread-1:17694 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:16  [ pool-21-thread-1:17694 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:49:16  [ pool-21-thread-1:17695 ] - [ INFO ]  Merged 1 segments, 193 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:16  [ pool-21-thread-1:17695 ] - [ INFO ]  Merging 1 files, 197 bytes from disk
2020-11-19 16:49:16  [ pool-21-thread-1:17695 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:16  [ pool-21-thread-1:17695 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:16  [ pool-21-thread-1:17695 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 189 bytes
2020-11-19 16:49:16  [ pool-21-thread-1:17696 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:16  [ pool-21-thread-1:17791 ] - [ INFO ]  Task:attempt_local895392217_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 16:49:16  [ pool-21-thread-1:17802 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:16  [ pool-21-thread-1:17802 ] - [ INFO ]  Task attempt_local895392217_0006_r_000000_0 is allowed to commit now
2020-11-19 16:49:16  [ pool-21-thread-1:17919 ] - [ INFO ]  Saved output of task 'attempt_local895392217_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local895392217_0006_r_000000
2020-11-19 16:49:16  [ pool-21-thread-1:17920 ] - [ INFO ]  reduce > reduce
2020-11-19 16:49:16  [ pool-21-thread-1:17920 ] - [ INFO ]  Task 'attempt_local895392217_0006_r_000000_0' done.
2020-11-19 16:49:16  [ pool-21-thread-1:17920 ] - [ INFO ]  Finishing task: attempt_local895392217_0006_r_000000_0
2020-11-19 16:49:17  [ Thread-168:17921 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:49:17  [ main:18258 ] - [ INFO ]  Job job_local895392217_0006 running in uber mode : false
2020-11-19 16:49:17  [ main:18259 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:49:17  [ main:18259 ] - [ INFO ]  Job job_local895392217_0006 completed successfully
2020-11-19 16:49:17  [ main:18261 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86498
		FILE: Number of bytes written=3502047
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383404
		HDFS: Number of bytes written=5119
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=197
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=197
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1684013056
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=175
2020-11-19 16:49:30  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:49:31  [ main:1654 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:49:31  [ main:1655 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:49:32  [ main:2009 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:49:32  [ main:2019 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:49:32  [ main:2036 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:49:32  [ main:2140 ] - [ INFO ]  number of splits:1
2020-11-19 16:49:32  [ main:2243 ] - [ INFO ]  Submitting tokens for job: job_local1864688992_0001
2020-11-19 16:49:32  [ main:2409 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:49:32  [ Thread-18:2410 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:49:32  [ main:2410 ] - [ INFO ]  Running job: job_local1864688992_0001
2020-11-19 16:49:32  [ Thread-18:2415 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:32  [ Thread-18:2417 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:49:32  [ Thread-18:2461 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2461 ] - [ INFO ]  Starting task: attempt_local1864688992_0001_m_000000_0
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2485 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2491 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2491 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2494 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2564 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2564 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2564 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2564 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2564 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:49:32  [ LocalJobRunner Map Task Executor #0:2567 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:49:33  [ main:3413 ] - [ INFO ]  Job job_local1864688992_0001 running in uber mode : false
2020-11-19 16:49:33  [ main:3414 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 16:49:38  [ communication thread:8498 ] - [ INFO ]  map > map
2020-11-19 16:49:39  [ main:9429 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 16:49:41  [ communication thread:11500 ] - [ INFO ]  map > map
2020-11-19 16:49:42  [ main:12433 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 16:49:44  [ communication thread:14501 ] - [ INFO ]  map > map
2020-11-19 16:49:45  [ main:15441 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 16:49:45  [ LocalJobRunner Map Task Executor #0:15452 ] - [ INFO ]  map > map
2020-11-19 16:49:45  [ LocalJobRunner Map Task Executor #0:15454 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:49:45  [ LocalJobRunner Map Task Executor #0:15454 ] - [ INFO ]  Spilling map output
2020-11-19 16:49:45  [ LocalJobRunner Map Task Executor #0:15454 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 16:49:45  [ LocalJobRunner Map Task Executor #0:15454 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 16:49:47  [ communication thread:17504 ] - [ INFO ]  map > sort
2020-11-19 16:49:48  [ LocalJobRunner Map Task Executor #0:18375 ] - [ INFO ]  Finished spill 0
2020-11-19 16:49:48  [ LocalJobRunner Map Task Executor #0:18382 ] - [ INFO ]  Task:attempt_local1864688992_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:49:48  [ LocalJobRunner Map Task Executor #0:18409 ] - [ INFO ]  map
2020-11-19 16:49:48  [ LocalJobRunner Map Task Executor #0:18409 ] - [ INFO ]  Task 'attempt_local1864688992_0001_m_000000_0' done.
2020-11-19 16:49:48  [ LocalJobRunner Map Task Executor #0:18409 ] - [ INFO ]  Finishing task: attempt_local1864688992_0001_m_000000_0
2020-11-19 16:49:48  [ Thread-18:18409 ] - [ INFO ]  map task executor complete.
2020-11-19 16:49:48  [ Thread-18:18411 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:49:48  [ pool-6-thread-1:18411 ] - [ INFO ]  Starting task: attempt_local1864688992_0001_r_000000_0
2020-11-19 16:49:48  [ pool-6-thread-1:18417 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:49:48  [ pool-6-thread-1:18417 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:49:48  [ pool-6-thread-1:18417 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:49:48  [ pool-6-thread-1:18420 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69608679
2020-11-19 16:49:48  [ pool-6-thread-1:18431 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:49:48  [ EventFetcher for fetching Map Completion Events:18433 ] - [ INFO ]  attempt_local1864688992_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:49:48  [ main:18447 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 16:49:48  [ localfetcher#1:18461 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1864688992_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 16:49:48  [ localfetcher#1:18497 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1864688992_0001_m_000000_0
2020-11-19 16:49:48  [ localfetcher#1:18499 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 16:49:48  [ EventFetcher for fetching Map Completion Events:18500 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:49:48  [ pool-6-thread-1:18501 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:48  [ pool-6-thread-1:18501 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:49:48  [ pool-6-thread-1:18507 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:48  [ pool-6-thread-1:18507 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 16:49:48  [ pool-6-thread-1:18559 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 16:49:48  [ pool-6-thread-1:18560 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 16:49:48  [ pool-6-thread-1:18560 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:49:48  [ pool-6-thread-1:18561 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:49:48  [ pool-6-thread-1:18561 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 16:49:48  [ pool-6-thread-1:18561 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:49:48  [ pool-6-thread-1:18670 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:50:08  [ communication thread:38795 ] - [ INFO ]  reduce > reduce
2020-11-19 16:50:18  [ main:48450 ] - [ INFO ]   map 100% reduce 67%
2020-11-19 16:50:26  [ communication thread:56025 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:06  [ communication thread:96242 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:09  [ communication thread:99406 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:28  [ main:1 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:51:29  [ main:1448 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:51:29  [ main:1449 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:51:30  [ main:1811 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:51:30  [ main:1821 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:51:30  [ main:1838 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:51:30  [ main:1984 ] - [ INFO ]  number of splits:1
2020-11-19 16:51:30  [ main:2119 ] - [ INFO ]  Submitting tokens for job: job_local1748755443_0001
2020-11-19 16:51:30  [ main:2332 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:51:30  [ main:2333 ] - [ INFO ]  Running job: job_local1748755443_0001
2020-11-19 16:51:30  [ Thread-18:2334 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:51:30  [ Thread-18:2339 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:51:30  [ Thread-18:2341 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:51:30  [ Thread-18:2396 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2396 ] - [ INFO ]  Starting task: attempt_local1748755443_0001_m_000000_0
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2427 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2435 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2436 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2441 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2518 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2518 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2518 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2518 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2518 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:51:30  [ LocalJobRunner Map Task Executor #0:2529 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:51:31  [ main:3339 ] - [ INFO ]  Job job_local1748755443_0001 running in uber mode : false
2020-11-19 16:51:31  [ main:3340 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 16:51:36  [ communication thread:8438 ] - [ INFO ]  map > map
2020-11-19 16:51:37  [ main:9363 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 16:51:39  [ communication thread:11439 ] - [ INFO ]  map > map
2020-11-19 16:51:40  [ main:12371 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 16:51:42  [ communication thread:14443 ] - [ INFO ]  map > map
2020-11-19 16:51:43  [ LocalJobRunner Map Task Executor #0:15230 ] - [ INFO ]  map > map
2020-11-19 16:51:43  [ LocalJobRunner Map Task Executor #0:15232 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:51:43  [ LocalJobRunner Map Task Executor #0:15232 ] - [ INFO ]  Spilling map output
2020-11-19 16:51:43  [ LocalJobRunner Map Task Executor #0:15232 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 16:51:43  [ LocalJobRunner Map Task Executor #0:15232 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 16:51:43  [ main:15384 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 16:51:45  [ communication thread:17448 ] - [ INFO ]  map > sort
2020-11-19 16:51:46  [ main:18393 ] - [ INFO ]   map 67% reduce 0%
2020-11-19 16:51:46  [ LocalJobRunner Map Task Executor #0:18540 ] - [ INFO ]  Finished spill 0
2020-11-19 16:51:46  [ LocalJobRunner Map Task Executor #0:18544 ] - [ INFO ]  Task:attempt_local1748755443_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:51:46  [ LocalJobRunner Map Task Executor #0:18567 ] - [ INFO ]  map
2020-11-19 16:51:46  [ LocalJobRunner Map Task Executor #0:18567 ] - [ INFO ]  Task 'attempt_local1748755443_0001_m_000000_0' done.
2020-11-19 16:51:46  [ LocalJobRunner Map Task Executor #0:18567 ] - [ INFO ]  Finishing task: attempt_local1748755443_0001_m_000000_0
2020-11-19 16:51:46  [ Thread-18:18567 ] - [ INFO ]  map task executor complete.
2020-11-19 16:51:46  [ Thread-18:18569 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:51:46  [ pool-6-thread-1:18570 ] - [ INFO ]  Starting task: attempt_local1748755443_0001_r_000000_0
2020-11-19 16:51:46  [ pool-6-thread-1:18576 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:51:46  [ pool-6-thread-1:18576 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:51:46  [ pool-6-thread-1:18576 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:51:46  [ pool-6-thread-1:18579 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@78d65ab4
2020-11-19 16:51:46  [ pool-6-thread-1:18592 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:51:46  [ EventFetcher for fetching Map Completion Events:18595 ] - [ INFO ]  attempt_local1748755443_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:51:46  [ localfetcher#1:18633 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1748755443_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 16:51:47  [ localfetcher#1:18672 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local1748755443_0001_m_000000_0
2020-11-19 16:51:47  [ localfetcher#1:18673 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 16:51:47  [ EventFetcher for fetching Map Completion Events:18675 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:51:47  [ pool-6-thread-1:18675 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:51:47  [ pool-6-thread-1:18676 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:51:47  [ pool-6-thread-1:18682 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:51:47  [ pool-6-thread-1:18682 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 16:51:47  [ pool-6-thread-1:18729 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 16:51:47  [ pool-6-thread-1:18730 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 16:51:47  [ pool-6-thread-1:18730 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:51:47  [ pool-6-thread-1:18730 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:51:47  [ pool-6-thread-1:18731 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 16:51:47  [ pool-6-thread-1:18731 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:51:47  [ pool-6-thread-1:18766 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:51:51  [ main:23090 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 16:51:56  [ communication thread:27807 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:57  [ main:28807 ] - [ INFO ]   map 100% reduce 67%
2020-11-19 16:51:59  [ communication thread:30811 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:59  [ main:30814 ] - [ INFO ]   map 100% reduce 99%
2020-11-19 16:51:59  [ pool-6-thread-1:31004 ] - [ INFO ]  Task:attempt_local1748755443_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 16:51:59  [ pool-6-thread-1:31016 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:59  [ pool-6-thread-1:31016 ] - [ INFO ]  Task attempt_local1748755443_0001_r_000000_0 is allowed to commit now
2020-11-19 16:51:59  [ pool-6-thread-1:31050 ] - [ INFO ]  Saved output of task 'attempt_local1748755443_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1748755443_0001_r_000000
2020-11-19 16:51:59  [ pool-6-thread-1:31051 ] - [ INFO ]  reduce > reduce
2020-11-19 16:51:59  [ pool-6-thread-1:31051 ] - [ INFO ]  Task 'attempt_local1748755443_0001_r_000000_0' done.
2020-11-19 16:51:59  [ pool-6-thread-1:31051 ] - [ INFO ]  Finishing task: attempt_local1748755443_0001_r_000000_0
2020-11-19 16:51:59  [ Thread-18:31051 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:52:00  [ main:31817 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:52:00  [ main:31818 ] - [ INFO ]  Job job_local1748755443_0001 completed successfully
2020-11-19 16:52:00  [ main:31831 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61498356
		FILE: Number of bytes written=92817876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=1782162
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=30748996
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1209008128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=1782162
2020-11-19 16:56:50  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 16:56:51  [ main:1188 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 16:56:51  [ main:1189 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 16:56:51  [ main:1474 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 16:56:51  [ main:1481 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 16:56:51  [ main:1547 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 16:56:51  [ main:1764 ] - [ INFO ]  number of splits:1
2020-11-19 16:56:52  [ main:1865 ] - [ INFO ]  Submitting tokens for job: job_local341095607_0001
2020-11-19 16:56:52  [ main:1996 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 16:56:52  [ main:1996 ] - [ INFO ]  Running job: job_local341095607_0001
2020-11-19 16:56:52  [ Thread-18:1997 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 16:56:52  [ Thread-18:2002 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:56:52  [ Thread-18:2004 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 16:56:52  [ Thread-18:2057 ] - [ INFO ]  Waiting for map tasks
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2058 ] - [ INFO ]  Starting task: attempt_local341095607_0001_m_000000_0
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2081 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2089 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2089 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2092 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2163 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2164 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2164 ] - [ INFO ]  soft limit at 83886080
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2164 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2164 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 16:56:52  [ LocalJobRunner Map Task Executor #0:2167 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 16:56:53  [ main:2998 ] - [ INFO ]  Job job_local341095607_0001 running in uber mode : false
2020-11-19 16:56:53  [ main:2999 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 16:56:58  [ communication thread:8091 ] - [ INFO ]  map > map
2020-11-19 16:56:59  [ main:9012 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 16:57:01  [ communication thread:11094 ] - [ INFO ]  map > map
2020-11-19 16:57:02  [ main:12018 ] - [ INFO ]   map 44% reduce 0%
2020-11-19 16:57:04  [ communication thread:14095 ] - [ INFO ]  map > map
2020-11-19 16:57:05  [ main:15023 ] - [ INFO ]   map 59% reduce 0%
2020-11-19 16:57:05  [ LocalJobRunner Map Task Executor #0:15299 ] - [ INFO ]  map > map
2020-11-19 16:57:05  [ LocalJobRunner Map Task Executor #0:15301 ] - [ INFO ]  Starting flush of map output
2020-11-19 16:57:05  [ LocalJobRunner Map Task Executor #0:15301 ] - [ INFO ]  Spilling map output
2020-11-19 16:57:05  [ LocalJobRunner Map Task Executor #0:15301 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 16:57:05  [ LocalJobRunner Map Task Executor #0:15301 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 16:57:07  [ communication thread:17100 ] - [ INFO ]  map > sort
2020-11-19 16:57:07  [ LocalJobRunner Map Task Executor #0:17196 ] - [ INFO ]  Finished spill 0
2020-11-19 16:57:07  [ LocalJobRunner Map Task Executor #0:17199 ] - [ INFO ]  Task:attempt_local341095607_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 16:57:07  [ LocalJobRunner Map Task Executor #0:17234 ] - [ INFO ]  map
2020-11-19 16:57:07  [ LocalJobRunner Map Task Executor #0:17234 ] - [ INFO ]  Task 'attempt_local341095607_0001_m_000000_0' done.
2020-11-19 16:57:07  [ LocalJobRunner Map Task Executor #0:17235 ] - [ INFO ]  Finishing task: attempt_local341095607_0001_m_000000_0
2020-11-19 16:57:07  [ Thread-18:17235 ] - [ INFO ]  map task executor complete.
2020-11-19 16:57:07  [ Thread-18:17237 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 16:57:07  [ pool-6-thread-1:17237 ] - [ INFO ]  Starting task: attempt_local341095607_0001_r_000000_0
2020-11-19 16:57:07  [ pool-6-thread-1:17243 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 16:57:07  [ pool-6-thread-1:17244 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 16:57:07  [ pool-6-thread-1:17244 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 16:57:07  [ pool-6-thread-1:17246 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ced2cc5
2020-11-19 16:57:07  [ pool-6-thread-1:17258 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 16:57:07  [ EventFetcher for fetching Map Completion Events:17260 ] - [ INFO ]  attempt_local341095607_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 16:57:07  [ localfetcher#1:17286 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local341095607_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 16:57:07  [ localfetcher#1:17315 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local341095607_0001_m_000000_0
2020-11-19 16:57:07  [ localfetcher#1:17316 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 16:57:07  [ EventFetcher for fetching Map Completion Events:17317 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 16:57:07  [ pool-6-thread-1:17318 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:57:07  [ pool-6-thread-1:17318 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 16:57:07  [ pool-6-thread-1:17323 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:57:07  [ pool-6-thread-1:17323 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 16:57:07  [ pool-6-thread-1:17354 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 16:57:07  [ pool-6-thread-1:17354 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 16:57:07  [ pool-6-thread-1:17354 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 16:57:07  [ pool-6-thread-1:17355 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 16:57:07  [ pool-6-thread-1:17355 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 16:57:07  [ pool-6-thread-1:17355 ] - [ INFO ]  1 / 1 copied.
2020-11-19 16:57:07  [ pool-6-thread-1:17384 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 16:57:08  [ main:18033 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 16:57:13  [ communication thread:23248 ] - [ INFO ]  reduce > reduce
2020-11-19 16:57:14  [ main:24050 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 16:57:16  [ pool-6-thread-1:26007 ] - [ INFO ]  Task:attempt_local341095607_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 16:57:16  [ pool-6-thread-1:26024 ] - [ INFO ]  reduce > reduce
2020-11-19 16:57:16  [ pool-6-thread-1:26024 ] - [ INFO ]  Task attempt_local341095607_0001_r_000000_0 is allowed to commit now
2020-11-19 16:57:16  [ pool-6-thread-1:26138 ] - [ INFO ]  Saved output of task 'attempt_local341095607_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local341095607_0001_r_000000
2020-11-19 16:57:16  [ pool-6-thread-1:26139 ] - [ INFO ]  reduce > reduce
2020-11-19 16:57:16  [ pool-6-thread-1:26139 ] - [ INFO ]  Task 'attempt_local341095607_0001_r_000000_0' done.
2020-11-19 16:57:16  [ pool-6-thread-1:26139 ] - [ INFO ]  Finishing task: attempt_local341095607_0001_r_000000_0
2020-11-19 16:57:16  [ Thread-18:26139 ] - [ INFO ]  reduce task executor complete.
2020-11-19 16:57:17  [ main:27061 ] - [ INFO ]  Job job_local341095607_0001 completed successfully
2020-11-19 16:57:17  [ main:27071 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61498356
		FILE: Number of bytes written=92814832
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3592330
		HDFS: Number of bytes written=1782162
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=30748996
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=1163395072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=1782162
2020-11-19 17:01:27  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 17:01:28  [ main:742 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 17:01:28  [ main:742 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 17:01:28  [ main:977 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 17:01:28  [ main:985 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 17:01:28  [ main:999 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 17:01:28  [ main:1104 ] - [ INFO ]  number of splits:1
2020-11-19 17:01:28  [ main:1188 ] - [ INFO ]  Submitting tokens for job: job_local949280031_0001
2020-11-19 17:01:29  [ main:1324 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 17:01:29  [ main:1325 ] - [ INFO ]  Running job: job_local949280031_0001
2020-11-19 17:01:29  [ Thread-18:1325 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 17:01:29  [ Thread-18:1329 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 17:01:29  [ Thread-18:1331 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 17:01:29  [ Thread-18:1372 ] - [ INFO ]  Waiting for map tasks
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1372 ] - [ INFO ]  Starting task: attempt_local949280031_0001_m_000000_0
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1390 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1395 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1395 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1398 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1456 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1456 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1456 ] - [ INFO ]  soft limit at 83886080
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1456 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1456 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 17:01:29  [ LocalJobRunner Map Task Executor #0:1459 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 17:01:30  [ main:2327 ] - [ INFO ]  Job job_local949280031_0001 running in uber mode : false
2020-11-19 17:01:30  [ main:2328 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 17:01:35  [ communication thread:7398 ] - [ INFO ]  map > map
2020-11-19 17:01:36  [ main:8342 ] - [ INFO ]   map 32% reduce 0%
2020-11-19 17:01:38  [ communication thread:10401 ] - [ INFO ]  map > map
2020-11-19 17:01:39  [ main:11350 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 17:01:41  [ communication thread:13406 ] - [ INFO ]  map > map
2020-11-19 17:01:41  [ LocalJobRunner Map Task Executor #0:14158 ] - [ INFO ]  map > map
2020-11-19 17:01:41  [ LocalJobRunner Map Task Executor #0:14159 ] - [ INFO ]  Starting flush of map output
2020-11-19 17:01:41  [ LocalJobRunner Map Task Executor #0:14160 ] - [ INFO ]  Spilling map output
2020-11-19 17:01:41  [ LocalJobRunner Map Task Executor #0:14160 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 17:01:41  [ LocalJobRunner Map Task Executor #0:14160 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 17:01:42  [ main:14355 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 17:01:44  [ communication thread:16407 ] - [ INFO ]  map > sort
2020-11-19 17:01:44  [ LocalJobRunner Map Task Executor #0:16732 ] - [ INFO ]  Finished spill 0
2020-11-19 17:01:44  [ LocalJobRunner Map Task Executor #0:16736 ] - [ INFO ]  Task:attempt_local949280031_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 17:01:44  [ LocalJobRunner Map Task Executor #0:16748 ] - [ INFO ]  map
2020-11-19 17:01:44  [ LocalJobRunner Map Task Executor #0:16748 ] - [ INFO ]  Task 'attempt_local949280031_0001_m_000000_0' done.
2020-11-19 17:01:44  [ LocalJobRunner Map Task Executor #0:16748 ] - [ INFO ]  Finishing task: attempt_local949280031_0001_m_000000_0
2020-11-19 17:01:44  [ Thread-18:16748 ] - [ INFO ]  map task executor complete.
2020-11-19 17:01:44  [ Thread-18:16750 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 17:01:44  [ pool-6-thread-1:16750 ] - [ INFO ]  Starting task: attempt_local949280031_0001_r_000000_0
2020-11-19 17:01:44  [ pool-6-thread-1:16755 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 17:01:44  [ pool-6-thread-1:16755 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 17:01:44  [ pool-6-thread-1:16755 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 17:01:44  [ pool-6-thread-1:16756 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@318b7b47
2020-11-19 17:01:44  [ pool-6-thread-1:16766 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 17:01:44  [ EventFetcher for fetching Map Completion Events:16767 ] - [ INFO ]  attempt_local949280031_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 17:01:44  [ localfetcher#1:16796 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local949280031_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 17:01:44  [ localfetcher#1:16828 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local949280031_0001_m_000000_0
2020-11-19 17:01:44  [ localfetcher#1:16830 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 17:01:44  [ EventFetcher for fetching Map Completion Events:16831 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 17:01:44  [ pool-6-thread-1:16832 ] - [ INFO ]  1 / 1 copied.
2020-11-19 17:01:44  [ pool-6-thread-1:16832 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 17:01:44  [ pool-6-thread-1:16837 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 17:01:44  [ pool-6-thread-1:16838 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 17:01:44  [ pool-6-thread-1:16874 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 17:01:44  [ pool-6-thread-1:16874 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 17:01:44  [ pool-6-thread-1:16875 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 17:01:44  [ pool-6-thread-1:16875 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 17:01:44  [ pool-6-thread-1:16875 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 17:01:44  [ pool-6-thread-1:16876 ] - [ INFO ]  1 / 1 copied.
2020-11-19 17:01:44  [ pool-6-thread-1:16895 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 17:01:45  [ main:17359 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 17:01:50  [ communication thread:22762 ] - [ INFO ]  reduce > reduce
2020-11-19 17:01:51  [ main:23374 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 17:01:52  [ pool-6-thread-1:24393 ] - [ INFO ]  Task:attempt_local949280031_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 17:01:52  [ pool-6-thread-1:24399 ] - [ INFO ]  reduce > reduce
2020-11-19 17:01:52  [ pool-6-thread-1:24399 ] - [ INFO ]  Task attempt_local949280031_0001_r_000000_0 is allowed to commit now
2020-11-19 17:01:52  [ pool-6-thread-1:24422 ] - [ INFO ]  Saved output of task 'attempt_local949280031_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local949280031_0001_r_000000
2020-11-19 17:01:52  [ pool-6-thread-1:24422 ] - [ INFO ]  reduce > reduce
2020-11-19 17:01:52  [ pool-6-thread-1:24423 ] - [ INFO ]  Task 'attempt_local949280031_0001_r_000000_0' done.
2020-11-19 17:01:52  [ pool-6-thread-1:24423 ] - [ INFO ]  Finishing task: attempt_local949280031_0001_r_000000_0
2020-11-19 17:01:52  [ Thread-18:24423 ] - [ INFO ]  reduce task executor complete.
2020-11-19 17:01:53  [ main:25375 ] - [ INFO ]  Job job_local949280031_0001 completed successfully
2020-11-19 17:01:53  [ main:25386 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61498356
		FILE: Number of bytes written=92814832
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=30743224
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=30748996
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=961019904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=30743224
2020-11-19 21:47:13  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 21:47:48  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 21:51:02  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 21:53:01  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 21:55:37  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:04:04  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:08:44  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:22:52  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:24:38  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:34:14  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:34:30  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:37:58  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:39:38  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:40:20  [ main:1 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:43:27  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:43:28  [ main:712 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:43:28  [ main:713 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:43:28  [ main:898 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:43:28  [ main:904 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:43:28  [ main:927 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:43:28  [ main:979 ] - [ INFO ]  number of splits:1
2020-11-19 22:43:28  [ main:1053 ] - [ INFO ]  Submitting tokens for job: job_local1335114506_0001
2020-11-19 22:43:28  [ main:1143 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:43:28  [ main:1144 ] - [ INFO ]  Running job: job_local1335114506_0001
2020-11-19 22:43:28  [ Thread-18:1145 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:43:28  [ Thread-18:1149 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:43:28  [ Thread-18:1150 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:43:28  [ Thread-18:1188 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  Starting task: attempt_local1335114506_0001_m_000000_0
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1204 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1210 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1210 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1263 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1263 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1263 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1264 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1264 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1266 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:43:28  [ LocalJobRunner Map Task Executor #0:1284 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:43:28  [ Thread-18:1294 ] - [ INFO ]  map task executor complete.
2020-11-19 22:43:28  [ Thread-18:1304 ] - [ WARN ]  job_local1335114506_0001
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:43:29  [ main:2148 ] - [ INFO ]  Job job_local1335114506_0001 running in uber mode : false
2020-11-19 22:43:29  [ main:2150 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:43:29  [ main:2151 ] - [ INFO ]  Job job_local1335114506_0001 failed with state FAILED due to: NA
2020-11-19 22:43:29  [ main:2157 ] - [ INFO ]  Counters: 0
2020-11-19 22:43:29  [ main:2185 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2206 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2221 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2234 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2249 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2263 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2286 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2300 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2313 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2329 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2348 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2364 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2383 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2401 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2417 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2434 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2451 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2470 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2492 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2512 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2534 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2548 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2563 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:29  [ main:2577 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2591 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2604 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2620 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2633 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2648 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2668 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2690 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2710 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2725 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2739 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2758 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2771 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2785 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2799 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2815 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2829 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2847 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2861 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2878 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2895 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2909 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2922 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2936 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2954 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2968 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2980 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:2999 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3013 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3031 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3043 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3058 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3072 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3085 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3100 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3113 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3127 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3140 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3152 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3168 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3189 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3203 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3216 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3233 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3252 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3268 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3282 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3297 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3329 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3345 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3361 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3376 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3390 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3405 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3418 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3430 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3444 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3457 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3476 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3489 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3514 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3528 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3544 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3558 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:30  [ main:3573 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3593 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3611 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3626 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3641 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3655 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3669 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3684 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3699 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3715 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3730 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3748 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3767 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3782 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3796 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3809 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3822 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3834 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3848 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3862 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3878 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3894 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3909 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3924 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3938 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3956 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3980 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:3996 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4011 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4029 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4044 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4058 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4072 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4096 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4122 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4135 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4158 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4173 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4188 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4204 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4227 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4247 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4261 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4274 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4287 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4303 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4322 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4342 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4357 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4371 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4386 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4401 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4415 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4431 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4444 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4463 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4476 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4489 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4503 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4519 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4533 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4551 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:31  [ main:4567 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4581 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4608 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4624 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4640 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4652 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4667 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4679 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4693 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4710 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4728 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4743 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4760 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4774 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4788 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4804 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4823 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4839 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4852 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4864 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4877 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4889 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4902 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4916 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4929 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4941 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4958 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4974 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:4986 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5004 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5023 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5043 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5057 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5069 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5083 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5096 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5113 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5129 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5142 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5161 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5177 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5193 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5212 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5227 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5255 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5270 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5284 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5299 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5312 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5328 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5341 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5362 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5376 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:32  [ main:5389 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:43:59  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:44:00  [ main:697 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:44:00  [ main:697 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:44:00  [ main:730 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:751 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:767 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:783 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:802 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:817 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:832 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:846 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:862 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:882 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:897 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:912 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:938 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:952 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:967 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:983 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1000 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1014 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1029 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1042 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1055 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1068 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1081 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1094 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1111 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1124 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1138 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1151 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1163 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:00  [ main:1176 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1190 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1204 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1217 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1229 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1244 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1259 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1272 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1288 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1305 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1329 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1342 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1357 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1369 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1383 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1405 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1419 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1433 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1449 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1470 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1486 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1499 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1515 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1530 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1543 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1570 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1586 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1600 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1612 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1628 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1645 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1660 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1674 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1690 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1704 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1727 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1743 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1756 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1768 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1783 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1796 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1810 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1827 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1839 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1853 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1866 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1885 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1901 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1913 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1946 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1959 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1972 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:1987 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2003 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2015 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2035 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2047 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2060 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2078 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2091 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2104 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2137 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:01  [ main:2149 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2207 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2220 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2234 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2249 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2261 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2274 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2286 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2299 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2313 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2326 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2337 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2349 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2362 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2377 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2391 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2405 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2419 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2431 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2444 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2458 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2473 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2489 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2521 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2534 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2547 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2560 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2575 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2590 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2606 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2621 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2643 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2655 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2667 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2682 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2695 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2709 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2723 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2736 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2754 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2767 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2781 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2794 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2823 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2843 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2856 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2873 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2888 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2900 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2922 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2937 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2959 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2974 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:2988 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3002 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3016 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3039 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3054 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3071 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3083 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3097 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3110 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3126 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3141 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3156 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:02  [ main:3172 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3185 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3204 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3217 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3233 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3248 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3276 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3293 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3310 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3333 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3353 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3367 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3383 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3401 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3416 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3440 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3456 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:44:03  [ main:3482 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:45:10  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:45:11  [ main:691 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:45:11  [ main:692 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:45:11  [ main:847 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:45:11  [ main:851 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:45:11  [ main:877 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:45:11  [ main:922 ] - [ INFO ]  number of splits:1
2020-11-19 22:45:11  [ main:978 ] - [ INFO ]  Submitting tokens for job: job_local391604440_0001
2020-11-19 22:45:11  [ main:1055 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:45:11  [ main:1055 ] - [ INFO ]  Running job: job_local391604440_0001
2020-11-19 22:45:11  [ Thread-18:1056 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:45:11  [ Thread-18:1058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:11  [ Thread-18:1059 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:45:11  [ Thread-18:1091 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:45:11  [ LocalJobRunner Map Task Executor #0:1091 ] - [ INFO ]  Starting task: attempt_local391604440_0001_m_000000_0
2020-11-19 22:45:11  [ LocalJobRunner Map Task Executor #0:1104 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:11  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:45:11  [ LocalJobRunner Map Task Executor #0:1107 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:45:11  [ LocalJobRunner Map Task Executor #0:1109 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1155 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1158 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:45:12  [ LocalJobRunner Map Task Executor #0:1176 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:45:12  [ Thread-18:1182 ] - [ INFO ]  map task executor complete.
2020-11-19 22:45:12  [ Thread-18:1192 ] - [ WARN ]  job_local391604440_0001
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:45:12  [ main:2059 ] - [ INFO ]  Job job_local391604440_0001 running in uber mode : false
2020-11-19 22:45:12  [ main:2060 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:45:12  [ main:2061 ] - [ INFO ]  Job job_local391604440_0001 failed with state FAILED due to: NA
2020-11-19 22:45:12  [ main:2064 ] - [ INFO ]  Counters: 0
2020-11-19 22:45:12  [ main:2103 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:45:13  [ main:2118 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:45:13  [ main:2123 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:45:13  [ main:2142 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:45:13  [ main:2173 ] - [ INFO ]  number of splits:1
2020-11-19 22:45:13  [ main:2191 ] - [ INFO ]  Submitting tokens for job: job_local1875726974_0002
2020-11-19 22:45:13  [ main:2236 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:45:13  [ Thread-36:2236 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:45:13  [ main:2236 ] - [ INFO ]  Running job: job_local1875726974_0002
2020-11-19 22:45:13  [ Thread-36:2236 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:13  [ Thread-36:2236 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:45:13  [ Thread-36:2248 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2248 ] - [ INFO ]  Starting task: attempt_local1875726974_0002_m_000000_0
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2249 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2249 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2249 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2250 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2290 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2290 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2290 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2290 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2290 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2290 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:45:13  [ LocalJobRunner Map Task Executor #0:2298 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:45:13  [ Thread-36:2301 ] - [ INFO ]  map task executor complete.
2020-11-19 22:45:13  [ Thread-36:2309 ] - [ WARN ]  job_local1875726974_0002
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:45:14  [ main:3238 ] - [ INFO ]  Job job_local1875726974_0002 running in uber mode : false
2020-11-19 22:45:14  [ main:3238 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:45:14  [ main:3238 ] - [ INFO ]  Job job_local1875726974_0002 failed with state FAILED due to: NA
2020-11-19 22:45:14  [ main:3238 ] - [ INFO ]  Counters: 0
2020-11-19 22:45:14  [ main:3271 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:45:14  [ main:3284 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:45:14  [ main:3288 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:45:14  [ main:3308 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:45:14  [ main:3337 ] - [ INFO ]  number of splits:1
2020-11-19 22:45:14  [ main:3358 ] - [ INFO ]  Submitting tokens for job: job_local778749658_0003
2020-11-19 22:45:14  [ main:3405 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:45:14  [ Thread-54:3405 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:45:14  [ main:3405 ] - [ INFO ]  Running job: job_local778749658_0003
2020-11-19 22:45:14  [ Thread-54:3405 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:14  [ Thread-54:3406 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:45:14  [ Thread-54:3415 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3415 ] - [ INFO ]  Starting task: attempt_local778749658_0003_m_000000_0
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3416 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3416 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3416 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3417 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3464 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3464 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3464 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3464 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3464 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3464 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:45:14  [ LocalJobRunner Map Task Executor #0:3472 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:45:14  [ Thread-54:3476 ] - [ INFO ]  map task executor complete.
2020-11-19 22:45:14  [ Thread-54:3496 ] - [ WARN ]  job_local778749658_0003
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:45:15  [ main:4406 ] - [ INFO ]  Job job_local778749658_0003 running in uber mode : false
2020-11-19 22:45:15  [ main:4407 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:45:15  [ main:4407 ] - [ INFO ]  Job job_local778749658_0003 failed with state FAILED due to: NA
2020-11-19 22:45:15  [ main:4407 ] - [ INFO ]  Counters: 0
2020-11-19 22:45:15  [ main:4456 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:45:15  [ main:4472 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:45:15  [ main:4477 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:45:15  [ main:4502 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:45:15  [ main:4537 ] - [ INFO ]  number of splits:1
2020-11-19 22:45:15  [ main:4556 ] - [ INFO ]  Submitting tokens for job: job_local1061520668_0004
2020-11-19 22:45:15  [ main:4610 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:45:15  [ main:4610 ] - [ INFO ]  Running job: job_local1061520668_0004
2020-11-19 22:45:15  [ Thread-72:4610 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:45:15  [ Thread-72:4610 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:15  [ Thread-72:4611 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:45:15  [ Thread-72:4621 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4621 ] - [ INFO ]  Starting task: attempt_local1061520668_0004_m_000000_0
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4622 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4622 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4622 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4623 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4638 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4638 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4638 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4638 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4638 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4638 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:45:15  [ LocalJobRunner Map Task Executor #0:4646 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:45:15  [ Thread-72:4649 ] - [ INFO ]  map task executor complete.
2020-11-19 22:45:15  [ Thread-72:4657 ] - [ WARN ]  job_local1061520668_0004
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:45:16  [ main:5610 ] - [ INFO ]  Job job_local1061520668_0004 running in uber mode : false
2020-11-19 22:45:16  [ main:5611 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:45:16  [ main:5611 ] - [ INFO ]  Job job_local1061520668_0004 failed with state FAILED due to: NA
2020-11-19 22:45:16  [ main:5611 ] - [ INFO ]  Counters: 0
2020-11-19 22:46:33  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:46:34  [ main:661 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:46:34  [ main:662 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:46:34  [ main:843 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:46:34  [ main:848 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:46:34  [ main:874 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:46:34  [ main:925 ] - [ INFO ]  number of splits:1
2020-11-19 22:46:34  [ main:989 ] - [ INFO ]  Submitting tokens for job: job_local1671546032_0001
2020-11-19 22:46:34  [ main:1081 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:46:34  [ main:1081 ] - [ INFO ]  Running job: job_local1671546032_0001
2020-11-19 22:46:34  [ Thread-18:1082 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:46:34  [ Thread-18:1085 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:46:34  [ Thread-18:1086 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:46:35  [ Thread-18:1117 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1117 ] - [ INFO ]  Starting task: attempt_local1671546032_0001_m_000000_0
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1130 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1136 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1187 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1187 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1187 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1187 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1187 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1195 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:46:35  [ LocalJobRunner Map Task Executor #0:1207 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:46:35  [ Thread-18:1213 ] - [ INFO ]  map task executor complete.
2020-11-19 22:46:35  [ Thread-18:1228 ] - [ WARN ]  job_local1671546032_0001
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:46:35  [ main:2085 ] - [ INFO ]  Job job_local1671546032_0001 running in uber mode : false
2020-11-19 22:46:35  [ main:2087 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:46:35  [ main:2089 ] - [ INFO ]  Job job_local1671546032_0001 failed with state FAILED due to: NA
2020-11-19 22:46:35  [ main:2093 ] - [ INFO ]  Counters: 0
2020-11-19 22:46:36  [ main:2158 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:46:36  [ main:2174 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:46:36  [ main:2179 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:46:36  [ main:2197 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:46:36  [ main:2226 ] - [ INFO ]  number of splits:1
2020-11-19 22:46:36  [ main:2246 ] - [ INFO ]  Submitting tokens for job: job_local1111194581_0002
2020-11-19 22:46:36  [ main:2291 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:46:36  [ main:2291 ] - [ INFO ]  Running job: job_local1111194581_0002
2020-11-19 22:46:36  [ Thread-38:2291 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:46:36  [ Thread-38:2291 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:46:36  [ Thread-38:2292 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:46:36  [ Thread-38:2302 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2302 ] - [ INFO ]  Starting task: attempt_local1111194581_0002_m_000000_0
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2302 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2303 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2303 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2303 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2345 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2345 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2345 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2345 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2345 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2346 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:46:36  [ LocalJobRunner Map Task Executor #0:2354 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:46:36  [ Thread-38:2356 ] - [ INFO ]  map task executor complete.
2020-11-19 22:46:36  [ Thread-38:2363 ] - [ WARN ]  job_local1111194581_0002
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:46:37  [ main:3291 ] - [ INFO ]  Job job_local1111194581_0002 running in uber mode : false
2020-11-19 22:46:37  [ main:3292 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:46:37  [ main:3292 ] - [ INFO ]  Job job_local1111194581_0002 failed with state FAILED due to: NA
2020-11-19 22:46:37  [ main:3292 ] - [ INFO ]  Counters: 0
2020-11-19 22:46:48  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:46:49  [ main:906 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:46:49  [ main:907 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:46:49  [ main:1105 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:46:49  [ main:1112 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:46:49  [ main:1140 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:46:49  [ main:1189 ] - [ INFO ]  number of splits:1
2020-11-19 22:46:49  [ main:1265 ] - [ INFO ]  Submitting tokens for job: job_local2009178798_0001
2020-11-19 22:46:49  [ main:1364 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:46:49  [ main:1365 ] - [ INFO ]  Running job: job_local2009178798_0001
2020-11-19 22:46:49  [ Thread-18:1365 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:46:49  [ Thread-18:1369 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:46:49  [ Thread-18:1370 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:46:49  [ Thread-18:1416 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1416 ] - [ INFO ]  Starting task: attempt_local2009178798_0001_m_000000_0
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1431 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1435 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1435 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1437 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1489 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1489 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1489 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1489 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1489 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:46:49  [ LocalJobRunner Map Task Executor #0:1491 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:46:55  [ LocalJobRunner Map Task Executor #0:7665 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:46:55  [ main:7665 ] - [ INFO ]  Job job_local2009178798_0001 running in uber mode : false
2020-11-19 22:46:55  [ main:7667 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:46:55  [ Thread-18:7674 ] - [ INFO ]  map task executor complete.
2020-11-19 22:46:55  [ Thread-18:7685 ] - [ WARN ]  job_local2009178798_0001
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:50:38  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:50:38  [ main:557 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:50:38  [ main:558 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:50:38  [ main:779 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:50:38  [ main:784 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:50:38  [ main:795 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:50:39  [ main:862 ] - [ INFO ]  number of splits:1
2020-11-19 22:50:39  [ main:919 ] - [ INFO ]  Submitting tokens for job: job_local2128072257_0001
2020-11-19 22:50:39  [ main:1012 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:50:39  [ main:1013 ] - [ INFO ]  Running job: job_local2128072257_0001
2020-11-19 22:50:39  [ Thread-18:1013 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:50:39  [ Thread-18:1017 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:50:39  [ Thread-18:1018 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:50:39  [ Thread-18:1052 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1052 ] - [ INFO ]  Starting task: attempt_local2128072257_0001_m_000000_0
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1068 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1072 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1072 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1074 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1125 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1125 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1125 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1125 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1125 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:50:39  [ LocalJobRunner Map Task Executor #0:1127 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:50:40  [ main:2016 ] - [ INFO ]  Job job_local2128072257_0001 running in uber mode : false
2020-11-19 22:50:40  [ main:2018 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:50:45  [ communication thread:7080 ] - [ INFO ]  map > map
2020-11-19 22:50:46  [ main:8040 ] - [ INFO ]   map 12% reduce 0%
2020-11-19 22:50:48  [ communication thread:10081 ] - [ INFO ]  map > map
2020-11-19 22:50:49  [ main:11046 ] - [ INFO ]   map 22% reduce 0%
2020-11-19 22:50:51  [ communication thread:13083 ] - [ INFO ]  map > map
2020-11-19 22:50:52  [ main:14060 ] - [ INFO ]   map 29% reduce 0%
2020-11-19 22:50:54  [ communication thread:16086 ] - [ INFO ]  map > map
2020-11-19 22:50:55  [ main:17064 ] - [ INFO ]   map 34% reduce 0%
2020-11-19 22:50:57  [ communication thread:19088 ] - [ INFO ]  map > map
2020-11-19 22:50:58  [ main:20074 ] - [ INFO ]   map 41% reduce 0%
2020-11-19 22:51:00  [ communication thread:22090 ] - [ INFO ]  map > map
2020-11-19 22:51:01  [ main:23084 ] - [ INFO ]   map 46% reduce 0%
2020-11-19 22:51:03  [ communication thread:25094 ] - [ INFO ]  map > map
2020-11-19 22:51:04  [ main:26096 ] - [ INFO ]   map 54% reduce 0%
2020-11-19 22:51:06  [ communication thread:28097 ] - [ INFO ]  map > map
2020-11-19 22:51:06  [ main:28105 ] - [ INFO ]   map 61% reduce 0%
2020-11-19 22:51:07  [ LocalJobRunner Map Task Executor #0:29406 ] - [ INFO ]  map > map
2020-11-19 22:51:07  [ LocalJobRunner Map Task Executor #0:29409 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:51:07  [ LocalJobRunner Map Task Executor #0:29409 ] - [ INFO ]  Spilling map output
2020-11-19 22:51:07  [ LocalJobRunner Map Task Executor #0:29409 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-19 22:51:07  [ LocalJobRunner Map Task Executor #0:29409 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-19 22:51:09  [ LocalJobRunner Map Task Executor #0:31015 ] - [ INFO ]  Finished spill 0
2020-11-19 22:51:09  [ LocalJobRunner Map Task Executor #0:31018 ] - [ INFO ]  Task:attempt_local2128072257_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 22:51:09  [ LocalJobRunner Map Task Executor #0:31047 ] - [ INFO ]  map
2020-11-19 22:51:09  [ LocalJobRunner Map Task Executor #0:31048 ] - [ INFO ]  Task 'attempt_local2128072257_0001_m_000000_0' done.
2020-11-19 22:51:09  [ LocalJobRunner Map Task Executor #0:31048 ] - [ INFO ]  Finishing task: attempt_local2128072257_0001_m_000000_0
2020-11-19 22:51:09  [ Thread-18:31048 ] - [ INFO ]  map task executor complete.
2020-11-19 22:51:09  [ Thread-18:31051 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 22:51:09  [ pool-6-thread-1:31051 ] - [ INFO ]  Starting task: attempt_local2128072257_0001_r_000000_0
2020-11-19 22:51:09  [ pool-6-thread-1:31057 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:51:09  [ pool-6-thread-1:31057 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:51:09  [ pool-6-thread-1:31058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:51:09  [ pool-6-thread-1:31061 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@130f11d8
2020-11-19 22:51:09  [ main:31114 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 22:51:09  [ pool-6-thread-1:31293 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 22:51:09  [ EventFetcher for fetching Map Completion Events:31295 ] - [ INFO ]  attempt_local2128072257_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 22:51:09  [ localfetcher#1:31326 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2128072257_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-19 22:51:09  [ localfetcher#1:31353 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local2128072257_0001_m_000000_0
2020-11-19 22:51:09  [ localfetcher#1:31354 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-19 22:51:09  [ EventFetcher for fetching Map Completion Events:31355 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 22:51:09  [ pool-6-thread-1:31356 ] - [ INFO ]  1 / 1 copied.
2020-11-19 22:51:09  [ pool-6-thread-1:31356 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 22:51:09  [ pool-6-thread-1:31362 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 22:51:09  [ pool-6-thread-1:31362 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 22:51:09  [ pool-6-thread-1:31403 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-19 22:51:09  [ pool-6-thread-1:31403 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-19 22:51:09  [ pool-6-thread-1:31403 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 22:51:09  [ pool-6-thread-1:31404 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 22:51:09  [ pool-6-thread-1:31404 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-19 22:51:09  [ pool-6-thread-1:31404 ] - [ INFO ]  1 / 1 copied.
2020-11-19 22:51:09  [ pool-6-thread-1:31434 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 22:51:15  [ communication thread:37063 ] - [ INFO ]  reduce > reduce
2020-11-19 22:51:15  [ main:37128 ] - [ INFO ]   map 100% reduce 93%
2020-11-19 22:51:18  [ communication thread:40068 ] - [ INFO ]  reduce > reduce
2020-11-19 22:51:18  [ main:40132 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 22:51:19  [ pool-6-thread-1:41239 ] - [ INFO ]  Task:attempt_local2128072257_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 22:51:19  [ pool-6-thread-1:41248 ] - [ INFO ]  reduce > reduce
2020-11-19 22:51:19  [ pool-6-thread-1:41248 ] - [ INFO ]  Task attempt_local2128072257_0001_r_000000_0 is allowed to commit now
2020-11-19 22:51:19  [ pool-6-thread-1:41281 ] - [ INFO ]  Saved output of task 'attempt_local2128072257_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local2128072257_0001_r_000000
2020-11-19 22:51:19  [ pool-6-thread-1:41282 ] - [ INFO ]  reduce > reduce
2020-11-19 22:51:19  [ pool-6-thread-1:41282 ] - [ INFO ]  Task 'attempt_local2128072257_0001_r_000000_0' done.
2020-11-19 22:51:19  [ pool-6-thread-1:41282 ] - [ INFO ]  Finishing task: attempt_local2128072257_0001_r_000000_0
2020-11-19 22:51:19  [ Thread-18:41282 ] - [ INFO ]  reduce task executor complete.
2020-11-19 22:51:20  [ main:42140 ] - [ INFO ]  Job job_local2128072257_0001 completed successfully
2020-11-19 22:51:20  [ main:42151 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61498356
		FILE: Number of bytes written=92817148
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=30743224
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=30748996
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=962068480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=30743224
2020-11-19 22:52:04  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:52:04  [ main:729 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 22:52:04  [ main:729 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 22:52:05  [ main:904 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:52:05  [ main:909 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:52:05  [ main:933 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:52:05  [ main:990 ] - [ INFO ]  number of splits:1
2020-11-19 22:52:05  [ main:1048 ] - [ INFO ]  Submitting tokens for job: job_local1222972354_0001
2020-11-19 22:52:05  [ main:1130 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:52:05  [ main:1131 ] - [ INFO ]  Running job: job_local1222972354_0001
2020-11-19 22:52:05  [ Thread-18:1131 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:52:05  [ Thread-18:1134 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:05  [ Thread-18:1135 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:52:05  [ Thread-18:1170 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1170 ] - [ INFO ]  Starting task: attempt_local1222972354_0001_m_000000_0
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1184 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1188 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1188 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1190 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1250 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1251 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1251 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1251 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1251 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1253 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:52:05  [ LocalJobRunner Map Task Executor #0:1268 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:52:05  [ Thread-18:1275 ] - [ INFO ]  map task executor complete.
2020-11-19 22:52:05  [ Thread-18:1287 ] - [ WARN ]  job_local1222972354_0001
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:52:06  [ main:2136 ] - [ INFO ]  Job job_local1222972354_0001 running in uber mode : false
2020-11-19 22:52:06  [ main:2138 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:52:06  [ main:2140 ] - [ INFO ]  Job job_local1222972354_0001 failed with state FAILED due to: NA
2020-11-19 22:52:06  [ main:2144 ] - [ INFO ]  Counters: 0
2020-11-19 22:52:06  [ main:2244 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:52:06  [ main:2258 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:52:06  [ main:2262 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:52:06  [ main:2280 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:52:06  [ main:2323 ] - [ INFO ]  number of splits:1
2020-11-19 22:52:06  [ main:2341 ] - [ INFO ]  Submitting tokens for job: job_local890655221_0002
2020-11-19 22:52:06  [ main:2385 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:52:06  [ main:2385 ] - [ INFO ]  Running job: job_local890655221_0002
2020-11-19 22:52:06  [ Thread-38:2385 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:52:06  [ Thread-38:2386 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:06  [ Thread-38:2386 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:52:06  [ Thread-38:2401 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2401 ] - [ INFO ]  Starting task: attempt_local890655221_0002_m_000000_0
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2402 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2402 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2402 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2403 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2450 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2450 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2450 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2450 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2450 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2451 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:52:06  [ LocalJobRunner Map Task Executor #0:2461 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:52:06  [ Thread-38:2463 ] - [ INFO ]  map task executor complete.
2020-11-19 22:52:06  [ Thread-38:2476 ] - [ WARN ]  job_local890655221_0002
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:52:07  [ main:3386 ] - [ INFO ]  Job job_local890655221_0002 running in uber mode : false
2020-11-19 22:52:07  [ main:3386 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:52:07  [ main:3386 ] - [ INFO ]  Job job_local890655221_0002 failed with state FAILED due to: NA
2020-11-19 22:52:07  [ main:3387 ] - [ INFO ]  Counters: 0
2020-11-19 22:52:07  [ main:3468 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:52:07  [ main:3482 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:52:07  [ main:3485 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:52:07  [ main:3496 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:52:07  [ main:3535 ] - [ INFO ]  number of splits:1
2020-11-19 22:52:07  [ main:3554 ] - [ INFO ]  Submitting tokens for job: job_local2139237293_0003
2020-11-19 22:52:07  [ main:3595 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:52:07  [ main:3595 ] - [ INFO ]  Running job: job_local2139237293_0003
2020-11-19 22:52:07  [ Thread-57:3595 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:52:07  [ Thread-57:3595 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:07  [ Thread-57:3596 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:52:07  [ Thread-57:3608 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3608 ] - [ INFO ]  Starting task: attempt_local2139237293_0003_m_000000_0
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3609 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3609 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3609 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3610 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3651 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3651 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3651 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3651 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3651 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3652 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:52:07  [ LocalJobRunner Map Task Executor #0:3672 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:52:07  [ Thread-57:3673 ] - [ INFO ]  map task executor complete.
2020-11-19 22:52:07  [ Thread-57:3684 ] - [ WARN ]  job_local2139237293_0003
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:52:08  [ main:4597 ] - [ INFO ]  Job job_local2139237293_0003 running in uber mode : false
2020-11-19 22:52:08  [ main:4598 ] - [ INFO ]   map 0% reduce 0%
2020-11-19 22:52:08  [ main:4598 ] - [ INFO ]  Job job_local2139237293_0003 failed with state FAILED due to: NA
2020-11-19 22:52:08  [ main:4598 ] - [ INFO ]  Counters: 0
2020-11-19 22:52:08  [ main:4691 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 22:52:08  [ main:4710 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 22:52:08  [ main:4715 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 22:52:08  [ main:4725 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 22:52:08  [ main:4771 ] - [ INFO ]  number of splits:1
2020-11-19 22:52:08  [ main:4792 ] - [ INFO ]  Submitting tokens for job: job_local1025176941_0004
2020-11-19 22:52:08  [ main:4844 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 22:52:08  [ Thread-76:4844 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 22:52:08  [ main:4844 ] - [ INFO ]  Running job: job_local1025176941_0004
2020-11-19 22:52:08  [ Thread-76:4844 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:08  [ Thread-76:4845 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 22:52:08  [ Thread-76:4858 ] - [ INFO ]  Waiting for map tasks
2020-11-19 22:52:08  [ LocalJobRunner Map Task Executor #0:4858 ] - [ INFO ]  Starting task: attempt_local1025176941_0004_m_000000_0
2020-11-19 22:52:08  [ LocalJobRunner Map Task Executor #0:4859 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 22:52:08  [ LocalJobRunner Map Task Executor #0:4859 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 22:52:08  [ LocalJobRunner Map Task Executor #0:4859 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 22:52:08  [ LocalJobRunner Map Task Executor #0:4860 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+30743224
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4875 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4875 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4875 ] - [ INFO ]  soft limit at 83886080
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4875 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4875 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4876 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 22:52:09  [ LocalJobRunner Map Task Executor #0:4889 ] - [ INFO ]  Starting flush of map output
2020-11-19 22:52:09  [ Thread-76:4893 ] - [ INFO ]  map task executor complete.
2020-11-19 22:52:09  [ Thread-76:4904 ] - [ WARN ]  job_local1025176941_0004
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.satan.hadoop.utils.CFUtil.initMap(CFUtil.java:90)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:51)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-19 22:52:21  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:52:52  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:54:48  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:54:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:55:34  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:56:59  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 22:59:49  [ main:1 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
