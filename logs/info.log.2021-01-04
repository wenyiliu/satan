2021-01-04 17:04:02  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:04:02  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:04:02  [ main:52 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:04:02  [ main:323 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:04:03  [ main:503 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:04:03  [ main:570 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:04:03  [ main:571 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:04:03  [ main:571 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:04:03  [ main:572 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:04:03  [ main:572 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:04:03  [ main:1018 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54289.
2021-01-04 17:04:03  [ main:1044 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:04:03  [ main:1060 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:04:03  [ main:1063 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:04:03  [ main:1063 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:04:03  [ main:1103 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-b7386c92-d566-4c4d-828e-867cd8623cbf
2021-01-04 17:04:03  [ main:1146 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:04:03  [ main:1159 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:04:03  [ main:1228 ] - [ INFO ]  Logging initialized @1795ms
2021-01-04 17:04:03  [ main:1288 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:04:03  [ main:1305 ] - [ INFO ]  Started @1873ms
2021-01-04 17:04:03  [ main:1330 ] - [ INFO ]  Started ServerConnector@26ccf937{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:04:03  [ main:1331 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:04:03  [ main:1393 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6ffab045{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1394 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60d8c0dc{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1395 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1398 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4602c2a9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1398 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1399 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1400 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1402 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@69c79f09{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1403 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1404 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1405 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1406 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1407 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1410 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1411 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1411 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1412 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1413 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1414 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:04:03  [ main:1415 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:1425 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/static,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:1426 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@46e8a539{/,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:1427 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/api,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:1428 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@66629f63{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:1428 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:1432 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:04:04  [ main:1554 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:04:04  [ main:1623 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54290.
2021-01-04 17:04:04  [ main:1624 ] - [ INFO ]  Server created on 192.168.3.166:54290
2021-01-04 17:04:04  [ main:1625 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:04:04  [ main:1649 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54290, None)
2021-01-04 17:04:04  [ dispatcher-event-loop-10:1652 ] - [ INFO ]  Registering block manager 192.168.3.166:54290 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54290, None)
2021-01-04 17:04:04  [ main:1653 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54290, None)
2021-01-04 17:04:04  [ main:1653 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54290, None)
2021-01-04 17:04:04  [ main:1864 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@107e5441{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:04:04  [ main:2368 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:04:05  [ main:2621 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:04:05  [ dispatcher-event-loop-12:2624 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54290 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:04:05  [ main:2626 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:04:05  [ main:2711 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:04:05  [ main:2722 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:22
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2735 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:22) with 2 output partitions
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2735 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at AvgSparkCore.scala:22)
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2735 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2736 ] - [ INFO ]  Missing parents: List()
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2740 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:21), which has no missing parents
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2807 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 2004.4 MB)
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2809 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 2004.4 MB)
2021-01-04 17:04:05  [ dispatcher-event-loop-13:2810 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54290 (size: 2.2 KB, free: 2004.6 MB)
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2810 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2821 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:21) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2822 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:04:05  [ dispatcher-event-loop-14:2854 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7929 bytes)
2021-01-04 17:04:05  [ dispatcher-event-loop-14:2855 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7929 bytes)
2021-01-04 17:04:05  [ Executor task launch worker for task 1:2863 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:04:05  [ Executor task launch worker for task 0:2863 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:04:05  [ Executor task launch worker for task 1:2904 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:04:05  [ Executor task launch worker for task 0:2904 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:04:05  [ Executor task launch worker for task 1:2932 ] - [ ERROR ]  Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:101)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:19)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 17:04:05  [ Executor task launch worker for task 0:2932 ] - [ ERROR ]  Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:101)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:19)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 17:04:05  [ task-result-getter-0:2958 ] - [ WARN ]  Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:101)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:19)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2021-01-04 17:04:05  [ task-result-getter-0:2960 ] - [ ERROR ]  Task 1 in stage 0.0 failed 1 times; aborting job
2021-01-04 17:04:05  [ task-result-getter-0:2962 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:04:05  [ task-result-getter-1:2962 ] - [ INFO ]  Lost task 0.0 in stage 0.0 (TID 0) on localhost, executor driver: java.lang.ClassCastException (java.lang.String cannot be cast to java.lang.Integer) [duplicate 1]
2021-01-04 17:04:05  [ task-result-getter-1:2962 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2965 ] - [ INFO ]  Cancelling stage 0
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2966 ] - [ INFO ]  Killing all running tasks in stage 0: Stage cancelled
2021-01-04 17:04:05  [ dag-scheduler-event-loop:2967 ] - [ INFO ]  ResultStage 0 (foreach at AvgSparkCore.scala:22) failed in 0.212 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:101)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:19)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2021-01-04 17:04:05  [ main:2972 ] - [ INFO ]  Job 0 failed: foreach at AvgSparkCore.scala:22, took 0.249974 s
2021-01-04 17:04:05  [ Thread-1:2975 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:04:05  [ Thread-1:2985 ] - [ INFO ]  Stopped Spark@26ccf937{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:04:05  [ Thread-1:2987 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:04:05  [ dispatcher-event-loop-5:2993 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:04:05  [ Thread-1:3006 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:04:05  [ Thread-1:3006 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:04:05  [ Thread-1:3009 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:04:05  [ dispatcher-event-loop-10:3011 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:04:05  [ Thread-1:3019 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:04:05  [ Thread-1:3020 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:04:05  [ Thread-1:3020 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-8fcd20b1-d5ba-41e0-889b-8eda01e0ad9f
2021-01-04 17:06:19  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:06:19  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:06:19  [ main:36 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:06:20  [ main:264 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:06:20  [ main:385 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:06:20  [ main:421 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:06:20  [ main:422 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:06:20  [ main:422 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:06:20  [ main:422 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:06:20  [ main:422 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:06:20  [ main:678 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54533.
2021-01-04 17:06:20  [ main:693 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:06:20  [ main:707 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:06:20  [ main:709 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:06:20  [ main:709 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:06:20  [ main:748 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-d3be5bf2-0cb7-4923-8325-ab88253cd6bc
2021-01-04 17:06:20  [ main:764 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:06:20  [ main:774 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:06:20  [ main:838 ] - [ INFO ]  Logging initialized @1661ms
2021-01-04 17:06:20  [ main:880 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:06:20  [ main:891 ] - [ INFO ]  Started @1714ms
2021-01-04 17:06:20  [ main:903 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:06:20  [ main:903 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:06:20  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:940 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:940 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:941 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:941 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:06:20  [ main:944 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:06:20  [ main:1003 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:06:20  [ main:1060 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54534.
2021-01-04 17:06:20  [ main:1061 ] - [ INFO ]  Server created on 192.168.3.166:54534
2021-01-04 17:06:20  [ main:1062 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:06:20  [ main:1079 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54534, None)
2021-01-04 17:06:20  [ dispatcher-event-loop-10:1081 ] - [ INFO ]  Registering block manager 192.168.3.166:54534 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54534, None)
2021-01-04 17:06:20  [ main:1083 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54534, None)
2021-01-04 17:06:20  [ main:1084 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54534, None)
2021-01-04 17:06:20  [ main:1213 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:06:21  [ main:1475 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:06:21  [ main:1629 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:06:21  [ dispatcher-event-loop-12:1631 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54534 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:06:21  [ main:1633 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:06:21  [ main:1692 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:06:21  [ main:1701 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:22
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1712 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:22) with 2 output partitions
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1712 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at AvgSparkCore.scala:22)
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1713 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1713 ] - [ INFO ]  Missing parents: List()
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1716 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:21), which has no missing parents
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1782 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 2004.4 MB)
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1784 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 2004.4 MB)
2021-01-04 17:06:21  [ dispatcher-event-loop-13:1784 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54534 (size: 2.2 KB, free: 2004.6 MB)
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1785 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1795 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:21) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1796 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:06:21  [ dispatcher-event-loop-14:1820 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7929 bytes)
2021-01-04 17:06:21  [ dispatcher-event-loop-14:1822 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7929 bytes)
2021-01-04 17:06:21  [ Executor task launch worker for task 0:1829 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:06:21  [ Executor task launch worker for task 1:1829 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:06:21  [ Executor task launch worker for task 0:1865 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:06:21  [ Executor task launch worker for task 1:1865 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:06:21  [ Executor task launch worker for task 1:1890 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 794 bytes result sent to driver
2021-01-04 17:06:21  [ Executor task launch worker for task 0:1890 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 794 bytes result sent to driver
2021-01-04 17:06:21  [ task-result-getter-1:1896 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 82 ms on localhost (executor driver) (1/2)
2021-01-04 17:06:21  [ task-result-getter-0:1898 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 77 ms on localhost (executor driver) (2/2)
2021-01-04 17:06:21  [ task-result-getter-0:1899 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:06:21  [ dag-scheduler-event-loop:1903 ] - [ INFO ]  ResultStage 0 (foreach at AvgSparkCore.scala:22) finished in 0.171 s
2021-01-04 17:06:21  [ main:1907 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:22, took 0.205591 s
2021-01-04 17:06:21  [ Thread-1:1909 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:06:21  [ Thread-1:1919 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:06:21  [ Thread-1:1920 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:06:21  [ dispatcher-event-loop-5:1926 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:06:21  [ Thread-1:1936 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:06:21  [ Thread-1:1937 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:06:21  [ Thread-1:1940 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:06:21  [ dispatcher-event-loop-10:1941 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:06:21  [ Thread-1:1948 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:06:21  [ Thread-1:1948 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:06:21  [ Thread-1:1949 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-7aea1802-c6a9-42b6-ac02-9b9de7a4a51a
2021-01-04 17:11:00  [ main:1 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:11:00  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:11:00  [ main:34 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:11:00  [ main:364 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:11:00  [ main:579 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:11:01  [ main:647 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:11:01  [ main:648 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:11:01  [ main:648 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:11:01  [ main:649 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:11:01  [ main:650 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:11:01  [ main:933 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54665.
2021-01-04 17:11:01  [ main:949 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:11:01  [ main:961 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:11:01  [ main:963 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:11:01  [ main:963 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:11:01  [ main:999 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-48a79c4e-9d95-46aa-9f3b-4fcedfcfb2aa
2021-01-04 17:11:01  [ main:1014 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:11:01  [ main:1025 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:11:01  [ main:1105 ] - [ INFO ]  Logging initialized @1722ms
2021-01-04 17:11:01  [ main:1166 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:11:01  [ main:1178 ] - [ INFO ]  Started @1797ms
2021-01-04 17:11:01  [ main:1191 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:11:01  [ main:1191 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:11:01  [ main:1210 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1211 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1212 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1212 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1213 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1213 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1214 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1215 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1216 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1216 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1217 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1218 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1218 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1219 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1220 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1221 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1222 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1223 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1223 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1224 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1229 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1230 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1231 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1231 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1232 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:11:01  [ main:1233 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:11:01  [ main:1295 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:11:01  [ main:1347 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54666.
2021-01-04 17:11:01  [ main:1348 ] - [ INFO ]  Server created on 192.168.3.166:54666
2021-01-04 17:11:01  [ main:1349 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:11:01  [ main:1366 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54666, None)
2021-01-04 17:11:01  [ dispatcher-event-loop-10:1369 ] - [ INFO ]  Registering block manager 192.168.3.166:54666 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54666, None)
2021-01-04 17:11:01  [ main:1370 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54666, None)
2021-01-04 17:11:01  [ main:1371 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54666, None)
2021-01-04 17:11:01  [ main:1488 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:11:02  [ main:1804 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:11:02  [ main:1955 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:11:02  [ dispatcher-event-loop-12:1956 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54666 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:11:02  [ main:1958 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:11:02  [ main:2012 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:11:02  [ main:2053 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:19
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2065 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2068 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:19) with 2 output partitions
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2069 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:19)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2069 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2070 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2073 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2120 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2121 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:11:02  [ dispatcher-event-loop-13:2122 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54666 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2122 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2132 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2132 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:11:02  [ dispatcher-event-loop-14:2156 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:11:02  [ dispatcher-event-loop-14:2158 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:11:02  [ Executor task launch worker for task 0:2164 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:11:02  [ Executor task launch worker for task 1:2164 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:11:02  [ Executor task launch worker for task 1:2198 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:11:02  [ Executor task launch worker for task 0:2198 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:11:02  [ Executor task launch worker for task 0:2411 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:11:02  [ Executor task launch worker for task 1:2411 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:11:02  [ task-result-getter-0:2415 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 266 ms on localhost (executor driver) (1/2)
2021-01-04 17:11:02  [ task-result-getter-1:2417 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 260 ms on localhost (executor driver) (2/2)
2021-01-04 17:11:02  [ task-result-getter-1:2417 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2421 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.309 s
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2421 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2422 ] - [ INFO ]  running: Set()
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2422 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2422 ] - [ INFO ]  failed: Set()
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2423 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[4] at groupByKey at AvgSparkCore.scala:18), which has no missing parents
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2430 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.7 KB, free 2004.4 MB)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2431 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 2004.4 MB)
2021-01-04 17:11:02  [ dispatcher-event-loop-3:2432 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54666 (size: 3.5 KB, free: 2004.6 MB)
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2432 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2433 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[4] at groupByKey at AvgSparkCore.scala:18) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2433 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:11:02  [ dispatcher-event-loop-4:2436 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:11:02  [ dispatcher-event-loop-4:2437 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:11:02  [ Executor task launch worker for task 2:2437 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:11:02  [ Executor task launch worker for task 3:2437 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:11:02  [ Executor task launch worker for task 3:2449 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:11:02  [ Executor task launch worker for task 2:2449 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:11:02  [ Executor task launch worker for task 3:2450 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:11:02  [ Executor task launch worker for task 2:2450 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:11:02  [ Executor task launch worker for task 2:2486 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:11:02  [ Executor task launch worker for task 3:2486 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:11:02  [ task-result-getter-2:2487 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 52 ms on localhost (executor driver) (1/2)
2021-01-04 17:11:02  [ task-result-getter-3:2487 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (executor driver) (2/2)
2021-01-04 17:11:02  [ task-result-getter-3:2487 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:11:02  [ dag-scheduler-event-loop:2488 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:19) finished in 0.061 s
2021-01-04 17:11:02  [ main:2491 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:19, took 0.437934 s
2021-01-04 17:11:02  [ Thread-1:2494 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:11:02  [ Thread-1:2499 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:11:02  [ Thread-1:2500 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:11:02  [ dispatcher-event-loop-11:2505 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:11:02  [ Thread-1:2514 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:11:02  [ Thread-1:2515 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:11:02  [ Thread-1:2517 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:11:02  [ dispatcher-event-loop-15:2519 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:11:02  [ Thread-1:2525 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:11:02  [ Thread-1:2525 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:11:02  [ Thread-1:2526 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-1f47e925-dca6-491a-ae4e-1072ff593242
2021-01-04 17:14:22  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:14:22  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:14:22  [ main:33 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:14:22  [ main:262 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:14:22  [ main:384 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:14:22  [ main:426 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:14:22  [ main:426 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:14:22  [ main:426 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:14:22  [ main:427 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:14:22  [ main:427 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:14:22  [ main:681 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54756.
2021-01-04 17:14:22  [ main:695 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:14:22  [ main:706 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:14:22  [ main:708 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:14:22  [ main:708 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:14:22  [ main:745 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-a16947e4-41f4-4af6-a3ab-2f5cd60d37b9
2021-01-04 17:14:22  [ main:759 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:14:22  [ main:769 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:14:22  [ main:824 ] - [ INFO ]  Logging initialized @1363ms
2021-01-04 17:14:23  [ main:867 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:14:23  [ main:881 ] - [ INFO ]  Started @1422ms
2021-01-04 17:14:23  [ main:896 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:14:23  [ main:896 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:14:23  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:940 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:940 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:941 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:944 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:14:23  [ main:1008 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:14:23  [ main:1066 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54757.
2021-01-04 17:14:23  [ main:1067 ] - [ INFO ]  Server created on 192.168.3.166:54757
2021-01-04 17:14:23  [ main:1068 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:14:23  [ main:1091 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54757, None)
2021-01-04 17:14:23  [ dispatcher-event-loop-10:1095 ] - [ INFO ]  Registering block manager 192.168.3.166:54757 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54757, None)
2021-01-04 17:14:23  [ main:1097 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54757, None)
2021-01-04 17:14:23  [ main:1097 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54757, None)
2021-01-04 17:14:23  [ main:1240 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:14:23  [ main:1568 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:14:23  [ main:1715 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:14:23  [ dispatcher-event-loop-12:1717 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54757 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:14:23  [ main:1718 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:14:23  [ main:1776 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:14:23  [ main:1816 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:18
2021-01-04 17:14:23  [ dag-scheduler-event-loop:1828 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:14:23  [ dag-scheduler-event-loop:1830 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:18) with 2 output partitions
2021-01-04 17:14:23  [ dag-scheduler-event-loop:1830 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:18)
2021-01-04 17:14:23  [ dag-scheduler-event-loop:1830 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:14:23  [ dag-scheduler-event-loop:1832 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:14:23  [ dag-scheduler-event-loop:1834 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:14:24  [ dag-scheduler-event-loop:1886 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:14:24  [ dag-scheduler-event-loop:1887 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:14:24  [ dispatcher-event-loop-13:1888 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54757 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:14:24  [ dag-scheduler-event-loop:1888 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:14:24  [ dag-scheduler-event-loop:1899 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:14:24  [ dag-scheduler-event-loop:1900 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:14:24  [ dispatcher-event-loop-14:1926 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:14:24  [ dispatcher-event-loop-14:1927 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:14:24  [ Executor task launch worker for task 0:1933 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:14:24  [ Executor task launch worker for task 1:1933 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:14:24  [ Executor task launch worker for task 1:1969 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:14:24  [ Executor task launch worker for task 0:1969 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:14:24  [ Executor task launch worker for task 0:2152 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:14:24  [ Executor task launch worker for task 1:2152 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:14:24  [ task-result-getter-1:2156 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 229 ms on localhost (executor driver) (1/2)
2021-01-04 17:14:24  [ task-result-getter-0:2157 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 239 ms on localhost (executor driver) (2/2)
2021-01-04 17:14:24  [ task-result-getter-0:2158 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.286 s
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  running: Set()
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2164 ] - [ INFO ]  failed: Set()
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2165 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[4] at groupByKey at AvgSparkCore.scala:18), which has no missing parents
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2172 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.7 KB, free 2004.4 MB)
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2173 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 2004.4 MB)
2021-01-04 17:14:24  [ dispatcher-event-loop-3:2174 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54757 (size: 3.5 KB, free: 2004.6 MB)
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2174 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2176 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[4] at groupByKey at AvgSparkCore.scala:18) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2176 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:14:24  [ dispatcher-event-loop-4:2179 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:14:24  [ dispatcher-event-loop-4:2179 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:14:24  [ Executor task launch worker for task 2:2179 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:14:24  [ Executor task launch worker for task 3:2179 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:14:24  [ Executor task launch worker for task 3:2192 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:14:24  [ Executor task launch worker for task 2:2192 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:14:24  [ Executor task launch worker for task 3:2193 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:14:24  [ Executor task launch worker for task 2:2193 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:14:24  [ Executor task launch worker for task 3:2228 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1181 bytes result sent to driver
2021-01-04 17:14:24  [ Executor task launch worker for task 2:2228 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:14:24  [ task-result-getter-2:2230 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (executor driver) (1/2)
2021-01-04 17:14:24  [ task-result-getter-3:2230 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 53 ms on localhost (executor driver) (2/2)
2021-01-04 17:14:24  [ task-result-getter-3:2230 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:14:24  [ dag-scheduler-event-loop:2232 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:18) finished in 0.064 s
2021-01-04 17:14:24  [ main:2235 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:18, took 0.419154 s
2021-01-04 17:14:24  [ Thread-1:2238 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:14:24  [ Thread-1:2244 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:14:24  [ Thread-1:2245 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:14:24  [ dispatcher-event-loop-11:2250 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:14:24  [ Thread-1:2260 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:14:24  [ Thread-1:2260 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:14:24  [ Thread-1:2263 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:14:24  [ dispatcher-event-loop-15:2264 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:14:24  [ Thread-1:2271 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:14:24  [ Thread-1:2271 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:14:24  [ Thread-1:2272 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-f1a3c996-e511-4963-8372-5d6191b1b570
2021-01-04 17:19:09  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:19:09  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:19:09  [ main:36 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:19:09  [ main:249 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:19:09  [ main:371 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:19:09  [ main:412 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:19:09  [ main:412 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:19:09  [ main:413 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:19:09  [ main:413 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:19:09  [ main:413 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:19:09  [ main:635 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54872.
2021-01-04 17:19:09  [ main:650 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:19:09  [ main:660 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:19:09  [ main:662 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:19:09  [ main:662 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:19:09  [ main:694 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-d8efc21e-b848-402b-8508-d0661dc23b56
2021-01-04 17:19:09  [ main:707 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:19:09  [ main:717 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:19:09  [ main:775 ] - [ INFO ]  Logging initialized @1530ms
2021-01-04 17:19:10  [ main:817 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:19:10  [ main:828 ] - [ INFO ]  Started @1585ms
2021-01-04 17:19:10  [ main:839 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:19:10  [ main:839 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:19:10  [ main:861 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:862 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:863 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:863 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:864 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:865 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:865 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:867 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:867 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:868 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:868 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:869 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:870 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:871 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:871 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:872 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:873 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:873 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:874 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:875 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:880 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:880 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:881 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:882 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:883 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:884 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:19:10  [ main:965 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:19:10  [ main:1026 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54873.
2021-01-04 17:19:10  [ main:1027 ] - [ INFO ]  Server created on 192.168.3.166:54873
2021-01-04 17:19:10  [ main:1028 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:19:10  [ main:1045 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54873, None)
2021-01-04 17:19:10  [ dispatcher-event-loop-10:1047 ] - [ INFO ]  Registering block manager 192.168.3.166:54873 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54873, None)
2021-01-04 17:19:10  [ main:1049 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54873, None)
2021-01-04 17:19:10  [ main:1049 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54873, None)
2021-01-04 17:19:10  [ main:1165 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:10  [ main:1504 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:19:10  [ main:1708 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:19:10  [ dispatcher-event-loop-12:1710 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54873 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:19:10  [ main:1712 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:19:10  [ main:1770 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:19:11  [ main:1814 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1829 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1831 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1831 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1831 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1833 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1836 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1886 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1888 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:19:11  [ dispatcher-event-loop-13:1888 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54873 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1889 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1902 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:19:11  [ dag-scheduler-event-loop:1903 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:19:11  [ dispatcher-event-loop-14:1932 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:19:11  [ dispatcher-event-loop-14:1934 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:19:11  [ Executor task launch worker for task 0:1941 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:19:11  [ Executor task launch worker for task 1:1941 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:19:11  [ Executor task launch worker for task 1:1980 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:19:11  [ Executor task launch worker for task 0:1980 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:19:11  [ Executor task launch worker for task 1:2175 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:19:11  [ Executor task launch worker for task 0:2175 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:19:11  [ task-result-getter-1:2180 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 256 ms on localhost (executor driver) (1/2)
2021-01-04 17:19:11  [ task-result-getter-0:2181 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 248 ms on localhost (executor driver) (2/2)
2021-01-04 17:19:11  [ task-result-getter-0:2182 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2186 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.307 s
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2186 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2186 ] - [ INFO ]  running: Set()
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2187 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2187 ] - [ INFO ]  failed: Set()
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2189 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2196 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2197 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:19:11  [ dispatcher-event-loop-3:2198 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54873 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2198 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2200 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2200 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:19:11  [ dispatcher-event-loop-4:2203 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:19:11  [ dispatcher-event-loop-4:2204 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:19:11  [ Executor task launch worker for task 2:2204 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:19:11  [ Executor task launch worker for task 3:2204 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:19:11  [ Executor task launch worker for task 2:2219 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:19:11  [ Executor task launch worker for task 3:2219 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:19:11  [ Executor task launch worker for task 3:2220 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:19:11  [ Executor task launch worker for task 2:2220 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:19:11  [ Executor task launch worker for task 2:2256 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:19:11  [ Executor task launch worker for task 3:2256 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:19:11  [ task-result-getter-2:2257 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 55 ms on localhost (executor driver) (1/2)
2021-01-04 17:19:11  [ task-result-getter-3:2257 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 54 ms on localhost (executor driver) (2/2)
2021-01-04 17:19:11  [ task-result-getter-3:2257 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:19:11  [ dag-scheduler-event-loop:2258 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.065 s
2021-01-04 17:19:11  [ main:2261 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.447333 s
2021-01-04 17:19:11  [ Thread-1:2264 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:19:11  [ Thread-1:2271 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:19:11  [ Thread-1:2272 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:19:11  [ dispatcher-event-loop-11:2278 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:19:11  [ Thread-1:2288 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:19:11  [ Thread-1:2288 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:19:11  [ Thread-1:2292 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:19:11  [ dispatcher-event-loop-15:2293 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:19:11  [ Thread-1:2300 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:19:11  [ Thread-1:2301 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:19:11  [ Thread-1:2301 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-e3938190-f663-43f0-9ad5-cc4ec58d246b
2021-01-04 17:19:47  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:19:47  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:19:47  [ main:34 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:19:47  [ main:239 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:19:47  [ main:340 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:19:47  [ main:377 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:19:47  [ main:377 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:19:47  [ main:378 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:19:47  [ main:378 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:19:47  [ main:378 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:19:47  [ main:597 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54896.
2021-01-04 17:19:47  [ main:612 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:19:47  [ main:623 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:19:47  [ main:625 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:19:47  [ main:626 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:19:48  [ main:655 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-c81db187-7d44-48b8-880d-dc68e1ff2e5c
2021-01-04 17:19:48  [ main:669 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:19:48  [ main:678 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:19:48  [ main:724 ] - [ INFO ]  Logging initialized @1214ms
2021-01-04 17:19:48  [ main:762 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:19:48  [ main:773 ] - [ INFO ]  Started @1263ms
2021-01-04 17:19:48  [ main:784 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:19:48  [ main:784 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:19:48  [ main:802 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:802 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:803 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:804 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:805 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:805 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:806 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:806 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:807 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:807 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:808 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:808 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:809 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:810 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:810 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:811 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:811 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:812 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:812 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:813 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:818 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:818 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:819 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:819 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:820 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:821 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:19:48  [ main:879 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:19:48  [ main:934 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54897.
2021-01-04 17:19:48  [ main:934 ] - [ INFO ]  Server created on 192.168.3.166:54897
2021-01-04 17:19:48  [ main:935 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:19:48  [ main:953 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54897, None)
2021-01-04 17:19:48  [ dispatcher-event-loop-10:955 ] - [ INFO ]  Registering block manager 192.168.3.166:54897 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54897, None)
2021-01-04 17:19:48  [ main:957 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54897, None)
2021-01-04 17:19:48  [ main:957 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54897, None)
2021-01-04 17:19:48  [ main:1092 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:19:48  [ main:1415 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:19:48  [ main:1557 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:19:48  [ dispatcher-event-loop-12:1559 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54897 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:19:48  [ main:1561 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:19:49  [ main:1628 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:19:49  [ main:1675 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1688 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1689 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1690 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1690 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1691 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1695 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1752 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1754 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:19:49  [ dispatcher-event-loop-13:1755 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54897 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1755 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1765 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:19:49  [ dag-scheduler-event-loop:1766 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:19:49  [ dispatcher-event-loop-14:1791 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:19:49  [ dispatcher-event-loop-14:1793 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:19:49  [ Executor task launch worker for task 1:1798 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:19:49  [ Executor task launch worker for task 0:1799 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:19:49  [ Executor task launch worker for task 1:1839 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:19:49  [ Executor task launch worker for task 0:1839 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:19:49  [ Executor task launch worker for task 0:2037 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:19:49  [ Executor task launch worker for task 1:2037 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:19:49  [ task-result-getter-1:2043 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 250 ms on localhost (executor driver) (1/2)
2021-01-04 17:19:49  [ task-result-getter-0:2044 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 260 ms on localhost (executor driver) (2/2)
2021-01-04 17:19:49  [ task-result-getter-0:2045 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2050 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.305 s
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2051 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2051 ] - [ INFO ]  running: Set()
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2052 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2052 ] - [ INFO ]  failed: Set()
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2054 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2062 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2064 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:19:49  [ dispatcher-event-loop-3:2065 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54897 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2065 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2067 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2067 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:19:49  [ dispatcher-event-loop-4:2071 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:19:49  [ dispatcher-event-loop-4:2071 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:19:49  [ Executor task launch worker for task 2:2072 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:19:49  [ Executor task launch worker for task 3:2072 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:19:49  [ Executor task launch worker for task 3:2084 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:19:49  [ Executor task launch worker for task 2:2084 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:19:49  [ Executor task launch worker for task 3:2085 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:19:49  [ Executor task launch worker for task 2:2085 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:19:49  [ Executor task launch worker for task 2:2123 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:19:49  [ Executor task launch worker for task 3:2123 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:19:49  [ task-result-getter-2:2125 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 56 ms on localhost (executor driver) (1/2)
2021-01-04 17:19:49  [ task-result-getter-3:2125 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 54 ms on localhost (executor driver) (2/2)
2021-01-04 17:19:49  [ task-result-getter-3:2125 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:19:49  [ dag-scheduler-event-loop:2126 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.068 s
2021-01-04 17:19:49  [ main:2130 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.454759 s
2021-01-04 17:19:49  [ Thread-1:2133 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:19:49  [ Thread-1:2140 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:19:49  [ Thread-1:2142 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:19:49  [ dispatcher-event-loop-11:2147 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:19:49  [ Thread-1:2159 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:19:49  [ Thread-1:2159 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:19:49  [ Thread-1:2162 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:19:49  [ dispatcher-event-loop-15:2164 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:19:49  [ Thread-1:2170 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:19:49  [ Thread-1:2171 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:19:49  [ Thread-1:2171 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-1ecfde03-8cec-4678-be58-da1490b2e3df
2021-01-04 17:20:08  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:20:08  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:20:08  [ main:31 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:20:09  [ main:245 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:20:09  [ main:356 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:20:09  [ main:393 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:20:09  [ main:394 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:20:09  [ main:394 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:20:09  [ main:394 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:20:09  [ main:395 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:20:09  [ main:665 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54915.
2021-01-04 17:20:09  [ main:683 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:20:09  [ main:696 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:20:09  [ main:698 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:20:09  [ main:699 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:20:09  [ main:732 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-7fdef3c7-66c3-46b4-aca9-a364db51ff63
2021-01-04 17:20:09  [ main:746 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:20:09  [ main:755 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:20:09  [ main:807 ] - [ INFO ]  Logging initialized @1332ms
2021-01-04 17:20:09  [ main:849 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:20:09  [ main:860 ] - [ INFO ]  Started @1386ms
2021-01-04 17:20:09  [ main:873 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:20:09  [ main:873 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:20:09  [ main:892 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:893 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:893 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:894 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:895 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:895 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:895 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:896 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:897 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:897 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:898 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:899 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:899 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:900 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:901 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:901 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:902 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:902 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:903 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:903 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:908 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:909 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:20:09  [ main:912 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:20:09  [ main:974 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:20:09  [ main:1040 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54916.
2021-01-04 17:20:09  [ main:1040 ] - [ INFO ]  Server created on 192.168.3.166:54916
2021-01-04 17:20:09  [ main:1042 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:20:09  [ main:1062 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54916, None)
2021-01-04 17:20:09  [ dispatcher-event-loop-10:1064 ] - [ INFO ]  Registering block manager 192.168.3.166:54916 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54916, None)
2021-01-04 17:20:09  [ main:1066 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54916, None)
2021-01-04 17:20:09  [ main:1066 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54916, None)
2021-01-04 17:20:10  [ main:1217 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:10  [ main:1505 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:20:10  [ main:1679 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:20:10  [ dispatcher-event-loop-12:1681 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54916 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:20:10  [ main:1683 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:20:10  [ main:1738 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:20:10  [ main:1778 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1791 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1793 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1794 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1794 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1795 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1798 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1848 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1849 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:20:10  [ dispatcher-event-loop-13:1850 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54916 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1850 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1862 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:20:10  [ dag-scheduler-event-loop:1863 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:20:10  [ dispatcher-event-loop-14:1891 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:20:10  [ dispatcher-event-loop-14:1892 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:20:10  [ Executor task launch worker for task 0:1898 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:20:10  [ Executor task launch worker for task 1:1899 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:20:10  [ Executor task launch worker for task 0:1941 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+28
2021-01-04 17:20:10  [ Executor task launch worker for task 1:1941 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:28+28
2021-01-04 17:20:10  [ Executor task launch worker for task 1:2140 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:20:10  [ Executor task launch worker for task 0:2140 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:20:11  [ task-result-getter-0:2145 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 252 ms on localhost (executor driver) (1/2)
2021-01-04 17:20:11  [ task-result-getter-1:2146 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 263 ms on localhost (executor driver) (2/2)
2021-01-04 17:20:11  [ task-result-getter-1:2147 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2151 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.310 s
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2151 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2152 ] - [ INFO ]  running: Set()
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2152 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2152 ] - [ INFO ]  failed: Set()
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2154 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2161 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:20:11  [ dispatcher-event-loop-3:2163 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54916 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2164 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2165 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2165 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:20:11  [ dispatcher-event-loop-4:2168 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:20:11  [ dispatcher-event-loop-4:2168 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:20:11  [ Executor task launch worker for task 3:2169 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:20:11  [ Executor task launch worker for task 2:2169 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:20:11  [ Executor task launch worker for task 2:2182 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:20:11  [ Executor task launch worker for task 3:2182 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:20:11  [ Executor task launch worker for task 2:2183 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:20:11  [ Executor task launch worker for task 3:2183 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:20:11  [ Executor task launch worker for task 3:2219 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:20:11  [ Executor task launch worker for task 2:2219 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:20:11  [ task-result-getter-3:2220 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 53 ms on localhost (executor driver) (1/2)
2021-01-04 17:20:11  [ task-result-getter-2:2220 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 52 ms on localhost (executor driver) (2/2)
2021-01-04 17:20:11  [ task-result-getter-2:2220 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:20:11  [ dag-scheduler-event-loop:2222 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.064 s
2021-01-04 17:20:11  [ main:2225 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.446434 s
2021-01-04 17:20:11  [ Thread-1:2228 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:20:11  [ Thread-1:2234 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:20:11  [ Thread-1:2235 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:20:11  [ dispatcher-event-loop-11:2240 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:20:11  [ Thread-1:2251 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:20:11  [ Thread-1:2251 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:20:11  [ Thread-1:2255 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:20:11  [ dispatcher-event-loop-15:2256 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:20:11  [ Thread-1:2263 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:20:11  [ Thread-1:2263 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:20:11  [ Thread-1:2264 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-b74da11f-a4c0-46c8-8c07-7a9d0a600809
2021-01-04 17:20:38  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:20:38  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:20:38  [ main:31 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:20:38  [ main:253 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:20:38  [ main:377 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:20:38  [ main:416 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:20:38  [ main:416 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:20:38  [ main:417 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:20:38  [ main:417 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:20:38  [ main:418 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:20:38  [ main:692 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 54943.
2021-01-04 17:20:38  [ main:709 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:20:38  [ main:721 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:20:38  [ main:722 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:20:38  [ main:723 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:20:38  [ main:753 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-b22fb66e-fe04-4f25-b237-d7c9e35f9abd
2021-01-04 17:20:38  [ main:765 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:20:38  [ main:774 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:20:38  [ main:825 ] - [ INFO ]  Logging initialized @1347ms
2021-01-04 17:20:39  [ main:870 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:20:39  [ main:881 ] - [ INFO ]  Started @1405ms
2021-01-04 17:20:39  [ main:894 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:20:39  [ main:894 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:20:39  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:933 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:20:39  [ main:999 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:20:39  [ main:1056 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54944.
2021-01-04 17:20:39  [ main:1056 ] - [ INFO ]  Server created on 192.168.3.166:54944
2021-01-04 17:20:39  [ main:1058 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:20:39  [ main:1075 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 54944, None)
2021-01-04 17:20:39  [ dispatcher-event-loop-10:1078 ] - [ INFO ]  Registering block manager 192.168.3.166:54944 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 54944, None)
2021-01-04 17:20:39  [ main:1080 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 54944, None)
2021-01-04 17:20:39  [ main:1080 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 54944, None)
2021-01-04 17:20:39  [ main:1229 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:20:39  [ main:1539 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:20:39  [ main:1653 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:20:39  [ dispatcher-event-loop-12:1655 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:54944 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:20:39  [ main:1657 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:20:39  [ main:1712 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:20:39  [ main:1754 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1766 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1768 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1768 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1768 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1769 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1773 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1821 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1823 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:20:39  [ dispatcher-event-loop-13:1823 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:54944 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1824 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1834 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:20:39  [ dag-scheduler-event-loop:1835 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:20:40  [ dispatcher-event-loop-14:1861 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:20:40  [ dispatcher-event-loop-14:1862 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:20:40  [ Executor task launch worker for task 0:1868 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:20:40  [ Executor task launch worker for task 1:1869 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:20:40  [ Executor task launch worker for task 1:1905 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:29+29
2021-01-04 17:20:40  [ Executor task launch worker for task 0:1905 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+29
2021-01-04 17:20:40  [ Executor task launch worker for task 0:2093 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:20:40  [ Executor task launch worker for task 1:2093 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:20:40  [ task-result-getter-1:2100 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 237 ms on localhost (executor driver) (1/2)
2021-01-04 17:20:40  [ task-result-getter-0:2102 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 249 ms on localhost (executor driver) (2/2)
2021-01-04 17:20:40  [ task-result-getter-0:2102 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2106 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.292 s
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2107 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2107 ] - [ INFO ]  running: Set()
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2107 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2108 ] - [ INFO ]  failed: Set()
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2109 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2116 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2118 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:20:40  [ dispatcher-event-loop-3:2118 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:54944 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2119 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2120 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2120 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:20:40  [ dispatcher-event-loop-4:2123 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:20:40  [ dispatcher-event-loop-4:2123 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:20:40  [ Executor task launch worker for task 2:2124 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:20:40  [ Executor task launch worker for task 3:2124 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:20:40  [ Executor task launch worker for task 2:2136 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:20:40  [ Executor task launch worker for task 3:2136 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:20:40  [ Executor task launch worker for task 2:2137 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:20:40  [ Executor task launch worker for task 3:2137 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:20:40  [ Executor task launch worker for task 3:2172 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1181 bytes result sent to driver
2021-01-04 17:20:40  [ Executor task launch worker for task 2:2172 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:20:40  [ task-result-getter-2:2173 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (executor driver) (1/2)
2021-01-04 17:20:40  [ task-result-getter-3:2173 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 51 ms on localhost (executor driver) (2/2)
2021-01-04 17:20:40  [ task-result-getter-3:2173 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:20:40  [ dag-scheduler-event-loop:2174 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.061 s
2021-01-04 17:20:40  [ main:2178 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.423771 s
2021-01-04 17:20:40  [ Thread-1:2180 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:20:40  [ Thread-1:2186 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:20:40  [ Thread-1:2188 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:20:40  [ dispatcher-event-loop-11:2193 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:20:40  [ Thread-1:2205 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:20:40  [ Thread-1:2205 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:20:40  [ Thread-1:2209 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:20:40  [ dispatcher-event-loop-15:2210 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:20:40  [ Thread-1:2217 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:20:40  [ Thread-1:2217 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:20:40  [ Thread-1:2218 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-00119246-374b-4acc-b128-a10a978f7515
2021-01-04 17:24:46  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:24:46  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:24:46  [ main:38 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:24:46  [ main:263 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:24:46  [ main:372 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:24:46  [ main:414 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:24:46  [ main:414 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:24:46  [ main:414 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:24:46  [ main:414 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:24:46  [ main:415 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:24:46  [ main:669 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55130.
2021-01-04 17:24:46  [ main:684 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:24:46  [ main:697 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:24:46  [ main:699 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:24:46  [ main:699 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:24:47  [ main:735 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-950f82ff-2abc-4f0b-a03e-e27a9e441f4d
2021-01-04 17:24:47  [ main:752 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:24:47  [ main:765 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:24:47  [ main:828 ] - [ INFO ]  Logging initialized @1620ms
2021-01-04 17:24:47  [ main:868 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:24:47  [ main:879 ] - [ INFO ]  Started @1672ms
2021-01-04 17:24:47  [ main:890 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:24:47  [ main:891 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:24:47  [ main:907 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:908 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:908 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:909 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:926 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:24:47  [ main:979 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:24:47  [ main:1031 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55131.
2021-01-04 17:24:47  [ main:1032 ] - [ INFO ]  Server created on 192.168.3.166:55131
2021-01-04 17:24:47  [ main:1033 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:24:47  [ main:1050 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55131, None)
2021-01-04 17:24:47  [ dispatcher-event-loop-10:1053 ] - [ INFO ]  Registering block manager 192.168.3.166:55131 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55131, None)
2021-01-04 17:24:47  [ main:1055 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55131, None)
2021-01-04 17:24:47  [ main:1055 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55131, None)
2021-01-04 17:24:47  [ main:1205 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:24:47  [ main:1512 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:24:47  [ main:1695 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:24:47  [ dispatcher-event-loop-12:1697 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55131 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:24:47  [ main:1698 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:24:48  [ main:1758 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:24:48  [ main:1799 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1811 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1813 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1813 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1814 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1815 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1818 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1868 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1870 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:24:48  [ dispatcher-event-loop-13:1870 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55131 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1871 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1882 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:24:48  [ dag-scheduler-event-loop:1882 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:24:48  [ dispatcher-event-loop-14:1908 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:24:48  [ dispatcher-event-loop-14:1910 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:24:48  [ Executor task launch worker for task 1:1915 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:24:48  [ Executor task launch worker for task 0:1916 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:24:48  [ Executor task launch worker for task 1:1951 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:32+32
2021-01-04 17:24:48  [ Executor task launch worker for task 0:1951 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+32
2021-01-04 17:24:48  [ Executor task launch worker for task 1:2142 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:24:48  [ Executor task launch worker for task 0:2142 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:24:48  [ task-result-getter-0:2147 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 237 ms on localhost (executor driver) (1/2)
2021-01-04 17:24:48  [ task-result-getter-1:2148 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 248 ms on localhost (executor driver) (2/2)
2021-01-04 17:24:48  [ task-result-getter-1:2149 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2153 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.291 s
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2153 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2153 ] - [ INFO ]  running: Set()
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2154 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2154 ] - [ INFO ]  failed: Set()
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2156 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2162 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2163 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:24:48  [ dispatcher-event-loop-3:2164 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55131 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2165 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2166 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2166 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:24:48  [ dispatcher-event-loop-4:2169 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:24:48  [ dispatcher-event-loop-4:2169 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:24:48  [ Executor task launch worker for task 2:2169 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:24:48  [ Executor task launch worker for task 3:2169 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:24:48  [ Executor task launch worker for task 2:2182 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:24:48  [ Executor task launch worker for task 3:2182 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:24:48  [ Executor task launch worker for task 2:2183 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:24:48  [ Executor task launch worker for task 3:2183 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:24:48  [ Executor task launch worker for task 3:2218 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1181 bytes result sent to driver
2021-01-04 17:24:48  [ Executor task launch worker for task 2:2218 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:24:48  [ task-result-getter-2:2219 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (executor driver) (1/2)
2021-01-04 17:24:48  [ task-result-getter-3:2220 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 52 ms on localhost (executor driver) (2/2)
2021-01-04 17:24:48  [ task-result-getter-3:2220 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:24:48  [ dag-scheduler-event-loop:2220 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.061 s
2021-01-04 17:24:48  [ main:2224 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.424591 s
2021-01-04 17:24:48  [ Thread-1:2227 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:24:48  [ Thread-1:2233 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:24:48  [ Thread-1:2235 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:24:48  [ dispatcher-event-loop-11:2240 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:24:48  [ Thread-1:2250 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:24:48  [ Thread-1:2250 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:24:48  [ Thread-1:2254 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:24:48  [ dispatcher-event-loop-15:2255 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:24:48  [ Thread-1:2262 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:24:48  [ Thread-1:2263 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:24:48  [ Thread-1:2263 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-129b541e-4bfc-4c92-9ce5-26e401ee871a
2021-01-04 17:25:05  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:25:05  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:25:05  [ main:33 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:25:05  [ main:234 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:25:05  [ main:342 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:25:05  [ main:382 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:25:05  [ main:382 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:25:05  [ main:383 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:25:05  [ main:383 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:25:05  [ main:383 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:25:06  [ main:656 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55146.
2021-01-04 17:25:06  [ main:675 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:25:06  [ main:690 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:25:06  [ main:693 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:25:06  [ main:693 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:25:06  [ main:731 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-b59b100b-8bbf-4d5b-b6aa-7dfa700e17fd
2021-01-04 17:25:06  [ main:745 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:25:06  [ main:755 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:25:06  [ main:810 ] - [ INFO ]  Logging initialized @1302ms
2021-01-04 17:25:06  [ main:851 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:25:06  [ main:862 ] - [ INFO ]  Started @1355ms
2021-01-04 17:25:06  [ main:878 ] - [ INFO ]  Started ServerConnector@68cfbe1e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:25:06  [ main:878 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:25:06  [ main:900 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6ffab045{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:901 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60d8c0dc{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:902 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:902 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4602c2a9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:903 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:903 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:904 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:905 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@69c79f09{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:905 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:906 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:907 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:907 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:908 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:909 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:909 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/static,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@46e8a539{/,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/api,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@66629f63{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:923 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:25:06  [ main:981 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:25:06  [ main:1032 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55147.
2021-01-04 17:25:06  [ main:1033 ] - [ INFO ]  Server created on 192.168.3.166:55147
2021-01-04 17:25:06  [ main:1033 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:25:06  [ main:1051 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55147, None)
2021-01-04 17:25:06  [ dispatcher-event-loop-10:1054 ] - [ INFO ]  Registering block manager 192.168.3.166:55147 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55147, None)
2021-01-04 17:25:06  [ main:1056 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55147, None)
2021-01-04 17:25:06  [ main:1057 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55147, None)
2021-01-04 17:25:06  [ main:1201 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@107e5441{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:06  [ main:1445 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:25:06  [ main:1580 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:25:06  [ dispatcher-event-loop-12:1582 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55147 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:25:06  [ main:1585 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:25:07  [ main:1665 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:25:07  [ main:1721 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1735 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1736 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1737 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1737 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1738 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1742 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1794 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1796 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:25:07  [ dispatcher-event-loop-13:1797 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55147 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1797 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1808 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:25:07  [ dag-scheduler-event-loop:1809 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:25:07  [ dispatcher-event-loop-14:1837 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:25:07  [ dispatcher-event-loop-14:1838 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:25:07  [ Executor task launch worker for task 1:1846 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:25:07  [ Executor task launch worker for task 0:1846 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:25:07  [ Executor task launch worker for task 0:1892 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+31
2021-01-04 17:25:07  [ Executor task launch worker for task 1:1892 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:31+32
2021-01-04 17:25:07  [ Executor task launch worker for task 1:2099 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:25:07  [ Executor task launch worker for task 0:2099 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:25:07  [ task-result-getter-0:2105 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 266 ms on localhost (executor driver) (1/2)
2021-01-04 17:25:07  [ task-result-getter-1:2106 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 278 ms on localhost (executor driver) (2/2)
2021-01-04 17:25:07  [ task-result-getter-1:2107 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2111 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.324 s
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2112 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2112 ] - [ INFO ]  running: Set()
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2112 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2113 ] - [ INFO ]  failed: Set()
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2115 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2125 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2126 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:25:07  [ dispatcher-event-loop-3:2127 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55147 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2127 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2129 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2129 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:25:07  [ dispatcher-event-loop-4:2132 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:25:07  [ dispatcher-event-loop-4:2133 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:25:07  [ Executor task launch worker for task 3:2133 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:25:07  [ Executor task launch worker for task 2:2133 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:25:07  [ Executor task launch worker for task 3:2147 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:25:07  [ Executor task launch worker for task 2:2147 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:25:07  [ Executor task launch worker for task 3:2148 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:25:07  [ Executor task launch worker for task 2:2148 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:25:07  [ Executor task launch worker for task 3:2186 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:25:07  [ Executor task launch worker for task 2:2186 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:25:07  [ task-result-getter-2:2187 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (executor driver) (1/2)
2021-01-04 17:25:07  [ task-result-getter-3:2187 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 56 ms on localhost (executor driver) (2/2)
2021-01-04 17:25:07  [ task-result-getter-3:2187 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:25:07  [ dag-scheduler-event-loop:2188 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.068 s
2021-01-04 17:25:07  [ main:2192 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.471599 s
2021-01-04 17:25:07  [ Thread-1:2195 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:25:07  [ Thread-1:2202 ] - [ INFO ]  Stopped Spark@68cfbe1e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:25:07  [ Thread-1:2203 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:25:07  [ dispatcher-event-loop-11:2209 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:25:07  [ Thread-1:2219 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:25:07  [ Thread-1:2219 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:25:07  [ Thread-1:2222 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:25:07  [ dispatcher-event-loop-15:2224 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:25:07  [ Thread-1:2231 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:25:07  [ Thread-1:2231 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:25:07  [ Thread-1:2232 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-b85565ce-6017-4aa3-8281-36de7a1dce68
2021-01-04 17:25:35  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:25:35  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:25:35  [ main:32 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:25:36  [ main:253 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:25:36  [ main:373 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:25:36  [ main:413 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:25:36  [ main:414 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:25:36  [ main:414 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:25:36  [ main:414 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:25:36  [ main:415 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:25:36  [ main:689 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55174.
2021-01-04 17:25:36  [ main:705 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:25:36  [ main:716 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:25:36  [ main:718 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:25:36  [ main:719 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:25:36  [ main:749 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-418fcbcc-897b-4423-8b0e-95565390a8c8
2021-01-04 17:25:36  [ main:761 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:25:36  [ main:771 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:25:36  [ main:824 ] - [ INFO ]  Logging initialized @1351ms
2021-01-04 17:25:36  [ main:865 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:25:36  [ main:876 ] - [ INFO ]  Started @1404ms
2021-01-04 17:25:36  [ main:891 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:25:36  [ main:891 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:25:36  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:25:36  [ main:933 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:25:36  [ main:997 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:25:37  [ main:1052 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55175.
2021-01-04 17:25:37  [ main:1052 ] - [ INFO ]  Server created on 192.168.3.166:55175
2021-01-04 17:25:37  [ main:1053 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:25:37  [ main:1071 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55175, None)
2021-01-04 17:25:37  [ dispatcher-event-loop-10:1073 ] - [ INFO ]  Registering block manager 192.168.3.166:55175 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55175, None)
2021-01-04 17:25:37  [ main:1075 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55175, None)
2021-01-04 17:25:37  [ main:1075 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55175, None)
2021-01-04 17:25:37  [ main:1198 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:25:37  [ main:1481 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:25:37  [ main:1596 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:25:37  [ dispatcher-event-loop-12:1597 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55175 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:25:37  [ main:1599 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:25:37  [ main:1659 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:25:37  [ main:1701 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1714 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1716 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1716 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1716 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1717 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1720 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1769 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1771 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:25:37  [ dispatcher-event-loop-13:1772 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55175 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1772 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1782 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:25:37  [ dag-scheduler-event-loop:1783 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:25:37  [ dispatcher-event-loop-14:1809 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:25:37  [ dispatcher-event-loop-14:1811 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:25:37  [ Executor task launch worker for task 1:1818 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:25:37  [ Executor task launch worker for task 0:1818 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:25:37  [ Executor task launch worker for task 0:1859 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+32
2021-01-04 17:25:37  [ Executor task launch worker for task 1:1859 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:32+32
2021-01-04 17:25:38  [ Executor task launch worker for task 0:2059 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:25:38  [ Executor task launch worker for task 1:2059 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:25:38  [ task-result-getter-0:2065 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 263 ms on localhost (executor driver) (1/2)
2021-01-04 17:25:38  [ task-result-getter-1:2067 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 257 ms on localhost (executor driver) (2/2)
2021-01-04 17:25:38  [ task-result-getter-1:2068 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2073 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.310 s
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2074 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2074 ] - [ INFO ]  running: Set()
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2074 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2075 ] - [ INFO ]  failed: Set()
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2077 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2085 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2086 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:25:38  [ dispatcher-event-loop-3:2087 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55175 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2088 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2089 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2090 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:25:38  [ dispatcher-event-loop-4:2093 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:25:38  [ dispatcher-event-loop-4:2093 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:25:38  [ Executor task launch worker for task 2:2093 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:25:38  [ Executor task launch worker for task 3:2093 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:25:38  [ Executor task launch worker for task 3:2106 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:25:38  [ Executor task launch worker for task 2:2106 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:25:38  [ Executor task launch worker for task 3:2107 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:25:38  [ Executor task launch worker for task 2:2107 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:25:38  [ Executor task launch worker for task 2:2145 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:25:38  [ Executor task launch worker for task 3:2145 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1181 bytes result sent to driver
2021-01-04 17:25:38  [ task-result-getter-2:2148 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 57 ms on localhost (executor driver) (1/2)
2021-01-04 17:25:38  [ task-result-getter-3:2148 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (executor driver) (2/2)
2021-01-04 17:25:38  [ task-result-getter-3:2148 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:25:38  [ dag-scheduler-event-loop:2150 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.070 s
2021-01-04 17:25:38  [ main:2153 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.452086 s
2021-01-04 17:25:38  [ Thread-1:2156 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:25:38  [ Thread-1:2162 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:25:38  [ Thread-1:2163 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:25:38  [ dispatcher-event-loop-11:2169 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:25:38  [ Thread-1:2179 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:25:38  [ Thread-1:2180 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:25:38  [ Thread-1:2183 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:25:38  [ dispatcher-event-loop-15:2184 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:25:38  [ Thread-1:2190 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:25:38  [ Thread-1:2191 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:25:38  [ Thread-1:2192 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-da2c9d64-abb4-4957-8262-09eadf5b93e6
2021-01-04 17:26:06  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:26:06  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:26:06  [ main:33 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:26:07  [ main:256 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:26:07  [ main:379 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:26:07  [ main:420 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:26:07  [ main:420 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:26:07  [ main:421 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:26:07  [ main:421 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:26:07  [ main:421 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:26:07  [ main:704 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55197.
2021-01-04 17:26:07  [ main:720 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:26:07  [ main:731 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:26:07  [ main:732 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:26:07  [ main:733 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:26:07  [ main:764 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-0334a22a-fbc0-4925-a2e0-fb404cdc5d0e
2021-01-04 17:26:07  [ main:777 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:26:07  [ main:787 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:26:07  [ main:841 ] - [ INFO ]  Logging initialized @1362ms
2021-01-04 17:26:07  [ main:882 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:26:07  [ main:895 ] - [ INFO ]  Started @1416ms
2021-01-04 17:26:07  [ main:907 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:26:07  [ main:907 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:26:07  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:937 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:943 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:943 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:26:07  [ main:945 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:26:07  [ main:998 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:26:08  [ main:1052 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55198.
2021-01-04 17:26:08  [ main:1052 ] - [ INFO ]  Server created on 192.168.3.166:55198
2021-01-04 17:26:08  [ main:1053 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:26:08  [ main:1071 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55198, None)
2021-01-04 17:26:08  [ dispatcher-event-loop-10:1073 ] - [ INFO ]  Registering block manager 192.168.3.166:55198 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55198, None)
2021-01-04 17:26:08  [ main:1074 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55198, None)
2021-01-04 17:26:08  [ main:1075 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55198, None)
2021-01-04 17:26:08  [ main:1191 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:08  [ main:1517 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:26:08  [ main:1661 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:26:08  [ dispatcher-event-loop-12:1663 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55198 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:26:08  [ main:1665 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:26:08  [ main:1726 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:26:08  [ main:1768 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1781 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1783 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1783 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1784 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1785 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1788 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1839 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1840 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:26:08  [ dispatcher-event-loop-13:1841 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55198 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1841 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1851 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:26:08  [ dag-scheduler-event-loop:1851 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:26:08  [ dispatcher-event-loop-14:1876 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:26:08  [ dispatcher-event-loop-14:1877 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:26:08  [ Executor task launch worker for task 1:1884 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:26:08  [ Executor task launch worker for task 0:1884 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:26:08  [ Executor task launch worker for task 0:1920 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+35
2021-01-04 17:26:08  [ Executor task launch worker for task 1:1920 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:35+35
2021-01-04 17:26:09  [ Executor task launch worker for task 0:2107 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:26:09  [ Executor task launch worker for task 1:2107 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:26:09  [ task-result-getter-0:2112 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 242 ms on localhost (executor driver) (1/2)
2021-01-04 17:26:09  [ task-result-getter-1:2114 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 237 ms on localhost (executor driver) (2/2)
2021-01-04 17:26:09  [ task-result-getter-1:2114 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2118 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.287 s
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2119 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2119 ] - [ INFO ]  running: Set()
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2120 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2120 ] - [ INFO ]  failed: Set()
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2122 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2131 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2132 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:26:09  [ dispatcher-event-loop-3:2133 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55198 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2134 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2136 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2136 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:26:09  [ dispatcher-event-loop-4:2140 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:26:09  [ dispatcher-event-loop-4:2141 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:26:09  [ Executor task launch worker for task 3:2141 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:26:09  [ Executor task launch worker for task 2:2141 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:26:09  [ Executor task launch worker for task 3:2156 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:26:09  [ Executor task launch worker for task 2:2156 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:26:09  [ Executor task launch worker for task 3:2157 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:26:09  [ Executor task launch worker for task 2:2157 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:26:09  [ Executor task launch worker for task 3:2191 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1181 bytes result sent to driver
2021-01-04 17:26:09  [ Executor task launch worker for task 2:2191 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:26:09  [ task-result-getter-2:2192 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 52 ms on localhost (executor driver) (1/2)
2021-01-04 17:26:09  [ task-result-getter-3:2193 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 55 ms on localhost (executor driver) (2/2)
2021-01-04 17:26:09  [ task-result-getter-3:2193 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:26:09  [ dag-scheduler-event-loop:2194 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.068 s
2021-01-04 17:26:09  [ main:2197 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.428522 s
2021-01-04 17:26:09  [ Thread-1:2200 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:26:09  [ Thread-1:2206 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:26:09  [ Thread-1:2207 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:26:09  [ dispatcher-event-loop-11:2212 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:26:09  [ Thread-1:2228 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:26:09  [ Thread-1:2228 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:26:09  [ Thread-1:2231 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:26:09  [ dispatcher-event-loop-15:2233 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:26:09  [ Thread-1:2239 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:26:09  [ Thread-1:2239 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:26:09  [ Thread-1:2240 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-9beb518c-8421-4d67-a95e-f53e73060708
2021-01-04 17:26:22  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:26:22  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:26:23  [ main:35 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:26:23  [ main:248 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:26:23  [ main:360 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:26:23  [ main:404 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:26:23  [ main:404 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:26:23  [ main:404 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:26:23  [ main:405 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:26:23  [ main:405 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:26:23  [ main:674 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55209.
2021-01-04 17:26:23  [ main:689 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:26:23  [ main:700 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:26:23  [ main:702 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:26:23  [ main:702 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:26:23  [ main:733 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-611ac703-4b78-42c5-b7d6-3310c0790a55
2021-01-04 17:26:23  [ main:747 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:26:23  [ main:758 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:26:23  [ main:816 ] - [ INFO ]  Logging initialized @1326ms
2021-01-04 17:26:23  [ main:862 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:26:23  [ main:875 ] - [ INFO ]  Started @1386ms
2021-01-04 17:26:23  [ main:890 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:26:23  [ main:890 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:26:23  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:930 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:26:23  [ main:934 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:26:23  [ main:1003 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:26:24  [ main:1060 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55211.
2021-01-04 17:26:24  [ main:1061 ] - [ INFO ]  Server created on 192.168.3.166:55211
2021-01-04 17:26:24  [ main:1063 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:26:24  [ main:1084 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55211, None)
2021-01-04 17:26:24  [ dispatcher-event-loop-10:1086 ] - [ INFO ]  Registering block manager 192.168.3.166:55211 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55211, None)
2021-01-04 17:26:24  [ main:1088 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55211, None)
2021-01-04 17:26:24  [ main:1089 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55211, None)
2021-01-04 17:26:24  [ main:1223 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:26:24  [ main:1499 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:26:24  [ main:1616 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:26:24  [ dispatcher-event-loop-12:1618 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55211 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:26:24  [ main:1620 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:26:24  [ main:1679 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:26:24  [ main:1722 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1735 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1737 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1737 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1737 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1739 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1742 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1798 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1800 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:26:24  [ dispatcher-event-loop-13:1801 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55211 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1801 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1815 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:26:24  [ dag-scheduler-event-loop:1816 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:26:24  [ dispatcher-event-loop-14:1847 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:26:24  [ dispatcher-event-loop-14:1849 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:26:24  [ Executor task launch worker for task 0:1857 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:26:24  [ Executor task launch worker for task 1:1857 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:26:24  [ Executor task launch worker for task 1:1897 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:35+36
2021-01-04 17:26:24  [ Executor task launch worker for task 0:1897 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+35
2021-01-04 17:26:25  [ Executor task launch worker for task 1:2086 ] - [ ERROR ]  Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: empty String
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:16)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 17:26:25  [ Executor task launch worker for task 0:2096 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:26:25  [ task-result-getter-0:2103 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 265 ms on localhost (executor driver) (1/2)
2021-01-04 17:26:25  [ task-result-getter-1:2109 ] - [ WARN ]  Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: empty String
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:16)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2021-01-04 17:26:25  [ task-result-getter-1:2110 ] - [ ERROR ]  Task 1 in stage 0.0 failed 1 times; aborting job
2021-01-04 17:26:25  [ task-result-getter-1:2112 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:26:25  [ dag-scheduler-event-loop:2114 ] - [ INFO ]  Cancelling stage 0
2021-01-04 17:26:25  [ dag-scheduler-event-loop:2114 ] - [ INFO ]  Killing all running tasks in stage 0: Stage cancelled
2021-01-04 17:26:25  [ dag-scheduler-event-loop:2116 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) failed in 0.327 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: empty String
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:16)
	at sparkCore.AvgSparkCore$$anonfun$main$1.apply(AvgSparkCore.scala:14)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2021-01-04 17:26:25  [ main:2120 ] - [ INFO ]  Job 0 failed: foreach at AvgSparkCore.scala:23, took 0.397379 s
2021-01-04 17:26:25  [ Thread-1:2122 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:26:25  [ Thread-1:2131 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:26:25  [ Thread-1:2133 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:26:25  [ dispatcher-event-loop-5:2139 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:26:25  [ Thread-1:2150 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:26:25  [ Thread-1:2150 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:26:25  [ Thread-1:2154 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:26:25  [ dispatcher-event-loop-10:2155 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:26:25  [ Thread-1:2162 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:26:25  [ Thread-1:2163 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:26:25  [ Thread-1:2163 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-aa34d024-9dca-450c-a619-58eed8afee65
2021-01-04 17:27:03  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:27:03  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:27:03  [ main:33 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:27:03  [ main:263 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:27:03  [ main:393 ] - [ INFO ]  Submitted application: avg
2021-01-04 17:27:03  [ main:437 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:27:03  [ main:437 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:27:03  [ main:438 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:27:03  [ main:438 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:27:03  [ main:438 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:27:03  [ main:716 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55232.
2021-01-04 17:27:03  [ main:733 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:27:03  [ main:743 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:27:03  [ main:745 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:27:03  [ main:745 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:27:03  [ main:776 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-8defb6d9-06c1-4ea7-9e14-e7c1799dc980
2021-01-04 17:27:03  [ main:792 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:27:03  [ main:801 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:27:03  [ main:855 ] - [ INFO ]  Logging initialized @1400ms
2021-01-04 17:27:03  [ main:899 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:27:03  [ main:910 ] - [ INFO ]  Started @1456ms
2021-01-04 17:27:03  [ main:925 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:27:03  [ main:925 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:27:04  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:946 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:947 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:947 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:948 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:949 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:954 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:955 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:955 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:956 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:957 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:958 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:964 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:964 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:965 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:966 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:966 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:968 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:27:04  [ main:1040 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:27:04  [ main:1128 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55233.
2021-01-04 17:27:04  [ main:1129 ] - [ INFO ]  Server created on 192.168.3.166:55233
2021-01-04 17:27:04  [ main:1131 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:27:04  [ main:1204 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55233, None)
2021-01-04 17:27:04  [ dispatcher-event-loop-10:1217 ] - [ INFO ]  Registering block manager 192.168.3.166:55233 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55233, None)
2021-01-04 17:27:04  [ main:1241 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55233, None)
2021-01-04 17:27:04  [ main:1242 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55233, None)
2021-01-04 17:27:04  [ main:1440 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:27:04  [ main:1776 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:27:04  [ main:1885 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:27:04  [ dispatcher-event-loop-12:1887 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55233 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:27:04  [ main:1888 ] - [ INFO ]  Created broadcast 0 from textFile at AvgSparkCore.scala:13
2021-01-04 17:27:05  [ main:1945 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:27:05  [ main:1989 ] - [ INFO ]  Starting job: foreach at AvgSparkCore.scala:23
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2001 ] - [ INFO ]  Registering RDD 3 (filter at AvgSparkCore.scala:17)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2003 ] - [ INFO ]  Got job 0 (foreach at AvgSparkCore.scala:23) with 2 output partitions
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2003 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at AvgSparkCore.scala:23)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2003 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2005 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2007 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17), which has no missing parents
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2057 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2004.4 MB)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2059 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2004.4 MB)
2021-01-04 17:27:05  [ dispatcher-event-loop-13:2059 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55233 (size: 3.3 KB, free: 2004.6 MB)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2060 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2070 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at AvgSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2071 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:27:05  [ dispatcher-event-loop-14:2096 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:27:05  [ dispatcher-event-loop-14:2098 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:27:05  [ Executor task launch worker for task 0:2104 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:27:05  [ Executor task launch worker for task 1:2104 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:27:05  [ Executor task launch worker for task 0:2138 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+54
2021-01-04 17:27:05  [ Executor task launch worker for task 1:2138 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:54+55
2021-01-04 17:27:05  [ Executor task launch worker for task 1:2335 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:27:05  [ Executor task launch worker for task 0:2335 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:27:05  [ task-result-getter-0:2340 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 242 ms on localhost (executor driver) (1/2)
2021-01-04 17:27:05  [ task-result-getter-1:2341 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 252 ms on localhost (executor driver) (2/2)
2021-01-04 17:27:05  [ task-result-getter-1:2342 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2346 ] - [ INFO ]  ShuffleMapStage 0 (filter at AvgSparkCore.scala:17) finished in 0.296 s
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2347 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2347 ] - [ INFO ]  running: Set()
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2347 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2348 ] - [ INFO ]  failed: Set()
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2349 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19), which has no missing parents
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2358 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2004.4 MB)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2359 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:27:05  [ dispatcher-event-loop-3:2360 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55233 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2360 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2362 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at AvgSparkCore.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2362 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:27:05  [ dispatcher-event-loop-4:2366 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:27:05  [ dispatcher-event-loop-4:2366 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:27:05  [ Executor task launch worker for task 3:2367 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:27:05  [ Executor task launch worker for task 2:2367 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:27:05  [ Executor task launch worker for task 3:2380 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:27:05  [ Executor task launch worker for task 2:2380 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:27:05  [ Executor task launch worker for task 3:2381 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:27:05  [ Executor task launch worker for task 2:2381 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:27:05  [ Executor task launch worker for task 2:2418 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:27:05  [ Executor task launch worker for task 3:2419 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:27:05  [ task-result-getter-2:2420 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 56 ms on localhost (executor driver) (1/2)
2021-01-04 17:27:05  [ task-result-getter-3:2420 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 54 ms on localhost (executor driver) (2/2)
2021-01-04 17:27:05  [ task-result-getter-3:2420 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:27:05  [ dag-scheduler-event-loop:2422 ] - [ INFO ]  ResultStage 1 (foreach at AvgSparkCore.scala:23) finished in 0.068 s
2021-01-04 17:27:05  [ main:2425 ] - [ INFO ]  Job 0 finished: foreach at AvgSparkCore.scala:23, took 0.436387 s
2021-01-04 17:27:05  [ Thread-1:2428 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:27:05  [ Thread-1:2436 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:27:05  [ Thread-1:2437 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:27:05  [ dispatcher-event-loop-11:2442 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:27:05  [ Thread-1:2455 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:27:05  [ Thread-1:2455 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:27:05  [ Thread-1:2458 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:27:05  [ dispatcher-event-loop-15:2460 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:27:05  [ Thread-1:2466 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:27:05  [ Thread-1:2467 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:27:05  [ Thread-1:2467 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-9797c907-76df-4787-8df6-c7d850ec0c2f
2021-01-04 17:34:43  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:34:43  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:34:43  [ main:35 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:34:43  [ main:241 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:34:44  [ main:354 ] - [ INFO ]  Submitted application: max_min
2021-01-04 17:34:44  [ main:393 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:34:44  [ main:394 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:34:44  [ main:394 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:34:44  [ main:395 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:34:44  [ main:395 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:34:44  [ main:661 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55461.
2021-01-04 17:34:44  [ main:683 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:34:44  [ main:697 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:34:44  [ main:699 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:34:44  [ main:700 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:34:44  [ main:736 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-496ffc58-4e37-43da-83f5-2b8c0e72c2b0
2021-01-04 17:34:44  [ main:750 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:34:44  [ main:759 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:34:44  [ main:820 ] - [ INFO ]  Logging initialized @1320ms
2021-01-04 17:34:44  [ main:864 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:34:44  [ main:876 ] - [ INFO ]  Started @1377ms
2021-01-04 17:34:44  [ main:889 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:34:44  [ main:889 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:34:44  [ main:907 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:907 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:908 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:908 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:909 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:909 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:910 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:911 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:912 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:913 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:914 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:915 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:916 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:34:44  [ main:926 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:34:44  [ main:988 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:34:44  [ main:1043 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55462.
2021-01-04 17:34:44  [ main:1044 ] - [ INFO ]  Server created on 192.168.3.166:55462
2021-01-04 17:34:44  [ main:1045 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:34:44  [ main:1064 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55462, None)
2021-01-04 17:34:44  [ dispatcher-event-loop-10:1067 ] - [ INFO ]  Registering block manager 192.168.3.166:55462 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55462, None)
2021-01-04 17:34:44  [ main:1069 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55462, None)
2021-01-04 17:34:44  [ main:1069 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55462, None)
2021-01-04 17:34:45  [ main:1522 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:34:45  [ main:1839 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:34:45  [ main:2000 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:34:45  [ dispatcher-event-loop-12:2002 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55462 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:34:45  [ main:2004 ] - [ INFO ]  Created broadcast 0 from textFile at MaxMinSparkCore.scala:14
2021-01-04 17:34:45  [ Thread-1:2050 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:34:45  [ Thread-1:2060 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:34:45  [ Thread-1:2061 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:34:45  [ dispatcher-event-loop-15:2066 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:34:45  [ Thread-1:2077 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:34:45  [ Thread-1:2077 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:34:45  [ Thread-1:2080 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:34:45  [ dispatcher-event-loop-4:2083 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:34:45  [ Thread-1:2089 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:34:45  [ Thread-1:2089 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:34:45  [ Thread-1:2090 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-3ae1cc34-e27a-4b2f-8b9e-53b3e3be0d31
2021-01-04 17:35:24  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:35:24  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:35:25  [ main:34 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:35:25  [ main:250 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:35:25  [ main:374 ] - [ INFO ]  Submitted application: max_min
2021-01-04 17:35:25  [ main:416 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:35:25  [ main:417 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:35:25  [ main:417 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:35:25  [ main:417 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:35:25  [ main:418 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:35:25  [ main:698 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55488.
2021-01-04 17:35:25  [ main:714 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:35:25  [ main:726 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:35:25  [ main:728 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:35:25  [ main:728 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:35:25  [ main:759 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-616bf59f-28c3-48bf-87d6-a4d3ec854c6e
2021-01-04 17:35:25  [ main:773 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:35:25  [ main:783 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:35:25  [ main:836 ] - [ INFO ]  Logging initialized @1352ms
2021-01-04 17:35:25  [ main:877 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:35:25  [ main:888 ] - [ INFO ]  Started @1405ms
2021-01-04 17:35:25  [ main:899 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:35:25  [ main:900 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:35:25  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:929 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:35:25  [ main:938 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:35:25  [ main:991 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:35:26  [ main:1047 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55490.
2021-01-04 17:35:26  [ main:1048 ] - [ INFO ]  Server created on 192.168.3.166:55490
2021-01-04 17:35:26  [ main:1049 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:35:26  [ main:1066 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55490, None)
2021-01-04 17:35:26  [ dispatcher-event-loop-10:1068 ] - [ INFO ]  Registering block manager 192.168.3.166:55490 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55490, None)
2021-01-04 17:35:26  [ main:1070 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55490, None)
2021-01-04 17:35:26  [ main:1070 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55490, None)
2021-01-04 17:35:26  [ main:1188 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:35:26  [ main:1441 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:35:26  [ main:1553 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:35:26  [ dispatcher-event-loop-12:1555 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55490 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:35:26  [ main:1556 ] - [ INFO ]  Created broadcast 0 from textFile at MaxMinSparkCore.scala:14
2021-01-04 17:35:26  [ main:1613 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:35:26  [ main:1653 ] - [ INFO ]  Starting job: foreach at MaxMinSparkCore.scala:16
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1666 ] - [ INFO ]  Registering RDD 2 (map at MaxMinSparkCore.scala:15)
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1668 ] - [ INFO ]  Got job 0 (foreach at MaxMinSparkCore.scala:16) with 2 output partitions
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1668 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at MaxMinSparkCore.scala:16)
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1668 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1669 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1673 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at MaxMinSparkCore.scala:15), which has no missing parents
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1724 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.6 KB, free 2004.4 MB)
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1726 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:35:26  [ dispatcher-event-loop-13:1727 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55490 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1727 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1738 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at MaxMinSparkCore.scala:15) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:35:26  [ dag-scheduler-event-loop:1739 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:35:26  [ dispatcher-event-loop-14:1765 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:35:26  [ dispatcher-event-loop-14:1766 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:35:26  [ Executor task launch worker for task 1:1772 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:35:26  [ Executor task launch worker for task 0:1772 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:35:26  [ Executor task launch worker for task 0:1809 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+114
2021-01-04 17:35:26  [ Executor task launch worker for task 1:1809 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:114+115
2021-01-04 17:35:26  [ Executor task launch worker for task 1:2002 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:35:26  [ Executor task launch worker for task 0:2002 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:35:27  [ task-result-getter-1:2007 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 250 ms on localhost (executor driver) (1/2)
2021-01-04 17:35:27  [ task-result-getter-0:2009 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 243 ms on localhost (executor driver) (2/2)
2021-01-04 17:35:27  [ task-result-getter-0:2010 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2014 ] - [ INFO ]  ShuffleMapStage 0 (map at MaxMinSparkCore.scala:15) finished in 0.296 s
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2014 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2015 ] - [ INFO ]  running: Set()
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2015 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2015 ] - [ INFO ]  failed: Set()
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2017 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[3] at groupByKey at MaxMinSparkCore.scala:16), which has no missing parents
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2023 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.5 KB, free 2004.4 MB)
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2024 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 2004.4 MB)
2021-01-04 17:35:27  [ dispatcher-event-loop-3:2025 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55490 (size: 3.5 KB, free: 2004.6 MB)
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2025 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2027 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at groupByKey at MaxMinSparkCore.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2027 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:35:27  [ dispatcher-event-loop-4:2030 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:35:27  [ dispatcher-event-loop-4:2030 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:35:27  [ Executor task launch worker for task 2:2030 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:35:27  [ Executor task launch worker for task 3:2030 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:35:27  [ Executor task launch worker for task 2:2043 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:35:27  [ Executor task launch worker for task 3:2043 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:35:27  [ Executor task launch worker for task 2:2044 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:35:27  [ Executor task launch worker for task 3:2044 ] - [ INFO ]  Started 0 remote fetches in 5 ms
2021-01-04 17:35:27  [ Executor task launch worker for task 2:2079 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:35:27  [ Executor task launch worker for task 3:2079 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:35:27  [ task-result-getter-2:2080 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 51 ms on localhost (executor driver) (1/2)
2021-01-04 17:35:27  [ task-result-getter-3:2080 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (executor driver) (2/2)
2021-01-04 17:35:27  [ task-result-getter-3:2080 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:35:27  [ dag-scheduler-event-loop:2081 ] - [ INFO ]  ResultStage 1 (foreach at MaxMinSparkCore.scala:16) finished in 0.061 s
2021-01-04 17:35:27  [ main:2085 ] - [ INFO ]  Job 0 finished: foreach at MaxMinSparkCore.scala:16, took 0.431188 s
2021-01-04 17:35:27  [ Thread-1:2087 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:35:27  [ Thread-1:2093 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:35:27  [ Thread-1:2095 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:35:27  [ dispatcher-event-loop-11:2100 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:35:27  [ Thread-1:2112 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:35:27  [ Thread-1:2113 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:35:27  [ Thread-1:2116 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:35:27  [ dispatcher-event-loop-15:2118 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:35:27  [ Thread-1:2124 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:35:27  [ Thread-1:2125 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:35:27  [ Thread-1:2125 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-ab557cb6-5956-43d4-bf89-d77b72885cd4
2021-01-04 17:36:46  [ main:1 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:36:46  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:36:46  [ main:34 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:36:46  [ main:260 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:36:46  [ main:382 ] - [ INFO ]  Submitted application: max_min
2021-01-04 17:36:46  [ main:424 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:36:46  [ main:424 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:36:46  [ main:425 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:36:46  [ main:425 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:36:46  [ main:425 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:36:47  [ main:685 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55531.
2021-01-04 17:36:47  [ main:703 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:36:47  [ main:718 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:36:47  [ main:720 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:36:47  [ main:721 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:36:47  [ main:758 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-892dc550-0746-4838-9c37-5c94b27b97ea
2021-01-04 17:36:47  [ main:772 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:36:47  [ main:782 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:36:47  [ main:833 ] - [ INFO ]  Logging initialized @1643ms
2021-01-04 17:36:47  [ main:871 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:36:47  [ main:884 ] - [ INFO ]  Started @1695ms
2021-01-04 17:36:47  [ main:897 ] - [ INFO ]  Started ServerConnector@211b99d0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:36:47  [ main:898 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:36:47  [ main:917 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6ffab045{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:918 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60d8c0dc{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:919 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4602c2a9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:920 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:921 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@69c79f09{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:922 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:923 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:924 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:925 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:926 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:927 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:928 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/static,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@46e8a539{/,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/api,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@66629f63{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:936 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:36:47  [ main:994 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:36:47  [ main:1051 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55532.
2021-01-04 17:36:47  [ main:1052 ] - [ INFO ]  Server created on 192.168.3.166:55532
2021-01-04 17:36:47  [ main:1053 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:36:47  [ main:1073 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55532, None)
2021-01-04 17:36:47  [ dispatcher-event-loop-10:1076 ] - [ INFO ]  Registering block manager 192.168.3.166:55532 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55532, None)
2021-01-04 17:36:47  [ main:1078 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55532, None)
2021-01-04 17:36:47  [ main:1078 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55532, None)
2021-01-04 17:36:47  [ main:1202 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@107e5441{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:36:47  [ main:1507 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:36:48  [ main:1641 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:36:48  [ dispatcher-event-loop-12:1642 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55532 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:36:48  [ main:1644 ] - [ INFO ]  Created broadcast 0 from textFile at MaxMinSparkCore.scala:14
2021-01-04 17:36:48  [ main:1700 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:36:48  [ main:1742 ] - [ INFO ]  Starting job: foreach at MaxMinSparkCore.scala:19
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1756 ] - [ INFO ]  Registering RDD 2 (map at MaxMinSparkCore.scala:15)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1757 ] - [ INFO ]  Got job 0 (foreach at MaxMinSparkCore.scala:19) with 2 output partitions
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1758 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at MaxMinSparkCore.scala:19)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1758 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1759 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1762 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at MaxMinSparkCore.scala:15), which has no missing parents
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1810 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.6 KB, free 2004.4 MB)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1812 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:36:48  [ dispatcher-event-loop-13:1813 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55532 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1813 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1824 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at MaxMinSparkCore.scala:15) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:36:48  [ dag-scheduler-event-loop:1824 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:36:48  [ dispatcher-event-loop-14:1850 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:36:48  [ dispatcher-event-loop-14:1851 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:36:48  [ Executor task launch worker for task 0:1857 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:36:48  [ Executor task launch worker for task 1:1857 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:36:48  [ Executor task launch worker for task 0:1892 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+114
2021-01-04 17:36:48  [ Executor task launch worker for task 1:1892 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:114+115
2021-01-04 17:36:48  [ Executor task launch worker for task 1:2080 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:36:48  [ Executor task launch worker for task 0:2080 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:36:48  [ task-result-getter-0:2085 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 233 ms on localhost (executor driver) (1/2)
2021-01-04 17:36:48  [ task-result-getter-1:2086 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 244 ms on localhost (executor driver) (2/2)
2021-01-04 17:36:48  [ task-result-getter-1:2087 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2091 ] - [ INFO ]  ShuffleMapStage 0 (map at MaxMinSparkCore.scala:15) finished in 0.287 s
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2091 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2092 ] - [ INFO ]  running: Set()
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2092 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2092 ] - [ INFO ]  failed: Set()
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2094 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[4] at map at MaxMinSparkCore.scala:16), which has no missing parents
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2101 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.7 KB, free 2004.4 MB)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2102 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:36:48  [ dispatcher-event-loop-3:2103 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55532 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2103 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2104 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at MaxMinSparkCore.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2105 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:36:48  [ dispatcher-event-loop-4:2107 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:36:48  [ dispatcher-event-loop-4:2108 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:36:48  [ Executor task launch worker for task 2:2108 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:36:48  [ Executor task launch worker for task 3:2108 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:36:48  [ Executor task launch worker for task 2:2120 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:36:48  [ Executor task launch worker for task 3:2120 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:36:48  [ Executor task launch worker for task 2:2121 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:36:48  [ Executor task launch worker for task 3:2121 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:36:48  [ Executor task launch worker for task 2:2156 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1138 bytes result sent to driver
2021-01-04 17:36:48  [ Executor task launch worker for task 3:2156 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1138 bytes result sent to driver
2021-01-04 17:36:48  [ task-result-getter-2:2157 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 51 ms on localhost (executor driver) (1/2)
2021-01-04 17:36:48  [ task-result-getter-3:2158 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (executor driver) (2/2)
2021-01-04 17:36:48  [ task-result-getter-3:2158 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:36:48  [ dag-scheduler-event-loop:2159 ] - [ INFO ]  ResultStage 1 (foreach at MaxMinSparkCore.scala:19) finished in 0.061 s
2021-01-04 17:36:48  [ main:2162 ] - [ INFO ]  Job 0 finished: foreach at MaxMinSparkCore.scala:19, took 0.419398 s
2021-01-04 17:36:48  [ Thread-1:2164 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:36:48  [ Thread-1:2169 ] - [ INFO ]  Stopped Spark@211b99d0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:36:48  [ Thread-1:2171 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:36:48  [ dispatcher-event-loop-11:2175 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:36:48  [ Thread-1:2185 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:36:48  [ Thread-1:2185 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:36:48  [ Thread-1:2188 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:36:48  [ dispatcher-event-loop-15:2190 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:36:48  [ Thread-1:2197 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:36:48  [ Thread-1:2197 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:36:48  [ Thread-1:2198 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-8c4ccd05-a672-4d1b-81b3-48af02736b97
2021-01-04 17:40:12  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 17:40:12  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 17:40:12  [ main:36 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 17:40:12  [ main:252 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 17:40:13  [ main:399 ] - [ INFO ]  Submitted application: max_min
2021-01-04 17:40:13  [ main:442 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 17:40:13  [ main:443 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 17:40:13  [ main:443 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 17:40:13  [ main:444 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 17:40:13  [ main:444 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 17:40:13  [ main:693 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 55625.
2021-01-04 17:40:13  [ main:710 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 17:40:13  [ main:722 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 17:40:13  [ main:724 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 17:40:13  [ main:725 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 17:40:13  [ main:763 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-bea14311-de48-40ef-8792-93ff6591c4e2
2021-01-04 17:40:13  [ main:779 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 17:40:13  [ main:789 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 17:40:13  [ main:849 ] - [ INFO ]  Logging initialized @1657ms
2021-01-04 17:40:13  [ main:890 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 17:40:13  [ main:901 ] - [ INFO ]  Started @1710ms
2021-01-04 17:40:13  [ main:913 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:40:13  [ main:913 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 17:40:13  [ main:931 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:932 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:933 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:934 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:935 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:936 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:937 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:938 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:938 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:939 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:940 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:941 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:942 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:943 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 17:40:13  [ main:954 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 17:40:13  [ main:1010 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 17:40:13  [ main:1065 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55626.
2021-01-04 17:40:13  [ main:1066 ] - [ INFO ]  Server created on 192.168.3.166:55626
2021-01-04 17:40:13  [ main:1067 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 17:40:13  [ main:1085 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 55626, None)
2021-01-04 17:40:13  [ dispatcher-event-loop-10:1087 ] - [ INFO ]  Registering block manager 192.168.3.166:55626 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 55626, None)
2021-01-04 17:40:13  [ main:1089 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 55626, None)
2021-01-04 17:40:13  [ main:1089 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 55626, None)
2021-01-04 17:40:13  [ main:1226 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 17:40:14  [ main:1512 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 17:40:14  [ main:1650 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 17:40:14  [ dispatcher-event-loop-12:1652 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:55626 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 17:40:14  [ main:1653 ] - [ INFO ]  Created broadcast 0 from textFile at MaxMinSparkCore.scala:16
2021-01-04 17:40:14  [ main:1707 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 17:40:14  [ main:1749 ] - [ INFO ]  Starting job: foreach at MaxMinSparkCore.scala:21
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1761 ] - [ INFO ]  Registering RDD 2 (map at MaxMinSparkCore.scala:17)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1763 ] - [ INFO ]  Got job 0 (foreach at MaxMinSparkCore.scala:21) with 2 output partitions
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1763 ] - [ INFO ]  Final stage: ResultStage 1 (foreach at MaxMinSparkCore.scala:21)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1764 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1765 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1768 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at MaxMinSparkCore.scala:17), which has no missing parents
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1820 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.6 KB, free 2004.4 MB)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1822 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2004.4 MB)
2021-01-04 17:40:14  [ dispatcher-event-loop-13:1822 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:55626 (size: 3.2 KB, free: 2004.6 MB)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1823 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1833 ] - [ INFO ]  Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at MaxMinSparkCore.scala:17) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:40:14  [ dag-scheduler-event-loop:1834 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 17:40:14  [ dispatcher-event-loop-14:1860 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:40:14  [ dispatcher-event-loop-14:1861 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
2021-01-04 17:40:14  [ Executor task launch worker for task 1:1868 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 17:40:14  [ Executor task launch worker for task 0:1868 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 17:40:14  [ Executor task launch worker for task 0:1912 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+114
2021-01-04 17:40:14  [ Executor task launch worker for task 1:1912 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:114+115
2021-01-04 17:40:14  [ Executor task launch worker for task 0:2108 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1026 bytes result sent to driver
2021-01-04 17:40:14  [ Executor task launch worker for task 1:2108 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1026 bytes result sent to driver
2021-01-04 17:40:14  [ task-result-getter-0:2114 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 261 ms on localhost (executor driver) (1/2)
2021-01-04 17:40:14  [ task-result-getter-1:2115 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 254 ms on localhost (executor driver) (2/2)
2021-01-04 17:40:14  [ task-result-getter-1:2116 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2120 ] - [ INFO ]  ShuffleMapStage 0 (map at MaxMinSparkCore.scala:17) finished in 0.307 s
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2121 ] - [ INFO ]  looking for newly runnable stages
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2121 ] - [ INFO ]  running: Set()
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2121 ] - [ INFO ]  waiting: Set(ResultStage 1)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2121 ] - [ INFO ]  failed: Set()
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2123 ] - [ INFO ]  Submitting ResultStage 1 (MapPartitionsRDD[4] at map at MaxMinSparkCore.scala:18), which has no missing parents
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2131 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 6.7 KB, free 2004.4 MB)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2132 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 2004.4 MB)
2021-01-04 17:40:14  [ dispatcher-event-loop-3:2133 ] - [ INFO ]  Added broadcast_2_piece0 in memory on 192.168.3.166:55626 (size: 3.6 KB, free: 2004.6 MB)
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2133 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2135 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at MaxMinSparkCore.scala:18) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2135 ] - [ INFO ]  Adding task set 1.0 with 2 tasks
2021-01-04 17:40:14  [ dispatcher-event-loop-4:2138 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2021-01-04 17:40:14  [ dispatcher-event-loop-4:2139 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2021-01-04 17:40:14  [ Executor task launch worker for task 2:2139 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 2)
2021-01-04 17:40:14  [ Executor task launch worker for task 3:2139 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 3)
2021-01-04 17:40:14  [ Executor task launch worker for task 2:2151 ] - [ INFO ]  Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2021-01-04 17:40:14  [ Executor task launch worker for task 3:2151 ] - [ INFO ]  Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2021-01-04 17:40:14  [ Executor task launch worker for task 2:2152 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:40:14  [ Executor task launch worker for task 3:2152 ] - [ INFO ]  Started 0 remote fetches in 4 ms
2021-01-04 17:40:14  [ Executor task launch worker for task 2:2188 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2). 1181 bytes result sent to driver
2021-01-04 17:40:14  [ Executor task launch worker for task 3:2188 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3). 1181 bytes result sent to driver
2021-01-04 17:40:14  [ task-result-getter-2:2189 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 2) in 52 ms on localhost (executor driver) (1/2)
2021-01-04 17:40:14  [ task-result-getter-3:2189 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (executor driver) (2/2)
2021-01-04 17:40:14  [ task-result-getter-3:2189 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-01-04 17:40:14  [ dag-scheduler-event-loop:2190 ] - [ INFO ]  ResultStage 1 (foreach at MaxMinSparkCore.scala:21) finished in 0.063 s
2021-01-04 17:40:14  [ main:2194 ] - [ INFO ]  Job 0 finished: foreach at MaxMinSparkCore.scala:21, took 0.444889 s
2021-01-04 17:40:14  [ Thread-1:2196 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 17:40:14  [ Thread-1:2202 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 17:40:14  [ Thread-1:2203 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 17:40:14  [ dispatcher-event-loop-11:2208 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 17:40:14  [ Thread-1:2217 ] - [ INFO ]  MemoryStore cleared
2021-01-04 17:40:14  [ Thread-1:2217 ] - [ INFO ]  BlockManager stopped
2021-01-04 17:40:14  [ Thread-1:2221 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 17:40:14  [ dispatcher-event-loop-15:2222 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 17:40:14  [ Thread-1:2228 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 17:40:14  [ Thread-1:2229 ] - [ INFO ]  Shutdown hook called
2021-01-04 17:40:14  [ Thread-1:2229 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-6e850467-e81a-4a0a-9c88-28e275525449
2021-01-04 18:17:49  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 18:17:49  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 18:17:49  [ main:33 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 18:17:49  [ main:244 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 18:17:49  [ main:375 ] - [ INFO ]  Submitted application: user_log
2021-01-04 18:17:49  [ main:422 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 18:17:49  [ main:422 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 18:17:49  [ main:422 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 18:17:49  [ main:423 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 18:17:49  [ main:423 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 18:17:49  [ main:714 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 56873.
2021-01-04 18:17:49  [ main:734 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 18:17:49  [ main:748 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 18:17:49  [ main:751 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 18:17:49  [ main:752 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 18:17:49  [ main:799 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-0bf69d18-35ce-4b51-8dca-96e65d6bf11d
2021-01-04 18:17:49  [ main:821 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 18:17:49  [ main:837 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 18:17:49  [ main:900 ] - [ INFO ]  Logging initialized @1392ms
2021-01-04 18:17:49  [ main:942 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 18:17:49  [ main:954 ] - [ INFO ]  Started @1447ms
2021-01-04 18:17:49  [ main:967 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 18:17:49  [ main:968 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 18:17:50  [ main:990 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:991 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:992 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:993 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:993 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:994 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:996 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:997 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:998 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:999 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:999 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1000 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1001 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1001 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1002 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1002 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1003 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1008 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1009 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1010 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1010 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1011 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1012 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 18:17:50  [ main:1074 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 18:17:50  [ main:1127 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56874.
2021-01-04 18:17:50  [ main:1128 ] - [ INFO ]  Server created on 192.168.3.166:56874
2021-01-04 18:17:50  [ main:1128 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 18:17:50  [ main:1147 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 56874, None)
2021-01-04 18:17:50  [ dispatcher-event-loop-10:1149 ] - [ INFO ]  Registering block manager 192.168.3.166:56874 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 56874, None)
2021-01-04 18:17:50  [ main:1151 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 56874, None)
2021-01-04 18:17:50  [ main:1151 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 56874, None)
2021-01-04 18:17:50  [ main:1325 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 18:17:50  [ main:1706 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 18:17:51  [ main:2126 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 18:17:51  [ dispatcher-event-loop-12:2128 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:56874 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 18:17:51  [ main:2130 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:14
2021-01-04 18:17:51  [ main:2184 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 18:17:51  [ main:2193 ] - [ INFO ]  Starting job: foreach at UserLog.scala:15
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2204 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:15) with 2 output partitions
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2204 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:15)
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2204 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2205 ] - [ INFO ]  Missing parents: List()
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2208 ] - [ INFO ]  Submitting ResultStage 0 (/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt MapPartitionsRDD[1] at textFile at UserLog.scala:14), which has no missing parents
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2246 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 2004.4 MB)
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2248 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 2004.4 MB)
2021-01-04 18:17:51  [ dispatcher-event-loop-13:2248 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:56874 (size: 2.1 KB, free: 2004.6 MB)
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2249 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2283 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 0 (/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt MapPartitionsRDD[1] at textFile at UserLog.scala:14) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2283 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 18:17:51  [ dispatcher-event-loop-14:2309 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7929 bytes)
2021-01-04 18:17:51  [ dispatcher-event-loop-14:2311 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7929 bytes)
2021-01-04 18:17:51  [ Executor task launch worker for task 0:2318 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 18:17:51  [ Executor task launch worker for task 1:2318 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 18:17:51  [ Executor task launch worker for task 0:2354 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:0+404630
2021-01-04 18:17:51  [ Executor task launch worker for task 1:2354 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/spark/src/main/scala/test.txt:404630+404630
2021-01-04 18:17:51  [ Executor task launch worker for task 1:2474 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 794 bytes result sent to driver
2021-01-04 18:17:51  [ Executor task launch worker for task 0:2474 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 794 bytes result sent to driver
2021-01-04 18:17:51  [ task-result-getter-0:2479 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 168 ms on localhost (executor driver) (1/2)
2021-01-04 18:17:51  [ task-result-getter-1:2481 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 180 ms on localhost (executor driver) (2/2)
2021-01-04 18:17:51  [ task-result-getter-1:2481 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 18:17:51  [ dag-scheduler-event-loop:2486 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:15) finished in 0.264 s
2021-01-04 18:17:51  [ main:2489 ] - [ INFO ]  Job 0 finished: foreach at UserLog.scala:15, took 0.296249 s
2021-01-04 18:17:51  [ Thread-1:2492 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 18:17:51  [ Thread-1:2500 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 18:17:51  [ Thread-1:2501 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 18:17:51  [ dispatcher-event-loop-5:2507 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 18:17:51  [ Thread-1:2518 ] - [ INFO ]  MemoryStore cleared
2021-01-04 18:17:51  [ Thread-1:2518 ] - [ INFO ]  BlockManager stopped
2021-01-04 18:17:51  [ Thread-1:2521 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 18:17:51  [ dispatcher-event-loop-10:2522 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 18:17:51  [ Thread-1:2530 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 18:17:51  [ Thread-1:2530 ] - [ INFO ]  Shutdown hook called
2021-01-04 18:17:51  [ Thread-1:2530 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-6433b84b-5dad-4fa5-aab3-df23446d166b
2021-01-04 18:26:40  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 18:26:40  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 18:26:40  [ main:68 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 18:26:40  [ main:351 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 18:26:40  [ main:504 ] - [ INFO ]  Submitted application: user_log
2021-01-04 18:26:40  [ main:578 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 18:26:40  [ main:578 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 18:26:40  [ main:579 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 18:26:40  [ main:579 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 18:26:40  [ main:579 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 18:26:41  [ main:934 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 57138.
2021-01-04 18:26:41  [ main:958 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 18:26:41  [ main:979 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 18:26:41  [ main:984 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 18:26:41  [ main:985 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 18:26:41  [ main:1022 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-699c6997-e2e4-4eca-a567-028f1fe3d9d0
2021-01-04 18:26:41  [ main:1045 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 18:26:41  [ main:1062 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 18:26:41  [ main:1150 ] - [ INFO ]  Logging initialized @1779ms
2021-01-04 18:26:41  [ main:1215 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 18:26:41  [ main:1229 ] - [ INFO ]  Started @1858ms
2021-01-04 18:26:41  [ main:1246 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 18:26:41  [ main:1246 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 18:26:41  [ main:1266 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1267 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1268 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1268 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1269 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1269 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1270 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1271 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1272 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1272 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1273 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1273 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1274 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1274 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1275 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1276 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1276 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1277 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1277 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1278 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1284 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1285 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1286 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1287 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1287 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 18:26:41  [ main:1289 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 18:26:41  [ main:1364 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 18:26:41  [ main:1424 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57139.
2021-01-04 18:26:41  [ main:1424 ] - [ INFO ]  Server created on 192.168.3.166:57139
2021-01-04 18:26:41  [ main:1426 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 18:26:41  [ main:1450 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 57139, None)
2021-01-04 18:26:41  [ dispatcher-event-loop-10:1454 ] - [ INFO ]  Registering block manager 192.168.3.166:57139 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 57139, None)
2021-01-04 18:26:41  [ main:1457 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 57139, None)
2021-01-04 18:26:41  [ main:1458 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 57139, None)
2021-01-04 18:26:41  [ main:1599 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 18:26:42  [ main:1937 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 18:26:42  [ main:2115 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 18:26:42  [ dispatcher-event-loop-12:2117 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:57139 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 18:26:42  [ main:2121 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:14
2021-01-04 18:26:42  [ main:2202 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 18:26:42  [ main:2216 ] - [ INFO ]  Starting job: foreach at UserLog.scala:15
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2233 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:15) with 2 output partitions
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2234 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:15)
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2234 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2236 ] - [ INFO ]  Missing parents: List()
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2241 ] - [ INFO ]  Submitting ResultStage 0 (/Users/liuwenyi/IdeaProjects/satan/data/data1.csv MapPartitionsRDD[1] at textFile at UserLog.scala:14), which has no missing parents
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2322 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 2004.4 MB)
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2324 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 2004.4 MB)
2021-01-04 18:26:42  [ dispatcher-event-loop-13:2324 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:57139 (size: 2.1 KB, free: 2004.6 MB)
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2325 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2339 ] - [ INFO ]  Submitting 2 missing tasks from ResultStage 0 (/Users/liuwenyi/IdeaProjects/satan/data/data1.csv MapPartitionsRDD[1] at textFile at UserLog.scala:14) (first 15 tasks are for partitions Vector(0, 1))
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2340 ] - [ INFO ]  Adding task set 0.0 with 2 tasks
2021-01-04 18:26:42  [ dispatcher-event-loop-14:2380 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7914 bytes)
2021-01-04 18:26:42  [ dispatcher-event-loop-14:2383 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7914 bytes)
2021-01-04 18:26:42  [ Executor task launch worker for task 0:2394 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 18:26:42  [ Executor task launch worker for task 1:2394 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 18:26:42  [ Executor task launch worker for task 0:2448 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/data1.csv:0+61858
2021-01-04 18:26:42  [ Executor task launch worker for task 1:2448 ] - [ INFO ]  Input split: file:/Users/liuwenyi/IdeaProjects/satan/data/data1.csv:61858+61859
2021-01-04 18:26:42  [ Executor task launch worker for task 0:2523 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 837 bytes result sent to driver
2021-01-04 18:26:42  [ Executor task launch worker for task 1:2523 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 837 bytes result sent to driver
2021-01-04 18:26:42  [ task-result-getter-1:2531 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 147 ms on localhost (executor driver) (1/2)
2021-01-04 18:26:42  [ task-result-getter-0:2533 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 166 ms on localhost (executor driver) (2/2)
2021-01-04 18:26:42  [ task-result-getter-0:2534 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 18:26:42  [ dag-scheduler-event-loop:2540 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:15) finished in 0.273 s
2021-01-04 18:26:42  [ main:2547 ] - [ INFO ]  Job 0 finished: foreach at UserLog.scala:15, took 0.330892 s
2021-01-04 18:26:42  [ Thread-1:2549 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 18:26:42  [ Thread-1:2559 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 18:26:42  [ Thread-1:2561 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 18:26:42  [ dispatcher-event-loop-5:2569 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 18:26:42  [ Thread-1:2581 ] - [ INFO ]  MemoryStore cleared
2021-01-04 18:26:42  [ Thread-1:2581 ] - [ INFO ]  BlockManager stopped
2021-01-04 18:26:42  [ Thread-1:2586 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 18:26:42  [ dispatcher-event-loop-10:2588 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 18:26:42  [ Thread-1:2597 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 18:26:42  [ Thread-1:2597 ] - [ INFO ]  Shutdown hook called
2021-01-04 18:26:42  [ Thread-1:2598 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-a77331eb-df5a-4fb0-9923-f711635bf5b7
2021-01-04 18:40:13  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.166 instead (on interface en0)
2021-01-04 18:40:13  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 18:40:13  [ main:51 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 18:40:13  [ main:434 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 18:40:14  [ main:603 ] - [ INFO ]  Submitted application: user_log
2021-01-04 18:40:14  [ main:689 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 18:40:14  [ main:689 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 18:40:14  [ main:690 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 18:40:14  [ main:690 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 18:40:14  [ main:690 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 18:40:14  [ main:1049 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 57479.
2021-01-04 18:40:14  [ main:1080 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 18:40:14  [ main:1103 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 18:40:14  [ main:1107 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 18:40:14  [ main:1108 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 18:40:14  [ main:1150 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-83bb506f-52de-4d29-82ff-a9d38200f498
2021-01-04 18:40:14  [ main:1177 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 18:40:14  [ main:1192 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 18:40:14  [ main:1271 ] - [ INFO ]  Logging initialized @2097ms
2021-01-04 18:40:14  [ main:1326 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 18:40:14  [ main:1340 ] - [ INFO ]  Started @2167ms
2021-01-04 18:40:14  [ main:1358 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 18:40:14  [ main:1359 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 18:40:14  [ main:1388 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1389 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1390 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1390 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1391 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1391 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1392 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1393 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1393 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1394 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1394 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1395 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1396 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1396 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1397 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1397 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1398 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1398 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1399 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1399 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1406 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1406 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1407 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1408 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1408 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 18:40:14  [ main:1410 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.3.166:4040
2021-01-04 18:40:14  [ main:1506 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 18:40:15  [ main:1602 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57480.
2021-01-04 18:40:15  [ main:1603 ] - [ INFO ]  Server created on 192.168.3.166:57480
2021-01-04 18:40:15  [ main:1606 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 18:40:15  [ main:1641 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.3.166, 57480, None)
2021-01-04 18:40:15  [ dispatcher-event-loop-10:1645 ] - [ INFO ]  Registering block manager 192.168.3.166:57480 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.3.166, 57480, None)
2021-01-04 18:40:15  [ main:1649 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.3.166, 57480, None)
2021-01-04 18:40:15  [ main:1650 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.3.166, 57480, None)
2021-01-04 18:40:15  [ main:1857 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 18:40:15  [ main:2299 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 18:40:16  [ main:2577 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 18:40:16  [ dispatcher-event-loop-12:2579 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.3.166:57480 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 18:40:16  [ main:2584 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:14
2021-01-04 18:40:16  [ main:2674 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 18:40:16  [ main:2688 ] - [ INFO ]  Starting job: foreach at UserLog.scala:15
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2706 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:15) with 56 output partitions
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2707 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:15)
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2707 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2709 ] - [ INFO ]  Missing parents: List()
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2714 ] - [ INFO ]  Submitting ResultStage 0 (/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv MapPartitionsRDD[1] at textFile at UserLog.scala:14), which has no missing parents
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2795 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 2004.4 MB)
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2796 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 2004.4 MB)
2021-01-04 18:40:16  [ dispatcher-event-loop-13:2797 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.3.166:57480 (size: 2.1 KB, free: 2004.6 MB)
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2797 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2811 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv MapPartitionsRDD[1] at textFile at UserLog.scala:14) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 18:40:16  [ dag-scheduler-event-loop:2812 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2852 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2854 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2854 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2855 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2855 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2855 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2856 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2856 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2857 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2857 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2858 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2858 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2859 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2859 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2860 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ dispatcher-event-loop-14:2860 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 18:40:16  [ Executor task launch worker for task 9:2868 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 18:40:16  [ Executor task launch worker for task 15:2868 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 18:40:16  [ Executor task launch worker for task 5:2868 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 18:40:16  [ Executor task launch worker for task 7:2871 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 18:40:16  [ Executor task launch worker for task 10:2872 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 18:40:16  [ Executor task launch worker for task 8:2873 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 18:40:16  [ Executor task launch worker for task 0:2874 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 18:40:16  [ Executor task launch worker for task 13:2874 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 18:40:16  [ Executor task launch worker for task 6:2875 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 18:40:16  [ Executor task launch worker for task 3:2875 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 18:40:16  [ Executor task launch worker for task 1:2876 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 18:40:16  [ Executor task launch worker for task 11:2877 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 18:40:16  [ Executor task launch worker for task 2:2877 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 18:40:16  [ Executor task launch worker for task 14:2878 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 18:40:16  [ Executor task launch worker for task 12:2879 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 18:40:16  [ Executor task launch worker for task 4:2879 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 18:40:16  [ Executor task launch worker for task 12:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 7:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 2:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 1:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 4:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 3:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 5:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 9:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 13:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 8:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 11:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 6:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 14:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 15:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 10:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 18:40:16  [ Executor task launch worker for task 0:2933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 18:40:22  [ Thread-1:9164 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 18:40:22  [ Thread-1:9175 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 18:40:22  [ Thread-1:9177 ] - [ INFO ]  Stopped Spark web UI at http://192.168.3.166:4040
2021-01-04 18:40:22  [ main:9183 ] - [ INFO ]  Job 0 failed: foreach at UserLog.scala:15, took 6.494085 s
2021-01-04 18:40:22  [ Thread-1:9184 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:15) failed in 6.440 s due to Stage cancelled because SparkContext was shut down
2021-01-04 18:40:22  [ dispatcher-event-loop-15:9201 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 18:40:22  [ Thread-1:9217 ] - [ INFO ]  MemoryStore cleared
2021-01-04 18:40:22  [ Thread-1:9218 ] - [ INFO ]  BlockManager stopped
2021-01-04 18:40:22  [ Thread-1:9223 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 18:40:22  [ dispatcher-event-loop-6:9226 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 18:40:22  [ Thread-1:9236 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 18:40:22  [ Thread-1:9236 ] - [ INFO ]  Shutdown hook called
2021-01-04 18:40:22  [ Thread-1:9237 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-d67496c8-f0b8-4e45-ae79-49456f3f673d
2021-01-04 21:09:20  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 21:09:20  [ main:0 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 21:09:20  [ main:32 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 21:09:21  [ main:232 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 21:09:21  [ main:355 ] - [ INFO ]  Submitted application: user_log
2021-01-04 21:09:21  [ main:408 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 21:09:21  [ main:408 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 21:09:21  [ main:408 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 21:09:21  [ main:409 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 21:09:21  [ main:409 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 21:09:21  [ main:692 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 57617.
2021-01-04 21:09:21  [ main:709 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 21:09:21  [ main:721 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 21:09:21  [ main:723 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 21:09:21  [ main:724 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 21:09:21  [ main:759 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-9647df44-6dae-4bfd-93e4-9f4ff7b15031
2021-01-04 21:09:21  [ main:781 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 21:09:21  [ main:793 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 21:09:21  [ main:857 ] - [ INFO ]  Logging initialized @1348ms
2021-01-04 21:09:21  [ main:901 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 21:09:21  [ main:913 ] - [ INFO ]  Started @1405ms
2021-01-04 21:09:21  [ main:926 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:09:21  [ main:926 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 21:09:21  [ main:944 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:945 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:946 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:946 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:947 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:947 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:948 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:949 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:949 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:950 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:951 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:952 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:953 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:954 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:954 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:955 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:960 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:960 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:961 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:961 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:962 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 21:09:21  [ main:963 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 21:09:21  [ main:1019 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 21:09:21  [ main:1077 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57618.
2021-01-04 21:09:21  [ main:1077 ] - [ INFO ]  Server created on 192.168.124.5:57618
2021-01-04 21:09:21  [ main:1078 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 21:09:21  [ main:1096 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 57618, None)
2021-01-04 21:09:21  [ dispatcher-event-loop-10:1099 ] - [ INFO ]  Registering block manager 192.168.124.5:57618 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 57618, None)
2021-01-04 21:09:21  [ main:1102 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 57618, None)
2021-01-04 21:09:21  [ main:1102 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 57618, None)
2021-01-04 21:09:22  [ main:1257 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 21:09:22  [ main:1521 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 21:09:23  [ main:2232 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 21:09:23  [ dispatcher-event-loop-12:2234 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:57618 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 21:09:23  [ main:2237 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:14
2021-01-04 21:09:23  [ main:2302 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 21:09:23  [ main:2313 ] - [ INFO ]  Starting job: foreach at UserLog.scala:15
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2326 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:15) with 56 output partitions
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2326 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:15)
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2326 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2327 ] - [ INFO ]  Missing parents: List()
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2330 ] - [ INFO ]  Submitting ResultStage 0 (/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv MapPartitionsRDD[1] at textFile at UserLog.scala:14), which has no missing parents
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2397 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 2004.4 MB)
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2399 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 2004.4 MB)
2021-01-04 21:09:23  [ dispatcher-event-loop-13:2399 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:57618 (size: 2.1 KB, free: 2004.6 MB)
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2400 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2411 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv MapPartitionsRDD[1] at textFile at UserLog.scala:14) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 21:09:23  [ dag-scheduler-event-loop:2411 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2438 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2439 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2440 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2440 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2440 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2441 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2441 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2442 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2442 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2443 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2443 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2444 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2444 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2445 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2446 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ dispatcher-event-loop-14:2447 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:09:23  [ Executor task launch worker for task 0:2454 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 21:09:23  [ Executor task launch worker for task 11:2454 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 21:09:23  [ Executor task launch worker for task 10:2455 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 21:09:23  [ Executor task launch worker for task 9:2456 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 21:09:23  [ Executor task launch worker for task 4:2456 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 21:09:23  [ Executor task launch worker for task 3:2457 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 21:09:23  [ Executor task launch worker for task 8:2458 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 21:09:23  [ Executor task launch worker for task 7:2458 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 21:09:23  [ Executor task launch worker for task 5:2459 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 21:09:23  [ Executor task launch worker for task 6:2460 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 21:09:23  [ Executor task launch worker for task 2:2460 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 21:09:23  [ Executor task launch worker for task 12:2461 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 21:09:23  [ Executor task launch worker for task 15:2467 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 21:09:23  [ Executor task launch worker for task 13:2468 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 21:09:23  [ Executor task launch worker for task 1:2469 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 21:09:23  [ Executor task launch worker for task 14:2470 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 21:09:23  [ Executor task launch worker for task 3:2512 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 0:2512 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 14:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 11:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 9:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 13:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 4:2512 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 15:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 10:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 7:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 5:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 6:2512 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 8:2512 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 12:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 2:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 21:09:23  [ Executor task launch worker for task 1:2513 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 21:09:37  [ Thread-1:16432 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 21:09:37  [ Thread-1:16440 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:09:37  [ Thread-1:16442 ] - [ INFO ]  Stopped Spark web UI at http://192.168.124.5:4040
2021-01-04 21:09:37  [ main:16446 ] - [ INFO ]  Job 0 failed: foreach at UserLog.scala:15, took 14.132276 s
2021-01-04 21:09:37  [ Thread-1:16446 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:15) failed in 14.097 s due to Stage cancelled because SparkContext was shut down
2021-01-04 21:09:37  [ dispatcher-event-loop-3:16452 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 21:09:37  [ Thread-1:16464 ] - [ INFO ]  MemoryStore cleared
2021-01-04 21:09:37  [ Thread-1:16464 ] - [ INFO ]  BlockManager stopped
2021-01-04 21:09:37  [ Thread-1:16465 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 21:09:37  [ dispatcher-event-loop-8:16468 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 21:09:37  [ Thread-1:16475 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 21:09:37  [ Thread-1:16478 ] - [ INFO ]  Shutdown hook called
2021-01-04 21:09:37  [ Thread-1:16478 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-8f7a1050-7f76-4711-8318-0c9845b88bbe
2021-01-04 21:25:37  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 21:25:37  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 21:25:37  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 21:25:37  [ main:325 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 21:25:38  [ main:471 ] - [ INFO ]  Submitted application: user_log
2021-01-04 21:25:38  [ main:539 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 21:25:38  [ main:539 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 21:25:38  [ main:539 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 21:25:38  [ main:540 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 21:25:38  [ main:540 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 21:25:38  [ main:861 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 58032.
2021-01-04 21:25:38  [ main:886 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 21:25:38  [ main:907 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 21:25:38  [ main:911 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 21:25:38  [ main:911 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 21:25:38  [ main:946 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-4abc82ce-d08a-46ac-ade8-ea6b6f5404b6
2021-01-04 21:25:38  [ main:966 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 21:25:38  [ main:980 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 21:25:38  [ main:1061 ] - [ INFO ]  Logging initialized @1683ms
2021-01-04 21:25:38  [ main:1113 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 21:25:38  [ main:1127 ] - [ INFO ]  Started @1750ms
2021-01-04 21:25:38  [ main:1144 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:25:38  [ main:1144 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 21:25:38  [ main:1168 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1169 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1170 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1171 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1171 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1172 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1173 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1174 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1175 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1175 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1176 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1177 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1177 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1178 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1179 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1179 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1180 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1181 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1182 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1182 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1190 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1191 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1192 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1192 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1192 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 21:25:38  [ main:1194 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 21:25:38  [ main:1271 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 21:25:38  [ main:1336 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58033.
2021-01-04 21:25:38  [ main:1336 ] - [ INFO ]  Server created on 192.168.124.5:58033
2021-01-04 21:25:38  [ main:1338 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 21:25:38  [ main:1368 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 58033, None)
2021-01-04 21:25:38  [ dispatcher-event-loop-10:1372 ] - [ INFO ]  Registering block manager 192.168.124.5:58033 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 58033, None)
2021-01-04 21:25:38  [ main:1376 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 58033, None)
2021-01-04 21:25:38  [ main:1376 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 58033, None)
2021-01-04 21:25:39  [ main:1537 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 21:25:39  [ main:1951 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 21:25:39  [ main:2112 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 21:25:39  [ dispatcher-event-loop-12:2114 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:58033 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 21:25:39  [ main:2118 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:37
2021-01-04 21:25:39  [ main:2200 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 21:25:39  [ main:2216 ] - [ INFO ]  Starting job: foreach at UserLog.scala:43
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2238 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:43) with 56 output partitions
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2238 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:43)
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2238 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2240 ] - [ INFO ]  Missing parents: List()
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2245 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[2] at map at UserLog.scala:38), which has no missing parents
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2332 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 2004.4 MB)
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2334 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2004.4 MB)
2021-01-04 21:25:39  [ dispatcher-event-loop-13:2335 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:58033 (size: 2.3 KB, free: 2004.6 MB)
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2335 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2348 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at UserLog.scala:38) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 21:25:39  [ dag-scheduler-event-loop:2349 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2393 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2396 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2396 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2396 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2397 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2398 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2398 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2398 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2399 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2399 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2399 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2401 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2402 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2402 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2403 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ dispatcher-event-loop-14:2404 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:39  [ Executor task launch worker for task 11:2412 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 21:25:39  [ Executor task launch worker for task 14:2412 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 21:25:39  [ Executor task launch worker for task 5:2416 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 21:25:39  [ Executor task launch worker for task 7:2418 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 21:25:39  [ Executor task launch worker for task 13:2418 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 21:25:39  [ Executor task launch worker for task 0:2419 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 21:25:39  [ Executor task launch worker for task 8:2421 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 21:25:39  [ Executor task launch worker for task 12:2421 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 21:25:39  [ Executor task launch worker for task 15:2422 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 21:25:39  [ Executor task launch worker for task 10:2423 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 21:25:39  [ Executor task launch worker for task 9:2424 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 21:25:39  [ Executor task launch worker for task 2:2424 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 21:25:39  [ Executor task launch worker for task 1:2425 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 21:25:39  [ Executor task launch worker for task 3:2426 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 21:25:39  [ Executor task launch worker for task 4:2426 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 21:25:39  [ Executor task launch worker for task 6:2427 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 21:25:40  [ Executor task launch worker for task 9:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 8:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 7:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 6:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 14:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 15:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 3:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 13:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 12:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 1:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 10:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 2:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 11:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 5:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 0:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 4:2483 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 21:25:40  [ Executor task launch worker for task 0:2522 ] - [ ERROR ]  Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:40)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 21:25:40  [ dispatcher-event-loop-0:2562 ] - [ INFO ]  Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:25:40  [ Executor task launch worker for task 16:2563 ] - [ INFO ]  Running task 16.0 in stage 0.0 (TID 16)
2021-01-04 21:25:40  [ task-result-getter-0:2564 ] - [ WARN ]  Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:40)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2021-01-04 21:25:40  [ Executor task launch worker for task 16:2567 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:536870912+33554432
2021-01-04 21:25:40  [ task-result-getter-0:2568 ] - [ ERROR ]  Task 0 in stage 0.0 failed 1 times; aborting job
2021-01-04 21:25:40  [ dag-scheduler-event-loop:2579 ] - [ INFO ]  Cancelling stage 0
2021-01-04 21:25:40  [ dag-scheduler-event-loop:2581 ] - [ INFO ]  Killing all running tasks in stage 0: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2584 ] - [ INFO ]  Executor is trying to kill task 15.0 in stage 0.0 (TID 15), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2585 ] - [ INFO ]  Executor is trying to kill task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2585 ] - [ INFO ]  Executor is trying to kill task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled
2021-01-04 21:25:40  [ dag-scheduler-event-loop:2585 ] - [ INFO ]  Stage 0 was cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2585 ] - [ INFO ]  Executor is trying to kill task 16.0 in stage 0.0 (TID 16), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 15:2586 ] - [ INFO ]  Executor killed task 15.0 in stage 0.0 (TID 15), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 9:2586 ] - [ INFO ]  Executor killed task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled
2021-01-04 21:25:40  [ dag-scheduler-event-loop:2587 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:43) failed in 0.282 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:40)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2021-01-04 21:25:40  [ Executor task launch worker for task 16:2587 ] - [ INFO ]  Executor killed task 16.0 in stage 0.0 (TID 16), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 1:2586 ] - [ INFO ]  Executor killed task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2587 ] - [ INFO ]  Executor is trying to kill task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2590 ] - [ INFO ]  Executor is trying to kill task 3.0 in stage 0.0 (TID 3), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2590 ] - [ INFO ]  Executor is trying to kill task 10.0 in stage 0.0 (TID 10), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2590 ] - [ INFO ]  Executor is trying to kill task 4.0 in stage 0.0 (TID 4), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2590 ] - [ INFO ]  Executor is trying to kill task 11.0 in stage 0.0 (TID 11), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2592 ] - [ INFO ]  Executor is trying to kill task 12.0 in stage 0.0 (TID 12), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2592 ] - [ INFO ]  Executor is trying to kill task 13.0 in stage 0.0 (TID 13), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2593 ] - [ INFO ]  Executor is trying to kill task 5.0 in stage 0.0 (TID 5), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2595 ] - [ INFO ]  Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2595 ] - [ INFO ]  Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 3:2592 ] - [ INFO ]  Executor killed task 3.0 in stage 0.0 (TID 3), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 4:2592 ] - [ INFO ]  Executor killed task 4.0 in stage 0.0 (TID 4), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 7:2596 ] - [ INFO ]  Executor killed task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 6:2596 ] - [ INFO ]  Executor killed task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 5:2597 ] - [ INFO ]  Executor killed task 5.0 in stage 0.0 (TID 5), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2595 ] - [ INFO ]  Executor is trying to kill task 14.0 in stage 0.0 (TID 14), reason: Stage cancelled
2021-01-04 21:25:40  [ dispatcher-event-loop-1:2598 ] - [ INFO ]  Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled
2021-01-04 21:25:40  [ main:2595 ] - [ INFO ]  Job 0 failed: foreach at UserLog.scala:43, took 0.378741 s
2021-01-04 21:25:40  [ Executor task launch worker for task 14:2599 ] - [ INFO ]  Executor killed task 14.0 in stage 0.0 (TID 14), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 13:2594 ] - [ INFO ]  Executor killed task 13.0 in stage 0.0 (TID 13), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 8:2599 ] - [ INFO ]  Executor killed task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 11:2594 ] - [ INFO ]  Executor killed task 11.0 in stage 0.0 (TID 11), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 2:2593 ] - [ INFO ]  Executor killed task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 12:2593 ] - [ INFO ]  Executor killed task 12.0 in stage 0.0 (TID 12), reason: Stage cancelled
2021-01-04 21:25:40  [ Executor task launch worker for task 10:2593 ] - [ INFO ]  Executor killed task 10.0 in stage 0.0 (TID 10), reason: Stage cancelled
2021-01-04 21:25:40  [ task-result-getter-1:2602 ] - [ WARN ]  Lost task 15.0 in stage 0.0 (TID 15, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ Thread-1:2602 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 21:25:40  [ task-result-getter-2:2603 ] - [ WARN ]  Lost task 9.0 in stage 0.0 (TID 9, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-3:2603 ] - [ WARN ]  Lost task 16.0 in stage 0.0 (TID 16, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-0:2604 ] - [ WARN ]  Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-1:2605 ] - [ WARN ]  Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-2:2605 ] - [ WARN ]  Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-3:2606 ] - [ WARN ]  Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-0:2607 ] - [ WARN ]  Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-1:2608 ] - [ WARN ]  Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-0:2608 ] - [ WARN ]  Lost task 13.0 in stage 0.0 (TID 13, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-0:2609 ] - [ WARN ]  Lost task 8.0 in stage 0.0 (TID 8, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-1:2609 ] - [ WARN ]  Lost task 11.0 in stage 0.0 (TID 11, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-2:2610 ] - [ WARN ]  Lost task 14.0 in stage 0.0 (TID 14, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-3:2611 ] - [ WARN ]  Lost task 12.0 in stage 0.0 (TID 12, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-0:2611 ] - [ WARN ]  Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-0:2613 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 21:25:40  [ task-result-getter-1:2613 ] - [ WARN ]  Lost task 10.0 in stage 0.0 (TID 10, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:25:40  [ task-result-getter-1:2613 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 21:25:40  [ Thread-1:2616 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:25:40  [ Thread-1:2618 ] - [ INFO ]  Stopped Spark web UI at http://192.168.124.5:4040
2021-01-04 21:25:40  [ dispatcher-event-loop-5:2626 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 21:25:40  [ Thread-1:2642 ] - [ INFO ]  MemoryStore cleared
2021-01-04 21:25:40  [ Thread-1:2642 ] - [ INFO ]  BlockManager stopped
2021-01-04 21:25:40  [ Thread-1:2647 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 21:25:40  [ dispatcher-event-loop-10:2648 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 21:25:40  [ Thread-1:2655 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 21:25:40  [ Thread-1:2655 ] - [ INFO ]  Shutdown hook called
2021-01-04 21:25:40  [ Thread-1:2656 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-2e4c6166-fbaa-40bc-bb54-0e67059e49e1
2021-01-04 21:27:35  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 21:27:35  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 21:27:35  [ main:31 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 21:27:35  [ main:232 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 21:27:35  [ main:333 ] - [ INFO ]  Submitted application: user_log
2021-01-04 21:27:36  [ main:368 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 21:27:36  [ main:369 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 21:27:36  [ main:369 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 21:27:36  [ main:369 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 21:27:36  [ main:369 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 21:27:36  [ main:604 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 58058.
2021-01-04 21:27:36  [ main:625 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 21:27:36  [ main:643 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 21:27:36  [ main:646 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 21:27:36  [ main:647 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 21:27:36  [ main:678 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-36a647cb-1eeb-414f-a0e3-baed6dd56a5c
2021-01-04 21:27:36  [ main:691 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 21:27:36  [ main:700 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 21:27:36  [ main:748 ] - [ INFO ]  Logging initialized @1244ms
2021-01-04 21:27:36  [ main:782 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 21:27:36  [ main:791 ] - [ INFO ]  Started @1288ms
2021-01-04 21:27:36  [ main:802 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:27:36  [ main:802 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 21:27:36  [ main:818 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:818 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:819 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:820 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:820 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:820 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:821 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:822 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:823 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:823 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:824 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:825 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:825 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:826 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:826 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:827 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:828 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:828 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:829 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:830 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:835 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:836 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:837 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:837 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:838 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:839 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 21:27:36  [ main:896 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 21:27:36  [ main:942 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58059.
2021-01-04 21:27:36  [ main:942 ] - [ INFO ]  Server created on 192.168.124.5:58059
2021-01-04 21:27:36  [ main:943 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 21:27:36  [ main:958 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 58059, None)
2021-01-04 21:27:36  [ dispatcher-event-loop-10:960 ] - [ INFO ]  Registering block manager 192.168.124.5:58059 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 58059, None)
2021-01-04 21:27:36  [ main:962 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 58059, None)
2021-01-04 21:27:36  [ main:962 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 58059, None)
2021-01-04 21:27:36  [ main:1066 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 21:27:36  [ main:1314 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 21:27:37  [ main:1666 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 21:27:37  [ dispatcher-event-loop-12:1668 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:58059 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 21:27:37  [ main:1671 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:37
2021-01-04 21:27:37  [ main:1735 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 21:27:37  [ main:1744 ] - [ INFO ]  Starting job: foreach at UserLog.scala:55
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1755 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:55) with 56 output partitions
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1756 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:55)
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1756 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1757 ] - [ INFO ]  Missing parents: List()
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1760 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[2] at map at UserLog.scala:38), which has no missing parents
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1836 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 2004.4 MB)
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1837 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2004.4 MB)
2021-01-04 21:27:37  [ dispatcher-event-loop-13:1838 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:58059 (size: 2.3 KB, free: 2004.6 MB)
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1838 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1850 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at UserLog.scala:38) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 21:27:37  [ dag-scheduler-event-loop:1851 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1883 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1885 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1885 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1886 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1887 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1887 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1888 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1888 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1889 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1889 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1890 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1891 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1892 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1892 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1893 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ dispatcher-event-loop-14:1894 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ Executor task launch worker for task 5:1902 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 21:27:37  [ Executor task launch worker for task 13:1903 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 21:27:37  [ Executor task launch worker for task 8:1904 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 21:27:37  [ Executor task launch worker for task 10:1904 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 21:27:37  [ Executor task launch worker for task 4:1905 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 21:27:37  [ Executor task launch worker for task 1:1906 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 21:27:37  [ Executor task launch worker for task 12:1907 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 21:27:37  [ Executor task launch worker for task 9:1908 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 21:27:37  [ Executor task launch worker for task 3:1909 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 21:27:37  [ Executor task launch worker for task 7:1909 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 21:27:37  [ Executor task launch worker for task 0:1910 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 21:27:37  [ Executor task launch worker for task 6:1911 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 21:27:37  [ Executor task launch worker for task 11:1911 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 21:27:37  [ Executor task launch worker for task 2:1912 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 21:27:37  [ Executor task launch worker for task 15:1920 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 21:27:37  [ Executor task launch worker for task 14:1921 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 21:27:37  [ Executor task launch worker for task 11:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 0:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 8:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 2:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 1:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 15:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 12:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 4:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 14:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 9:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 13:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 7:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 10:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 3:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 6:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 5:1961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 21:27:37  [ Executor task launch worker for task 0:1990 ] - [ ERROR ]  Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:40)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 21:27:37  [ dispatcher-event-loop-15:2020 ] - [ INFO ]  Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:27:37  [ Executor task launch worker for task 16:2020 ] - [ INFO ]  Running task 16.0 in stage 0.0 (TID 16)
2021-01-04 21:27:37  [ task-result-getter-0:2023 ] - [ WARN ]  Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:40)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2021-01-04 21:27:37  [ Executor task launch worker for task 16:2027 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:536870912+33554432
2021-01-04 21:27:37  [ task-result-getter-0:2032 ] - [ ERROR ]  Task 0 in stage 0.0 failed 1 times; aborting job
2021-01-04 21:27:37  [ dag-scheduler-event-loop:2039 ] - [ INFO ]  Cancelling stage 0
2021-01-04 21:27:37  [ dag-scheduler-event-loop:2042 ] - [ INFO ]  Killing all running tasks in stage 0: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2046 ] - [ INFO ]  Executor is trying to kill task 15.0 in stage 0.0 (TID 15), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2047 ] - [ INFO ]  Executor is trying to kill task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 15:2049 ] - [ INFO ]  Executor killed task 15.0 in stage 0.0 (TID 15), reason: Stage cancelled
2021-01-04 21:27:37  [ dag-scheduler-event-loop:2048 ] - [ INFO ]  Stage 0 was cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2050 ] - [ INFO ]  Executor is trying to kill task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 9:2051 ] - [ INFO ]  Executor killed task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled
2021-01-04 21:27:37  [ dag-scheduler-event-loop:2051 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:55) failed in 0.237 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:40)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2052 ] - [ INFO ]  Executor is trying to kill task 16.0 in stage 0.0 (TID 16), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 1:2053 ] - [ INFO ]  Executor killed task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 16:2054 ] - [ INFO ]  Executor killed task 16.0 in stage 0.0 (TID 16), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2053 ] - [ INFO ]  Executor is trying to kill task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2054 ] - [ INFO ]  Executor is trying to kill task 3.0 in stage 0.0 (TID 3), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2054 ] - [ INFO ]  Executor is trying to kill task 10.0 in stage 0.0 (TID 10), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 2:2056 ] - [ INFO ]  Executor killed task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 3:2055 ] - [ INFO ]  Executor killed task 3.0 in stage 0.0 (TID 3), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2056 ] - [ INFO ]  Executor is trying to kill task 4.0 in stage 0.0 (TID 4), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2057 ] - [ INFO ]  Executor is trying to kill task 11.0 in stage 0.0 (TID 11), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 10:2057 ] - [ INFO ]  Executor killed task 10.0 in stage 0.0 (TID 10), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2057 ] - [ INFO ]  Executor is trying to kill task 12.0 in stage 0.0 (TID 12), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2058 ] - [ INFO ]  Executor is trying to kill task 13.0 in stage 0.0 (TID 13), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2058 ] - [ INFO ]  Executor is trying to kill task 5.0 in stage 0.0 (TID 5), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2058 ] - [ INFO ]  Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2058 ] - [ INFO ]  Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2058 ] - [ INFO ]  Executor is trying to kill task 14.0 in stage 0.0 (TID 14), reason: Stage cancelled
2021-01-04 21:27:37  [ main:2058 ] - [ INFO ]  Job 0 failed: foreach at UserLog.scala:55, took 0.313435 s
2021-01-04 21:27:37  [ dispatcher-event-loop-0:2058 ] - [ INFO ]  Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 11:2058 ] - [ INFO ]  Executor killed task 11.0 in stage 0.0 (TID 11), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 4:2059 ] - [ INFO ]  Executor killed task 4.0 in stage 0.0 (TID 4), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 12:2059 ] - [ INFO ]  Executor killed task 12.0 in stage 0.0 (TID 12), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 14:2061 ] - [ INFO ]  Executor killed task 14.0 in stage 0.0 (TID 14), reason: Stage cancelled
2021-01-04 21:27:37  [ task-result-getter-1:2061 ] - [ WARN ]  Lost task 15.0 in stage 0.0 (TID 15, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ Executor task launch worker for task 13:2061 ] - [ INFO ]  Executor killed task 13.0 in stage 0.0 (TID 13), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 6:2061 ] - [ INFO ]  Executor killed task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 5:2061 ] - [ INFO ]  Executor killed task 5.0 in stage 0.0 (TID 5), reason: Stage cancelled
2021-01-04 21:27:37  [ Executor task launch worker for task 7:2061 ] - [ INFO ]  Executor killed task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled
2021-01-04 21:27:37  [ Thread-1:2061 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 21:27:37  [ Executor task launch worker for task 8:2061 ] - [ INFO ]  Executor killed task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled
2021-01-04 21:27:37  [ task-result-getter-2:2062 ] - [ WARN ]  Lost task 9.0 in stage 0.0 (TID 9, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-3:2062 ] - [ WARN ]  Lost task 16.0 in stage 0.0 (TID 16, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-0:2062 ] - [ WARN ]  Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-1:2063 ] - [ WARN ]  Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-2:2063 ] - [ WARN ]  Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-3:2064 ] - [ WARN ]  Lost task 10.0 in stage 0.0 (TID 10, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-0:2064 ] - [ WARN ]  Lost task 11.0 in stage 0.0 (TID 11, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-1:2064 ] - [ WARN ]  Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-2:2065 ] - [ WARN ]  Lost task 12.0 in stage 0.0 (TID 12, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-3:2065 ] - [ WARN ]  Lost task 14.0 in stage 0.0 (TID 14, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-0:2066 ] - [ WARN ]  Lost task 13.0 in stage 0.0 (TID 13, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-1:2066 ] - [ WARN ]  Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-2:2066 ] - [ WARN ]  Lost task 8.0 in stage 0.0 (TID 8, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-3:2067 ] - [ WARN ]  Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-0:2067 ] - [ WARN ]  Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:27:37  [ task-result-getter-0:2068 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 21:27:37  [ Thread-1:2073 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:27:37  [ Thread-1:2075 ] - [ INFO ]  Stopped Spark web UI at http://192.168.124.5:4040
2021-01-04 21:27:37  [ dispatcher-event-loop-5:2081 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 21:27:37  [ Thread-1:2092 ] - [ INFO ]  MemoryStore cleared
2021-01-04 21:27:37  [ Thread-1:2092 ] - [ INFO ]  BlockManager stopped
2021-01-04 21:27:37  [ Thread-1:2096 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 21:27:37  [ dispatcher-event-loop-10:2097 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 21:27:37  [ Thread-1:2105 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 21:27:37  [ Thread-1:2105 ] - [ INFO ]  Shutdown hook called
2021-01-04 21:27:37  [ Thread-1:2105 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-4eddbcc7-b053-4c02-a125-cb193cef53d0
2021-01-04 21:28:17  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 21:28:17  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 21:28:17  [ main:44 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 21:28:17  [ main:303 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 21:28:17  [ main:450 ] - [ INFO ]  Submitted application: user_log
2021-01-04 21:28:17  [ main:506 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 21:28:17  [ main:506 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 21:28:17  [ main:507 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 21:28:17  [ main:507 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 21:28:17  [ main:508 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 21:28:18  [ main:821 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 58076.
2021-01-04 21:28:18  [ main:838 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 21:28:18  [ main:874 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 21:28:18  [ main:876 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 21:28:18  [ main:876 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 21:28:18  [ main:890 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-123a2cbf-9266-4303-99ab-9d6eb453cbba
2021-01-04 21:28:18  [ main:906 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 21:28:18  [ main:918 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 21:28:18  [ main:975 ] - [ INFO ]  Logging initialized @2293ms
2021-01-04 21:28:18  [ main:1019 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 21:28:18  [ main:1032 ] - [ INFO ]  Started @2352ms
2021-01-04 21:28:18  [ main:1046 ] - [ INFO ]  Started ServerConnector@1d540566{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:28:18  [ main:1046 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 21:28:18  [ main:1070 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1aa6e3c0{/jobs,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1070 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@316a598d{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1071 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@216914{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1072 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5633dafd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1072 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5d5160e6{/stages,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1073 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2eadc9f6{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1073 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2903c6ff{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1074 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@59901c4d{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1075 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@168cd36b{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1076 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@d8d9199{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1076 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3901f6af{/storage,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1077 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@602ae7b6{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1078 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@10cd6753{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1078 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@71ad3d8a{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1079 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@47af099e{/environment,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1080 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@700f518a{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1081 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@b835727{/executors,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1081 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@13da7ab0{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1082 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2c8662ac{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1083 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@260ff5b7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1089 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3724b43e{/static,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1089 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2f61d591{/,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1090 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@332820f4{/api,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1091 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@21f459fc{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1091 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4d192aef{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 21:28:18  [ main:1093 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 21:28:18  [ main:1157 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 21:28:18  [ main:1211 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58078.
2021-01-04 21:28:18  [ main:1211 ] - [ INFO ]  Server created on 192.168.124.5:58078
2021-01-04 21:28:18  [ main:1212 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 21:28:18  [ main:1230 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 58078, None)
2021-01-04 21:28:18  [ dispatcher-event-loop-10:1232 ] - [ INFO ]  Registering block manager 192.168.124.5:58078 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 58078, None)
2021-01-04 21:28:18  [ main:1234 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 58078, None)
2021-01-04 21:28:18  [ main:1235 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 58078, None)
2021-01-04 21:28:18  [ main:1370 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@51ab1ee3{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 21:28:19  [ main:1835 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 21:28:19  [ main:2022 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 21:28:19  [ dispatcher-event-loop-12:2026 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:58078 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 21:28:19  [ main:2031 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:37
2021-01-04 21:28:19  [ main:2230 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 21:28:19  [ main:2242 ] - [ INFO ]  Starting job: foreach at UserLog.scala:56
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2259 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:56) with 56 output partitions
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2259 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:56)
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2259 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2261 ] - [ INFO ]  Missing parents: List()
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2264 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[2] at map at UserLog.scala:38), which has no missing parents
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2364 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 2004.4 MB)
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2366 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2004.4 MB)
2021-01-04 21:28:19  [ dispatcher-event-loop-13:2367 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:58078 (size: 2.3 KB, free: 2004.6 MB)
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2367 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2381 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at UserLog.scala:38) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 21:28:19  [ dag-scheduler-event-loop:2382 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2420 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2421 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2422 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2423 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2423 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2424 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2424 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2425 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2425 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2426 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2427 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2427 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2428 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2429 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2430 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ dispatcher-event-loop-14:2430 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:19  [ Executor task launch worker for task 4:2439 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 21:28:19  [ Executor task launch worker for task 13:2440 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 21:28:19  [ Executor task launch worker for task 7:2440 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 21:28:19  [ Executor task launch worker for task 6:2441 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 21:28:19  [ Executor task launch worker for task 5:2442 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 21:28:19  [ Executor task launch worker for task 9:2443 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 21:28:19  [ Executor task launch worker for task 1:2443 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 21:28:19  [ Executor task launch worker for task 10:2444 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 21:28:19  [ Executor task launch worker for task 11:2445 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 21:28:19  [ Executor task launch worker for task 12:2445 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 21:28:19  [ Executor task launch worker for task 2:2446 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 21:28:19  [ Executor task launch worker for task 0:2447 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 21:28:19  [ Executor task launch worker for task 8:2447 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 21:28:19  [ Executor task launch worker for task 3:2448 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 21:28:19  [ Executor task launch worker for task 15:2458 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 21:28:19  [ Executor task launch worker for task 14:2459 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 21:28:19  [ Executor task launch worker for task 13:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 15:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 9:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 5:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 11:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 0:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 2:2504 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 12:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 1:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 3:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 4:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 10:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 7:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 14:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 8:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 21:28:19  [ Executor task launch worker for task 6:2503 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 21:28:30  [ Executor task launch worker for task 0:13621 ] - [ ERROR ]  Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:41)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 21:28:31  [ dispatcher-event-loop-0:13652 ] - [ INFO ]  Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:28:31  [ Executor task launch worker for task 16:13653 ] - [ INFO ]  Running task 16.0 in stage 0.0 (TID 16)
2021-01-04 21:28:31  [ task-result-getter-0:13655 ] - [ WARN ]  Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:41)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2021-01-04 21:28:31  [ Executor task launch worker for task 16:13656 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:536870912+33554432
2021-01-04 21:28:31  [ task-result-getter-0:13658 ] - [ ERROR ]  Task 0 in stage 0.0 failed 1 times; aborting job
2021-01-04 21:28:31  [ dag-scheduler-event-loop:13665 ] - [ INFO ]  Cancelling stage 0
2021-01-04 21:28:31  [ dag-scheduler-event-loop:13666 ] - [ INFO ]  Killing all running tasks in stage 0: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13669 ] - [ INFO ]  Executor is trying to kill task 15.0 in stage 0.0 (TID 15), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13669 ] - [ INFO ]  Executor is trying to kill task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13669 ] - [ INFO ]  Executor is trying to kill task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled
2021-01-04 21:28:31  [ dag-scheduler-event-loop:13669 ] - [ INFO ]  Stage 0 was cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 9:13671 ] - [ INFO ]  Executor killed task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 15:13671 ] - [ INFO ]  Executor killed task 15.0 in stage 0.0 (TID 15), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13670 ] - [ INFO ]  Executor is trying to kill task 16.0 in stage 0.0 (TID 16), reason: Stage cancelled
2021-01-04 21:28:31  [ dag-scheduler-event-loop:13673 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:56) failed in 11.342 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "id"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:41)
	at sparkCore.userLog.UserLog$$anonfun$main$1.apply(UserLog.scala:38)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:927)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2021-01-04 21:28:31  [ Executor task launch worker for task 1:13672 ] - [ INFO ]  Executor killed task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13673 ] - [ INFO ]  Executor is trying to kill task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled
2021-01-04 21:28:31  [ Thread-1:13677 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 21:28:31  [ Executor task launch worker for task 16:13675 ] - [ INFO ]  Executor killed task 16.0 in stage 0.0 (TID 16), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13677 ] - [ INFO ]  Executor is trying to kill task 3.0 in stage 0.0 (TID 3), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 2:13678 ] - [ INFO ]  Executor killed task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13679 ] - [ INFO ]  Executor is trying to kill task 10.0 in stage 0.0 (TID 10), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 3:13680 ] - [ INFO ]  Executor killed task 3.0 in stage 0.0 (TID 3), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13681 ] - [ INFO ]  Executor is trying to kill task 4.0 in stage 0.0 (TID 4), reason: Stage cancelled
2021-01-04 21:28:31  [ main:13680 ] - [ INFO ]  Job 0 failed: foreach at UserLog.scala:56, took 11.437679 s
2021-01-04 21:28:31  [ Executor task launch worker for task 10:13682 ] - [ INFO ]  Executor killed task 10.0 in stage 0.0 (TID 10), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13682 ] - [ INFO ]  Executor is trying to kill task 11.0 in stage 0.0 (TID 11), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 4:13683 ] - [ INFO ]  Executor killed task 4.0 in stage 0.0 (TID 4), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13685 ] - [ INFO ]  Executor is trying to kill task 12.0 in stage 0.0 (TID 12), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13685 ] - [ INFO ]  Executor is trying to kill task 13.0 in stage 0.0 (TID 13), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 11:13685 ] - [ INFO ]  Executor killed task 11.0 in stage 0.0 (TID 11), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 13:13686 ] - [ INFO ]  Executor killed task 13.0 in stage 0.0 (TID 13), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 12:13686 ] - [ INFO ]  Executor killed task 12.0 in stage 0.0 (TID 12), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13686 ] - [ INFO ]  Executor is trying to kill task 5.0 in stage 0.0 (TID 5), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13688 ] - [ INFO ]  Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13688 ] - [ INFO ]  Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13688 ] - [ INFO ]  Executor is trying to kill task 14.0 in stage 0.0 (TID 14), reason: Stage cancelled
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13688 ] - [ INFO ]  Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 5:13688 ] - [ INFO ]  Executor killed task 5.0 in stage 0.0 (TID 5), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 7:13689 ] - [ INFO ]  Executor killed task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 6:13690 ] - [ INFO ]  Executor killed task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 14:13690 ] - [ INFO ]  Executor killed task 14.0 in stage 0.0 (TID 14), reason: Stage cancelled
2021-01-04 21:28:31  [ Executor task launch worker for task 8:13690 ] - [ INFO ]  Executor killed task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled
2021-01-04 21:28:31  [ Thread-1:13691 ] - [ INFO ]  Stopped Spark@1d540566{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:28:31  [ task-result-getter-1:13691 ] - [ WARN ]  Lost task 9.0 in stage 0.0 (TID 9, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-2:13691 ] - [ WARN ]  Lost task 15.0 in stage 0.0 (TID 15, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-3:13692 ] - [ WARN ]  Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-0:13693 ] - [ WARN ]  Lost task 16.0 in stage 0.0 (TID 16, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-2:13694 ] - [ WARN ]  Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ Thread-1:13694 ] - [ INFO ]  Stopped Spark web UI at http://192.168.124.5:4040
2021-01-04 21:28:31  [ task-result-getter-1:13694 ] - [ WARN ]  Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-3:13694 ] - [ WARN ]  Lost task 10.0 in stage 0.0 (TID 10, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-0:13695 ] - [ WARN ]  Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-2:13695 ] - [ WARN ]  Lost task 11.0 in stage 0.0 (TID 11, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-1:13695 ] - [ WARN ]  Lost task 13.0 in stage 0.0 (TID 13, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-3:13696 ] - [ WARN ]  Lost task 12.0 in stage 0.0 (TID 12, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-0:13696 ] - [ WARN ]  Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-2:13696 ] - [ WARN ]  Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-1:13697 ] - [ WARN ]  Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ dispatcher-event-loop-15:13699 ] - [ ERROR ]  Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@111e0d2f rejected from java.util.concurrent.ThreadPoolExecutor@cc258f6[Shutting down, pool size = 4, active threads = 1, queued tasks = 0, completed tasks = 15]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-01-04 21:28:31  [ task-result-getter-3:13699 ] - [ WARN ]  Lost task 14.0 in stage 0.0 (TID 14, localhost, executor driver): TaskKilled (Stage cancelled)
2021-01-04 21:28:31  [ task-result-getter-3:13700 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 21:28:31  [ dispatcher-event-loop-6:13703 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 21:28:31  [ Thread-1:13713 ] - [ INFO ]  MemoryStore cleared
2021-01-04 21:28:31  [ Thread-1:13713 ] - [ INFO ]  BlockManager stopped
2021-01-04 21:28:31  [ Thread-1:13716 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 21:28:31  [ dispatcher-event-loop-11:13718 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 21:28:31  [ Thread-1:13725 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 21:28:31  [ Thread-1:13725 ] - [ INFO ]  Shutdown hook called
2021-01-04 21:28:31  [ Thread-1:13726 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-e5ffaa40-08cc-46f9-8d65-0a721e0012e6
2021-01-04 21:31:50  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 21:31:50  [ main:2 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 21:31:50  [ main:34 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 21:31:50  [ main:247 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 21:31:50  [ main:361 ] - [ INFO ]  Submitted application: user_log
2021-01-04 21:31:50  [ main:398 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 21:31:50  [ main:398 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 21:31:50  [ main:398 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 21:31:50  [ main:399 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 21:31:50  [ main:399 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 21:31:50  [ main:633 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 58481.
2021-01-04 21:31:50  [ main:646 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 21:31:50  [ main:656 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 21:31:50  [ main:657 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 21:31:50  [ main:658 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 21:31:50  [ main:686 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-2241ed10-5665-420f-8af0-0bd5a21f9702
2021-01-04 21:31:50  [ main:699 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 21:31:50  [ main:707 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 21:31:50  [ main:753 ] - [ INFO ]  Logging initialized @1263ms
2021-01-04 21:31:50  [ main:791 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 21:31:50  [ main:801 ] - [ INFO ]  Started @1312ms
2021-01-04 21:31:50  [ main:812 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:31:50  [ main:813 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 21:31:50  [ main:829 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:830 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:830 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:831 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:832 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:832 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:833 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:834 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:835 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:835 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:836 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:837 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:837 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:838 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:838 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:839 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:839 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:840 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:840 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:841 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:846 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:846 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:847 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:848 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:848 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 21:31:50  [ main:850 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 21:31:50  [ main:926 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 21:31:51  [ main:988 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58482.
2021-01-04 21:31:51  [ main:988 ] - [ INFO ]  Server created on 192.168.124.5:58482
2021-01-04 21:31:51  [ main:989 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 21:31:51  [ main:1006 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 58482, None)
2021-01-04 21:31:51  [ dispatcher-event-loop-10:1008 ] - [ INFO ]  Registering block manager 192.168.124.5:58482 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 58482, None)
2021-01-04 21:31:51  [ main:1010 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 58482, None)
2021-01-04 21:31:51  [ main:1010 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 58482, None)
2021-01-04 21:31:51  [ main:1169 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 21:31:51  [ main:1494 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 21:31:51  [ main:1766 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 21:31:51  [ dispatcher-event-loop-12:1768 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:58482 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 21:31:51  [ main:1770 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:37
2021-01-04 21:31:51  [ main:1832 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 21:31:51  [ main:1841 ] - [ INFO ]  Starting job: foreach at UserLog.scala:57
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1853 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:57) with 56 output partitions
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1853 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:57)
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1854 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1855 ] - [ INFO ]  Missing parents: List()
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1858 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at map at UserLog.scala:39), which has no missing parents
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1926 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 2004.4 MB)
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1927 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2021-01-04 21:31:51  [ dispatcher-event-loop-13:1928 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:58482 (size: 2.4 KB, free: 2004.6 MB)
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1929 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1941 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at UserLog.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 21:31:51  [ dag-scheduler-event-loop:1941 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1972 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1974 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1974 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1975 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1976 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1976 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1977 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1977 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1978 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1978 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1979 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1979 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1980 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1981 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1982 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ dispatcher-event-loop-14:1983 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:31:52  [ Executor task launch worker for task 10:1991 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 21:31:52  [ Executor task launch worker for task 12:1992 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 21:31:52  [ Executor task launch worker for task 1:1993 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 21:31:52  [ Executor task launch worker for task 3:1993 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 21:31:52  [ Executor task launch worker for task 2:1995 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 21:31:52  [ Executor task launch worker for task 4:1995 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 21:31:52  [ Executor task launch worker for task 7:1996 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 21:31:52  [ Executor task launch worker for task 0:1997 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 21:31:52  [ Executor task launch worker for task 6:1998 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 21:31:52  [ Executor task launch worker for task 8:1999 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 21:31:52  [ Executor task launch worker for task 5:1999 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 21:31:52  [ Executor task launch worker for task 9:2000 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 21:31:52  [ Executor task launch worker for task 11:2001 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 21:31:52  [ Executor task launch worker for task 15:2009 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 21:31:52  [ Executor task launch worker for task 14:2010 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 21:31:52  [ Executor task launch worker for task 13:2011 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 21:31:52  [ Executor task launch worker for task 3:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 2:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 10:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 14:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 0:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 9:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 11:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 7:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 4:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 13:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 5:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 1:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 15:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 6:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 12:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 21:31:52  [ Executor task launch worker for task 8:2051 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 21:32:02  [ Thread-1:12495 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 21:32:02  [ Thread-1:12503 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:32:02  [ Thread-1:12505 ] - [ INFO ]  Stopped Spark web UI at http://192.168.124.5:4040
2021-01-04 21:32:02  [ main:12507 ] - [ INFO ]  Job 0 failed: foreach at UserLog.scala:57, took 10.666048 s
2021-01-04 21:32:02  [ Thread-1:12508 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:57) failed in 10.603 s due to Stage cancelled because SparkContext was shut down
2021-01-04 21:32:02  [ dispatcher-event-loop-1:12513 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 21:32:02  [ Thread-1:12523 ] - [ INFO ]  MemoryStore cleared
2021-01-04 21:32:02  [ Thread-1:12524 ] - [ INFO ]  BlockManager stopped
2021-01-04 21:32:02  [ Thread-1:12527 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 21:32:02  [ dispatcher-event-loop-6:12528 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 21:32:02  [ Thread-1:12535 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 21:32:02  [ Thread-1:12536 ] - [ INFO ]  Shutdown hook called
2021-01-04 21:32:02  [ Thread-1:12537 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-9cc38abc-e508-44f8-89fa-681d8b7b62a2
2021-01-04 21:39:09  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 21:39:09  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 21:39:09  [ main:35 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 21:39:09  [ main:255 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 21:39:09  [ main:388 ] - [ INFO ]  Submitted application: user_log
2021-01-04 21:39:09  [ main:426 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 21:39:09  [ main:426 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 21:39:09  [ main:427 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 21:39:09  [ main:427 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 21:39:09  [ main:427 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 21:39:09  [ main:658 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 58896.
2021-01-04 21:39:09  [ main:672 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 21:39:09  [ main:682 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 21:39:09  [ main:684 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 21:39:09  [ main:684 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 21:39:10  [ main:716 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-497fa368-ed42-48bf-a64a-abd59d3bd2dc
2021-01-04 21:39:10  [ main:729 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 21:39:10  [ main:738 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 21:39:10  [ main:783 ] - [ INFO ]  Logging initialized @1606ms
2021-01-04 21:39:10  [ main:817 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 21:39:10  [ main:828 ] - [ INFO ]  Started @1651ms
2021-01-04 21:39:10  [ main:839 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 21:39:10  [ main:840 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 21:39:10  [ main:857 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:858 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:858 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:859 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:860 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:860 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:860 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:862 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:862 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:863 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:863 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:864 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:864 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:865 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:865 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:866 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:866 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:867 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:867 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:868 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:872 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:873 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:874 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:874 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:875 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:876 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 21:39:10  [ main:933 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 21:39:10  [ main:982 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58897.
2021-01-04 21:39:10  [ main:982 ] - [ INFO ]  Server created on 192.168.124.5:58897
2021-01-04 21:39:10  [ main:983 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 21:39:10  [ main:1000 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 58897, None)
2021-01-04 21:39:10  [ dispatcher-event-loop-10:1002 ] - [ INFO ]  Registering block manager 192.168.124.5:58897 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 58897, None)
2021-01-04 21:39:10  [ main:1003 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 58897, None)
2021-01-04 21:39:10  [ main:1003 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 58897, None)
2021-01-04 21:39:10  [ main:1107 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 21:39:10  [ main:1358 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 21:39:12  [ main:2822 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 21:39:12  [ dispatcher-event-loop-12:2824 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:58897 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 21:39:12  [ main:2826 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:57
2021-01-04 21:39:12  [ main:2890 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 21:39:12  [ main:2899 ] - [ INFO ]  Starting job: foreach at UserLog.scala:61
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2912 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:61) with 56 output partitions
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2913 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:61)
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2913 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2914 ] - [ INFO ]  Missing parents: List()
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2918 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at map at UserLog.scala:60), which has no missing parents
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2997 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 2004.4 MB)
2021-01-04 21:39:12  [ dag-scheduler-event-loop:2998 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2004.4 MB)
2021-01-04 21:39:12  [ dispatcher-event-loop-13:2999 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:58897 (size: 2.4 KB, free: 2004.6 MB)
2021-01-04 21:39:12  [ dag-scheduler-event-loop:3000 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 21:39:12  [ dag-scheduler-event-loop:3013 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at UserLog.scala:60) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 21:39:12  [ dag-scheduler-event-loop:3014 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3044 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3046 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3046 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3047 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3048 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3048 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3049 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3049 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3050 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3050 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3051 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3052 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3053 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3054 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3054 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ dispatcher-event-loop-14:3055 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:12  [ Executor task launch worker for task 4:3064 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 21:39:12  [ Executor task launch worker for task 15:3064 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 21:39:12  [ Executor task launch worker for task 14:3065 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 21:39:12  [ Executor task launch worker for task 13:3065 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 21:39:12  [ Executor task launch worker for task 12:3067 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 21:39:12  [ Executor task launch worker for task 10:3067 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 21:39:12  [ Executor task launch worker for task 2:3068 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 21:39:12  [ Executor task launch worker for task 7:3069 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 21:39:12  [ Executor task launch worker for task 3:3069 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 21:39:12  [ Executor task launch worker for task 0:3070 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 21:39:12  [ Executor task launch worker for task 6:3071 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 21:39:12  [ Executor task launch worker for task 5:3071 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 21:39:12  [ Executor task launch worker for task 8:3072 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 21:39:12  [ Executor task launch worker for task 1:3073 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 21:39:12  [ Executor task launch worker for task 9:3073 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 21:39:12  [ Executor task launch worker for task 11:3074 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 21:39:12  [ Executor task launch worker for task 11:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 6:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 3:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 9:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 8:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 2:3128 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 10:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 7:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 14:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 0:3128 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 15:3128 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 13:3128 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 5:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 12:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 4:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 21:39:12  [ Executor task launch worker for task 1:3127 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 21:39:39  [ Executor task launch worker for task 5:30447 ] - [ INFO ]  Finished task 5.0 in stage 0.0 (TID 5). 880 bytes result sent to driver
2021-01-04 21:39:39  [ dispatcher-event-loop-3:30449 ] - [ INFO ]  Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:39  [ Executor task launch worker for task 16:30450 ] - [ INFO ]  Running task 16.0 in stage 0.0 (TID 16)
2021-01-04 21:39:39  [ Executor task launch worker for task 16:30452 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:536870912+33554432
2021-01-04 21:39:39  [ task-result-getter-0:30455 ] - [ INFO ]  Finished task 5.0 in stage 0.0 (TID 5) in 27405 ms on localhost (executor driver) (1/56)
2021-01-04 21:39:39  [ Executor task launch worker for task 10:30658 ] - [ INFO ]  Finished task 10.0 in stage 0.0 (TID 10). 837 bytes result sent to driver
2021-01-04 21:39:39  [ dispatcher-event-loop-5:30659 ] - [ INFO ]  Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:39  [ Executor task launch worker for task 17:30660 ] - [ INFO ]  Running task 17.0 in stage 0.0 (TID 17)
2021-01-04 21:39:39  [ task-result-getter-1:30660 ] - [ INFO ]  Finished task 10.0 in stage 0.0 (TID 10) in 27609 ms on localhost (executor driver) (2/56)
2021-01-04 21:39:39  [ Executor task launch worker for task 17:30662 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:570425344+33554432
2021-01-04 21:39:40  [ Executor task launch worker for task 1:30877 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 837 bytes result sent to driver
2021-01-04 21:39:40  [ dispatcher-event-loop-7:30878 ] - [ INFO ]  Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:40  [ Executor task launch worker for task 18:30879 ] - [ INFO ]  Running task 18.0 in stage 0.0 (TID 18)
2021-01-04 21:39:40  [ task-result-getter-2:30879 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 27834 ms on localhost (executor driver) (3/56)
2021-01-04 21:39:40  [ Executor task launch worker for task 18:30881 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:603979776+33554432
2021-01-04 21:39:40  [ Executor task launch worker for task 15:31031 ] - [ INFO ]  Finished task 15.0 in stage 0.0 (TID 15). 837 bytes result sent to driver
2021-01-04 21:39:40  [ dispatcher-event-loop-9:31033 ] - [ INFO ]  Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, PROCESS_LOCAL, 7943 bytes)
2021-01-04 21:39:40  [ Executor task launch worker for task 19:31033 ] - [ INFO ]  Running task 19.0 in stage 0.0 (TID 19)
2021-01-04 21:39:40  [ task-result-getter-3:31033 ] - [ INFO ]  Finished task 15.0 in stage 0.0 (TID 15) in 27979 ms on localhost (executor driver) (4/56)
2021-01-04 21:39:40  [ Executor task launch worker for task 19:31035 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:637534208+33554432
2021-01-04 22:35:25  [ main:0 ] - [ WARN ]  Your hostname, liuwenyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.124.5 instead (on interface en0)
2021-01-04 22:35:25  [ main:1 ] - [ WARN ]  Set SPARK_LOCAL_IP if you need to bind to another address
2021-01-04 22:35:25  [ main:49 ] - [ INFO ]  Running Spark version 2.4.4
2021-01-04 22:35:25  [ main:367 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-01-04 22:35:25  [ main:596 ] - [ INFO ]  Submitted application: user_log
2021-01-04 22:35:26  [ main:692 ] - [ INFO ]  Changing view acls to: liuwenyi,root
2021-01-04 22:35:26  [ main:693 ] - [ INFO ]  Changing modify acls to: liuwenyi,root
2021-01-04 22:35:26  [ main:693 ] - [ INFO ]  Changing view acls groups to: 
2021-01-04 22:35:26  [ main:694 ] - [ INFO ]  Changing modify acls groups to: 
2021-01-04 22:35:26  [ main:694 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liuwenyi, root); groups with view permissions: Set(); users  with modify permissions: Set(liuwenyi, root); groups with modify permissions: Set()
2021-01-04 22:35:26  [ main:1137 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50354.
2021-01-04 22:35:26  [ main:1164 ] - [ INFO ]  Registering MapOutputTracker
2021-01-04 22:35:26  [ main:1186 ] - [ INFO ]  Registering BlockManagerMaster
2021-01-04 22:35:26  [ main:1190 ] - [ INFO ]  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-01-04 22:35:26  [ main:1190 ] - [ INFO ]  BlockManagerMasterEndpoint up
2021-01-04 22:35:26  [ main:1228 ] - [ INFO ]  Created local directory at /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/blockmgr-14e0aee2-c56c-4972-984b-d96a8bf1b79f
2021-01-04 22:35:26  [ main:1249 ] - [ INFO ]  MemoryStore started with capacity 2004.6 MB
2021-01-04 22:35:26  [ main:1265 ] - [ INFO ]  Registering OutputCommitCoordinator
2021-01-04 22:35:26  [ main:1353 ] - [ INFO ]  Logging initialized @2037ms
2021-01-04 22:35:26  [ main:1433 ] - [ INFO ]  jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-01-04 22:35:26  [ main:1452 ] - [ INFO ]  Started @2138ms
2021-01-04 22:35:26  [ main:1478 ] - [ INFO ]  Started ServerConnector@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 22:35:26  [ main:1479 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2021-01-04 22:35:26  [ main:1521 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@26fb628{/jobs,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1523 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4204541c{/jobs/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1525 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a62689d{/jobs/job,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1526 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1527 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3e2822{/stages,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1527 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@79e18e38{/stages/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1528 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@29a60c27{/stages/stage,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1530 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1ca25c47{/stages/stage/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1531 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fcacc0{/stages/pool,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1532 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@533b266e{/stages/pool/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1532 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6d1d4d7{/storage,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1533 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@89ff02e{/storage/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1535 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6865c751{/storage/rdd,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1537 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@62679465{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1539 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@6a988392{/environment,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1540 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@1d71006f{/environment/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1542 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5b6813df{/executors,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1544 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5f2606b{/executors/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1546 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2b58f754{/executors/threadDump,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1547 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@3ebff828{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1557 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@2552f2cb{/static,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1558 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@495083a0{/,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1559 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@5fd62371{/api,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1560 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@841e575{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1560 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@27a5328c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-01-04 22:35:26  [ main:1563 ] - [ INFO ]  Bound SparkUI to 0.0.0.0, and started at http://192.168.124.5:4040
2021-01-04 22:35:27  [ main:1660 ] - [ INFO ]  Starting executor ID driver on host localhost
2021-01-04 22:35:27  [ main:1730 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50355.
2021-01-04 22:35:27  [ main:1731 ] - [ INFO ]  Server created on 192.168.124.5:50355
2021-01-04 22:35:27  [ main:1732 ] - [ INFO ]  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-01-04 22:35:27  [ main:1755 ] - [ INFO ]  Registering BlockManager BlockManagerId(driver, 192.168.124.5, 50355, None)
2021-01-04 22:35:27  [ dispatcher-event-loop-10:1758 ] - [ INFO ]  Registering block manager 192.168.124.5:50355 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.124.5, 50355, None)
2021-01-04 22:35:27  [ main:1760 ] - [ INFO ]  Registered BlockManager BlockManagerId(driver, 192.168.124.5, 50355, None)
2021-01-04 22:35:27  [ main:1760 ] - [ INFO ]  Initialized BlockManager: BlockManagerId(driver, 192.168.124.5, 50355, None)
2021-01-04 22:35:27  [ main:1995 ] - [ INFO ]  Started o.s.j.s.ServletContextHandler@4aeaadc1{/metrics/json,null,AVAILABLE,@Spark}
2021-01-04 22:35:27  [ main:2506 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 2004.4 MB)
2021-01-04 22:35:28  [ main:2718 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 2004.4 MB)
2021-01-04 22:35:28  [ dispatcher-event-loop-12:2721 ] - [ INFO ]  Added broadcast_0_piece0 in memory on 192.168.124.5:50355 (size: 20.4 KB, free: 2004.6 MB)
2021-01-04 22:35:28  [ main:2724 ] - [ INFO ]  Created broadcast 0 from textFile at UserLog.scala:56
2021-01-04 22:35:28  [ main:2857 ] - [ INFO ]  Total input paths to process : 1
2021-01-04 22:35:28  [ main:2872 ] - [ INFO ]  Starting job: foreach at UserLog.scala:63
2021-01-04 22:35:28  [ dag-scheduler-event-loop:2898 ] - [ INFO ]  Got job 0 (foreach at UserLog.scala:63) with 56 output partitions
2021-01-04 22:35:28  [ dag-scheduler-event-loop:2899 ] - [ INFO ]  Final stage: ResultStage 0 (foreach at UserLog.scala:63)
2021-01-04 22:35:28  [ dag-scheduler-event-loop:2899 ] - [ INFO ]  Parents of final stage: List()
2021-01-04 22:35:28  [ dag-scheduler-event-loop:2901 ] - [ INFO ]  Missing parents: List()
2021-01-04 22:35:28  [ dag-scheduler-event-loop:2906 ] - [ INFO ]  Submitting ResultStage 0 (MapPartitionsRDD[3] at map at UserLog.scala:59), which has no missing parents
2021-01-04 22:35:28  [ dag-scheduler-event-loop:3024 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 2004.4 MB)
2021-01-04 22:35:28  [ dag-scheduler-event-loop:3026 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KB, free 2004.4 MB)
2021-01-04 22:35:28  [ dispatcher-event-loop-13:3027 ] - [ INFO ]  Added broadcast_1_piece0 in memory on 192.168.124.5:50355 (size: 2.6 KB, free: 2004.6 MB)
2021-01-04 22:35:28  [ dag-scheduler-event-loop:3028 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-01-04 22:35:28  [ dag-scheduler-event-loop:3041 ] - [ INFO ]  Submitting 56 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at UserLog.scala:59) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-01-04 22:35:28  [ dag-scheduler-event-loop:3043 ] - [ INFO ]  Adding task set 0.0 with 56 tasks
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3095 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3099 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3100 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3100 ] - [ INFO ]  Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3101 ] - [ INFO ]  Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3101 ] - [ INFO ]  Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3102 ] - [ INFO ]  Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3102 ] - [ INFO ]  Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3103 ] - [ INFO ]  Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3103 ] - [ INFO ]  Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3104 ] - [ INFO ]  Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3104 ] - [ INFO ]  Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3105 ] - [ INFO ]  Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3106 ] - [ INFO ]  Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3108 ] - [ INFO ]  Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ dispatcher-event-loop-14:3110 ] - [ INFO ]  Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:28  [ Executor task launch worker for task 7:3117 ] - [ INFO ]  Running task 7.0 in stage 0.0 (TID 7)
2021-01-04 22:35:28  [ Executor task launch worker for task 9:3120 ] - [ INFO ]  Running task 9.0 in stage 0.0 (TID 9)
2021-01-04 22:35:28  [ Executor task launch worker for task 14:3121 ] - [ INFO ]  Running task 14.0 in stage 0.0 (TID 14)
2021-01-04 22:35:28  [ Executor task launch worker for task 1:3122 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2021-01-04 22:35:28  [ Executor task launch worker for task 2:3122 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2021-01-04 22:35:28  [ Executor task launch worker for task 8:3123 ] - [ INFO ]  Running task 8.0 in stage 0.0 (TID 8)
2021-01-04 22:35:28  [ Executor task launch worker for task 15:3124 ] - [ INFO ]  Running task 15.0 in stage 0.0 (TID 15)
2021-01-04 22:35:28  [ Executor task launch worker for task 5:3125 ] - [ INFO ]  Running task 5.0 in stage 0.0 (TID 5)
2021-01-04 22:35:28  [ Executor task launch worker for task 6:3125 ] - [ INFO ]  Running task 6.0 in stage 0.0 (TID 6)
2021-01-04 22:35:28  [ Executor task launch worker for task 3:3126 ] - [ INFO ]  Running task 3.0 in stage 0.0 (TID 3)
2021-01-04 22:35:28  [ Executor task launch worker for task 4:3127 ] - [ INFO ]  Running task 4.0 in stage 0.0 (TID 4)
2021-01-04 22:35:28  [ Executor task launch worker for task 10:3128 ] - [ INFO ]  Running task 10.0 in stage 0.0 (TID 10)
2021-01-04 22:35:28  [ Executor task launch worker for task 11:3129 ] - [ INFO ]  Running task 11.0 in stage 0.0 (TID 11)
2021-01-04 22:35:28  [ Executor task launch worker for task 0:3130 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2021-01-04 22:35:28  [ Executor task launch worker for task 12:3130 ] - [ INFO ]  Running task 12.0 in stage 0.0 (TID 12)
2021-01-04 22:35:28  [ Executor task launch worker for task 13:3131 ] - [ INFO ]  Running task 13.0 in stage 0.0 (TID 13)
2021-01-04 22:35:28  [ Executor task launch worker for task 3:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:100663296+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 11:3208 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:369098752+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 4:3208 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:134217728+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 15:3208 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:503316480+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 5:3208 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:167772160+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 10:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:335544320+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 1:3208 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:33554432+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 8:3208 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:268435456+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 0:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:0+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 13:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:436207616+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 9:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:301989888+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 2:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:67108864+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 12:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:402653184+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 14:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:469762048+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 7:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:234881024+33554432
2021-01-04 22:35:28  [ Executor task launch worker for task 6:3207 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:201326592+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 1:6264 ] - [ INFO ]  Block taskresult_1 stored as bytes in memory (estimated size 1112.9 KB, free 2003.3 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6267 ] - [ INFO ]  Added taskresult_1 in memory on 192.168.124.5:50355 (size: 1112.9 KB, free: 2003.5 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 1:6269 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 1139581 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 7:6272 ] - [ INFO ]  Block taskresult_7 stored as bytes in memory (estimated size 1117.0 KB, free 2001.1 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 15:6272 ] - [ INFO ]  Block taskresult_15 stored as bytes in memory (estimated size 1150.6 KB, free 2001.1 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-0:6274 ] - [ INFO ]  Added taskresult_7 in memory on 192.168.124.5:50355 (size: 1117.0 KB, free: 2002.4 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-0:6274 ] - [ INFO ]  Added taskresult_15 in memory on 192.168.124.5:50355 (size: 1150.6 KB, free: 2001.3 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 7:6274 ] - [ INFO ]  Finished task 7.0 in stage 0.0 (TID 7). 1143762 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 15:6274 ] - [ INFO ]  Finished task 15.0 in stage 0.0 (TID 15). 1178173 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 9:6275 ] - [ INFO ]  Block taskresult_9 stored as bytes in memory (estimated size 1170.7 KB, free 1999.9 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-2:6277 ] - [ INFO ]  Added taskresult_9 in memory on 192.168.124.5:50355 (size: 1170.7 KB, free: 2000.1 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 9:6277 ] - [ INFO ]  Finished task 9.0 in stage 0.0 (TID 9). 1198823 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ dispatcher-event-loop-3:6281 ] - [ INFO ]  Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-3:6282 ] - [ INFO ]  Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 16:6283 ] - [ INFO ]  Running task 16.0 in stage 0.0 (TID 16)
2021-01-04 22:35:31  [ Executor task launch worker for task 17:6283 ] - [ INFO ]  Running task 17.0 in stage 0.0 (TID 17)
2021-01-04 22:35:31  [ dispatcher-event-loop-3:6294 ] - [ INFO ]  Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-3:6301 ] - [ INFO ]  Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 18:6303 ] - [ INFO ]  Running task 18.0 in stage 0.0 (TID 18)
2021-01-04 22:35:31  [ Executor task launch worker for task 19:6303 ] - [ INFO ]  Running task 19.0 in stage 0.0 (TID 19)
2021-01-04 22:35:31  [ Executor task launch worker for task 18:6309 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:603979776+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 16:6313 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:536870912+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 19:6319 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:637534208+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 17:6320 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:570425344+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 6:6338 ] - [ INFO ]  Block taskresult_6 stored as bytes in memory (estimated size 1165.9 KB, free 1997.7 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 12:6339 ] - [ INFO ]  Block taskresult_12 stored as bytes in memory (estimated size 1115.8 KB, free 1997.7 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 4:6340 ] - [ INFO ]  Block taskresult_4 stored as bytes in memory (estimated size 1158.5 KB, free 1996.6 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 3:6341 ] - [ INFO ]  Block taskresult_3 stored as bytes in memory (estimated size 1126.7 KB, free 1995.5 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6343 ] - [ INFO ]  Added taskresult_6 in memory on 192.168.124.5:50355 (size: 1165.9 KB, free: 1999.0 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 6:6344 ] - [ INFO ]  Finished task 6.0 in stage 0.0 (TID 6). 1193930 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6344 ] - [ INFO ]  Added taskresult_12 in memory on 192.168.124.5:50355 (size: 1115.8 KB, free: 1997.9 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6344 ] - [ INFO ]  Added taskresult_4 in memory on 192.168.124.5:50355 (size: 1158.5 KB, free: 1996.8 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-4:6345 ] - [ INFO ]  Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6345 ] - [ INFO ]  Added taskresult_3 in memory on 192.168.124.5:50355 (size: 1126.7 KB, free: 1995.7 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 20:6350 ] - [ INFO ]  Running task 20.0 in stage 0.0 (TID 20)
2021-01-04 22:35:31  [ Executor task launch worker for task 12:6351 ] - [ INFO ]  Finished task 12.0 in stage 0.0 (TID 12). 1142578 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 3:6352 ] - [ INFO ]  Finished task 3.0 in stage 0.0 (TID 3). 1153736 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 0:6352 ] - [ INFO ]  Block taskresult_0 stored as bytes in memory (estimated size 1168.9 KB, free 1994.3 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 20:6353 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:671088640+33554432
2021-01-04 22:35:31  [ dispatcher-event-loop-6:6353 ] - [ INFO ]  Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-6:6354 ] - [ INFO ]  Starting task 22.0 in stage 0.0 (TID 22, localhost, executor driver, partition 22, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 21:6354 ] - [ INFO ]  Running task 21.0 in stage 0.0 (TID 21)
2021-01-04 22:35:31  [ Executor task launch worker for task 4:6353 ] - [ INFO ]  Finished task 4.0 in stage 0.0 (TID 4). 1186289 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 22:6354 ] - [ INFO ]  Running task 22.0 in stage 0.0 (TID 22)
2021-01-04 22:35:31  [ dispatcher-event-loop-8:6354 ] - [ INFO ]  Added taskresult_0 in memory on 192.168.124.5:50355 (size: 1168.9 KB, free: 1994.5 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-10:6355 ] - [ INFO ]  Starting task 23.0 in stage 0.0 (TID 23, localhost, executor driver, partition 23, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 21:6356 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:704643072+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 0:6356 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 1196967 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 23:6357 ] - [ INFO ]  Running task 23.0 in stage 0.0 (TID 23)
2021-01-04 22:35:31  [ Executor task launch worker for task 22:6356 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:738197504+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 23:6358 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:771751936+33554432
2021-01-04 22:35:31  [ dispatcher-event-loop-3:6359 ] - [ INFO ]  Starting task 24.0 in stage 0.0 (TID 24, localhost, executor driver, partition 24, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 24:6360 ] - [ INFO ]  Running task 24.0 in stage 0.0 (TID 24)
2021-01-04 22:35:31  [ Executor task launch worker for task 24:6361 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:805306368+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 14:6364 ] - [ INFO ]  Block taskresult_14 stored as bytes in memory (estimated size 1128.4 KB, free 1993.2 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-9:6365 ] - [ INFO ]  Added taskresult_14 in memory on 192.168.124.5:50355 (size: 1128.4 KB, free: 1993.4 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 14:6365 ] - [ INFO ]  Finished task 14.0 in stage 0.0 (TID 14). 1155436 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ dispatcher-event-loop-1:6368 ] - [ INFO ]  Starting task 25.0 in stage 0.0 (TID 25, localhost, executor driver, partition 25, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 11:6368 ] - [ INFO ]  Block taskresult_11 stored as bytes in memory (estimated size 1118.5 KB, free 1991.0 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 2:6368 ] - [ INFO ]  Block taskresult_2 stored as bytes in memory (estimated size 1195.2 KB, free 1992.0 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 5:6369 ] - [ INFO ]  Block taskresult_5 stored as bytes in memory (estimated size 1133.5 KB, free 1989.8 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 25:6370 ] - [ INFO ]  Running task 25.0 in stage 0.0 (TID 25)
2021-01-04 22:35:31  [ dispatcher-event-loop-0:6370 ] - [ INFO ]  Added taskresult_11 in memory on 192.168.124.5:50355 (size: 1118.5 KB, free: 1992.3 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 13:6370 ] - [ INFO ]  Block taskresult_13 stored as bytes in memory (estimated size 1187.7 KB, free 1988.7 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-0:6371 ] - [ INFO ]  Added taskresult_2 in memory on 192.168.124.5:50355 (size: 1195.2 KB, free: 1991.2 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-0:6371 ] - [ INFO ]  Added taskresult_5 in memory on 192.168.124.5:50355 (size: 1133.5 KB, free: 1990.1 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 25:6371 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:838860800+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 11:6372 ] - [ INFO ]  Finished task 11.0 in stage 0.0 (TID 11). 1145319 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 2:6372 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2). 1223889 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 5:6372 ] - [ INFO ]  Finished task 5.0 in stage 0.0 (TID 5). 1160697 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6373 ] - [ INFO ]  Starting task 26.0 in stage 0.0 (TID 26, localhost, executor driver, partition 26, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-5:6373 ] - [ INFO ]  Added taskresult_13 in memory on 192.168.124.5:50355 (size: 1187.7 KB, free: 1988.9 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 8:6374 ] - [ INFO ]  Block taskresult_8 stored as bytes in memory (estimated size 1142.8 KB, free 1987.6 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 13:6374 ] - [ INFO ]  Finished task 13.0 in stage 0.0 (TID 13). 1216236 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 26:6377 ] - [ INFO ]  Running task 26.0 in stage 0.0 (TID 26)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6377 ] - [ INFO ]  Starting task 27.0 in stage 0.0 (TID 27, localhost, executor driver, partition 27, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 27:6378 ] - [ INFO ]  Running task 27.0 in stage 0.0 (TID 27)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6378 ] - [ INFO ]  Starting task 28.0 in stage 0.0 (TID 28, localhost, executor driver, partition 28, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-3:6378 ] - [ INFO ]  Added taskresult_8 in memory on 192.168.124.5:50355 (size: 1142.8 KB, free: 1987.8 MB)
2021-01-04 22:35:31  [ dispatcher-event-loop-15:6378 ] - [ INFO ]  Starting task 29.0 in stage 0.0 (TID 29, localhost, executor driver, partition 29, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 28:6379 ] - [ INFO ]  Running task 28.0 in stage 0.0 (TID 28)
2021-01-04 22:35:31  [ Executor task launch worker for task 26:6379 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:872415232+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 8:6379 ] - [ INFO ]  Finished task 8.0 in stage 0.0 (TID 8). 1170253 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ Executor task launch worker for task 29:6379 ] - [ INFO ]  Running task 29.0 in stage 0.0 (TID 29)
2021-01-04 22:35:31  [ Executor task launch worker for task 27:6380 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:905969664+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 28:6380 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:939524096+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 10:6379 ] - [ INFO ]  Block taskresult_10 stored as bytes in memory (estimated size 1165.7 KB, free 1986.4 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 29:6381 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:973078528+33554432
2021-01-04 22:35:31  [ dispatcher-event-loop-13:6380 ] - [ INFO ]  Starting task 30.0 in stage 0.0 (TID 30, localhost, executor driver, partition 30, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ dispatcher-event-loop-9:6382 ] - [ INFO ]  Added taskresult_10 in memory on 192.168.124.5:50355 (size: 1165.7 KB, free: 1986.6 MB)
2021-01-04 22:35:31  [ Executor task launch worker for task 30:6383 ] - [ INFO ]  Running task 30.0 in stage 0.0 (TID 30)
2021-01-04 22:35:31  [ Executor task launch worker for task 10:6384 ] - [ INFO ]  Finished task 10.0 in stage 0.0 (TID 10). 1193712 bytes result sent via BlockManager)
2021-01-04 22:35:31  [ dispatcher-event-loop-0:6386 ] - [ INFO ]  Starting task 31.0 in stage 0.0 (TID 31, localhost, executor driver, partition 31, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:31  [ Executor task launch worker for task 30:6386 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1006632960+33554432
2021-01-04 22:35:31  [ Executor task launch worker for task 31:6386 ] - [ INFO ]  Running task 31.0 in stage 0.0 (TID 31)
2021-01-04 22:35:31  [ Executor task launch worker for task 31:6397 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1040187392+33554432
2021-01-04 22:35:31  [ task-result-getter-0:6478 ] - [ INFO ]  Successfully created connection to /192.168.124.5:50355 after 128 ms (0 ms spent in bootstraps)
2021-01-04 22:35:32  [ task-result-getter-1:6941 ] - [ INFO ]  Finished task 7.0 in stage 0.0 (TID 7) in 3837 ms on localhost (executor driver) (1/56)
2021-01-04 22:35:32  [ task-result-getter-3:6947 ] - [ INFO ]  Finished task 15.0 in stage 0.0 (TID 15) in 3839 ms on localhost (executor driver) (2/56)
2021-01-04 22:35:32  [ task-result-getter-0:6948 ] - [ INFO ]  Finished task 9.0 in stage 0.0 (TID 9) in 3845 ms on localhost (executor driver) (3/56)
2021-01-04 22:35:32  [ task-result-getter-2:6949 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 3851 ms on localhost (executor driver) (4/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-1:6959 ] - [ INFO ]  Removed taskresult_15 on 192.168.124.5:50355 in memory (size: 1150.6 KB, free: 1987.8 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-1:6970 ] - [ INFO ]  Removed taskresult_9 on 192.168.124.5:50355 in memory (size: 1170.7 KB, free: 1988.9 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-1:6971 ] - [ INFO ]  Removed taskresult_1 on 192.168.124.5:50355 in memory (size: 1112.9 KB, free: 1990.0 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-1:6972 ] - [ INFO ]  Removed taskresult_7 on 192.168.124.5:50355 in memory (size: 1117.0 KB, free: 1991.1 MB)
2021-01-04 22:35:32  [ task-result-getter-1:7025 ] - [ INFO ]  Finished task 6.0 in stage 0.0 (TID 6) in 3924 ms on localhost (executor driver) (5/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-8:7026 ] - [ INFO ]  Removed taskresult_6 on 192.168.124.5:50355 in memory (size: 1165.9 KB, free: 1992.2 MB)
2021-01-04 22:35:32  [ task-result-getter-0:7039 ] - [ INFO ]  Finished task 3.0 in stage 0.0 (TID 3) in 3939 ms on localhost (executor driver) (6/56)
2021-01-04 22:35:32  [ task-result-getter-2:7039 ] - [ INFO ]  Finished task 4.0 in stage 0.0 (TID 4) in 3939 ms on localhost (executor driver) (7/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-14:7040 ] - [ INFO ]  Removed taskresult_3 on 192.168.124.5:50355 in memory (size: 1126.7 KB, free: 1993.3 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-14:7041 ] - [ INFO ]  Removed taskresult_4 on 192.168.124.5:50355 in memory (size: 1158.5 KB, free: 1994.5 MB)
2021-01-04 22:35:32  [ task-result-getter-3:7045 ] - [ INFO ]  Finished task 12.0 in stage 0.0 (TID 12) in 3941 ms on localhost (executor driver) (8/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-4:7046 ] - [ INFO ]  Removed taskresult_12 on 192.168.124.5:50355 in memory (size: 1115.8 KB, free: 1995.6 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-10:7090 ] - [ INFO ]  Removed taskresult_0 on 192.168.124.5:50355 in memory (size: 1168.9 KB, free: 1996.7 MB)
2021-01-04 22:35:32  [ task-result-getter-1:7095 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 4017 ms on localhost (executor driver) (9/56)
2021-01-04 22:35:32  [ task-result-getter-2:7115 ] - [ INFO ]  Finished task 11.0 in stage 0.0 (TID 11) in 4011 ms on localhost (executor driver) (10/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-11:7116 ] - [ INFO ]  Removed taskresult_11 on 192.168.124.5:50355 in memory (size: 1118.5 KB, free: 1997.8 MB)
2021-01-04 22:35:32  [ task-result-getter-0:7124 ] - [ INFO ]  Finished task 14.0 in stage 0.0 (TID 14) in 4018 ms on localhost (executor driver) (11/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-9:7125 ] - [ INFO ]  Removed taskresult_14 on 192.168.124.5:50355 in memory (size: 1128.4 KB, free: 1998.9 MB)
2021-01-04 22:35:32  [ task-result-getter-3:7143 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2) in 4044 ms on localhost (executor driver) (12/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-1:7144 ] - [ INFO ]  Removed taskresult_2 on 192.168.124.5:50355 in memory (size: 1195.2 KB, free: 2000.1 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-10:7185 ] - [ INFO ]  Removed taskresult_13 on 192.168.124.5:50355 in memory (size: 1187.7 KB, free: 2001.2 MB)
2021-01-04 22:35:32  [ dispatcher-event-loop-15:7186 ] - [ INFO ]  Removed taskresult_5 on 192.168.124.5:50355 in memory (size: 1133.5 KB, free: 2002.3 MB)
2021-01-04 22:35:32  [ task-result-getter-1:7185 ] - [ INFO ]  Finished task 13.0 in stage 0.0 (TID 13) in 4079 ms on localhost (executor driver) (13/56)
2021-01-04 22:35:32  [ task-result-getter-2:7190 ] - [ INFO ]  Finished task 5.0 in stage 0.0 (TID 5) in 4089 ms on localhost (executor driver) (14/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-5:7210 ] - [ INFO ]  Removed taskresult_8 on 192.168.124.5:50355 in memory (size: 1142.8 KB, free: 2003.4 MB)
2021-01-04 22:35:32  [ task-result-getter-0:7259 ] - [ INFO ]  Finished task 8.0 in stage 0.0 (TID 8) in 4157 ms on localhost (executor driver) (15/56)
2021-01-04 22:35:32  [ task-result-getter-3:7262 ] - [ INFO ]  Finished task 10.0 in stage 0.0 (TID 10) in 4159 ms on localhost (executor driver) (16/56)
2021-01-04 22:35:32  [ dispatcher-event-loop-9:7263 ] - [ INFO ]  Removed taskresult_10 on 192.168.124.5:50355 in memory (size: 1165.7 KB, free: 2004.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 31:7816 ] - [ INFO ]  Block taskresult_31 stored as bytes in memory (estimated size 1139.9 KB, free 2003.3 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-2:7817 ] - [ INFO ]  Added taskresult_31 in memory on 192.168.124.5:50355 (size: 1139.9 KB, free: 2003.5 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 31:7821 ] - [ INFO ]  Finished task 31.0 in stage 0.0 (TID 31). 1167258 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-0:7823 ] - [ INFO ]  Starting task 32.0 in stage 0.0 (TID 32, localhost, executor driver, partition 32, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 32:7834 ] - [ INFO ]  Running task 32.0 in stage 0.0 (TID 32)
2021-01-04 22:35:33  [ task-result-getter-1:7853 ] - [ INFO ]  Finished task 31.0 in stage 0.0 (TID 31) in 1468 ms on localhost (executor driver) (17/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-8:7857 ] - [ INFO ]  Removed taskresult_31 on 192.168.124.5:50355 in memory (size: 1139.9 KB, free: 2004.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 32:7858 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1073741824+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 19:7868 ] - [ INFO ]  Block taskresult_19 stored as bytes in memory (estimated size 1129.7 KB, free 2003.3 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-10:7870 ] - [ INFO ]  Added taskresult_19 in memory on 192.168.124.5:50355 (size: 1129.7 KB, free: 2003.5 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 19:7871 ] - [ INFO ]  Finished task 19.0 in stage 0.0 (TID 19). 1156816 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:7873 ] - [ INFO ]  Starting task 33.0 in stage 0.0 (TID 33, localhost, executor driver, partition 33, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 33:7874 ] - [ INFO ]  Running task 33.0 in stage 0.0 (TID 33)
2021-01-04 22:35:33  [ Executor task launch worker for task 33:7877 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1107296256+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 21:7914 ] - [ INFO ]  Block taskresult_21 stored as bytes in memory (estimated size 1141.1 KB, free 2002.1 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-11:7916 ] - [ INFO ]  Added taskresult_21 in memory on 192.168.124.5:50355 (size: 1141.1 KB, free: 2002.4 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 21:7918 ] - [ INFO ]  Finished task 21.0 in stage 0.0 (TID 21). 1168463 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ task-result-getter-2:7918 ] - [ INFO ]  Finished task 19.0 in stage 0.0 (TID 19) in 1617 ms on localhost (executor driver) (18/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:7919 ] - [ INFO ]  Starting task 34.0 in stage 0.0 (TID 34, localhost, executor driver, partition 34, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 34:7921 ] - [ INFO ]  Running task 34.0 in stage 0.0 (TID 34)
2021-01-04 22:35:33  [ Executor task launch worker for task 34:7923 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1140850688+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 18:7923 ] - [ INFO ]  Block taskresult_18 stored as bytes in memory (estimated size 1136.4 KB, free 2002.1 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-2:7924 ] - [ INFO ]  Removed taskresult_19 on 192.168.124.5:50355 in memory (size: 1129.7 KB, free: 2003.5 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-2:7925 ] - [ INFO ]  Added taskresult_18 in memory on 192.168.124.5:50355 (size: 1136.4 KB, free: 2002.4 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 18:7928 ] - [ INFO ]  Finished task 18.0 in stage 0.0 (TID 18). 1163626 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-1:7930 ] - [ INFO ]  Starting task 35.0 in stage 0.0 (TID 35, localhost, executor driver, partition 35, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 35:7931 ] - [ INFO ]  Running task 35.0 in stage 0.0 (TID 35)
2021-01-04 22:35:33  [ Executor task launch worker for task 25:7933 ] - [ INFO ]  Block taskresult_25 stored as bytes in memory (estimated size 1129.6 KB, free 2001.0 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 35:7933 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1174405120+33554432
2021-01-04 22:35:33  [ dispatcher-event-loop-8:7937 ] - [ INFO ]  Added taskresult_25 in memory on 192.168.124.5:50355 (size: 1129.6 KB, free: 2001.3 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 26:7937 ] - [ INFO ]  Block taskresult_26 stored as bytes in memory (estimated size 1164.2 KB, free 1998.8 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 25:7938 ] - [ INFO ]  Finished task 25.0 in stage 0.0 (TID 25). 1156708 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 17:7939 ] - [ INFO ]  Block taskresult_17 stored as bytes in memory (estimated size 1163.6 KB, free 1997.7 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-10:7940 ] - [ INFO ]  Starting task 36.0 in stage 0.0 (TID 36, localhost, executor driver, partition 36, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:7940 ] - [ INFO ]  Added taskresult_26 in memory on 192.168.124.5:50355 (size: 1164.2 KB, free: 2000.1 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 36:7942 ] - [ INFO ]  Running task 36.0 in stage 0.0 (TID 36)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:7942 ] - [ INFO ]  Added taskresult_17 in memory on 192.168.124.5:50355 (size: 1163.6 KB, free: 1999.0 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 16:7942 ] - [ INFO ]  Block taskresult_16 stored as bytes in memory (estimated size 1136.2 KB, free 1996.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 26:7942 ] - [ INFO ]  Finished task 26.0 in stage 0.0 (TID 26). 1192146 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 27:7944 ] - [ INFO ]  Block taskresult_27 stored as bytes in memory (estimated size 1099.0 KB, free 2000.0 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 36:7944 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1207959552+33554432
2021-01-04 22:35:33  [ dispatcher-event-loop-5:7945 ] - [ INFO ]  Starting task 37.0 in stage 0.0 (TID 37, localhost, executor driver, partition 37, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 17:7946 ] - [ INFO ]  Finished task 17.0 in stage 0.0 (TID 17). 1191502 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 37:7946 ] - [ INFO ]  Running task 37.0 in stage 0.0 (TID 37)
2021-01-04 22:35:33  [ dispatcher-event-loop-9:7949 ] - [ INFO ]  Starting task 38.0 in stage 0.0 (TID 38, localhost, executor driver, partition 38, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 37:7950 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1241513984+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 38:7951 ] - [ INFO ]  Running task 38.0 in stage 0.0 (TID 38)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:7952 ] - [ INFO ]  Added taskresult_16 in memory on 192.168.124.5:50355 (size: 1136.2 KB, free: 1997.9 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:7953 ] - [ INFO ]  Added taskresult_27 in memory on 192.168.124.5:50355 (size: 1099.0 KB, free: 1996.8 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 16:7953 ] - [ INFO ]  Finished task 16.0 in stage 0.0 (TID 16). 1163482 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 38:7954 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1275068416+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 27:7955 ] - [ INFO ]  Finished task 27.0 in stage 0.0 (TID 27). 1125356 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-1:7956 ] - [ INFO ]  Starting task 39.0 in stage 0.0 (TID 39, localhost, executor driver, partition 39, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 39:7958 ] - [ INFO ]  Running task 39.0 in stage 0.0 (TID 39)
2021-01-04 22:35:33  [ Executor task launch worker for task 29:7958 ] - [ INFO ]  Block taskresult_29 stored as bytes in memory (estimated size 1135.3 KB, free 1995.5 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-1:7959 ] - [ INFO ]  Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 39:7961 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1308622848+33554432
2021-01-04 22:35:33  [ dispatcher-event-loop-1:7961 ] - [ INFO ]  Added taskresult_29 in memory on 192.168.124.5:50355 (size: 1135.3 KB, free: 1995.7 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 28:7962 ] - [ INFO ]  Block taskresult_28 stored as bytes in memory (estimated size 1199.4 KB, free 1994.3 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 40:7962 ] - [ INFO ]  Running task 40.0 in stage 0.0 (TID 40)
2021-01-04 22:35:33  [ Executor task launch worker for task 29:7962 ] - [ INFO ]  Finished task 29.0 in stage 0.0 (TID 29). 1162518 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 40:7963 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1342177280+33554432
2021-01-04 22:35:33  [ dispatcher-event-loop-10:7964 ] - [ INFO ]  Starting task 41.0 in stage 0.0 (TID 41, localhost, executor driver, partition 41, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ dispatcher-event-loop-10:7965 ] - [ INFO ]  Added taskresult_28 in memory on 192.168.124.5:50355 (size: 1199.4 KB, free: 1994.5 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 41:7967 ] - [ INFO ]  Running task 41.0 in stage 0.0 (TID 41)
2021-01-04 22:35:33  [ Executor task launch worker for task 28:7968 ] - [ INFO ]  Finished task 28.0 in stage 0.0 (TID 28). 1228231 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 41:7968 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1375731712+33554432
2021-01-04 22:35:33  [ dispatcher-event-loop-9:7981 ] - [ INFO ]  Removed taskresult_21 on 192.168.124.5:50355 in memory (size: 1141.1 KB, free: 1995.6 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-9:7981 ] - [ INFO ]  Removed taskresult_18 on 192.168.124.5:50355 in memory (size: 1136.4 KB, free: 1996.7 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 22:7984 ] - [ INFO ]  Block taskresult_22 stored as bytes in memory (estimated size 1132.3 KB, free 1995.4 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:7984 ] - [ INFO ]  Starting task 42.0 in stage 0.0 (TID 42, localhost, executor driver, partition 42, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ task-result-getter-3:7985 ] - [ INFO ]  Finished task 18.0 in stage 0.0 (TID 18) in 1702 ms on localhost (executor driver) (19/56)
2021-01-04 22:35:33  [ task-result-getter-0:7985 ] - [ INFO ]  Finished task 21.0 in stage 0.0 (TID 21) in 1633 ms on localhost (executor driver) (20/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:7986 ] - [ INFO ]  Added taskresult_22 in memory on 192.168.124.5:50355 (size: 1132.3 KB, free: 1995.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 23:7986 ] - [ INFO ]  Block taskresult_23 stored as bytes in memory (estimated size 1137.6 KB, free 1994.3 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-10:7990 ] - [ INFO ]  Added taskresult_23 in memory on 192.168.124.5:50355 (size: 1137.6 KB, free: 1994.5 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 42:7989 ] - [ INFO ]  Running task 42.0 in stage 0.0 (TID 42)
2021-01-04 22:35:33  [ task-result-getter-1:7989 ] - [ INFO ]  Finished task 25.0 in stage 0.0 (TID 25) in 1621 ms on localhost (executor driver) (21/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-10:7991 ] - [ INFO ]  Removed taskresult_25 on 192.168.124.5:50355 in memory (size: 1129.6 KB, free: 1995.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 22:7989 ] - [ INFO ]  Finished task 22.0 in stage 0.0 (TID 22). 1159464 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ Executor task launch worker for task 23:7992 ] - [ INFO ]  Finished task 23.0 in stage 0.0 (TID 23). 1164938 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-11:7995 ] - [ INFO ]  Starting task 43.0 in stage 0.0 (TID 43, localhost, executor driver, partition 43, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 43:8005 ] - [ INFO ]  Running task 43.0 in stage 0.0 (TID 43)
2021-01-04 22:35:33  [ Executor task launch worker for task 42:8006 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1409286144+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 43:8006 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1442840576+33554432
2021-01-04 22:35:33  [ dispatcher-event-loop-11:8007 ] - [ INFO ]  Starting task 44.0 in stage 0.0 (TID 44, localhost, executor driver, partition 44, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 44:8007 ] - [ INFO ]  Running task 44.0 in stage 0.0 (TID 44)
2021-01-04 22:35:33  [ Executor task launch worker for task 44:8010 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1476395008+33554432
2021-01-04 22:35:33  [ task-result-getter-2:8010 ] - [ INFO ]  Finished task 26.0 in stage 0.0 (TID 26) in 1637 ms on localhost (executor driver) (22/56)
2021-01-04 22:35:33  [ Executor task launch worker for task 20:8010 ] - [ INFO ]  Block taskresult_20 stored as bytes in memory (estimated size 1182.0 KB, free 1993.1 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 30:8012 ] - [ INFO ]  Block taskresult_30 stored as bytes in memory (estimated size 1147.9 KB, free 1994.3 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:8016 ] - [ INFO ]  Removed taskresult_26 on 192.168.124.5:50355 in memory (size: 1164.2 KB, free: 1996.8 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 24:8017 ] - [ INFO ]  Block taskresult_24 stored as bytes in memory (estimated size 1183.7 KB, free 1993.1 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:8017 ] - [ INFO ]  Added taskresult_20 in memory on 192.168.124.5:50355 (size: 1182.0 KB, free: 1995.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 20:8017 ] - [ INFO ]  Finished task 20.0 in stage 0.0 (TID 20). 1210388 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:8018 ] - [ INFO ]  Added taskresult_30 in memory on 192.168.124.5:50355 (size: 1147.9 KB, free: 1994.5 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 30:8018 ] - [ INFO ]  Finished task 30.0 in stage 0.0 (TID 30). 1175494 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-8:8019 ] - [ INFO ]  Added taskresult_24 in memory on 192.168.124.5:50355 (size: 1183.7 KB, free: 1993.3 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:8019 ] - [ INFO ]  Starting task 45.0 in stage 0.0 (TID 45, localhost, executor driver, partition 45, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:8019 ] - [ INFO ]  Starting task 46.0 in stage 0.0 (TID 46, localhost, executor driver, partition 46, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 46:8020 ] - [ INFO ]  Running task 46.0 in stage 0.0 (TID 46)
2021-01-04 22:35:33  [ Executor task launch worker for task 24:8021 ] - [ INFO ]  Finished task 24.0 in stage 0.0 (TID 24). 1212067 bytes result sent via BlockManager)
2021-01-04 22:35:33  [ dispatcher-event-loop-14:8021 ] - [ INFO ]  Starting task 47.0 in stage 0.0 (TID 47, localhost, executor driver, partition 47, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:33  [ Executor task launch worker for task 47:8022 ] - [ INFO ]  Running task 47.0 in stage 0.0 (TID 47)
2021-01-04 22:35:33  [ Executor task launch worker for task 46:8023 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1543503872+33554432
2021-01-04 22:35:33  [ Executor task launch worker for task 47:8024 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1577058304+33554432
2021-01-04 22:35:33  [ task-result-getter-0:8025 ] - [ INFO ]  Finished task 16.0 in stage 0.0 (TID 16) in 1745 ms on localhost (executor driver) (23/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-11:8026 ] - [ INFO ]  Removed taskresult_16 on 192.168.124.5:50355 in memory (size: 1136.2 KB, free: 1994.4 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 45:8036 ] - [ INFO ]  Running task 45.0 in stage 0.0 (TID 45)
2021-01-04 22:35:33  [ task-result-getter-3:8041 ] - [ INFO ]  Finished task 17.0 in stage 0.0 (TID 17) in 1759 ms on localhost (executor driver) (24/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-3:8044 ] - [ INFO ]  Removed taskresult_17 on 192.168.124.5:50355 in memory (size: 1163.6 KB, free: 1995.6 MB)
2021-01-04 22:35:33  [ Executor task launch worker for task 45:8054 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1509949440+33554432
2021-01-04 22:35:33  [ task-result-getter-1:8087 ] - [ INFO ]  Finished task 27.0 in stage 0.0 (TID 27) in 1709 ms on localhost (executor driver) (25/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-8:8089 ] - [ INFO ]  Removed taskresult_27 on 192.168.124.5:50355 in memory (size: 1099.0 KB, free: 1996.6 MB)
2021-01-04 22:35:33  [ task-result-getter-0:8111 ] - [ INFO ]  Finished task 28.0 in stage 0.0 (TID 28) in 1732 ms on localhost (executor driver) (26/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-10:8114 ] - [ INFO ]  Removed taskresult_28 on 192.168.124.5:50355 in memory (size: 1199.4 KB, free: 1997.8 MB)
2021-01-04 22:35:33  [ task-result-getter-3:8118 ] - [ INFO ]  Finished task 23.0 in stage 0.0 (TID 23) in 1763 ms on localhost (executor driver) (27/56)
2021-01-04 22:35:33  [ task-result-getter-2:8128 ] - [ INFO ]  Finished task 29.0 in stage 0.0 (TID 29) in 1750 ms on localhost (executor driver) (28/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-6:8132 ] - [ INFO ]  Removed taskresult_23 on 192.168.124.5:50355 in memory (size: 1137.6 KB, free: 1998.9 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-6:8134 ] - [ INFO ]  Removed taskresult_29 on 192.168.124.5:50355 in memory (size: 1135.3 KB, free: 2000.0 MB)
2021-01-04 22:35:33  [ task-result-getter-1:8164 ] - [ INFO ]  Finished task 22.0 in stage 0.0 (TID 22) in 1811 ms on localhost (executor driver) (29/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-13:8166 ] - [ INFO ]  Removed taskresult_22 on 192.168.124.5:50355 in memory (size: 1132.3 KB, free: 2001.1 MB)
2021-01-04 22:35:33  [ task-result-getter-2:8199 ] - [ INFO ]  Finished task 24.0 in stage 0.0 (TID 24) in 1840 ms on localhost (executor driver) (30/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-14:8201 ] - [ INFO ]  Removed taskresult_24 on 192.168.124.5:50355 in memory (size: 1183.7 KB, free: 2002.3 MB)
2021-01-04 22:35:33  [ task-result-getter-0:8206 ] - [ INFO ]  Finished task 20.0 in stage 0.0 (TID 20) in 1862 ms on localhost (executor driver) (31/56)
2021-01-04 22:35:33  [ dispatcher-event-loop-12:8206 ] - [ INFO ]  Removed taskresult_20 on 192.168.124.5:50355 in memory (size: 1182.0 KB, free: 2003.5 MB)
2021-01-04 22:35:33  [ dispatcher-event-loop-0:8209 ] - [ INFO ]  Removed taskresult_30 on 192.168.124.5:50355 in memory (size: 1147.9 KB, free: 2004.6 MB)
2021-01-04 22:35:33  [ task-result-getter-3:8216 ] - [ INFO ]  Finished task 30.0 in stage 0.0 (TID 30) in 1835 ms on localhost (executor driver) (32/56)
2021-01-04 22:35:34  [ Executor task launch worker for task 32:9202 ] - [ INFO ]  Block taskresult_32 stored as bytes in memory (estimated size 1172.5 KB, free 2003.2 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-2:9205 ] - [ INFO ]  Added taskresult_32 in memory on 192.168.124.5:50355 (size: 1172.5 KB, free: 2003.4 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 32:9207 ] - [ INFO ]  Finished task 32.0 in stage 0.0 (TID 32). 1200638 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-7:9208 ] - [ INFO ]  Starting task 48.0 in stage 0.0 (TID 48, localhost, executor driver, partition 48, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 33:9209 ] - [ INFO ]  Block taskresult_33 stored as bytes in memory (estimated size 1120.0 KB, free 2002.1 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 48:9210 ] - [ INFO ]  Running task 48.0 in stage 0.0 (TID 48)
2021-01-04 22:35:34  [ dispatcher-event-loop-1:9210 ] - [ INFO ]  Added taskresult_33 in memory on 192.168.124.5:50355 (size: 1120.0 KB, free: 2002.3 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 33:9211 ] - [ INFO ]  Finished task 33.0 in stage 0.0 (TID 33). 1146922 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-15:9213 ] - [ INFO ]  Starting task 49.0 in stage 0.0 (TID 49, localhost, executor driver, partition 49, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 49:9214 ] - [ INFO ]  Running task 49.0 in stage 0.0 (TID 49)
2021-01-04 22:35:34  [ Executor task launch worker for task 48:9214 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1610612736+33554432
2021-01-04 22:35:34  [ Executor task launch worker for task 49:9215 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1644167168+33554432
2021-01-04 22:35:34  [ Executor task launch worker for task 40:9238 ] - [ INFO ]  Block taskresult_40 stored as bytes in memory (estimated size 1142.4 KB, free 2001.0 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-5:9240 ] - [ INFO ]  Added taskresult_40 in memory on 192.168.124.5:50355 (size: 1142.4 KB, free: 2001.2 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 40:9241 ] - [ INFO ]  Finished task 40.0 in stage 0.0 (TID 40). 1169796 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ task-result-getter-1:9241 ] - [ INFO ]  Finished task 32.0 in stage 0.0 (TID 32) in 1419 ms on localhost (executor driver) (33/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-14:9243 ] - [ INFO ]  Starting task 50.0 in stage 0.0 (TID 50, localhost, executor driver, partition 50, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 50:9244 ] - [ INFO ]  Running task 50.0 in stage 0.0 (TID 50)
2021-01-04 22:35:34  [ dispatcher-event-loop-12:9245 ] - [ INFO ]  Removed taskresult_32 on 192.168.124.5:50355 in memory (size: 1172.5 KB, free: 2002.4 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 50:9246 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1677721600+33554432
2021-01-04 22:35:34  [ Executor task launch worker for task 38:9247 ] - [ INFO ]  Block taskresult_38 stored as bytes in memory (estimated size 1114.1 KB, free 2001.1 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-0:9248 ] - [ INFO ]  Added taskresult_38 in memory on 192.168.124.5:50355 (size: 1114.1 KB, free: 2001.3 MB)
2021-01-04 22:35:34  [ task-result-getter-2:9248 ] - [ INFO ]  Finished task 33.0 in stage 0.0 (TID 33) in 1375 ms on localhost (executor driver) (34/56)
2021-01-04 22:35:34  [ Executor task launch worker for task 38:9248 ] - [ INFO ]  Finished task 38.0 in stage 0.0 (TID 38). 1140879 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-3:9251 ] - [ INFO ]  Starting task 51.0 in stage 0.0 (TID 51, localhost, executor driver, partition 51, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 51:9251 ] - [ INFO ]  Running task 51.0 in stage 0.0 (TID 51)
2021-01-04 22:35:34  [ dispatcher-event-loop-6:9251 ] - [ INFO ]  Removed taskresult_33 on 192.168.124.5:50355 in memory (size: 1120.0 KB, free: 2002.4 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 35:9252 ] - [ INFO ]  Block taskresult_35 stored as bytes in memory (estimated size 1184.5 KB, free 2001.0 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-6:9252 ] - [ INFO ]  Added taskresult_35 in memory on 192.168.124.5:50355 (size: 1184.5 KB, free: 2001.2 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 37:9252 ] - [ INFO ]  Block taskresult_37 stored as bytes in memory (estimated size 1116.6 KB, free 1999.9 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 35:9253 ] - [ INFO ]  Finished task 35.0 in stage 0.0 (TID 35). 1212941 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-8:9253 ] - [ INFO ]  Added taskresult_37 in memory on 192.168.124.5:50355 (size: 1116.6 KB, free: 2000.1 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 37:9254 ] - [ INFO ]  Finished task 37.0 in stage 0.0 (TID 37). 1143378 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-8:9255 ] - [ INFO ]  Starting task 52.0 in stage 0.0 (TID 52, localhost, executor driver, partition 52, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 52:9256 ] - [ INFO ]  Running task 52.0 in stage 0.0 (TID 52)
2021-01-04 22:35:34  [ dispatcher-event-loop-8:9257 ] - [ INFO ]  Starting task 53.0 in stage 0.0 (TID 53, localhost, executor driver, partition 53, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 51:9257 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1711276032+33554432
2021-01-04 22:35:34  [ Executor task launch worker for task 53:9258 ] - [ INFO ]  Running task 53.0 in stage 0.0 (TID 53)
2021-01-04 22:35:34  [ Executor task launch worker for task 52:9258 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1744830464+33554432
2021-01-04 22:35:34  [ Executor task launch worker for task 34:9259 ] - [ INFO ]  Block taskresult_34 stored as bytes in memory (estimated size 1131.6 KB, free 1998.8 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 53:9259 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1778384896+33554432
2021-01-04 22:35:34  [ dispatcher-event-loop-11:9262 ] - [ INFO ]  Added taskresult_34 in memory on 192.168.124.5:50355 (size: 1131.6 KB, free: 1999.0 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 34:9262 ] - [ INFO ]  Finished task 34.0 in stage 0.0 (TID 34). 1158809 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-0:9263 ] - [ INFO ]  Starting task 54.0 in stage 0.0 (TID 54, localhost, executor driver, partition 54, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 54:9267 ] - [ INFO ]  Running task 54.0 in stage 0.0 (TID 54)
2021-01-04 22:35:34  [ Executor task launch worker for task 54:9268 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1811939328+33554432
2021-01-04 22:35:34  [ Executor task launch worker for task 36:9276 ] - [ INFO ]  Block taskresult_36 stored as bytes in memory (estimated size 1156.2 KB, free 1997.7 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-2:9277 ] - [ INFO ]  Added taskresult_36 in memory on 192.168.124.5:50355 (size: 1156.2 KB, free: 1997.9 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 36:9279 ] - [ INFO ]  Finished task 36.0 in stage 0.0 (TID 36). 1183904 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ Executor task launch worker for task 41:9282 ] - [ INFO ]  Block taskresult_41 stored as bytes in memory (estimated size 1133.4 KB, free 1996.6 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-1:9284 ] - [ INFO ]  Added taskresult_41 in memory on 192.168.124.5:50355 (size: 1133.4 KB, free: 1996.8 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 41:9285 ] - [ INFO ]  Finished task 41.0 in stage 0.0 (TID 41). 1160595 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-3:9285 ] - [ INFO ]  Starting task 55.0 in stage 0.0 (TID 55, localhost, executor driver, partition 55, PROCESS_LOCAL, 7943 bytes)
2021-01-04 22:35:34  [ Executor task launch worker for task 55:9285 ] - [ INFO ]  Running task 55.0 in stage 0.0 (TID 55)
2021-01-04 22:35:34  [ Executor task launch worker for task 55:9287 ] - [ INFO ]  Input split: file:/Users/liuwenyi/Downloads/八斗19期/badou_project_data/project2/user_log.csv:1845493760+30280030
2021-01-04 22:35:34  [ Executor task launch worker for task 39:9287 ] - [ INFO ]  Block taskresult_39 stored as bytes in memory (estimated size 1196.3 KB, free 1995.4 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-13:9288 ] - [ INFO ]  Added taskresult_39 in memory on 192.168.124.5:50355 (size: 1196.3 KB, free: 1995.6 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 39:9290 ] - [ INFO ]  Finished task 39.0 in stage 0.0 (TID 39). 1225032 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ Executor task launch worker for task 42:9291 ] - [ INFO ]  Block taskresult_42 stored as bytes in memory (estimated size 1113.0 KB, free 1993.2 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 44:9291 ] - [ INFO ]  Block taskresult_44 stored as bytes in memory (estimated size 1126.5 KB, free 1993.2 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-4:9292 ] - [ INFO ]  Added taskresult_42 in memory on 192.168.124.5:50355 (size: 1113.0 KB, free: 1994.5 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 42:9293 ] - [ INFO ]  Finished task 42.0 in stage 0.0 (TID 42). 1139749 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-4:9293 ] - [ INFO ]  Added taskresult_44 in memory on 192.168.124.5:50355 (size: 1126.5 KB, free: 1993.4 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 44:9293 ] - [ INFO ]  Finished task 44.0 in stage 0.0 (TID 44). 1153502 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ Executor task launch worker for task 47:9296 ] - [ INFO ]  Block taskresult_47 stored as bytes in memory (estimated size 1150.2 KB, free 1992.1 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-9:9296 ] - [ INFO ]  Added taskresult_47 in memory on 192.168.124.5:50355 (size: 1150.2 KB, free: 1992.3 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 47:9297 ] - [ INFO ]  Finished task 47.0 in stage 0.0 (TID 47). 1177854 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ Executor task launch worker for task 43:9301 ] - [ INFO ]  Block taskresult_43 stored as bytes in memory (estimated size 1182.5 KB, free 1990.9 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-11:9302 ] - [ INFO ]  Added taskresult_43 in memory on 192.168.124.5:50355 (size: 1182.5 KB, free: 1991.2 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 43:9302 ] - [ INFO ]  Finished task 43.0 in stage 0.0 (TID 43). 1210906 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ Executor task launch worker for task 46:9302 ] - [ INFO ]  Block taskresult_46 stored as bytes in memory (estimated size 1136.9 KB, free 1989.8 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 45:9303 ] - [ INFO ]  Block taskresult_45 stored as bytes in memory (estimated size 1160.5 KB, free 1988.7 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-7:9303 ] - [ INFO ]  Added taskresult_46 in memory on 192.168.124.5:50355 (size: 1136.9 KB, free: 1990.0 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 46:9303 ] - [ INFO ]  Finished task 46.0 in stage 0.0 (TID 46). 1164214 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ dispatcher-event-loop-7:9303 ] - [ INFO ]  Added taskresult_45 in memory on 192.168.124.5:50355 (size: 1160.5 KB, free: 1988.9 MB)
2021-01-04 22:35:34  [ Executor task launch worker for task 45:9303 ] - [ INFO ]  Finished task 45.0 in stage 0.0 (TID 45). 1188320 bytes result sent via BlockManager)
2021-01-04 22:35:34  [ task-result-getter-1:9305 ] - [ INFO ]  Finished task 40.0 in stage 0.0 (TID 40) in 1348 ms on localhost (executor driver) (35/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-5:9305 ] - [ INFO ]  Removed taskresult_40 on 192.168.124.5:50355 in memory (size: 1142.4 KB, free: 1990.0 MB)
2021-01-04 22:35:34  [ task-result-getter-0:9309 ] - [ INFO ]  Finished task 35.0 in stage 0.0 (TID 35) in 1380 ms on localhost (executor driver) (36/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-3:9310 ] - [ INFO ]  Removed taskresult_35 on 192.168.124.5:50355 in memory (size: 1184.5 KB, free: 1991.2 MB)
2021-01-04 22:35:34  [ task-result-getter-2:9310 ] - [ INFO ]  Finished task 37.0 in stage 0.0 (TID 37) in 1365 ms on localhost (executor driver) (37/56)
2021-01-04 22:35:34  [ task-result-getter-3:9311 ] - [ INFO ]  Finished task 38.0 in stage 0.0 (TID 38) in 1363 ms on localhost (executor driver) (38/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-11:9311 ] - [ INFO ]  Removed taskresult_37 on 192.168.124.5:50355 in memory (size: 1116.6 KB, free: 1992.3 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-11:9311 ] - [ INFO ]  Removed taskresult_38 on 192.168.124.5:50355 in memory (size: 1114.1 KB, free: 1993.4 MB)
2021-01-04 22:35:34  [ task-result-getter-1:9325 ] - [ INFO ]  Finished task 34.0 in stage 0.0 (TID 34) in 1406 ms on localhost (executor driver) (39/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-10:9326 ] - [ INFO ]  Removed taskresult_34 on 192.168.124.5:50355 in memory (size: 1131.6 KB, free: 1994.5 MB)
2021-01-04 22:35:34  [ task-result-getter-0:9331 ] - [ INFO ]  Finished task 36.0 in stage 0.0 (TID 36) in 1391 ms on localhost (executor driver) (40/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-14:9331 ] - [ INFO ]  Removed taskresult_36 on 192.168.124.5:50355 in memory (size: 1156.2 KB, free: 1995.6 MB)
2021-01-04 22:35:34  [ task-result-getter-3:9351 ] - [ INFO ]  Finished task 39.0 in stage 0.0 (TID 39) in 1395 ms on localhost (executor driver) (41/56)
2021-01-04 22:35:34  [ task-result-getter-2:9351 ] - [ INFO ]  Finished task 41.0 in stage 0.0 (TID 41) in 1387 ms on localhost (executor driver) (42/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-0:9352 ] - [ INFO ]  Removed taskresult_39 on 192.168.124.5:50355 in memory (size: 1196.3 KB, free: 1996.8 MB)
2021-01-04 22:35:34  [ dispatcher-event-loop-0:9352 ] - [ INFO ]  Removed taskresult_41 on 192.168.124.5:50355 in memory (size: 1133.4 KB, free: 1997.9 MB)
2021-01-04 22:35:34  [ task-result-getter-1:9361 ] - [ INFO ]  Finished task 42.0 in stage 0.0 (TID 42) in 1378 ms on localhost (executor driver) (43/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-5:9362 ] - [ INFO ]  Removed taskresult_42 on 192.168.124.5:50355 in memory (size: 1113.0 KB, free: 1999.0 MB)
2021-01-04 22:35:34  [ task-result-getter-0:9369 ] - [ INFO ]  Finished task 44.0 in stage 0.0 (TID 44) in 1362 ms on localhost (executor driver) (44/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-9:9369 ] - [ INFO ]  Removed taskresult_44 on 192.168.124.5:50355 in memory (size: 1126.5 KB, free: 2000.1 MB)
2021-01-04 22:35:34  [ task-result-getter-3:9372 ] - [ INFO ]  Finished task 47.0 in stage 0.0 (TID 47) in 1351 ms on localhost (executor driver) (45/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-2:9373 ] - [ INFO ]  Removed taskresult_47 on 192.168.124.5:50355 in memory (size: 1150.2 KB, free: 2001.2 MB)
2021-01-04 22:35:34  [ task-result-getter-2:9375 ] - [ INFO ]  Finished task 43.0 in stage 0.0 (TID 43) in 1380 ms on localhost (executor driver) (46/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-15:9375 ] - [ INFO ]  Removed taskresult_43 on 192.168.124.5:50355 in memory (size: 1182.5 KB, free: 2002.3 MB)
2021-01-04 22:35:34  [ task-result-getter-1:9378 ] - [ INFO ]  Finished task 46.0 in stage 0.0 (TID 46) in 1359 ms on localhost (executor driver) (47/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-13:9379 ] - [ INFO ]  Removed taskresult_46 on 192.168.124.5:50355 in memory (size: 1136.9 KB, free: 2003.4 MB)
2021-01-04 22:35:34  [ task-result-getter-0:9385 ] - [ INFO ]  Finished task 45.0 in stage 0.0 (TID 45) in 1366 ms on localhost (executor driver) (48/56)
2021-01-04 22:35:34  [ dispatcher-event-loop-5:9385 ] - [ INFO ]  Removed taskresult_45 on 192.168.124.5:50355 in memory (size: 1160.5 KB, free: 2004.6 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 55:9914 ] - [ INFO ]  Finished task 55.0 in stage 0.0 (TID 55). 1035216 bytes result sent to driver
2021-01-04 22:35:35  [ task-result-getter-3:9922 ] - [ INFO ]  Finished task 55.0 in stage 0.0 (TID 55) in 640 ms on localhost (executor driver) (49/56)
2021-01-04 22:35:35  [ Executor task launch worker for task 48:9948 ] - [ INFO ]  Block taskresult_48 stored as bytes in memory (estimated size 1122.2 KB, free 2003.3 MB)
2021-01-04 22:35:35  [ dispatcher-event-loop-8:9948 ] - [ INFO ]  Added taskresult_48 in memory on 192.168.124.5:50355 (size: 1122.2 KB, free: 2003.5 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 48:9948 ] - [ INFO ]  Finished task 48.0 in stage 0.0 (TID 48). 1149108 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ Executor task launch worker for task 49:9952 ] - [ INFO ]  Block taskresult_49 stored as bytes in memory (estimated size 1121.0 KB, free 2002.2 MB)
2021-01-04 22:35:35  [ dispatcher-event-loop-3:9953 ] - [ INFO ]  Added taskresult_49 in memory on 192.168.124.5:50355 (size: 1121.0 KB, free: 2002.4 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 49:9953 ] - [ INFO ]  Finished task 49.0 in stage 0.0 (TID 49). 1147915 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ task-result-getter-2:9962 ] - [ INFO ]  Finished task 48.0 in stage 0.0 (TID 48) in 754 ms on localhost (executor driver) (50/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-15:9963 ] - [ INFO ]  Removed taskresult_48 on 192.168.124.5:50355 in memory (size: 1122.2 KB, free: 2003.5 MB)
2021-01-04 22:35:35  [ task-result-getter-1:9966 ] - [ INFO ]  Finished task 49.0 in stage 0.0 (TID 49) in 753 ms on localhost (executor driver) (51/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-13:9967 ] - [ INFO ]  Removed taskresult_49 on 192.168.124.5:50355 in memory (size: 1121.0 KB, free: 2004.6 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 52:9970 ] - [ INFO ]  Block taskresult_52 stored as bytes in memory (estimated size 1111.9 KB, free 2003.3 MB)
2021-01-04 22:35:35  [ dispatcher-event-loop-10:9971 ] - [ INFO ]  Added taskresult_52 in memory on 192.168.124.5:50355 (size: 1111.9 KB, free: 2003.5 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 50:9971 ] - [ INFO ]  Block taskresult_50 stored as bytes in memory (estimated size 1176.9 KB, free 2002.1 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 52:9971 ] - [ INFO ]  Finished task 52.0 in stage 0.0 (TID 52). 1138570 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ dispatcher-event-loop-6:9971 ] - [ INFO ]  Added taskresult_50 in memory on 192.168.124.5:50355 (size: 1176.9 KB, free: 2002.3 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 50:9971 ] - [ INFO ]  Finished task 50.0 in stage 0.0 (TID 50). 1205154 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ Executor task launch worker for task 51:9972 ] - [ INFO ]  Block taskresult_51 stored as bytes in memory (estimated size 1157.9 KB, free 2001.0 MB)
2021-01-04 22:35:35  [ dispatcher-event-loop-9:9972 ] - [ INFO ]  Added taskresult_51 in memory on 192.168.124.5:50355 (size: 1157.9 KB, free: 2001.2 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 51:9972 ] - [ INFO ]  Finished task 51.0 in stage 0.0 (TID 51). 1185705 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ Executor task launch worker for task 53:9973 ] - [ INFO ]  Block taskresult_53 stored as bytes in memory (estimated size 1106.2 KB, free 1999.9 MB)
2021-01-04 22:35:35  [ dispatcher-event-loop-2:9974 ] - [ INFO ]  Added taskresult_53 in memory on 192.168.124.5:50355 (size: 1106.2 KB, free: 2000.1 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 53:9974 ] - [ INFO ]  Finished task 53.0 in stage 0.0 (TID 53). 1132698 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ Executor task launch worker for task 54:9979 ] - [ INFO ]  Block taskresult_54 stored as bytes in memory (estimated size 1185.6 KB, free 1998.8 MB)
2021-01-04 22:35:35  [ dispatcher-event-loop-15:9980 ] - [ INFO ]  Added taskresult_54 in memory on 192.168.124.5:50355 (size: 1185.6 KB, free: 1999.0 MB)
2021-01-04 22:35:35  [ Executor task launch worker for task 54:9980 ] - [ INFO ]  Finished task 54.0 in stage 0.0 (TID 54). 1214083 bytes result sent via BlockManager)
2021-01-04 22:35:35  [ task-result-getter-0:9985 ] - [ INFO ]  Finished task 52.0 in stage 0.0 (TID 52) in 730 ms on localhost (executor driver) (52/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-10:9985 ] - [ INFO ]  Removed taskresult_52 on 192.168.124.5:50355 in memory (size: 1111.9 KB, free: 2000.1 MB)
2021-01-04 22:35:35  [ task-result-getter-3:9987 ] - [ INFO ]  Finished task 50.0 in stage 0.0 (TID 50) in 744 ms on localhost (executor driver) (53/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-8:9987 ] - [ INFO ]  Removed taskresult_50 on 192.168.124.5:50355 in memory (size: 1176.9 KB, free: 2001.2 MB)
2021-01-04 22:35:35  [ task-result-getter-2:9988 ] - [ INFO ]  Finished task 51.0 in stage 0.0 (TID 51) in 737 ms on localhost (executor driver) (54/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-3:9988 ] - [ INFO ]  Removed taskresult_51 on 192.168.124.5:50355 in memory (size: 1157.9 KB, free: 2002.3 MB)
2021-01-04 22:35:35  [ task-result-getter-1:9989 ] - [ INFO ]  Finished task 53.0 in stage 0.0 (TID 53) in 733 ms on localhost (executor driver) (55/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-1:9989 ] - [ INFO ]  Removed taskresult_53 on 192.168.124.5:50355 in memory (size: 1106.2 KB, free: 2003.4 MB)
2021-01-04 22:35:35  [ task-result-getter-0:9998 ] - [ INFO ]  Finished task 54.0 in stage 0.0 (TID 54) in 735 ms on localhost (executor driver) (56/56)
2021-01-04 22:35:35  [ dispatcher-event-loop-11:9999 ] - [ INFO ]  Removed taskresult_54 on 192.168.124.5:50355 in memory (size: 1185.6 KB, free: 2004.6 MB)
2021-01-04 22:35:35  [ task-result-getter-0:9999 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-01-04 22:35:35  [ dag-scheduler-event-loop:10434 ] - [ INFO ]  ResultStage 0 (foreach at UserLog.scala:63) finished in 7.456 s
2021-01-04 22:35:35  [ main:10440 ] - [ INFO ]  Job 0 finished: foreach at UserLog.scala:63, took 7.566501 s
2021-01-04 22:35:36  [ Thread-1:10963 ] - [ INFO ]  Invoking stop() from shutdown hook
2021-01-04 22:35:36  [ Thread-1:10971 ] - [ INFO ]  Stopped Spark@77192705{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-01-04 22:35:36  [ Thread-1:10973 ] - [ INFO ]  Stopped Spark web UI at http://192.168.124.5:4040
2021-01-04 22:35:36  [ dispatcher-event-loop-6:10982 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2021-01-04 22:35:36  [ Thread-1:11015 ] - [ INFO ]  MemoryStore cleared
2021-01-04 22:35:36  [ Thread-1:11015 ] - [ INFO ]  BlockManager stopped
2021-01-04 22:35:36  [ Thread-1:11016 ] - [ INFO ]  BlockManagerMaster stopped
2021-01-04 22:35:36  [ dispatcher-event-loop-9:11019 ] - [ INFO ]  OutputCommitCoordinator stopped!
2021-01-04 22:35:36  [ Thread-1:11025 ] - [ INFO ]  Successfully stopped SparkContext
2021-01-04 22:35:36  [ Thread-1:11026 ] - [ INFO ]  Shutdown hook called
2021-01-04 22:35:36  [ Thread-1:11026 ] - [ INFO ]  Deleting directory /private/var/folders/y1/26k_xzzj321fz8xhvjvvdd4c0000gn/T/spark-dedc97b6-bcae-47eb-8c4c-46e24e23c484
