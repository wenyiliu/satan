2020-11-19 10:13:25  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 10:13:25  [ main:770 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 10:13:25  [ main:771 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 10:13:26  [ main:974 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:26  [ main:979 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:26  [ main:992 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:26  [ main:1079 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:26  [ main:1157 ] - [ INFO ]  Submitting tokens for job: job_local2007936094_0001
2020-11-19 10:13:26  [ main:1248 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:26  [ main:1249 ] - [ INFO ]  Running job: job_local2007936094_0001
2020-11-19 10:13:26  [ Thread-18:1249 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:26  [ Thread-18:1253 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:26  [ Thread-18:1255 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:26  [ Thread-18:1291 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1292 ] - [ INFO ]  Starting task: attempt_local2007936094_0001_m_000000_0
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1315 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1315 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1317 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1370 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1474 ] - [ INFO ]  
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1475 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1476 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1476 ] - [ INFO ]  bufstart = 0; bufend = 20411; bufvoid = 104857600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1476 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213032(104852128); length = 1365/6553600
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1486 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1490 ] - [ INFO ]  Task:attempt_local2007936094_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1502 ] - [ INFO ]  map
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1502 ] - [ INFO ]  Task 'attempt_local2007936094_0001_m_000000_0' done.
2020-11-19 10:13:26  [ LocalJobRunner Map Task Executor #0:1502 ] - [ INFO ]  Finishing task: attempt_local2007936094_0001_m_000000_0
2020-11-19 10:13:26  [ Thread-18:1502 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:26  [ Thread-18:1505 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:26  [ pool-6-thread-1:1505 ] - [ INFO ]  Starting task: attempt_local2007936094_0001_r_000000_0
2020-11-19 10:13:26  [ pool-6-thread-1:1509 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:26  [ pool-6-thread-1:1510 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:26  [ pool-6-thread-1:1510 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:26  [ pool-6-thread-1:1512 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54532f11
2020-11-19 10:13:26  [ pool-6-thread-1:1523 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:26  [ EventFetcher for fetching Map Completion Events:1524 ] - [ INFO ]  attempt_local2007936094_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:26  [ localfetcher#1:1544 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2007936094_0001_m_000000_0 decomp: 21097 len: 21101 to MEMORY
2020-11-19 10:13:26  [ localfetcher#1:1548 ] - [ INFO ]  Read 21097 bytes from map-output for attempt_local2007936094_0001_m_000000_0
2020-11-19 10:13:26  [ localfetcher#1:1549 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 21097, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->21097
2020-11-19 10:13:26  [ EventFetcher for fetching Map Completion Events:1550 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:26  [ pool-6-thread-1:1551 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:26  [ pool-6-thread-1:1551 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:26  [ pool-6-thread-1:1555 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:26  [ pool-6-thread-1:1559 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 21093 bytes
2020-11-19 10:13:26  [ pool-6-thread-1:1561 ] - [ INFO ]  Merged 1 segments, 21097 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:26  [ pool-6-thread-1:1562 ] - [ INFO ]  Merging 1 files, 21101 bytes from disk
2020-11-19 10:13:26  [ pool-6-thread-1:1562 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:26  [ pool-6-thread-1:1562 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:26  [ pool-6-thread-1:1563 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 21093 bytes
2020-11-19 10:13:26  [ pool-6-thread-1:1563 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:26  [ pool-6-thread-1:1584 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 10:13:26  [ pool-6-thread-1:1697 ] - [ INFO ]  Task:attempt_local2007936094_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:26  [ pool-6-thread-1:1703 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:26  [ pool-6-thread-1:1703 ] - [ INFO ]  Task attempt_local2007936094_0001_r_000000_0 is allowed to commit now
2020-11-19 10:13:26  [ pool-6-thread-1:1724 ] - [ INFO ]  Saved output of task 'attempt_local2007936094_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2007936094_0001_r_000000
2020-11-19 10:13:26  [ pool-6-thread-1:1725 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:26  [ pool-6-thread-1:1725 ] - [ INFO ]  Task 'attempt_local2007936094_0001_r_000000_0' done.
2020-11-19 10:13:26  [ pool-6-thread-1:1725 ] - [ INFO ]  Finishing task: attempt_local2007936094_0001_r_000000_0
2020-11-19 10:13:26  [ Thread-18:1725 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:27  [ main:2251 ] - [ INFO ]  Job job_local2007936094_0001 running in uber mode : false
2020-11-19 10:13:27  [ main:2252 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:27  [ main:2252 ] - [ INFO ]  Job job_local2007936094_0001 completed successfully
2020-11-19 10:13:27  [ main:2259 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=42584
		FILE: Number of bytes written=631493
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=174
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=342
		Map output bytes=20411
		Map output materialized bytes=21101
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=21101
		Reduce input records=342
		Reduce output records=3
		Spilled Records=684
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=174
2020-11-19 10:13:27  [ main:2375 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:27  [ main:2384 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:27  [ main:2389 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:27  [ main:2395 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:27  [ main:2438 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:27  [ main:2460 ] - [ INFO ]  Submitting tokens for job: job_local323101412_0002
2020-11-19 10:13:27  [ main:2512 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:27  [ main:2512 ] - [ INFO ]  Running job: job_local323101412_0002
2020-11-19 10:13:27  [ Thread-48:2512 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:27  [ Thread-48:2512 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:27  [ Thread-48:2512 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:27  [ Thread-48:2520 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2520 ] - [ INFO ]  Starting task: attempt_local323101412_0002_m_000000_0
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2521 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2521 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2523 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2571 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2573 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2657 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2662 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2663 ] - [ INFO ]  Task:attempt_local323101412_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2669 ] - [ INFO ]  map
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2669 ] - [ INFO ]  Task 'attempt_local323101412_0002_m_000000_0' done.
2020-11-19 10:13:27  [ LocalJobRunner Map Task Executor #0:2669 ] - [ INFO ]  Finishing task: attempt_local323101412_0002_m_000000_0
2020-11-19 10:13:27  [ Thread-48:2669 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:27  [ Thread-48:2670 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:27  [ pool-9-thread-1:2670 ] - [ INFO ]  Starting task: attempt_local323101412_0002_r_000000_0
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:27  [ pool-9-thread-1:2671 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67a496cf
2020-11-19 10:13:27  [ pool-9-thread-1:2672 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:27  [ EventFetcher for fetching Map Completion Events:2672 ] - [ INFO ]  attempt_local323101412_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:27  [ localfetcher#2:2673 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local323101412_0002_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-19 10:13:27  [ localfetcher#2:2673 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local323101412_0002_m_000000_0
2020-11-19 10:13:27  [ localfetcher#2:2673 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-19 10:13:27  [ EventFetcher for fetching Map Completion Events:2674 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:27  [ pool-9-thread-1:2674 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:27  [ pool-9-thread-1:2674 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:27  [ pool-9-thread-1:2675 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:27  [ pool-9-thread-1:2675 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 10:13:27  [ pool-9-thread-1:2675 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 190 bytes
2020-11-19 10:13:27  [ pool-9-thread-1:2676 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:27  [ pool-9-thread-1:2732 ] - [ INFO ]  Task:attempt_local323101412_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:27  [ pool-9-thread-1:2737 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:27  [ pool-9-thread-1:2738 ] - [ INFO ]  Task attempt_local323101412_0002_r_000000_0 is allowed to commit now
2020-11-19 10:13:27  [ pool-9-thread-1:2754 ] - [ INFO ]  Saved output of task 'attempt_local323101412_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local323101412_0002_r_000000
2020-11-19 10:13:27  [ pool-9-thread-1:2755 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:27  [ pool-9-thread-1:2755 ] - [ INFO ]  Task 'attempt_local323101412_0002_r_000000_0' done.
2020-11-19 10:13:27  [ pool-9-thread-1:2755 ] - [ INFO ]  Finishing task: attempt_local323101412_0002_r_000000_0
2020-11-19 10:13:27  [ Thread-48:2755 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:28  [ main:3513 ] - [ INFO ]  Job job_local323101412_0002 running in uber mode : false
2020-11-19 10:13:28  [ main:3514 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:28  [ main:3514 ] - [ INFO ]  Job job_local323101412_0002 completed successfully
2020-11-19 10:13:28  [ main:3517 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85596
		FILE: Number of bytes written=1221282
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125908
		HDFS: Number of bytes written=874
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=198
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=198
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=844103680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 10:13:29  [ main:3823 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:29  [ main:3834 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:29  [ main:3838 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:29  [ main:3845 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:29  [ main:3885 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:29  [ main:3909 ] - [ INFO ]  Submitting tokens for job: job_local859066095_0003
2020-11-19 10:13:29  [ main:3958 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:29  [ main:3958 ] - [ INFO ]  Running job: job_local859066095_0003
2020-11-19 10:13:29  [ Thread-78:3958 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:29  [ Thread-78:3959 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:29  [ Thread-78:3959 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:29  [ Thread-78:3967 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3967 ] - [ INFO ]  Starting task: attempt_local859066095_0003_m_000000_0
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3968 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3987 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:3988 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4073 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4215 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4216 ] - [ INFO ]  Task:attempt_local859066095_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4223 ] - [ INFO ]  map
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4223 ] - [ INFO ]  Task 'attempt_local859066095_0003_m_000000_0' done.
2020-11-19 10:13:29  [ LocalJobRunner Map Task Executor #0:4223 ] - [ INFO ]  Finishing task: attempt_local859066095_0003_m_000000_0
2020-11-19 10:13:29  [ Thread-78:4223 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:29  [ Thread-78:4224 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:29  [ pool-12-thread-1:4224 ] - [ INFO ]  Starting task: attempt_local859066095_0003_r_000000_0
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:29  [ pool-12-thread-1:4225 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@538bd303
2020-11-19 10:13:29  [ pool-12-thread-1:4226 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:29  [ EventFetcher for fetching Map Completion Events:4226 ] - [ INFO ]  attempt_local859066095_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:29  [ localfetcher#3:4227 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local859066095_0003_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 10:13:29  [ localfetcher#3:4228 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local859066095_0003_m_000000_0
2020-11-19 10:13:29  [ localfetcher#3:4228 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 10:13:29  [ EventFetcher for fetching Map Completion Events:4228 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:29  [ pool-12-thread-1:4229 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:29  [ pool-12-thread-1:4229 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:29  [ pool-12-thread-1:4230 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:29  [ pool-12-thread-1:4230 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:29  [ pool-12-thread-1:4231 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:13:29  [ pool-12-thread-1:4232 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:29  [ pool-12-thread-1:4285 ] - [ INFO ]  Task:attempt_local859066095_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:29  [ pool-12-thread-1:4291 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:29  [ pool-12-thread-1:4291 ] - [ INFO ]  Task attempt_local859066095_0003_r_000000_0 is allowed to commit now
2020-11-19 10:13:29  [ pool-12-thread-1:4308 ] - [ INFO ]  Saved output of task 'attempt_local859066095_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local859066095_0003_r_000000
2020-11-19 10:13:29  [ pool-12-thread-1:4309 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:29  [ pool-12-thread-1:4309 ] - [ INFO ]  Task 'attempt_local859066095_0003_r_000000_0' done.
2020-11-19 10:13:29  [ pool-12-thread-1:4309 ] - [ INFO ]  Finishing task: attempt_local859066095_0003_r_000000_0
2020-11-19 10:13:29  [ Thread-78:4309 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:30  [ main:4959 ] - [ INFO ]  Job job_local859066095_0003 running in uber mode : false
2020-11-19 10:13:30  [ main:4959 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:30  [ main:4959 ] - [ INFO ]  Job job_local859066095_0003 completed successfully
2020-11-19 10:13:30  [ main:4962 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86792
		FILE: Number of bytes written=1790153
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190286
		HDFS: Number of bytes written=1941
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=177
2020-11-19 10:13:31  [ main:6258 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:31  [ main:6275 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:31  [ main:6281 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:31  [ main:6288 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:31  [ main:6334 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:31  [ main:6354 ] - [ INFO ]  Submitting tokens for job: job_local1838117753_0004
2020-11-19 10:13:31  [ main:6394 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:31  [ main:6395 ] - [ INFO ]  Running job: job_local1838117753_0004
2020-11-19 10:13:31  [ Thread-108:6395 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:31  [ Thread-108:6395 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:31  [ Thread-108:6395 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:31  [ Thread-108:6402 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6402 ] - [ INFO ]  Starting task: attempt_local1838117753_0004_m_000000_0
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6403 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6403 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6403 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6404 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6414 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6483 ] - [ INFO ]  
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6484 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6487 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6488 ] - [ INFO ]  Task:attempt_local1838117753_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6496 ] - [ INFO ]  map
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6496 ] - [ INFO ]  Task 'attempt_local1838117753_0004_m_000000_0' done.
2020-11-19 10:13:31  [ LocalJobRunner Map Task Executor #0:6496 ] - [ INFO ]  Finishing task: attempt_local1838117753_0004_m_000000_0
2020-11-19 10:13:31  [ Thread-108:6496 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:31  [ Thread-108:6496 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:31  [ pool-15-thread-1:6497 ] - [ INFO ]  Starting task: attempt_local1838117753_0004_r_000000_0
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5616d409
2020-11-19 10:13:31  [ pool-15-thread-1:6498 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:31  [ EventFetcher for fetching Map Completion Events:6499 ] - [ INFO ]  attempt_local1838117753_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:31  [ localfetcher#4:6500 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1838117753_0004_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:31  [ localfetcher#4:6500 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1838117753_0004_m_000000_0
2020-11-19 10:13:31  [ localfetcher#4:6500 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:31  [ EventFetcher for fetching Map Completion Events:6500 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:31  [ pool-15-thread-1:6501 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:31  [ pool-15-thread-1:6502 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:31  [ pool-15-thread-1:6503 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:31  [ pool-15-thread-1:6545 ] - [ INFO ]  Task:attempt_local1838117753_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:31  [ pool-15-thread-1:6551 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:31  [ pool-15-thread-1:6551 ] - [ INFO ]  Task attempt_local1838117753_0004_r_000000_0 is allowed to commit now
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  Saved output of task 'attempt_local1838117753_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1838117753_0004_r_000000
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  Task 'attempt_local1838117753_0004_r_000000_0' done.
2020-11-19 10:13:31  [ pool-15-thread-1:6570 ] - [ INFO ]  Finishing task: attempt_local1838117753_0004_r_000000_0
2020-11-19 10:13:31  [ Thread-108:6570 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:32  [ main:7396 ] - [ INFO ]  Job job_local1838117753_0004 running in uber mode : false
2020-11-19 10:13:32  [ main:7396 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:32  [ main:7397 ] - [ INFO ]  Job job_local1838117753_0004 completed successfully
2020-11-19 10:13:32  [ main:7399 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=87980
		FILE: Number of bytes written=2362070
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254664
		HDFS: Number of bytes written=3006
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:32  [ main:7690 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:32  [ main:7702 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:32  [ main:7707 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:32  [ main:7712 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:32  [ main:7752 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:32  [ main:7772 ] - [ INFO ]  Submitting tokens for job: job_local1620197152_0005
2020-11-19 10:13:33  [ main:7809 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:33  [ main:7809 ] - [ INFO ]  Running job: job_local1620197152_0005
2020-11-19 10:13:33  [ Thread-138:7809 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:33  [ Thread-138:7810 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:33  [ Thread-138:7810 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:33  [ Thread-138:7818 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7818 ] - [ INFO ]  Starting task: attempt_local1620197152_0005_m_000000_0
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7819 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7819 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7819 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7820 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7828 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7829 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7899 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7902 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7903 ] - [ INFO ]  Task:attempt_local1620197152_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7910 ] - [ INFO ]  map
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7910 ] - [ INFO ]  Task 'attempt_local1620197152_0005_m_000000_0' done.
2020-11-19 10:13:33  [ LocalJobRunner Map Task Executor #0:7910 ] - [ INFO ]  Finishing task: attempt_local1620197152_0005_m_000000_0
2020-11-19 10:13:33  [ Thread-138:7910 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:33  [ Thread-138:7910 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:33  [ pool-18-thread-1:7910 ] - [ INFO ]  Starting task: attempt_local1620197152_0005_r_000000_0
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:33  [ pool-18-thread-1:7911 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68bdd6a4
2020-11-19 10:13:33  [ pool-18-thread-1:7912 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:33  [ EventFetcher for fetching Map Completion Events:7912 ] - [ INFO ]  attempt_local1620197152_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:33  [ localfetcher#5:7913 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local1620197152_0005_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:33  [ localfetcher#5:7913 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1620197152_0005_m_000000_0
2020-11-19 10:13:33  [ localfetcher#5:7913 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:33  [ EventFetcher for fetching Map Completion Events:7913 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:33  [ pool-18-thread-1:7913 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:33  [ pool-18-thread-1:7913 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:33  [ pool-18-thread-1:7914 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:33  [ pool-18-thread-1:7914 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:33  [ pool-18-thread-1:7914 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:33  [ pool-18-thread-1:7915 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:33  [ pool-18-thread-1:7967 ] - [ INFO ]  Task:attempt_local1620197152_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:33  [ pool-18-thread-1:7973 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:33  [ pool-18-thread-1:7973 ] - [ INFO ]  Task attempt_local1620197152_0005_r_000000_0 is allowed to commit now
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  Saved output of task 'attempt_local1620197152_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1620197152_0005_r_000000
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  Task 'attempt_local1620197152_0005_r_000000_0' done.
2020-11-19 10:13:33  [ pool-18-thread-1:7992 ] - [ INFO ]  Finishing task: attempt_local1620197152_0005_r_000000_0
2020-11-19 10:13:33  [ Thread-138:7992 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:34  [ main:8813 ] - [ INFO ]  Job job_local1620197152_0005 running in uber mode : false
2020-11-19 10:13:34  [ main:8813 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:34  [ main:8813 ] - [ INFO ]  Job job_local1620197152_0005 completed successfully
2020-11-19 10:13:34  [ main:8815 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=89172
		FILE: Number of bytes written=2933991
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319064
		HDFS: Number of bytes written=4086
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=90
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1500512256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:34  [ main:9118 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:34  [ main:9129 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:34  [ main:9134 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:34  [ main:9140 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:34  [ main:9179 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:34  [ main:9196 ] - [ INFO ]  Submitting tokens for job: job_local514750714_0006
2020-11-19 10:13:34  [ main:9236 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:34  [ main:9236 ] - [ INFO ]  Running job: job_local514750714_0006
2020-11-19 10:13:34  [ Thread-168:9236 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:34  [ Thread-168:9236 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:34  [ Thread-168:9236 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:34  [ Thread-168:9245 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]  Starting task: attempt_local514750714_0006_m_000000_0
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9245 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9246 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9258 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9384 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9387 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9388 ] - [ INFO ]  Task:attempt_local514750714_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9396 ] - [ INFO ]  map
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9396 ] - [ INFO ]  Task 'attempt_local514750714_0006_m_000000_0' done.
2020-11-19 10:13:34  [ LocalJobRunner Map Task Executor #0:9396 ] - [ INFO ]  Finishing task: attempt_local514750714_0006_m_000000_0
2020-11-19 10:13:34  [ Thread-168:9396 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:34  [ Thread-168:9397 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:34  [ pool-21-thread-1:9397 ] - [ INFO ]  Starting task: attempt_local514750714_0006_r_000000_0
2020-11-19 10:13:34  [ pool-21-thread-1:9397 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@478bafde
2020-11-19 10:13:34  [ pool-21-thread-1:9398 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:34  [ EventFetcher for fetching Map Completion Events:9398 ] - [ INFO ]  attempt_local514750714_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:34  [ localfetcher#6:9399 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local514750714_0006_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:34  [ localfetcher#6:9399 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local514750714_0006_m_000000_0
2020-11-19 10:13:34  [ localfetcher#6:9399 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:34  [ EventFetcher for fetching Map Completion Events:9400 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:34  [ pool-21-thread-1:9400 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:34  [ pool-21-thread-1:9400 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:34  [ pool-21-thread-1:9401 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:34  [ pool-21-thread-1:9402 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:34  [ pool-21-thread-1:9402 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:34  [ pool-21-thread-1:9456 ] - [ INFO ]  Task:attempt_local514750714_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:34  [ pool-21-thread-1:9462 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:34  [ pool-21-thread-1:9462 ] - [ INFO ]  Task attempt_local514750714_0006_r_000000_0 is allowed to commit now
2020-11-19 10:13:34  [ pool-21-thread-1:9478 ] - [ INFO ]  Saved output of task 'attempt_local514750714_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local514750714_0006_r_000000
2020-11-19 10:13:34  [ pool-21-thread-1:9479 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:34  [ pool-21-thread-1:9479 ] - [ INFO ]  Task 'attempt_local514750714_0006_r_000000_0' done.
2020-11-19 10:13:34  [ pool-21-thread-1:9479 ] - [ INFO ]  Finishing task: attempt_local514750714_0006_r_000000_0
2020-11-19 10:13:34  [ Thread-168:9479 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:35  [ main:10238 ] - [ INFO ]  Job job_local514750714_0006 running in uber mode : false
2020-11-19 10:13:35  [ main:10238 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:35  [ main:10239 ] - [ INFO ]  Job job_local514750714_0006 completed successfully
2020-11-19 10:13:35  [ main:10241 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=90364
		FILE: Number of bytes written=3502862
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383470
		HDFS: Number of bytes written=5166
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=61
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:35  [ main:10509 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:35  [ main:10520 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:35  [ main:10524 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:35  [ main:10530 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:35  [ main:10566 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:35  [ main:10582 ] - [ INFO ]  Submitting tokens for job: job_local1921099520_0007
2020-11-19 10:13:35  [ main:10616 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:35  [ main:10616 ] - [ INFO ]  Running job: job_local1921099520_0007
2020-11-19 10:13:35  [ Thread-198:10616 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:35  [ Thread-198:10616 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:35  [ Thread-198:10617 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:35  [ Thread-198:10624 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10624 ] - [ INFO ]  Starting task: attempt_local1921099520_0007_m_000000_0
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10625 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10633 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10695 ] - [ INFO ]  
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10696 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10698 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10699 ] - [ INFO ]  Task:attempt_local1921099520_0007_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10705 ] - [ INFO ]  map
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10705 ] - [ INFO ]  Task 'attempt_local1921099520_0007_m_000000_0' done.
2020-11-19 10:13:35  [ LocalJobRunner Map Task Executor #0:10705 ] - [ INFO ]  Finishing task: attempt_local1921099520_0007_m_000000_0
2020-11-19 10:13:35  [ Thread-198:10705 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:35  [ Thread-198:10706 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  Starting task: attempt_local1921099520_0007_r_000000_0
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:35  [ pool-24-thread-1:10706 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@43784ce4
2020-11-19 10:13:35  [ pool-24-thread-1:10707 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:35  [ EventFetcher for fetching Map Completion Events:10707 ] - [ INFO ]  attempt_local1921099520_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:35  [ localfetcher#7:10708 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local1921099520_0007_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:35  [ localfetcher#7:10708 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1921099520_0007_m_000000_0
2020-11-19 10:13:35  [ localfetcher#7:10708 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:35  [ EventFetcher for fetching Map Completion Events:10709 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:35  [ pool-24-thread-1:10709 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:35  [ pool-24-thread-1:10709 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:35  [ pool-24-thread-1:10710 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:35  [ pool-24-thread-1:10711 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:35  [ pool-24-thread-1:10711 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:35  [ pool-24-thread-1:10760 ] - [ INFO ]  Task:attempt_local1921099520_0007_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:35  [ pool-24-thread-1:10766 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:35  [ pool-24-thread-1:10766 ] - [ INFO ]  Task attempt_local1921099520_0007_r_000000_0 is allowed to commit now
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  Saved output of task 'attempt_local1921099520_0007_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1921099520_0007_r_000000
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  Task 'attempt_local1921099520_0007_r_000000_0' done.
2020-11-19 10:13:36  [ pool-24-thread-1:10787 ] - [ INFO ]  Finishing task: attempt_local1921099520_0007_r_000000_0
2020-11-19 10:13:36  [ Thread-198:10787 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:36  [ main:11617 ] - [ INFO ]  Job job_local1921099520_0007 running in uber mode : false
2020-11-19 10:13:36  [ main:11617 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:36  [ main:11617 ] - [ INFO ]  Job job_local1921099520_0007 completed successfully
2020-11-19 10:13:36  [ main:11619 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=91554
		FILE: Number of bytes written=4074780
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=447876
		HDFS: Number of bytes written=6246
		HDFS: Number of read operations=401
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=134
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:37  [ main:11936 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:37  [ main:11947 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:37  [ main:11952 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:37  [ main:11957 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:37  [ main:11996 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:37  [ main:12013 ] - [ INFO ]  Submitting tokens for job: job_local694841777_0008
2020-11-19 10:13:37  [ main:12048 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:37  [ main:12048 ] - [ INFO ]  Running job: job_local694841777_0008
2020-11-19 10:13:37  [ Thread-228:12048 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:37  [ Thread-228:12048 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:37  [ Thread-228:12048 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:37  [ Thread-228:12056 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]  Starting task: attempt_local694841777_0008_m_000000_0
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12056 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12057 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12064 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12131 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12133 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12134 ] - [ INFO ]  Task:attempt_local694841777_0008_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12140 ] - [ INFO ]  map
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12140 ] - [ INFO ]  Task 'attempt_local694841777_0008_m_000000_0' done.
2020-11-19 10:13:37  [ LocalJobRunner Map Task Executor #0:12140 ] - [ INFO ]  Finishing task: attempt_local694841777_0008_m_000000_0
2020-11-19 10:13:37  [ Thread-228:12140 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:37  [ Thread-228:12141 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:37  [ pool-27-thread-1:12141 ] - [ INFO ]  Starting task: attempt_local694841777_0008_r_000000_0
2020-11-19 10:13:37  [ pool-27-thread-1:12141 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@170f9268
2020-11-19 10:13:37  [ pool-27-thread-1:12142 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:37  [ EventFetcher for fetching Map Completion Events:12142 ] - [ INFO ]  attempt_local694841777_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:37  [ localfetcher#8:12143 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local694841777_0008_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:37  [ localfetcher#8:12143 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local694841777_0008_m_000000_0
2020-11-19 10:13:37  [ localfetcher#8:12143 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:37  [ EventFetcher for fetching Map Completion Events:12144 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:37  [ pool-27-thread-1:12144 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:37  [ pool-27-thread-1:12144 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:37  [ pool-27-thread-1:12145 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:37  [ pool-27-thread-1:12146 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:37  [ pool-27-thread-1:12146 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:37  [ pool-27-thread-1:12187 ] - [ INFO ]  Task:attempt_local694841777_0008_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:37  [ pool-27-thread-1:12193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:37  [ pool-27-thread-1:12193 ] - [ INFO ]  Task attempt_local694841777_0008_r_000000_0 is allowed to commit now
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  Saved output of task 'attempt_local694841777_0008_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local694841777_0008_r_000000
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  Task 'attempt_local694841777_0008_r_000000_0' done.
2020-11-19 10:13:37  [ pool-27-thread-1:12210 ] - [ INFO ]  Finishing task: attempt_local694841777_0008_r_000000_0
2020-11-19 10:13:37  [ Thread-228:12210 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:38  [ main:13049 ] - [ INFO ]  Job job_local694841777_0008 running in uber mode : false
2020-11-19 10:13:38  [ main:13050 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:38  [ main:13050 ] - [ INFO ]  Job job_local694841777_0008 completed successfully
2020-11-19 10:13:38  [ main:13051 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=92746
		FILE: Number of bytes written=4643653
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=512282
		HDFS: Number of bytes written=7326
		HDFS: Number of read operations=469
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=156
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:38  [ main:13314 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:38  [ main:13324 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:38  [ main:13328 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:38  [ main:13334 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:38  [ main:13373 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:38  [ main:13390 ] - [ INFO ]  Submitting tokens for job: job_local633411448_0009
2020-11-19 10:13:38  [ main:13424 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:38  [ main:13424 ] - [ INFO ]  Running job: job_local633411448_0009
2020-11-19 10:13:38  [ Thread-258:13424 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:38  [ Thread-258:13424 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:38  [ Thread-258:13424 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:38  [ Thread-258:13433 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13433 ] - [ INFO ]  Starting task: attempt_local633411448_0009_m_000000_0
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13434 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13442 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13509 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13511 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13512 ] - [ INFO ]  Task:attempt_local633411448_0009_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13519 ] - [ INFO ]  map
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13520 ] - [ INFO ]  Task 'attempt_local633411448_0009_m_000000_0' done.
2020-11-19 10:13:38  [ LocalJobRunner Map Task Executor #0:13520 ] - [ INFO ]  Finishing task: attempt_local633411448_0009_m_000000_0
2020-11-19 10:13:38  [ Thread-258:13520 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:38  [ Thread-258:13520 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:38  [ pool-30-thread-1:13520 ] - [ INFO ]  Starting task: attempt_local633411448_0009_r_000000_0
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f849f75
2020-11-19 10:13:38  [ pool-30-thread-1:13521 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:38  [ EventFetcher for fetching Map Completion Events:13522 ] - [ INFO ]  attempt_local633411448_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:38  [ localfetcher#9:13522 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local633411448_0009_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:38  [ localfetcher#9:13522 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local633411448_0009_m_000000_0
2020-11-19 10:13:38  [ localfetcher#9:13523 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:38  [ EventFetcher for fetching Map Completion Events:13523 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:38  [ pool-30-thread-1:13523 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:38  [ pool-30-thread-1:13523 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:38  [ pool-30-thread-1:13524 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:38  [ pool-30-thread-1:13524 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:38  [ pool-30-thread-1:13524 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:38  [ pool-30-thread-1:13525 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:38  [ pool-30-thread-1:13567 ] - [ INFO ]  Task:attempt_local633411448_0009_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:38  [ pool-30-thread-1:13573 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:38  [ pool-30-thread-1:13573 ] - [ INFO ]  Task attempt_local633411448_0009_r_000000_0 is allowed to commit now
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  Saved output of task 'attempt_local633411448_0009_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local633411448_0009_r_000000
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  Task 'attempt_local633411448_0009_r_000000_0' done.
2020-11-19 10:13:38  [ pool-30-thread-1:13589 ] - [ INFO ]  Finishing task: attempt_local633411448_0009_r_000000_0
2020-11-19 10:13:38  [ Thread-258:13589 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:39  [ main:14429 ] - [ INFO ]  Job job_local633411448_0009 running in uber mode : false
2020-11-19 10:13:39  [ main:14430 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:39  [ main:14430 ] - [ INFO ]  Job job_local633411448_0009 completed successfully
2020-11-19 10:13:39  [ main:14431 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=93938
		FILE: Number of bytes written=5212524
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=576688
		HDFS: Number of bytes written=8406
		HDFS: Number of read operations=537
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=178
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1487929344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:39  [ main:14682 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:39  [ main:14695 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:39  [ main:14699 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:39  [ main:14704 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:39  [ main:14744 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:39  [ main:14762 ] - [ INFO ]  Submitting tokens for job: job_local1836307206_0010
2020-11-19 10:13:40  [ main:14798 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:40  [ main:14799 ] - [ INFO ]  Running job: job_local1836307206_0010
2020-11-19 10:13:40  [ Thread-288:14799 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:40  [ Thread-288:14799 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:40  [ Thread-288:14799 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:40  [ Thread-288:14807 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]  Starting task: attempt_local1836307206_0010_m_000000_0
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14807 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14808 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14817 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14892 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14895 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14896 ] - [ INFO ]  Task:attempt_local1836307206_0010_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14901 ] - [ INFO ]  map
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14901 ] - [ INFO ]  Task 'attempt_local1836307206_0010_m_000000_0' done.
2020-11-19 10:13:40  [ LocalJobRunner Map Task Executor #0:14901 ] - [ INFO ]  Finishing task: attempt_local1836307206_0010_m_000000_0
2020-11-19 10:13:40  [ Thread-288:14901 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:40  [ Thread-288:14902 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:40  [ pool-33-thread-1:14902 ] - [ INFO ]  Starting task: attempt_local1836307206_0010_r_000000_0
2020-11-19 10:13:40  [ pool-33-thread-1:14902 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64ced2fd
2020-11-19 10:13:40  [ pool-33-thread-1:14903 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:40  [ EventFetcher for fetching Map Completion Events:14903 ] - [ INFO ]  attempt_local1836307206_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:40  [ localfetcher#10:14904 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1836307206_0010_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:40  [ localfetcher#10:14904 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1836307206_0010_m_000000_0
2020-11-19 10:13:40  [ localfetcher#10:14904 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:40  [ EventFetcher for fetching Map Completion Events:14905 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:40  [ pool-33-thread-1:14905 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:40  [ pool-33-thread-1:14905 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:40  [ pool-33-thread-1:14906 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:40  [ pool-33-thread-1:14906 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:40  [ pool-33-thread-1:14906 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:40  [ pool-33-thread-1:14907 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:40  [ pool-33-thread-1:14961 ] - [ INFO ]  Task:attempt_local1836307206_0010_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:40  [ pool-33-thread-1:14966 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:40  [ pool-33-thread-1:14966 ] - [ INFO ]  Task attempt_local1836307206_0010_r_000000_0 is allowed to commit now
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  Saved output of task 'attempt_local1836307206_0010_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1836307206_0010_r_000000
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  Task 'attempt_local1836307206_0010_r_000000_0' done.
2020-11-19 10:13:40  [ pool-33-thread-1:14982 ] - [ INFO ]  Finishing task: attempt_local1836307206_0010_r_000000_0
2020-11-19 10:13:40  [ Thread-288:14982 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:41  [ main:15801 ] - [ INFO ]  Job job_local1836307206_0010 running in uber mode : false
2020-11-19 10:13:41  [ main:15801 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:41  [ main:15801 ] - [ INFO ]  Job job_local1836307206_0010 completed successfully
2020-11-19 10:13:41  [ main:15802 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=95128
		FILE: Number of bytes written=5784442
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=641094
		HDFS: Number of bytes written=9486
		HDFS: Number of read operations=605
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=200
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1504706560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:41  [ main:16056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:41  [ main:16065 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:41  [ main:16069 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:41  [ main:16075 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:41  [ main:16113 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:41  [ main:16133 ] - [ INFO ]  Submitting tokens for job: job_local2041082458_0011
2020-11-19 10:13:41  [ main:16178 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:41  [ main:16178 ] - [ INFO ]  Running job: job_local2041082458_0011
2020-11-19 10:13:41  [ Thread-318:16178 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:41  [ Thread-318:16179 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:41  [ Thread-318:16179 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:41  [ Thread-318:16186 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16186 ] - [ INFO ]  Starting task: attempt_local2041082458_0011_m_000000_0
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16187 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16197 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16265 ] - [ INFO ]  
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16266 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16268 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16269 ] - [ INFO ]  Task:attempt_local2041082458_0011_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16275 ] - [ INFO ]  map
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16275 ] - [ INFO ]  Task 'attempt_local2041082458_0011_m_000000_0' done.
2020-11-19 10:13:41  [ LocalJobRunner Map Task Executor #0:16275 ] - [ INFO ]  Finishing task: attempt_local2041082458_0011_m_000000_0
2020-11-19 10:13:41  [ Thread-318:16275 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:41  [ Thread-318:16275 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:41  [ pool-36-thread-1:16275 ] - [ INFO ]  Starting task: attempt_local2041082458_0011_r_000000_0
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@779e96ed
2020-11-19 10:13:41  [ pool-36-thread-1:16276 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:41  [ EventFetcher for fetching Map Completion Events:16277 ] - [ INFO ]  attempt_local2041082458_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:41  [ localfetcher#11:16278 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local2041082458_0011_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:41  [ localfetcher#11:16278 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local2041082458_0011_m_000000_0
2020-11-19 10:13:41  [ localfetcher#11:16278 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:41  [ EventFetcher for fetching Map Completion Events:16278 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:41  [ pool-36-thread-1:16278 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:41  [ pool-36-thread-1:16278 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:41  [ pool-36-thread-1:16279 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:41  [ pool-36-thread-1:16279 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:41  [ pool-36-thread-1:16280 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:41  [ pool-36-thread-1:16324 ] - [ INFO ]  Task:attempt_local2041082458_0011_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:41  [ pool-36-thread-1:16330 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:41  [ pool-36-thread-1:16330 ] - [ INFO ]  Task attempt_local2041082458_0011_r_000000_0 is allowed to commit now
2020-11-19 10:13:41  [ pool-36-thread-1:16348 ] - [ INFO ]  Saved output of task 'attempt_local2041082458_0011_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2041082458_0011_r_000000
2020-11-19 10:13:41  [ pool-36-thread-1:16349 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:41  [ pool-36-thread-1:16349 ] - [ INFO ]  Task 'attempt_local2041082458_0011_r_000000_0' done.
2020-11-19 10:13:41  [ pool-36-thread-1:16349 ] - [ INFO ]  Finishing task: attempt_local2041082458_0011_r_000000_0
2020-11-19 10:13:41  [ Thread-318:16349 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:42  [ main:17179 ] - [ INFO ]  Job job_local2041082458_0011 running in uber mode : false
2020-11-19 10:13:42  [ main:17179 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:42  [ main:17180 ] - [ INFO ]  Job job_local2041082458_0011 completed successfully
2020-11-19 10:13:42  [ main:17181 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=96320
		FILE: Number of bytes written=6356363
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=705500
		HDFS: Number of bytes written=10566
		HDFS: Number of read operations=673
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=222
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1514143744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:42  [ main:17474 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:42  [ main:17486 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:42  [ main:17491 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:42  [ main:17496 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:42  [ main:17531 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:42  [ main:17546 ] - [ INFO ]  Submitting tokens for job: job_local1518534492_0012
2020-11-19 10:13:42  [ main:17582 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:42  [ main:17582 ] - [ INFO ]  Running job: job_local1518534492_0012
2020-11-19 10:13:42  [ Thread-348:17582 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:42  [ Thread-348:17583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:42  [ Thread-348:17583 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:42  [ Thread-348:17591 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]  Starting task: attempt_local1518534492_0012_m_000000_0
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17591 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17592 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17625 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17626 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17748 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17751 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17752 ] - [ INFO ]  Task:attempt_local1518534492_0012_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17757 ] - [ INFO ]  map
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17757 ] - [ INFO ]  Task 'attempt_local1518534492_0012_m_000000_0' done.
2020-11-19 10:13:42  [ LocalJobRunner Map Task Executor #0:17757 ] - [ INFO ]  Finishing task: attempt_local1518534492_0012_m_000000_0
2020-11-19 10:13:42  [ Thread-348:17757 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:42  [ Thread-348:17758 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:42  [ pool-39-thread-1:17758 ] - [ INFO ]  Starting task: attempt_local1518534492_0012_r_000000_0
2020-11-19 10:13:42  [ pool-39-thread-1:17758 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7f90cf5b
2020-11-19 10:13:42  [ pool-39-thread-1:17759 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:42  [ EventFetcher for fetching Map Completion Events:17759 ] - [ INFO ]  attempt_local1518534492_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:42  [ localfetcher#12:17760 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local1518534492_0012_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:42  [ localfetcher#12:17760 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1518534492_0012_m_000000_0
2020-11-19 10:13:42  [ localfetcher#12:17760 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:42  [ EventFetcher for fetching Map Completion Events:17760 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:42  [ pool-39-thread-1:17761 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:42  [ pool-39-thread-1:17762 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:43  [ pool-39-thread-1:17810 ] - [ INFO ]  Task:attempt_local1518534492_0012_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:43  [ pool-39-thread-1:17815 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:43  [ pool-39-thread-1:17815 ] - [ INFO ]  Task attempt_local1518534492_0012_r_000000_0 is allowed to commit now
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  Saved output of task 'attempt_local1518534492_0012_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1518534492_0012_r_000000
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  Task 'attempt_local1518534492_0012_r_000000_0' done.
2020-11-19 10:13:43  [ pool-39-thread-1:17831 ] - [ INFO ]  Finishing task: attempt_local1518534492_0012_r_000000_0
2020-11-19 10:13:43  [ Thread-348:17831 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:43  [ main:18585 ] - [ INFO ]  Job job_local1518534492_0012 running in uber mode : false
2020-11-19 10:13:43  [ main:18586 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:43  [ main:18586 ] - [ INFO ]  Job job_local1518534492_0012 completed successfully
2020-11-19 10:13:43  [ main:18587 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=97512
		FILE: Number of bytes written=6928286
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=769906
		HDFS: Number of bytes written=11646
		HDFS: Number of read operations=741
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=244
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=39
		Total committed heap usage (bytes)=2015363072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:44  [ main:18900 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:44  [ main:18910 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:44  [ main:18914 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:44  [ main:18924 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:44  [ main:18961 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:44  [ main:18981 ] - [ INFO ]  Submitting tokens for job: job_local1027567860_0013
2020-11-19 10:13:44  [ main:19019 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:44  [ main:19019 ] - [ INFO ]  Running job: job_local1027567860_0013
2020-11-19 10:13:44  [ Thread-378:19019 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:44  [ Thread-378:19019 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:44  [ Thread-378:19019 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:44  [ Thread-378:19040 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19040 ] - [ INFO ]  Starting task: attempt_local1027567860_0013_m_000000_0
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19041 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19049 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19050 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19125 ] - [ INFO ]  
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19125 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19126 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19126 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19126 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19129 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19130 ] - [ INFO ]  Task:attempt_local1027567860_0013_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19139 ] - [ INFO ]  map
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19139 ] - [ INFO ]  Task 'attempt_local1027567860_0013_m_000000_0' done.
2020-11-19 10:13:44  [ LocalJobRunner Map Task Executor #0:19139 ] - [ INFO ]  Finishing task: attempt_local1027567860_0013_m_000000_0
2020-11-19 10:13:44  [ Thread-378:19139 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:44  [ Thread-378:19140 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]  Starting task: attempt_local1027567860_0013_r_000000_0
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:44  [ pool-42-thread-1:19140 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:44  [ pool-42-thread-1:19141 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61ae3b10
2020-11-19 10:13:44  [ pool-42-thread-1:19141 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:44  [ EventFetcher for fetching Map Completion Events:19141 ] - [ INFO ]  attempt_local1027567860_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:44  [ localfetcher#13:19142 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local1027567860_0013_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:44  [ localfetcher#13:19142 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1027567860_0013_m_000000_0
2020-11-19 10:13:44  [ localfetcher#13:19142 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:44  [ EventFetcher for fetching Map Completion Events:19142 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:44  [ pool-42-thread-1:19142 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:44  [ pool-42-thread-1:19142 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:44  [ pool-42-thread-1:19143 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:44  [ pool-42-thread-1:19144 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:44  [ pool-42-thread-1:19185 ] - [ INFO ]  Task:attempt_local1027567860_0013_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:44  [ pool-42-thread-1:19190 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:44  [ pool-42-thread-1:19190 ] - [ INFO ]  Task attempt_local1027567860_0013_r_000000_0 is allowed to commit now
2020-11-19 10:13:44  [ pool-42-thread-1:19209 ] - [ INFO ]  Saved output of task 'attempt_local1027567860_0013_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1027567860_0013_r_000000
2020-11-19 10:13:44  [ pool-42-thread-1:19209 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:44  [ pool-42-thread-1:19210 ] - [ INFO ]  Task 'attempt_local1027567860_0013_r_000000_0' done.
2020-11-19 10:13:44  [ pool-42-thread-1:19210 ] - [ INFO ]  Finishing task: attempt_local1027567860_0013_r_000000_0
2020-11-19 10:13:44  [ Thread-378:19210 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:45  [ main:20022 ] - [ INFO ]  Job job_local1027567860_0013 running in uber mode : false
2020-11-19 10:13:45  [ main:20022 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:45  [ main:20022 ] - [ INFO ]  Job job_local1027567860_0013 completed successfully
2020-11-19 10:13:45  [ main:20023 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=98702
		FILE: Number of bytes written=7500208
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=834312
		HDFS: Number of bytes written=12726
		HDFS: Number of read operations=809
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=266
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2015363072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:45  [ main:20303 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:45  [ main:20313 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:45  [ main:20317 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:45  [ main:20322 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:45  [ main:20361 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:45  [ main:20379 ] - [ INFO ]  Submitting tokens for job: job_local1130360853_0014
2020-11-19 10:13:45  [ main:20417 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:45  [ main:20417 ] - [ INFO ]  Running job: job_local1130360853_0014
2020-11-19 10:13:45  [ Thread-408:20417 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:45  [ Thread-408:20418 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:45  [ Thread-408:20418 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:45  [ Thread-408:20425 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20425 ] - [ INFO ]  Starting task: attempt_local1130360853_0014_m_000000_0
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20425 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20426 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20426 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20426 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20452 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20453 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20523 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20527 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20528 ] - [ INFO ]  Task:attempt_local1130360853_0014_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20536 ] - [ INFO ]  map
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20536 ] - [ INFO ]  Task 'attempt_local1130360853_0014_m_000000_0' done.
2020-11-19 10:13:45  [ LocalJobRunner Map Task Executor #0:20536 ] - [ INFO ]  Finishing task: attempt_local1130360853_0014_m_000000_0
2020-11-19 10:13:45  [ Thread-408:20536 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:45  [ Thread-408:20536 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:45  [ pool-45-thread-1:20536 ] - [ INFO ]  Starting task: attempt_local1130360853_0014_r_000000_0
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:45  [ pool-45-thread-1:20537 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@430da8cd
2020-11-19 10:13:45  [ pool-45-thread-1:20538 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:45  [ EventFetcher for fetching Map Completion Events:20538 ] - [ INFO ]  attempt_local1130360853_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:45  [ localfetcher#14:20539 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local1130360853_0014_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:45  [ localfetcher#14:20539 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1130360853_0014_m_000000_0
2020-11-19 10:13:45  [ localfetcher#14:20539 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:45  [ EventFetcher for fetching Map Completion Events:20539 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:45  [ pool-45-thread-1:20539 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:45  [ pool-45-thread-1:20539 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:45  [ pool-45-thread-1:20540 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:45  [ pool-45-thread-1:20540 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:45  [ pool-45-thread-1:20541 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:45  [ pool-45-thread-1:20542 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:45  [ pool-45-thread-1:20596 ] - [ INFO ]  Task:attempt_local1130360853_0014_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:45  [ pool-45-thread-1:20602 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:45  [ pool-45-thread-1:20602 ] - [ INFO ]  Task attempt_local1130360853_0014_r_000000_0 is allowed to commit now
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  Saved output of task 'attempt_local1130360853_0014_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1130360853_0014_r_000000
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  Task 'attempt_local1130360853_0014_r_000000_0' done.
2020-11-19 10:13:45  [ pool-45-thread-1:20618 ] - [ INFO ]  Finishing task: attempt_local1130360853_0014_r_000000_0
2020-11-19 10:13:45  [ Thread-408:20618 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:46  [ main:21422 ] - [ INFO ]  Job job_local1130360853_0014 running in uber mode : false
2020-11-19 10:13:46  [ main:21422 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:46  [ main:21423 ] - [ INFO ]  Job job_local1130360853_0014 completed successfully
2020-11-19 10:13:46  [ main:21423 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=99894
		FILE: Number of bytes written=8072133
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=898718
		HDFS: Number of bytes written=13806
		HDFS: Number of read operations=877
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=288
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2015363072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:46  [ main:21729 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:46  [ main:21741 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:46  [ main:21745 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:46  [ main:21751 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:47  [ main:21788 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:47  [ main:21809 ] - [ INFO ]  Submitting tokens for job: job_local739671580_0015
2020-11-19 10:13:47  [ main:21852 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:47  [ main:21852 ] - [ INFO ]  Running job: job_local739671580_0015
2020-11-19 10:13:47  [ Thread-438:21852 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:47  [ Thread-438:21852 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:47  [ Thread-438:21852 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:47  [ Thread-438:21860 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21860 ] - [ INFO ]  Starting task: attempt_local739671580_0015_m_000000_0
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21860 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21861 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21861 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21861 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21871 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21941 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21944 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21945 ] - [ INFO ]  Task:attempt_local739671580_0015_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21951 ] - [ INFO ]  map
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21951 ] - [ INFO ]  Task 'attempt_local739671580_0015_m_000000_0' done.
2020-11-19 10:13:47  [ LocalJobRunner Map Task Executor #0:21951 ] - [ INFO ]  Finishing task: attempt_local739671580_0015_m_000000_0
2020-11-19 10:13:47  [ Thread-438:21951 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:47  [ Thread-438:21952 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  Starting task: attempt_local739671580_0015_r_000000_0
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:47  [ pool-48-thread-1:21952 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@587c4103
2020-11-19 10:13:47  [ pool-48-thread-1:21953 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:47  [ EventFetcher for fetching Map Completion Events:21953 ] - [ INFO ]  attempt_local739671580_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:47  [ localfetcher#15:21953 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local739671580_0015_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:47  [ localfetcher#15:21954 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local739671580_0015_m_000000_0
2020-11-19 10:13:47  [ localfetcher#15:21954 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:47  [ EventFetcher for fetching Map Completion Events:21954 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:47  [ pool-48-thread-1:21954 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:47  [ pool-48-thread-1:21954 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:47  [ pool-48-thread-1:21955 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:47  [ pool-48-thread-1:21955 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:47  [ pool-48-thread-1:21956 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:47  [ pool-48-thread-1:21957 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:47  [ pool-48-thread-1:21997 ] - [ INFO ]  Task:attempt_local739671580_0015_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:47  [ pool-48-thread-1:22002 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:47  [ pool-48-thread-1:22002 ] - [ INFO ]  Task attempt_local739671580_0015_r_000000_0 is allowed to commit now
2020-11-19 10:13:47  [ pool-48-thread-1:22018 ] - [ INFO ]  Saved output of task 'attempt_local739671580_0015_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local739671580_0015_r_000000
2020-11-19 10:13:47  [ pool-48-thread-1:22019 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:47  [ pool-48-thread-1:22019 ] - [ INFO ]  Task 'attempt_local739671580_0015_r_000000_0' done.
2020-11-19 10:13:47  [ pool-48-thread-1:22019 ] - [ INFO ]  Finishing task: attempt_local739671580_0015_r_000000_0
2020-11-19 10:13:47  [ Thread-438:22019 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:48  [ main:22855 ] - [ INFO ]  Job job_local739671580_0015 running in uber mode : false
2020-11-19 10:13:48  [ main:22855 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:48  [ main:22855 ] - [ INFO ]  Job job_local739671580_0015 completed successfully
2020-11-19 10:13:48  [ main:22857 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=101086
		FILE: Number of bytes written=8641008
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=963124
		HDFS: Number of bytes written=14886
		HDFS: Number of read operations=945
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=310
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2024800256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:48  [ main:23168 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:48  [ main:23179 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:48  [ main:23184 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:48  [ main:23190 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:48  [ main:23229 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:48  [ main:23247 ] - [ INFO ]  Submitting tokens for job: job_local1625719503_0016
2020-11-19 10:13:48  [ main:23281 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:48  [ main:23281 ] - [ INFO ]  Running job: job_local1625719503_0016
2020-11-19 10:13:48  [ Thread-468:23281 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:48  [ Thread-468:23281 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:48  [ Thread-468:23282 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:48  [ Thread-468:23289 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23289 ] - [ INFO ]  Starting task: attempt_local1625719503_0016_m_000000_0
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23290 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23298 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23299 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23373 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23375 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23376 ] - [ INFO ]  Task:attempt_local1625719503_0016_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23381 ] - [ INFO ]  map
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23381 ] - [ INFO ]  Task 'attempt_local1625719503_0016_m_000000_0' done.
2020-11-19 10:13:48  [ LocalJobRunner Map Task Executor #0:23381 ] - [ INFO ]  Finishing task: attempt_local1625719503_0016_m_000000_0
2020-11-19 10:13:48  [ Thread-468:23381 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:48  [ Thread-468:23382 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]  Starting task: attempt_local1625719503_0016_r_000000_0
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:48  [ pool-51-thread-1:23382 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:48  [ pool-51-thread-1:23383 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3888df8f
2020-11-19 10:13:48  [ pool-51-thread-1:23383 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:48  [ EventFetcher for fetching Map Completion Events:23383 ] - [ INFO ]  attempt_local1625719503_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:48  [ localfetcher#16:23384 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local1625719503_0016_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:48  [ localfetcher#16:23384 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1625719503_0016_m_000000_0
2020-11-19 10:13:48  [ localfetcher#16:23384 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:48  [ EventFetcher for fetching Map Completion Events:23384 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:48  [ pool-51-thread-1:23385 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:48  [ pool-51-thread-1:23385 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:48  [ pool-51-thread-1:23386 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:48  [ pool-51-thread-1:23442 ] - [ INFO ]  Task:attempt_local1625719503_0016_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:48  [ pool-51-thread-1:23447 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:48  [ pool-51-thread-1:23447 ] - [ INFO ]  Task attempt_local1625719503_0016_r_000000_0 is allowed to commit now
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  Saved output of task 'attempt_local1625719503_0016_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1625719503_0016_r_000000
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  Task 'attempt_local1625719503_0016_r_000000_0' done.
2020-11-19 10:13:48  [ pool-51-thread-1:23465 ] - [ INFO ]  Finishing task: attempt_local1625719503_0016_r_000000_0
2020-11-19 10:13:48  [ Thread-468:23466 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:49  [ main:24284 ] - [ INFO ]  Job job_local1625719503_0016 running in uber mode : false
2020-11-19 10:13:49  [ main:24284 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:49  [ main:24284 ] - [ INFO ]  Job job_local1625719503_0016 completed successfully
2020-11-19 10:13:49  [ main:24285 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=102276
		FILE: Number of bytes written=9212930
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1027530
		HDFS: Number of bytes written=15966
		HDFS: Number of read operations=1013
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=332
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2024800256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:49  [ main:24575 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:49  [ main:24584 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:49  [ main:24588 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:49  [ main:24594 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:49  [ main:24627 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:49  [ main:24643 ] - [ INFO ]  Submitting tokens for job: job_local1070818853_0017
2020-11-19 10:13:49  [ main:24675 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:49  [ main:24675 ] - [ INFO ]  Running job: job_local1070818853_0017
2020-11-19 10:13:49  [ Thread-498:24676 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:49  [ Thread-498:24676 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:49  [ Thread-498:24676 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:49  [ Thread-498:24683 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24683 ] - [ INFO ]  Starting task: attempt_local1070818853_0017_m_000000_0
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24683 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24683 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24684 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24684 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24693 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24694 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24766 ] - [ INFO ]  
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24767 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24769 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24770 ] - [ INFO ]  Task:attempt_local1070818853_0017_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24776 ] - [ INFO ]  map
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24776 ] - [ INFO ]  Task 'attempt_local1070818853_0017_m_000000_0' done.
2020-11-19 10:13:49  [ LocalJobRunner Map Task Executor #0:24776 ] - [ INFO ]  Finishing task: attempt_local1070818853_0017_m_000000_0
2020-11-19 10:13:49  [ Thread-498:24776 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:49  [ Thread-498:24777 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  Starting task: attempt_local1070818853_0017_r_000000_0
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:49  [ pool-54-thread-1:24777 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21df333d
2020-11-19 10:13:49  [ pool-54-thread-1:24778 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:49  [ EventFetcher for fetching Map Completion Events:24778 ] - [ INFO ]  attempt_local1070818853_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:49  [ localfetcher#17:24779 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local1070818853_0017_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:13:49  [ localfetcher#17:24779 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1070818853_0017_m_000000_0
2020-11-19 10:13:49  [ localfetcher#17:24779 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:13:49  [ EventFetcher for fetching Map Completion Events:24779 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:49  [ pool-54-thread-1:24779 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:49  [ pool-54-thread-1:24779 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:49  [ pool-54-thread-1:24780 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:49  [ pool-54-thread-1:24780 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:13:49  [ pool-54-thread-1:24781 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:50  [ pool-54-thread-1:24847 ] - [ INFO ]  Task:attempt_local1070818853_0017_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:50  [ pool-54-thread-1:24854 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:50  [ pool-54-thread-1:24854 ] - [ INFO ]  Task attempt_local1070818853_0017_r_000000_0 is allowed to commit now
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  Saved output of task 'attempt_local1070818853_0017_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1070818853_0017_r_000000
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  Task 'attempt_local1070818853_0017_r_000000_0' done.
2020-11-19 10:13:50  [ pool-54-thread-1:24870 ] - [ INFO ]  Finishing task: attempt_local1070818853_0017_r_000000_0
2020-11-19 10:13:50  [ Thread-498:24870 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:13:50  [ main:25677 ] - [ INFO ]  Job job_local1070818853_0017 running in uber mode : false
2020-11-19 10:13:50  [ main:25677 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:13:50  [ main:25677 ] - [ INFO ]  Job job_local1070818853_0017 completed successfully
2020-11-19 10:13:50  [ main:25678 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=103468
		FILE: Number of bytes written=9784855
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1091936
		HDFS: Number of bytes written=17046
		HDFS: Number of read operations=1081
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=354
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2337275904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:13:51  [ main:25957 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:13:51  [ main:25967 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:13:51  [ main:25971 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:13:51  [ main:25976 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:13:51  [ main:26011 ] - [ INFO ]  number of splits:1
2020-11-19 10:13:51  [ main:26028 ] - [ INFO ]  Submitting tokens for job: job_local1137772343_0018
2020-11-19 10:13:51  [ main:26063 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:13:51  [ main:26063 ] - [ INFO ]  Running job: job_local1137772343_0018
2020-11-19 10:13:51  [ Thread-528:26064 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:13:51  [ Thread-528:26064 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:51  [ Thread-528:26064 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:13:51  [ Thread-528:26071 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]  Starting task: attempt_local1137772343_0018_m_000000_0
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26071 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26072 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26080 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  Spilling map output
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26149 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26151 ] - [ INFO ]  Finished spill 0
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26152 ] - [ INFO ]  Task:attempt_local1137772343_0018_m_000000_0 is done. And is in the process of committing
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26157 ] - [ INFO ]  map
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26157 ] - [ INFO ]  Task 'attempt_local1137772343_0018_m_000000_0' done.
2020-11-19 10:13:51  [ LocalJobRunner Map Task Executor #0:26157 ] - [ INFO ]  Finishing task: attempt_local1137772343_0018_m_000000_0
2020-11-19 10:13:51  [ Thread-528:26157 ] - [ INFO ]  map task executor complete.
2020-11-19 10:13:51  [ Thread-528:26158 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  Starting task: attempt_local1137772343_0018_r_000000_0
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:13:51  [ pool-57-thread-1:26158 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@203836d2
2020-11-19 10:13:51  [ pool-57-thread-1:26159 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:13:51  [ EventFetcher for fetching Map Completion Events:26159 ] - [ INFO ]  attempt_local1137772343_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:13:51  [ localfetcher#18:26159 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local1137772343_0018_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:13:51  [ localfetcher#18:26160 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1137772343_0018_m_000000_0
2020-11-19 10:13:51  [ localfetcher#18:26160 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:13:51  [ EventFetcher for fetching Map Completion Events:26160 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:13:51  [ pool-57-thread-1:26160 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:51  [ pool-57-thread-1:26160 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:13:51  [ pool-57-thread-1:26161 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:51  [ pool-57-thread-1:26161 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:13:51  [ pool-57-thread-1:26162 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:51  [ pool-57-thread-1:26218 ] - [ INFO ]  Task:attempt_local1137772343_0018_r_000000_0 is done. And is in the process of committing
2020-11-19 10:13:51  [ pool-57-thread-1:26224 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:13:51  [ pool-57-thread-1:26224 ] - [ INFO ]  Task attempt_local1137772343_0018_r_000000_0 is allowed to commit now
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  Saved output of task 'attempt_local1137772343_0018_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1137772343_0018_r_000000
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  reduce > reduce
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  Task 'attempt_local1137772343_0018_r_000000_0' done.
2020-11-19 10:13:51  [ pool-57-thread-1:26244 ] - [ INFO ]  Finishing task: attempt_local1137772343_0018_r_000000_0
2020-11-19 10:13:51  [ Thread-528:26244 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 10:14:54  [ main:585 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 10:14:54  [ main:585 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 10:14:54  [ main:775 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:54  [ main:779 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:54  [ main:791 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:54  [ main:866 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:54  [ main:933 ] - [ INFO ]  Submitting tokens for job: job_local853577622_0001
2020-11-19 10:14:54  [ main:1031 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:54  [ main:1032 ] - [ INFO ]  Running job: job_local853577622_0001
2020-11-19 10:14:54  [ Thread-18:1032 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:54  [ Thread-18:1035 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:54  [ Thread-18:1037 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:54  [ Thread-18:1080 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1081 ] - [ INFO ]  Starting task: attempt_local853577622_0001_m_000000_0
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1099 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1100 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1102 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1152 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1154 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1247 ] - [ INFO ]  
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  bufstart = 0; bufend = 19877; bufvoid = 104857600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1249 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213068(104852272); length = 1329/6553600
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1257 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1260 ] - [ INFO ]  Task:attempt_local853577622_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1273 ] - [ INFO ]  map
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1273 ] - [ INFO ]  Task 'attempt_local853577622_0001_m_000000_0' done.
2020-11-19 10:14:54  [ LocalJobRunner Map Task Executor #0:1273 ] - [ INFO ]  Finishing task: attempt_local853577622_0001_m_000000_0
2020-11-19 10:14:54  [ Thread-18:1273 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:54  [ Thread-18:1275 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:54  [ pool-6-thread-1:1275 ] - [ INFO ]  Starting task: attempt_local853577622_0001_r_000000_0
2020-11-19 10:14:54  [ pool-6-thread-1:1280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:54  [ pool-6-thread-1:1280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:54  [ pool-6-thread-1:1281 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:54  [ pool-6-thread-1:1282 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57dc39e0
2020-11-19 10:14:54  [ pool-6-thread-1:1291 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:54  [ EventFetcher for fetching Map Completion Events:1293 ] - [ INFO ]  attempt_local853577622_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:54  [ localfetcher#1:1313 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local853577622_0001_m_000000_0 decomp: 20545 len: 20549 to MEMORY
2020-11-19 10:14:54  [ localfetcher#1:1317 ] - [ INFO ]  Read 20545 bytes from map-output for attempt_local853577622_0001_m_000000_0
2020-11-19 10:14:54  [ localfetcher#1:1318 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20545, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20545
2020-11-19 10:14:54  [ EventFetcher for fetching Map Completion Events:1319 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:54  [ pool-6-thread-1:1319 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:54  [ pool-6-thread-1:1320 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:54  [ pool-6-thread-1:1324 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:54  [ pool-6-thread-1:1324 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20541 bytes
2020-11-19 10:14:54  [ pool-6-thread-1:1327 ] - [ INFO ]  Merged 1 segments, 20545 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:54  [ pool-6-thread-1:1327 ] - [ INFO ]  Merging 1 files, 20549 bytes from disk
2020-11-19 10:14:54  [ pool-6-thread-1:1328 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:54  [ pool-6-thread-1:1328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:54  [ pool-6-thread-1:1328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20541 bytes
2020-11-19 10:14:54  [ pool-6-thread-1:1329 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:54  [ pool-6-thread-1:1351 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 10:14:55  [ pool-6-thread-1:1484 ] - [ INFO ]  Task:attempt_local853577622_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:55  [ pool-6-thread-1:1493 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:55  [ pool-6-thread-1:1493 ] - [ INFO ]  Task attempt_local853577622_0001_r_000000_0 is allowed to commit now
2020-11-19 10:14:55  [ pool-6-thread-1:1516 ] - [ INFO ]  Saved output of task 'attempt_local853577622_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local853577622_0001_r_000000
2020-11-19 10:14:55  [ pool-6-thread-1:1517 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:55  [ pool-6-thread-1:1517 ] - [ INFO ]  Task 'attempt_local853577622_0001_r_000000_0' done.
2020-11-19 10:14:55  [ pool-6-thread-1:1517 ] - [ INFO ]  Finishing task: attempt_local853577622_0001_r_000000_0
2020-11-19 10:14:55  [ Thread-18:1517 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:55  [ main:2037 ] - [ INFO ]  Job job_local853577622_0001 running in uber mode : false
2020-11-19 10:14:55  [ main:2038 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:55  [ main:2039 ] - [ INFO ]  Job job_local853577622_0001 completed successfully
2020-11-19 10:14:55  [ main:2046 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=41480
		FILE: Number of bytes written=626805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=181
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=333
		Map output bytes=19877
		Map output materialized bytes=20549
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20549
		Reduce input records=333
		Reduce output records=3
		Spilled Records=666
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:55  [ main:2188 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:55  [ main:2200 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:55  [ main:2204 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:55  [ main:2210 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:55  [ main:2252 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:55  [ main:2272 ] - [ INFO ]  Submitting tokens for job: job_local1814568215_0002
2020-11-19 10:14:55  [ main:2315 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:55  [ main:2315 ] - [ INFO ]  Running job: job_local1814568215_0002
2020-11-19 10:14:55  [ Thread-48:2315 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:55  [ Thread-48:2315 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:55  [ Thread-48:2315 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:55  [ Thread-48:2325 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2325 ] - [ INFO ]  Starting task: attempt_local1814568215_0002_m_000000_0
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2326 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2326 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2326 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2327 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2367 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:55  [ LocalJobRunner Map Task Executor #0:2368 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2457 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2465 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2467 ] - [ INFO ]  Task:attempt_local1814568215_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  map
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  Task 'attempt_local1814568215_0002_m_000000_0' done.
2020-11-19 10:14:56  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  Finishing task: attempt_local1814568215_0002_m_000000_0
2020-11-19 10:14:56  [ Thread-48:2474 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:56  [ Thread-48:2475 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:56  [ pool-9-thread-1:2475 ] - [ INFO ]  Starting task: attempt_local1814568215_0002_r_000000_0
2020-11-19 10:14:56  [ pool-9-thread-1:2475 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:56  [ pool-9-thread-1:2476 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:56  [ pool-9-thread-1:2476 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:56  [ pool-9-thread-1:2476 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a73e19a
2020-11-19 10:14:56  [ pool-9-thread-1:2477 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:56  [ EventFetcher for fetching Map Completion Events:2477 ] - [ INFO ]  attempt_local1814568215_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:56  [ localfetcher#2:2478 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1814568215_0002_m_000000_0 decomp: 183 len: 187 to MEMORY
2020-11-19 10:14:56  [ localfetcher#2:2478 ] - [ INFO ]  Read 183 bytes from map-output for attempt_local1814568215_0002_m_000000_0
2020-11-19 10:14:56  [ localfetcher#2:2478 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 183, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->183
2020-11-19 10:14:56  [ EventFetcher for fetching Map Completion Events:2479 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:56  [ pool-9-thread-1:2479 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:56  [ pool-9-thread-1:2479 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:56  [ pool-9-thread-1:2480 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 179 bytes
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merged 1 segments, 183 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merging 1 files, 187 bytes from disk
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:56  [ pool-9-thread-1:2481 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:56  [ pool-9-thread-1:2482 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 179 bytes
2020-11-19 10:14:56  [ pool-9-thread-1:2482 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:56  [ pool-9-thread-1:2539 ] - [ INFO ]  Task:attempt_local1814568215_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:56  [ pool-9-thread-1:2545 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:56  [ pool-9-thread-1:2545 ] - [ INFO ]  Task attempt_local1814568215_0002_r_000000_0 is allowed to commit now
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  Saved output of task 'attempt_local1814568215_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1814568215_0002_r_000000
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  Task 'attempt_local1814568215_0002_r_000000_0' done.
2020-11-19 10:14:56  [ pool-9-thread-1:2563 ] - [ INFO ]  Finishing task: attempt_local1814568215_0002_r_000000_0
2020-11-19 10:14:56  [ Thread-48:2564 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:56  [ main:3318 ] - [ INFO ]  Job job_local1814568215_0002 running in uber mode : false
2020-11-19 10:14:56  [ main:3319 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:56  [ main:3319 ] - [ INFO ]  Job job_local1814568215_0002 completed successfully
2020-11-19 10:14:56  [ main:3321 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=83366
		FILE: Number of bytes written=1219057
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125936
		HDFS: Number of bytes written=905
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=187
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=187
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:57  [ main:3616 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:57  [ main:3628 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:57  [ main:3632 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:57  [ main:3639 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:57  [ main:3682 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:57  [ main:3706 ] - [ INFO ]  Submitting tokens for job: job_local614724230_0003
2020-11-19 10:14:57  [ main:3756 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:57  [ main:3756 ] - [ INFO ]  Running job: job_local614724230_0003
2020-11-19 10:14:57  [ Thread-78:3756 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:57  [ Thread-78:3756 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:57  [ Thread-78:3756 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:57  [ Thread-78:3765 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3765 ] - [ INFO ]  Starting task: attempt_local614724230_0003_m_000000_0
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3766 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3766 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3766 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3767 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3788 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3789 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3977 ] - [ INFO ]  
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3978 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3983 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3984 ] - [ INFO ]  Task:attempt_local614724230_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3991 ] - [ INFO ]  map
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3991 ] - [ INFO ]  Task 'attempt_local614724230_0003_m_000000_0' done.
2020-11-19 10:14:57  [ LocalJobRunner Map Task Executor #0:3991 ] - [ INFO ]  Finishing task: attempt_local614724230_0003_m_000000_0
2020-11-19 10:14:57  [ Thread-78:3991 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:57  [ Thread-78:3992 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:57  [ pool-12-thread-1:3992 ] - [ INFO ]  Starting task: attempt_local614724230_0003_r_000000_0
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a6d5f8e
2020-11-19 10:14:57  [ pool-12-thread-1:3993 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:57  [ EventFetcher for fetching Map Completion Events:3994 ] - [ INFO ]  attempt_local614724230_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:57  [ localfetcher#3:3995 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local614724230_0003_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:14:57  [ localfetcher#3:3995 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local614724230_0003_m_000000_0
2020-11-19 10:14:57  [ localfetcher#3:3995 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:14:57  [ EventFetcher for fetching Map Completion Events:3996 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:57  [ pool-12-thread-1:3996 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:57  [ pool-12-thread-1:3996 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:57  [ pool-12-thread-1:3998 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:57  [ pool-12-thread-1:3998 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:57  [ pool-12-thread-1:3998 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:57  [ pool-12-thread-1:3999 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:57  [ pool-12-thread-1:4048 ] - [ INFO ]  Task:attempt_local614724230_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:57  [ pool-12-thread-1:4054 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:57  [ pool-12-thread-1:4054 ] - [ INFO ]  Task attempt_local614724230_0003_r_000000_0 is allowed to commit now
2020-11-19 10:14:57  [ pool-12-thread-1:4070 ] - [ INFO ]  Saved output of task 'attempt_local614724230_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local614724230_0003_r_000000
2020-11-19 10:14:57  [ pool-12-thread-1:4071 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:57  [ pool-12-thread-1:4071 ] - [ INFO ]  Task 'attempt_local614724230_0003_r_000000_0' done.
2020-11-19 10:14:57  [ pool-12-thread-1:4071 ] - [ INFO ]  Finishing task: attempt_local614724230_0003_r_000000_0
2020-11-19 10:14:57  [ Thread-78:4071 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:58  [ main:4757 ] - [ INFO ]  Job job_local614724230_0003 running in uber mode : false
2020-11-19 10:14:58  [ main:4757 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:58  [ main:4758 ] - [ INFO ]  Job job_local614724230_0003 completed successfully
2020-11-19 10:14:58  [ main:4761 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84542
		FILE: Number of bytes written=1787920
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190352
		HDFS: Number of bytes written=1991
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=94
		Total committed heap usage (bytes)=1027604480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:58  [ main:5079 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:58  [ main:5089 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:58  [ main:5093 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:58  [ main:5098 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:58  [ main:5138 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:58  [ main:5157 ] - [ INFO ]  Submitting tokens for job: job_local1521157371_0004
2020-11-19 10:14:58  [ main:5197 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:58  [ main:5197 ] - [ INFO ]  Running job: job_local1521157371_0004
2020-11-19 10:14:58  [ Thread-108:5197 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:58  [ Thread-108:5197 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:58  [ Thread-108:5198 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:58  [ Thread-108:5207 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  Starting task: attempt_local1521157371_0004_m_000000_0
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5208 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5208 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5208 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  Spilling map output
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5291 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5295 ] - [ INFO ]  Finished spill 0
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5296 ] - [ INFO ]  Task:attempt_local1521157371_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5303 ] - [ INFO ]  map
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5303 ] - [ INFO ]  Task 'attempt_local1521157371_0004_m_000000_0' done.
2020-11-19 10:14:58  [ LocalJobRunner Map Task Executor #0:5303 ] - [ INFO ]  Finishing task: attempt_local1521157371_0004_m_000000_0
2020-11-19 10:14:58  [ Thread-108:5304 ] - [ INFO ]  map task executor complete.
2020-11-19 10:14:58  [ Thread-108:5304 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:14:58  [ pool-15-thread-1:5304 ] - [ INFO ]  Starting task: attempt_local1521157371_0004_r_000000_0
2020-11-19 10:14:58  [ pool-15-thread-1:5305 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@131866ad
2020-11-19 10:14:58  [ pool-15-thread-1:5306 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:14:58  [ EventFetcher for fetching Map Completion Events:5306 ] - [ INFO ]  attempt_local1521157371_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:14:58  [ localfetcher#4:5307 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1521157371_0004_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:14:58  [ localfetcher#4:5308 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1521157371_0004_m_000000_0
2020-11-19 10:14:58  [ localfetcher#4:5308 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:14:58  [ EventFetcher for fetching Map Completion Events:5308 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:14:58  [ pool-15-thread-1:5308 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:58  [ pool-15-thread-1:5309 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:14:58  [ pool-15-thread-1:5309 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:58  [ pool-15-thread-1:5309 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:14:58  [ pool-15-thread-1:5310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:14:58  [ pool-15-thread-1:5311 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:58  [ pool-15-thread-1:5371 ] - [ INFO ]  Task:attempt_local1521157371_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 10:14:58  [ pool-15-thread-1:5379 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:14:58  [ pool-15-thread-1:5379 ] - [ INFO ]  Task attempt_local1521157371_0004_r_000000_0 is allowed to commit now
2020-11-19 10:14:58  [ pool-15-thread-1:5400 ] - [ INFO ]  Saved output of task 'attempt_local1521157371_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1521157371_0004_r_000000
2020-11-19 10:14:58  [ pool-15-thread-1:5401 ] - [ INFO ]  reduce > reduce
2020-11-19 10:14:58  [ pool-15-thread-1:5401 ] - [ INFO ]  Task 'attempt_local1521157371_0004_r_000000_0' done.
2020-11-19 10:14:58  [ pool-15-thread-1:5401 ] - [ INFO ]  Finishing task: attempt_local1521157371_0004_r_000000_0
2020-11-19 10:14:58  [ Thread-108:5401 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:14:59  [ main:6202 ] - [ INFO ]  Job job_local1521157371_0004 running in uber mode : false
2020-11-19 10:14:59  [ main:6203 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:14:59  [ main:6203 ] - [ INFO ]  Job job_local1521157371_0004 completed successfully
2020-11-19 10:14:59  [ main:6205 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=85732
		FILE: Number of bytes written=2359838
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254768
		HDFS: Number of bytes written=3077
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1027604480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=181
2020-11-19 10:14:59  [ main:6289 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:14:59  [ main:6305 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:14:59  [ main:6310 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:14:59  [ main:6317 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:14:59  [ main:6358 ] - [ INFO ]  number of splits:1
2020-11-19 10:14:59  [ main:6378 ] - [ INFO ]  Submitting tokens for job: job_local435709595_0005
2020-11-19 10:14:59  [ main:6413 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:14:59  [ main:6413 ] - [ INFO ]  Running job: job_local435709595_0005
2020-11-19 10:14:59  [ Thread-134:6413 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:14:59  [ Thread-134:6414 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:59  [ Thread-134:6414 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:14:59  [ Thread-134:6422 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6422 ] - [ INFO ]  Starting task: attempt_local435709595_0005_m_000000_0
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6423 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6423 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6423 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6424 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/tmp/center.txt:0+181
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:14:59  [ LocalJobRunner Map Task Executor #0:6434 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  Spilling map output
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  bufstart = 0; bufend = 123; bufvoid = 104857600
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6491 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6494 ] - [ INFO ]  Finished spill 0
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6495 ] - [ INFO ]  Task:attempt_local435709595_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6502 ] - [ INFO ]  map
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6502 ] - [ INFO ]  Task 'attempt_local435709595_0005_m_000000_0' done.
2020-11-19 10:15:00  [ LocalJobRunner Map Task Executor #0:6502 ] - [ INFO ]  Finishing task: attempt_local435709595_0005_m_000000_0
2020-11-19 10:15:00  [ Thread-134:6502 ] - [ INFO ]  map task executor complete.
2020-11-19 10:15:00  [ Thread-134:6503 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:15:00  [ pool-18-thread-1:6503 ] - [ INFO ]  Starting task: attempt_local435709595_0005_r_000000_0
2020-11-19 10:15:00  [ pool-18-thread-1:6503 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52aeabe3
2020-11-19 10:15:00  [ pool-18-thread-1:6504 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:15:00  [ EventFetcher for fetching Map Completion Events:6504 ] - [ INFO ]  attempt_local435709595_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:15:00  [ localfetcher#5:6505 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local435709595_0005_m_000000_0 decomp: 131 len: 135 to MEMORY
2020-11-19 10:15:00  [ localfetcher#5:6505 ] - [ INFO ]  Read 131 bytes from map-output for attempt_local435709595_0005_m_000000_0
2020-11-19 10:15:00  [ localfetcher#5:6505 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 131, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->131
2020-11-19 10:15:00  [ EventFetcher for fetching Map Completion Events:6506 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:15:00  [ pool-18-thread-1:6506 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:15:00  [ pool-18-thread-1:6506 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:15:00  [ pool-18-thread-1:6507 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:15:00  [ pool-18-thread-1:6507 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 127 bytes
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merged 1 segments, 131 bytes to disk to satisfy reduce memory limit
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merging 1 files, 135 bytes from disk
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 127 bytes
2020-11-19 10:15:00  [ pool-18-thread-1:6508 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:15:00  [ pool-18-thread-1:6556 ] - [ INFO ]  Task:attempt_local435709595_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 10:15:00  [ pool-18-thread-1:6563 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:15:00  [ pool-18-thread-1:6563 ] - [ INFO ]  Task attempt_local435709595_0005_r_000000_0 is allowed to commit now
2020-11-19 10:15:00  [ main:7414 ] - [ INFO ]  Job job_local435709595_0005 running in uber mode : false
2020-11-19 10:15:00  [ main:7415 ] - [ INFO ]   map 100% reduce 0%
2020-11-19 10:15:00  [ pool-18-thread-1:7444 ] - [ INFO ]  Saved output of task 'attempt_local435709595_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local435709595_0005_r_000000
2020-11-19 10:15:00  [ pool-18-thread-1:7445 ] - [ INFO ]  reduce > reduce
2020-11-19 10:15:00  [ pool-18-thread-1:7445 ] - [ INFO ]  Task 'attempt_local435709595_0005_r_000000_0' done.
2020-11-19 10:15:00  [ pool-18-thread-1:7445 ] - [ INFO ]  Finishing task: attempt_local435709595_0005_r_000000_0
2020-11-19 10:15:00  [ Thread-134:7445 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:15:01  [ main:8419 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:15:01  [ main:8419 ] - [ INFO ]  Job job_local435709595_0005 completed successfully
2020-11-19 10:15:01  [ main:8421 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86804
		FILE: Number of bytes written=2925191
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=256216
		HDFS: Number of bytes written=3381
		HDFS: Number of read operations=245
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=82
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Map output bytes=123
		Map output materialized bytes=135
		Input split bytes=123
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=135
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1027604480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=181
	File Output Format Counters 
		Bytes Written=123
2020-11-19 10:18:12  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-19 10:18:12  [ main:565 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-19 10:18:12  [ main:565 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-19 10:18:12  [ main:747 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:12  [ main:752 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:12  [ main:766 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:12  [ main:839 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:12  [ main:902 ] - [ INFO ]  Submitting tokens for job: job_local2080574219_0001
2020-11-19 10:18:13  [ main:999 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:13  [ main:1000 ] - [ INFO ]  Running job: job_local2080574219_0001
2020-11-19 10:18:13  [ Thread-18:1000 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:13  [ Thread-18:1004 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:13  [ Thread-18:1006 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:13  [ Thread-18:1041 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1041 ] - [ INFO ]  Starting task: attempt_local2080574219_0001_m_000000_0
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1060 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1064 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1064 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1067 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1120 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1207 ] - [ INFO ]  
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  bufstart = 0; bufend = 19965; bufvoid = 104857600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1209 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213064(104852256); length = 1333/6553600
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1217 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1220 ] - [ INFO ]  Task:attempt_local2080574219_0001_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  map
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  Task 'attempt_local2080574219_0001_m_000000_0' done.
2020-11-19 10:18:13  [ LocalJobRunner Map Task Executor #0:1231 ] - [ INFO ]  Finishing task: attempt_local2080574219_0001_m_000000_0
2020-11-19 10:18:13  [ Thread-18:1231 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:13  [ Thread-18:1233 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:13  [ pool-6-thread-1:1233 ] - [ INFO ]  Starting task: attempt_local2080574219_0001_r_000000_0
2020-11-19 10:18:13  [ pool-6-thread-1:1237 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:13  [ pool-6-thread-1:1238 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:13  [ pool-6-thread-1:1238 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:13  [ pool-6-thread-1:1239 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7eea48c7
2020-11-19 10:18:13  [ pool-6-thread-1:1247 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:13  [ EventFetcher for fetching Map Completion Events:1249 ] - [ INFO ]  attempt_local2080574219_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:13  [ localfetcher#1:1267 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2080574219_0001_m_000000_0 decomp: 20635 len: 20639 to MEMORY
2020-11-19 10:18:13  [ localfetcher#1:1271 ] - [ INFO ]  Read 20635 bytes from map-output for attempt_local2080574219_0001_m_000000_0
2020-11-19 10:18:13  [ localfetcher#1:1272 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 20635, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20635
2020-11-19 10:18:13  [ EventFetcher for fetching Map Completion Events:1273 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:13  [ pool-6-thread-1:1273 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:13  [ pool-6-thread-1:1273 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:13  [ pool-6-thread-1:1277 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:13  [ pool-6-thread-1:1278 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20631 bytes
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merged 1 segments, 20635 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merging 1 files, 20639 bytes from disk
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:13  [ pool-6-thread-1:1280 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:13  [ pool-6-thread-1:1281 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 20631 bytes
2020-11-19 10:18:13  [ pool-6-thread-1:1281 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:13  [ pool-6-thread-1:1300 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-19 10:18:13  [ pool-6-thread-1:1407 ] - [ INFO ]  Task:attempt_local2080574219_0001_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:13  [ pool-6-thread-1:1414 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:13  [ pool-6-thread-1:1414 ] - [ INFO ]  Task attempt_local2080574219_0001_r_000000_0 is allowed to commit now
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  Saved output of task 'attempt_local2080574219_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2080574219_0001_r_000000
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  Task 'attempt_local2080574219_0001_r_000000_0' done.
2020-11-19 10:18:13  [ pool-6-thread-1:1444 ] - [ INFO ]  Finishing task: attempt_local2080574219_0001_r_000000_0
2020-11-19 10:18:13  [ Thread-18:1444 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:14  [ main:2002 ] - [ INFO ]  Job job_local2080574219_0001 running in uber mode : false
2020-11-19 10:18:14  [ main:2003 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:14  [ main:2004 ] - [ INFO ]  Job job_local2080574219_0001 completed successfully
2020-11-19 10:18:14  [ main:2011 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=41660
		FILE: Number of bytes written=630107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=62606
		HDFS: Number of bytes written=178
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=501
		Map output records=334
		Map output bytes=19965
		Map output materialized bytes=20639
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=20639
		Reduce input records=334
		Reduce output records=3
		Spilled Records=668
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 10:18:14  [ main:2119 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:14  [ main:2130 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:14  [ main:2135 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:14  [ main:2141 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:14  [ main:2182 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:14  [ main:2201 ] - [ INFO ]  Submitting tokens for job: job_local1023893339_0002
2020-11-19 10:18:14  [ main:2242 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:14  [ main:2242 ] - [ INFO ]  Running job: job_local1023893339_0002
2020-11-19 10:18:14  [ Thread-48:2242 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:14  [ Thread-48:2243 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:14  [ Thread-48:2243 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:14  [ Thread-48:2250 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2250 ] - [ INFO ]  Starting task: attempt_local1023893339_0002_m_000000_0
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2251 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2252 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2252 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2253 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2293 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2294 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2366 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2372 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2373 ] - [ INFO ]  Task:attempt_local1023893339_0002_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2382 ] - [ INFO ]  map
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2382 ] - [ INFO ]  Task 'attempt_local1023893339_0002_m_000000_0' done.
2020-11-19 10:18:14  [ LocalJobRunner Map Task Executor #0:2382 ] - [ INFO ]  Finishing task: attempt_local1023893339_0002_m_000000_0
2020-11-19 10:18:14  [ Thread-48:2382 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:14  [ Thread-48:2382 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:14  [ pool-9-thread-1:2383 ] - [ INFO ]  Starting task: attempt_local1023893339_0002_r_000000_0
2020-11-19 10:18:14  [ pool-9-thread-1:2383 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@18b11366
2020-11-19 10:18:14  [ pool-9-thread-1:2384 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:14  [ EventFetcher for fetching Map Completion Events:2385 ] - [ INFO ]  attempt_local1023893339_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:14  [ localfetcher#2:2385 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1023893339_0002_m_000000_0 decomp: 189 len: 193 to MEMORY
2020-11-19 10:18:14  [ localfetcher#2:2386 ] - [ INFO ]  Read 189 bytes from map-output for attempt_local1023893339_0002_m_000000_0
2020-11-19 10:18:14  [ localfetcher#2:2386 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 189, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->189
2020-11-19 10:18:14  [ EventFetcher for fetching Map Completion Events:2386 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:14  [ pool-9-thread-1:2386 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:14  [ pool-9-thread-1:2387 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:14  [ pool-9-thread-1:2387 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:14  [ pool-9-thread-1:2387 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merged 1 segments, 189 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merging 1 files, 193 bytes from disk
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:14  [ pool-9-thread-1:2388 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2020-11-19 10:18:14  [ pool-9-thread-1:2389 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:14  [ pool-9-thread-1:2439 ] - [ INFO ]  Task:attempt_local1023893339_0002_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:14  [ pool-9-thread-1:2445 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:14  [ pool-9-thread-1:2446 ] - [ INFO ]  Task attempt_local1023893339_0002_r_000000_0 is allowed to commit now
2020-11-19 10:18:14  [ pool-9-thread-1:2463 ] - [ INFO ]  Saved output of task 'attempt_local1023893339_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1023893339_0002_r_000000
2020-11-19 10:18:14  [ pool-9-thread-1:2464 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:14  [ pool-9-thread-1:2464 ] - [ INFO ]  Task 'attempt_local1023893339_0002_r_000000_0' done.
2020-11-19 10:18:14  [ pool-9-thread-1:2464 ] - [ INFO ]  Finishing task: attempt_local1023893339_0002_r_000000_0
2020-11-19 10:18:14  [ Thread-48:2464 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:15  [ main:3244 ] - [ INFO ]  Job job_local1023893339_0002 running in uber mode : false
2020-11-19 10:18:15  [ main:3245 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:15  [ main:3245 ] - [ INFO ]  Job job_local1023893339_0002 completed successfully
2020-11-19 10:18:15  [ main:3247 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=83738
		FILE: Number of bytes written=1222467
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=125924
		HDFS: Number of bytes written=890
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=193
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=193
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=178
2020-11-19 10:18:15  [ main:3554 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:15  [ main:3564 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:15  [ main:3568 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:15  [ main:3574 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:15  [ main:3609 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:15  [ main:3634 ] - [ INFO ]  Submitting tokens for job: job_local968598121_0003
2020-11-19 10:18:15  [ main:3687 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:15  [ main:3687 ] - [ INFO ]  Running job: job_local968598121_0003
2020-11-19 10:18:15  [ Thread-78:3687 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:15  [ Thread-78:3687 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:15  [ Thread-78:3687 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:15  [ Thread-78:3696 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3696 ] - [ INFO ]  Starting task: attempt_local968598121_0003_m_000000_0
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3697 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3697 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3698 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3718 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3719 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3805 ] - [ INFO ]  
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3806 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3809 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3912 ] - [ INFO ]  Task:attempt_local968598121_0003_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  map
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  Task 'attempt_local968598121_0003_m_000000_0' done.
2020-11-19 10:18:15  [ LocalJobRunner Map Task Executor #0:3918 ] - [ INFO ]  Finishing task: attempt_local968598121_0003_m_000000_0
2020-11-19 10:18:15  [ Thread-78:3918 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:15  [ Thread-78:3919 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:15  [ pool-12-thread-1:3919 ] - [ INFO ]  Starting task: attempt_local968598121_0003_r_000000_0
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55b16c99
2020-11-19 10:18:15  [ pool-12-thread-1:3920 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:15  [ EventFetcher for fetching Map Completion Events:3921 ] - [ INFO ]  attempt_local968598121_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:15  [ localfetcher#3:3922 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local968598121_0003_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:15  [ localfetcher#3:3922 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local968598121_0003_m_000000_0
2020-11-19 10:18:15  [ localfetcher#3:3922 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:15  [ EventFetcher for fetching Map Completion Events:3923 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:15  [ pool-12-thread-1:3923 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:15  [ pool-12-thread-1:3923 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:15  [ pool-12-thread-1:3924 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:15  [ pool-12-thread-1:3924 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:15  [ pool-12-thread-1:3925 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:15  [ pool-12-thread-1:3926 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:15  [ pool-12-thread-1:3926 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:15  [ pool-12-thread-1:3969 ] - [ INFO ]  Task:attempt_local968598121_0003_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:15  [ pool-12-thread-1:3974 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:15  [ pool-12-thread-1:3974 ] - [ INFO ]  Task attempt_local968598121_0003_r_000000_0 is allowed to commit now
2020-11-19 10:18:15  [ pool-12-thread-1:3993 ] - [ INFO ]  Saved output of task 'attempt_local968598121_0003_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local968598121_0003_r_000000
2020-11-19 10:18:15  [ pool-12-thread-1:3994 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:15  [ pool-12-thread-1:3994 ] - [ INFO ]  Task 'attempt_local968598121_0003_r_000000_0' done.
2020-11-19 10:18:15  [ pool-12-thread-1:3994 ] - [ INFO ]  Finishing task: attempt_local968598121_0003_r_000000_0
2020-11-19 10:18:15  [ Thread-78:3994 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:16  [ main:4687 ] - [ INFO ]  Job job_local968598121_0003 running in uber mode : false
2020-11-19 10:18:16  [ main:4687 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:16  [ main:4688 ] - [ INFO ]  Job job_local968598121_0003 completed successfully
2020-11-19 10:18:16  [ main:4690 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84926
		FILE: Number of bytes written=1791336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=190310
		HDFS: Number of bytes written=1960
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=46
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=100
		Total committed heap usage (bytes)=1026555904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:16  [ main:4958 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:16  [ main:4974 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:16  [ main:4980 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:16  [ main:4988 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:17  [ main:5034 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:17  [ main:5058 ] - [ INFO ]  Submitting tokens for job: job_local863482358_0004
2020-11-19 10:18:17  [ main:5104 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:17  [ main:5104 ] - [ INFO ]  Running job: job_local863482358_0004
2020-11-19 10:18:17  [ Thread-108:5104 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:17  [ Thread-108:5104 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:17  [ Thread-108:5104 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:17  [ Thread-108:5115 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5115 ] - [ INFO ]  Starting task: attempt_local863482358_0004_m_000000_0
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5116 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5116 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5116 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5117 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5127 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5206 ] - [ INFO ]  
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5206 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5207 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5210 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  Task:attempt_local863482358_0004_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  map
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  Task 'attempt_local863482358_0004_m_000000_0' done.
2020-11-19 10:18:17  [ LocalJobRunner Map Task Executor #0:5218 ] - [ INFO ]  Finishing task: attempt_local863482358_0004_m_000000_0
2020-11-19 10:18:17  [ Thread-108:5218 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:17  [ Thread-108:5219 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:17  [ pool-15-thread-1:5219 ] - [ INFO ]  Starting task: attempt_local863482358_0004_r_000000_0
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:17  [ pool-15-thread-1:5220 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7211e92
2020-11-19 10:18:17  [ pool-15-thread-1:5221 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:17  [ EventFetcher for fetching Map Completion Events:5221 ] - [ INFO ]  attempt_local863482358_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:17  [ localfetcher#4:5222 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local863482358_0004_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:17  [ localfetcher#4:5223 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local863482358_0004_m_000000_0
2020-11-19 10:18:17  [ localfetcher#4:5223 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:17  [ EventFetcher for fetching Map Completion Events:5223 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:17  [ pool-15-thread-1:5223 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:17  [ pool-15-thread-1:5223 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:17  [ pool-15-thread-1:5224 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:17  [ pool-15-thread-1:5224 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:17  [ pool-15-thread-1:5225 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:17  [ pool-15-thread-1:5274 ] - [ INFO ]  Task:attempt_local863482358_0004_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:17  [ pool-15-thread-1:5281 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:17  [ pool-15-thread-1:5281 ] - [ INFO ]  Task attempt_local863482358_0004_r_000000_0 is allowed to commit now
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  Saved output of task 'attempt_local863482358_0004_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local863482358_0004_r_000000
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  Task 'attempt_local863482358_0004_r_000000_0' done.
2020-11-19 10:18:17  [ pool-15-thread-1:5300 ] - [ INFO ]  Finishing task: attempt_local863482358_0004_r_000000_0
2020-11-19 10:18:17  [ Thread-108:5300 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:18  [ main:6108 ] - [ INFO ]  Job job_local863482358_0004 running in uber mode : false
2020-11-19 10:18:18  [ main:6108 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:18  [ main:6109 ] - [ INFO ]  Job job_local863482358_0004 completed successfully
2020-11-19 10:18:18  [ main:6111 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=86118
		FILE: Number of bytes written=2360209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254712
		HDFS: Number of bytes written=3040
		HDFS: Number of read operations=197
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1026555904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:18  [ main:6465 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:18  [ main:6476 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:18  [ main:6481 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:18  [ main:6487 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:18  [ main:6528 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:18  [ main:6548 ] - [ INFO ]  Submitting tokens for job: job_local62746438_0005
2020-11-19 10:18:18  [ main:6583 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:18  [ main:6583 ] - [ INFO ]  Running job: job_local62746438_0005
2020-11-19 10:18:18  [ Thread-138:6584 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:18  [ Thread-138:6584 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:18  [ Thread-138:6584 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:18  [ Thread-138:6591 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6591 ] - [ INFO ]  Starting task: attempt_local62746438_0005_m_000000_0
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6592 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6592 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6592 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6593 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6601 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6675 ] - [ INFO ]  
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6676 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6679 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6680 ] - [ INFO ]  Task:attempt_local62746438_0005_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6686 ] - [ INFO ]  map
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6686 ] - [ INFO ]  Task 'attempt_local62746438_0005_m_000000_0' done.
2020-11-19 10:18:18  [ LocalJobRunner Map Task Executor #0:6686 ] - [ INFO ]  Finishing task: attempt_local62746438_0005_m_000000_0
2020-11-19 10:18:18  [ Thread-138:6686 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:18  [ Thread-138:6687 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:18  [ pool-18-thread-1:6687 ] - [ INFO ]  Starting task: attempt_local62746438_0005_r_000000_0
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@62b7934b
2020-11-19 10:18:18  [ pool-18-thread-1:6688 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:18  [ EventFetcher for fetching Map Completion Events:6689 ] - [ INFO ]  attempt_local62746438_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:18  [ localfetcher#5:6689 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local62746438_0005_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:18  [ localfetcher#5:6690 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local62746438_0005_m_000000_0
2020-11-19 10:18:18  [ localfetcher#5:6690 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:18  [ EventFetcher for fetching Map Completion Events:6690 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:18  [ pool-18-thread-1:6690 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:18  [ pool-18-thread-1:6690 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:18  [ pool-18-thread-1:6691 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:18  [ pool-18-thread-1:6691 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:18  [ pool-18-thread-1:6692 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:18  [ pool-18-thread-1:6739 ] - [ INFO ]  Task:attempt_local62746438_0005_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:18  [ pool-18-thread-1:6745 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:18  [ pool-18-thread-1:6745 ] - [ INFO ]  Task attempt_local62746438_0005_r_000000_0 is allowed to commit now
2020-11-19 10:18:18  [ pool-18-thread-1:6765 ] - [ INFO ]  Saved output of task 'attempt_local62746438_0005_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local62746438_0005_r_000000
2020-11-19 10:18:18  [ pool-18-thread-1:6766 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:18  [ pool-18-thread-1:6766 ] - [ INFO ]  Task 'attempt_local62746438_0005_r_000000_0' done.
2020-11-19 10:18:18  [ pool-18-thread-1:6766 ] - [ INFO ]  Finishing task: attempt_local62746438_0005_r_000000_0
2020-11-19 10:18:18  [ Thread-138:6766 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:19  [ main:7584 ] - [ INFO ]  Job job_local62746438_0005 running in uber mode : false
2020-11-19 10:18:19  [ main:7585 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:19  [ main:7585 ] - [ INFO ]  Job job_local62746438_0005 completed successfully
2020-11-19 10:18:19  [ main:7587 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=87310
		FILE: Number of bytes written=2926032
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319118
		HDFS: Number of bytes written=4120
		HDFS: Number of read operations=265
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=90
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1026555904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:19  [ main:7860 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:19  [ main:7871 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:19  [ main:7876 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:19  [ main:7883 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:19  [ main:7922 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:19  [ main:7939 ] - [ INFO ]  Submitting tokens for job: job_local1668807133_0006
2020-11-19 10:18:19  [ main:7978 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:19  [ main:7979 ] - [ INFO ]  Running job: job_local1668807133_0006
2020-11-19 10:18:19  [ Thread-168:7979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:19  [ Thread-168:7979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:19  [ Thread-168:7979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:19  [ Thread-168:7986 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8032 ] - [ INFO ]  Starting task: attempt_local1668807133_0006_m_000000_0
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8032 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8033 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8033 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8033 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8041 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8042 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8114 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8117 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8118 ] - [ INFO ]  Task:attempt_local1668807133_0006_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8124 ] - [ INFO ]  map
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8124 ] - [ INFO ]  Task 'attempt_local1668807133_0006_m_000000_0' done.
2020-11-19 10:18:20  [ LocalJobRunner Map Task Executor #0:8124 ] - [ INFO ]  Finishing task: attempt_local1668807133_0006_m_000000_0
2020-11-19 10:18:20  [ Thread-168:8124 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:20  [ Thread-168:8124 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:20  [ pool-21-thread-1:8124 ] - [ INFO ]  Starting task: attempt_local1668807133_0006_r_000000_0
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35a693b9
2020-11-19 10:18:20  [ pool-21-thread-1:8125 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:20  [ EventFetcher for fetching Map Completion Events:8126 ] - [ INFO ]  attempt_local1668807133_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:20  [ localfetcher#6:8126 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local1668807133_0006_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:20  [ localfetcher#6:8127 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1668807133_0006_m_000000_0
2020-11-19 10:18:20  [ localfetcher#6:8127 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:20  [ EventFetcher for fetching Map Completion Events:8127 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:20  [ pool-21-thread-1:8127 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:20  [ pool-21-thread-1:8127 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:20  [ pool-21-thread-1:8128 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:20  [ pool-21-thread-1:8128 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:20  [ pool-21-thread-1:8128 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:20  [ pool-21-thread-1:8129 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:20  [ pool-21-thread-1:8187 ] - [ INFO ]  Task:attempt_local1668807133_0006_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:20  [ pool-21-thread-1:8193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:20  [ pool-21-thread-1:8193 ] - [ INFO ]  Task attempt_local1668807133_0006_r_000000_0 is allowed to commit now
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  Saved output of task 'attempt_local1668807133_0006_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1668807133_0006_r_000000
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  Task 'attempt_local1668807133_0006_r_000000_0' done.
2020-11-19 10:18:20  [ pool-21-thread-1:8212 ] - [ INFO ]  Finishing task: attempt_local1668807133_0006_r_000000_0
2020-11-19 10:18:20  [ Thread-168:8212 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:20  [ main:8981 ] - [ INFO ]  Job job_local1668807133_0006 running in uber mode : false
2020-11-19 10:18:20  [ main:8981 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:20  [ main:8981 ] - [ INFO ]  Job job_local1668807133_0006 completed successfully
2020-11-19 10:18:20  [ main:8983 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=88500
		FILE: Number of bytes written=3497950
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=383524
		HDFS: Number of bytes written=5200
		HDFS: Number of read operations=333
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=835715072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:21  [ main:9272 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:21  [ main:9283 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:21  [ main:9288 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:21  [ main:9294 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:21  [ main:9332 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:21  [ main:9349 ] - [ INFO ]  Submitting tokens for job: job_local120107098_0007
2020-11-19 10:18:21  [ main:9385 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:21  [ main:9385 ] - [ INFO ]  Running job: job_local120107098_0007
2020-11-19 10:18:21  [ Thread-198:9385 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:21  [ Thread-198:9385 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:21  [ Thread-198:9385 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:21  [ Thread-198:9392 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]  Starting task: attempt_local120107098_0007_m_000000_0
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9393 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9394 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9401 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9402 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9498 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9501 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9502 ] - [ INFO ]  Task:attempt_local120107098_0007_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9507 ] - [ INFO ]  map
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9507 ] - [ INFO ]  Task 'attempt_local120107098_0007_m_000000_0' done.
2020-11-19 10:18:21  [ LocalJobRunner Map Task Executor #0:9507 ] - [ INFO ]  Finishing task: attempt_local120107098_0007_m_000000_0
2020-11-19 10:18:21  [ Thread-198:9507 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:21  [ Thread-198:9508 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:21  [ pool-24-thread-1:9508 ] - [ INFO ]  Starting task: attempt_local120107098_0007_r_000000_0
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@670f98df
2020-11-19 10:18:21  [ pool-24-thread-1:9509 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:21  [ EventFetcher for fetching Map Completion Events:9510 ] - [ INFO ]  attempt_local120107098_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:21  [ localfetcher#7:9511 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local120107098_0007_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:21  [ localfetcher#7:9511 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local120107098_0007_m_000000_0
2020-11-19 10:18:21  [ localfetcher#7:9511 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:21  [ EventFetcher for fetching Map Completion Events:9511 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:21  [ pool-24-thread-1:9512 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:21  [ pool-24-thread-1:9513 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:21  [ pool-24-thread-1:9556 ] - [ INFO ]  Task:attempt_local120107098_0007_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:21  [ pool-24-thread-1:9562 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:21  [ pool-24-thread-1:9562 ] - [ INFO ]  Task attempt_local120107098_0007_r_000000_0 is allowed to commit now
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  Saved output of task 'attempt_local120107098_0007_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local120107098_0007_r_000000
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  Task 'attempt_local120107098_0007_r_000000_0' done.
2020-11-19 10:18:21  [ pool-24-thread-1:9584 ] - [ INFO ]  Finishing task: attempt_local120107098_0007_r_000000_0
2020-11-19 10:18:21  [ Thread-198:9584 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:22  [ main:10390 ] - [ INFO ]  Job job_local120107098_0007 running in uber mode : false
2020-11-19 10:18:22  [ main:10390 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:22  [ main:10390 ] - [ INFO ]  Job job_local120107098_0007 completed successfully
2020-11-19 10:18:22  [ main:10392 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=89692
		FILE: Number of bytes written=4066823
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=447930
		HDFS: Number of bytes written=6280
		HDFS: Number of read operations=401
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=134
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=836763648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:22  [ main:10664 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:22  [ main:10674 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:22  [ main:10679 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:22  [ main:10686 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:22  [ main:10726 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:22  [ main:10744 ] - [ INFO ]  Submitting tokens for job: job_local2010153951_0008
2020-11-19 10:18:22  [ main:10780 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:22  [ main:10780 ] - [ INFO ]  Running job: job_local2010153951_0008
2020-11-19 10:18:22  [ Thread-228:10780 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:22  [ Thread-228:10780 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:22  [ Thread-228:10780 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:22  [ Thread-228:10789 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10789 ] - [ INFO ]  Starting task: attempt_local2010153951_0008_m_000000_0
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10790 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10798 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10860 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10862 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10863 ] - [ INFO ]  Task:attempt_local2010153951_0008_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10870 ] - [ INFO ]  map
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10872 ] - [ INFO ]  Task 'attempt_local2010153951_0008_m_000000_0' done.
2020-11-19 10:18:22  [ LocalJobRunner Map Task Executor #0:10872 ] - [ INFO ]  Finishing task: attempt_local2010153951_0008_m_000000_0
2020-11-19 10:18:22  [ Thread-228:10872 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:22  [ Thread-228:10873 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:22  [ pool-27-thread-1:10873 ] - [ INFO ]  Starting task: attempt_local2010153951_0008_r_000000_0
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@302e1cd6
2020-11-19 10:18:22  [ pool-27-thread-1:10874 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:22  [ EventFetcher for fetching Map Completion Events:10875 ] - [ INFO ]  attempt_local2010153951_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:22  [ localfetcher#8:10876 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local2010153951_0008_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:22  [ localfetcher#8:10876 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2010153951_0008_m_000000_0
2020-11-19 10:18:22  [ localfetcher#8:10876 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:22  [ EventFetcher for fetching Map Completion Events:10877 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:22  [ pool-27-thread-1:10877 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:22  [ pool-27-thread-1:10877 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:22  [ pool-27-thread-1:10878 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:22  [ pool-27-thread-1:10879 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:22  [ pool-27-thread-1:10879 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:22  [ pool-27-thread-1:10879 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:22  [ pool-27-thread-1:10935 ] - [ INFO ]  Task:attempt_local2010153951_0008_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:22  [ pool-27-thread-1:10941 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:22  [ pool-27-thread-1:10941 ] - [ INFO ]  Task attempt_local2010153951_0008_r_000000_0 is allowed to commit now
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  Saved output of task 'attempt_local2010153951_0008_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2010153951_0008_r_000000
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  Task 'attempt_local2010153951_0008_r_000000_0' done.
2020-11-19 10:18:22  [ pool-27-thread-1:10958 ] - [ INFO ]  Finishing task: attempt_local2010153951_0008_r_000000_0
2020-11-19 10:18:22  [ Thread-228:10958 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:23  [ main:11784 ] - [ INFO ]  Job job_local2010153951_0008 running in uber mode : false
2020-11-19 10:18:23  [ main:11785 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:23  [ main:11785 ] - [ INFO ]  Job job_local2010153951_0008 completed successfully
2020-11-19 10:18:23  [ main:11786 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=90884
		FILE: Number of bytes written=4638742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=512336
		HDFS: Number of bytes written=7360
		HDFS: Number of read operations=469
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=156
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1058013184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:24  [ main:12080 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:24  [ main:12091 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:24  [ main:12095 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:24  [ main:12102 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:24  [ main:12136 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:24  [ main:12153 ] - [ INFO ]  Submitting tokens for job: job_local1892191704_0009
2020-11-19 10:18:24  [ main:12193 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:24  [ main:12193 ] - [ INFO ]  Running job: job_local1892191704_0009
2020-11-19 10:18:24  [ Thread-258:12193 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:24  [ Thread-258:12194 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:24  [ Thread-258:12194 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:24  [ Thread-258:12202 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]  Starting task: attempt_local1892191704_0009_m_000000_0
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12202 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12203 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12214 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12287 ] - [ INFO ]  
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12288 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12290 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12291 ] - [ INFO ]  Task:attempt_local1892191704_0009_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12296 ] - [ INFO ]  map
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12296 ] - [ INFO ]  Task 'attempt_local1892191704_0009_m_000000_0' done.
2020-11-19 10:18:24  [ LocalJobRunner Map Task Executor #0:12297 ] - [ INFO ]  Finishing task: attempt_local1892191704_0009_m_000000_0
2020-11-19 10:18:24  [ Thread-258:12297 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:24  [ Thread-258:12297 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:24  [ pool-30-thread-1:12297 ] - [ INFO ]  Starting task: attempt_local1892191704_0009_r_000000_0
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f0f48ae
2020-11-19 10:18:24  [ pool-30-thread-1:12298 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:24  [ EventFetcher for fetching Map Completion Events:12299 ] - [ INFO ]  attempt_local1892191704_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:24  [ localfetcher#9:12299 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local1892191704_0009_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:24  [ localfetcher#9:12299 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1892191704_0009_m_000000_0
2020-11-19 10:18:24  [ localfetcher#9:12300 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:24  [ EventFetcher for fetching Map Completion Events:12300 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:24  [ pool-30-thread-1:12300 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:24  [ pool-30-thread-1:12300 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:24  [ pool-30-thread-1:12301 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:24  [ pool-30-thread-1:12301 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:24  [ pool-30-thread-1:12302 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:24  [ pool-30-thread-1:12345 ] - [ INFO ]  Task:attempt_local1892191704_0009_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:24  [ pool-30-thread-1:12351 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:24  [ pool-30-thread-1:12351 ] - [ INFO ]  Task attempt_local1892191704_0009_r_000000_0 is allowed to commit now
2020-11-19 10:18:24  [ pool-30-thread-1:12367 ] - [ INFO ]  Saved output of task 'attempt_local1892191704_0009_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1892191704_0009_r_000000
2020-11-19 10:18:24  [ pool-30-thread-1:12368 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:24  [ pool-30-thread-1:12368 ] - [ INFO ]  Task 'attempt_local1892191704_0009_r_000000_0' done.
2020-11-19 10:18:24  [ pool-30-thread-1:12368 ] - [ INFO ]  Finishing task: attempt_local1892191704_0009_r_000000_0
2020-11-19 10:18:24  [ Thread-258:12368 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:25  [ main:13194 ] - [ INFO ]  Job job_local1892191704_0009 running in uber mode : false
2020-11-19 10:18:25  [ main:13195 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:25  [ main:13195 ] - [ INFO ]  Job job_local1892191704_0009 completed successfully
2020-11-19 10:18:25  [ main:13196 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=92074
		FILE: Number of bytes written=5210660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=576742
		HDFS: Number of bytes written=8440
		HDFS: Number of read operations=537
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=178
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1068498944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:25  [ main:13479 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:25  [ main:13489 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:25  [ main:13494 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:25  [ main:13500 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:25  [ main:13538 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:25  [ main:13555 ] - [ INFO ]  Submitting tokens for job: job_local1486998289_0010
2020-11-19 10:18:25  [ main:13592 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:25  [ main:13592 ] - [ INFO ]  Running job: job_local1486998289_0010
2020-11-19 10:18:25  [ Thread-288:13592 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:25  [ Thread-288:13593 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:25  [ Thread-288:13593 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:25  [ Thread-288:13600 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]  Starting task: attempt_local1486998289_0010_m_000000_0
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13600 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13601 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13610 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13670 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13673 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13674 ] - [ INFO ]  Task:attempt_local1486998289_0010_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13680 ] - [ INFO ]  map
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13680 ] - [ INFO ]  Task 'attempt_local1486998289_0010_m_000000_0' done.
2020-11-19 10:18:25  [ LocalJobRunner Map Task Executor #0:13680 ] - [ INFO ]  Finishing task: attempt_local1486998289_0010_m_000000_0
2020-11-19 10:18:25  [ Thread-288:13680 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:25  [ Thread-288:13681 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:25  [ pool-33-thread-1:13681 ] - [ INFO ]  Starting task: attempt_local1486998289_0010_r_000000_0
2020-11-19 10:18:25  [ pool-33-thread-1:13681 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a9ff27d
2020-11-19 10:18:25  [ pool-33-thread-1:13682 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:25  [ EventFetcher for fetching Map Completion Events:13682 ] - [ INFO ]  attempt_local1486998289_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:25  [ localfetcher#10:13683 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1486998289_0010_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:25  [ localfetcher#10:13683 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1486998289_0010_m_000000_0
2020-11-19 10:18:25  [ localfetcher#10:13683 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:25  [ EventFetcher for fetching Map Completion Events:13684 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:25  [ pool-33-thread-1:13684 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:25  [ pool-33-thread-1:13684 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:25  [ pool-33-thread-1:13685 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:25  [ pool-33-thread-1:13686 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:25  [ pool-33-thread-1:13686 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:25  [ pool-33-thread-1:13686 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:25  [ pool-33-thread-1:13740 ] - [ INFO ]  Task:attempt_local1486998289_0010_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:25  [ pool-33-thread-1:13745 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:25  [ pool-33-thread-1:13745 ] - [ INFO ]  Task attempt_local1486998289_0010_r_000000_0 is allowed to commit now
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  Saved output of task 'attempt_local1486998289_0010_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1486998289_0010_r_000000
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  Task 'attempt_local1486998289_0010_r_000000_0' done.
2020-11-19 10:18:25  [ pool-33-thread-1:13762 ] - [ INFO ]  Finishing task: attempt_local1486998289_0010_r_000000_0
2020-11-19 10:18:25  [ Thread-288:13762 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:26  [ main:14594 ] - [ INFO ]  Job job_local1486998289_0010 running in uber mode : false
2020-11-19 10:18:26  [ main:14595 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:26  [ main:14595 ] - [ INFO ]  Job job_local1486998289_0010 completed successfully
2020-11-19 10:18:26  [ main:14596 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=93266
		FILE: Number of bytes written=5782581
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=641148
		HDFS: Number of bytes written=9520
		HDFS: Number of read operations=605
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=200
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1269825536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:26  [ main:14866 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:26  [ main:14876 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:26  [ main:14881 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:26  [ main:14887 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:26  [ main:14928 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:26  [ main:14945 ] - [ INFO ]  Submitting tokens for job: job_local1132607359_0011
2020-11-19 10:18:26  [ main:14978 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:26  [ main:14978 ] - [ INFO ]  Running job: job_local1132607359_0011
2020-11-19 10:18:26  [ Thread-318:14979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:26  [ Thread-318:14979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:26  [ Thread-318:14979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:26  [ Thread-318:14986 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  Starting task: attempt_local1132607359_0011_m_000000_0
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:26  [ LocalJobRunner Map Task Executor #0:14987 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15024 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15089 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15092 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15093 ] - [ INFO ]  Task:attempt_local1132607359_0011_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15099 ] - [ INFO ]  map
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15099 ] - [ INFO ]  Task 'attempt_local1132607359_0011_m_000000_0' done.
2020-11-19 10:18:27  [ LocalJobRunner Map Task Executor #0:15099 ] - [ INFO ]  Finishing task: attempt_local1132607359_0011_m_000000_0
2020-11-19 10:18:27  [ Thread-318:15099 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:27  [ Thread-318:15100 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:27  [ pool-36-thread-1:15100 ] - [ INFO ]  Starting task: attempt_local1132607359_0011_r_000000_0
2020-11-19 10:18:27  [ pool-36-thread-1:15100 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1bffb309
2020-11-19 10:18:27  [ pool-36-thread-1:15101 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:27  [ EventFetcher for fetching Map Completion Events:15101 ] - [ INFO ]  attempt_local1132607359_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:27  [ localfetcher#11:15102 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local1132607359_0011_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:27  [ localfetcher#11:15102 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1132607359_0011_m_000000_0
2020-11-19 10:18:27  [ localfetcher#11:15102 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:27  [ EventFetcher for fetching Map Completion Events:15103 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:27  [ pool-36-thread-1:15103 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:27  [ pool-36-thread-1:15103 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:27  [ pool-36-thread-1:15104 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:27  [ pool-36-thread-1:15105 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:27  [ pool-36-thread-1:15148 ] - [ INFO ]  Task:attempt_local1132607359_0011_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:27  [ pool-36-thread-1:15153 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:27  [ pool-36-thread-1:15153 ] - [ INFO ]  Task attempt_local1132607359_0011_r_000000_0 is allowed to commit now
2020-11-19 10:18:27  [ pool-36-thread-1:15170 ] - [ INFO ]  Saved output of task 'attempt_local1132607359_0011_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1132607359_0011_r_000000
2020-11-19 10:18:27  [ pool-36-thread-1:15171 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:27  [ pool-36-thread-1:15171 ] - [ INFO ]  Task 'attempt_local1132607359_0011_r_000000_0' done.
2020-11-19 10:18:27  [ pool-36-thread-1:15171 ] - [ INFO ]  Finishing task: attempt_local1132607359_0011_r_000000_0
2020-11-19 10:18:27  [ Thread-318:15171 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:27  [ main:15982 ] - [ INFO ]  Job job_local1132607359_0011 running in uber mode : false
2020-11-19 10:18:27  [ main:15983 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:27  [ main:15983 ] - [ INFO ]  Job job_local1132607359_0011 completed successfully
2020-11-19 10:18:27  [ main:15984 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=94458
		FILE: Number of bytes written=6354500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=705554
		HDFS: Number of bytes written=10600
		HDFS: Number of read operations=673
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=222
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1269825536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:28  [ main:16256 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:28  [ main:16266 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:28  [ main:16271 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:28  [ main:16277 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:28  [ main:16312 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:28  [ main:16331 ] - [ INFO ]  Submitting tokens for job: job_local448977998_0012
2020-11-19 10:18:28  [ main:16371 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:28  [ main:16371 ] - [ INFO ]  Running job: job_local448977998_0012
2020-11-19 10:18:28  [ Thread-348:16371 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:28  [ Thread-348:16371 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:28  [ Thread-348:16371 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:28  [ Thread-348:16379 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]  Starting task: attempt_local448977998_0012_m_000000_0
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16379 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16380 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16389 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16459 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16462 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16463 ] - [ INFO ]  Task:attempt_local448977998_0012_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16470 ] - [ INFO ]  map
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16470 ] - [ INFO ]  Task 'attempt_local448977998_0012_m_000000_0' done.
2020-11-19 10:18:28  [ LocalJobRunner Map Task Executor #0:16471 ] - [ INFO ]  Finishing task: attempt_local448977998_0012_m_000000_0
2020-11-19 10:18:28  [ Thread-348:16471 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:28  [ Thread-348:16471 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:28  [ pool-39-thread-1:16471 ] - [ INFO ]  Starting task: attempt_local448977998_0012_r_000000_0
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:28  [ pool-39-thread-1:16472 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74015e73
2020-11-19 10:18:28  [ pool-39-thread-1:16473 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:28  [ EventFetcher for fetching Map Completion Events:16473 ] - [ INFO ]  attempt_local448977998_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:28  [ localfetcher#12:16474 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local448977998_0012_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:28  [ localfetcher#12:16474 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local448977998_0012_m_000000_0
2020-11-19 10:18:28  [ localfetcher#12:16474 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:28  [ EventFetcher for fetching Map Completion Events:16475 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:28  [ pool-39-thread-1:16475 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:28  [ pool-39-thread-1:16475 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:28  [ pool-39-thread-1:16476 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:28  [ pool-39-thread-1:16476 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:28  [ pool-39-thread-1:16477 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:28  [ pool-39-thread-1:16531 ] - [ INFO ]  Task:attempt_local448977998_0012_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:28  [ pool-39-thread-1:16536 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:28  [ pool-39-thread-1:16536 ] - [ INFO ]  Task attempt_local448977998_0012_r_000000_0 is allowed to commit now
2020-11-19 10:18:28  [ pool-39-thread-1:16552 ] - [ INFO ]  Saved output of task 'attempt_local448977998_0012_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local448977998_0012_r_000000
2020-11-19 10:18:28  [ pool-39-thread-1:16553 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:28  [ pool-39-thread-1:16553 ] - [ INFO ]  Task 'attempt_local448977998_0012_r_000000_0' done.
2020-11-19 10:18:28  [ pool-39-thread-1:16553 ] - [ INFO ]  Finishing task: attempt_local448977998_0012_r_000000_0
2020-11-19 10:18:28  [ Thread-348:16553 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:29  [ main:17375 ] - [ INFO ]  Job job_local448977998_0012 running in uber mode : false
2020-11-19 10:18:29  [ main:17375 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:29  [ main:17375 ] - [ INFO ]  Job job_local448977998_0012 completed successfully
2020-11-19 10:18:29  [ main:17376 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=95648
		FILE: Number of bytes written=6923374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=769960
		HDFS: Number of bytes written=11680
		HDFS: Number of read operations=741
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=244
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1286602752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:29  [ main:17661 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:29  [ main:17673 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:29  [ main:17678 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:29  [ main:17684 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:29  [ main:17721 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:29  [ main:17738 ] - [ INFO ]  Submitting tokens for job: job_local1152972653_0013
2020-11-19 10:18:29  [ main:17778 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:29  [ main:17778 ] - [ INFO ]  Running job: job_local1152972653_0013
2020-11-19 10:18:29  [ Thread-378:17778 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:29  [ Thread-378:17778 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:29  [ Thread-378:17779 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:29  [ Thread-378:17787 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]  Starting task: attempt_local1152972653_0013_m_000000_0
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17787 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17788 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17801 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17872 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17874 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17875 ] - [ INFO ]  Task:attempt_local1152972653_0013_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17881 ] - [ INFO ]  map
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17881 ] - [ INFO ]  Task 'attempt_local1152972653_0013_m_000000_0' done.
2020-11-19 10:18:29  [ LocalJobRunner Map Task Executor #0:17881 ] - [ INFO ]  Finishing task: attempt_local1152972653_0013_m_000000_0
2020-11-19 10:18:29  [ Thread-378:17881 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:29  [ Thread-378:17882 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  Starting task: attempt_local1152972653_0013_r_000000_0
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:29  [ pool-42-thread-1:17882 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27eb4427
2020-11-19 10:18:29  [ pool-42-thread-1:17883 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:29  [ EventFetcher for fetching Map Completion Events:17883 ] - [ INFO ]  attempt_local1152972653_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:29  [ localfetcher#13:17884 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local1152972653_0013_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:29  [ localfetcher#13:17884 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1152972653_0013_m_000000_0
2020-11-19 10:18:29  [ localfetcher#13:17884 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:29  [ EventFetcher for fetching Map Completion Events:17884 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:29  [ pool-42-thread-1:17884 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:29  [ pool-42-thread-1:17884 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:29  [ pool-42-thread-1:17885 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:29  [ pool-42-thread-1:17886 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:29  [ pool-42-thread-1:17886 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:29  [ pool-42-thread-1:17942 ] - [ INFO ]  Task:attempt_local1152972653_0013_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:29  [ pool-42-thread-1:17948 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:29  [ pool-42-thread-1:17948 ] - [ INFO ]  Task attempt_local1152972653_0013_r_000000_0 is allowed to commit now
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  Saved output of task 'attempt_local1152972653_0013_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1152972653_0013_r_000000
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  Task 'attempt_local1152972653_0013_r_000000_0' done.
2020-11-19 10:18:29  [ pool-42-thread-1:17967 ] - [ INFO ]  Finishing task: attempt_local1152972653_0013_r_000000_0
2020-11-19 10:18:29  [ Thread-378:17967 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:30  [ main:18779 ] - [ INFO ]  Job job_local1152972653_0013 running in uber mode : false
2020-11-19 10:18:30  [ main:18779 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:30  [ main:18779 ] - [ INFO ]  Job job_local1152972653_0013 completed successfully
2020-11-19 10:18:30  [ main:18780 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=96840
		FILE: Number of bytes written=7495299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=834366
		HDFS: Number of bytes written=12760
		HDFS: Number of read operations=809
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=266
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1286602752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:31  [ main:19064 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:31  [ main:19073 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:31  [ main:19078 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:31  [ main:19082 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:31  [ main:19118 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:31  [ main:19138 ] - [ INFO ]  Submitting tokens for job: job_local691028471_0014
2020-11-19 10:18:31  [ main:19178 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:31  [ main:19178 ] - [ INFO ]  Running job: job_local691028471_0014
2020-11-19 10:18:31  [ Thread-408:19178 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:31  [ Thread-408:19178 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:31  [ Thread-408:19178 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:31  [ Thread-408:19185 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19185 ] - [ INFO ]  Starting task: attempt_local691028471_0014_m_000000_0
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19186 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19196 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19269 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19272 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19273 ] - [ INFO ]  Task:attempt_local691028471_0014_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19278 ] - [ INFO ]  map
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19278 ] - [ INFO ]  Task 'attempt_local691028471_0014_m_000000_0' done.
2020-11-19 10:18:31  [ LocalJobRunner Map Task Executor #0:19278 ] - [ INFO ]  Finishing task: attempt_local691028471_0014_m_000000_0
2020-11-19 10:18:31  [ Thread-408:19278 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:31  [ Thread-408:19279 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:31  [ pool-45-thread-1:19279 ] - [ INFO ]  Starting task: attempt_local691028471_0014_r_000000_0
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2efed196
2020-11-19 10:18:31  [ pool-45-thread-1:19280 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:31  [ EventFetcher for fetching Map Completion Events:19280 ] - [ INFO ]  attempt_local691028471_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:31  [ localfetcher#14:19281 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local691028471_0014_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:31  [ localfetcher#14:19281 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local691028471_0014_m_000000_0
2020-11-19 10:18:31  [ localfetcher#14:19281 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:31  [ EventFetcher for fetching Map Completion Events:19282 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:31  [ pool-45-thread-1:19282 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:31  [ pool-45-thread-1:19282 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:31  [ pool-45-thread-1:19283 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:31  [ pool-45-thread-1:19284 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:31  [ pool-45-thread-1:19325 ] - [ INFO ]  Task:attempt_local691028471_0014_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:31  [ pool-45-thread-1:19331 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:31  [ pool-45-thread-1:19331 ] - [ INFO ]  Task attempt_local691028471_0014_r_000000_0 is allowed to commit now
2020-11-19 10:18:31  [ pool-45-thread-1:19348 ] - [ INFO ]  Saved output of task 'attempt_local691028471_0014_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local691028471_0014_r_000000
2020-11-19 10:18:31  [ pool-45-thread-1:19349 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:31  [ pool-45-thread-1:19349 ] - [ INFO ]  Task 'attempt_local691028471_0014_r_000000_0' done.
2020-11-19 10:18:31  [ pool-45-thread-1:19349 ] - [ INFO ]  Finishing task: attempt_local691028471_0014_r_000000_0
2020-11-19 10:18:31  [ Thread-408:19349 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:32  [ main:20178 ] - [ INFO ]  Job job_local691028471_0014 running in uber mode : false
2020-11-19 10:18:32  [ main:20178 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:32  [ main:20179 ] - [ INFO ]  Job job_local691028471_0014 completed successfully
2020-11-19 10:18:32  [ main:20180 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=98032
		FILE: Number of bytes written=8064174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=898772
		HDFS: Number of bytes written=13840
		HDFS: Number of read operations=877
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=288
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1519386624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:32  [ main:20463 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:32  [ main:20473 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:32  [ main:20477 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:32  [ main:20485 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:32  [ main:20522 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:32  [ main:20540 ] - [ INFO ]  Submitting tokens for job: job_local935923951_0015
2020-11-19 10:18:32  [ main:20574 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:32  [ main:20574 ] - [ INFO ]  Running job: job_local935923951_0015
2020-11-19 10:18:32  [ Thread-438:20574 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:32  [ Thread-438:20575 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:32  [ Thread-438:20575 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:32  [ Thread-438:20582 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20582 ] - [ INFO ]  Starting task: attempt_local935923951_0015_m_000000_0
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20583 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20591 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20658 ] - [ INFO ]  
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20659 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20661 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20662 ] - [ INFO ]  Task:attempt_local935923951_0015_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20670 ] - [ INFO ]  map
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20670 ] - [ INFO ]  Task 'attempt_local935923951_0015_m_000000_0' done.
2020-11-19 10:18:32  [ LocalJobRunner Map Task Executor #0:20670 ] - [ INFO ]  Finishing task: attempt_local935923951_0015_m_000000_0
2020-11-19 10:18:32  [ Thread-438:20670 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:32  [ Thread-438:20670 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:32  [ pool-48-thread-1:20670 ] - [ INFO ]  Starting task: attempt_local935923951_0015_r_000000_0
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@246c289e
2020-11-19 10:18:32  [ pool-48-thread-1:20671 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:32  [ EventFetcher for fetching Map Completion Events:20671 ] - [ INFO ]  attempt_local935923951_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:32  [ localfetcher#15:20672 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local935923951_0015_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:32  [ localfetcher#15:20672 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local935923951_0015_m_000000_0
2020-11-19 10:18:32  [ localfetcher#15:20672 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:32  [ EventFetcher for fetching Map Completion Events:20673 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:32  [ pool-48-thread-1:20673 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:32  [ pool-48-thread-1:20673 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:32  [ pool-48-thread-1:20674 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:32  [ pool-48-thread-1:20721 ] - [ INFO ]  Task:attempt_local935923951_0015_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:32  [ pool-48-thread-1:20727 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:32  [ pool-48-thread-1:20727 ] - [ INFO ]  Task attempt_local935923951_0015_r_000000_0 is allowed to commit now
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  Saved output of task 'attempt_local935923951_0015_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local935923951_0015_r_000000
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  Task 'attempt_local935923951_0015_r_000000_0' done.
2020-11-19 10:18:32  [ pool-48-thread-1:20743 ] - [ INFO ]  Finishing task: attempt_local935923951_0015_r_000000_0
2020-11-19 10:18:32  [ Thread-438:20743 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:33  [ main:21575 ] - [ INFO ]  Job job_local935923951_0015 running in uber mode : false
2020-11-19 10:18:33  [ main:21575 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:33  [ main:21576 ] - [ INFO ]  Job job_local935923951_0015 completed successfully
2020-11-19 10:18:33  [ main:21577 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=99222
		FILE: Number of bytes written=8633048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=963178
		HDFS: Number of bytes written=14920
		HDFS: Number of read operations=945
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=310
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1519386624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:33  [ main:21865 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:33  [ main:21877 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:33  [ main:21882 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:33  [ main:21888 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:33  [ main:21927 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:33  [ main:21945 ] - [ INFO ]  Submitting tokens for job: job_local510652144_0016
2020-11-19 10:18:33  [ main:21979 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:33  [ main:21979 ] - [ INFO ]  Running job: job_local510652144_0016
2020-11-19 10:18:33  [ Thread-468:21979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:33  [ Thread-468:21979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:33  [ Thread-468:21979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:33  [ Thread-468:21987 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21987 ] - [ INFO ]  Starting task: attempt_local510652144_0016_m_000000_0
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21988 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21988 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21988 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:33  [ LocalJobRunner Map Task Executor #0:21989 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22031 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22094 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22097 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22098 ] - [ INFO ]  Task:attempt_local510652144_0016_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22104 ] - [ INFO ]  map
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22104 ] - [ INFO ]  Task 'attempt_local510652144_0016_m_000000_0' done.
2020-11-19 10:18:34  [ LocalJobRunner Map Task Executor #0:22104 ] - [ INFO ]  Finishing task: attempt_local510652144_0016_m_000000_0
2020-11-19 10:18:34  [ Thread-468:22104 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:34  [ Thread-468:22104 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:34  [ pool-51-thread-1:22104 ] - [ INFO ]  Starting task: attempt_local510652144_0016_r_000000_0
2020-11-19 10:18:34  [ pool-51-thread-1:22105 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:34  [ pool-51-thread-1:22105 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:34  [ pool-51-thread-1:22105 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:34  [ pool-51-thread-1:22106 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7064db35
2020-11-19 10:18:34  [ pool-51-thread-1:22106 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:34  [ EventFetcher for fetching Map Completion Events:22106 ] - [ INFO ]  attempt_local510652144_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:34  [ localfetcher#16:22107 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local510652144_0016_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:34  [ localfetcher#16:22107 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local510652144_0016_m_000000_0
2020-11-19 10:18:34  [ localfetcher#16:22107 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:34  [ EventFetcher for fetching Map Completion Events:22107 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:34  [ pool-51-thread-1:22108 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:34  [ pool-51-thread-1:22109 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:34  [ pool-51-thread-1:22154 ] - [ INFO ]  Task:attempt_local510652144_0016_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:34  [ pool-51-thread-1:22160 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:34  [ pool-51-thread-1:22160 ] - [ INFO ]  Task attempt_local510652144_0016_r_000000_0 is allowed to commit now
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  Saved output of task 'attempt_local510652144_0016_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local510652144_0016_r_000000
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  Task 'attempt_local510652144_0016_r_000000_0' done.
2020-11-19 10:18:34  [ pool-51-thread-1:22178 ] - [ INFO ]  Finishing task: attempt_local510652144_0016_r_000000_0
2020-11-19 10:18:34  [ Thread-468:22178 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:34  [ main:22984 ] - [ INFO ]  Job job_local510652144_0016 running in uber mode : false
2020-11-19 10:18:34  [ main:22984 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:34  [ main:22984 ] - [ INFO ]  Job job_local510652144_0016 completed successfully
2020-11-19 10:18:34  [ main:22985 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=100414
		FILE: Number of bytes written=9201925
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1027584
		HDFS: Number of bytes written=16000
		HDFS: Number of read operations=1013
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=332
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1519386624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:35  [ main:23264 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:35  [ main:23275 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:35  [ main:23279 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:35  [ main:23284 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:35  [ main:23320 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:35  [ main:23337 ] - [ INFO ]  Submitting tokens for job: job_local1479460518_0017
2020-11-19 10:18:35  [ main:23373 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:35  [ main:23373 ] - [ INFO ]  Running job: job_local1479460518_0017
2020-11-19 10:18:35  [ Thread-498:23373 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:35  [ Thread-498:23373 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:35  [ Thread-498:23373 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:35  [ Thread-498:23382 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]  Starting task: attempt_local1479460518_0017_m_000000_0
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23382 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23383 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23390 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23455 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23457 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23458 ] - [ INFO ]  Task:attempt_local1479460518_0017_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23468 ] - [ INFO ]  map
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23469 ] - [ INFO ]  Task 'attempt_local1479460518_0017_m_000000_0' done.
2020-11-19 10:18:35  [ LocalJobRunner Map Task Executor #0:23469 ] - [ INFO ]  Finishing task: attempt_local1479460518_0017_m_000000_0
2020-11-19 10:18:35  [ Thread-498:23469 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:35  [ Thread-498:23469 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:35  [ pool-54-thread-1:23469 ] - [ INFO ]  Starting task: attempt_local1479460518_0017_r_000000_0
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27bdc7bf
2020-11-19 10:18:35  [ pool-54-thread-1:23470 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:35  [ EventFetcher for fetching Map Completion Events:23470 ] - [ INFO ]  attempt_local1479460518_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:35  [ localfetcher#17:23471 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local1479460518_0017_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:35  [ localfetcher#17:23471 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1479460518_0017_m_000000_0
2020-11-19 10:18:35  [ localfetcher#17:23471 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:35  [ EventFetcher for fetching Map Completion Events:23471 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:35  [ pool-54-thread-1:23471 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:35  [ pool-54-thread-1:23472 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:35  [ pool-54-thread-1:23472 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:35  [ pool-54-thread-1:23472 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:35  [ pool-54-thread-1:23473 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:35  [ pool-54-thread-1:23527 ] - [ INFO ]  Task:attempt_local1479460518_0017_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:35  [ pool-54-thread-1:23532 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:35  [ pool-54-thread-1:23532 ] - [ INFO ]  Task attempt_local1479460518_0017_r_000000_0 is allowed to commit now
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  Saved output of task 'attempt_local1479460518_0017_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1479460518_0017_r_000000
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  Task 'attempt_local1479460518_0017_r_000000_0' done.
2020-11-19 10:18:35  [ pool-54-thread-1:23551 ] - [ INFO ]  Finishing task: attempt_local1479460518_0017_r_000000_0
2020-11-19 10:18:35  [ Thread-498:23551 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:36  [ main:24375 ] - [ INFO ]  Job job_local1479460518_0017 running in uber mode : false
2020-11-19 10:18:36  [ main:24375 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:36  [ main:24375 ] - [ INFO ]  Job job_local1479460518_0017 completed successfully
2020-11-19 10:18:36  [ main:24376 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=101606
		FILE: Number of bytes written=9773848
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1091990
		HDFS: Number of bytes written=17080
		HDFS: Number of read operations=1081
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=354
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1548746752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:36  [ main:24661 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:36  [ main:24672 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:36  [ main:24677 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:36  [ main:24685 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:36  [ main:24724 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:36  [ main:24741 ] - [ INFO ]  Submitting tokens for job: job_local851378642_0018
2020-11-19 10:18:36  [ main:24773 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:36  [ main:24773 ] - [ INFO ]  Running job: job_local851378642_0018
2020-11-19 10:18:36  [ Thread-528:24773 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:36  [ Thread-528:24773 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:36  [ Thread-528:24773 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:36  [ Thread-528:24781 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24781 ] - [ INFO ]  Starting task: attempt_local851378642_0018_m_000000_0
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24782 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24791 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24861 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24863 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24864 ] - [ INFO ]  Task:attempt_local851378642_0018_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24870 ] - [ INFO ]  map
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24870 ] - [ INFO ]  Task 'attempt_local851378642_0018_m_000000_0' done.
2020-11-19 10:18:36  [ LocalJobRunner Map Task Executor #0:24870 ] - [ INFO ]  Finishing task: attempt_local851378642_0018_m_000000_0
2020-11-19 10:18:36  [ Thread-528:24870 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:36  [ Thread-528:24871 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]  Starting task: attempt_local851378642_0018_r_000000_0
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:36  [ pool-57-thread-1:24871 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:36  [ pool-57-thread-1:24872 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d5c2b79
2020-11-19 10:18:36  [ pool-57-thread-1:24872 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:36  [ EventFetcher for fetching Map Completion Events:24872 ] - [ INFO ]  attempt_local851378642_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:36  [ localfetcher#18:24873 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local851378642_0018_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:36  [ localfetcher#18:24873 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local851378642_0018_m_000000_0
2020-11-19 10:18:36  [ localfetcher#18:24873 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:36  [ EventFetcher for fetching Map Completion Events:24873 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:36  [ pool-57-thread-1:24874 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:36  [ pool-57-thread-1:24874 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:36  [ pool-57-thread-1:24875 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:36  [ pool-57-thread-1:24920 ] - [ INFO ]  Task:attempt_local851378642_0018_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:36  [ pool-57-thread-1:24925 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:36  [ pool-57-thread-1:24925 ] - [ INFO ]  Task attempt_local851378642_0018_r_000000_0 is allowed to commit now
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  Saved output of task 'attempt_local851378642_0018_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local851378642_0018_r_000000
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  Task 'attempt_local851378642_0018_r_000000_0' done.
2020-11-19 10:18:36  [ pool-57-thread-1:24943 ] - [ INFO ]  Finishing task: attempt_local851378642_0018_r_000000_0
2020-11-19 10:18:36  [ Thread-528:24943 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:37  [ main:25777 ] - [ INFO ]  Job job_local851378642_0018 running in uber mode : false
2020-11-19 10:18:37  [ main:25777 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:37  [ main:25778 ] - [ INFO ]  Job job_local851378642_0018 completed successfully
2020-11-19 10:18:37  [ main:25778 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=102796
		FILE: Number of bytes written=10342722
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1156396
		HDFS: Number of bytes written=18160
		HDFS: Number of read operations=1149
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=376
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1548746752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:38  [ main:26043 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:38  [ main:26053 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:38  [ main:26058 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:38  [ main:26063 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:38  [ main:26099 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:38  [ main:26116 ] - [ INFO ]  Submitting tokens for job: job_local904095313_0019
2020-11-19 10:18:38  [ main:26152 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:38  [ main:26152 ] - [ INFO ]  Running job: job_local904095313_0019
2020-11-19 10:18:38  [ Thread-558:26152 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:38  [ Thread-558:26153 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:38  [ Thread-558:26153 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:38  [ Thread-558:26160 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26160 ] - [ INFO ]  Starting task: attempt_local904095313_0019_m_000000_0
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26161 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26175 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26176 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26246 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26248 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26249 ] - [ INFO ]  Task:attempt_local904095313_0019_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26256 ] - [ INFO ]  map
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26256 ] - [ INFO ]  Task 'attempt_local904095313_0019_m_000000_0' done.
2020-11-19 10:18:38  [ LocalJobRunner Map Task Executor #0:26256 ] - [ INFO ]  Finishing task: attempt_local904095313_0019_m_000000_0
2020-11-19 10:18:38  [ Thread-558:26256 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:38  [ Thread-558:26256 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:38  [ pool-60-thread-1:26256 ] - [ INFO ]  Starting task: attempt_local904095313_0019_r_000000_0
2020-11-19 10:18:38  [ pool-60-thread-1:26256 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fab5ad9
2020-11-19 10:18:38  [ pool-60-thread-1:26257 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:38  [ EventFetcher for fetching Map Completion Events:26257 ] - [ INFO ]  attempt_local904095313_0019_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:38  [ localfetcher#19:26258 ] - [ INFO ]  localfetcher#19 about to shuffle output of map attempt_local904095313_0019_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:38  [ localfetcher#19:26258 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local904095313_0019_m_000000_0
2020-11-19 10:18:38  [ localfetcher#19:26258 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:38  [ EventFetcher for fetching Map Completion Events:26258 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:38  [ pool-60-thread-1:26258 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:38  [ pool-60-thread-1:26258 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:38  [ pool-60-thread-1:26259 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:38  [ pool-60-thread-1:26260 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:38  [ pool-60-thread-1:26260 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:38  [ pool-60-thread-1:26301 ] - [ INFO ]  Task:attempt_local904095313_0019_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:38  [ pool-60-thread-1:26306 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:38  [ pool-60-thread-1:26306 ] - [ INFO ]  Task attempt_local904095313_0019_r_000000_0 is allowed to commit now
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  Saved output of task 'attempt_local904095313_0019_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local904095313_0019_r_000000
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  Task 'attempt_local904095313_0019_r_000000_0' done.
2020-11-19 10:18:38  [ pool-60-thread-1:26324 ] - [ INFO ]  Finishing task: attempt_local904095313_0019_r_000000_0
2020-11-19 10:18:38  [ Thread-558:26324 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:39  [ main:27156 ] - [ INFO ]  Job job_local904095313_0019 running in uber mode : false
2020-11-19 10:18:39  [ main:27156 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:39  [ main:27156 ] - [ INFO ]  Job job_local904095313_0019 completed successfully
2020-11-19 10:18:39  [ main:27157 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=103988
		FILE: Number of bytes written=10911599
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1220802
		HDFS: Number of bytes written=19240
		HDFS: Number of read operations=1217
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=398
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1548746752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:39  [ main:27418 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:39  [ main:27428 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:39  [ main:27432 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:39  [ main:27437 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:39  [ main:27475 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:39  [ main:27494 ] - [ INFO ]  Submitting tokens for job: job_local1472890628_0020
2020-11-19 10:18:39  [ main:27532 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:39  [ main:27532 ] - [ INFO ]  Running job: job_local1472890628_0020
2020-11-19 10:18:39  [ Thread-588:27532 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:39  [ Thread-588:27532 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:39  [ Thread-588:27532 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:39  [ Thread-588:27539 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27539 ] - [ INFO ]  Starting task: attempt_local1472890628_0020_m_000000_0
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27540 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27547 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27613 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27615 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27616 ] - [ INFO ]  Task:attempt_local1472890628_0020_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27621 ] - [ INFO ]  map
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27621 ] - [ INFO ]  Task 'attempt_local1472890628_0020_m_000000_0' done.
2020-11-19 10:18:39  [ LocalJobRunner Map Task Executor #0:27621 ] - [ INFO ]  Finishing task: attempt_local1472890628_0020_m_000000_0
2020-11-19 10:18:39  [ Thread-588:27622 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:39  [ Thread-588:27622 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:39  [ pool-63-thread-1:27622 ] - [ INFO ]  Starting task: attempt_local1472890628_0020_r_000000_0
2020-11-19 10:18:39  [ pool-63-thread-1:27622 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30809f99
2020-11-19 10:18:39  [ pool-63-thread-1:27623 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:39  [ EventFetcher for fetching Map Completion Events:27623 ] - [ INFO ]  attempt_local1472890628_0020_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:39  [ localfetcher#20:27624 ] - [ INFO ]  localfetcher#20 about to shuffle output of map attempt_local1472890628_0020_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:39  [ localfetcher#20:27624 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1472890628_0020_m_000000_0
2020-11-19 10:18:39  [ localfetcher#20:27624 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:39  [ EventFetcher for fetching Map Completion Events:27624 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:39  [ pool-63-thread-1:27624 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:39  [ pool-63-thread-1:27625 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:39  [ pool-63-thread-1:27625 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:39  [ pool-63-thread-1:27625 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:39  [ pool-63-thread-1:27626 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:39  [ pool-63-thread-1:27667 ] - [ INFO ]  Task:attempt_local1472890628_0020_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:39  [ pool-63-thread-1:27674 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:39  [ pool-63-thread-1:27674 ] - [ INFO ]  Task attempt_local1472890628_0020_r_000000_0 is allowed to commit now
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  Saved output of task 'attempt_local1472890628_0020_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1472890628_0020_r_000000
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  Task 'attempt_local1472890628_0020_r_000000_0' done.
2020-11-19 10:18:39  [ pool-63-thread-1:27690 ] - [ INFO ]  Finishing task: attempt_local1472890628_0020_r_000000_0
2020-11-19 10:18:39  [ Thread-588:27690 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:40  [ main:28534 ] - [ INFO ]  Job job_local1472890628_0020 running in uber mode : false
2020-11-19 10:18:40  [ main:28534 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:40  [ main:28534 ] - [ INFO ]  Job job_local1472890628_0020 completed successfully
2020-11-19 10:18:40  [ main:28535 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=105180
		FILE: Number of bytes written=11483522
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1285208
		HDFS: Number of bytes written=20320
		HDFS: Number of read operations=1285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=420
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1793064960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:40  [ main:28813 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:40  [ main:28825 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:40  [ main:28830 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:40  [ main:28835 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:40  [ main:28872 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:40  [ main:28889 ] - [ INFO ]  Submitting tokens for job: job_local938339314_0021
2020-11-19 10:18:40  [ main:28921 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:40  [ main:28921 ] - [ INFO ]  Running job: job_local938339314_0021
2020-11-19 10:18:40  [ Thread-618:28921 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:40  [ Thread-618:28921 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:40  [ Thread-618:28921 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:40  [ Thread-618:28928 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  Starting task: attempt_local938339314_0021_m_000000_0
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28928 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28936 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28996 ] - [ INFO ]  
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28997 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:40  [ LocalJobRunner Map Task Executor #0:28998 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:28999 ] - [ INFO ]  Task:attempt_local938339314_0021_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:29005 ] - [ INFO ]  map
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:29006 ] - [ INFO ]  Task 'attempt_local938339314_0021_m_000000_0' done.
2020-11-19 10:18:41  [ LocalJobRunner Map Task Executor #0:29006 ] - [ INFO ]  Finishing task: attempt_local938339314_0021_m_000000_0
2020-11-19 10:18:41  [ Thread-618:29006 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:41  [ Thread-618:29006 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:41  [ pool-66-thread-1:29006 ] - [ INFO ]  Starting task: attempt_local938339314_0021_r_000000_0
2020-11-19 10:18:41  [ pool-66-thread-1:29006 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c649262
2020-11-19 10:18:41  [ pool-66-thread-1:29007 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:41  [ EventFetcher for fetching Map Completion Events:29007 ] - [ INFO ]  attempt_local938339314_0021_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:41  [ localfetcher#21:29008 ] - [ INFO ]  localfetcher#21 about to shuffle output of map attempt_local938339314_0021_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:41  [ localfetcher#21:29008 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local938339314_0021_m_000000_0
2020-11-19 10:18:41  [ localfetcher#21:29008 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:41  [ EventFetcher for fetching Map Completion Events:29008 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:41  [ pool-66-thread-1:29008 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:41  [ pool-66-thread-1:29008 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:41  [ pool-66-thread-1:29009 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:41  [ pool-66-thread-1:29010 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:41  [ pool-66-thread-1:29050 ] - [ INFO ]  Task:attempt_local938339314_0021_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:41  [ pool-66-thread-1:29055 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:41  [ pool-66-thread-1:29055 ] - [ INFO ]  Task attempt_local938339314_0021_r_000000_0 is allowed to commit now
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  Saved output of task 'attempt_local938339314_0021_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local938339314_0021_r_000000
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  Task 'attempt_local938339314_0021_r_000000_0' done.
2020-11-19 10:18:41  [ pool-66-thread-1:29071 ] - [ INFO ]  Finishing task: attempt_local938339314_0021_r_000000_0
2020-11-19 10:18:41  [ Thread-618:29071 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:41  [ main:29922 ] - [ INFO ]  Job job_local938339314_0021 running in uber mode : false
2020-11-19 10:18:41  [ main:29922 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:41  [ main:29922 ] - [ INFO ]  Job job_local938339314_0021 completed successfully
2020-11-19 10:18:41  [ main:29923 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=106370
		FILE: Number of bytes written=12052396
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1349614
		HDFS: Number of bytes written=21400
		HDFS: Number of read operations=1353
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=442
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1793064960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:42  [ main:30210 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:42  [ main:30221 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:42  [ main:30226 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:42  [ main:30231 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:42  [ main:30269 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:42  [ main:30286 ] - [ INFO ]  Submitting tokens for job: job_local752712392_0022
2020-11-19 10:18:42  [ main:30316 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:42  [ main:30316 ] - [ INFO ]  Running job: job_local752712392_0022
2020-11-19 10:18:42  [ Thread-648:30317 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:42  [ Thread-648:30317 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:42  [ Thread-648:30317 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:42  [ Thread-648:30325 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]  Starting task: attempt_local752712392_0022_m_000000_0
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30325 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30326 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30337 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30338 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30415 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30418 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30419 ] - [ INFO ]  Task:attempt_local752712392_0022_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30425 ] - [ INFO ]  map
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30425 ] - [ INFO ]  Task 'attempt_local752712392_0022_m_000000_0' done.
2020-11-19 10:18:42  [ LocalJobRunner Map Task Executor #0:30425 ] - [ INFO ]  Finishing task: attempt_local752712392_0022_m_000000_0
2020-11-19 10:18:42  [ Thread-648:30425 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:42  [ Thread-648:30425 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  Starting task: attempt_local752712392_0022_r_000000_0
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@dd7fb1a
2020-11-19 10:18:42  [ pool-69-thread-1:30426 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:42  [ EventFetcher for fetching Map Completion Events:30427 ] - [ INFO ]  attempt_local752712392_0022_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:42  [ localfetcher#22:30427 ] - [ INFO ]  localfetcher#22 about to shuffle output of map attempt_local752712392_0022_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:42  [ localfetcher#22:30428 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local752712392_0022_m_000000_0
2020-11-19 10:18:42  [ localfetcher#22:30428 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:42  [ EventFetcher for fetching Map Completion Events:30428 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:42  [ pool-69-thread-1:30428 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:42  [ pool-69-thread-1:30428 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:42  [ pool-69-thread-1:30429 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:42  [ pool-69-thread-1:30429 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:42  [ pool-69-thread-1:30430 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:42  [ pool-69-thread-1:30475 ] - [ INFO ]  Task:attempt_local752712392_0022_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:42  [ pool-69-thread-1:30480 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:42  [ pool-69-thread-1:30480 ] - [ INFO ]  Task attempt_local752712392_0022_r_000000_0 is allowed to commit now
2020-11-19 10:18:42  [ pool-69-thread-1:30498 ] - [ INFO ]  Saved output of task 'attempt_local752712392_0022_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local752712392_0022_r_000000
2020-11-19 10:18:42  [ pool-69-thread-1:30499 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:42  [ pool-69-thread-1:30499 ] - [ INFO ]  Task 'attempt_local752712392_0022_r_000000_0' done.
2020-11-19 10:18:42  [ pool-69-thread-1:30499 ] - [ INFO ]  Finishing task: attempt_local752712392_0022_r_000000_0
2020-11-19 10:18:42  [ Thread-648:30499 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:43  [ main:31318 ] - [ INFO ]  Job job_local752712392_0022 running in uber mode : false
2020-11-19 10:18:43  [ main:31318 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:43  [ main:31318 ] - [ INFO ]  Job job_local752712392_0022 completed successfully
2020-11-19 10:18:43  [ main:31319 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=107562
		FILE: Number of bytes written=12621273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1414020
		HDFS: Number of bytes written=22480
		HDFS: Number of read operations=1421
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=464
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1793064960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:43  [ main:31604 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:43  [ main:31617 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:43  [ main:31622 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:43  [ main:31627 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:43  [ main:31662 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:43  [ main:31679 ] - [ INFO ]  Submitting tokens for job: job_local1095469340_0023
2020-11-19 10:18:43  [ main:31716 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:43  [ main:31716 ] - [ INFO ]  Running job: job_local1095469340_0023
2020-11-19 10:18:43  [ Thread-678:31717 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:43  [ Thread-678:31717 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:43  [ Thread-678:31717 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:43  [ Thread-678:31724 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]  Starting task: attempt_local1095469340_0023_m_000000_0
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31724 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31725 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31735 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31806 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31808 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31809 ] - [ INFO ]  Task:attempt_local1095469340_0023_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31815 ] - [ INFO ]  map
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31815 ] - [ INFO ]  Task 'attempt_local1095469340_0023_m_000000_0' done.
2020-11-19 10:18:43  [ LocalJobRunner Map Task Executor #0:31815 ] - [ INFO ]  Finishing task: attempt_local1095469340_0023_m_000000_0
2020-11-19 10:18:43  [ Thread-678:31815 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:43  [ Thread-678:31815 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:43  [ pool-72-thread-1:31815 ] - [ INFO ]  Starting task: attempt_local1095469340_0023_r_000000_0
2020-11-19 10:18:43  [ pool-72-thread-1:31815 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6025b510
2020-11-19 10:18:43  [ pool-72-thread-1:31816 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:43  [ EventFetcher for fetching Map Completion Events:31816 ] - [ INFO ]  attempt_local1095469340_0023_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:43  [ localfetcher#23:31817 ] - [ INFO ]  localfetcher#23 about to shuffle output of map attempt_local1095469340_0023_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:43  [ localfetcher#23:31817 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1095469340_0023_m_000000_0
2020-11-19 10:18:43  [ localfetcher#23:31817 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:43  [ EventFetcher for fetching Map Completion Events:31817 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:43  [ pool-72-thread-1:31818 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:43  [ pool-72-thread-1:31819 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:43  [ pool-72-thread-1:31860 ] - [ INFO ]  Task:attempt_local1095469340_0023_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:43  [ pool-72-thread-1:31866 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:43  [ pool-72-thread-1:31866 ] - [ INFO ]  Task attempt_local1095469340_0023_r_000000_0 is allowed to commit now
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  Saved output of task 'attempt_local1095469340_0023_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1095469340_0023_r_000000
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  Task 'attempt_local1095469340_0023_r_000000_0' done.
2020-11-19 10:18:43  [ pool-72-thread-1:31885 ] - [ INFO ]  Finishing task: attempt_local1095469340_0023_r_000000_0
2020-11-19 10:18:43  [ Thread-678:31885 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:44  [ main:32720 ] - [ INFO ]  Job job_local1095469340_0023 running in uber mode : false
2020-11-19 10:18:44  [ main:32720 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:44  [ main:32721 ] - [ INFO ]  Job job_local1095469340_0023 completed successfully
2020-11-19 10:18:44  [ main:32722 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=108754
		FILE: Number of bytes written=13193196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1478426
		HDFS: Number of bytes written=23560
		HDFS: Number of read operations=1489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=486
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1822425088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:44  [ main:32984 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:44  [ main:32996 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:45  [ main:33000 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:45  [ main:33006 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:45  [ main:33046 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:45  [ main:33063 ] - [ INFO ]  Submitting tokens for job: job_local1750381313_0024
2020-11-19 10:18:45  [ main:33098 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:45  [ main:33098 ] - [ INFO ]  Running job: job_local1750381313_0024
2020-11-19 10:18:45  [ Thread-708:33098 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:45  [ Thread-708:33099 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:45  [ Thread-708:33099 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:45  [ Thread-708:33106 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  Starting task: attempt_local1750381313_0024_m_000000_0
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33106 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33115 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33179 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33181 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33182 ] - [ INFO ]  Task:attempt_local1750381313_0024_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33189 ] - [ INFO ]  map
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33189 ] - [ INFO ]  Task 'attempt_local1750381313_0024_m_000000_0' done.
2020-11-19 10:18:45  [ LocalJobRunner Map Task Executor #0:33189 ] - [ INFO ]  Finishing task: attempt_local1750381313_0024_m_000000_0
2020-11-19 10:18:45  [ Thread-708:33189 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:45  [ Thread-708:33189 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:45  [ pool-75-thread-1:33189 ] - [ INFO ]  Starting task: attempt_local1750381313_0024_r_000000_0
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61b4ab20
2020-11-19 10:18:45  [ pool-75-thread-1:33190 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:45  [ EventFetcher for fetching Map Completion Events:33190 ] - [ INFO ]  attempt_local1750381313_0024_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:45  [ localfetcher#24:33191 ] - [ INFO ]  localfetcher#24 about to shuffle output of map attempt_local1750381313_0024_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:45  [ localfetcher#24:33191 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1750381313_0024_m_000000_0
2020-11-19 10:18:45  [ localfetcher#24:33191 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:45  [ EventFetcher for fetching Map Completion Events:33192 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:45  [ pool-75-thread-1:33192 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:45  [ pool-75-thread-1:33192 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:45  [ pool-75-thread-1:33193 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:45  [ pool-75-thread-1:33236 ] - [ INFO ]  Task:attempt_local1750381313_0024_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:45  [ pool-75-thread-1:33241 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:45  [ pool-75-thread-1:33241 ] - [ INFO ]  Task attempt_local1750381313_0024_r_000000_0 is allowed to commit now
2020-11-19 10:18:45  [ pool-75-thread-1:33257 ] - [ INFO ]  Saved output of task 'attempt_local1750381313_0024_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1750381313_0024_r_000000
2020-11-19 10:18:45  [ pool-75-thread-1:33258 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:45  [ pool-75-thread-1:33258 ] - [ INFO ]  Task 'attempt_local1750381313_0024_r_000000_0' done.
2020-11-19 10:18:45  [ pool-75-thread-1:33258 ] - [ INFO ]  Finishing task: attempt_local1750381313_0024_r_000000_0
2020-11-19 10:18:45  [ Thread-708:33258 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:46  [ main:34099 ] - [ INFO ]  Job job_local1750381313_0024 running in uber mode : false
2020-11-19 10:18:46  [ main:34099 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:46  [ main:34100 ] - [ INFO ]  Job job_local1750381313_0024 completed successfully
2020-11-19 10:18:46  [ main:34100 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=109944
		FILE: Number of bytes written=13765118
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1542832
		HDFS: Number of bytes written=24640
		HDFS: Number of read operations=1557
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=508
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1822425088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:46  [ main:34391 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:46  [ main:34406 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:46  [ main:34411 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:46  [ main:34417 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:46  [ main:34459 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:46  [ main:34476 ] - [ INFO ]  Submitting tokens for job: job_local2132610406_0025
2020-11-19 10:18:46  [ main:34508 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:46  [ main:34508 ] - [ INFO ]  Running job: job_local2132610406_0025
2020-11-19 10:18:46  [ Thread-738:34508 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:46  [ Thread-738:34508 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:46  [ Thread-738:34508 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:46  [ Thread-738:34515 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  Starting task: attempt_local2132610406_0025_m_000000_0
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34516 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34524 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34586 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34588 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34589 ] - [ INFO ]  Task:attempt_local2132610406_0025_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34595 ] - [ INFO ]  map
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34595 ] - [ INFO ]  Task 'attempt_local2132610406_0025_m_000000_0' done.
2020-11-19 10:18:46  [ LocalJobRunner Map Task Executor #0:34595 ] - [ INFO ]  Finishing task: attempt_local2132610406_0025_m_000000_0
2020-11-19 10:18:46  [ Thread-738:34595 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:46  [ Thread-738:34596 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  Starting task: attempt_local2132610406_0025_r_000000_0
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:46  [ pool-78-thread-1:34596 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@188e30
2020-11-19 10:18:46  [ pool-78-thread-1:34597 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:46  [ EventFetcher for fetching Map Completion Events:34597 ] - [ INFO ]  attempt_local2132610406_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:46  [ localfetcher#25:34598 ] - [ INFO ]  localfetcher#25 about to shuffle output of map attempt_local2132610406_0025_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:46  [ localfetcher#25:34598 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local2132610406_0025_m_000000_0
2020-11-19 10:18:46  [ localfetcher#25:34598 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:46  [ EventFetcher for fetching Map Completion Events:34598 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:46  [ pool-78-thread-1:34598 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:46  [ pool-78-thread-1:34598 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:46  [ pool-78-thread-1:34599 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:46  [ pool-78-thread-1:34599 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:46  [ pool-78-thread-1:34600 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:46  [ pool-78-thread-1:34651 ] - [ INFO ]  Task:attempt_local2132610406_0025_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:46  [ pool-78-thread-1:34659 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:46  [ pool-78-thread-1:34659 ] - [ INFO ]  Task attempt_local2132610406_0025_r_000000_0 is allowed to commit now
2020-11-19 10:18:46  [ pool-78-thread-1:34676 ] - [ INFO ]  Saved output of task 'attempt_local2132610406_0025_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2132610406_0025_r_000000
2020-11-19 10:18:46  [ pool-78-thread-1:34676 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:46  [ pool-78-thread-1:34677 ] - [ INFO ]  Task 'attempt_local2132610406_0025_r_000000_0' done.
2020-11-19 10:18:46  [ pool-78-thread-1:34677 ] - [ INFO ]  Finishing task: attempt_local2132610406_0025_r_000000_0
2020-11-19 10:18:46  [ Thread-738:34677 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]  Job job_local2132610406_0025 running in uber mode : false
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]  Job job_local2132610406_0025 completed successfully
2020-11-19 10:18:47  [ main:35509 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=111136
		FILE: Number of bytes written=14337043
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1607238
		HDFS: Number of bytes written=25720
		HDFS: Number of read operations=1625
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=530
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1822425088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:48  [ main:36045 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:48  [ main:36065 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:48  [ main:36070 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:48  [ main:36091 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:48  [ main:36143 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:48  [ main:36162 ] - [ INFO ]  Submitting tokens for job: job_local335205706_0026
2020-11-19 10:18:48  [ main:36199 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:48  [ main:36199 ] - [ INFO ]  Running job: job_local335205706_0026
2020-11-19 10:18:48  [ Thread-768:36199 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:48  [ Thread-768:36199 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:48  [ Thread-768:36199 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:48  [ Thread-768:36210 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36210 ] - [ INFO ]  Starting task: attempt_local335205706_0026_m_000000_0
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36211 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36244 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36245 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36372 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36374 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36375 ] - [ INFO ]  Task:attempt_local335205706_0026_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36385 ] - [ INFO ]  map
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36385 ] - [ INFO ]  Task 'attempt_local335205706_0026_m_000000_0' done.
2020-11-19 10:18:48  [ LocalJobRunner Map Task Executor #0:36385 ] - [ INFO ]  Finishing task: attempt_local335205706_0026_m_000000_0
2020-11-19 10:18:48  [ Thread-768:36385 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:48  [ Thread-768:36386 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  Starting task: attempt_local335205706_0026_r_000000_0
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:48  [ pool-81-thread-1:36386 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54521048
2020-11-19 10:18:48  [ pool-81-thread-1:36387 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:48  [ EventFetcher for fetching Map Completion Events:36387 ] - [ INFO ]  attempt_local335205706_0026_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:48  [ localfetcher#26:36387 ] - [ INFO ]  localfetcher#26 about to shuffle output of map attempt_local335205706_0026_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:48  [ localfetcher#26:36388 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local335205706_0026_m_000000_0
2020-11-19 10:18:48  [ localfetcher#26:36388 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:48  [ EventFetcher for fetching Map Completion Events:36388 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:48  [ pool-81-thread-1:36388 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:48  [ pool-81-thread-1:36388 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:48  [ pool-81-thread-1:36389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:48  [ pool-81-thread-1:36389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:48  [ pool-81-thread-1:36390 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:48  [ pool-81-thread-1:36453 ] - [ INFO ]  Task:attempt_local335205706_0026_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:48  [ pool-81-thread-1:36459 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:48  [ pool-81-thread-1:36459 ] - [ INFO ]  Task attempt_local335205706_0026_r_000000_0 is allowed to commit now
2020-11-19 10:18:48  [ pool-81-thread-1:36485 ] - [ INFO ]  Saved output of task 'attempt_local335205706_0026_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local335205706_0026_r_000000
2020-11-19 10:18:48  [ pool-81-thread-1:36486 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:48  [ pool-81-thread-1:36486 ] - [ INFO ]  Task 'attempt_local335205706_0026_r_000000_0' done.
2020-11-19 10:18:48  [ pool-81-thread-1:36486 ] - [ INFO ]  Finishing task: attempt_local335205706_0026_r_000000_0
2020-11-19 10:18:48  [ Thread-768:36486 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:49  [ main:37202 ] - [ INFO ]  Job job_local335205706_0026 running in uber mode : false
2020-11-19 10:18:49  [ main:37202 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:49  [ main:37202 ] - [ INFO ]  Job job_local335205706_0026 completed successfully
2020-11-19 10:18:49  [ main:37203 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=112328
		FILE: Number of bytes written=14905918
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1671644
		HDFS: Number of bytes written=26800
		HDFS: Number of read operations=1693
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=552
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:49  [ main:37495 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:49  [ main:37508 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:49  [ main:37513 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:49  [ main:37525 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:49  [ main:37563 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:49  [ main:37580 ] - [ INFO ]  Submitting tokens for job: job_local1153725832_0027
2020-11-19 10:18:49  [ main:37612 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:49  [ main:37613 ] - [ INFO ]  Running job: job_local1153725832_0027
2020-11-19 10:18:49  [ Thread-798:37613 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:49  [ Thread-798:37613 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:49  [ Thread-798:37613 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:49  [ Thread-798:37620 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]  Starting task: attempt_local1153725832_0027_m_000000_0
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37620 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37621 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37628 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37629 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37694 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37696 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37697 ] - [ INFO ]  Task:attempt_local1153725832_0027_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37702 ] - [ INFO ]  map
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37702 ] - [ INFO ]  Task 'attempt_local1153725832_0027_m_000000_0' done.
2020-11-19 10:18:49  [ LocalJobRunner Map Task Executor #0:37702 ] - [ INFO ]  Finishing task: attempt_local1153725832_0027_m_000000_0
2020-11-19 10:18:49  [ Thread-798:37703 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:49  [ Thread-798:37703 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:49  [ pool-84-thread-1:37703 ] - [ INFO ]  Starting task: attempt_local1153725832_0027_r_000000_0
2020-11-19 10:18:49  [ pool-84-thread-1:37703 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b30b02e
2020-11-19 10:18:49  [ pool-84-thread-1:37704 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:49  [ EventFetcher for fetching Map Completion Events:37704 ] - [ INFO ]  attempt_local1153725832_0027_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:49  [ localfetcher#27:37705 ] - [ INFO ]  localfetcher#27 about to shuffle output of map attempt_local1153725832_0027_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:49  [ localfetcher#27:37705 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1153725832_0027_m_000000_0
2020-11-19 10:18:49  [ localfetcher#27:37705 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:49  [ EventFetcher for fetching Map Completion Events:37705 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:49  [ pool-84-thread-1:37705 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:49  [ pool-84-thread-1:37706 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:49  [ pool-84-thread-1:37706 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:49  [ pool-84-thread-1:37706 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:49  [ pool-84-thread-1:37707 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:49  [ pool-84-thread-1:37758 ] - [ INFO ]  Task:attempt_local1153725832_0027_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:49  [ pool-84-thread-1:37763 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:49  [ pool-84-thread-1:37764 ] - [ INFO ]  Task attempt_local1153725832_0027_r_000000_0 is allowed to commit now
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  Saved output of task 'attempt_local1153725832_0027_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1153725832_0027_r_000000
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  Task 'attempt_local1153725832_0027_r_000000_0' done.
2020-11-19 10:18:49  [ pool-84-thread-1:37780 ] - [ INFO ]  Finishing task: attempt_local1153725832_0027_r_000000_0
2020-11-19 10:18:49  [ Thread-798:37781 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:50  [ main:38618 ] - [ INFO ]  Job job_local1153725832_0027 running in uber mode : false
2020-11-19 10:18:50  [ main:38618 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:50  [ main:38618 ] - [ INFO ]  Job job_local1153725832_0027 completed successfully
2020-11-19 10:18:50  [ main:38619 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=113518
		FILE: Number of bytes written=15477840
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1736050
		HDFS: Number of bytes written=27880
		HDFS: Number of read operations=1761
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=574
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:50  [ main:38897 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:50  [ main:38908 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:50  [ main:38912 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:50  [ main:38918 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:50  [ main:38955 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:50  [ main:38972 ] - [ INFO ]  Submitting tokens for job: job_local420316057_0028
2020-11-19 10:18:51  [ main:39003 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:51  [ main:39003 ] - [ INFO ]  Running job: job_local420316057_0028
2020-11-19 10:18:51  [ Thread-828:39003 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:51  [ Thread-828:39004 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:51  [ Thread-828:39004 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:51  [ Thread-828:39010 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  Starting task: attempt_local420316057_0028_m_000000_0
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39011 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39019 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39020 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39092 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39095 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39096 ] - [ INFO ]  Task:attempt_local420316057_0028_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39101 ] - [ INFO ]  map
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39101 ] - [ INFO ]  Task 'attempt_local420316057_0028_m_000000_0' done.
2020-11-19 10:18:51  [ LocalJobRunner Map Task Executor #0:39101 ] - [ INFO ]  Finishing task: attempt_local420316057_0028_m_000000_0
2020-11-19 10:18:51  [ Thread-828:39101 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:51  [ Thread-828:39102 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  Starting task: attempt_local420316057_0028_r_000000_0
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:51  [ pool-87-thread-1:39102 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a9c9fd
2020-11-19 10:18:51  [ pool-87-thread-1:39103 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:51  [ EventFetcher for fetching Map Completion Events:39103 ] - [ INFO ]  attempt_local420316057_0028_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:51  [ localfetcher#28:39103 ] - [ INFO ]  localfetcher#28 about to shuffle output of map attempt_local420316057_0028_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:51  [ localfetcher#28:39104 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local420316057_0028_m_000000_0
2020-11-19 10:18:51  [ localfetcher#28:39104 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:51  [ EventFetcher for fetching Map Completion Events:39104 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:51  [ pool-87-thread-1:39104 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:51  [ pool-87-thread-1:39104 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:51  [ pool-87-thread-1:39105 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:51  [ pool-87-thread-1:39106 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:51  [ pool-87-thread-1:39106 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:51  [ pool-87-thread-1:39106 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:51  [ pool-87-thread-1:39147 ] - [ INFO ]  Task:attempt_local420316057_0028_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:51  [ pool-87-thread-1:39153 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:51  [ pool-87-thread-1:39153 ] - [ INFO ]  Task attempt_local420316057_0028_r_000000_0 is allowed to commit now
2020-11-19 10:18:51  [ pool-87-thread-1:39169 ] - [ INFO ]  Saved output of task 'attempt_local420316057_0028_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local420316057_0028_r_000000
2020-11-19 10:18:51  [ pool-87-thread-1:39170 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:51  [ pool-87-thread-1:39170 ] - [ INFO ]  Task 'attempt_local420316057_0028_r_000000_0' done.
2020-11-19 10:18:51  [ pool-87-thread-1:39170 ] - [ INFO ]  Finishing task: attempt_local420316057_0028_r_000000_0
2020-11-19 10:18:51  [ Thread-828:39170 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]  Job job_local420316057_0028 running in uber mode : false
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]  Job job_local420316057_0028 completed successfully
2020-11-19 10:18:52  [ main:40004 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=114710
		FILE: Number of bytes written=16046717
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1800456
		HDFS: Number of bytes written=28960
		HDFS: Number of read operations=1829
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=596
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:52  [ main:40261 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:52  [ main:40272 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:52  [ main:40276 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:52  [ main:40281 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:52  [ main:40321 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:52  [ main:40338 ] - [ INFO ]  Submitting tokens for job: job_local1933719465_0029
2020-11-19 10:18:52  [ main:40370 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:52  [ main:40370 ] - [ INFO ]  Running job: job_local1933719465_0029
2020-11-19 10:18:52  [ Thread-858:40370 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:52  [ Thread-858:40370 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:52  [ Thread-858:40370 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:52  [ Thread-858:40378 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]  Starting task: attempt_local1933719465_0029_m_000000_0
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40378 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40379 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40388 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40453 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40455 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40456 ] - [ INFO ]  Task:attempt_local1933719465_0029_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40462 ] - [ INFO ]  map
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40462 ] - [ INFO ]  Task 'attempt_local1933719465_0029_m_000000_0' done.
2020-11-19 10:18:52  [ LocalJobRunner Map Task Executor #0:40463 ] - [ INFO ]  Finishing task: attempt_local1933719465_0029_m_000000_0
2020-11-19 10:18:52  [ Thread-858:40463 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:52  [ Thread-858:40463 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:52  [ pool-90-thread-1:40463 ] - [ INFO ]  Starting task: attempt_local1933719465_0029_r_000000_0
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56c2f2ab
2020-11-19 10:18:52  [ pool-90-thread-1:40464 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:52  [ EventFetcher for fetching Map Completion Events:40464 ] - [ INFO ]  attempt_local1933719465_0029_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:52  [ localfetcher#29:40465 ] - [ INFO ]  localfetcher#29 about to shuffle output of map attempt_local1933719465_0029_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:52  [ localfetcher#29:40465 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1933719465_0029_m_000000_0
2020-11-19 10:18:52  [ localfetcher#29:40465 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:52  [ EventFetcher for fetching Map Completion Events:40465 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:52  [ pool-90-thread-1:40466 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:52  [ pool-90-thread-1:40467 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:52  [ pool-90-thread-1:40525 ] - [ INFO ]  Task:attempt_local1933719465_0029_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:52  [ pool-90-thread-1:40531 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:52  [ pool-90-thread-1:40531 ] - [ INFO ]  Task attempt_local1933719465_0029_r_000000_0 is allowed to commit now
2020-11-19 10:18:52  [ pool-90-thread-1:40547 ] - [ INFO ]  Saved output of task 'attempt_local1933719465_0029_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1933719465_0029_r_000000
2020-11-19 10:18:52  [ pool-90-thread-1:40547 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:52  [ pool-90-thread-1:40548 ] - [ INFO ]  Task 'attempt_local1933719465_0029_r_000000_0' done.
2020-11-19 10:18:52  [ pool-90-thread-1:40548 ] - [ INFO ]  Finishing task: attempt_local1933719465_0029_r_000000_0
2020-11-19 10:18:52  [ Thread-858:40548 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:53  [ main:41374 ] - [ INFO ]  Job job_local1933719465_0029 running in uber mode : false
2020-11-19 10:18:53  [ main:41374 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:53  [ main:41375 ] - [ INFO ]  Job job_local1933719465_0029 completed successfully
2020-11-19 10:18:53  [ main:41375 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=115902
		FILE: Number of bytes written=16618640
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1864862
		HDFS: Number of bytes written=30040
		HDFS: Number of read operations=1897
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=618
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:53  [ main:41665 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:53  [ main:41675 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:53  [ main:41679 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:53  [ main:41684 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:53  [ main:41720 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:53  [ main:41737 ] - [ INFO ]  Submitting tokens for job: job_local677201198_0030
2020-11-19 10:18:53  [ main:41770 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:53  [ main:41770 ] - [ INFO ]  Running job: job_local677201198_0030
2020-11-19 10:18:53  [ Thread-888:41770 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:53  [ Thread-888:41771 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:53  [ Thread-888:41771 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:53  [ Thread-888:41779 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41779 ] - [ INFO ]  Starting task: attempt_local677201198_0030_m_000000_0
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41779 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41780 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41780 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41780 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41818 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41891 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41894 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41894 ] - [ INFO ]  Task:attempt_local677201198_0030_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41901 ] - [ INFO ]  map
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41901 ] - [ INFO ]  Task 'attempt_local677201198_0030_m_000000_0' done.
2020-11-19 10:18:53  [ LocalJobRunner Map Task Executor #0:41901 ] - [ INFO ]  Finishing task: attempt_local677201198_0030_m_000000_0
2020-11-19 10:18:53  [ Thread-888:41901 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:53  [ Thread-888:41901 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:53  [ pool-93-thread-1:41901 ] - [ INFO ]  Starting task: attempt_local677201198_0030_r_000000_0
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@45976be3
2020-11-19 10:18:53  [ pool-93-thread-1:41902 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:53  [ EventFetcher for fetching Map Completion Events:41903 ] - [ INFO ]  attempt_local677201198_0030_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:53  [ localfetcher#30:41903 ] - [ INFO ]  localfetcher#30 about to shuffle output of map attempt_local677201198_0030_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:53  [ localfetcher#30:41904 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local677201198_0030_m_000000_0
2020-11-19 10:18:53  [ localfetcher#30:41904 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:53  [ EventFetcher for fetching Map Completion Events:41904 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:53  [ pool-93-thread-1:41904 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:53  [ pool-93-thread-1:41904 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:53  [ pool-93-thread-1:41905 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:53  [ pool-93-thread-1:41906 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:53  [ pool-93-thread-1:41953 ] - [ INFO ]  Task:attempt_local677201198_0030_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:53  [ pool-93-thread-1:41959 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:53  [ pool-93-thread-1:41959 ] - [ INFO ]  Task attempt_local677201198_0030_r_000000_0 is allowed to commit now
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  Saved output of task 'attempt_local677201198_0030_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local677201198_0030_r_000000
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  Task 'attempt_local677201198_0030_r_000000_0' done.
2020-11-19 10:18:53  [ pool-93-thread-1:41976 ] - [ INFO ]  Finishing task: attempt_local677201198_0030_r_000000_0
2020-11-19 10:18:53  [ Thread-888:41976 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:54  [ main:42774 ] - [ INFO ]  Job job_local677201198_0030 running in uber mode : false
2020-11-19 10:18:54  [ main:42775 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:54  [ main:42775 ] - [ INFO ]  Job job_local677201198_0030 completed successfully
2020-11-19 10:18:54  [ main:42775 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=117092
		FILE: Number of bytes written=17187514
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1929268
		HDFS: Number of bytes written=31120
		HDFS: Number of read operations=1965
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=640
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:55  [ main:43073 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:55  [ main:43084 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:55  [ main:43089 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:55  [ main:43094 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:55  [ main:43136 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:55  [ main:43152 ] - [ INFO ]  Submitting tokens for job: job_local1466756406_0031
2020-11-19 10:18:55  [ main:43184 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:55  [ main:43184 ] - [ INFO ]  Running job: job_local1466756406_0031
2020-11-19 10:18:55  [ Thread-918:43185 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:55  [ Thread-918:43185 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:55  [ Thread-918:43185 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:55  [ Thread-918:43192 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]  Starting task: attempt_local1466756406_0031_m_000000_0
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43192 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43193 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43200 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43269 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43271 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43272 ] - [ INFO ]  Task:attempt_local1466756406_0031_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43279 ] - [ INFO ]  map
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43279 ] - [ INFO ]  Task 'attempt_local1466756406_0031_m_000000_0' done.
2020-11-19 10:18:55  [ LocalJobRunner Map Task Executor #0:43279 ] - [ INFO ]  Finishing task: attempt_local1466756406_0031_m_000000_0
2020-11-19 10:18:55  [ Thread-918:43279 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:55  [ Thread-918:43279 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:55  [ pool-96-thread-1:43279 ] - [ INFO ]  Starting task: attempt_local1466756406_0031_r_000000_0
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12c36af1
2020-11-19 10:18:55  [ pool-96-thread-1:43280 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:55  [ EventFetcher for fetching Map Completion Events:43280 ] - [ INFO ]  attempt_local1466756406_0031_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:55  [ localfetcher#31:43281 ] - [ INFO ]  localfetcher#31 about to shuffle output of map attempt_local1466756406_0031_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:55  [ localfetcher#31:43281 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1466756406_0031_m_000000_0
2020-11-19 10:18:55  [ localfetcher#31:43281 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:55  [ EventFetcher for fetching Map Completion Events:43281 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:55  [ pool-96-thread-1:43282 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:55  [ pool-96-thread-1:43283 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:55  [ pool-96-thread-1:43325 ] - [ INFO ]  Task:attempt_local1466756406_0031_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:55  [ pool-96-thread-1:43332 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:55  [ pool-96-thread-1:43332 ] - [ INFO ]  Task attempt_local1466756406_0031_r_000000_0 is allowed to commit now
2020-11-19 10:18:55  [ pool-96-thread-1:43348 ] - [ INFO ]  Saved output of task 'attempt_local1466756406_0031_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1466756406_0031_r_000000
2020-11-19 10:18:55  [ pool-96-thread-1:43349 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:55  [ pool-96-thread-1:43349 ] - [ INFO ]  Task 'attempt_local1466756406_0031_r_000000_0' done.
2020-11-19 10:18:55  [ pool-96-thread-1:43349 ] - [ INFO ]  Finishing task: attempt_local1466756406_0031_r_000000_0
2020-11-19 10:18:55  [ Thread-918:43349 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:56  [ main:44189 ] - [ INFO ]  Job job_local1466756406_0031 running in uber mode : false
2020-11-19 10:18:56  [ main:44189 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:56  [ main:44189 ] - [ INFO ]  Job job_local1466756406_0031 completed successfully
2020-11-19 10:18:56  [ main:44190 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=118284
		FILE: Number of bytes written=17759439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1993674
		HDFS: Number of bytes written=32200
		HDFS: Number of read operations=2033
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=662
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:56  [ main:44867 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:56  [ main:44878 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:56  [ main:44883 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:56  [ main:44889 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:56  [ main:44929 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:56  [ main:44946 ] - [ INFO ]  Submitting tokens for job: job_local297105078_0032
2020-11-19 10:18:56  [ main:44978 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:56  [ main:44979 ] - [ INFO ]  Running job: job_local297105078_0032
2020-11-19 10:18:56  [ Thread-948:44979 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:56  [ Thread-948:44979 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:56  [ Thread-948:44979 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:56  [ Thread-948:44988 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]  Starting task: attempt_local297105078_0032_m_000000_0
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44988 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44989 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:56  [ LocalJobRunner Map Task Executor #0:44996 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45060 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45062 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45063 ] - [ INFO ]  Task:attempt_local297105078_0032_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45071 ] - [ INFO ]  map
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45071 ] - [ INFO ]  Task 'attempt_local297105078_0032_m_000000_0' done.
2020-11-19 10:18:57  [ LocalJobRunner Map Task Executor #0:45071 ] - [ INFO ]  Finishing task: attempt_local297105078_0032_m_000000_0
2020-11-19 10:18:57  [ Thread-948:45071 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:57  [ Thread-948:45071 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:57  [ pool-99-thread-1:45071 ] - [ INFO ]  Starting task: attempt_local297105078_0032_r_000000_0
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3af3fc30
2020-11-19 10:18:57  [ pool-99-thread-1:45072 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:57  [ EventFetcher for fetching Map Completion Events:45073 ] - [ INFO ]  attempt_local297105078_0032_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:57  [ localfetcher#32:45073 ] - [ INFO ]  localfetcher#32 about to shuffle output of map attempt_local297105078_0032_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:57  [ localfetcher#32:45073 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local297105078_0032_m_000000_0
2020-11-19 10:18:57  [ localfetcher#32:45073 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:57  [ EventFetcher for fetching Map Completion Events:45074 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:57  [ pool-99-thread-1:45074 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:57  [ pool-99-thread-1:45074 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:57  [ pool-99-thread-1:45075 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:57  [ pool-99-thread-1:45076 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:57  [ pool-99-thread-1:45076 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:57  [ pool-99-thread-1:45116 ] - [ INFO ]  Task:attempt_local297105078_0032_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:57  [ pool-99-thread-1:45122 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:57  [ pool-99-thread-1:45122 ] - [ INFO ]  Task attempt_local297105078_0032_r_000000_0 is allowed to commit now
2020-11-19 10:18:57  [ pool-99-thread-1:45138 ] - [ INFO ]  Saved output of task 'attempt_local297105078_0032_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local297105078_0032_r_000000
2020-11-19 10:18:57  [ pool-99-thread-1:45139 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:57  [ pool-99-thread-1:45139 ] - [ INFO ]  Task 'attempt_local297105078_0032_r_000000_0' done.
2020-11-19 10:18:57  [ pool-99-thread-1:45139 ] - [ INFO ]  Finishing task: attempt_local297105078_0032_r_000000_0
2020-11-19 10:18:57  [ Thread-948:45139 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:57  [ main:45981 ] - [ INFO ]  Job job_local297105078_0032 running in uber mode : false
2020-11-19 10:18:57  [ main:45982 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:57  [ main:45982 ] - [ INFO ]  Job job_local297105078_0032 completed successfully
2020-11-19 10:18:57  [ main:45983 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=119476
		FILE: Number of bytes written=18328314
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2058080
		HDFS: Number of bytes written=33280
		HDFS: Number of read operations=2101
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=684
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:58  [ main:46282 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:58  [ main:46294 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:58  [ main:46298 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:58  [ main:46305 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:58  [ main:46345 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:58  [ main:46361 ] - [ INFO ]  Submitting tokens for job: job_local126845285_0033
2020-11-19 10:18:58  [ main:46392 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:58  [ main:46392 ] - [ INFO ]  Running job: job_local126845285_0033
2020-11-19 10:18:58  [ Thread-978:46392 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:58  [ Thread-978:46392 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:58  [ Thread-978:46392 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:58  [ Thread-978:46399 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46399 ] - [ INFO ]  Starting task: attempt_local126845285_0033_m_000000_0
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46400 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46408 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46492 ] - [ INFO ]  
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46493 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46495 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46496 ] - [ INFO ]  Task:attempt_local126845285_0033_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46502 ] - [ INFO ]  map
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46502 ] - [ INFO ]  Task 'attempt_local126845285_0033_m_000000_0' done.
2020-11-19 10:18:58  [ LocalJobRunner Map Task Executor #0:46502 ] - [ INFO ]  Finishing task: attempt_local126845285_0033_m_000000_0
2020-11-19 10:18:58  [ Thread-978:46502 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:58  [ Thread-978:46502 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:58  [ pool-102-thread-1:46502 ] - [ INFO ]  Starting task: attempt_local126845285_0033_r_000000_0
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b9e5251
2020-11-19 10:18:58  [ pool-102-thread-1:46503 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:58  [ EventFetcher for fetching Map Completion Events:46503 ] - [ INFO ]  attempt_local126845285_0033_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:58  [ localfetcher#33:46504 ] - [ INFO ]  localfetcher#33 about to shuffle output of map attempt_local126845285_0033_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:18:58  [ localfetcher#33:46504 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local126845285_0033_m_000000_0
2020-11-19 10:18:58  [ localfetcher#33:46504 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:18:58  [ EventFetcher for fetching Map Completion Events:46505 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:58  [ pool-102-thread-1:46505 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:58  [ pool-102-thread-1:46505 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:58  [ pool-102-thread-1:46506 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:18:58  [ pool-102-thread-1:46507 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:58  [ pool-102-thread-1:46561 ] - [ INFO ]  Task:attempt_local126845285_0033_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:58  [ pool-102-thread-1:46566 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:58  [ pool-102-thread-1:46567 ] - [ INFO ]  Task attempt_local126845285_0033_r_000000_0 is allowed to commit now
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  Saved output of task 'attempt_local126845285_0033_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local126845285_0033_r_000000
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  Task 'attempt_local126845285_0033_r_000000_0' done.
2020-11-19 10:18:58  [ pool-102-thread-1:46584 ] - [ INFO ]  Finishing task: attempt_local126845285_0033_r_000000_0
2020-11-19 10:18:58  [ Thread-978:46584 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:18:59  [ main:47394 ] - [ INFO ]  Job job_local126845285_0033 running in uber mode : false
2020-11-19 10:18:59  [ main:47394 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:18:59  [ main:47394 ] - [ INFO ]  Job job_local126845285_0033 completed successfully
2020-11-19 10:18:59  [ main:47395 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=120666
		FILE: Number of bytes written=18897188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2122486
		HDFS: Number of bytes written=34360
		HDFS: Number of read operations=2169
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=706
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:18:59  [ main:47717 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:18:59  [ main:47727 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:18:59  [ main:47730 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:18:59  [ main:47737 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:18:59  [ main:47772 ] - [ INFO ]  number of splits:1
2020-11-19 10:18:59  [ main:47789 ] - [ INFO ]  Submitting tokens for job: job_local708387464_0034
2020-11-19 10:18:59  [ main:47818 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:18:59  [ main:47819 ] - [ INFO ]  Running job: job_local708387464_0034
2020-11-19 10:18:59  [ Thread-1008:47819 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:18:59  [ Thread-1008:47819 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:59  [ Thread-1008:47819 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:18:59  [ Thread-1008:47826 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]  Starting task: attempt_local708387464_0034_m_000000_0
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47827 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47828 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47838 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47839 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  Spilling map output
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47894 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47896 ] - [ INFO ]  Finished spill 0
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47897 ] - [ INFO ]  Task:attempt_local708387464_0034_m_000000_0 is done. And is in the process of committing
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47904 ] - [ INFO ]  map
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47904 ] - [ INFO ]  Task 'attempt_local708387464_0034_m_000000_0' done.
2020-11-19 10:18:59  [ LocalJobRunner Map Task Executor #0:47904 ] - [ INFO ]  Finishing task: attempt_local708387464_0034_m_000000_0
2020-11-19 10:18:59  [ Thread-1008:47904 ] - [ INFO ]  map task executor complete.
2020-11-19 10:18:59  [ Thread-1008:47905 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  Starting task: attempt_local708387464_0034_r_000000_0
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53b36b4d
2020-11-19 10:18:59  [ pool-105-thread-1:47905 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:18:59  [ EventFetcher for fetching Map Completion Events:47906 ] - [ INFO ]  attempt_local708387464_0034_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:18:59  [ localfetcher#34:47906 ] - [ INFO ]  localfetcher#34 about to shuffle output of map attempt_local708387464_0034_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:18:59  [ localfetcher#34:47906 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local708387464_0034_m_000000_0
2020-11-19 10:18:59  [ localfetcher#34:47906 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:18:59  [ EventFetcher for fetching Map Completion Events:47907 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:18:59  [ pool-105-thread-1:47907 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:59  [ pool-105-thread-1:47907 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:18:59  [ pool-105-thread-1:47907 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:18:59  [ pool-105-thread-1:47908 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:59  [ pool-105-thread-1:47952 ] - [ INFO ]  Task:attempt_local708387464_0034_r_000000_0 is done. And is in the process of committing
2020-11-19 10:18:59  [ pool-105-thread-1:47958 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:18:59  [ pool-105-thread-1:47958 ] - [ INFO ]  Task attempt_local708387464_0034_r_000000_0 is allowed to commit now
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  Saved output of task 'attempt_local708387464_0034_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local708387464_0034_r_000000
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  reduce > reduce
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  Task 'attempt_local708387464_0034_r_000000_0' done.
2020-11-19 10:18:59  [ pool-105-thread-1:47976 ] - [ INFO ]  Finishing task: attempt_local708387464_0034_r_000000_0
2020-11-19 10:18:59  [ Thread-1008:47976 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:00  [ main:48820 ] - [ INFO ]  Job job_local708387464_0034 running in uber mode : false
2020-11-19 10:19:00  [ main:48820 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:00  [ main:48820 ] - [ INFO ]  Job job_local708387464_0034 completed successfully
2020-11-19 10:19:00  [ main:48821 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=121858
		FILE: Number of bytes written=19466065
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2186892
		HDFS: Number of bytes written=35440
		HDFS: Number of read operations=2237
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=728
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2423259136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:01  [ main:49105 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:01  [ main:49115 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:01  [ main:49120 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:01  [ main:49125 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:01  [ main:49164 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:01  [ main:49182 ] - [ INFO ]  Submitting tokens for job: job_local566160288_0035
2020-11-19 10:19:01  [ main:49227 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:01  [ main:49227 ] - [ INFO ]  Running job: job_local566160288_0035
2020-11-19 10:19:01  [ Thread-1038:49227 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:01  [ Thread-1038:49227 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:01  [ Thread-1038:49227 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:01  [ Thread-1038:49235 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  Starting task: attempt_local566160288_0035_m_000000_0
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49236 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49244 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49299 ] - [ INFO ]  
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49300 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49301 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49302 ] - [ INFO ]  Task:attempt_local566160288_0035_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49308 ] - [ INFO ]  map
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49308 ] - [ INFO ]  Task 'attempt_local566160288_0035_m_000000_0' done.
2020-11-19 10:19:01  [ LocalJobRunner Map Task Executor #0:49308 ] - [ INFO ]  Finishing task: attempt_local566160288_0035_m_000000_0
2020-11-19 10:19:01  [ Thread-1038:49308 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:01  [ Thread-1038:49309 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  Starting task: attempt_local566160288_0035_r_000000_0
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b93d762
2020-11-19 10:19:01  [ pool-108-thread-1:49309 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:01  [ EventFetcher for fetching Map Completion Events:49310 ] - [ INFO ]  attempt_local566160288_0035_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:01  [ localfetcher#35:49310 ] - [ INFO ]  localfetcher#35 about to shuffle output of map attempt_local566160288_0035_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:01  [ localfetcher#35:49310 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local566160288_0035_m_000000_0
2020-11-19 10:19:01  [ localfetcher#35:49310 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:01  [ EventFetcher for fetching Map Completion Events:49311 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:01  [ pool-108-thread-1:49311 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:01  [ pool-108-thread-1:49312 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:01  [ pool-108-thread-1:49367 ] - [ INFO ]  Task:attempt_local566160288_0035_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:01  [ pool-108-thread-1:49373 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:01  [ pool-108-thread-1:49373 ] - [ INFO ]  Task attempt_local566160288_0035_r_000000_0 is allowed to commit now
2020-11-19 10:19:01  [ pool-108-thread-1:49393 ] - [ INFO ]  Saved output of task 'attempt_local566160288_0035_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local566160288_0035_r_000000
2020-11-19 10:19:01  [ pool-108-thread-1:49394 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:01  [ pool-108-thread-1:49394 ] - [ INFO ]  Task 'attempt_local566160288_0035_r_000000_0' done.
2020-11-19 10:19:01  [ pool-108-thread-1:49394 ] - [ INFO ]  Finishing task: attempt_local566160288_0035_r_000000_0
2020-11-19 10:19:01  [ Thread-1038:49394 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:02  [ main:50227 ] - [ INFO ]  Job job_local566160288_0035 running in uber mode : false
2020-11-19 10:19:02  [ main:50228 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:02  [ main:50228 ] - [ INFO ]  Job job_local566160288_0035 completed successfully
2020-11-19 10:19:02  [ main:50228 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=123050
		FILE: Number of bytes written=20034940
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2251298
		HDFS: Number of bytes written=36520
		HDFS: Number of read operations=2305
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=750
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:02  [ main:50497 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:02  [ main:50508 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:02  [ main:50512 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:02  [ main:50517 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:02  [ main:50555 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:02  [ main:50572 ] - [ INFO ]  Submitting tokens for job: job_local1343639200_0036
2020-11-19 10:19:02  [ main:50601 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:02  [ main:50602 ] - [ INFO ]  Running job: job_local1343639200_0036
2020-11-19 10:19:02  [ Thread-1068:50602 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:02  [ Thread-1068:50602 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:02  [ Thread-1068:50602 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:02  [ Thread-1068:50609 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]  Starting task: attempt_local1343639200_0036_m_000000_0
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50609 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50610 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50616 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50617 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50617 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50682 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50684 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50685 ] - [ INFO ]  Task:attempt_local1343639200_0036_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50691 ] - [ INFO ]  map
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50691 ] - [ INFO ]  Task 'attempt_local1343639200_0036_m_000000_0' done.
2020-11-19 10:19:02  [ LocalJobRunner Map Task Executor #0:50691 ] - [ INFO ]  Finishing task: attempt_local1343639200_0036_m_000000_0
2020-11-19 10:19:02  [ Thread-1068:50691 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:02  [ Thread-1068:50692 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  Starting task: attempt_local1343639200_0036_r_000000_0
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4720fd5f
2020-11-19 10:19:02  [ pool-111-thread-1:50692 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:02  [ EventFetcher for fetching Map Completion Events:50693 ] - [ INFO ]  attempt_local1343639200_0036_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:02  [ localfetcher#36:50693 ] - [ INFO ]  localfetcher#36 about to shuffle output of map attempt_local1343639200_0036_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:02  [ localfetcher#36:50694 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1343639200_0036_m_000000_0
2020-11-19 10:19:02  [ localfetcher#36:50694 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:02  [ EventFetcher for fetching Map Completion Events:50694 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:02  [ pool-111-thread-1:50694 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:02  [ pool-111-thread-1:50694 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:02  [ pool-111-thread-1:50695 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:02  [ pool-111-thread-1:50696 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:02  [ pool-111-thread-1:50696 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:02  [ pool-111-thread-1:50749 ] - [ INFO ]  Task:attempt_local1343639200_0036_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:02  [ pool-111-thread-1:50755 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:02  [ pool-111-thread-1:50755 ] - [ INFO ]  Task attempt_local1343639200_0036_r_000000_0 is allowed to commit now
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  Saved output of task 'attempt_local1343639200_0036_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1343639200_0036_r_000000
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  Task 'attempt_local1343639200_0036_r_000000_0' done.
2020-11-19 10:19:02  [ pool-111-thread-1:50771 ] - [ INFO ]  Finishing task: attempt_local1343639200_0036_r_000000_0
2020-11-19 10:19:02  [ Thread-1068:50771 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:03  [ main:51606 ] - [ INFO ]  Job job_local1343639200_0036 running in uber mode : false
2020-11-19 10:19:03  [ main:51607 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:03  [ main:51607 ] - [ INFO ]  Job job_local1343639200_0036 completed successfully
2020-11-19 10:19:03  [ main:51607 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=124240
		FILE: Number of bytes written=20606862
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2315704
		HDFS: Number of bytes written=37600
		HDFS: Number of read operations=2373
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=772
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:04  [ main:52096 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:04  [ main:52107 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:04  [ main:52112 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:04  [ main:52117 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:04  [ main:52155 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:04  [ main:52173 ] - [ INFO ]  Submitting tokens for job: job_local1711682094_0037
2020-11-19 10:19:04  [ main:52202 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:04  [ main:52202 ] - [ INFO ]  Running job: job_local1711682094_0037
2020-11-19 10:19:04  [ Thread-1098:52202 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:04  [ Thread-1098:52202 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:04  [ Thread-1098:52203 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:04  [ Thread-1098:52210 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52210 ] - [ INFO ]  Starting task: attempt_local1711682094_0037_m_000000_0
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52211 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52219 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52287 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52289 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52290 ] - [ INFO ]  Task:attempt_local1711682094_0037_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52296 ] - [ INFO ]  map
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52296 ] - [ INFO ]  Task 'attempt_local1711682094_0037_m_000000_0' done.
2020-11-19 10:19:04  [ LocalJobRunner Map Task Executor #0:52296 ] - [ INFO ]  Finishing task: attempt_local1711682094_0037_m_000000_0
2020-11-19 10:19:04  [ Thread-1098:52296 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:04  [ Thread-1098:52297 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  Starting task: attempt_local1711682094_0037_r_000000_0
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:04  [ pool-114-thread-1:52297 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@727f2737
2020-11-19 10:19:04  [ pool-114-thread-1:52298 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:04  [ EventFetcher for fetching Map Completion Events:52298 ] - [ INFO ]  attempt_local1711682094_0037_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:04  [ localfetcher#37:52299 ] - [ INFO ]  localfetcher#37 about to shuffle output of map attempt_local1711682094_0037_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:04  [ localfetcher#37:52299 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1711682094_0037_m_000000_0
2020-11-19 10:19:04  [ localfetcher#37:52299 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:04  [ EventFetcher for fetching Map Completion Events:52299 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:04  [ pool-114-thread-1:52299 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:04  [ pool-114-thread-1:52299 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:04  [ pool-114-thread-1:52300 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:04  [ pool-114-thread-1:52300 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:04  [ pool-114-thread-1:52301 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:04  [ pool-114-thread-1:52345 ] - [ INFO ]  Task:attempt_local1711682094_0037_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:04  [ pool-114-thread-1:52352 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:04  [ pool-114-thread-1:52352 ] - [ INFO ]  Task attempt_local1711682094_0037_r_000000_0 is allowed to commit now
2020-11-19 10:19:04  [ pool-114-thread-1:52370 ] - [ INFO ]  Saved output of task 'attempt_local1711682094_0037_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1711682094_0037_r_000000
2020-11-19 10:19:04  [ pool-114-thread-1:52371 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:04  [ pool-114-thread-1:52371 ] - [ INFO ]  Task 'attempt_local1711682094_0037_r_000000_0' done.
2020-11-19 10:19:04  [ pool-114-thread-1:52371 ] - [ INFO ]  Finishing task: attempt_local1711682094_0037_r_000000_0
2020-11-19 10:19:04  [ Thread-1098:52371 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]  Job job_local1711682094_0037 running in uber mode : false
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]  Job job_local1711682094_0037 completed successfully
2020-11-19 10:19:05  [ main:53208 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=125432
		FILE: Number of bytes written=21178787
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2380110
		HDFS: Number of bytes written=38680
		HDFS: Number of read operations=2441
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=794
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:05  [ main:53536 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:05  [ main:53547 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:05  [ main:53552 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:05  [ main:53559 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:05  [ main:53599 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:05  [ main:53616 ] - [ INFO ]  Submitting tokens for job: job_local621588039_0038
2020-11-19 10:19:05  [ main:53647 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:05  [ main:53647 ] - [ INFO ]  Running job: job_local621588039_0038
2020-11-19 10:19:05  [ Thread-1128:53647 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:05  [ Thread-1128:53647 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:05  [ Thread-1128:53647 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:05  [ Thread-1128:53655 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53655 ] - [ INFO ]  Starting task: attempt_local621588039_0038_m_000000_0
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53656 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53663 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53731 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53732 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53733 ] - [ INFO ]  Task:attempt_local621588039_0038_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53743 ] - [ INFO ]  map
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53743 ] - [ INFO ]  Task 'attempt_local621588039_0038_m_000000_0' done.
2020-11-19 10:19:05  [ LocalJobRunner Map Task Executor #0:53743 ] - [ INFO ]  Finishing task: attempt_local621588039_0038_m_000000_0
2020-11-19 10:19:05  [ Thread-1128:53743 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:05  [ Thread-1128:53743 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  Starting task: attempt_local621588039_0038_r_000000_0
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30efd474
2020-11-19 10:19:05  [ pool-117-thread-1:53744 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:05  [ EventFetcher for fetching Map Completion Events:53745 ] - [ INFO ]  attempt_local621588039_0038_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:05  [ localfetcher#38:53745 ] - [ INFO ]  localfetcher#38 about to shuffle output of map attempt_local621588039_0038_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:05  [ localfetcher#38:53746 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local621588039_0038_m_000000_0
2020-11-19 10:19:05  [ localfetcher#38:53746 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:05  [ EventFetcher for fetching Map Completion Events:53746 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:05  [ pool-117-thread-1:53746 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:05  [ pool-117-thread-1:53746 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:05  [ pool-117-thread-1:53747 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:05  [ pool-117-thread-1:53748 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:05  [ pool-117-thread-1:53748 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:05  [ pool-117-thread-1:53812 ] - [ INFO ]  Task:attempt_local621588039_0038_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:05  [ pool-117-thread-1:53818 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:05  [ pool-117-thread-1:53818 ] - [ INFO ]  Task attempt_local621588039_0038_r_000000_0 is allowed to commit now
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  Saved output of task 'attempt_local621588039_0038_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local621588039_0038_r_000000
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  Task 'attempt_local621588039_0038_r_000000_0' done.
2020-11-19 10:19:05  [ pool-117-thread-1:53836 ] - [ INFO ]  Finishing task: attempt_local621588039_0038_r_000000_0
2020-11-19 10:19:05  [ Thread-1128:53837 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:06  [ main:54648 ] - [ INFO ]  Job job_local621588039_0038 running in uber mode : false
2020-11-19 10:19:06  [ main:54648 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:06  [ main:54648 ] - [ INFO ]  Job job_local621588039_0038 completed successfully
2020-11-19 10:19:06  [ main:54649 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=126624
		FILE: Number of bytes written=21747662
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2444516
		HDFS: Number of bytes written=39760
		HDFS: Number of read operations=2509
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=816
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2597322752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:06  [ main:54932 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:06  [ main:54943 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:06  [ main:54948 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:06  [ main:54953 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:06  [ main:54993 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:07  [ main:55010 ] - [ INFO ]  Submitting tokens for job: job_local677122145_0039
2020-11-19 10:19:07  [ main:55050 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:07  [ main:55050 ] - [ INFO ]  Running job: job_local677122145_0039
2020-11-19 10:19:07  [ Thread-1158:55051 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:07  [ Thread-1158:55051 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:07  [ Thread-1158:55051 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:07  [ Thread-1158:55059 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]  Starting task: attempt_local677122145_0039_m_000000_0
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55059 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55060 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55069 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55070 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55134 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55136 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55136 ] - [ INFO ]  Task:attempt_local677122145_0039_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55143 ] - [ INFO ]  map
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55143 ] - [ INFO ]  Task 'attempt_local677122145_0039_m_000000_0' done.
2020-11-19 10:19:07  [ LocalJobRunner Map Task Executor #0:55143 ] - [ INFO ]  Finishing task: attempt_local677122145_0039_m_000000_0
2020-11-19 10:19:07  [ Thread-1158:55143 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:07  [ Thread-1158:55143 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  Starting task: attempt_local677122145_0039_r_000000_0
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23663e43
2020-11-19 10:19:07  [ pool-120-thread-1:55144 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:07  [ EventFetcher for fetching Map Completion Events:55145 ] - [ INFO ]  attempt_local677122145_0039_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:07  [ localfetcher#39:55146 ] - [ INFO ]  localfetcher#39 about to shuffle output of map attempt_local677122145_0039_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:07  [ localfetcher#39:55146 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local677122145_0039_m_000000_0
2020-11-19 10:19:07  [ localfetcher#39:55146 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:07  [ EventFetcher for fetching Map Completion Events:55146 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:07  [ pool-120-thread-1:55146 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:07  [ pool-120-thread-1:55146 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:07  [ pool-120-thread-1:55147 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:07  [ pool-120-thread-1:55147 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:07  [ pool-120-thread-1:55148 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:07  [ pool-120-thread-1:55205 ] - [ INFO ]  Task:attempt_local677122145_0039_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:07  [ pool-120-thread-1:55211 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:07  [ pool-120-thread-1:55211 ] - [ INFO ]  Task attempt_local677122145_0039_r_000000_0 is allowed to commit now
2020-11-19 10:19:07  [ pool-120-thread-1:55230 ] - [ INFO ]  Saved output of task 'attempt_local677122145_0039_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local677122145_0039_r_000000
2020-11-19 10:19:07  [ pool-120-thread-1:55231 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:07  [ pool-120-thread-1:55231 ] - [ INFO ]  Task 'attempt_local677122145_0039_r_000000_0' done.
2020-11-19 10:19:07  [ pool-120-thread-1:55231 ] - [ INFO ]  Finishing task: attempt_local677122145_0039_r_000000_0
2020-11-19 10:19:07  [ Thread-1158:55231 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:08  [ main:56051 ] - [ INFO ]  Job job_local677122145_0039 running in uber mode : false
2020-11-19 10:19:08  [ main:56052 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:08  [ main:56052 ] - [ INFO ]  Job job_local677122145_0039 completed successfully
2020-11-19 10:19:08  [ main:56052 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=127814
		FILE: Number of bytes written=22316536
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2508922
		HDFS: Number of bytes written=40840
		HDFS: Number of read operations=2577
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=838
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:08  [ main:56325 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:08  [ main:56336 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:08  [ main:56341 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:08  [ main:56349 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:08  [ main:56390 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:08  [ main:56407 ] - [ INFO ]  Submitting tokens for job: job_local1982298173_0040
2020-11-19 10:19:08  [ main:56439 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:08  [ main:56439 ] - [ INFO ]  Running job: job_local1982298173_0040
2020-11-19 10:19:08  [ Thread-1188:56439 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:08  [ Thread-1188:56439 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:08  [ Thread-1188:56439 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:08  [ Thread-1188:56446 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56446 ] - [ INFO ]  Starting task: attempt_local1982298173_0040_m_000000_0
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56447 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56454 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56525 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56527 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56528 ] - [ INFO ]  Task:attempt_local1982298173_0040_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56533 ] - [ INFO ]  map
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56533 ] - [ INFO ]  Task 'attempt_local1982298173_0040_m_000000_0' done.
2020-11-19 10:19:08  [ LocalJobRunner Map Task Executor #0:56533 ] - [ INFO ]  Finishing task: attempt_local1982298173_0040_m_000000_0
2020-11-19 10:19:08  [ Thread-1188:56534 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:08  [ Thread-1188:56534 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  Starting task: attempt_local1982298173_0040_r_000000_0
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:08  [ pool-123-thread-1:56534 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@de71f5a
2020-11-19 10:19:08  [ pool-123-thread-1:56535 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:08  [ EventFetcher for fetching Map Completion Events:56535 ] - [ INFO ]  attempt_local1982298173_0040_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:08  [ localfetcher#40:56536 ] - [ INFO ]  localfetcher#40 about to shuffle output of map attempt_local1982298173_0040_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:08  [ localfetcher#40:56536 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1982298173_0040_m_000000_0
2020-11-19 10:19:08  [ localfetcher#40:56536 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:08  [ EventFetcher for fetching Map Completion Events:56536 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:08  [ pool-123-thread-1:56536 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:08  [ pool-123-thread-1:56536 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:08  [ pool-123-thread-1:56537 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:08  [ pool-123-thread-1:56537 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:08  [ pool-123-thread-1:56538 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:08  [ pool-123-thread-1:56584 ] - [ INFO ]  Task:attempt_local1982298173_0040_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:08  [ pool-123-thread-1:56589 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:08  [ pool-123-thread-1:56589 ] - [ INFO ]  Task attempt_local1982298173_0040_r_000000_0 is allowed to commit now
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  Saved output of task 'attempt_local1982298173_0040_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1982298173_0040_r_000000
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  Task 'attempt_local1982298173_0040_r_000000_0' done.
2020-11-19 10:19:08  [ pool-123-thread-1:56606 ] - [ INFO ]  Finishing task: attempt_local1982298173_0040_r_000000_0
2020-11-19 10:19:08  [ Thread-1188:56606 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]  Job job_local1982298173_0040 running in uber mode : false
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]  Job job_local1982298173_0040 completed successfully
2020-11-19 10:19:09  [ main:57441 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=129006
		FILE: Number of bytes written=22888461
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2573328
		HDFS: Number of bytes written=41920
		HDFS: Number of read operations=2645
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=860
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:09  [ main:57754 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:09  [ main:57765 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:09  [ main:57770 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:09  [ main:57775 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:09  [ main:57814 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:09  [ main:57831 ] - [ INFO ]  Submitting tokens for job: job_local1559126420_0041
2020-11-19 10:19:09  [ main:57861 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:09  [ main:57861 ] - [ INFO ]  Running job: job_local1559126420_0041
2020-11-19 10:19:09  [ Thread-1218:57861 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:09  [ Thread-1218:57861 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:09  [ Thread-1218:57861 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:09  [ Thread-1218:57870 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57870 ] - [ INFO ]  Starting task: attempt_local1559126420_0041_m_000000_0
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57871 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57878 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57879 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57947 ] - [ INFO ]  
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57948 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57949 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57950 ] - [ INFO ]  Task:attempt_local1559126420_0041_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57956 ] - [ INFO ]  map
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57956 ] - [ INFO ]  Task 'attempt_local1559126420_0041_m_000000_0' done.
2020-11-19 10:19:09  [ LocalJobRunner Map Task Executor #0:57956 ] - [ INFO ]  Finishing task: attempt_local1559126420_0041_m_000000_0
2020-11-19 10:19:09  [ Thread-1218:57956 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:09  [ Thread-1218:57957 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  Starting task: attempt_local1559126420_0041_r_000000_0
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@536362e9
2020-11-19 10:19:09  [ pool-126-thread-1:57957 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:09  [ EventFetcher for fetching Map Completion Events:57958 ] - [ INFO ]  attempt_local1559126420_0041_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:09  [ localfetcher#41:57958 ] - [ INFO ]  localfetcher#41 about to shuffle output of map attempt_local1559126420_0041_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:09  [ localfetcher#41:57959 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1559126420_0041_m_000000_0
2020-11-19 10:19:09  [ localfetcher#41:57959 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:09  [ EventFetcher for fetching Map Completion Events:57959 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:09  [ pool-126-thread-1:57959 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:09  [ pool-126-thread-1:57959 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:09  [ pool-126-thread-1:57960 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:09  [ pool-126-thread-1:57960 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:09  [ pool-126-thread-1:57960 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:09  [ pool-126-thread-1:57961 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:10  [ pool-126-thread-1:58021 ] - [ INFO ]  Task:attempt_local1559126420_0041_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:10  [ pool-126-thread-1:58028 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:10  [ pool-126-thread-1:58028 ] - [ INFO ]  Task attempt_local1559126420_0041_r_000000_0 is allowed to commit now
2020-11-19 10:19:10  [ pool-126-thread-1:58044 ] - [ INFO ]  Saved output of task 'attempt_local1559126420_0041_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1559126420_0041_r_000000
2020-11-19 10:19:10  [ pool-126-thread-1:58045 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:10  [ pool-126-thread-1:58045 ] - [ INFO ]  Task 'attempt_local1559126420_0041_r_000000_0' done.
2020-11-19 10:19:10  [ pool-126-thread-1:58045 ] - [ INFO ]  Finishing task: attempt_local1559126420_0041_r_000000_0
2020-11-19 10:19:10  [ Thread-1218:58045 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:10  [ main:58863 ] - [ INFO ]  Job job_local1559126420_0041 running in uber mode : false
2020-11-19 10:19:10  [ main:58863 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:10  [ main:58863 ] - [ INFO ]  Job job_local1559126420_0041 completed successfully
2020-11-19 10:19:10  [ main:58864 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=130198
		FILE: Number of bytes written=23460384
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2637734
		HDFS: Number of bytes written=43000
		HDFS: Number of read operations=2713
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=882
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:11  [ main:59156 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:11  [ main:59167 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:11  [ main:59172 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:11  [ main:59177 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:11  [ main:59216 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:11  [ main:59234 ] - [ INFO ]  Submitting tokens for job: job_local1396890892_0042
2020-11-19 10:19:11  [ main:59265 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:11  [ main:59265 ] - [ INFO ]  Running job: job_local1396890892_0042
2020-11-19 10:19:11  [ Thread-1248:59265 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:11  [ Thread-1248:59265 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:11  [ Thread-1248:59265 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:11  [ Thread-1248:59273 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  Starting task: attempt_local1396890892_0042_m_000000_0
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59274 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59282 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59346 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59348 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59349 ] - [ INFO ]  Task:attempt_local1396890892_0042_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59356 ] - [ INFO ]  map
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59356 ] - [ INFO ]  Task 'attempt_local1396890892_0042_m_000000_0' done.
2020-11-19 10:19:11  [ LocalJobRunner Map Task Executor #0:59356 ] - [ INFO ]  Finishing task: attempt_local1396890892_0042_m_000000_0
2020-11-19 10:19:11  [ Thread-1248:59357 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:11  [ Thread-1248:59357 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:11  [ pool-129-thread-1:59357 ] - [ INFO ]  Starting task: attempt_local1396890892_0042_r_000000_0
2020-11-19 10:19:11  [ pool-129-thread-1:59357 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23ed2db9
2020-11-19 10:19:11  [ pool-129-thread-1:59358 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:11  [ EventFetcher for fetching Map Completion Events:59358 ] - [ INFO ]  attempt_local1396890892_0042_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:11  [ localfetcher#42:59359 ] - [ INFO ]  localfetcher#42 about to shuffle output of map attempt_local1396890892_0042_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:11  [ localfetcher#42:59359 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1396890892_0042_m_000000_0
2020-11-19 10:19:11  [ localfetcher#42:59359 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:11  [ EventFetcher for fetching Map Completion Events:59359 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:11  [ pool-129-thread-1:59359 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:11  [ pool-129-thread-1:59360 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:11  [ pool-129-thread-1:59360 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:11  [ pool-129-thread-1:59360 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:11  [ pool-129-thread-1:59361 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:11  [ pool-129-thread-1:59422 ] - [ INFO ]  Task:attempt_local1396890892_0042_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:11  [ pool-129-thread-1:59427 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:11  [ pool-129-thread-1:59427 ] - [ INFO ]  Task attempt_local1396890892_0042_r_000000_0 is allowed to commit now
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  Saved output of task 'attempt_local1396890892_0042_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1396890892_0042_r_000000
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  Task 'attempt_local1396890892_0042_r_000000_0' done.
2020-11-19 10:19:11  [ pool-129-thread-1:59446 ] - [ INFO ]  Finishing task: attempt_local1396890892_0042_r_000000_0
2020-11-19 10:19:11  [ Thread-1248:59446 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:12  [ main:60268 ] - [ INFO ]  Job job_local1396890892_0042 running in uber mode : false
2020-11-19 10:19:12  [ main:60268 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:12  [ main:60268 ] - [ INFO ]  Job job_local1396890892_0042 completed successfully
2020-11-19 10:19:12  [ main:60269 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=131388
		FILE: Number of bytes written=24032306
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2702140
		HDFS: Number of bytes written=44080
		HDFS: Number of read operations=2781
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=904
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2635071488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:12  [ main:60549 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:12  [ main:60560 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:12  [ main:60565 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:12  [ main:60570 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:12  [ main:60609 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:12  [ main:60626 ] - [ INFO ]  Submitting tokens for job: job_local815155349_0043
2020-11-19 10:19:12  [ main:60669 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:12  [ main:60669 ] - [ INFO ]  Running job: job_local815155349_0043
2020-11-19 10:19:12  [ Thread-1278:60670 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:12  [ Thread-1278:60670 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:12  [ Thread-1278:60670 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:12  [ Thread-1278:60677 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60677 ] - [ INFO ]  Starting task: attempt_local815155349_0043_m_000000_0
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60678 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60711 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60768 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60771 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60771 ] - [ INFO ]  Task:attempt_local815155349_0043_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60776 ] - [ INFO ]  map
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60776 ] - [ INFO ]  Task 'attempt_local815155349_0043_m_000000_0' done.
2020-11-19 10:19:12  [ LocalJobRunner Map Task Executor #0:60776 ] - [ INFO ]  Finishing task: attempt_local815155349_0043_m_000000_0
2020-11-19 10:19:12  [ Thread-1278:60777 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:12  [ Thread-1278:60777 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:12  [ pool-132-thread-1:60777 ] - [ INFO ]  Starting task: attempt_local815155349_0043_r_000000_0
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27af4549
2020-11-19 10:19:12  [ pool-132-thread-1:60778 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:12  [ EventFetcher for fetching Map Completion Events:60778 ] - [ INFO ]  attempt_local815155349_0043_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:12  [ localfetcher#43:60782 ] - [ INFO ]  localfetcher#43 about to shuffle output of map attempt_local815155349_0043_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:12  [ localfetcher#43:60782 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local815155349_0043_m_000000_0
2020-11-19 10:19:12  [ localfetcher#43:60782 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:12  [ EventFetcher for fetching Map Completion Events:60782 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:12  [ pool-132-thread-1:60784 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:12  [ pool-132-thread-1:60784 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:12  [ pool-132-thread-1:60785 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:12  [ pool-132-thread-1:60786 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:12  [ pool-132-thread-1:60826 ] - [ INFO ]  Task:attempt_local815155349_0043_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:12  [ pool-132-thread-1:60832 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:12  [ pool-132-thread-1:60832 ] - [ INFO ]  Task attempt_local815155349_0043_r_000000_0 is allowed to commit now
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  Saved output of task 'attempt_local815155349_0043_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local815155349_0043_r_000000
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  Task 'attempt_local815155349_0043_r_000000_0' done.
2020-11-19 10:19:12  [ pool-132-thread-1:60849 ] - [ INFO ]  Finishing task: attempt_local815155349_0043_r_000000_0
2020-11-19 10:19:12  [ Thread-1278:60849 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]  Job job_local815155349_0043 running in uber mode : false
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]  Job job_local815155349_0043 completed successfully
2020-11-19 10:19:13  [ main:61674 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=132580
		FILE: Number of bytes written=24601183
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2766546
		HDFS: Number of bytes written=45160
		HDFS: Number of read operations=2849
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=926
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2706898944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:13  [ main:61974 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:13  [ main:61984 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:13  [ main:61989 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:13  [ main:61997 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:14  [ main:62035 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:14  [ main:62052 ] - [ INFO ]  Submitting tokens for job: job_local545838815_0044
2020-11-19 10:19:14  [ main:62084 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:14  [ main:62084 ] - [ INFO ]  Running job: job_local545838815_0044
2020-11-19 10:19:14  [ Thread-1308:62084 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:14  [ Thread-1308:62084 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:14  [ Thread-1308:62085 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:14  [ Thread-1308:62091 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]  Starting task: attempt_local545838815_0044_m_000000_0
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62091 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62092 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62100 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62174 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62176 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62177 ] - [ INFO ]  Task:attempt_local545838815_0044_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62183 ] - [ INFO ]  map
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62183 ] - [ INFO ]  Task 'attempt_local545838815_0044_m_000000_0' done.
2020-11-19 10:19:14  [ LocalJobRunner Map Task Executor #0:62183 ] - [ INFO ]  Finishing task: attempt_local545838815_0044_m_000000_0
2020-11-19 10:19:14  [ Thread-1308:62183 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:14  [ Thread-1308:62183 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:14  [ pool-135-thread-1:62183 ] - [ INFO ]  Starting task: attempt_local545838815_0044_r_000000_0
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5117456f
2020-11-19 10:19:14  [ pool-135-thread-1:62184 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:14  [ EventFetcher for fetching Map Completion Events:62184 ] - [ INFO ]  attempt_local545838815_0044_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:14  [ localfetcher#44:62185 ] - [ INFO ]  localfetcher#44 about to shuffle output of map attempt_local545838815_0044_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:14  [ localfetcher#44:62185 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local545838815_0044_m_000000_0
2020-11-19 10:19:14  [ localfetcher#44:62185 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:14  [ EventFetcher for fetching Map Completion Events:62185 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:14  [ pool-135-thread-1:62186 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:14  [ pool-135-thread-1:62187 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:14  [ pool-135-thread-1:62242 ] - [ INFO ]  Task:attempt_local545838815_0044_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:14  [ pool-135-thread-1:62247 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:14  [ pool-135-thread-1:62247 ] - [ INFO ]  Task attempt_local545838815_0044_r_000000_0 is allowed to commit now
2020-11-19 10:19:14  [ pool-135-thread-1:62265 ] - [ INFO ]  Saved output of task 'attempt_local545838815_0044_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local545838815_0044_r_000000
2020-11-19 10:19:14  [ pool-135-thread-1:62266 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:14  [ pool-135-thread-1:62266 ] - [ INFO ]  Task 'attempt_local545838815_0044_r_000000_0' done.
2020-11-19 10:19:14  [ pool-135-thread-1:62266 ] - [ INFO ]  Finishing task: attempt_local545838815_0044_r_000000_0
2020-11-19 10:19:14  [ Thread-1308:62266 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]  Job job_local545838815_0044 running in uber mode : false
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]  Job job_local545838815_0044 completed successfully
2020-11-19 10:19:15  [ main:63089 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=133772
		FILE: Number of bytes written=25170058
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2830952
		HDFS: Number of bytes written=46240
		HDFS: Number of read operations=2917
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=948
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:15  [ main:63367 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:15  [ main:63380 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:15  [ main:63385 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:15  [ main:63389 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:15  [ main:63429 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:15  [ main:63446 ] - [ INFO ]  Submitting tokens for job: job_local812009207_0045
2020-11-19 10:19:15  [ main:63475 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:15  [ main:63476 ] - [ INFO ]  Running job: job_local812009207_0045
2020-11-19 10:19:15  [ Thread-1338:63476 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:15  [ Thread-1338:63476 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:15  [ Thread-1338:63476 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:15  [ Thread-1338:63482 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63482 ] - [ INFO ]  Starting task: attempt_local812009207_0045_m_000000_0
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63483 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63490 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63491 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63562 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63564 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63565 ] - [ INFO ]  Task:attempt_local812009207_0045_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63571 ] - [ INFO ]  map
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63571 ] - [ INFO ]  Task 'attempt_local812009207_0045_m_000000_0' done.
2020-11-19 10:19:15  [ LocalJobRunner Map Task Executor #0:63571 ] - [ INFO ]  Finishing task: attempt_local812009207_0045_m_000000_0
2020-11-19 10:19:15  [ Thread-1338:63571 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:15  [ Thread-1338:63571 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:15  [ pool-138-thread-1:63571 ] - [ INFO ]  Starting task: attempt_local812009207_0045_r_000000_0
2020-11-19 10:19:15  [ pool-138-thread-1:63571 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cf8d531
2020-11-19 10:19:15  [ pool-138-thread-1:63572 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:15  [ EventFetcher for fetching Map Completion Events:63572 ] - [ INFO ]  attempt_local812009207_0045_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:15  [ localfetcher#45:63573 ] - [ INFO ]  localfetcher#45 about to shuffle output of map attempt_local812009207_0045_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:15  [ localfetcher#45:63573 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local812009207_0045_m_000000_0
2020-11-19 10:19:15  [ localfetcher#45:63573 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:15  [ EventFetcher for fetching Map Completion Events:63573 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:15  [ pool-138-thread-1:63574 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:15  [ pool-138-thread-1:63575 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:15  [ pool-138-thread-1:63628 ] - [ INFO ]  Task:attempt_local812009207_0045_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:15  [ pool-138-thread-1:63634 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:15  [ pool-138-thread-1:63634 ] - [ INFO ]  Task attempt_local812009207_0045_r_000000_0 is allowed to commit now
2020-11-19 10:19:15  [ pool-138-thread-1:63650 ] - [ INFO ]  Saved output of task 'attempt_local812009207_0045_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local812009207_0045_r_000000
2020-11-19 10:19:15  [ pool-138-thread-1:63651 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:15  [ pool-138-thread-1:63651 ] - [ INFO ]  Task 'attempt_local812009207_0045_r_000000_0' done.
2020-11-19 10:19:15  [ pool-138-thread-1:63651 ] - [ INFO ]  Finishing task: attempt_local812009207_0045_r_000000_0
2020-11-19 10:19:15  [ Thread-1338:63651 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:16  [ main:64477 ] - [ INFO ]  Job job_local812009207_0045 running in uber mode : false
2020-11-19 10:19:16  [ main:64477 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:16  [ main:64477 ] - [ INFO ]  Job job_local812009207_0045 completed successfully
2020-11-19 10:19:16  [ main:64478 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=134962
		FILE: Number of bytes written=25738932
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2895358
		HDFS: Number of bytes written=47320
		HDFS: Number of read operations=2985
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=970
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:16  [ main:64748 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:16  [ main:64759 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:16  [ main:64764 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:16  [ main:64770 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:16  [ main:64811 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:16  [ main:64828 ] - [ INFO ]  Submitting tokens for job: job_local1820082500_0046
2020-11-19 10:19:16  [ main:64859 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:16  [ main:64859 ] - [ INFO ]  Running job: job_local1820082500_0046
2020-11-19 10:19:16  [ Thread-1368:64859 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:16  [ Thread-1368:64859 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:16  [ Thread-1368:64859 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:16  [ Thread-1368:64867 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64867 ] - [ INFO ]  Starting task: attempt_local1820082500_0046_m_000000_0
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64867 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64867 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64868 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64868 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64875 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64947 ] - [ INFO ]  
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64947 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64948 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64948 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64948 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64949 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64950 ] - [ INFO ]  Task:attempt_local1820082500_0046_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64956 ] - [ INFO ]  map
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64956 ] - [ INFO ]  Task 'attempt_local1820082500_0046_m_000000_0' done.
2020-11-19 10:19:16  [ LocalJobRunner Map Task Executor #0:64956 ] - [ INFO ]  Finishing task: attempt_local1820082500_0046_m_000000_0
2020-11-19 10:19:16  [ Thread-1368:64956 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:16  [ Thread-1368:64956 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  Starting task: attempt_local1820082500_0046_r_000000_0
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6343ed77
2020-11-19 10:19:16  [ pool-141-thread-1:64957 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:16  [ EventFetcher for fetching Map Completion Events:64958 ] - [ INFO ]  attempt_local1820082500_0046_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:16  [ localfetcher#46:64958 ] - [ INFO ]  localfetcher#46 about to shuffle output of map attempt_local1820082500_0046_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:16  [ localfetcher#46:64959 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1820082500_0046_m_000000_0
2020-11-19 10:19:16  [ localfetcher#46:64959 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:16  [ EventFetcher for fetching Map Completion Events:64959 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:16  [ pool-141-thread-1:64959 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:16  [ pool-141-thread-1:64959 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:16  [ pool-141-thread-1:64960 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:16  [ pool-141-thread-1:64960 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:16  [ pool-141-thread-1:64960 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:16  [ pool-141-thread-1:64961 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:17  [ pool-141-thread-1:65013 ] - [ INFO ]  Task:attempt_local1820082500_0046_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:17  [ pool-141-thread-1:65019 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:17  [ pool-141-thread-1:65019 ] - [ INFO ]  Task attempt_local1820082500_0046_r_000000_0 is allowed to commit now
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  Saved output of task 'attempt_local1820082500_0046_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1820082500_0046_r_000000
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  Task 'attempt_local1820082500_0046_r_000000_0' done.
2020-11-19 10:19:17  [ pool-141-thread-1:65049 ] - [ INFO ]  Finishing task: attempt_local1820082500_0046_r_000000_0
2020-11-19 10:19:17  [ Thread-1368:65049 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:17  [ main:65859 ] - [ INFO ]  Job job_local1820082500_0046 running in uber mode : false
2020-11-19 10:19:17  [ main:65859 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:17  [ main:65859 ] - [ INFO ]  Job job_local1820082500_0046 completed successfully
2020-11-19 10:19:17  [ main:65860 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=136154
		FILE: Number of bytes written=26310857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2959764
		HDFS: Number of bytes written=48400
		HDFS: Number of read operations=3053
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=992
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:18  [ main:66337 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:18  [ main:66349 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:18  [ main:66353 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:18  [ main:66359 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:18  [ main:66398 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:18  [ main:66415 ] - [ INFO ]  Submitting tokens for job: job_local945525481_0047
2020-11-19 10:19:18  [ main:66444 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:18  [ main:66444 ] - [ INFO ]  Running job: job_local945525481_0047
2020-11-19 10:19:18  [ Thread-1398:66444 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:18  [ Thread-1398:66444 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:18  [ Thread-1398:66445 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:18  [ Thread-1398:66452 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]  Starting task: attempt_local945525481_0047_m_000000_0
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66452 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66453 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66463 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66529 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66531 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66532 ] - [ INFO ]  Task:attempt_local945525481_0047_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66538 ] - [ INFO ]  map
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66538 ] - [ INFO ]  Task 'attempt_local945525481_0047_m_000000_0' done.
2020-11-19 10:19:18  [ LocalJobRunner Map Task Executor #0:66538 ] - [ INFO ]  Finishing task: attempt_local945525481_0047_m_000000_0
2020-11-19 10:19:18  [ Thread-1398:66538 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:18  [ Thread-1398:66538 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:18  [ pool-144-thread-1:66538 ] - [ INFO ]  Starting task: attempt_local945525481_0047_r_000000_0
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f29e0de
2020-11-19 10:19:18  [ pool-144-thread-1:66539 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:18  [ EventFetcher for fetching Map Completion Events:66539 ] - [ INFO ]  attempt_local945525481_0047_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:18  [ localfetcher#47:66540 ] - [ INFO ]  localfetcher#47 about to shuffle output of map attempt_local945525481_0047_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:18  [ localfetcher#47:66540 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local945525481_0047_m_000000_0
2020-11-19 10:19:18  [ localfetcher#47:66540 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:18  [ EventFetcher for fetching Map Completion Events:66540 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:18  [ pool-144-thread-1:66541 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:18  [ pool-144-thread-1:66542 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:18  [ pool-144-thread-1:66581 ] - [ INFO ]  Task:attempt_local945525481_0047_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:18  [ pool-144-thread-1:66587 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:18  [ pool-144-thread-1:66587 ] - [ INFO ]  Task attempt_local945525481_0047_r_000000_0 is allowed to commit now
2020-11-19 10:19:18  [ pool-144-thread-1:66602 ] - [ INFO ]  Saved output of task 'attempt_local945525481_0047_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local945525481_0047_r_000000
2020-11-19 10:19:18  [ pool-144-thread-1:66603 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:18  [ pool-144-thread-1:66603 ] - [ INFO ]  Task 'attempt_local945525481_0047_r_000000_0' done.
2020-11-19 10:19:18  [ pool-144-thread-1:66603 ] - [ INFO ]  Finishing task: attempt_local945525481_0047_r_000000_0
2020-11-19 10:19:18  [ Thread-1398:66603 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:19  [ main:67447 ] - [ INFO ]  Job job_local945525481_0047 running in uber mode : false
2020-11-19 10:19:19  [ main:67448 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:19  [ main:67448 ] - [ INFO ]  Job job_local945525481_0047 completed successfully
2020-11-19 10:19:19  [ main:67448 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=137346
		FILE: Number of bytes written=26879732
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3024170
		HDFS: Number of bytes written=49480
		HDFS: Number of read operations=3121
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1014
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2778726400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:19  [ main:67855 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:19  [ main:67866 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:19  [ main:67870 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:19  [ main:67876 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:19  [ main:67916 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:19  [ main:67933 ] - [ INFO ]  Submitting tokens for job: job_local1943269184_0048
2020-11-19 10:19:19  [ main:67964 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:19  [ main:67964 ] - [ INFO ]  Running job: job_local1943269184_0048
2020-11-19 10:19:19  [ Thread-1428:67964 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:19  [ Thread-1428:67964 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:19  [ Thread-1428:67964 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:19  [ Thread-1428:67972 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]  Starting task: attempt_local1943269184_0048_m_000000_0
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67972 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67973 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67982 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67982 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67982 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67983 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67983 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:19  [ LocalJobRunner Map Task Executor #0:67983 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68047 ] - [ INFO ]  
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68047 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68047 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68048 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68048 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68049 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68050 ] - [ INFO ]  Task:attempt_local1943269184_0048_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68057 ] - [ INFO ]  map
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68057 ] - [ INFO ]  Task 'attempt_local1943269184_0048_m_000000_0' done.
2020-11-19 10:19:20  [ LocalJobRunner Map Task Executor #0:68057 ] - [ INFO ]  Finishing task: attempt_local1943269184_0048_m_000000_0
2020-11-19 10:19:20  [ Thread-1428:68057 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:20  [ Thread-1428:68057 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:20  [ pool-147-thread-1:68057 ] - [ INFO ]  Starting task: attempt_local1943269184_0048_r_000000_0
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2bdd98c0
2020-11-19 10:19:20  [ pool-147-thread-1:68058 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:20  [ EventFetcher for fetching Map Completion Events:68058 ] - [ INFO ]  attempt_local1943269184_0048_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:20  [ localfetcher#48:68059 ] - [ INFO ]  localfetcher#48 about to shuffle output of map attempt_local1943269184_0048_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:20  [ localfetcher#48:68059 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1943269184_0048_m_000000_0
2020-11-19 10:19:20  [ localfetcher#48:68059 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:20  [ EventFetcher for fetching Map Completion Events:68059 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:20  [ pool-147-thread-1:68060 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:20  [ pool-147-thread-1:68061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:20  [ pool-147-thread-1:68116 ] - [ INFO ]  Task:attempt_local1943269184_0048_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:20  [ pool-147-thread-1:68122 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:20  [ pool-147-thread-1:68122 ] - [ INFO ]  Task attempt_local1943269184_0048_r_000000_0 is allowed to commit now
2020-11-19 10:19:20  [ pool-147-thread-1:68138 ] - [ INFO ]  Saved output of task 'attempt_local1943269184_0048_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1943269184_0048_r_000000
2020-11-19 10:19:20  [ pool-147-thread-1:68138 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:20  [ pool-147-thread-1:68139 ] - [ INFO ]  Task 'attempt_local1943269184_0048_r_000000_0' done.
2020-11-19 10:19:20  [ pool-147-thread-1:68139 ] - [ INFO ]  Finishing task: attempt_local1943269184_0048_r_000000_0
2020-11-19 10:19:20  [ Thread-1428:68139 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:20  [ main:68968 ] - [ INFO ]  Job job_local1943269184_0048 running in uber mode : false
2020-11-19 10:19:20  [ main:68968 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:20  [ main:68968 ] - [ INFO ]  Job job_local1943269184_0048 completed successfully
2020-11-19 10:19:20  [ main:68969 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=138536
		FILE: Number of bytes written=27451654
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3088576
		HDFS: Number of bytes written=50560
		HDFS: Number of read operations=3189
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1036
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:21  [ main:69434 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:21  [ main:69446 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:21  [ main:69451 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:21  [ main:69457 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:21  [ main:69499 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:21  [ main:69516 ] - [ INFO ]  Submitting tokens for job: job_local375415053_0049
2020-11-19 10:19:21  [ main:69548 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:21  [ main:69548 ] - [ INFO ]  Running job: job_local375415053_0049
2020-11-19 10:19:21  [ Thread-1458:69548 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:21  [ Thread-1458:69548 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:21  [ Thread-1458:69548 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:21  [ Thread-1458:69558 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69558 ] - [ INFO ]  Starting task: attempt_local375415053_0049_m_000000_0
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69559 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69568 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69759 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69761 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69762 ] - [ INFO ]  Task:attempt_local375415053_0049_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69768 ] - [ INFO ]  map
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69768 ] - [ INFO ]  Task 'attempt_local375415053_0049_m_000000_0' done.
2020-11-19 10:19:21  [ LocalJobRunner Map Task Executor #0:69768 ] - [ INFO ]  Finishing task: attempt_local375415053_0049_m_000000_0
2020-11-19 10:19:21  [ Thread-1458:69769 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:21  [ Thread-1458:69769 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]  Starting task: attempt_local375415053_0049_r_000000_0
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:21  [ pool-150-thread-1:69769 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:21  [ pool-150-thread-1:69770 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@499ee14c
2020-11-19 10:19:21  [ pool-150-thread-1:69770 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:21  [ EventFetcher for fetching Map Completion Events:69770 ] - [ INFO ]  attempt_local375415053_0049_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:21  [ localfetcher#49:69771 ] - [ INFO ]  localfetcher#49 about to shuffle output of map attempt_local375415053_0049_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:21  [ localfetcher#49:69771 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local375415053_0049_m_000000_0
2020-11-19 10:19:21  [ localfetcher#49:69771 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:21  [ EventFetcher for fetching Map Completion Events:69771 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:21  [ pool-150-thread-1:69771 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:21  [ pool-150-thread-1:69771 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:21  [ pool-150-thread-1:69772 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:21  [ pool-150-thread-1:69772 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:21  [ pool-150-thread-1:69773 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:21  [ pool-150-thread-1:69812 ] - [ INFO ]  Task:attempt_local375415053_0049_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:21  [ pool-150-thread-1:69818 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:21  [ pool-150-thread-1:69818 ] - [ INFO ]  Task attempt_local375415053_0049_r_000000_0 is allowed to commit now
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  Saved output of task 'attempt_local375415053_0049_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local375415053_0049_r_000000
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  Task 'attempt_local375415053_0049_r_000000_0' done.
2020-11-19 10:19:21  [ pool-150-thread-1:69834 ] - [ INFO ]  Finishing task: attempt_local375415053_0049_r_000000_0
2020-11-19 10:19:21  [ Thread-1458:69835 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:22  [ main:70552 ] - [ INFO ]  Job job_local375415053_0049 running in uber mode : false
2020-11-19 10:19:22  [ main:70553 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:22  [ main:70553 ] - [ INFO ]  Job job_local375415053_0049 completed successfully
2020-11-19 10:19:22  [ main:70553 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=139728
		FILE: Number of bytes written=28020531
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3152982
		HDFS: Number of bytes written=51640
		HDFS: Number of read operations=3257
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1058
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:22  [ main:70846 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:22  [ main:70861 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:22  [ main:70866 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:22  [ main:70872 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:22  [ main:70911 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:22  [ main:70928 ] - [ INFO ]  Submitting tokens for job: job_local1436142197_0050
2020-11-19 10:19:22  [ main:70968 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:22  [ main:70968 ] - [ INFO ]  Running job: job_local1436142197_0050
2020-11-19 10:19:22  [ Thread-1488:70968 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:22  [ Thread-1488:70968 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:22  [ Thread-1488:70968 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:22  [ Thread-1488:70975 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]  Starting task: attempt_local1436142197_0050_m_000000_0
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70975 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70976 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:22  [ LocalJobRunner Map Task Executor #0:70985 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71047 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71049 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71050 ] - [ INFO ]  Task:attempt_local1436142197_0050_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71057 ] - [ INFO ]  map
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71057 ] - [ INFO ]  Task 'attempt_local1436142197_0050_m_000000_0' done.
2020-11-19 10:19:23  [ LocalJobRunner Map Task Executor #0:71057 ] - [ INFO ]  Finishing task: attempt_local1436142197_0050_m_000000_0
2020-11-19 10:19:23  [ Thread-1488:71057 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:23  [ Thread-1488:71057 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:23  [ pool-153-thread-1:71057 ] - [ INFO ]  Starting task: attempt_local1436142197_0050_r_000000_0
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1456ec6
2020-11-19 10:19:23  [ pool-153-thread-1:71058 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:23  [ EventFetcher for fetching Map Completion Events:71058 ] - [ INFO ]  attempt_local1436142197_0050_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:23  [ localfetcher#50:71059 ] - [ INFO ]  localfetcher#50 about to shuffle output of map attempt_local1436142197_0050_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:23  [ localfetcher#50:71059 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1436142197_0050_m_000000_0
2020-11-19 10:19:23  [ localfetcher#50:71059 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:23  [ EventFetcher for fetching Map Completion Events:71059 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:23  [ pool-153-thread-1:71060 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:23  [ pool-153-thread-1:71060 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:23  [ pool-153-thread-1:71060 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:23  [ pool-153-thread-1:71061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:23  [ pool-153-thread-1:71113 ] - [ INFO ]  Task:attempt_local1436142197_0050_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:23  [ pool-153-thread-1:71119 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:23  [ pool-153-thread-1:71119 ] - [ INFO ]  Task attempt_local1436142197_0050_r_000000_0 is allowed to commit now
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  Saved output of task 'attempt_local1436142197_0050_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1436142197_0050_r_000000
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  Task 'attempt_local1436142197_0050_r_000000_0' done.
2020-11-19 10:19:23  [ pool-153-thread-1:71137 ] - [ INFO ]  Finishing task: attempt_local1436142197_0050_r_000000_0
2020-11-19 10:19:23  [ Thread-1488:71137 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:23  [ main:71973 ] - [ INFO ]  Job job_local1436142197_0050 running in uber mode : false
2020-11-19 10:19:23  [ main:71973 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:23  [ main:71974 ] - [ INFO ]  Job job_local1436142197_0050 completed successfully
2020-11-19 10:19:23  [ main:71974 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=140920
		FILE: Number of bytes written=28592454
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3217388
		HDFS: Number of bytes written=52720
		HDFS: Number of read operations=3325
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1080
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:24  [ main:72382 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:24  [ main:72392 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:24  [ main:72397 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:24  [ main:72408 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:24  [ main:72452 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:24  [ main:72468 ] - [ INFO ]  Submitting tokens for job: job_local953586171_0051
2020-11-19 10:19:24  [ main:72499 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:24  [ main:72499 ] - [ INFO ]  Running job: job_local953586171_0051
2020-11-19 10:19:24  [ Thread-1518:72499 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:24  [ Thread-1518:72499 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:24  [ Thread-1518:72499 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:24  [ Thread-1518:72506 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72506 ] - [ INFO ]  Starting task: attempt_local953586171_0051_m_000000_0
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72507 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72514 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72515 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72579 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72581 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72582 ] - [ INFO ]  Task:attempt_local953586171_0051_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72589 ] - [ INFO ]  map
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72590 ] - [ INFO ]  Task 'attempt_local953586171_0051_m_000000_0' done.
2020-11-19 10:19:24  [ LocalJobRunner Map Task Executor #0:72590 ] - [ INFO ]  Finishing task: attempt_local953586171_0051_m_000000_0
2020-11-19 10:19:24  [ Thread-1518:72590 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:24  [ Thread-1518:72590 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:24  [ pool-156-thread-1:72590 ] - [ INFO ]  Starting task: attempt_local953586171_0051_r_000000_0
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67887e5a
2020-11-19 10:19:24  [ pool-156-thread-1:72591 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:24  [ EventFetcher for fetching Map Completion Events:72591 ] - [ INFO ]  attempt_local953586171_0051_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:24  [ localfetcher#51:72592 ] - [ INFO ]  localfetcher#51 about to shuffle output of map attempt_local953586171_0051_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:24  [ localfetcher#51:72592 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local953586171_0051_m_000000_0
2020-11-19 10:19:24  [ localfetcher#51:72592 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:24  [ EventFetcher for fetching Map Completion Events:72592 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:24  [ pool-156-thread-1:72593 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:24  [ pool-156-thread-1:72594 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:24  [ pool-156-thread-1:72639 ] - [ INFO ]  Task:attempt_local953586171_0051_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:24  [ pool-156-thread-1:72646 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:24  [ pool-156-thread-1:72646 ] - [ INFO ]  Task attempt_local953586171_0051_r_000000_0 is allowed to commit now
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  Saved output of task 'attempt_local953586171_0051_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local953586171_0051_r_000000
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  Task 'attempt_local953586171_0051_r_000000_0' done.
2020-11-19 10:19:24  [ pool-156-thread-1:72666 ] - [ INFO ]  Finishing task: attempt_local953586171_0051_r_000000_0
2020-11-19 10:19:24  [ Thread-1518:72666 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]  Job job_local953586171_0051 running in uber mode : false
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]  Job job_local953586171_0051 completed successfully
2020-11-19 10:19:25  [ main:73502 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=142110
		FILE: Number of bytes written=29161328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3281794
		HDFS: Number of bytes written=53800
		HDFS: Number of read operations=3393
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1102
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:25  [ main:73782 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:25  [ main:73793 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:25  [ main:73798 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:25  [ main:73803 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:25  [ main:73843 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:25  [ main:73860 ] - [ INFO ]  Submitting tokens for job: job_local1757105829_0052
2020-11-19 10:19:25  [ main:73890 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:25  [ main:73890 ] - [ INFO ]  Running job: job_local1757105829_0052
2020-11-19 10:19:25  [ Thread-1548:73890 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:25  [ Thread-1548:73890 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:25  [ Thread-1548:73890 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:25  [ Thread-1548:73897 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73897 ] - [ INFO ]  Starting task: attempt_local1757105829_0052_m_000000_0
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73898 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73910 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73911 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73979 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73982 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73983 ] - [ INFO ]  Task:attempt_local1757105829_0052_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73990 ] - [ INFO ]  map
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73990 ] - [ INFO ]  Task 'attempt_local1757105829_0052_m_000000_0' done.
2020-11-19 10:19:25  [ LocalJobRunner Map Task Executor #0:73990 ] - [ INFO ]  Finishing task: attempt_local1757105829_0052_m_000000_0
2020-11-19 10:19:25  [ Thread-1548:73990 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:25  [ Thread-1548:73990 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:25  [ pool-159-thread-1:73990 ] - [ INFO ]  Starting task: attempt_local1757105829_0052_r_000000_0
2020-11-19 10:19:25  [ pool-159-thread-1:73990 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77fe45be
2020-11-19 10:19:25  [ pool-159-thread-1:73991 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:25  [ EventFetcher for fetching Map Completion Events:73991 ] - [ INFO ]  attempt_local1757105829_0052_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:25  [ localfetcher#52:73992 ] - [ INFO ]  localfetcher#52 about to shuffle output of map attempt_local1757105829_0052_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:25  [ localfetcher#52:73992 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1757105829_0052_m_000000_0
2020-11-19 10:19:25  [ localfetcher#52:73992 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:25  [ EventFetcher for fetching Map Completion Events:73992 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:25  [ pool-159-thread-1:73993 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:25  [ pool-159-thread-1:73994 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:26  [ pool-159-thread-1:74055 ] - [ INFO ]  Task:attempt_local1757105829_0052_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:26  [ pool-159-thread-1:74063 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:26  [ pool-159-thread-1:74063 ] - [ INFO ]  Task attempt_local1757105829_0052_r_000000_0 is allowed to commit now
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  Saved output of task 'attempt_local1757105829_0052_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1757105829_0052_r_000000
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  Task 'attempt_local1757105829_0052_r_000000_0' done.
2020-11-19 10:19:26  [ pool-159-thread-1:74083 ] - [ INFO ]  Finishing task: attempt_local1757105829_0052_r_000000_0
2020-11-19 10:19:26  [ Thread-1548:74083 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:26  [ main:74890 ] - [ INFO ]  Job job_local1757105829_0052 running in uber mode : false
2020-11-19 10:19:26  [ main:74890 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:26  [ main:74891 ] - [ INFO ]  Job job_local1757105829_0052 completed successfully
2020-11-19 10:19:26  [ main:74891 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=143302
		FILE: Number of bytes written=29733253
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3346200
		HDFS: Number of bytes written=54880
		HDFS: Number of read operations=3461
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1124
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2781872128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:27  [ main:75163 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:27  [ main:75176 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:27  [ main:75181 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:27  [ main:75187 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:27  [ main:75227 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:27  [ main:75246 ] - [ INFO ]  Submitting tokens for job: job_local403055273_0053
2020-11-19 10:19:27  [ main:75284 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:27  [ main:75284 ] - [ INFO ]  Running job: job_local403055273_0053
2020-11-19 10:19:27  [ Thread-1578:75285 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:27  [ Thread-1578:75285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:27  [ Thread-1578:75285 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:27  [ Thread-1578:75292 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75292 ] - [ INFO ]  Starting task: attempt_local403055273_0053_m_000000_0
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75292 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75292 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75293 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75293 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75300 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75365 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75367 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75368 ] - [ INFO ]  Task:attempt_local403055273_0053_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75375 ] - [ INFO ]  map
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75375 ] - [ INFO ]  Task 'attempt_local403055273_0053_m_000000_0' done.
2020-11-19 10:19:27  [ LocalJobRunner Map Task Executor #0:75375 ] - [ INFO ]  Finishing task: attempt_local403055273_0053_m_000000_0
2020-11-19 10:19:27  [ Thread-1578:75375 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:27  [ Thread-1578:75375 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:27  [ pool-162-thread-1:75375 ] - [ INFO ]  Starting task: attempt_local403055273_0053_r_000000_0
2020-11-19 10:19:27  [ pool-162-thread-1:75375 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ebc9bbf
2020-11-19 10:19:27  [ pool-162-thread-1:75376 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:27  [ EventFetcher for fetching Map Completion Events:75376 ] - [ INFO ]  attempt_local403055273_0053_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:27  [ localfetcher#53:75377 ] - [ INFO ]  localfetcher#53 about to shuffle output of map attempt_local403055273_0053_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:27  [ localfetcher#53:75377 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local403055273_0053_m_000000_0
2020-11-19 10:19:27  [ localfetcher#53:75377 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:27  [ EventFetcher for fetching Map Completion Events:75377 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:27  [ pool-162-thread-1:75377 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:27  [ pool-162-thread-1:75377 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:27  [ pool-162-thread-1:75378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:27  [ pool-162-thread-1:75378 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:27  [ pool-162-thread-1:75379 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:27  [ pool-162-thread-1:75428 ] - [ INFO ]  Task:attempt_local403055273_0053_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:27  [ pool-162-thread-1:75434 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:27  [ pool-162-thread-1:75434 ] - [ INFO ]  Task attempt_local403055273_0053_r_000000_0 is allowed to commit now
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  Saved output of task 'attempt_local403055273_0053_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local403055273_0053_r_000000
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  Task 'attempt_local403055273_0053_r_000000_0' done.
2020-11-19 10:19:27  [ pool-162-thread-1:75451 ] - [ INFO ]  Finishing task: attempt_local403055273_0053_r_000000_0
2020-11-19 10:19:27  [ Thread-1578:75451 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:28  [ main:76288 ] - [ INFO ]  Job job_local403055273_0053 running in uber mode : false
2020-11-19 10:19:28  [ main:76288 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:28  [ main:76288 ] - [ INFO ]  Job job_local403055273_0053 completed successfully
2020-11-19 10:19:28  [ main:76289 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=144494
		FILE: Number of bytes written=30302128
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3410606
		HDFS: Number of bytes written=55960
		HDFS: Number of read operations=3529
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1146
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:28  [ main:76922 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:28  [ main:76945 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:28  [ main:76949 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:28  [ main:76965 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:29  [ main:77017 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:29  [ main:77034 ] - [ INFO ]  Submitting tokens for job: job_local2007103891_0054
2020-11-19 10:19:29  [ main:77065 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:29  [ main:77065 ] - [ INFO ]  Running job: job_local2007103891_0054
2020-11-19 10:19:29  [ Thread-1608:77065 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:29  [ Thread-1608:77065 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:29  [ Thread-1608:77065 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:29  [ Thread-1608:77085 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]  Starting task: attempt_local2007103891_0054_m_000000_0
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77085 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77086 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77094 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77271 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77273 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77274 ] - [ INFO ]  Task:attempt_local2007103891_0054_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77293 ] - [ INFO ]  map
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77293 ] - [ INFO ]  Task 'attempt_local2007103891_0054_m_000000_0' done.
2020-11-19 10:19:29  [ LocalJobRunner Map Task Executor #0:77293 ] - [ INFO ]  Finishing task: attempt_local2007103891_0054_m_000000_0
2020-11-19 10:19:29  [ Thread-1608:77293 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:29  [ Thread-1608:77293 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  Starting task: attempt_local2007103891_0054_r_000000_0
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59ad20a7
2020-11-19 10:19:29  [ pool-165-thread-1:77294 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:29  [ EventFetcher for fetching Map Completion Events:77295 ] - [ INFO ]  attempt_local2007103891_0054_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:29  [ localfetcher#54:77295 ] - [ INFO ]  localfetcher#54 about to shuffle output of map attempt_local2007103891_0054_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:29  [ localfetcher#54:77295 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2007103891_0054_m_000000_0
2020-11-19 10:19:29  [ localfetcher#54:77295 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:29  [ EventFetcher for fetching Map Completion Events:77296 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:29  [ pool-165-thread-1:77296 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:29  [ pool-165-thread-1:77296 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:29  [ pool-165-thread-1:77297 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:29  [ pool-165-thread-1:77298 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:29  [ pool-165-thread-1:77427 ] - [ INFO ]  Task:attempt_local2007103891_0054_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:29  [ pool-165-thread-1:77442 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:29  [ pool-165-thread-1:77443 ] - [ INFO ]  Task attempt_local2007103891_0054_r_000000_0 is allowed to commit now
2020-11-19 10:19:29  [ pool-165-thread-1:77488 ] - [ INFO ]  Saved output of task 'attempt_local2007103891_0054_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2007103891_0054_r_000000
2020-11-19 10:19:29  [ pool-165-thread-1:77489 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:29  [ pool-165-thread-1:77489 ] - [ INFO ]  Task 'attempt_local2007103891_0054_r_000000_0' done.
2020-11-19 10:19:29  [ pool-165-thread-1:77489 ] - [ INFO ]  Finishing task: attempt_local2007103891_0054_r_000000_0
2020-11-19 10:19:29  [ Thread-1608:77489 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]  Job job_local2007103891_0054 running in uber mode : false
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]  Job job_local2007103891_0054 completed successfully
2020-11-19 10:19:30  [ main:78068 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=145684
		FILE: Number of bytes written=30874050
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3475012
		HDFS: Number of bytes written=57040
		HDFS: Number of read operations=3597
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1168
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:30  [ main:78749 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:30  [ main:78770 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:30  [ main:78775 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:30  [ main:78789 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:30  [ main:78840 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:30  [ main:78856 ] - [ INFO ]  Submitting tokens for job: job_local1354142743_0055
2020-11-19 10:19:30  [ main:78889 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:30  [ main:78889 ] - [ INFO ]  Running job: job_local1354142743_0055
2020-11-19 10:19:30  [ Thread-1638:78889 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:30  [ Thread-1638:78889 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:30  [ Thread-1638:78889 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:30  [ Thread-1638:78907 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78907 ] - [ INFO ]  Starting task: attempt_local1354142743_0055_m_000000_0
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78908 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:30  [ LocalJobRunner Map Task Executor #0:78915 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79078 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79080 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79081 ] - [ INFO ]  Task:attempt_local1354142743_0055_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79095 ] - [ INFO ]  map
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79095 ] - [ INFO ]  Task 'attempt_local1354142743_0055_m_000000_0' done.
2020-11-19 10:19:31  [ LocalJobRunner Map Task Executor #0:79095 ] - [ INFO ]  Finishing task: attempt_local1354142743_0055_m_000000_0
2020-11-19 10:19:31  [ Thread-1638:79095 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:31  [ Thread-1638:79095 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:31  [ pool-168-thread-1:79095 ] - [ INFO ]  Starting task: attempt_local1354142743_0055_r_000000_0
2020-11-19 10:19:31  [ pool-168-thread-1:79095 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b599e1e
2020-11-19 10:19:31  [ pool-168-thread-1:79096 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:31  [ EventFetcher for fetching Map Completion Events:79096 ] - [ INFO ]  attempt_local1354142743_0055_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:31  [ localfetcher#55:79097 ] - [ INFO ]  localfetcher#55 about to shuffle output of map attempt_local1354142743_0055_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:31  [ localfetcher#55:79097 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1354142743_0055_m_000000_0
2020-11-19 10:19:31  [ localfetcher#55:79097 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:31  [ EventFetcher for fetching Map Completion Events:79097 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:31  [ pool-168-thread-1:79098 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:31  [ pool-168-thread-1:79099 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:31  [ pool-168-thread-1:79201 ] - [ INFO ]  Task:attempt_local1354142743_0055_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:31  [ pool-168-thread-1:79214 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:31  [ pool-168-thread-1:79214 ] - [ INFO ]  Task attempt_local1354142743_0055_r_000000_0 is allowed to commit now
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  Saved output of task 'attempt_local1354142743_0055_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1354142743_0055_r_000000
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  Task 'attempt_local1354142743_0055_r_000000_0' done.
2020-11-19 10:19:31  [ pool-168-thread-1:79253 ] - [ INFO ]  Finishing task: attempt_local1354142743_0055_r_000000_0
2020-11-19 10:19:31  [ Thread-1638:79253 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:31  [ main:79890 ] - [ INFO ]  Job job_local1354142743_0055 running in uber mode : false
2020-11-19 10:19:31  [ main:79890 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:31  [ main:79890 ] - [ INFO ]  Job job_local1354142743_0055 completed successfully
2020-11-19 10:19:31  [ main:79891 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=146876
		FILE: Number of bytes written=31445975
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3539418
		HDFS: Number of bytes written=58120
		HDFS: Number of read operations=3665
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1190
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:32  [ main:80301 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:32  [ main:80313 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:32  [ main:80318 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:32  [ main:80323 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:32  [ main:80363 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:32  [ main:80380 ] - [ INFO ]  Submitting tokens for job: job_local2022973440_0056
2020-11-19 10:19:32  [ main:80412 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:32  [ main:80412 ] - [ INFO ]  Running job: job_local2022973440_0056
2020-11-19 10:19:32  [ Thread-1668:80412 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:32  [ Thread-1668:80412 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:32  [ Thread-1668:80412 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:32  [ Thread-1668:80420 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]  Starting task: attempt_local2022973440_0056_m_000000_0
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80420 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80421 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80428 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80497 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80499 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80499 ] - [ INFO ]  Task:attempt_local2022973440_0056_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80505 ] - [ INFO ]  map
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80505 ] - [ INFO ]  Task 'attempt_local2022973440_0056_m_000000_0' done.
2020-11-19 10:19:32  [ LocalJobRunner Map Task Executor #0:80505 ] - [ INFO ]  Finishing task: attempt_local2022973440_0056_m_000000_0
2020-11-19 10:19:32  [ Thread-1668:80505 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:32  [ Thread-1668:80505 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:32  [ pool-171-thread-1:80505 ] - [ INFO ]  Starting task: attempt_local2022973440_0056_r_000000_0
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ba0a24
2020-11-19 10:19:32  [ pool-171-thread-1:80506 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:32  [ EventFetcher for fetching Map Completion Events:80506 ] - [ INFO ]  attempt_local2022973440_0056_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:32  [ localfetcher#56:80507 ] - [ INFO ]  localfetcher#56 about to shuffle output of map attempt_local2022973440_0056_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:32  [ localfetcher#56:80507 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2022973440_0056_m_000000_0
2020-11-19 10:19:32  [ localfetcher#56:80507 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:32  [ EventFetcher for fetching Map Completion Events:80508 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:32  [ pool-171-thread-1:80508 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:32  [ pool-171-thread-1:80509 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:32  [ pool-171-thread-1:80551 ] - [ INFO ]  Task:attempt_local2022973440_0056_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:32  [ pool-171-thread-1:80558 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:32  [ pool-171-thread-1:80558 ] - [ INFO ]  Task attempt_local2022973440_0056_r_000000_0 is allowed to commit now
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  Saved output of task 'attempt_local2022973440_0056_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2022973440_0056_r_000000
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  Task 'attempt_local2022973440_0056_r_000000_0' done.
2020-11-19 10:19:32  [ pool-171-thread-1:80576 ] - [ INFO ]  Finishing task: attempt_local2022973440_0056_r_000000_0
2020-11-19 10:19:32  [ Thread-1668:80576 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]  Job job_local2022973440_0056 running in uber mode : false
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]  Job job_local2022973440_0056 completed successfully
2020-11-19 10:19:33  [ main:81414 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=148068
		FILE: Number of bytes written=32017898
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3603824
		HDFS: Number of bytes written=59200
		HDFS: Number of read operations=3733
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1212
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:33  [ main:81777 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:33  [ main:81790 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:33  [ main:81795 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:33  [ main:81801 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:33  [ main:81843 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:33  [ main:81860 ] - [ INFO ]  Submitting tokens for job: job_local1963254711_0057
2020-11-19 10:19:33  [ main:81892 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:33  [ main:81892 ] - [ INFO ]  Running job: job_local1963254711_0057
2020-11-19 10:19:33  [ Thread-1698:81892 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:33  [ Thread-1698:81892 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:33  [ Thread-1698:81892 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:33  [ Thread-1698:81899 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  Starting task: attempt_local1963254711_0057_m_000000_0
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81899 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81907 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81986 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81988 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81989 ] - [ INFO ]  Task:attempt_local1963254711_0057_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81995 ] - [ INFO ]  map
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81995 ] - [ INFO ]  Task 'attempt_local1963254711_0057_m_000000_0' done.
2020-11-19 10:19:33  [ LocalJobRunner Map Task Executor #0:81995 ] - [ INFO ]  Finishing task: attempt_local1963254711_0057_m_000000_0
2020-11-19 10:19:33  [ Thread-1698:81995 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:33  [ Thread-1698:81995 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:33  [ pool-174-thread-1:81995 ] - [ INFO ]  Starting task: attempt_local1963254711_0057_r_000000_0
2020-11-19 10:19:33  [ pool-174-thread-1:81995 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b3cca9d
2020-11-19 10:19:33  [ pool-174-thread-1:81996 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:33  [ EventFetcher for fetching Map Completion Events:81996 ] - [ INFO ]  attempt_local1963254711_0057_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:33  [ localfetcher#57:81997 ] - [ INFO ]  localfetcher#57 about to shuffle output of map attempt_local1963254711_0057_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:33  [ localfetcher#57:81997 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1963254711_0057_m_000000_0
2020-11-19 10:19:33  [ localfetcher#57:81997 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:33  [ EventFetcher for fetching Map Completion Events:81997 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:33  [ pool-174-thread-1:81998 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:34  [ pool-174-thread-1:81999 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:34  [ pool-174-thread-1:82104 ] - [ INFO ]  Task:attempt_local1963254711_0057_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:34  [ pool-174-thread-1:82111 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:34  [ pool-174-thread-1:82111 ] - [ INFO ]  Task attempt_local1963254711_0057_r_000000_0 is allowed to commit now
2020-11-19 10:19:34  [ pool-174-thread-1:82130 ] - [ INFO ]  Saved output of task 'attempt_local1963254711_0057_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1963254711_0057_r_000000
2020-11-19 10:19:34  [ pool-174-thread-1:82131 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:34  [ pool-174-thread-1:82131 ] - [ INFO ]  Task 'attempt_local1963254711_0057_r_000000_0' done.
2020-11-19 10:19:34  [ pool-174-thread-1:82131 ] - [ INFO ]  Finishing task: attempt_local1963254711_0057_r_000000_0
2020-11-19 10:19:34  [ Thread-1698:82131 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:34  [ main:82893 ] - [ INFO ]  Job job_local1963254711_0057 running in uber mode : false
2020-11-19 10:19:34  [ main:82894 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:34  [ main:82894 ] - [ INFO ]  Job job_local1963254711_0057 completed successfully
2020-11-19 10:19:34  [ main:82894 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=149258
		FILE: Number of bytes written=32589820
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3668230
		HDFS: Number of bytes written=60280
		HDFS: Number of read operations=3801
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1234
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:35  [ main:83176 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:35  [ main:83196 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:35  [ main:83201 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:35  [ main:83211 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:35  [ main:83252 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:35  [ main:83268 ] - [ INFO ]  Submitting tokens for job: job_local721628273_0058
2020-11-19 10:19:35  [ main:83298 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:35  [ main:83298 ] - [ INFO ]  Running job: job_local721628273_0058
2020-11-19 10:19:35  [ Thread-1728:83298 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:35  [ Thread-1728:83298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:35  [ Thread-1728:83298 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:35  [ Thread-1728:83310 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]  Starting task: attempt_local721628273_0058_m_000000_0
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83310 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83311 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83318 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83388 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83390 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83391 ] - [ INFO ]  Task:attempt_local721628273_0058_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83397 ] - [ INFO ]  map
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83397 ] - [ INFO ]  Task 'attempt_local721628273_0058_m_000000_0' done.
2020-11-19 10:19:35  [ LocalJobRunner Map Task Executor #0:83397 ] - [ INFO ]  Finishing task: attempt_local721628273_0058_m_000000_0
2020-11-19 10:19:35  [ Thread-1728:83397 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:35  [ Thread-1728:83397 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:35  [ pool-177-thread-1:83397 ] - [ INFO ]  Starting task: attempt_local721628273_0058_r_000000_0
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23d0a34c
2020-11-19 10:19:35  [ pool-177-thread-1:83398 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:35  [ EventFetcher for fetching Map Completion Events:83398 ] - [ INFO ]  attempt_local721628273_0058_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:35  [ localfetcher#58:83399 ] - [ INFO ]  localfetcher#58 about to shuffle output of map attempt_local721628273_0058_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:35  [ localfetcher#58:83399 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local721628273_0058_m_000000_0
2020-11-19 10:19:35  [ localfetcher#58:83399 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:35  [ EventFetcher for fetching Map Completion Events:83399 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:35  [ pool-177-thread-1:83400 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:35  [ pool-177-thread-1:83401 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:35  [ pool-177-thread-1:83444 ] - [ INFO ]  Task:attempt_local721628273_0058_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:35  [ pool-177-thread-1:83449 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:35  [ pool-177-thread-1:83449 ] - [ INFO ]  Task attempt_local721628273_0058_r_000000_0 is allowed to commit now
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  Saved output of task 'attempt_local721628273_0058_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local721628273_0058_r_000000
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  Task 'attempt_local721628273_0058_r_000000_0' done.
2020-11-19 10:19:35  [ pool-177-thread-1:83471 ] - [ INFO ]  Finishing task: attempt_local721628273_0058_r_000000_0
2020-11-19 10:19:35  [ Thread-1728:83471 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:36  [ main:84301 ] - [ INFO ]  Job job_local721628273_0058 running in uber mode : false
2020-11-19 10:19:36  [ main:84301 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:36  [ main:84302 ] - [ INFO ]  Job job_local721628273_0058 completed successfully
2020-11-19 10:19:36  [ main:84302 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=150450
		FILE: Number of bytes written=33158697
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3732636
		HDFS: Number of bytes written=61360
		HDFS: Number of read operations=3869
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1256
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:36  [ main:84592 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:36  [ main:84603 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:36  [ main:84607 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:36  [ main:84612 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:36  [ main:84651 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:36  [ main:84668 ] - [ INFO ]  Submitting tokens for job: job_local1259128178_0059
2020-11-19 10:19:36  [ main:84698 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:36  [ main:84698 ] - [ INFO ]  Running job: job_local1259128178_0059
2020-11-19 10:19:36  [ Thread-1758:84698 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:36  [ Thread-1758:84698 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:36  [ Thread-1758:84698 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:36  [ Thread-1758:84705 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  Starting task: attempt_local1259128178_0059_m_000000_0
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84705 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84713 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84776 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84778 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84779 ] - [ INFO ]  Task:attempt_local1259128178_0059_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84783 ] - [ INFO ]  map
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84783 ] - [ INFO ]  Task 'attempt_local1259128178_0059_m_000000_0' done.
2020-11-19 10:19:36  [ LocalJobRunner Map Task Executor #0:84783 ] - [ INFO ]  Finishing task: attempt_local1259128178_0059_m_000000_0
2020-11-19 10:19:36  [ Thread-1758:84783 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:36  [ Thread-1758:84784 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  Starting task: attempt_local1259128178_0059_r_000000_0
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33714d38
2020-11-19 10:19:36  [ pool-180-thread-1:84784 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:36  [ EventFetcher for fetching Map Completion Events:84785 ] - [ INFO ]  attempt_local1259128178_0059_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:36  [ localfetcher#59:84785 ] - [ INFO ]  localfetcher#59 about to shuffle output of map attempt_local1259128178_0059_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:36  [ localfetcher#59:84785 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1259128178_0059_m_000000_0
2020-11-19 10:19:36  [ localfetcher#59:84785 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:36  [ EventFetcher for fetching Map Completion Events:84786 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:36  [ pool-180-thread-1:84786 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:36  [ pool-180-thread-1:84786 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:36  [ pool-180-thread-1:84787 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:36  [ pool-180-thread-1:84788 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:36  [ pool-180-thread-1:84788 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:36  [ pool-180-thread-1:84828 ] - [ INFO ]  Task:attempt_local1259128178_0059_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:36  [ pool-180-thread-1:84833 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:36  [ pool-180-thread-1:84833 ] - [ INFO ]  Task attempt_local1259128178_0059_r_000000_0 is allowed to commit now
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  Saved output of task 'attempt_local1259128178_0059_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1259128178_0059_r_000000
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  Task 'attempt_local1259128178_0059_r_000000_0' done.
2020-11-19 10:19:36  [ pool-180-thread-1:84848 ] - [ INFO ]  Finishing task: attempt_local1259128178_0059_r_000000_0
2020-11-19 10:19:36  [ Thread-1758:84848 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:37  [ main:85703 ] - [ INFO ]  Job job_local1259128178_0059 running in uber mode : false
2020-11-19 10:19:37  [ main:85703 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:37  [ main:85703 ] - [ INFO ]  Job job_local1259128178_0059 completed successfully
2020-11-19 10:19:37  [ main:85704 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=151642
		FILE: Number of bytes written=33730620
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3797042
		HDFS: Number of bytes written=62440
		HDFS: Number of read operations=3937
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1278
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:38  [ main:86093 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:38  [ main:86151 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:38  [ main:86155 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:38  [ main:86162 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:38  [ main:86204 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:38  [ main:86221 ] - [ INFO ]  Submitting tokens for job: job_local939927194_0060
2020-11-19 10:19:38  [ main:86250 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:38  [ main:86250 ] - [ INFO ]  Running job: job_local939927194_0060
2020-11-19 10:19:38  [ Thread-1788:86250 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:38  [ Thread-1788:86250 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:38  [ Thread-1788:86250 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:38  [ Thread-1788:86258 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]  Starting task: attempt_local939927194_0060_m_000000_0
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86258 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86259 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86266 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86342 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86344 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86345 ] - [ INFO ]  Task:attempt_local939927194_0060_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86350 ] - [ INFO ]  map
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86350 ] - [ INFO ]  Task 'attempt_local939927194_0060_m_000000_0' done.
2020-11-19 10:19:38  [ LocalJobRunner Map Task Executor #0:86350 ] - [ INFO ]  Finishing task: attempt_local939927194_0060_m_000000_0
2020-11-19 10:19:38  [ Thread-1788:86350 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:38  [ Thread-1788:86350 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  Starting task: attempt_local939927194_0060_r_000000_0
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5eada6ee
2020-11-19 10:19:38  [ pool-183-thread-1:86351 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:38  [ EventFetcher for fetching Map Completion Events:86352 ] - [ INFO ]  attempt_local939927194_0060_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:38  [ localfetcher#60:86352 ] - [ INFO ]  localfetcher#60 about to shuffle output of map attempt_local939927194_0060_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:38  [ localfetcher#60:86352 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local939927194_0060_m_000000_0
2020-11-19 10:19:38  [ localfetcher#60:86352 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:38  [ EventFetcher for fetching Map Completion Events:86353 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:38  [ pool-183-thread-1:86353 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:38  [ pool-183-thread-1:86353 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:38  [ pool-183-thread-1:86354 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:38  [ pool-183-thread-1:86411 ] - [ INFO ]  Task:attempt_local939927194_0060_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:38  [ pool-183-thread-1:86416 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:38  [ pool-183-thread-1:86416 ] - [ INFO ]  Task attempt_local939927194_0060_r_000000_0 is allowed to commit now
2020-11-19 10:19:38  [ pool-183-thread-1:86432 ] - [ INFO ]  Saved output of task 'attempt_local939927194_0060_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local939927194_0060_r_000000
2020-11-19 10:19:38  [ pool-183-thread-1:86433 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:38  [ pool-183-thread-1:86433 ] - [ INFO ]  Task 'attempt_local939927194_0060_r_000000_0' done.
2020-11-19 10:19:38  [ pool-183-thread-1:86433 ] - [ INFO ]  Finishing task: attempt_local939927194_0060_r_000000_0
2020-11-19 10:19:38  [ Thread-1788:86433 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]  Job job_local939927194_0060 running in uber mode : false
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]  Job job_local939927194_0060 completed successfully
2020-11-19 10:19:39  [ main:87251 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=152832
		FILE: Number of bytes written=34299494
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3861448
		HDFS: Number of bytes written=63520
		HDFS: Number of read operations=4005
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1300
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:39  [ main:87543 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:39  [ main:87555 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:39  [ main:87560 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:39  [ main:87567 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:39  [ main:87607 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:39  [ main:87624 ] - [ INFO ]  Submitting tokens for job: job_local956872601_0061
2020-11-19 10:19:39  [ main:87655 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:39  [ main:87655 ] - [ INFO ]  Running job: job_local956872601_0061
2020-11-19 10:19:39  [ Thread-1818:87655 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:39  [ Thread-1818:87655 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:39  [ Thread-1818:87655 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:39  [ Thread-1818:87662 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]  Starting task: attempt_local956872601_0061_m_000000_0
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87662 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87663 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87670 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87742 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87744 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87745 ] - [ INFO ]  Task:attempt_local956872601_0061_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87752 ] - [ INFO ]  map
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87752 ] - [ INFO ]  Task 'attempt_local956872601_0061_m_000000_0' done.
2020-11-19 10:19:39  [ LocalJobRunner Map Task Executor #0:87752 ] - [ INFO ]  Finishing task: attempt_local956872601_0061_m_000000_0
2020-11-19 10:19:39  [ Thread-1818:87753 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:39  [ Thread-1818:87753 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:39  [ pool-186-thread-1:87753 ] - [ INFO ]  Starting task: attempt_local956872601_0061_r_000000_0
2020-11-19 10:19:39  [ pool-186-thread-1:87753 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a24610e
2020-11-19 10:19:39  [ pool-186-thread-1:87754 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:39  [ EventFetcher for fetching Map Completion Events:87754 ] - [ INFO ]  attempt_local956872601_0061_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:39  [ localfetcher#61:87755 ] - [ INFO ]  localfetcher#61 about to shuffle output of map attempt_local956872601_0061_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:39  [ localfetcher#61:87755 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local956872601_0061_m_000000_0
2020-11-19 10:19:39  [ localfetcher#61:87755 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:39  [ EventFetcher for fetching Map Completion Events:87755 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:39  [ pool-186-thread-1:87755 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:39  [ pool-186-thread-1:87755 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:39  [ pool-186-thread-1:87756 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:39  [ pool-186-thread-1:87756 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:39  [ pool-186-thread-1:87757 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:39  [ pool-186-thread-1:87816 ] - [ INFO ]  Task:attempt_local956872601_0061_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:39  [ pool-186-thread-1:87822 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:39  [ pool-186-thread-1:87822 ] - [ INFO ]  Task attempt_local956872601_0061_r_000000_0 is allowed to commit now
2020-11-19 10:19:39  [ pool-186-thread-1:87840 ] - [ INFO ]  Saved output of task 'attempt_local956872601_0061_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local956872601_0061_r_000000
2020-11-19 10:19:39  [ pool-186-thread-1:87841 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:39  [ pool-186-thread-1:87841 ] - [ INFO ]  Task 'attempt_local956872601_0061_r_000000_0' done.
2020-11-19 10:19:39  [ pool-186-thread-1:87841 ] - [ INFO ]  Finishing task: attempt_local956872601_0061_r_000000_0
2020-11-19 10:19:39  [ Thread-1818:87841 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]  Job job_local956872601_0061 running in uber mode : false
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]  Job job_local956872601_0061 completed successfully
2020-11-19 10:19:40  [ main:88659 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=154024
		FILE: Number of bytes written=34868371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3925854
		HDFS: Number of bytes written=64600
		HDFS: Number of read operations=4073
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1322
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2614099968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:40  [ main:88927 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:40  [ main:88938 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:40  [ main:88943 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:40  [ main:88949 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:40  [ main:88989 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:41  [ main:89006 ] - [ INFO ]  Submitting tokens for job: job_local197268278_0062
2020-11-19 10:19:41  [ main:89038 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:41  [ main:89039 ] - [ INFO ]  Running job: job_local197268278_0062
2020-11-19 10:19:41  [ Thread-1848:89039 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:41  [ Thread-1848:89039 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:41  [ Thread-1848:89039 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:41  [ Thread-1848:89047 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]  Starting task: attempt_local197268278_0062_m_000000_0
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89047 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89048 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89058 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89128 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89130 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89131 ] - [ INFO ]  Task:attempt_local197268278_0062_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89138 ] - [ INFO ]  map
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89138 ] - [ INFO ]  Task 'attempt_local197268278_0062_m_000000_0' done.
2020-11-19 10:19:41  [ LocalJobRunner Map Task Executor #0:89138 ] - [ INFO ]  Finishing task: attempt_local197268278_0062_m_000000_0
2020-11-19 10:19:41  [ Thread-1848:89138 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:41  [ Thread-1848:89138 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:41  [ pool-189-thread-1:89138 ] - [ INFO ]  Starting task: attempt_local197268278_0062_r_000000_0
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26a6f0a5
2020-11-19 10:19:41  [ pool-189-thread-1:89139 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:41  [ EventFetcher for fetching Map Completion Events:89139 ] - [ INFO ]  attempt_local197268278_0062_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:41  [ localfetcher#62:89140 ] - [ INFO ]  localfetcher#62 about to shuffle output of map attempt_local197268278_0062_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:41  [ localfetcher#62:89140 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local197268278_0062_m_000000_0
2020-11-19 10:19:41  [ localfetcher#62:89140 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:41  [ EventFetcher for fetching Map Completion Events:89140 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:41  [ pool-189-thread-1:89141 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:41  [ pool-189-thread-1:89142 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:41  [ pool-189-thread-1:89201 ] - [ INFO ]  Task:attempt_local197268278_0062_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:41  [ pool-189-thread-1:89207 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:41  [ pool-189-thread-1:89207 ] - [ INFO ]  Task attempt_local197268278_0062_r_000000_0 is allowed to commit now
2020-11-19 10:19:41  [ pool-189-thread-1:89223 ] - [ INFO ]  Saved output of task 'attempt_local197268278_0062_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local197268278_0062_r_000000
2020-11-19 10:19:41  [ pool-189-thread-1:89224 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:41  [ pool-189-thread-1:89224 ] - [ INFO ]  Task 'attempt_local197268278_0062_r_000000_0' done.
2020-11-19 10:19:41  [ pool-189-thread-1:89224 ] - [ INFO ]  Finishing task: attempt_local197268278_0062_r_000000_0
2020-11-19 10:19:41  [ Thread-1848:89224 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:42  [ main:90040 ] - [ INFO ]  Job job_local197268278_0062 running in uber mode : false
2020-11-19 10:19:42  [ main:90040 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:42  [ main:90040 ] - [ INFO ]  Job job_local197268278_0062 completed successfully
2020-11-19 10:19:42  [ main:90041 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=155216
		FILE: Number of bytes written=35437246
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3990260
		HDFS: Number of bytes written=65680
		HDFS: Number of read operations=4141
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1344
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:42  [ main:90324 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:42  [ main:90335 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:42  [ main:90340 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:42  [ main:90346 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:42  [ main:90387 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:42  [ main:90404 ] - [ INFO ]  Submitting tokens for job: job_local670949491_0063
2020-11-19 10:19:42  [ main:90433 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:42  [ main:90433 ] - [ INFO ]  Running job: job_local670949491_0063
2020-11-19 10:19:42  [ Thread-1878:90433 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:42  [ Thread-1878:90433 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:42  [ Thread-1878:90433 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:42  [ Thread-1878:90442 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90442 ] - [ INFO ]  Starting task: attempt_local670949491_0063_m_000000_0
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90442 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90443 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90443 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90443 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90450 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90518 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90520 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90521 ] - [ INFO ]  Task:attempt_local670949491_0063_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90527 ] - [ INFO ]  map
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90527 ] - [ INFO ]  Task 'attempt_local670949491_0063_m_000000_0' done.
2020-11-19 10:19:42  [ LocalJobRunner Map Task Executor #0:90527 ] - [ INFO ]  Finishing task: attempt_local670949491_0063_m_000000_0
2020-11-19 10:19:42  [ Thread-1878:90527 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:42  [ Thread-1878:90527 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  Starting task: attempt_local670949491_0063_r_000000_0
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3fff53ed
2020-11-19 10:19:42  [ pool-192-thread-1:90528 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:42  [ EventFetcher for fetching Map Completion Events:90529 ] - [ INFO ]  attempt_local670949491_0063_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:42  [ localfetcher#63:90529 ] - [ INFO ]  localfetcher#63 about to shuffle output of map attempt_local670949491_0063_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:42  [ localfetcher#63:90529 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local670949491_0063_m_000000_0
2020-11-19 10:19:42  [ localfetcher#63:90529 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:42  [ EventFetcher for fetching Map Completion Events:90530 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:42  [ pool-192-thread-1:90530 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:42  [ pool-192-thread-1:90530 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:42  [ pool-192-thread-1:90531 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:42  [ pool-192-thread-1:90532 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:42  [ pool-192-thread-1:90532 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:42  [ pool-192-thread-1:90574 ] - [ INFO ]  Task:attempt_local670949491_0063_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:42  [ pool-192-thread-1:90580 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:42  [ pool-192-thread-1:90580 ] - [ INFO ]  Task attempt_local670949491_0063_r_000000_0 is allowed to commit now
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  Saved output of task 'attempt_local670949491_0063_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local670949491_0063_r_000000
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  Task 'attempt_local670949491_0063_r_000000_0' done.
2020-11-19 10:19:42  [ pool-192-thread-1:90598 ] - [ INFO ]  Finishing task: attempt_local670949491_0063_r_000000_0
2020-11-19 10:19:42  [ Thread-1878:90598 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:43  [ main:91434 ] - [ INFO ]  Job job_local670949491_0063 running in uber mode : false
2020-11-19 10:19:43  [ main:91435 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:43  [ main:91435 ] - [ INFO ]  Job job_local670949491_0063 completed successfully
2020-11-19 10:19:43  [ main:91435 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=156406
		FILE: Number of bytes written=36006120
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4054666
		HDFS: Number of bytes written=66760
		HDFS: Number of read operations=4209
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1366
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:43  [ main:91694 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:43  [ main:91706 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:43  [ main:91710 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:43  [ main:91716 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:43  [ main:91758 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:43  [ main:91775 ] - [ INFO ]  Submitting tokens for job: job_local1689872815_0064
2020-11-19 10:19:43  [ main:91806 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:43  [ main:91806 ] - [ INFO ]  Running job: job_local1689872815_0064
2020-11-19 10:19:43  [ Thread-1908:91806 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:43  [ Thread-1908:91807 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:43  [ Thread-1908:91807 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:43  [ Thread-1908:91814 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]  Starting task: attempt_local1689872815_0064_m_000000_0
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91814 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91815 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91823 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91883 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91885 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91885 ] - [ INFO ]  Task:attempt_local1689872815_0064_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91891 ] - [ INFO ]  map
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91891 ] - [ INFO ]  Task 'attempt_local1689872815_0064_m_000000_0' done.
2020-11-19 10:19:43  [ LocalJobRunner Map Task Executor #0:91891 ] - [ INFO ]  Finishing task: attempt_local1689872815_0064_m_000000_0
2020-11-19 10:19:43  [ Thread-1908:91891 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:43  [ Thread-1908:91891 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  Starting task: attempt_local1689872815_0064_r_000000_0
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:43  [ pool-195-thread-1:91892 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@557ecf69
2020-11-19 10:19:43  [ pool-195-thread-1:91893 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:43  [ EventFetcher for fetching Map Completion Events:91893 ] - [ INFO ]  attempt_local1689872815_0064_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:43  [ localfetcher#64:91894 ] - [ INFO ]  localfetcher#64 about to shuffle output of map attempt_local1689872815_0064_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:43  [ localfetcher#64:91894 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1689872815_0064_m_000000_0
2020-11-19 10:19:43  [ localfetcher#64:91894 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:43  [ EventFetcher for fetching Map Completion Events:91894 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:43  [ pool-195-thread-1:91894 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:43  [ pool-195-thread-1:91894 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:43  [ pool-195-thread-1:91895 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:43  [ pool-195-thread-1:91895 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:43  [ pool-195-thread-1:91896 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:43  [ pool-195-thread-1:91949 ] - [ INFO ]  Task:attempt_local1689872815_0064_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:43  [ pool-195-thread-1:91955 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:43  [ pool-195-thread-1:91955 ] - [ INFO ]  Task attempt_local1689872815_0064_r_000000_0 is allowed to commit now
2020-11-19 10:19:43  [ pool-195-thread-1:91971 ] - [ INFO ]  Saved output of task 'attempt_local1689872815_0064_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1689872815_0064_r_000000
2020-11-19 10:19:43  [ pool-195-thread-1:91973 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:43  [ pool-195-thread-1:91973 ] - [ INFO ]  Task 'attempt_local1689872815_0064_r_000000_0' done.
2020-11-19 10:19:43  [ pool-195-thread-1:91973 ] - [ INFO ]  Finishing task: attempt_local1689872815_0064_r_000000_0
2020-11-19 10:19:43  [ Thread-1908:91973 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:44  [ main:92807 ] - [ INFO ]  Job job_local1689872815_0064 running in uber mode : false
2020-11-19 10:19:44  [ main:92807 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:44  [ main:92807 ] - [ INFO ]  Job job_local1689872815_0064 completed successfully
2020-11-19 10:19:44  [ main:92808 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=157598
		FILE: Number of bytes written=36578045
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4119072
		HDFS: Number of bytes written=67840
		HDFS: Number of read operations=4277
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1388
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:45  [ main:93077 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:45  [ main:93092 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:45  [ main:93097 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:45  [ main:93103 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:45  [ main:93141 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:45  [ main:93158 ] - [ INFO ]  Submitting tokens for job: job_local673703084_0065
2020-11-19 10:19:45  [ main:93187 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:45  [ main:93187 ] - [ INFO ]  Running job: job_local673703084_0065
2020-11-19 10:19:45  [ Thread-1938:93187 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:45  [ Thread-1938:93187 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:45  [ Thread-1938:93187 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:45  [ Thread-1938:93194 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93194 ] - [ INFO ]  Starting task: attempt_local673703084_0065_m_000000_0
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93195 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93203 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93275 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93277 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93278 ] - [ INFO ]  Task:attempt_local673703084_0065_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93284 ] - [ INFO ]  map
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93284 ] - [ INFO ]  Task 'attempt_local673703084_0065_m_000000_0' done.
2020-11-19 10:19:45  [ LocalJobRunner Map Task Executor #0:93284 ] - [ INFO ]  Finishing task: attempt_local673703084_0065_m_000000_0
2020-11-19 10:19:45  [ Thread-1938:93284 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:45  [ Thread-1938:93285 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  Starting task: attempt_local673703084_0065_r_000000_0
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:45  [ pool-198-thread-1:93285 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a5749d5
2020-11-19 10:19:45  [ pool-198-thread-1:93286 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:45  [ EventFetcher for fetching Map Completion Events:93286 ] - [ INFO ]  attempt_local673703084_0065_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:45  [ localfetcher#65:93286 ] - [ INFO ]  localfetcher#65 about to shuffle output of map attempt_local673703084_0065_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:45  [ localfetcher#65:93287 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local673703084_0065_m_000000_0
2020-11-19 10:19:45  [ localfetcher#65:93287 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:45  [ EventFetcher for fetching Map Completion Events:93287 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:45  [ pool-198-thread-1:93287 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:45  [ pool-198-thread-1:93287 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:45  [ pool-198-thread-1:93288 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:45  [ pool-198-thread-1:93288 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:45  [ pool-198-thread-1:93289 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:45  [ pool-198-thread-1:93331 ] - [ INFO ]  Task:attempt_local673703084_0065_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:45  [ pool-198-thread-1:93336 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:45  [ pool-198-thread-1:93336 ] - [ INFO ]  Task attempt_local673703084_0065_r_000000_0 is allowed to commit now
2020-11-19 10:19:45  [ pool-198-thread-1:93351 ] - [ INFO ]  Saved output of task 'attempt_local673703084_0065_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local673703084_0065_r_000000
2020-11-19 10:19:45  [ pool-198-thread-1:93351 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:45  [ pool-198-thread-1:93352 ] - [ INFO ]  Task 'attempt_local673703084_0065_r_000000_0' done.
2020-11-19 10:19:45  [ pool-198-thread-1:93352 ] - [ INFO ]  Finishing task: attempt_local673703084_0065_r_000000_0
2020-11-19 10:19:45  [ Thread-1938:93352 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:46  [ main:94189 ] - [ INFO ]  Job job_local673703084_0065 running in uber mode : false
2020-11-19 10:19:46  [ main:94189 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:46  [ main:94190 ] - [ INFO ]  Job job_local673703084_0065 completed successfully
2020-11-19 10:19:46  [ main:94190 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=158790
		FILE: Number of bytes written=37146920
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4183478
		HDFS: Number of bytes written=68920
		HDFS: Number of read operations=4345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1410
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2541748224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:46  [ main:94462 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:46  [ main:94474 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:46  [ main:94479 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:46  [ main:94485 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:46  [ main:94524 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:46  [ main:94541 ] - [ INFO ]  Submitting tokens for job: job_local1171920739_0066
2020-11-19 10:19:46  [ main:94571 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:46  [ main:94571 ] - [ INFO ]  Running job: job_local1171920739_0066
2020-11-19 10:19:46  [ Thread-1968:94572 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:46  [ Thread-1968:94572 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:46  [ Thread-1968:94572 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:46  [ Thread-1968:94578 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  Starting task: attempt_local1171920739_0066_m_000000_0
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94579 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94589 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94648 ] - [ INFO ]  
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94649 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94650 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94651 ] - [ INFO ]  Task:attempt_local1171920739_0066_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94657 ] - [ INFO ]  map
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94657 ] - [ INFO ]  Task 'attempt_local1171920739_0066_m_000000_0' done.
2020-11-19 10:19:46  [ LocalJobRunner Map Task Executor #0:94657 ] - [ INFO ]  Finishing task: attempt_local1171920739_0066_m_000000_0
2020-11-19 10:19:46  [ Thread-1968:94658 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:46  [ Thread-1968:94658 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:46  [ pool-201-thread-1:94658 ] - [ INFO ]  Starting task: attempt_local1171920739_0066_r_000000_0
2020-11-19 10:19:46  [ pool-201-thread-1:94658 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72c1e677
2020-11-19 10:19:46  [ pool-201-thread-1:94659 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:46  [ EventFetcher for fetching Map Completion Events:94659 ] - [ INFO ]  attempt_local1171920739_0066_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:46  [ localfetcher#66:94660 ] - [ INFO ]  localfetcher#66 about to shuffle output of map attempt_local1171920739_0066_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:46  [ localfetcher#66:94660 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1171920739_0066_m_000000_0
2020-11-19 10:19:46  [ localfetcher#66:94660 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:46  [ EventFetcher for fetching Map Completion Events:94660 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:46  [ pool-201-thread-1:94660 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:46  [ pool-201-thread-1:94660 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:46  [ pool-201-thread-1:94661 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:46  [ pool-201-thread-1:94661 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:46  [ pool-201-thread-1:94662 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:46  [ pool-201-thread-1:94713 ] - [ INFO ]  Task:attempt_local1171920739_0066_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:46  [ pool-201-thread-1:94719 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:46  [ pool-201-thread-1:94719 ] - [ INFO ]  Task attempt_local1171920739_0066_r_000000_0 is allowed to commit now
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  Saved output of task 'attempt_local1171920739_0066_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1171920739_0066_r_000000
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  Task 'attempt_local1171920739_0066_r_000000_0' done.
2020-11-19 10:19:46  [ pool-201-thread-1:94735 ] - [ INFO ]  Finishing task: attempt_local1171920739_0066_r_000000_0
2020-11-19 10:19:46  [ Thread-1968:94735 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:47  [ main:95572 ] - [ INFO ]  Job job_local1171920739_0066 running in uber mode : false
2020-11-19 10:19:47  [ main:95573 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:47  [ main:95573 ] - [ INFO ]  Job job_local1171920739_0066 completed successfully
2020-11-19 10:19:47  [ main:95573 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=159980
		FILE: Number of bytes written=37718842
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4247884
		HDFS: Number of bytes written=70000
		HDFS: Number of read operations=4413
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1432
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:47  [ main:95841 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:47  [ main:95851 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:47  [ main:95856 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:47  [ main:95862 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:47  [ main:95902 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:47  [ main:95919 ] - [ INFO ]  Submitting tokens for job: job_local989508229_0067
2020-11-19 10:19:47  [ main:95949 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:47  [ main:95949 ] - [ INFO ]  Running job: job_local989508229_0067
2020-11-19 10:19:47  [ Thread-1998:95949 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:47  [ Thread-1998:95949 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:47  [ Thread-1998:95949 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:47  [ Thread-1998:95955 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]  Starting task: attempt_local989508229_0067_m_000000_0
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95955 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95956 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:47  [ LocalJobRunner Map Task Executor #0:95963 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96026 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96028 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96029 ] - [ INFO ]  Task:attempt_local989508229_0067_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96034 ] - [ INFO ]  map
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96034 ] - [ INFO ]  Task 'attempt_local989508229_0067_m_000000_0' done.
2020-11-19 10:19:48  [ LocalJobRunner Map Task Executor #0:96034 ] - [ INFO ]  Finishing task: attempt_local989508229_0067_m_000000_0
2020-11-19 10:19:48  [ Thread-1998:96034 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:48  [ Thread-1998:96034 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:48  [ pool-204-thread-1:96034 ] - [ INFO ]  Starting task: attempt_local989508229_0067_r_000000_0
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54cb3a59
2020-11-19 10:19:48  [ pool-204-thread-1:96035 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:48  [ EventFetcher for fetching Map Completion Events:96035 ] - [ INFO ]  attempt_local989508229_0067_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:48  [ localfetcher#67:96036 ] - [ INFO ]  localfetcher#67 about to shuffle output of map attempt_local989508229_0067_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:48  [ localfetcher#67:96036 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local989508229_0067_m_000000_0
2020-11-19 10:19:48  [ localfetcher#67:96036 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:48  [ EventFetcher for fetching Map Completion Events:96036 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:48  [ pool-204-thread-1:96036 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:48  [ pool-204-thread-1:96037 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:48  [ pool-204-thread-1:96037 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:48  [ pool-204-thread-1:96037 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:48  [ pool-204-thread-1:96038 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:48  [ pool-204-thread-1:96079 ] - [ INFO ]  Task:attempt_local989508229_0067_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:48  [ pool-204-thread-1:96084 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:48  [ pool-204-thread-1:96084 ] - [ INFO ]  Task attempt_local989508229_0067_r_000000_0 is allowed to commit now
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  Saved output of task 'attempt_local989508229_0067_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local989508229_0067_r_000000
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  Task 'attempt_local989508229_0067_r_000000_0' done.
2020-11-19 10:19:48  [ pool-204-thread-1:96100 ] - [ INFO ]  Finishing task: attempt_local989508229_0067_r_000000_0
2020-11-19 10:19:48  [ Thread-1998:96100 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]  Job job_local989508229_0067 running in uber mode : false
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]  Job job_local989508229_0067 completed successfully
2020-11-19 10:19:48  [ main:96953 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=161172
		FILE: Number of bytes written=38287719
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4312290
		HDFS: Number of bytes written=71080
		HDFS: Number of read operations=4481
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1454
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:49  [ main:97207 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:49  [ main:97220 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:49  [ main:97224 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:49  [ main:97230 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:49  [ main:97271 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:49  [ main:97289 ] - [ INFO ]  Submitting tokens for job: job_local852729690_0068
2020-11-19 10:19:49  [ main:97319 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:49  [ main:97319 ] - [ INFO ]  Running job: job_local852729690_0068
2020-11-19 10:19:49  [ Thread-2028:97319 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:49  [ Thread-2028:97319 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:49  [ Thread-2028:97320 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:49  [ Thread-2028:97326 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  Starting task: attempt_local852729690_0068_m_000000_0
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97327 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97334 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97335 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97399 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97400 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97401 ] - [ INFO ]  Task:attempt_local852729690_0068_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97407 ] - [ INFO ]  map
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97407 ] - [ INFO ]  Task 'attempt_local852729690_0068_m_000000_0' done.
2020-11-19 10:19:49  [ LocalJobRunner Map Task Executor #0:97407 ] - [ INFO ]  Finishing task: attempt_local852729690_0068_m_000000_0
2020-11-19 10:19:49  [ Thread-2028:97407 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:49  [ Thread-2028:97407 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:49  [ pool-207-thread-1:97407 ] - [ INFO ]  Starting task: attempt_local852729690_0068_r_000000_0
2020-11-19 10:19:49  [ pool-207-thread-1:97407 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27c822e5
2020-11-19 10:19:49  [ pool-207-thread-1:97408 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:49  [ EventFetcher for fetching Map Completion Events:97408 ] - [ INFO ]  attempt_local852729690_0068_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:49  [ localfetcher#68:97409 ] - [ INFO ]  localfetcher#68 about to shuffle output of map attempt_local852729690_0068_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:49  [ localfetcher#68:97409 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local852729690_0068_m_000000_0
2020-11-19 10:19:49  [ localfetcher#68:97409 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:49  [ EventFetcher for fetching Map Completion Events:97409 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:49  [ pool-207-thread-1:97409 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:49  [ pool-207-thread-1:97409 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:49  [ pool-207-thread-1:97410 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:49  [ pool-207-thread-1:97410 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:49  [ pool-207-thread-1:97411 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:49  [ pool-207-thread-1:97461 ] - [ INFO ]  Task:attempt_local852729690_0068_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:49  [ pool-207-thread-1:97468 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:49  [ pool-207-thread-1:97468 ] - [ INFO ]  Task attempt_local852729690_0068_r_000000_0 is allowed to commit now
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  Saved output of task 'attempt_local852729690_0068_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local852729690_0068_r_000000
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  Task 'attempt_local852729690_0068_r_000000_0' done.
2020-11-19 10:19:49  [ pool-207-thread-1:97485 ] - [ INFO ]  Finishing task: attempt_local852729690_0068_r_000000_0
2020-11-19 10:19:49  [ Thread-2028:97485 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:50  [ main:98323 ] - [ INFO ]  Job job_local852729690_0068 running in uber mode : false
2020-11-19 10:19:50  [ main:98323 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:50  [ main:98324 ] - [ INFO ]  Job job_local852729690_0068 completed successfully
2020-11-19 10:19:50  [ main:98324 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=162364
		FILE: Number of bytes written=38856594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4376696
		HDFS: Number of bytes written=72160
		HDFS: Number of read operations=4549
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1476
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:50  [ main:98632 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:50  [ main:98645 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:50  [ main:98649 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:50  [ main:98654 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:50  [ main:98695 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:50  [ main:98711 ] - [ INFO ]  Submitting tokens for job: job_local2065812434_0069
2020-11-19 10:19:50  [ main:98743 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:50  [ main:98743 ] - [ INFO ]  Running job: job_local2065812434_0069
2020-11-19 10:19:50  [ Thread-2058:98743 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:50  [ Thread-2058:98743 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:50  [ Thread-2058:98743 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:50  [ Thread-2058:98750 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  Starting task: attempt_local2065812434_0069_m_000000_0
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98750 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98758 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98833 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98835 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98836 ] - [ INFO ]  Task:attempt_local2065812434_0069_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98841 ] - [ INFO ]  map
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98841 ] - [ INFO ]  Task 'attempt_local2065812434_0069_m_000000_0' done.
2020-11-19 10:19:50  [ LocalJobRunner Map Task Executor #0:98841 ] - [ INFO ]  Finishing task: attempt_local2065812434_0069_m_000000_0
2020-11-19 10:19:50  [ Thread-2058:98841 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:50  [ Thread-2058:98842 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  Starting task: attempt_local2065812434_0069_r_000000_0
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55d84354
2020-11-19 10:19:50  [ pool-210-thread-1:98842 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:50  [ EventFetcher for fetching Map Completion Events:98843 ] - [ INFO ]  attempt_local2065812434_0069_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:50  [ localfetcher#69:98843 ] - [ INFO ]  localfetcher#69 about to shuffle output of map attempt_local2065812434_0069_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:50  [ localfetcher#69:98843 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2065812434_0069_m_000000_0
2020-11-19 10:19:50  [ localfetcher#69:98844 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:50  [ EventFetcher for fetching Map Completion Events:98844 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:50  [ pool-210-thread-1:98844 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:50  [ pool-210-thread-1:98844 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:50  [ pool-210-thread-1:98845 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:50  [ pool-210-thread-1:98845 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:50  [ pool-210-thread-1:98846 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:50  [ pool-210-thread-1:98888 ] - [ INFO ]  Task:attempt_local2065812434_0069_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:50  [ pool-210-thread-1:98893 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:50  [ pool-210-thread-1:98893 ] - [ INFO ]  Task attempt_local2065812434_0069_r_000000_0 is allowed to commit now
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  Saved output of task 'attempt_local2065812434_0069_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2065812434_0069_r_000000
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  Task 'attempt_local2065812434_0069_r_000000_0' done.
2020-11-19 10:19:50  [ pool-210-thread-1:98909 ] - [ INFO ]  Finishing task: attempt_local2065812434_0069_r_000000_0
2020-11-19 10:19:50  [ Thread-2058:98910 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]  Job job_local2065812434_0069 running in uber mode : false
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]  Job job_local2065812434_0069 completed successfully
2020-11-19 10:19:51  [ main:99744 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=163554
		FILE: Number of bytes written=39428516
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4441102
		HDFS: Number of bytes written=73240
		HDFS: Number of read operations=4617
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1498
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2471493632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:52  [ main:100056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:52  [ main:100069 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:52  [ main:100074 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:52  [ main:100079 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:52  [ main:100119 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:52  [ main:100136 ] - [ INFO ]  Submitting tokens for job: job_local526923166_0070
2020-11-19 10:19:52  [ main:100168 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:52  [ main:100168 ] - [ INFO ]  Running job: job_local526923166_0070
2020-11-19 10:19:52  [ Thread-2088:100168 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:52  [ Thread-2088:100168 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:52  [ Thread-2088:100168 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:52  [ Thread-2088:100175 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  Starting task: attempt_local526923166_0070_m_000000_0
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100176 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100186 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100249 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100251 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100252 ] - [ INFO ]  Task:attempt_local526923166_0070_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100257 ] - [ INFO ]  map
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100257 ] - [ INFO ]  Task 'attempt_local526923166_0070_m_000000_0' done.
2020-11-19 10:19:52  [ LocalJobRunner Map Task Executor #0:100257 ] - [ INFO ]  Finishing task: attempt_local526923166_0070_m_000000_0
2020-11-19 10:19:52  [ Thread-2088:100258 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:52  [ Thread-2088:100258 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  Starting task: attempt_local526923166_0070_r_000000_0
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:52  [ pool-213-thread-1:100258 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@408a8c1
2020-11-19 10:19:52  [ pool-213-thread-1:100259 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:52  [ EventFetcher for fetching Map Completion Events:100259 ] - [ INFO ]  attempt_local526923166_0070_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:52  [ localfetcher#70:100260 ] - [ INFO ]  localfetcher#70 about to shuffle output of map attempt_local526923166_0070_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:52  [ localfetcher#70:100260 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local526923166_0070_m_000000_0
2020-11-19 10:19:52  [ localfetcher#70:100260 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:52  [ EventFetcher for fetching Map Completion Events:100260 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:52  [ pool-213-thread-1:100260 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:52  [ pool-213-thread-1:100260 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:52  [ pool-213-thread-1:100261 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:52  [ pool-213-thread-1:100261 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:52  [ pool-213-thread-1:100261 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:52  [ pool-213-thread-1:100262 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:52  [ pool-213-thread-1:100321 ] - [ INFO ]  Task:attempt_local526923166_0070_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:52  [ pool-213-thread-1:100326 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:52  [ pool-213-thread-1:100327 ] - [ INFO ]  Task attempt_local526923166_0070_r_000000_0 is allowed to commit now
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  Saved output of task 'attempt_local526923166_0070_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local526923166_0070_r_000000
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  Task 'attempt_local526923166_0070_r_000000_0' done.
2020-11-19 10:19:52  [ pool-213-thread-1:100343 ] - [ INFO ]  Finishing task: attempt_local526923166_0070_r_000000_0
2020-11-19 10:19:52  [ Thread-2088:100343 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:53  [ main:101173 ] - [ INFO ]  Job job_local526923166_0070 running in uber mode : false
2020-11-19 10:19:53  [ main:101173 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:53  [ main:101174 ] - [ INFO ]  Job job_local526923166_0070 completed successfully
2020-11-19 10:19:53  [ main:101174 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=164746
		FILE: Number of bytes written=39997393
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4505508
		HDFS: Number of bytes written=74320
		HDFS: Number of read operations=4685
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1520
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:53  [ main:101665 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:53  [ main:101677 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:53  [ main:101682 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:53  [ main:101687 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:53  [ main:101727 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:53  [ main:101744 ] - [ INFO ]  Submitting tokens for job: job_local1715160703_0071
2020-11-19 10:19:53  [ main:101774 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:53  [ main:101774 ] - [ INFO ]  Running job: job_local1715160703_0071
2020-11-19 10:19:53  [ Thread-2118:101774 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:53  [ Thread-2118:101774 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:53  [ Thread-2118:101774 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:53  [ Thread-2118:101780 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  Starting task: attempt_local1715160703_0071_m_000000_0
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101781 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101788 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101976 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101978 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101979 ] - [ INFO ]  Task:attempt_local1715160703_0071_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101984 ] - [ INFO ]  map
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101985 ] - [ INFO ]  Task 'attempt_local1715160703_0071_m_000000_0' done.
2020-11-19 10:19:53  [ LocalJobRunner Map Task Executor #0:101985 ] - [ INFO ]  Finishing task: attempt_local1715160703_0071_m_000000_0
2020-11-19 10:19:53  [ Thread-2118:101985 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:53  [ Thread-2118:101985 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:53  [ pool-216-thread-1:101985 ] - [ INFO ]  Starting task: attempt_local1715160703_0071_r_000000_0
2020-11-19 10:19:53  [ pool-216-thread-1:101985 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d281c3a
2020-11-19 10:19:53  [ pool-216-thread-1:101986 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:53  [ EventFetcher for fetching Map Completion Events:101986 ] - [ INFO ]  attempt_local1715160703_0071_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:53  [ localfetcher#71:101987 ] - [ INFO ]  localfetcher#71 about to shuffle output of map attempt_local1715160703_0071_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:53  [ localfetcher#71:101987 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1715160703_0071_m_000000_0
2020-11-19 10:19:53  [ localfetcher#71:101987 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:53  [ EventFetcher for fetching Map Completion Events:101987 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:53  [ pool-216-thread-1:101987 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:53  [ pool-216-thread-1:101987 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:53  [ pool-216-thread-1:101988 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:53  [ pool-216-thread-1:101988 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:53  [ pool-216-thread-1:101989 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:54  [ pool-216-thread-1:102050 ] - [ INFO ]  Task:attempt_local1715160703_0071_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:54  [ pool-216-thread-1:102056 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:54  [ pool-216-thread-1:102056 ] - [ INFO ]  Task attempt_local1715160703_0071_r_000000_0 is allowed to commit now
2020-11-19 10:19:54  [ pool-216-thread-1:102072 ] - [ INFO ]  Saved output of task 'attempt_local1715160703_0071_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1715160703_0071_r_000000
2020-11-19 10:19:54  [ pool-216-thread-1:102072 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:54  [ pool-216-thread-1:102073 ] - [ INFO ]  Task 'attempt_local1715160703_0071_r_000000_0' done.
2020-11-19 10:19:54  [ pool-216-thread-1:102073 ] - [ INFO ]  Finishing task: attempt_local1715160703_0071_r_000000_0
2020-11-19 10:19:54  [ Thread-2118:102073 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]  Job job_local1715160703_0071 running in uber mode : false
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]  Job job_local1715160703_0071 completed successfully
2020-11-19 10:19:54  [ main:102776 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=165938
		FILE: Number of bytes written=40569316
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4569914
		HDFS: Number of bytes written=75400
		HDFS: Number of read operations=4753
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1542
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:55  [ main:103086 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:55  [ main:103097 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:55  [ main:103102 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:55  [ main:103109 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:55  [ main:103151 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:55  [ main:103168 ] - [ INFO ]  Submitting tokens for job: job_local1852177960_0072
2020-11-19 10:19:55  [ main:103198 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:55  [ main:103198 ] - [ INFO ]  Running job: job_local1852177960_0072
2020-11-19 10:19:55  [ Thread-2148:103198 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:55  [ Thread-2148:103198 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:55  [ Thread-2148:103198 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:55  [ Thread-2148:103205 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103205 ] - [ INFO ]  Starting task: attempt_local1852177960_0072_m_000000_0
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103205 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103206 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103206 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103206 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103213 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103277 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103279 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103280 ] - [ INFO ]  Task:attempt_local1852177960_0072_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103286 ] - [ INFO ]  map
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103286 ] - [ INFO ]  Task 'attempt_local1852177960_0072_m_000000_0' done.
2020-11-19 10:19:55  [ LocalJobRunner Map Task Executor #0:103286 ] - [ INFO ]  Finishing task: attempt_local1852177960_0072_m_000000_0
2020-11-19 10:19:55  [ Thread-2148:103286 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:55  [ Thread-2148:103287 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  Starting task: attempt_local1852177960_0072_r_000000_0
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b394c35
2020-11-19 10:19:55  [ pool-219-thread-1:103287 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:55  [ EventFetcher for fetching Map Completion Events:103288 ] - [ INFO ]  attempt_local1852177960_0072_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:55  [ localfetcher#72:103288 ] - [ INFO ]  localfetcher#72 about to shuffle output of map attempt_local1852177960_0072_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:55  [ localfetcher#72:103289 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1852177960_0072_m_000000_0
2020-11-19 10:19:55  [ localfetcher#72:103289 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:55  [ EventFetcher for fetching Map Completion Events:103289 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:55  [ pool-219-thread-1:103289 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:55  [ pool-219-thread-1:103289 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:55  [ pool-219-thread-1:103290 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:55  [ pool-219-thread-1:103291 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:55  [ pool-219-thread-1:103291 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:55  [ pool-219-thread-1:103357 ] - [ INFO ]  Task:attempt_local1852177960_0072_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:55  [ pool-219-thread-1:103365 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:55  [ pool-219-thread-1:103365 ] - [ INFO ]  Task attempt_local1852177960_0072_r_000000_0 is allowed to commit now
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  Saved output of task 'attempt_local1852177960_0072_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1852177960_0072_r_000000
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  Task 'attempt_local1852177960_0072_r_000000_0' done.
2020-11-19 10:19:55  [ pool-219-thread-1:103388 ] - [ INFO ]  Finishing task: attempt_local1852177960_0072_r_000000_0
2020-11-19 10:19:55  [ Thread-2148:103388 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:56  [ main:104199 ] - [ INFO ]  Job job_local1852177960_0072 running in uber mode : false
2020-11-19 10:19:56  [ main:104199 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:56  [ main:104199 ] - [ INFO ]  Job job_local1852177960_0072 completed successfully
2020-11-19 10:19:56  [ main:104200 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=167128
		FILE: Number of bytes written=41141238
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4634320
		HDFS: Number of bytes written=76480
		HDFS: Number of read operations=4821
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1564
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:56  [ main:104503 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:56  [ main:104515 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:56  [ main:104520 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:56  [ main:104526 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:56  [ main:104567 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:56  [ main:104585 ] - [ INFO ]  Submitting tokens for job: job_local960261656_0073
2020-11-19 10:19:56  [ main:104614 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:56  [ main:104614 ] - [ INFO ]  Running job: job_local960261656_0073
2020-11-19 10:19:56  [ Thread-2178:104614 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:56  [ Thread-2178:104614 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:56  [ Thread-2178:104614 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:56  [ Thread-2178:104621 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]  Starting task: attempt_local960261656_0073_m_000000_0
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104621 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104622 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104629 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104693 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104695 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104696 ] - [ INFO ]  Task:attempt_local960261656_0073_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104701 ] - [ INFO ]  map
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104701 ] - [ INFO ]  Task 'attempt_local960261656_0073_m_000000_0' done.
2020-11-19 10:19:56  [ LocalJobRunner Map Task Executor #0:104701 ] - [ INFO ]  Finishing task: attempt_local960261656_0073_m_000000_0
2020-11-19 10:19:56  [ Thread-2178:104701 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:56  [ Thread-2178:104702 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  Starting task: attempt_local960261656_0073_r_000000_0
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51d424e6
2020-11-19 10:19:56  [ pool-222-thread-1:104702 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:56  [ EventFetcher for fetching Map Completion Events:104703 ] - [ INFO ]  attempt_local960261656_0073_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:56  [ localfetcher#73:104703 ] - [ INFO ]  localfetcher#73 about to shuffle output of map attempt_local960261656_0073_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:19:56  [ localfetcher#73:104703 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local960261656_0073_m_000000_0
2020-11-19 10:19:56  [ localfetcher#73:104703 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:19:56  [ EventFetcher for fetching Map Completion Events:104704 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:56  [ pool-222-thread-1:104704 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:56  [ pool-222-thread-1:104704 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:19:56  [ pool-222-thread-1:104705 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:56  [ pool-222-thread-1:104758 ] - [ INFO ]  Task:attempt_local960261656_0073_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:56  [ pool-222-thread-1:104763 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:56  [ pool-222-thread-1:104763 ] - [ INFO ]  Task attempt_local960261656_0073_r_000000_0 is allowed to commit now
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  Saved output of task 'attempt_local960261656_0073_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local960261656_0073_r_000000
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  Task 'attempt_local960261656_0073_r_000000_0' done.
2020-11-19 10:19:56  [ pool-222-thread-1:104782 ] - [ INFO ]  Finishing task: attempt_local960261656_0073_r_000000_0
2020-11-19 10:19:56  [ Thread-2178:104782 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]  Job job_local960261656_0073 running in uber mode : false
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]  Job job_local960261656_0073 completed successfully
2020-11-19 10:19:57  [ main:105618 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=168320
		FILE: Number of bytes written=41710115
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4698726
		HDFS: Number of bytes written=77560
		HDFS: Number of read operations=4889
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1586
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2405433344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:57  [ main:105895 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:57  [ main:105908 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:57  [ main:105913 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:57  [ main:105924 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:57  [ main:105971 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:57  [ main:105988 ] - [ INFO ]  Submitting tokens for job: job_local1674126219_0074
2020-11-19 10:19:58  [ main:106020 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:58  [ main:106020 ] - [ INFO ]  Running job: job_local1674126219_0074
2020-11-19 10:19:58  [ Thread-2208:106020 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:58  [ Thread-2208:106020 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:58  [ Thread-2208:106020 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:58  [ Thread-2208:106028 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]  Starting task: attempt_local1674126219_0074_m_000000_0
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106028 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106029 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106038 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106039 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106101 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106102 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106103 ] - [ INFO ]  Task:attempt_local1674126219_0074_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106108 ] - [ INFO ]  map
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106108 ] - [ INFO ]  Task 'attempt_local1674126219_0074_m_000000_0' done.
2020-11-19 10:19:58  [ LocalJobRunner Map Task Executor #0:106108 ] - [ INFO ]  Finishing task: attempt_local1674126219_0074_m_000000_0
2020-11-19 10:19:58  [ Thread-2208:106108 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:58  [ Thread-2208:106109 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:58  [ pool-225-thread-1:106109 ] - [ INFO ]  Starting task: attempt_local1674126219_0074_r_000000_0
2020-11-19 10:19:58  [ pool-225-thread-1:106109 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:58  [ pool-225-thread-1:106109 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:58  [ pool-225-thread-1:106110 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:58  [ pool-225-thread-1:106110 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@86cfb56
2020-11-19 10:19:58  [ pool-225-thread-1:106110 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:58  [ EventFetcher for fetching Map Completion Events:106110 ] - [ INFO ]  attempt_local1674126219_0074_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:58  [ localfetcher#74:106111 ] - [ INFO ]  localfetcher#74 about to shuffle output of map attempt_local1674126219_0074_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:58  [ localfetcher#74:106111 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1674126219_0074_m_000000_0
2020-11-19 10:19:58  [ localfetcher#74:106111 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:58  [ EventFetcher for fetching Map Completion Events:106111 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:58  [ pool-225-thread-1:106112 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:58  [ pool-225-thread-1:106112 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:58  [ pool-225-thread-1:106113 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:58  [ pool-225-thread-1:106114 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:58  [ pool-225-thread-1:106114 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:58  [ pool-225-thread-1:106168 ] - [ INFO ]  Task:attempt_local1674126219_0074_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:58  [ pool-225-thread-1:106173 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:58  [ pool-225-thread-1:106173 ] - [ INFO ]  Task attempt_local1674126219_0074_r_000000_0 is allowed to commit now
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  Saved output of task 'attempt_local1674126219_0074_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1674126219_0074_r_000000
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  Task 'attempt_local1674126219_0074_r_000000_0' done.
2020-11-19 10:19:58  [ pool-225-thread-1:106191 ] - [ INFO ]  Finishing task: attempt_local1674126219_0074_r_000000_0
2020-11-19 10:19:58  [ Thread-2208:106191 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:19:59  [ main:107022 ] - [ INFO ]  Job job_local1674126219_0074 running in uber mode : false
2020-11-19 10:19:59  [ main:107022 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:19:59  [ main:107022 ] - [ INFO ]  Job job_local1674126219_0074 completed successfully
2020-11-19 10:19:59  [ main:107023 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=169512
		FILE: Number of bytes written=42282038
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4763132
		HDFS: Number of bytes written=78640
		HDFS: Number of read operations=4957
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1608
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:19:59  [ main:107313 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:19:59  [ main:107323 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:19:59  [ main:107328 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:19:59  [ main:107334 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:19:59  [ main:107373 ] - [ INFO ]  number of splits:1
2020-11-19 10:19:59  [ main:107389 ] - [ INFO ]  Submitting tokens for job: job_local1557998078_0075
2020-11-19 10:19:59  [ main:107419 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:19:59  [ main:107419 ] - [ INFO ]  Running job: job_local1557998078_0075
2020-11-19 10:19:59  [ Thread-2238:107419 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:19:59  [ Thread-2238:107419 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:59  [ Thread-2238:107419 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:19:59  [ Thread-2238:107426 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107426 ] - [ INFO ]  Starting task: attempt_local1557998078_0075_m_000000_0
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107427 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107434 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  Spilling map output
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107503 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107504 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107505 ] - [ INFO ]  Finished spill 0
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107506 ] - [ INFO ]  Task:attempt_local1557998078_0075_m_000000_0 is done. And is in the process of committing
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107511 ] - [ INFO ]  map
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107511 ] - [ INFO ]  Task 'attempt_local1557998078_0075_m_000000_0' done.
2020-11-19 10:19:59  [ LocalJobRunner Map Task Executor #0:107511 ] - [ INFO ]  Finishing task: attempt_local1557998078_0075_m_000000_0
2020-11-19 10:19:59  [ Thread-2238:107511 ] - [ INFO ]  map task executor complete.
2020-11-19 10:19:59  [ Thread-2238:107512 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  Starting task: attempt_local1557998078_0075_r_000000_0
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30f51aa6
2020-11-19 10:19:59  [ pool-228-thread-1:107512 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:19:59  [ EventFetcher for fetching Map Completion Events:107513 ] - [ INFO ]  attempt_local1557998078_0075_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:19:59  [ localfetcher#75:107513 ] - [ INFO ]  localfetcher#75 about to shuffle output of map attempt_local1557998078_0075_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:19:59  [ localfetcher#75:107514 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1557998078_0075_m_000000_0
2020-11-19 10:19:59  [ localfetcher#75:107514 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:19:59  [ EventFetcher for fetching Map Completion Events:107514 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:19:59  [ pool-228-thread-1:107514 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:59  [ pool-228-thread-1:107514 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:19:59  [ pool-228-thread-1:107515 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:19:59  [ pool-228-thread-1:107516 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:59  [ pool-228-thread-1:107572 ] - [ INFO ]  Task:attempt_local1557998078_0075_r_000000_0 is done. And is in the process of committing
2020-11-19 10:19:59  [ pool-228-thread-1:107577 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:19:59  [ pool-228-thread-1:107577 ] - [ INFO ]  Task attempt_local1557998078_0075_r_000000_0 is allowed to commit now
2020-11-19 10:19:59  [ pool-228-thread-1:107595 ] - [ INFO ]  Saved output of task 'attempt_local1557998078_0075_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1557998078_0075_r_000000
2020-11-19 10:19:59  [ pool-228-thread-1:107595 ] - [ INFO ]  reduce > reduce
2020-11-19 10:19:59  [ pool-228-thread-1:107596 ] - [ INFO ]  Task 'attempt_local1557998078_0075_r_000000_0' done.
2020-11-19 10:19:59  [ pool-228-thread-1:107596 ] - [ INFO ]  Finishing task: attempt_local1557998078_0075_r_000000_0
2020-11-19 10:19:59  [ Thread-2238:107596 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:00  [ main:108422 ] - [ INFO ]  Job job_local1557998078_0075 running in uber mode : false
2020-11-19 10:20:00  [ main:108422 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:00  [ main:108422 ] - [ INFO ]  Job job_local1557998078_0075 completed successfully
2020-11-19 10:20:00  [ main:108423 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=170702
		FILE: Number of bytes written=42853960
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4827538
		HDFS: Number of bytes written=79720
		HDFS: Number of read operations=5025
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1630
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:00  [ main:108717 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:00  [ main:108729 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:00  [ main:108734 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:00  [ main:108740 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:00  [ main:108781 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:00  [ main:108798 ] - [ INFO ]  Submitting tokens for job: job_local1258752764_0076
2020-11-19 10:20:00  [ main:108828 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:00  [ main:108828 ] - [ INFO ]  Running job: job_local1258752764_0076
2020-11-19 10:20:00  [ Thread-2268:108828 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:00  [ Thread-2268:108828 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:00  [ Thread-2268:108828 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:00  [ Thread-2268:108835 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]  Starting task: attempt_local1258752764_0076_m_000000_0
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108835 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108836 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108843 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108911 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108913 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108914 ] - [ INFO ]  Task:attempt_local1258752764_0076_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108919 ] - [ INFO ]  map
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108919 ] - [ INFO ]  Task 'attempt_local1258752764_0076_m_000000_0' done.
2020-11-19 10:20:00  [ LocalJobRunner Map Task Executor #0:108919 ] - [ INFO ]  Finishing task: attempt_local1258752764_0076_m_000000_0
2020-11-19 10:20:00  [ Thread-2268:108919 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:00  [ Thread-2268:108919 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:00  [ pool-231-thread-1:108919 ] - [ INFO ]  Starting task: attempt_local1258752764_0076_r_000000_0
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2adf1ff1
2020-11-19 10:20:00  [ pool-231-thread-1:108920 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:00  [ EventFetcher for fetching Map Completion Events:108921 ] - [ INFO ]  attempt_local1258752764_0076_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:00  [ localfetcher#76:108921 ] - [ INFO ]  localfetcher#76 about to shuffle output of map attempt_local1258752764_0076_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:00  [ localfetcher#76:108921 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1258752764_0076_m_000000_0
2020-11-19 10:20:00  [ localfetcher#76:108921 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:00  [ EventFetcher for fetching Map Completion Events:108922 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:00  [ pool-231-thread-1:108922 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:00  [ pool-231-thread-1:108922 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:00  [ pool-231-thread-1:108922 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:00  [ pool-231-thread-1:108923 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:00  [ pool-231-thread-1:108976 ] - [ INFO ]  Task:attempt_local1258752764_0076_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:00  [ pool-231-thread-1:108981 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:00  [ pool-231-thread-1:108981 ] - [ INFO ]  Task attempt_local1258752764_0076_r_000000_0 is allowed to commit now
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  Saved output of task 'attempt_local1258752764_0076_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1258752764_0076_r_000000
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  Task 'attempt_local1258752764_0076_r_000000_0' done.
2020-11-19 10:20:00  [ pool-231-thread-1:108997 ] - [ INFO ]  Finishing task: attempt_local1258752764_0076_r_000000_0
2020-11-19 10:20:00  [ Thread-2268:108997 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:01  [ main:109829 ] - [ INFO ]  Job job_local1258752764_0076 running in uber mode : false
2020-11-19 10:20:01  [ main:109830 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:01  [ main:109830 ] - [ INFO ]  Job job_local1258752764_0076 completed successfully
2020-11-19 10:20:01  [ main:109830 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=171894
		FILE: Number of bytes written=43425885
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4891944
		HDFS: Number of bytes written=80800
		HDFS: Number of read operations=5093
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1652
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:02  [ main:110115 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:02  [ main:110126 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:02  [ main:110131 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:02  [ main:110136 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:02  [ main:110174 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:02  [ main:110190 ] - [ INFO ]  Submitting tokens for job: job_local1861038094_0077
2020-11-19 10:20:02  [ main:110219 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:02  [ main:110219 ] - [ INFO ]  Running job: job_local1861038094_0077
2020-11-19 10:20:02  [ Thread-2298:110219 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:02  [ Thread-2298:110219 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:02  [ Thread-2298:110219 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:02  [ Thread-2298:110226 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]  Starting task: attempt_local1861038094_0077_m_000000_0
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110226 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110227 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110234 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110298 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110299 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110300 ] - [ INFO ]  Task:attempt_local1861038094_0077_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110306 ] - [ INFO ]  map
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110306 ] - [ INFO ]  Task 'attempt_local1861038094_0077_m_000000_0' done.
2020-11-19 10:20:02  [ LocalJobRunner Map Task Executor #0:110306 ] - [ INFO ]  Finishing task: attempt_local1861038094_0077_m_000000_0
2020-11-19 10:20:02  [ Thread-2298:110306 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:02  [ Thread-2298:110307 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  Starting task: attempt_local1861038094_0077_r_000000_0
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:02  [ pool-234-thread-1:110307 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f81baba
2020-11-19 10:20:02  [ pool-234-thread-1:110308 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:02  [ EventFetcher for fetching Map Completion Events:110308 ] - [ INFO ]  attempt_local1861038094_0077_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:02  [ localfetcher#77:110308 ] - [ INFO ]  localfetcher#77 about to shuffle output of map attempt_local1861038094_0077_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:02  [ localfetcher#77:110309 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1861038094_0077_m_000000_0
2020-11-19 10:20:02  [ localfetcher#77:110309 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:02  [ EventFetcher for fetching Map Completion Events:110309 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:02  [ pool-234-thread-1:110309 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:02  [ pool-234-thread-1:110309 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:02  [ pool-234-thread-1:110310 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:02  [ pool-234-thread-1:110355 ] - [ INFO ]  Task:attempt_local1861038094_0077_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:02  [ pool-234-thread-1:110360 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:02  [ pool-234-thread-1:110360 ] - [ INFO ]  Task attempt_local1861038094_0077_r_000000_0 is allowed to commit now
2020-11-19 10:20:02  [ pool-234-thread-1:110376 ] - [ INFO ]  Saved output of task 'attempt_local1861038094_0077_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1861038094_0077_r_000000
2020-11-19 10:20:02  [ pool-234-thread-1:110377 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:02  [ pool-234-thread-1:110377 ] - [ INFO ]  Task 'attempt_local1861038094_0077_r_000000_0' done.
2020-11-19 10:20:02  [ pool-234-thread-1:110377 ] - [ INFO ]  Finishing task: attempt_local1861038094_0077_r_000000_0
2020-11-19 10:20:02  [ Thread-2298:110377 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]  Job job_local1861038094_0077 running in uber mode : false
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]  Job job_local1861038094_0077 completed successfully
2020-11-19 10:20:03  [ main:111222 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=173086
		FILE: Number of bytes written=43997808
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4956350
		HDFS: Number of bytes written=81880
		HDFS: Number of read operations=5161
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1674
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2342518784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:03  [ main:111474 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:03  [ main:111485 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:03  [ main:111490 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:03  [ main:111495 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:03  [ main:111538 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:03  [ main:111557 ] - [ INFO ]  Submitting tokens for job: job_local732622909_0078
2020-11-19 10:20:03  [ main:111589 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:03  [ main:111589 ] - [ INFO ]  Running job: job_local732622909_0078
2020-11-19 10:20:03  [ Thread-2328:111589 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:03  [ Thread-2328:111589 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:03  [ Thread-2328:111589 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:03  [ Thread-2328:111596 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]  Starting task: attempt_local732622909_0078_m_000000_0
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111596 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111597 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111604 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111665 ] - [ INFO ]  
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111666 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111667 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111668 ] - [ INFO ]  Task:attempt_local732622909_0078_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111675 ] - [ INFO ]  map
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111675 ] - [ INFO ]  Task 'attempt_local732622909_0078_m_000000_0' done.
2020-11-19 10:20:03  [ LocalJobRunner Map Task Executor #0:111675 ] - [ INFO ]  Finishing task: attempt_local732622909_0078_m_000000_0
2020-11-19 10:20:03  [ Thread-2328:111675 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:03  [ Thread-2328:111675 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:03  [ pool-237-thread-1:111675 ] - [ INFO ]  Starting task: attempt_local732622909_0078_r_000000_0
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2debd373
2020-11-19 10:20:03  [ pool-237-thread-1:111676 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:03  [ EventFetcher for fetching Map Completion Events:111676 ] - [ INFO ]  attempt_local732622909_0078_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:03  [ localfetcher#78:111677 ] - [ INFO ]  localfetcher#78 about to shuffle output of map attempt_local732622909_0078_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:03  [ localfetcher#78:111677 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local732622909_0078_m_000000_0
2020-11-19 10:20:03  [ localfetcher#78:111677 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:03  [ EventFetcher for fetching Map Completion Events:111678 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:03  [ pool-237-thread-1:111678 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:03  [ pool-237-thread-1:111679 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:03  [ pool-237-thread-1:111732 ] - [ INFO ]  Task:attempt_local732622909_0078_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:03  [ pool-237-thread-1:111739 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:03  [ pool-237-thread-1:111739 ] - [ INFO ]  Task attempt_local732622909_0078_r_000000_0 is allowed to commit now
2020-11-19 10:20:03  [ pool-237-thread-1:111754 ] - [ INFO ]  Saved output of task 'attempt_local732622909_0078_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local732622909_0078_r_000000
2020-11-19 10:20:03  [ pool-237-thread-1:111755 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:03  [ pool-237-thread-1:111755 ] - [ INFO ]  Task 'attempt_local732622909_0078_r_000000_0' done.
2020-11-19 10:20:03  [ pool-237-thread-1:111755 ] - [ INFO ]  Finishing task: attempt_local732622909_0078_r_000000_0
2020-11-19 10:20:03  [ Thread-2328:111755 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]  Job job_local732622909_0078 running in uber mode : false
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]  Job job_local732622909_0078 completed successfully
2020-11-19 10:20:04  [ main:112593 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=174276
		FILE: Number of bytes written=44566682
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5020756
		HDFS: Number of bytes written=82960
		HDFS: Number of read operations=5229
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1696
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2282749952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:04  [ main:112846 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:04  [ main:112856 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:04  [ main:112861 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:04  [ main:112866 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:04  [ main:112909 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:04  [ main:112927 ] - [ INFO ]  Submitting tokens for job: job_local1131422728_0079
2020-11-19 10:20:04  [ main:112957 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:04  [ main:112957 ] - [ INFO ]  Running job: job_local1131422728_0079
2020-11-19 10:20:04  [ Thread-2358:112957 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:04  [ Thread-2358:112957 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:04  [ Thread-2358:112957 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:04  [ Thread-2358:112964 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]  Starting task: attempt_local1131422728_0079_m_000000_0
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112964 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112965 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:04  [ LocalJobRunner Map Task Executor #0:112972 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113033 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113035 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113035 ] - [ INFO ]  Task:attempt_local1131422728_0079_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113041 ] - [ INFO ]  map
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113042 ] - [ INFO ]  Task 'attempt_local1131422728_0079_m_000000_0' done.
2020-11-19 10:20:05  [ LocalJobRunner Map Task Executor #0:113042 ] - [ INFO ]  Finishing task: attempt_local1131422728_0079_m_000000_0
2020-11-19 10:20:05  [ Thread-2358:113042 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:05  [ Thread-2358:113042 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:05  [ pool-240-thread-1:113042 ] - [ INFO ]  Starting task: attempt_local1131422728_0079_r_000000_0
2020-11-19 10:20:05  [ pool-240-thread-1:113042 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19bc6416
2020-11-19 10:20:05  [ pool-240-thread-1:113043 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:05  [ EventFetcher for fetching Map Completion Events:113043 ] - [ INFO ]  attempt_local1131422728_0079_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:05  [ localfetcher#79:113044 ] - [ INFO ]  localfetcher#79 about to shuffle output of map attempt_local1131422728_0079_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:05  [ localfetcher#79:113044 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1131422728_0079_m_000000_0
2020-11-19 10:20:05  [ localfetcher#79:113044 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:05  [ EventFetcher for fetching Map Completion Events:113044 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:05  [ pool-240-thread-1:113044 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:05  [ pool-240-thread-1:113044 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:05  [ pool-240-thread-1:113045 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:05  [ pool-240-thread-1:113045 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:05  [ pool-240-thread-1:113045 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:05  [ pool-240-thread-1:113046 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:05  [ pool-240-thread-1:113098 ] - [ INFO ]  Task:attempt_local1131422728_0079_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:05  [ pool-240-thread-1:113103 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:05  [ pool-240-thread-1:113103 ] - [ INFO ]  Task attempt_local1131422728_0079_r_000000_0 is allowed to commit now
2020-11-19 10:20:05  [ pool-240-thread-1:113120 ] - [ INFO ]  Saved output of task 'attempt_local1131422728_0079_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1131422728_0079_r_000000
2020-11-19 10:20:05  [ pool-240-thread-1:113121 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:05  [ pool-240-thread-1:113121 ] - [ INFO ]  Task 'attempt_local1131422728_0079_r_000000_0' done.
2020-11-19 10:20:05  [ pool-240-thread-1:113121 ] - [ INFO ]  Finishing task: attempt_local1131422728_0079_r_000000_0
2020-11-19 10:20:05  [ Thread-2358:113121 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:05  [ main:113962 ] - [ INFO ]  Job job_local1131422728_0079 running in uber mode : false
2020-11-19 10:20:05  [ main:113962 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:05  [ main:113962 ] - [ INFO ]  Job job_local1131422728_0079 completed successfully
2020-11-19 10:20:05  [ main:113963 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=175468
		FILE: Number of bytes written=45138607
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5085162
		HDFS: Number of bytes written=84040
		HDFS: Number of read operations=5297
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1718
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2282749952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:06  [ main:114215 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:06  [ main:114226 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:06  [ main:114230 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:06  [ main:114235 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:06  [ main:114272 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:06  [ main:114290 ] - [ INFO ]  Submitting tokens for job: job_local473498102_0080
2020-11-19 10:20:06  [ main:114319 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:06  [ main:114319 ] - [ INFO ]  Running job: job_local473498102_0080
2020-11-19 10:20:06  [ Thread-2388:114319 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:06  [ Thread-2388:114319 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:06  [ Thread-2388:114319 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:06  [ Thread-2388:114327 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]  Starting task: attempt_local473498102_0080_m_000000_0
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114327 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114328 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114334 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114334 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114335 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114398 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114400 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114401 ] - [ INFO ]  Task:attempt_local473498102_0080_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114408 ] - [ INFO ]  map
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114408 ] - [ INFO ]  Task 'attempt_local473498102_0080_m_000000_0' done.
2020-11-19 10:20:06  [ LocalJobRunner Map Task Executor #0:114408 ] - [ INFO ]  Finishing task: attempt_local473498102_0080_m_000000_0
2020-11-19 10:20:06  [ Thread-2388:114408 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:06  [ Thread-2388:114408 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:06  [ pool-243-thread-1:114408 ] - [ INFO ]  Starting task: attempt_local473498102_0080_r_000000_0
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53f64c0b
2020-11-19 10:20:06  [ pool-243-thread-1:114409 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:06  [ EventFetcher for fetching Map Completion Events:114409 ] - [ INFO ]  attempt_local473498102_0080_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:06  [ localfetcher#80:114410 ] - [ INFO ]  localfetcher#80 about to shuffle output of map attempt_local473498102_0080_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:06  [ localfetcher#80:114410 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local473498102_0080_m_000000_0
2020-11-19 10:20:06  [ localfetcher#80:114410 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:06  [ EventFetcher for fetching Map Completion Events:114411 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:06  [ pool-243-thread-1:114411 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:06  [ pool-243-thread-1:114411 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:06  [ pool-243-thread-1:114412 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:06  [ pool-243-thread-1:114471 ] - [ INFO ]  Task:attempt_local473498102_0080_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:06  [ pool-243-thread-1:114476 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:06  [ pool-243-thread-1:114476 ] - [ INFO ]  Task attempt_local473498102_0080_r_000000_0 is allowed to commit now
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  Saved output of task 'attempt_local473498102_0080_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local473498102_0080_r_000000
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  Task 'attempt_local473498102_0080_r_000000_0' done.
2020-11-19 10:20:06  [ pool-243-thread-1:114497 ] - [ INFO ]  Finishing task: attempt_local473498102_0080_r_000000_0
2020-11-19 10:20:06  [ Thread-2388:114497 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:07  [ main:115322 ] - [ INFO ]  Job job_local473498102_0080 running in uber mode : false
2020-11-19 10:20:07  [ main:115322 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:07  [ main:115322 ] - [ INFO ]  Job job_local473498102_0080 completed successfully
2020-11-19 10:20:07  [ main:115323 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=176660
		FILE: Number of bytes written=45707482
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5149568
		HDFS: Number of bytes written=85120
		HDFS: Number of read operations=5365
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1740
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2282749952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:07  [ main:115596 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:07  [ main:115607 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:07  [ main:115612 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:07  [ main:115617 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:07  [ main:115659 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:07  [ main:115676 ] - [ INFO ]  Submitting tokens for job: job_local1925231719_0081
2020-11-19 10:20:07  [ main:115708 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:07  [ main:115708 ] - [ INFO ]  Running job: job_local1925231719_0081
2020-11-19 10:20:07  [ Thread-2418:115708 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:07  [ Thread-2418:115708 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:07  [ Thread-2418:115708 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:07  [ Thread-2418:115716 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  Starting task: attempt_local1925231719_0081_m_000000_0
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115716 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115724 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115799 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115801 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115802 ] - [ INFO ]  Task:attempt_local1925231719_0081_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115807 ] - [ INFO ]  map
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115807 ] - [ INFO ]  Task 'attempt_local1925231719_0081_m_000000_0' done.
2020-11-19 10:20:07  [ LocalJobRunner Map Task Executor #0:115807 ] - [ INFO ]  Finishing task: attempt_local1925231719_0081_m_000000_0
2020-11-19 10:20:07  [ Thread-2418:115807 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:07  [ Thread-2418:115808 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  Starting task: attempt_local1925231719_0081_r_000000_0
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:07  [ pool-246-thread-1:115808 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9162568
2020-11-19 10:20:07  [ pool-246-thread-1:115809 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:07  [ EventFetcher for fetching Map Completion Events:115809 ] - [ INFO ]  attempt_local1925231719_0081_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:07  [ localfetcher#81:115812 ] - [ INFO ]  localfetcher#81 about to shuffle output of map attempt_local1925231719_0081_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:07  [ localfetcher#81:115812 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1925231719_0081_m_000000_0
2020-11-19 10:20:07  [ localfetcher#81:115812 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:07  [ EventFetcher for fetching Map Completion Events:115813 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:07  [ pool-246-thread-1:115813 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:07  [ pool-246-thread-1:115813 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:07  [ pool-246-thread-1:115814 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:07  [ pool-246-thread-1:115815 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:07  [ pool-246-thread-1:115815 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:07  [ pool-246-thread-1:115872 ] - [ INFO ]  Task:attempt_local1925231719_0081_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:07  [ pool-246-thread-1:115881 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:07  [ pool-246-thread-1:115881 ] - [ INFO ]  Task attempt_local1925231719_0081_r_000000_0 is allowed to commit now
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  Saved output of task 'attempt_local1925231719_0081_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1925231719_0081_r_000000
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  Task 'attempt_local1925231719_0081_r_000000_0' done.
2020-11-19 10:20:07  [ pool-246-thread-1:115898 ] - [ INFO ]  Finishing task: attempt_local1925231719_0081_r_000000_0
2020-11-19 10:20:07  [ Thread-2418:115898 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]  Job job_local1925231719_0081 running in uber mode : false
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]  Job job_local1925231719_0081 completed successfully
2020-11-19 10:20:08  [ main:116710 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=177850
		FILE: Number of bytes written=46279404
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5213974
		HDFS: Number of bytes written=86200
		HDFS: Number of read operations=5433
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1762
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=2254438400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:08  [ main:116989 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:09  [ main:117000 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:09  [ main:117005 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:09  [ main:117011 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:09  [ main:117055 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:09  [ main:117072 ] - [ INFO ]  Submitting tokens for job: job_local2000796854_0082
2020-11-19 10:20:09  [ main:117104 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:09  [ main:117104 ] - [ INFO ]  Running job: job_local2000796854_0082
2020-11-19 10:20:09  [ Thread-2448:117104 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:09  [ Thread-2448:117104 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:09  [ Thread-2448:117105 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:09  [ Thread-2448:117113 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]  Starting task: attempt_local2000796854_0082_m_000000_0
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117113 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117114 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117195 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117197 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117198 ] - [ INFO ]  Task:attempt_local2000796854_0082_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117204 ] - [ INFO ]  map
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117204 ] - [ INFO ]  Task 'attempt_local2000796854_0082_m_000000_0' done.
2020-11-19 10:20:09  [ LocalJobRunner Map Task Executor #0:117204 ] - [ INFO ]  Finishing task: attempt_local2000796854_0082_m_000000_0
2020-11-19 10:20:09  [ Thread-2448:117204 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:09  [ Thread-2448:117204 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:09  [ pool-249-thread-1:117204 ] - [ INFO ]  Starting task: attempt_local2000796854_0082_r_000000_0
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4af6b400
2020-11-19 10:20:09  [ pool-249-thread-1:117205 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:09  [ EventFetcher for fetching Map Completion Events:117205 ] - [ INFO ]  attempt_local2000796854_0082_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:09  [ localfetcher#82:117206 ] - [ INFO ]  localfetcher#82 about to shuffle output of map attempt_local2000796854_0082_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:09  [ localfetcher#82:117206 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local2000796854_0082_m_000000_0
2020-11-19 10:20:09  [ localfetcher#82:117206 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:09  [ EventFetcher for fetching Map Completion Events:117207 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:09  [ pool-249-thread-1:117207 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:09  [ pool-249-thread-1:117208 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:09  [ pool-249-thread-1:117254 ] - [ INFO ]  Task:attempt_local2000796854_0082_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:09  [ pool-249-thread-1:117259 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:09  [ pool-249-thread-1:117259 ] - [ INFO ]  Task attempt_local2000796854_0082_r_000000_0 is allowed to commit now
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  Saved output of task 'attempt_local2000796854_0082_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2000796854_0082_r_000000
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  Task 'attempt_local2000796854_0082_r_000000_0' done.
2020-11-19 10:20:09  [ pool-249-thread-1:117279 ] - [ INFO ]  Finishing task: attempt_local2000796854_0082_r_000000_0
2020-11-19 10:20:09  [ Thread-2448:117279 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:10  [ main:118105 ] - [ INFO ]  Job job_local2000796854_0082 running in uber mode : false
2020-11-19 10:20:10  [ main:118106 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:10  [ main:118106 ] - [ INFO ]  Job job_local2000796854_0082 completed successfully
2020-11-19 10:20:10  [ main:118106 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=179042
		FILE: Number of bytes written=46851329
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5278380
		HDFS: Number of bytes written=87280
		HDFS: Number of read operations=5501
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1784
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2226126848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:10  [ main:118406 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:10  [ main:118417 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:10  [ main:118422 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:10  [ main:118428 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:10  [ main:118468 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:10  [ main:118486 ] - [ INFO ]  Submitting tokens for job: job_local1478786048_0083
2020-11-19 10:20:10  [ main:118515 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:10  [ main:118515 ] - [ INFO ]  Running job: job_local1478786048_0083
2020-11-19 10:20:10  [ Thread-2478:118515 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:10  [ Thread-2478:118515 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:10  [ Thread-2478:118515 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:10  [ Thread-2478:118524 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  Starting task: attempt_local1478786048_0083_m_000000_0
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118524 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118531 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118531 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118532 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118588 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118590 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118591 ] - [ INFO ]  Task:attempt_local1478786048_0083_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118597 ] - [ INFO ]  map
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118597 ] - [ INFO ]  Task 'attempt_local1478786048_0083_m_000000_0' done.
2020-11-19 10:20:10  [ LocalJobRunner Map Task Executor #0:118597 ] - [ INFO ]  Finishing task: attempt_local1478786048_0083_m_000000_0
2020-11-19 10:20:10  [ Thread-2478:118597 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:10  [ Thread-2478:118598 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  Starting task: attempt_local1478786048_0083_r_000000_0
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:10  [ pool-252-thread-1:118598 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7cb282e8
2020-11-19 10:20:10  [ pool-252-thread-1:118599 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:10  [ EventFetcher for fetching Map Completion Events:118599 ] - [ INFO ]  attempt_local1478786048_0083_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:10  [ localfetcher#83:118599 ] - [ INFO ]  localfetcher#83 about to shuffle output of map attempt_local1478786048_0083_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:10  [ localfetcher#83:118600 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1478786048_0083_m_000000_0
2020-11-19 10:20:10  [ localfetcher#83:118600 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:10  [ EventFetcher for fetching Map Completion Events:118600 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:10  [ pool-252-thread-1:118600 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:10  [ pool-252-thread-1:118600 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:10  [ pool-252-thread-1:118601 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:10  [ pool-252-thread-1:118654 ] - [ INFO ]  Task:attempt_local1478786048_0083_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:10  [ pool-252-thread-1:118661 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:10  [ pool-252-thread-1:118661 ] - [ INFO ]  Task attempt_local1478786048_0083_r_000000_0 is allowed to commit now
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  Saved output of task 'attempt_local1478786048_0083_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1478786048_0083_r_000000
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  Task 'attempt_local1478786048_0083_r_000000_0' done.
2020-11-19 10:20:10  [ pool-252-thread-1:118677 ] - [ INFO ]  Finishing task: attempt_local1478786048_0083_r_000000_0
2020-11-19 10:20:10  [ Thread-2478:118677 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]  Job job_local1478786048_0083 running in uber mode : false
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]  Job job_local1478786048_0083 completed successfully
2020-11-19 10:20:11  [ main:119518 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=180234
		FILE: Number of bytes written=47423252
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5342786
		HDFS: Number of bytes written=88360
		HDFS: Number of read operations=5569
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1806
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2226126848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:11  [ main:119841 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:12  [ main:120292 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:12  [ main:120297 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:12  [ main:120303 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:12  [ main:120344 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:12  [ main:120361 ] - [ INFO ]  Submitting tokens for job: job_local2003526011_0084
2020-11-19 10:20:12  [ main:120391 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:12  [ main:120391 ] - [ INFO ]  Running job: job_local2003526011_0084
2020-11-19 10:20:12  [ Thread-2508:120391 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:12  [ Thread-2508:120392 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:12  [ Thread-2508:120392 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:12  [ Thread-2508:120399 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  Starting task: attempt_local2003526011_0084_m_000000_0
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120400 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120408 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120475 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120477 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120478 ] - [ INFO ]  Task:attempt_local2003526011_0084_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120484 ] - [ INFO ]  map
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120484 ] - [ INFO ]  Task 'attempt_local2003526011_0084_m_000000_0' done.
2020-11-19 10:20:12  [ LocalJobRunner Map Task Executor #0:120484 ] - [ INFO ]  Finishing task: attempt_local2003526011_0084_m_000000_0
2020-11-19 10:20:12  [ Thread-2508:120484 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:12  [ Thread-2508:120484 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:12  [ pool-255-thread-1:120484 ] - [ INFO ]  Starting task: attempt_local2003526011_0084_r_000000_0
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33fb7763
2020-11-19 10:20:12  [ pool-255-thread-1:120485 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:12  [ EventFetcher for fetching Map Completion Events:120485 ] - [ INFO ]  attempt_local2003526011_0084_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:12  [ localfetcher#84:120486 ] - [ INFO ]  localfetcher#84 about to shuffle output of map attempt_local2003526011_0084_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:12  [ localfetcher#84:120486 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local2003526011_0084_m_000000_0
2020-11-19 10:20:12  [ localfetcher#84:120486 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:12  [ EventFetcher for fetching Map Completion Events:120486 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:12  [ pool-255-thread-1:120487 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:12  [ pool-255-thread-1:120488 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:12  [ pool-255-thread-1:120545 ] - [ INFO ]  Task:attempt_local2003526011_0084_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:12  [ pool-255-thread-1:120550 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:12  [ pool-255-thread-1:120550 ] - [ INFO ]  Task attempt_local2003526011_0084_r_000000_0 is allowed to commit now
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  Saved output of task 'attempt_local2003526011_0084_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local2003526011_0084_r_000000
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  Task 'attempt_local2003526011_0084_r_000000_0' done.
2020-11-19 10:20:12  [ pool-255-thread-1:120567 ] - [ INFO ]  Finishing task: attempt_local2003526011_0084_r_000000_0
2020-11-19 10:20:12  [ Thread-2508:120567 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]  Job job_local2003526011_0084 running in uber mode : false
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]  Job job_local2003526011_0084 completed successfully
2020-11-19 10:20:13  [ main:121393 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=181424
		FILE: Number of bytes written=47995174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5407192
		HDFS: Number of bytes written=89440
		HDFS: Number of read operations=5637
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1828
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2226126848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:13  [ main:121686 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:13  [ main:121696 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:13  [ main:121700 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:13  [ main:121705 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:13  [ main:121741 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:13  [ main:121757 ] - [ INFO ]  Submitting tokens for job: job_local1852874694_0085
2020-11-19 10:20:13  [ main:121785 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:13  [ main:121786 ] - [ INFO ]  Running job: job_local1852874694_0085
2020-11-19 10:20:13  [ Thread-2538:121786 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:13  [ Thread-2538:121786 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:13  [ Thread-2538:121786 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:13  [ Thread-2538:121794 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121794 ] - [ INFO ]  Starting task: attempt_local1852874694_0085_m_000000_0
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121795 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121804 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121872 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121874 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121875 ] - [ INFO ]  Task:attempt_local1852874694_0085_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121880 ] - [ INFO ]  map
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121880 ] - [ INFO ]  Task 'attempt_local1852874694_0085_m_000000_0' done.
2020-11-19 10:20:13  [ LocalJobRunner Map Task Executor #0:121880 ] - [ INFO ]  Finishing task: attempt_local1852874694_0085_m_000000_0
2020-11-19 10:20:13  [ Thread-2538:121881 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:13  [ Thread-2538:121881 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  Starting task: attempt_local1852874694_0085_r_000000_0
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:13  [ pool-258-thread-1:121881 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3dbdf482
2020-11-19 10:20:13  [ pool-258-thread-1:121882 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:13  [ EventFetcher for fetching Map Completion Events:121882 ] - [ INFO ]  attempt_local1852874694_0085_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:13  [ localfetcher#85:121883 ] - [ INFO ]  localfetcher#85 about to shuffle output of map attempt_local1852874694_0085_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:13  [ localfetcher#85:121883 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1852874694_0085_m_000000_0
2020-11-19 10:20:13  [ localfetcher#85:121883 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:13  [ EventFetcher for fetching Map Completion Events:121883 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:13  [ pool-258-thread-1:121883 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:13  [ pool-258-thread-1:121883 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:13  [ pool-258-thread-1:121884 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:13  [ pool-258-thread-1:121884 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:13  [ pool-258-thread-1:121885 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:13  [ pool-258-thread-1:121943 ] - [ INFO ]  Task:attempt_local1852874694_0085_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:13  [ pool-258-thread-1:121949 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:13  [ pool-258-thread-1:121949 ] - [ INFO ]  Task attempt_local1852874694_0085_r_000000_0 is allowed to commit now
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  Saved output of task 'attempt_local1852874694_0085_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1852874694_0085_r_000000
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  Task 'attempt_local1852874694_0085_r_000000_0' done.
2020-11-19 10:20:13  [ pool-258-thread-1:121966 ] - [ INFO ]  Finishing task: attempt_local1852874694_0085_r_000000_0
2020-11-19 10:20:13  [ Thread-2538:121966 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:14  [ main:122788 ] - [ INFO ]  Job job_local1852874694_0085 running in uber mode : false
2020-11-19 10:20:14  [ main:122788 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:14  [ main:122788 ] - [ INFO ]  Job job_local1852874694_0085 completed successfully
2020-11-19 10:20:14  [ main:122789 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=182616
		FILE: Number of bytes written=48567099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5471598
		HDFS: Number of bytes written=90520
		HDFS: Number of read operations=5705
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1850
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=2171600896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:15  [ main:123052 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:15  [ main:123062 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:15  [ main:123067 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:15  [ main:123073 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:15  [ main:123121 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:15  [ main:123138 ] - [ INFO ]  Submitting tokens for job: job_local261036237_0086
2020-11-19 10:20:15  [ main:123170 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:15  [ main:123170 ] - [ INFO ]  Running job: job_local261036237_0086
2020-11-19 10:20:15  [ Thread-2568:123170 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:15  [ Thread-2568:123170 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:15  [ Thread-2568:123171 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:15  [ Thread-2568:123190 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123190 ] - [ INFO ]  Starting task: attempt_local261036237_0086_m_000000_0
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123191 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123191 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123191 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123192 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123199 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123200 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123315 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123317 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123318 ] - [ INFO ]  Task:attempt_local261036237_0086_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123324 ] - [ INFO ]  map
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123324 ] - [ INFO ]  Task 'attempt_local261036237_0086_m_000000_0' done.
2020-11-19 10:20:15  [ LocalJobRunner Map Task Executor #0:123324 ] - [ INFO ]  Finishing task: attempt_local261036237_0086_m_000000_0
2020-11-19 10:20:15  [ Thread-2568:123324 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:15  [ Thread-2568:123324 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:15  [ pool-261-thread-1:123324 ] - [ INFO ]  Starting task: attempt_local261036237_0086_r_000000_0
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72796177
2020-11-19 10:20:15  [ pool-261-thread-1:123325 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:15  [ EventFetcher for fetching Map Completion Events:123325 ] - [ INFO ]  attempt_local261036237_0086_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:15  [ localfetcher#86:123326 ] - [ INFO ]  localfetcher#86 about to shuffle output of map attempt_local261036237_0086_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:15  [ localfetcher#86:123326 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local261036237_0086_m_000000_0
2020-11-19 10:20:15  [ localfetcher#86:123326 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:15  [ EventFetcher for fetching Map Completion Events:123327 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:15  [ pool-261-thread-1:123327 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:15  [ pool-261-thread-1:123327 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:15  [ pool-261-thread-1:123328 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:15  [ pool-261-thread-1:123386 ] - [ INFO ]  Task:attempt_local261036237_0086_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:15  [ pool-261-thread-1:123392 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:15  [ pool-261-thread-1:123392 ] - [ INFO ]  Task attempt_local261036237_0086_r_000000_0 is allowed to commit now
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  Saved output of task 'attempt_local261036237_0086_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local261036237_0086_r_000000
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  Task 'attempt_local261036237_0086_r_000000_0' done.
2020-11-19 10:20:15  [ pool-261-thread-1:123412 ] - [ INFO ]  Finishing task: attempt_local261036237_0086_r_000000_0
2020-11-19 10:20:15  [ Thread-2568:123412 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:16  [ main:124174 ] - [ INFO ]  Job job_local261036237_0086 running in uber mode : false
2020-11-19 10:20:16  [ main:124175 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:16  [ main:124175 ] - [ INFO ]  Job job_local261036237_0086 completed successfully
2020-11-19 10:20:16  [ main:124175 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=183808
		FILE: Number of bytes written=49135974
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5536004
		HDFS: Number of bytes written=91600
		HDFS: Number of read operations=5773
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1872
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2171600896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:16  [ main:124449 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:16  [ main:124459 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:16  [ main:124464 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:16  [ main:124471 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:16  [ main:124512 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:16  [ main:124529 ] - [ INFO ]  Submitting tokens for job: job_local1445428528_0087
2020-11-19 10:20:16  [ main:124558 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:16  [ main:124558 ] - [ INFO ]  Running job: job_local1445428528_0087
2020-11-19 10:20:16  [ Thread-2598:124558 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:16  [ Thread-2598:124558 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:16  [ Thread-2598:124558 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:16  [ Thread-2598:124566 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]  Starting task: attempt_local1445428528_0087_m_000000_0
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124566 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124567 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124574 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124643 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124645 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124645 ] - [ INFO ]  Task:attempt_local1445428528_0087_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124650 ] - [ INFO ]  map
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124650 ] - [ INFO ]  Task 'attempt_local1445428528_0087_m_000000_0' done.
2020-11-19 10:20:16  [ LocalJobRunner Map Task Executor #0:124650 ] - [ INFO ]  Finishing task: attempt_local1445428528_0087_m_000000_0
2020-11-19 10:20:16  [ Thread-2598:124650 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:16  [ Thread-2598:124651 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  Starting task: attempt_local1445428528_0087_r_000000_0
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:16  [ pool-264-thread-1:124651 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5233c4c2
2020-11-19 10:20:16  [ pool-264-thread-1:124652 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:16  [ EventFetcher for fetching Map Completion Events:124652 ] - [ INFO ]  attempt_local1445428528_0087_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:16  [ localfetcher#87:124653 ] - [ INFO ]  localfetcher#87 about to shuffle output of map attempt_local1445428528_0087_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:16  [ localfetcher#87:124653 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1445428528_0087_m_000000_0
2020-11-19 10:20:16  [ localfetcher#87:124653 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:16  [ EventFetcher for fetching Map Completion Events:124653 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:16  [ pool-264-thread-1:124653 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:16  [ pool-264-thread-1:124653 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:16  [ pool-264-thread-1:124654 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:16  [ pool-264-thread-1:124654 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:16  [ pool-264-thread-1:124654 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:16  [ pool-264-thread-1:124655 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:16  [ pool-264-thread-1:124708 ] - [ INFO ]  Task:attempt_local1445428528_0087_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:16  [ pool-264-thread-1:124713 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:16  [ pool-264-thread-1:124713 ] - [ INFO ]  Task attempt_local1445428528_0087_r_000000_0 is allowed to commit now
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  Saved output of task 'attempt_local1445428528_0087_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1445428528_0087_r_000000
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  Task 'attempt_local1445428528_0087_r_000000_0' done.
2020-11-19 10:20:16  [ pool-264-thread-1:124731 ] - [ INFO ]  Finishing task: attempt_local1445428528_0087_r_000000_0
2020-11-19 10:20:16  [ Thread-2598:124731 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:17  [ main:125559 ] - [ INFO ]  Job job_local1445428528_0087 running in uber mode : false
2020-11-19 10:20:17  [ main:125559 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:17  [ main:125559 ] - [ INFO ]  Job job_local1445428528_0087 completed successfully
2020-11-19 10:20:17  [ main:125560 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=184998
		FILE: Number of bytes written=49707896
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5600410
		HDFS: Number of bytes written=92680
		HDFS: Number of read operations=5841
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1894
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2171600896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:18  [ main:126383 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:18  [ main:126409 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:18  [ main:126413 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:18  [ main:126426 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:18  [ main:126474 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:18  [ main:126491 ] - [ INFO ]  Submitting tokens for job: job_local1048465810_0088
2020-11-19 10:20:18  [ main:126520 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:18  [ main:126521 ] - [ INFO ]  Running job: job_local1048465810_0088
2020-11-19 10:20:18  [ Thread-2628:126521 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:18  [ Thread-2628:126521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:18  [ Thread-2628:126521 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:18  [ Thread-2628:126536 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  Starting task: attempt_local1048465810_0088_m_000000_0
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126537 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126546 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126546 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126546 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126547 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126547 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126547 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126631 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126633 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126634 ] - [ INFO ]  Task:attempt_local1048465810_0088_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126640 ] - [ INFO ]  map
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126640 ] - [ INFO ]  Task 'attempt_local1048465810_0088_m_000000_0' done.
2020-11-19 10:20:18  [ LocalJobRunner Map Task Executor #0:126640 ] - [ INFO ]  Finishing task: attempt_local1048465810_0088_m_000000_0
2020-11-19 10:20:18  [ Thread-2628:126640 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:18  [ Thread-2628:126640 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:18  [ pool-267-thread-1:126640 ] - [ INFO ]  Starting task: attempt_local1048465810_0088_r_000000_0
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68bc0a67
2020-11-19 10:20:18  [ pool-267-thread-1:126641 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:18  [ EventFetcher for fetching Map Completion Events:126641 ] - [ INFO ]  attempt_local1048465810_0088_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:18  [ localfetcher#88:126642 ] - [ INFO ]  localfetcher#88 about to shuffle output of map attempt_local1048465810_0088_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:18  [ localfetcher#88:126642 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1048465810_0088_m_000000_0
2020-11-19 10:20:18  [ localfetcher#88:126642 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:18  [ EventFetcher for fetching Map Completion Events:126643 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:18  [ pool-267-thread-1:126643 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:18  [ pool-267-thread-1:126644 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:18  [ pool-267-thread-1:126691 ] - [ INFO ]  Task:attempt_local1048465810_0088_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:18  [ pool-267-thread-1:126696 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:18  [ pool-267-thread-1:126697 ] - [ INFO ]  Task attempt_local1048465810_0088_r_000000_0 is allowed to commit now
2020-11-19 10:20:18  [ pool-267-thread-1:126715 ] - [ INFO ]  Saved output of task 'attempt_local1048465810_0088_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1048465810_0088_r_000000
2020-11-19 10:20:18  [ pool-267-thread-1:126716 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:18  [ pool-267-thread-1:126716 ] - [ INFO ]  Task 'attempt_local1048465810_0088_r_000000_0' done.
2020-11-19 10:20:18  [ pool-267-thread-1:126716 ] - [ INFO ]  Finishing task: attempt_local1048465810_0088_r_000000_0
2020-11-19 10:20:18  [ Thread-2628:126716 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]  Job job_local1048465810_0088 running in uber mode : false
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]  Job job_local1048465810_0088 completed successfully
2020-11-19 10:20:19  [ main:127522 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=186190
		FILE: Number of bytes written=50279821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5664816
		HDFS: Number of bytes written=93760
		HDFS: Number of read operations=5909
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1916
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2120220672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:19  [ main:127815 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:19  [ main:127826 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:19  [ main:127831 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:19  [ main:127835 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:19  [ main:127873 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:19  [ main:127891 ] - [ INFO ]  Submitting tokens for job: job_local809445797_0089
2020-11-19 10:20:19  [ main:127919 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:19  [ main:127919 ] - [ INFO ]  Running job: job_local809445797_0089
2020-11-19 10:20:19  [ Thread-2658:127920 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:19  [ Thread-2658:127920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:19  [ Thread-2658:127920 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:19  [ Thread-2658:127927 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127927 ] - [ INFO ]  Starting task: attempt_local809445797_0089_m_000000_0
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127928 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:19  [ LocalJobRunner Map Task Executor #0:127935 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128001 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128003 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128003 ] - [ INFO ]  Task:attempt_local809445797_0089_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128009 ] - [ INFO ]  map
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128010 ] - [ INFO ]  Task 'attempt_local809445797_0089_m_000000_0' done.
2020-11-19 10:20:20  [ LocalJobRunner Map Task Executor #0:128010 ] - [ INFO ]  Finishing task: attempt_local809445797_0089_m_000000_0
2020-11-19 10:20:20  [ Thread-2658:128010 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:20  [ Thread-2658:128010 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:20  [ pool-270-thread-1:128010 ] - [ INFO ]  Starting task: attempt_local809445797_0089_r_000000_0
2020-11-19 10:20:20  [ pool-270-thread-1:128010 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57643eab
2020-11-19 10:20:20  [ pool-270-thread-1:128011 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:20  [ EventFetcher for fetching Map Completion Events:128011 ] - [ INFO ]  attempt_local809445797_0089_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:20  [ localfetcher#89:128012 ] - [ INFO ]  localfetcher#89 about to shuffle output of map attempt_local809445797_0089_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:20  [ localfetcher#89:128012 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local809445797_0089_m_000000_0
2020-11-19 10:20:20  [ localfetcher#89:128012 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:20  [ EventFetcher for fetching Map Completion Events:128012 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:20  [ pool-270-thread-1:128012 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:20  [ pool-270-thread-1:128012 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:20  [ pool-270-thread-1:128013 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:20  [ pool-270-thread-1:128013 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:20  [ pool-270-thread-1:128014 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:20  [ pool-270-thread-1:128059 ] - [ INFO ]  Task:attempt_local809445797_0089_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:20  [ pool-270-thread-1:128064 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:20  [ pool-270-thread-1:128064 ] - [ INFO ]  Task attempt_local809445797_0089_r_000000_0 is allowed to commit now
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  Saved output of task 'attempt_local809445797_0089_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local809445797_0089_r_000000
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  Task 'attempt_local809445797_0089_r_000000_0' done.
2020-11-19 10:20:20  [ pool-270-thread-1:128080 ] - [ INFO ]  Finishing task: attempt_local809445797_0089_r_000000_0
2020-11-19 10:20:20  [ Thread-2658:128080 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]  Job job_local809445797_0089 running in uber mode : false
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]  Job job_local809445797_0089 completed successfully
2020-11-19 10:20:20  [ main:128920 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=187382
		FILE: Number of bytes written=50848696
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5729222
		HDFS: Number of bytes written=94840
		HDFS: Number of read operations=5977
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1938
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2120220672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:21  [ main:129177 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:21  [ main:129188 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:21  [ main:129192 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:21  [ main:129198 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:21  [ main:129241 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:21  [ main:129258 ] - [ INFO ]  Submitting tokens for job: job_local1491281540_0090
2020-11-19 10:20:21  [ main:129289 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:21  [ main:129290 ] - [ INFO ]  Running job: job_local1491281540_0090
2020-11-19 10:20:21  [ Thread-2688:129290 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:21  [ Thread-2688:129290 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:21  [ Thread-2688:129290 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:21  [ Thread-2688:129297 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129297 ] - [ INFO ]  Starting task: attempt_local1491281540_0090_m_000000_0
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129298 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129305 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129377 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129379 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129379 ] - [ INFO ]  Task:attempt_local1491281540_0090_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129385 ] - [ INFO ]  map
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129385 ] - [ INFO ]  Task 'attempt_local1491281540_0090_m_000000_0' done.
2020-11-19 10:20:21  [ LocalJobRunner Map Task Executor #0:129385 ] - [ INFO ]  Finishing task: attempt_local1491281540_0090_m_000000_0
2020-11-19 10:20:21  [ Thread-2688:129385 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:21  [ Thread-2688:129385 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  Starting task: attempt_local1491281540_0090_r_000000_0
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6bc587ee
2020-11-19 10:20:21  [ pool-273-thread-1:129386 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:21  [ EventFetcher for fetching Map Completion Events:129387 ] - [ INFO ]  attempt_local1491281540_0090_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:21  [ localfetcher#90:129387 ] - [ INFO ]  localfetcher#90 about to shuffle output of map attempt_local1491281540_0090_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:21  [ localfetcher#90:129387 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1491281540_0090_m_000000_0
2020-11-19 10:20:21  [ localfetcher#90:129387 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:21  [ EventFetcher for fetching Map Completion Events:129388 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:21  [ pool-273-thread-1:129388 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:21  [ pool-273-thread-1:129388 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:21  [ pool-273-thread-1:129389 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:21  [ pool-273-thread-1:129448 ] - [ INFO ]  Task:attempt_local1491281540_0090_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:21  [ pool-273-thread-1:129453 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:21  [ pool-273-thread-1:129453 ] - [ INFO ]  Task attempt_local1491281540_0090_r_000000_0 is allowed to commit now
2020-11-19 10:20:21  [ pool-273-thread-1:129470 ] - [ INFO ]  Saved output of task 'attempt_local1491281540_0090_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1491281540_0090_r_000000
2020-11-19 10:20:21  [ pool-273-thread-1:129471 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:21  [ pool-273-thread-1:129471 ] - [ INFO ]  Task 'attempt_local1491281540_0090_r_000000_0' done.
2020-11-19 10:20:21  [ pool-273-thread-1:129471 ] - [ INFO ]  Finishing task: attempt_local1491281540_0090_r_000000_0
2020-11-19 10:20:21  [ Thread-2688:129471 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]  Job job_local1491281540_0090 running in uber mode : false
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]  Job job_local1491281540_0090 completed successfully
2020-11-19 10:20:22  [ main:130290 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=188572
		FILE: Number of bytes written=51420618
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5793628
		HDFS: Number of bytes written=95920
		HDFS: Number of read operations=6045
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1960
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2120220672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:22  [ main:130696 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:22  [ main:130712 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:22  [ main:130717 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:22  [ main:130722 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:22  [ main:130762 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:22  [ main:130779 ] - [ INFO ]  Submitting tokens for job: job_local1989001230_0091
2020-11-19 10:20:22  [ main:130807 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:22  [ main:130807 ] - [ INFO ]  Running job: job_local1989001230_0091
2020-11-19 10:20:22  [ Thread-2718:130807 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:22  [ Thread-2718:130807 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:22  [ Thread-2718:130807 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:22  [ Thread-2718:130815 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]  Starting task: attempt_local1989001230_0091_m_000000_0
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130815 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130816 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130825 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130889 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130891 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130891 ] - [ INFO ]  Task:attempt_local1989001230_0091_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130897 ] - [ INFO ]  map
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130897 ] - [ INFO ]  Task 'attempt_local1989001230_0091_m_000000_0' done.
2020-11-19 10:20:22  [ LocalJobRunner Map Task Executor #0:130897 ] - [ INFO ]  Finishing task: attempt_local1989001230_0091_m_000000_0
2020-11-19 10:20:22  [ Thread-2718:130897 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:22  [ Thread-2718:130897 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:22  [ pool-276-thread-1:130897 ] - [ INFO ]  Starting task: attempt_local1989001230_0091_r_000000_0
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63ad5b8d
2020-11-19 10:20:22  [ pool-276-thread-1:130898 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:22  [ EventFetcher for fetching Map Completion Events:130898 ] - [ INFO ]  attempt_local1989001230_0091_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:22  [ localfetcher#91:130899 ] - [ INFO ]  localfetcher#91 about to shuffle output of map attempt_local1989001230_0091_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:22  [ localfetcher#91:130899 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1989001230_0091_m_000000_0
2020-11-19 10:20:22  [ localfetcher#91:130899 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:22  [ EventFetcher for fetching Map Completion Events:130900 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:22  [ pool-276-thread-1:130900 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:22  [ pool-276-thread-1:130900 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:22  [ pool-276-thread-1:130901 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:22  [ pool-276-thread-1:130955 ] - [ INFO ]  Task:attempt_local1989001230_0091_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:22  [ pool-276-thread-1:130960 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:22  [ pool-276-thread-1:130960 ] - [ INFO ]  Task attempt_local1989001230_0091_r_000000_0 is allowed to commit now
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  Saved output of task 'attempt_local1989001230_0091_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1989001230_0091_r_000000
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  Task 'attempt_local1989001230_0091_r_000000_0' done.
2020-11-19 10:20:22  [ pool-276-thread-1:130976 ] - [ INFO ]  Finishing task: attempt_local1989001230_0091_r_000000_0
2020-11-19 10:20:22  [ Thread-2718:130976 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:23  [ main:131809 ] - [ INFO ]  Job job_local1989001230_0091 running in uber mode : false
2020-11-19 10:20:23  [ main:131809 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:23  [ main:131810 ] - [ INFO ]  Job job_local1989001230_0091 completed successfully
2020-11-19 10:20:23  [ main:131810 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=189764
		FILE: Number of bytes written=51992543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5858034
		HDFS: Number of bytes written=97000
		HDFS: Number of read operations=6113
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1982
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2070937600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:24  [ main:132080 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:24  [ main:132092 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:24  [ main:132097 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:24  [ main:132103 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:24  [ main:132142 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:24  [ main:132159 ] - [ INFO ]  Submitting tokens for job: job_local1676031403_0092
2020-11-19 10:20:24  [ main:132189 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:24  [ main:132189 ] - [ INFO ]  Running job: job_local1676031403_0092
2020-11-19 10:20:24  [ Thread-2748:132190 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:24  [ Thread-2748:132190 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:24  [ Thread-2748:132190 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:24  [ Thread-2748:132199 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  Starting task: attempt_local1676031403_0092_m_000000_0
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132199 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132206 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132207 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132275 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132277 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132277 ] - [ INFO ]  Task:attempt_local1676031403_0092_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132283 ] - [ INFO ]  map
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132283 ] - [ INFO ]  Task 'attempt_local1676031403_0092_m_000000_0' done.
2020-11-19 10:20:24  [ LocalJobRunner Map Task Executor #0:132283 ] - [ INFO ]  Finishing task: attempt_local1676031403_0092_m_000000_0
2020-11-19 10:20:24  [ Thread-2748:132283 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:24  [ Thread-2748:132283 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  Starting task: attempt_local1676031403_0092_r_000000_0
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2730e8a9
2020-11-19 10:20:24  [ pool-279-thread-1:132284 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:24  [ EventFetcher for fetching Map Completion Events:132285 ] - [ INFO ]  attempt_local1676031403_0092_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:24  [ localfetcher#92:132285 ] - [ INFO ]  localfetcher#92 about to shuffle output of map attempt_local1676031403_0092_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:24  [ localfetcher#92:132285 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1676031403_0092_m_000000_0
2020-11-19 10:20:24  [ localfetcher#92:132285 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:24  [ EventFetcher for fetching Map Completion Events:132286 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:24  [ pool-279-thread-1:132286 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:24  [ pool-279-thread-1:132286 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:24  [ pool-279-thread-1:132287 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:24  [ pool-279-thread-1:132331 ] - [ INFO ]  Task:attempt_local1676031403_0092_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:24  [ pool-279-thread-1:132336 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:24  [ pool-279-thread-1:132337 ] - [ INFO ]  Task attempt_local1676031403_0092_r_000000_0 is allowed to commit now
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  Saved output of task 'attempt_local1676031403_0092_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1676031403_0092_r_000000
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  Task 'attempt_local1676031403_0092_r_000000_0' done.
2020-11-19 10:20:24  [ pool-279-thread-1:132354 ] - [ INFO ]  Finishing task: attempt_local1676031403_0092_r_000000_0
2020-11-19 10:20:24  [ Thread-2748:132354 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:25  [ main:133190 ] - [ INFO ]  Job job_local1676031403_0092 running in uber mode : false
2020-11-19 10:20:25  [ main:133190 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:25  [ main:133191 ] - [ INFO ]  Job job_local1676031403_0092 completed successfully
2020-11-19 10:20:25  [ main:133191 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=190956
		FILE: Number of bytes written=52564466
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5922440
		HDFS: Number of bytes written=98080
		HDFS: Number of read operations=6181
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2004
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2070937600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:25  [ main:133462 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:25  [ main:133473 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:25  [ main:133478 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:25  [ main:133483 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:25  [ main:133525 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:25  [ main:133544 ] - [ INFO ]  Submitting tokens for job: job_local247079369_0093
2020-11-19 10:20:25  [ main:133576 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:25  [ main:133576 ] - [ INFO ]  Running job: job_local247079369_0093
2020-11-19 10:20:25  [ Thread-2778:133576 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:25  [ Thread-2778:133576 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:25  [ Thread-2778:133576 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:25  [ Thread-2778:133583 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]  Starting task: attempt_local247079369_0093_m_000000_0
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133583 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133584 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133591 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133644 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133646 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133647 ] - [ INFO ]  Task:attempt_local247079369_0093_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133654 ] - [ INFO ]  map
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133654 ] - [ INFO ]  Task 'attempt_local247079369_0093_m_000000_0' done.
2020-11-19 10:20:25  [ LocalJobRunner Map Task Executor #0:133654 ] - [ INFO ]  Finishing task: attempt_local247079369_0093_m_000000_0
2020-11-19 10:20:25  [ Thread-2778:133654 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:25  [ Thread-2778:133654 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:25  [ pool-282-thread-1:133654 ] - [ INFO ]  Starting task: attempt_local247079369_0093_r_000000_0
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e051215
2020-11-19 10:20:25  [ pool-282-thread-1:133655 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:25  [ EventFetcher for fetching Map Completion Events:133656 ] - [ INFO ]  attempt_local247079369_0093_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:25  [ localfetcher#93:133656 ] - [ INFO ]  localfetcher#93 about to shuffle output of map attempt_local247079369_0093_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:25  [ localfetcher#93:133656 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local247079369_0093_m_000000_0
2020-11-19 10:20:25  [ localfetcher#93:133656 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:25  [ EventFetcher for fetching Map Completion Events:133657 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:25  [ pool-282-thread-1:133657 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:25  [ pool-282-thread-1:133657 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:25  [ pool-282-thread-1:133657 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:25  [ pool-282-thread-1:133658 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:25  [ pool-282-thread-1:133700 ] - [ INFO ]  Task:attempt_local247079369_0093_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:25  [ pool-282-thread-1:133706 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:25  [ pool-282-thread-1:133706 ] - [ INFO ]  Task attempt_local247079369_0093_r_000000_0 is allowed to commit now
2020-11-19 10:20:25  [ pool-282-thread-1:133723 ] - [ INFO ]  Saved output of task 'attempt_local247079369_0093_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local247079369_0093_r_000000
2020-11-19 10:20:25  [ pool-282-thread-1:133724 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:25  [ pool-282-thread-1:133724 ] - [ INFO ]  Task 'attempt_local247079369_0093_r_000000_0' done.
2020-11-19 10:20:25  [ pool-282-thread-1:133724 ] - [ INFO ]  Finishing task: attempt_local247079369_0093_r_000000_0
2020-11-19 10:20:25  [ Thread-2778:133724 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:26  [ main:134576 ] - [ INFO ]  Job job_local247079369_0093 running in uber mode : false
2020-11-19 10:20:26  [ main:134576 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:26  [ main:134576 ] - [ INFO ]  Job job_local247079369_0093 completed successfully
2020-11-19 10:20:26  [ main:134577 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=192146
		FILE: Number of bytes written=53133340
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5986846
		HDFS: Number of bytes written=99160
		HDFS: Number of read operations=6249
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2026
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2070937600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:26  [ main:134882 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:26  [ main:134894 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:26  [ main:134899 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:26  [ main:134904 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:26  [ main:134947 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:26  [ main:134964 ] - [ INFO ]  Submitting tokens for job: job_local808920590_0094
2020-11-19 10:20:26  [ main:134993 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:26  [ main:134993 ] - [ INFO ]  Running job: job_local808920590_0094
2020-11-19 10:20:26  [ Thread-2808:134993 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:26  [ Thread-2808:134993 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:26  [ Thread-2808:134994 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:27  [ Thread-2808:135000 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]  Starting task: attempt_local808920590_0094_m_000000_0
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135000 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135001 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135010 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135082 ] - [ INFO ]  
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135083 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135084 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135085 ] - [ INFO ]  Task:attempt_local808920590_0094_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135091 ] - [ INFO ]  map
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135091 ] - [ INFO ]  Task 'attempt_local808920590_0094_m_000000_0' done.
2020-11-19 10:20:27  [ LocalJobRunner Map Task Executor #0:135091 ] - [ INFO ]  Finishing task: attempt_local808920590_0094_m_000000_0
2020-11-19 10:20:27  [ Thread-2808:135091 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:27  [ Thread-2808:135091 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:27  [ pool-285-thread-1:135091 ] - [ INFO ]  Starting task: attempt_local808920590_0094_r_000000_0
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@34d20946
2020-11-19 10:20:27  [ pool-285-thread-1:135092 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:27  [ EventFetcher for fetching Map Completion Events:135092 ] - [ INFO ]  attempt_local808920590_0094_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:27  [ localfetcher#94:135093 ] - [ INFO ]  localfetcher#94 about to shuffle output of map attempt_local808920590_0094_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:27  [ localfetcher#94:135093 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local808920590_0094_m_000000_0
2020-11-19 10:20:27  [ localfetcher#94:135093 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:27  [ EventFetcher for fetching Map Completion Events:135093 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:27  [ pool-285-thread-1:135093 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:27  [ pool-285-thread-1:135093 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:27  [ pool-285-thread-1:135094 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:27  [ pool-285-thread-1:135094 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:27  [ pool-285-thread-1:135095 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:27  [ pool-285-thread-1:135148 ] - [ INFO ]  Task:attempt_local808920590_0094_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:27  [ pool-285-thread-1:135154 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:27  [ pool-285-thread-1:135154 ] - [ INFO ]  Task attempt_local808920590_0094_r_000000_0 is allowed to commit now
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  Saved output of task 'attempt_local808920590_0094_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local808920590_0094_r_000000
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  Task 'attempt_local808920590_0094_r_000000_0' done.
2020-11-19 10:20:27  [ pool-285-thread-1:135173 ] - [ INFO ]  Finishing task: attempt_local808920590_0094_r_000000_0
2020-11-19 10:20:27  [ Thread-2808:135173 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:27  [ main:135995 ] - [ INFO ]  Job job_local808920590_0094 running in uber mode : false
2020-11-19 10:20:27  [ main:135995 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:27  [ main:135996 ] - [ INFO ]  Job job_local808920590_0094 completed successfully
2020-11-19 10:20:27  [ main:135996 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=193338
		FILE: Number of bytes written=53702217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6051252
		HDFS: Number of bytes written=100240
		HDFS: Number of read operations=6317
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2048
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:28  [ main:136288 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:28  [ main:136300 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:28  [ main:136305 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:28  [ main:136310 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:28  [ main:136351 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:28  [ main:136368 ] - [ INFO ]  Submitting tokens for job: job_local1789788895_0095
2020-11-19 10:20:28  [ main:136407 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:28  [ main:136407 ] - [ INFO ]  Running job: job_local1789788895_0095
2020-11-19 10:20:28  [ Thread-2838:136407 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:28  [ Thread-2838:136407 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:28  [ Thread-2838:136407 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:28  [ Thread-2838:136416 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]  Starting task: attempt_local1789788895_0095_m_000000_0
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136416 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136417 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136425 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136501 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136503 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136504 ] - [ INFO ]  Task:attempt_local1789788895_0095_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136510 ] - [ INFO ]  map
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136510 ] - [ INFO ]  Task 'attempt_local1789788895_0095_m_000000_0' done.
2020-11-19 10:20:28  [ LocalJobRunner Map Task Executor #0:136510 ] - [ INFO ]  Finishing task: attempt_local1789788895_0095_m_000000_0
2020-11-19 10:20:28  [ Thread-2838:136510 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:28  [ Thread-2838:136510 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  Starting task: attempt_local1789788895_0095_r_000000_0
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:28  [ pool-288-thread-1:136510 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46de3cfc
2020-11-19 10:20:28  [ pool-288-thread-1:136511 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:28  [ EventFetcher for fetching Map Completion Events:136511 ] - [ INFO ]  attempt_local1789788895_0095_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:28  [ localfetcher#95:136511 ] - [ INFO ]  localfetcher#95 about to shuffle output of map attempt_local1789788895_0095_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:28  [ localfetcher#95:136512 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1789788895_0095_m_000000_0
2020-11-19 10:20:28  [ localfetcher#95:136512 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:28  [ EventFetcher for fetching Map Completion Events:136512 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:28  [ pool-288-thread-1:136512 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:28  [ pool-288-thread-1:136512 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:28  [ pool-288-thread-1:136513 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:28  [ pool-288-thread-1:136514 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:28  [ pool-288-thread-1:136514 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:28  [ pool-288-thread-1:136568 ] - [ INFO ]  Task:attempt_local1789788895_0095_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:28  [ pool-288-thread-1:136574 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:28  [ pool-288-thread-1:136574 ] - [ INFO ]  Task attempt_local1789788895_0095_r_000000_0 is allowed to commit now
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  Saved output of task 'attempt_local1789788895_0095_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1789788895_0095_r_000000
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  Task 'attempt_local1789788895_0095_r_000000_0' done.
2020-11-19 10:20:28  [ pool-288-thread-1:136589 ] - [ INFO ]  Finishing task: attempt_local1789788895_0095_r_000000_0
2020-11-19 10:20:28  [ Thread-2838:136590 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:29  [ main:137409 ] - [ INFO ]  Job job_local1789788895_0095 running in uber mode : false
2020-11-19 10:20:29  [ main:137409 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:29  [ main:137409 ] - [ INFO ]  Job job_local1789788895_0095 completed successfully
2020-11-19 10:20:29  [ main:137410 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=194530
		FILE: Number of bytes written=54274140
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6115658
		HDFS: Number of bytes written=101320
		HDFS: Number of read operations=6385
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2070
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:29  [ main:137677 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:29  [ main:137688 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:29  [ main:137693 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:29  [ main:137697 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:29  [ main:137738 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:29  [ main:137755 ] - [ INFO ]  Submitting tokens for job: job_local1478274252_0096
2020-11-19 10:20:29  [ main:137786 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:29  [ main:137786 ] - [ INFO ]  Running job: job_local1478274252_0096
2020-11-19 10:20:29  [ Thread-2868:137786 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:29  [ Thread-2868:137786 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:29  [ Thread-2868:137786 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:29  [ Thread-2868:137793 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137793 ] - [ INFO ]  Starting task: attempt_local1478274252_0096_m_000000_0
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137794 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137801 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137874 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137876 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137877 ] - [ INFO ]  Task:attempt_local1478274252_0096_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137882 ] - [ INFO ]  map
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137883 ] - [ INFO ]  Task 'attempt_local1478274252_0096_m_000000_0' done.
2020-11-19 10:20:29  [ LocalJobRunner Map Task Executor #0:137883 ] - [ INFO ]  Finishing task: attempt_local1478274252_0096_m_000000_0
2020-11-19 10:20:29  [ Thread-2868:137883 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:29  [ Thread-2868:137883 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:29  [ pool-291-thread-1:137883 ] - [ INFO ]  Starting task: attempt_local1478274252_0096_r_000000_0
2020-11-19 10:20:29  [ pool-291-thread-1:137883 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ea8b1c9
2020-11-19 10:20:29  [ pool-291-thread-1:137884 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:29  [ EventFetcher for fetching Map Completion Events:137884 ] - [ INFO ]  attempt_local1478274252_0096_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:29  [ localfetcher#96:137885 ] - [ INFO ]  localfetcher#96 about to shuffle output of map attempt_local1478274252_0096_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:29  [ localfetcher#96:137885 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1478274252_0096_m_000000_0
2020-11-19 10:20:29  [ localfetcher#96:137885 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:29  [ EventFetcher for fetching Map Completion Events:137885 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:29  [ pool-291-thread-1:137886 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:29  [ pool-291-thread-1:137886 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:29  [ pool-291-thread-1:137887 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:29  [ pool-291-thread-1:137943 ] - [ INFO ]  Task:attempt_local1478274252_0096_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:29  [ pool-291-thread-1:137952 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:29  [ pool-291-thread-1:137952 ] - [ INFO ]  Task attempt_local1478274252_0096_r_000000_0 is allowed to commit now
2020-11-19 10:20:29  [ pool-291-thread-1:137968 ] - [ INFO ]  Saved output of task 'attempt_local1478274252_0096_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1478274252_0096_r_000000
2020-11-19 10:20:29  [ pool-291-thread-1:137969 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:29  [ pool-291-thread-1:137969 ] - [ INFO ]  Task 'attempt_local1478274252_0096_r_000000_0' done.
2020-11-19 10:20:29  [ pool-291-thread-1:137969 ] - [ INFO ]  Finishing task: attempt_local1478274252_0096_r_000000_0
2020-11-19 10:20:29  [ Thread-2868:137969 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:30  [ main:138788 ] - [ INFO ]  Job job_local1478274252_0096 running in uber mode : false
2020-11-19 10:20:30  [ main:138788 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:30  [ main:138789 ] - [ INFO ]  Job job_local1478274252_0096 completed successfully
2020-11-19 10:20:30  [ main:138789 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=195720
		FILE: Number of bytes written=54846062
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6180064
		HDFS: Number of bytes written=102400
		HDFS: Number of read operations=6453
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2092
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:31  [ main:139465 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:31  [ main:139475 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:31  [ main:139480 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:31  [ main:139485 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:31  [ main:139526 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:31  [ main:139543 ] - [ INFO ]  Submitting tokens for job: job_local1148258781_0097
2020-11-19 10:20:31  [ main:139572 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:31  [ main:139572 ] - [ INFO ]  Running job: job_local1148258781_0097
2020-11-19 10:20:31  [ Thread-2898:139572 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:31  [ Thread-2898:139572 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:31  [ Thread-2898:139572 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:31  [ Thread-2898:139579 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139579 ] - [ INFO ]  Starting task: attempt_local1148258781_0097_m_000000_0
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139580 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139589 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139658 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139660 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139661 ] - [ INFO ]  Task:attempt_local1148258781_0097_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139667 ] - [ INFO ]  map
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139667 ] - [ INFO ]  Task 'attempt_local1148258781_0097_m_000000_0' done.
2020-11-19 10:20:31  [ LocalJobRunner Map Task Executor #0:139667 ] - [ INFO ]  Finishing task: attempt_local1148258781_0097_m_000000_0
2020-11-19 10:20:31  [ Thread-2898:139667 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:31  [ Thread-2898:139668 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  Starting task: attempt_local1148258781_0097_r_000000_0
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@443dc3
2020-11-19 10:20:31  [ pool-294-thread-1:139668 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:31  [ EventFetcher for fetching Map Completion Events:139669 ] - [ INFO ]  attempt_local1148258781_0097_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:31  [ localfetcher#97:139669 ] - [ INFO ]  localfetcher#97 about to shuffle output of map attempt_local1148258781_0097_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:31  [ localfetcher#97:139669 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1148258781_0097_m_000000_0
2020-11-19 10:20:31  [ localfetcher#97:139669 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:31  [ EventFetcher for fetching Map Completion Events:139670 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:31  [ pool-294-thread-1:139670 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:31  [ pool-294-thread-1:139670 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:31  [ pool-294-thread-1:139671 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:31  [ pool-294-thread-1:139714 ] - [ INFO ]  Task:attempt_local1148258781_0097_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:31  [ pool-294-thread-1:139720 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:31  [ pool-294-thread-1:139720 ] - [ INFO ]  Task attempt_local1148258781_0097_r_000000_0 is allowed to commit now
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  Saved output of task 'attempt_local1148258781_0097_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1148258781_0097_r_000000
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  Task 'attempt_local1148258781_0097_r_000000_0' done.
2020-11-19 10:20:31  [ pool-294-thread-1:139737 ] - [ INFO ]  Finishing task: attempt_local1148258781_0097_r_000000_0
2020-11-19 10:20:31  [ Thread-2898:139737 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:32  [ main:140572 ] - [ INFO ]  Job job_local1148258781_0097 running in uber mode : false
2020-11-19 10:20:32  [ main:140572 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:32  [ main:140573 ] - [ INFO ]  Job job_local1148258781_0097 completed successfully
2020-11-19 10:20:32  [ main:140573 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=196912
		FILE: Number of bytes written=55417987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6244470
		HDFS: Number of bytes written=103480
		HDFS: Number of read operations=6521
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2114
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1977614336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:32  [ main:140853 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:32  [ main:140864 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:32  [ main:140868 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:32  [ main:140873 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:32  [ main:140915 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:32  [ main:140932 ] - [ INFO ]  Submitting tokens for job: job_local1061958396_0098
2020-11-19 10:20:32  [ main:140960 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:32  [ main:140960 ] - [ INFO ]  Running job: job_local1061958396_0098
2020-11-19 10:20:32  [ Thread-2928:140960 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:32  [ Thread-2928:140960 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:32  [ Thread-2928:140961 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:32  [ Thread-2928:140968 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  Starting task: attempt_local1061958396_0098_m_000000_0
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140968 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:32  [ LocalJobRunner Map Task Executor #0:140977 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141049 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141051 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141051 ] - [ INFO ]  Task:attempt_local1061958396_0098_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141057 ] - [ INFO ]  map
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141057 ] - [ INFO ]  Task 'attempt_local1061958396_0098_m_000000_0' done.
2020-11-19 10:20:33  [ LocalJobRunner Map Task Executor #0:141057 ] - [ INFO ]  Finishing task: attempt_local1061958396_0098_m_000000_0
2020-11-19 10:20:33  [ Thread-2928:141057 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:33  [ Thread-2928:141058 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  Starting task: attempt_local1061958396_0098_r_000000_0
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@433fdfdf
2020-11-19 10:20:33  [ pool-297-thread-1:141058 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:33  [ EventFetcher for fetching Map Completion Events:141059 ] - [ INFO ]  attempt_local1061958396_0098_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:33  [ localfetcher#98:141059 ] - [ INFO ]  localfetcher#98 about to shuffle output of map attempt_local1061958396_0098_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:33  [ localfetcher#98:141059 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1061958396_0098_m_000000_0
2020-11-19 10:20:33  [ localfetcher#98:141059 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:33  [ EventFetcher for fetching Map Completion Events:141060 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:33  [ pool-297-thread-1:141060 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:33  [ pool-297-thread-1:141060 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:33  [ pool-297-thread-1:141061 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:33  [ pool-297-thread-1:141116 ] - [ INFO ]  Task:attempt_local1061958396_0098_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:33  [ pool-297-thread-1:141121 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:33  [ pool-297-thread-1:141121 ] - [ INFO ]  Task attempt_local1061958396_0098_r_000000_0 is allowed to commit now
2020-11-19 10:20:33  [ pool-297-thread-1:141139 ] - [ INFO ]  Saved output of task 'attempt_local1061958396_0098_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1061958396_0098_r_000000
2020-11-19 10:20:33  [ pool-297-thread-1:141140 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:33  [ pool-297-thread-1:141140 ] - [ INFO ]  Task 'attempt_local1061958396_0098_r_000000_0' done.
2020-11-19 10:20:33  [ pool-297-thread-1:141140 ] - [ INFO ]  Finishing task: attempt_local1061958396_0098_r_000000_0
2020-11-19 10:20:33  [ Thread-2928:141140 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]  Job job_local1061958396_0098 running in uber mode : false
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]  Job job_local1061958396_0098 completed successfully
2020-11-19 10:20:33  [ main:141962 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=198104
		FILE: Number of bytes written=55989910
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6308876
		HDFS: Number of bytes written=104560
		HDFS: Number of read operations=6589
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2136
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1977614336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:34  [ main:142253 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:34  [ main:142264 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:34  [ main:142269 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:34  [ main:142276 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:34  [ main:142318 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:34  [ main:142335 ] - [ INFO ]  Submitting tokens for job: job_local1823907077_0099
2020-11-19 10:20:34  [ main:142366 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:34  [ main:142366 ] - [ INFO ]  Running job: job_local1823907077_0099
2020-11-19 10:20:34  [ Thread-2958:142366 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:34  [ Thread-2958:142366 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:34  [ Thread-2958:142366 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:34  [ Thread-2958:142373 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]  Starting task: attempt_local1823907077_0099_m_000000_0
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142373 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142374 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142381 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142683 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142684 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142685 ] - [ INFO ]  Task:attempt_local1823907077_0099_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142696 ] - [ INFO ]  map
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142696 ] - [ INFO ]  Task 'attempt_local1823907077_0099_m_000000_0' done.
2020-11-19 10:20:34  [ LocalJobRunner Map Task Executor #0:142696 ] - [ INFO ]  Finishing task: attempt_local1823907077_0099_m_000000_0
2020-11-19 10:20:34  [ Thread-2958:142697 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:34  [ Thread-2958:142697 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  Starting task: attempt_local1823907077_0099_r_000000_0
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:34  [ pool-300-thread-1:142697 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ed83bba
2020-11-19 10:20:34  [ pool-300-thread-1:142698 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:34  [ EventFetcher for fetching Map Completion Events:142699 ] - [ INFO ]  attempt_local1823907077_0099_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:34  [ localfetcher#99:142699 ] - [ INFO ]  localfetcher#99 about to shuffle output of map attempt_local1823907077_0099_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:34  [ localfetcher#99:142699 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local1823907077_0099_m_000000_0
2020-11-19 10:20:34  [ localfetcher#99:142699 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:34  [ EventFetcher for fetching Map Completion Events:142700 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:34  [ pool-300-thread-1:142700 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:34  [ pool-300-thread-1:142700 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:34  [ pool-300-thread-1:142701 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:34  [ pool-300-thread-1:142754 ] - [ INFO ]  Task:attempt_local1823907077_0099_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:34  [ pool-300-thread-1:142759 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:34  [ pool-300-thread-1:142759 ] - [ INFO ]  Task attempt_local1823907077_0099_r_000000_0 is allowed to commit now
2020-11-19 10:20:34  [ pool-300-thread-1:142775 ] - [ INFO ]  Saved output of task 'attempt_local1823907077_0099_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1823907077_0099_r_000000
2020-11-19 10:20:34  [ pool-300-thread-1:142775 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:34  [ pool-300-thread-1:142775 ] - [ INFO ]  Task 'attempt_local1823907077_0099_r_000000_0' done.
2020-11-19 10:20:34  [ pool-300-thread-1:142776 ] - [ INFO ]  Finishing task: attempt_local1823907077_0099_r_000000_0
2020-11-19 10:20:34  [ Thread-2958:142776 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:35  [ main:143368 ] - [ INFO ]  Job job_local1823907077_0099 running in uber mode : false
2020-11-19 10:20:35  [ main:143368 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:35  [ main:143368 ] - [ INFO ]  Job job_local1823907077_0099 completed successfully
2020-11-19 10:20:35  [ main:143369 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=199294
		FILE: Number of bytes written=56561832
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6373282
		HDFS: Number of bytes written=105640
		HDFS: Number of read operations=6657
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2158
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1977614336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:35  [ main:143664 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:35  [ main:143675 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:35  [ main:143680 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:35  [ main:143686 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:35  [ main:143723 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:35  [ main:143740 ] - [ INFO ]  Submitting tokens for job: job_local1542952657_0100
2020-11-19 10:20:35  [ main:143768 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:35  [ main:143768 ] - [ INFO ]  Running job: job_local1542952657_0100
2020-11-19 10:20:35  [ Thread-2988:143768 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:35  [ Thread-2988:143768 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:35  [ Thread-2988:143768 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:35  [ Thread-2988:143776 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  Starting task: attempt_local1542952657_0100_m_000000_0
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143776 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143786 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143856 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143858 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143858 ] - [ INFO ]  Task:attempt_local1542952657_0100_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143864 ] - [ INFO ]  map
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143864 ] - [ INFO ]  Task 'attempt_local1542952657_0100_m_000000_0' done.
2020-11-19 10:20:35  [ LocalJobRunner Map Task Executor #0:143865 ] - [ INFO ]  Finishing task: attempt_local1542952657_0100_m_000000_0
2020-11-19 10:20:35  [ Thread-2988:143865 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:35  [ Thread-2988:143865 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  Starting task: attempt_local1542952657_0100_r_000000_0
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:35  [ pool-303-thread-1:143865 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f44a097
2020-11-19 10:20:35  [ pool-303-thread-1:143866 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:35  [ EventFetcher for fetching Map Completion Events:143866 ] - [ INFO ]  attempt_local1542952657_0100_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:35  [ localfetcher#100:143867 ] - [ INFO ]  localfetcher#100 about to shuffle output of map attempt_local1542952657_0100_m_000000_0 decomp: 191 len: 195 to MEMORY
2020-11-19 10:20:35  [ localfetcher#100:143867 ] - [ INFO ]  Read 191 bytes from map-output for attempt_local1542952657_0100_m_000000_0
2020-11-19 10:20:35  [ localfetcher#100:143867 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->191
2020-11-19 10:20:35  [ EventFetcher for fetching Map Completion Events:143867 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:35  [ pool-303-thread-1:143867 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:35  [ pool-303-thread-1:143867 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:35  [ pool-303-thread-1:143868 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:35  [ pool-303-thread-1:143868 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merged 1 segments, 191 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merging 1 files, 195 bytes from disk
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 187 bytes
2020-11-19 10:20:35  [ pool-303-thread-1:143869 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:35  [ pool-303-thread-1:143922 ] - [ INFO ]  Task:attempt_local1542952657_0100_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:35  [ pool-303-thread-1:143928 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:35  [ pool-303-thread-1:143928 ] - [ INFO ]  Task attempt_local1542952657_0100_r_000000_0 is allowed to commit now
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  Saved output of task 'attempt_local1542952657_0100_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local1542952657_0100_r_000000
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  Task 'attempt_local1542952657_0100_r_000000_0' done.
2020-11-19 10:20:35  [ pool-303-thread-1:143946 ] - [ INFO ]  Finishing task: attempt_local1542952657_0100_r_000000_0
2020-11-19 10:20:35  [ Thread-2988:143947 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]  Job job_local1542952657_0100 running in uber mode : false
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]  Job job_local1542952657_0100 completed successfully
2020-11-19 10:20:36  [ main:144771 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=200486
		FILE: Number of bytes written=57133757
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6437688
		HDFS: Number of bytes written=106720
		HDFS: Number of read operations=6725
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2180
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=195
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=195
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1935671296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:37  [ main:145040 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:37  [ main:145055 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:37  [ main:145060 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:37  [ main:145065 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:37  [ main:145107 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:37  [ main:145125 ] - [ INFO ]  Submitting tokens for job: job_local963953789_0101
2020-11-19 10:20:37  [ main:145157 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:37  [ main:145157 ] - [ INFO ]  Running job: job_local963953789_0101
2020-11-19 10:20:37  [ Thread-3018:145157 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:37  [ Thread-3018:145157 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:37  [ Thread-3018:145157 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:37  [ Thread-3018:145164 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145164 ] - [ INFO ]  Starting task: attempt_local963953789_0101_m_000000_0
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145165 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/user_info.txt:0+31303
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145173 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145243 ] - [ INFO ]  
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  bufstart = 0; bufend = 29912; bufvoid = 104857600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145244 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26212396(104849584); length = 2001/6553600
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145245 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145246 ] - [ INFO ]  Task:attempt_local963953789_0101_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145253 ] - [ INFO ]  map
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145253 ] - [ INFO ]  Task 'attempt_local963953789_0101_m_000000_0' done.
2020-11-19 10:20:37  [ LocalJobRunner Map Task Executor #0:145253 ] - [ INFO ]  Finishing task: attempt_local963953789_0101_m_000000_0
2020-11-19 10:20:37  [ Thread-3018:145253 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:37  [ Thread-3018:145253 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:37  [ pool-306-thread-1:145253 ] - [ INFO ]  Starting task: attempt_local963953789_0101_r_000000_0
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@417a3bce
2020-11-19 10:20:37  [ pool-306-thread-1:145254 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:37  [ EventFetcher for fetching Map Completion Events:145254 ] - [ INFO ]  attempt_local963953789_0101_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:37  [ localfetcher#101:145255 ] - [ INFO ]  localfetcher#101 about to shuffle output of map attempt_local963953789_0101_m_000000_0 decomp: 190 len: 194 to MEMORY
2020-11-19 10:20:37  [ localfetcher#101:145255 ] - [ INFO ]  Read 190 bytes from map-output for attempt_local963953789_0101_m_000000_0
2020-11-19 10:20:37  [ localfetcher#101:145255 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 190, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->190
2020-11-19 10:20:37  [ EventFetcher for fetching Map Completion Events:145255 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:37  [ pool-306-thread-1:145256 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merged 1 segments, 190 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merging 1 files, 194 bytes from disk
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 186 bytes
2020-11-19 10:20:37  [ pool-306-thread-1:145257 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:37  [ pool-306-thread-1:145299 ] - [ INFO ]  Task:attempt_local963953789_0101_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:37  [ pool-306-thread-1:145304 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:37  [ pool-306-thread-1:145304 ] - [ INFO ]  Task attempt_local963953789_0101_r_000000_0 is allowed to commit now
2020-11-19 10:20:37  [ pool-306-thread-1:145320 ] - [ INFO ]  Saved output of task 'attempt_local963953789_0101_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local963953789_0101_r_000000
2020-11-19 10:20:37  [ pool-306-thread-1:145321 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:37  [ pool-306-thread-1:145321 ] - [ INFO ]  Task 'attempt_local963953789_0101_r_000000_0' done.
2020-11-19 10:20:37  [ pool-306-thread-1:145321 ] - [ INFO ]  Finishing task: attempt_local963953789_0101_r_000000_0
2020-11-19 10:20:37  [ Thread-3018:145321 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:38  [ main:146157 ] - [ INFO ]  Job job_local963953789_0101 running in uber mode : false
2020-11-19 10:20:38  [ main:146158 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:38  [ main:146158 ] - [ INFO ]  Job job_local963953789_0101 completed successfully
2020-11-19 10:20:38  [ main:146158 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=201678
		FILE: Number of bytes written=57702632
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6502094
		HDFS: Number of bytes written=107800
		HDFS: Number of read operations=6793
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2202
	Map-Reduce Framework
		Map input records=501
		Map output records=501
		Map output bytes=29912
		Map output materialized bytes=194
		Input split bytes=122
		Combine input records=501
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=194
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1935671296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=31303
	File Output Format Counters 
		Bytes Written=180
2020-11-19 10:20:38  [ main:146326 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-19 10:20:38  [ main:146337 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-19 10:20:38  [ main:146342 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-19 10:20:38  [ main:146348 ] - [ INFO ]  Total input paths to process : 1
2020-11-19 10:20:38  [ main:146390 ] - [ INFO ]  number of splits:1
2020-11-19 10:20:38  [ main:146408 ] - [ INFO ]  Submitting tokens for job: job_local385966202_0102
2020-11-19 10:20:38  [ main:146441 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-19 10:20:38  [ main:146441 ] - [ INFO ]  Running job: job_local385966202_0102
2020-11-19 10:20:38  [ Thread-3046:146441 ] - [ INFO ]  OutputCommitter set in config null
2020-11-19 10:20:38  [ Thread-3046:146441 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:38  [ Thread-3046:146441 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-19 10:20:38  [ Thread-3046:146448 ] - [ INFO ]  Waiting for map tasks
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146448 ] - [ INFO ]  Starting task: attempt_local385966202_0102_m_000000_0
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146448 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146449 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146449 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146449 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/kmeans/tmp/center.txt:0+180
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  soft limit at 83886080
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146456 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146457 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  Starting flush of map output
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  Spilling map output
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  bufstart = 0; bufend = 122; bufvoid = 104857600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146508 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146509 ] - [ INFO ]  Finished spill 0
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146510 ] - [ INFO ]  Task:attempt_local385966202_0102_m_000000_0 is done. And is in the process of committing
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146516 ] - [ INFO ]  map
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146516 ] - [ INFO ]  Task 'attempt_local385966202_0102_m_000000_0' done.
2020-11-19 10:20:38  [ LocalJobRunner Map Task Executor #0:146516 ] - [ INFO ]  Finishing task: attempt_local385966202_0102_m_000000_0
2020-11-19 10:20:38  [ Thread-3046:146516 ] - [ INFO ]  map task executor complete.
2020-11-19 10:20:38  [ Thread-3046:146516 ] - [ INFO ]  Waiting for reduce tasks
2020-11-19 10:20:38  [ pool-309-thread-1:146516 ] - [ INFO ]  Starting task: attempt_local385966202_0102_r_000000_0
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b3919dd
2020-11-19 10:20:38  [ pool-309-thread-1:146517 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-19 10:20:38  [ EventFetcher for fetching Map Completion Events:146517 ] - [ INFO ]  attempt_local385966202_0102_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-19 10:20:38  [ localfetcher#102:146518 ] - [ INFO ]  localfetcher#102 about to shuffle output of map attempt_local385966202_0102_m_000000_0 decomp: 136 len: 140 to MEMORY
2020-11-19 10:20:38  [ localfetcher#102:146518 ] - [ INFO ]  Read 136 bytes from map-output for attempt_local385966202_0102_m_000000_0
2020-11-19 10:20:38  [ localfetcher#102:146518 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->136
2020-11-19 10:20:38  [ EventFetcher for fetching Map Completion Events:146518 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-19 10:20:38  [ pool-309-thread-1:146519 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:38  [ pool-309-thread-1:146519 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 132 bytes
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merged 1 segments, 136 bytes to disk to satisfy reduce memory limit
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 1 files, 140 bytes from disk
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Merging 1 sorted segments
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 132 bytes
2020-11-19 10:20:38  [ pool-309-thread-1:146520 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:38  [ pool-309-thread-1:146562 ] - [ INFO ]  Task:attempt_local385966202_0102_r_000000_0 is done. And is in the process of committing
2020-11-19 10:20:38  [ pool-309-thread-1:146568 ] - [ INFO ]  1 / 1 copied.
2020-11-19 10:20:38  [ pool-309-thread-1:146568 ] - [ INFO ]  Task attempt_local385966202_0102_r_000000_0 is allowed to commit now
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  Saved output of task 'attempt_local385966202_0102_r_000000_0' to hdfs://master:9000/user/root/mr/data/kmeans/result/_temporary/0/task_local385966202_0102_r_000000
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  reduce > reduce
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  Task 'attempt_local385966202_0102_r_000000_0' done.
2020-11-19 10:20:38  [ pool-309-thread-1:146586 ] - [ INFO ]  Finishing task: attempt_local385966202_0102_r_000000_0
2020-11-19 10:20:38  [ Thread-3046:146586 ] - [ INFO ]  reduce task executor complete.
2020-11-19 10:20:39  [ main:147441 ] - [ INFO ]  Job job_local385966202_0102 running in uber mode : false
2020-11-19 10:20:39  [ main:147442 ] - [ INFO ]   map 100% reduce 100%
2020-11-19 10:20:39  [ main:147442 ] - [ INFO ]  Job job_local385966202_0102 completed successfully
2020-11-19 10:20:39  [ main:147442 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=202760
		FILE: Number of bytes written=58271352
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6503894
		HDFS: Number of bytes written=108462
		HDFS: Number of read operations=6851
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2220
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Map output bytes=122
		Map output materialized bytes=140
		Input split bytes=123
		Combine input records=3
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=140
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1935671296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=180
	File Output Format Counters 
		Bytes Written=122
