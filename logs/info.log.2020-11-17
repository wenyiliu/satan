2020-11-17 11:00:23  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 11:00:24  [ main:798 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 11:00:24  [ main:798 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 11:00:24  [ main:1009 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:00:24  [ main:1014 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:00:24  [ main:1031 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:00:24  [ main:1395 ] - [ INFO ]  number of splits:1
2020-11-17 11:00:24  [ main:1466 ] - [ INFO ]  Submitting tokens for job: job_local2120650050_0001
2020-11-17 11:00:24  [ main:1554 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:00:24  [ main:1555 ] - [ INFO ]  Running job: job_local2120650050_0001
2020-11-17 11:00:24  [ Thread-18:1555 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:00:24  [ Thread-18:1559 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:00:24  [ Thread-18:1560 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:00:24  [ Thread-18:1596 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1597 ] - [ INFO ]  Starting task: attempt_local2120650050_0001_m_000000_0
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1614 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1620 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1620 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1622 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1674 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1674 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1674 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1674 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1674 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:00:24  [ LocalJobRunner Map Task Executor #0:1676 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1789 ] - [ INFO ]  
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1791 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1791 ] - [ INFO ]  Spilling map output
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1791 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1791 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1798 ] - [ INFO ]  Finished spill 0
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1801 ] - [ INFO ]  Task:attempt_local2120650050_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1815 ] - [ INFO ]  map
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1815 ] - [ INFO ]  Task 'attempt_local2120650050_0001_m_000000_0' done.
2020-11-17 11:00:25  [ LocalJobRunner Map Task Executor #0:1815 ] - [ INFO ]  Finishing task: attempt_local2120650050_0001_m_000000_0
2020-11-17 11:00:25  [ Thread-18:1816 ] - [ INFO ]  map task executor complete.
2020-11-17 11:00:25  [ Thread-18:1818 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:00:25  [ pool-6-thread-1:1818 ] - [ INFO ]  Starting task: attempt_local2120650050_0001_r_000000_0
2020-11-17 11:00:25  [ pool-6-thread-1:1823 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:00:25  [ pool-6-thread-1:1823 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:00:25  [ pool-6-thread-1:1823 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:00:25  [ pool-6-thread-1:1826 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@782fe8c1
2020-11-17 11:00:25  [ pool-6-thread-1:1836 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:00:25  [ EventFetcher for fetching Map Completion Events:1838 ] - [ INFO ]  attempt_local2120650050_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:00:25  [ localfetcher#1:1859 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2120650050_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 11:00:25  [ localfetcher#1:1863 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local2120650050_0001_m_000000_0
2020-11-17 11:00:25  [ localfetcher#1:1864 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 11:00:25  [ EventFetcher for fetching Map Completion Events:1865 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:00:25  [ pool-6-thread-1:1865 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:00:25  [ pool-6-thread-1:1866 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:00:25  [ pool-6-thread-1:1870 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:00:25  [ pool-6-thread-1:1870 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:00:25  [ pool-6-thread-1:1872 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 11:00:25  [ pool-6-thread-1:1872 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 11:00:25  [ pool-6-thread-1:1873 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:00:25  [ pool-6-thread-1:1873 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:00:25  [ pool-6-thread-1:1873 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:00:25  [ pool-6-thread-1:1873 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:00:25  [ pool-6-thread-1:1898 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 11:00:25  [ pool-6-thread-1:2004 ] - [ INFO ]  Task:attempt_local2120650050_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 11:00:25  [ pool-6-thread-1:2018 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:00:25  [ pool-6-thread-1:2018 ] - [ INFO ]  Task attempt_local2120650050_0001_r_000000_0 is allowed to commit now
2020-11-17 11:00:25  [ pool-6-thread-1:2059 ] - [ INFO ]  Saved output of task 'attempt_local2120650050_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/findFriend/result2/_temporary/0/task_local2120650050_0001_r_000000
2020-11-17 11:00:25  [ pool-6-thread-1:2060 ] - [ INFO ]  reduce > reduce
2020-11-17 11:00:25  [ pool-6-thread-1:2060 ] - [ INFO ]  Task 'attempt_local2120650050_0001_r_000000_0' done.
2020-11-17 11:00:25  [ pool-6-thread-1:2060 ] - [ INFO ]  Finishing task: attempt_local2120650050_0001_r_000000_0
2020-11-17 11:00:25  [ Thread-18:2060 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:00:25  [ main:2558 ] - [ INFO ]  Job job_local2120650050_0001 running in uber mode : false
2020-11-17 11:00:25  [ main:2559 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:00:25  [ main:2559 ] - [ INFO ]  Job job_local2120650050_0001 completed successfully
2020-11-17 11:00:25  [ main:2566 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=569872
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=631242752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 11:43:22  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 11:43:23  [ main:1103 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 11:43:23  [ main:1104 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 11:43:23  [ main:1312 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:43:23  [ main:1317 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:43:23  [ main:1352 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:43:23  [ main:1459 ] - [ INFO ]  number of splits:1
2020-11-17 11:43:23  [ main:1534 ] - [ INFO ]  Submitting tokens for job: job_local966496149_0001
2020-11-17 11:43:23  [ main:1624 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:43:23  [ main:1625 ] - [ INFO ]  Running job: job_local966496149_0001
2020-11-17 11:43:23  [ Thread-18:1626 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:43:24  [ Thread-18:1630 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:43:24  [ Thread-18:1631 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:43:24  [ Thread-18:1677 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1677 ] - [ INFO ]  Starting task: attempt_local966496149_0001_m_000000_0
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1694 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1702 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1755 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1755 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1756 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1756 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1756 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1758 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1889 ] - [ INFO ]  
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1891 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1891 ] - [ INFO ]  Spilling map output
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1891 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1891 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1899 ] - [ INFO ]  Finished spill 0
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1902 ] - [ INFO ]  Task:attempt_local966496149_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1942 ] - [ INFO ]  map
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1943 ] - [ INFO ]  Task 'attempt_local966496149_0001_m_000000_0' done.
2020-11-17 11:43:24  [ LocalJobRunner Map Task Executor #0:1943 ] - [ INFO ]  Finishing task: attempt_local966496149_0001_m_000000_0
2020-11-17 11:43:24  [ Thread-18:1943 ] - [ INFO ]  map task executor complete.
2020-11-17 11:43:24  [ Thread-18:1945 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:43:24  [ pool-6-thread-1:1945 ] - [ INFO ]  Starting task: attempt_local966496149_0001_r_000000_0
2020-11-17 11:43:24  [ pool-6-thread-1:1950 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:43:24  [ pool-6-thread-1:1950 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:43:24  [ pool-6-thread-1:1950 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:43:24  [ pool-6-thread-1:1953 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@13f52dcf
2020-11-17 11:43:24  [ pool-6-thread-1:1963 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:43:24  [ EventFetcher for fetching Map Completion Events:1964 ] - [ INFO ]  attempt_local966496149_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:43:24  [ localfetcher#1:1984 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local966496149_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 11:43:24  [ localfetcher#1:1987 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local966496149_0001_m_000000_0
2020-11-17 11:43:24  [ localfetcher#1:1988 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 11:43:24  [ EventFetcher for fetching Map Completion Events:1989 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:43:24  [ pool-6-thread-1:1989 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:43:24  [ pool-6-thread-1:1989 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:43:24  [ pool-6-thread-1:1994 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:43:24  [ pool-6-thread-1:1994 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:43:24  [ pool-6-thread-1:1995 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 11:43:24  [ pool-6-thread-1:1995 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 11:43:24  [ pool-6-thread-1:1996 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:43:24  [ pool-6-thread-1:1996 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:43:24  [ pool-6-thread-1:1996 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:43:24  [ pool-6-thread-1:1996 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:43:24  [ pool-6-thread-1:2034 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 11:43:24  [ pool-6-thread-1:2226 ] - [ INFO ]  Task:attempt_local966496149_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 11:43:24  [ pool-6-thread-1:2252 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:43:24  [ pool-6-thread-1:2253 ] - [ INFO ]  Task attempt_local966496149_0001_r_000000_0 is allowed to commit now
2020-11-17 11:43:24  [ pool-6-thread-1:2310 ] - [ INFO ]  Saved output of task 'attempt_local966496149_0001_r_000000_0' to hdfs://master:9000/tmp52164866/friend1605584601868/_temporary/0/task_local966496149_0001_r_000000
2020-11-17 11:43:24  [ pool-6-thread-1:2311 ] - [ INFO ]  reduce > reduce
2020-11-17 11:43:24  [ pool-6-thread-1:2311 ] - [ INFO ]  Task 'attempt_local966496149_0001_r_000000_0' done.
2020-11-17 11:43:24  [ pool-6-thread-1:2311 ] - [ INFO ]  Finishing task: attempt_local966496149_0001_r_000000_0
2020-11-17 11:43:24  [ Thread-18:2311 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:43:24  [ main:2627 ] - [ INFO ]  Job job_local966496149_0001 running in uber mode : false
2020-11-17 11:43:24  [ main:2627 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:43:24  [ main:2628 ] - [ INFO ]  Job job_local966496149_0001 completed successfully
2020-11-17 11:43:25  [ main:2635 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=566136
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=581959680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 11:44:34  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 11:44:35  [ main:666 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 11:44:35  [ main:666 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 11:44:35  [ main:875 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:44:35  [ main:880 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:44:35  [ main:899 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:44:35  [ main:978 ] - [ INFO ]  number of splits:1
2020-11-17 11:44:35  [ main:1038 ] - [ INFO ]  Submitting tokens for job: job_local1655430711_0001
2020-11-17 11:44:35  [ main:1120 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:44:35  [ main:1121 ] - [ INFO ]  Running job: job_local1655430711_0001
2020-11-17 11:44:35  [ Thread-18:1121 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:44:35  [ Thread-18:1124 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:44:35  [ Thread-18:1126 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:44:35  [ Thread-18:1181 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:44:35  [ LocalJobRunner Map Task Executor #0:1182 ] - [ INFO ]  Starting task: attempt_local1655430711_0001_m_000000_0
2020-11-17 11:44:35  [ LocalJobRunner Map Task Executor #0:1197 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:44:35  [ LocalJobRunner Map Task Executor #0:1202 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:44:35  [ LocalJobRunner Map Task Executor #0:1202 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:44:35  [ LocalJobRunner Map Task Executor #0:1204 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1254 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1254 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1254 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1254 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1254 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1256 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1406 ] - [ INFO ]  
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1408 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1408 ] - [ INFO ]  Spilling map output
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1408 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1408 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1415 ] - [ INFO ]  Finished spill 0
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1419 ] - [ INFO ]  Task:attempt_local1655430711_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1441 ] - [ INFO ]  map
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1441 ] - [ INFO ]  Task 'attempt_local1655430711_0001_m_000000_0' done.
2020-11-17 11:44:36  [ LocalJobRunner Map Task Executor #0:1442 ] - [ INFO ]  Finishing task: attempt_local1655430711_0001_m_000000_0
2020-11-17 11:44:36  [ Thread-18:1442 ] - [ INFO ]  map task executor complete.
2020-11-17 11:44:36  [ Thread-18:1444 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:44:36  [ pool-6-thread-1:1444 ] - [ INFO ]  Starting task: attempt_local1655430711_0001_r_000000_0
2020-11-17 11:44:36  [ pool-6-thread-1:1447 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:44:36  [ pool-6-thread-1:1448 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:44:36  [ pool-6-thread-1:1448 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:44:36  [ pool-6-thread-1:1449 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a2ebf85
2020-11-17 11:44:36  [ pool-6-thread-1:1457 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:44:36  [ EventFetcher for fetching Map Completion Events:1459 ] - [ INFO ]  attempt_local1655430711_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:44:36  [ localfetcher#1:1481 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1655430711_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 11:44:36  [ localfetcher#1:1485 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local1655430711_0001_m_000000_0
2020-11-17 11:44:36  [ localfetcher#1:1486 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 11:44:36  [ EventFetcher for fetching Map Completion Events:1487 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:44:36  [ pool-6-thread-1:1487 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:44:36  [ pool-6-thread-1:1487 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:44:36  [ pool-6-thread-1:1492 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:44:36  [ pool-6-thread-1:1493 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:44:36  [ pool-6-thread-1:1494 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 11:44:36  [ pool-6-thread-1:1495 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 11:44:36  [ pool-6-thread-1:1495 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:44:36  [ pool-6-thread-1:1495 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:44:36  [ pool-6-thread-1:1496 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:44:36  [ pool-6-thread-1:1498 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:44:36  [ pool-6-thread-1:1523 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 11:44:36  [ pool-6-thread-1:1729 ] - [ INFO ]  Task:attempt_local1655430711_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 11:44:36  [ pool-6-thread-1:1755 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:44:36  [ pool-6-thread-1:1756 ] - [ INFO ]  Task attempt_local1655430711_0001_r_000000_0 is allowed to commit now
2020-11-17 11:44:36  [ pool-6-thread-1:1818 ] - [ INFO ]  Saved output of task 'attempt_local1655430711_0001_r_000000_0' to hdfs://master:9000/tmp1705080808/friend1605584674375/_temporary/0/task_local1655430711_0001_r_000000
2020-11-17 11:44:36  [ pool-6-thread-1:1819 ] - [ INFO ]  reduce > reduce
2020-11-17 11:44:36  [ pool-6-thread-1:1819 ] - [ INFO ]  Task 'attempt_local1655430711_0001_r_000000_0' done.
2020-11-17 11:44:36  [ pool-6-thread-1:1819 ] - [ INFO ]  Finishing task: attempt_local1655430711_0001_r_000000_0
2020-11-17 11:44:36  [ Thread-18:1820 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:44:36  [ main:2122 ] - [ INFO ]  Job job_local1655430711_0001 running in uber mode : false
2020-11-17 11:44:36  [ main:2123 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:44:36  [ main:2124 ] - [ INFO ]  Job job_local1655430711_0001 completed successfully
2020-11-17 11:44:36  [ main:2131 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=569176
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 11:44:36  [ main:2133 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-17 11:45:13  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 11:45:14  [ main:646 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 11:45:14  [ main:646 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 11:45:14  [ main:840 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:45:14  [ main:847 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:45:14  [ main:864 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:45:14  [ main:945 ] - [ INFO ]  number of splits:1
2020-11-17 11:45:14  [ main:1015 ] - [ INFO ]  Submitting tokens for job: job_local1988966577_0001
2020-11-17 11:45:14  [ main:1110 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:45:14  [ main:1110 ] - [ INFO ]  Running job: job_local1988966577_0001
2020-11-17 11:45:14  [ Thread-18:1111 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:45:14  [ Thread-18:1114 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:45:14  [ Thread-18:1115 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:45:14  [ Thread-18:1173 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1173 ] - [ INFO ]  Starting task: attempt_local1988966577_0001_m_000000_0
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1188 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1192 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1192 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1194 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1245 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1246 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1246 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1246 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1246 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:45:14  [ LocalJobRunner Map Task Executor #0:1247 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1383 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1383 ] - [ INFO ]  Spilling map output
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1383 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1384 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1390 ] - [ INFO ]  Finished spill 0
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1393 ] - [ INFO ]  Task:attempt_local1988966577_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1421 ] - [ INFO ]  map
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1421 ] - [ INFO ]  Task 'attempt_local1988966577_0001_m_000000_0' done.
2020-11-17 11:45:15  [ LocalJobRunner Map Task Executor #0:1421 ] - [ INFO ]  Finishing task: attempt_local1988966577_0001_m_000000_0
2020-11-17 11:45:15  [ Thread-18:1421 ] - [ INFO ]  map task executor complete.
2020-11-17 11:45:15  [ Thread-18:1423 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:45:15  [ pool-6-thread-1:1423 ] - [ INFO ]  Starting task: attempt_local1988966577_0001_r_000000_0
2020-11-17 11:45:15  [ pool-6-thread-1:1428 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:45:15  [ pool-6-thread-1:1428 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:45:15  [ pool-6-thread-1:1428 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:45:15  [ pool-6-thread-1:1430 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f246fee
2020-11-17 11:45:15  [ pool-6-thread-1:1437 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:45:15  [ EventFetcher for fetching Map Completion Events:1439 ] - [ INFO ]  attempt_local1988966577_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:45:15  [ localfetcher#1:1458 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1988966577_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 11:45:15  [ localfetcher#1:1462 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local1988966577_0001_m_000000_0
2020-11-17 11:45:15  [ localfetcher#1:1463 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 11:45:15  [ EventFetcher for fetching Map Completion Events:1464 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:45:15  [ pool-6-thread-1:1464 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:45:15  [ pool-6-thread-1:1464 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:45:15  [ pool-6-thread-1:1469 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:45:15  [ pool-6-thread-1:1469 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:45:15  [ pool-6-thread-1:1471 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 11:45:15  [ pool-6-thread-1:1471 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 11:45:15  [ pool-6-thread-1:1472 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:45:15  [ pool-6-thread-1:1472 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:45:15  [ pool-6-thread-1:1472 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:45:15  [ pool-6-thread-1:1473 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:45:15  [ pool-6-thread-1:1722 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 11:45:15  [ pool-6-thread-1:1843 ] - [ INFO ]  Task:attempt_local1988966577_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 11:45:15  [ pool-6-thread-1:1852 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:45:15  [ pool-6-thread-1:1853 ] - [ INFO ]  Task attempt_local1988966577_0001_r_000000_0 is allowed to commit now
2020-11-17 11:45:15  [ pool-6-thread-1:1888 ] - [ INFO ]  Saved output of task 'attempt_local1988966577_0001_r_000000_0' to hdfs://master:9000/tmp412594183/friend1605584713318/_temporary/0/task_local1988966577_0001_r_000000
2020-11-17 11:45:15  [ pool-6-thread-1:1888 ] - [ INFO ]  reduce > reduce
2020-11-17 11:45:15  [ pool-6-thread-1:1888 ] - [ INFO ]  Task 'attempt_local1988966577_0001_r_000000_0' done.
2020-11-17 11:45:15  [ pool-6-thread-1:1888 ] - [ INFO ]  Finishing task: attempt_local1988966577_0001_r_000000_0
2020-11-17 11:45:15  [ Thread-18:1889 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:45:15  [ main:2111 ] - [ INFO ]  Job job_local1988966577_0001 running in uber mode : false
2020-11-17 11:45:15  [ main:2112 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:45:15  [ main:2113 ] - [ INFO ]  Job job_local1988966577_0001 completed successfully
2020-11-17 11:45:15  [ main:2120 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=569172
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 11:45:15  [ main:2123 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-17 11:45:15  [ main:2155 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:45:15  [ main:2160 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:45:15  [ main:2189 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:45:15  [ main:2226 ] - [ INFO ]  number of splits:1
2020-11-17 11:45:15  [ main:2248 ] - [ INFO ]  Submitting tokens for job: job_local1504057213_0002
2020-11-17 11:45:16  [ main:2298 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:45:16  [ main:2298 ] - [ INFO ]  Running job: job_local1504057213_0002
2020-11-17 11:45:16  [ Thread-46:2298 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:45:16  [ Thread-46:2298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:45:16  [ Thread-46:2299 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:45:16  [ Thread-46:2310 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2310 ] - [ INFO ]  Starting task: attempt_local1504057213_0002_m_000000_0
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2311 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2311 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2311 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2312 ] - [ INFO ]  Processing split: hdfs://master:9000/tmp412594183/friend1605584713318/part-r-00000:0+142
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2357 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2358 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2358 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2358 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2358 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2358 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2388 ] - [ INFO ]  
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2388 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2390 ] - [ INFO ]  Task:attempt_local1504057213_0002_m_000000_0 is done. And is in the process of committing
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2408 ] - [ INFO ]  map
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2409 ] - [ INFO ]  Task 'attempt_local1504057213_0002_m_000000_0' done.
2020-11-17 11:45:16  [ LocalJobRunner Map Task Executor #0:2409 ] - [ INFO ]  Finishing task: attempt_local1504057213_0002_m_000000_0
2020-11-17 11:45:16  [ Thread-46:2409 ] - [ INFO ]  map task executor complete.
2020-11-17 11:45:16  [ Thread-46:2409 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:45:16  [ pool-9-thread-1:2409 ] - [ INFO ]  Starting task: attempt_local1504057213_0002_r_000000_0
2020-11-17 11:45:16  [ pool-9-thread-1:2410 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:45:16  [ pool-9-thread-1:2410 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:45:16  [ pool-9-thread-1:2410 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:45:16  [ pool-9-thread-1:2410 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@823649d
2020-11-17 11:45:16  [ pool-9-thread-1:2411 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:45:16  [ EventFetcher for fetching Map Completion Events:2411 ] - [ INFO ]  attempt_local1504057213_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:45:16  [ localfetcher#2:2412 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1504057213_0002_m_000000_0 decomp: 2 len: 6 to MEMORY
2020-11-17 11:45:16  [ localfetcher#2:2412 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1504057213_0002_m_000000_0
2020-11-17 11:45:16  [ localfetcher#2:2412 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2020-11-17 11:45:16  [ EventFetcher for fetching Map Completion Events:2412 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:45:16  [ pool-9-thread-1:2413 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:45:16  [ pool-9-thread-1:2413 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:45:16  [ pool-9-thread-1:2414 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:45:16  [ pool-9-thread-1:2414 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2020-11-17 11:45:16  [ pool-9-thread-1:2414 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2020-11-17 11:45:16  [ pool-9-thread-1:2414 ] - [ INFO ]  Merging 1 files, 6 bytes from disk
2020-11-17 11:45:16  [ pool-9-thread-1:2414 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:45:16  [ pool-9-thread-1:2414 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:45:16  [ pool-9-thread-1:2415 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2020-11-17 11:45:16  [ pool-9-thread-1:2415 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:45:16  [ pool-9-thread-1:2450 ] - [ INFO ]  Task:attempt_local1504057213_0002_r_000000_0 is done. And is in the process of committing
2020-11-17 11:45:16  [ pool-9-thread-1:2462 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:45:16  [ pool-9-thread-1:2462 ] - [ INFO ]  Task attempt_local1504057213_0002_r_000000_0 is allowed to commit now
2020-11-17 11:45:16  [ pool-9-thread-1:2492 ] - [ INFO ]  Saved output of task 'attempt_local1504057213_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/findFriend/result2/_temporary/0/task_local1504057213_0002_r_000000
2020-11-17 11:45:16  [ pool-9-thread-1:2493 ] - [ INFO ]  reduce > reduce
2020-11-17 11:45:16  [ pool-9-thread-1:2493 ] - [ INFO ]  Task 'attempt_local1504057213_0002_r_000000_0' done.
2020-11-17 11:45:16  [ pool-9-thread-1:2493 ] - [ INFO ]  Finishing task: attempt_local1504057213_0002_r_000000_0
2020-11-17 11:45:16  [ Thread-46:2493 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:45:17  [ main:3303 ] - [ INFO ]  Job job_local1504057213_0002 running in uber mode : false
2020-11-17 11:45:17  [ main:3304 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:45:17  [ main:3304 ] - [ INFO ]  Job job_local1504057213_0002 completed successfully
2020-11-17 11:45:17  [ main:3307 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2222
		FILE: Number of bytes written=1137628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=568
		HDFS: Number of bytes written=284
		HDFS: Number of read operations=43
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=129
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=844103680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=0
2020-11-17 11:52:45  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 11:52:46  [ main:776 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 11:52:46  [ main:777 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 11:52:46  [ main:1027 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:52:46  [ main:1032 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:52:46  [ main:1055 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:52:47  [ main:1151 ] - [ INFO ]  number of splits:1
2020-11-17 11:52:47  [ main:1230 ] - [ INFO ]  Submitting tokens for job: job_local1506726918_0001
2020-11-17 11:52:47  [ main:1337 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:52:47  [ main:1338 ] - [ INFO ]  Running job: job_local1506726918_0001
2020-11-17 11:52:47  [ Thread-18:1339 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:52:47  [ Thread-18:1342 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:52:47  [ Thread-18:1343 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:52:47  [ Thread-18:1388 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1389 ] - [ INFO ]  Starting task: attempt_local1506726918_0001_m_000000_0
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1406 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1410 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1410 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1412 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1465 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1465 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1465 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1465 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1465 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1467 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1550 ] - [ INFO ]  
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1551 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1551 ] - [ INFO ]  Spilling map output
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1551 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1551 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1559 ] - [ INFO ]  Finished spill 0
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1561 ] - [ INFO ]  Task:attempt_local1506726918_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1576 ] - [ INFO ]  map
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1576 ] - [ INFO ]  Task 'attempt_local1506726918_0001_m_000000_0' done.
2020-11-17 11:52:47  [ LocalJobRunner Map Task Executor #0:1576 ] - [ INFO ]  Finishing task: attempt_local1506726918_0001_m_000000_0
2020-11-17 11:52:47  [ Thread-18:1576 ] - [ INFO ]  map task executor complete.
2020-11-17 11:52:47  [ Thread-18:1578 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:52:47  [ pool-6-thread-1:1578 ] - [ INFO ]  Starting task: attempt_local1506726918_0001_r_000000_0
2020-11-17 11:52:47  [ pool-6-thread-1:1582 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:52:47  [ pool-6-thread-1:1582 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:52:47  [ pool-6-thread-1:1582 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:52:47  [ pool-6-thread-1:1584 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50a1a309
2020-11-17 11:52:47  [ pool-6-thread-1:1592 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:52:47  [ EventFetcher for fetching Map Completion Events:1594 ] - [ INFO ]  attempt_local1506726918_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:52:47  [ localfetcher#1:1614 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1506726918_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 11:52:47  [ localfetcher#1:1618 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local1506726918_0001_m_000000_0
2020-11-17 11:52:47  [ localfetcher#1:1619 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 11:52:47  [ EventFetcher for fetching Map Completion Events:1620 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:52:47  [ pool-6-thread-1:1620 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:52:47  [ pool-6-thread-1:1620 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:52:47  [ pool-6-thread-1:1624 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:52:47  [ pool-6-thread-1:1624 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:52:47  [ pool-6-thread-1:1626 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 11:52:47  [ pool-6-thread-1:1626 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 11:52:47  [ pool-6-thread-1:1626 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:52:47  [ pool-6-thread-1:1627 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:52:47  [ pool-6-thread-1:1627 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:52:47  [ pool-6-thread-1:1627 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:52:47  [ pool-6-thread-1:1651 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 11:52:47  [ pool-6-thread-1:1753 ] - [ INFO ]  Task:attempt_local1506726918_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 11:52:47  [ pool-6-thread-1:1762 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:52:47  [ pool-6-thread-1:1762 ] - [ INFO ]  Task attempt_local1506726918_0001_r_000000_0 is allowed to commit now
2020-11-17 11:52:47  [ pool-6-thread-1:1796 ] - [ INFO ]  Saved output of task 'attempt_local1506726918_0001_r_000000_0' to hdfs://master:9000/tmp1633455108/friend1605585165444/_temporary/0/task_local1506726918_0001_r_000000
2020-11-17 11:52:47  [ pool-6-thread-1:1796 ] - [ INFO ]  reduce > reduce
2020-11-17 11:52:47  [ pool-6-thread-1:1796 ] - [ INFO ]  Task 'attempt_local1506726918_0001_r_000000_0' done.
2020-11-17 11:52:47  [ pool-6-thread-1:1797 ] - [ INFO ]  Finishing task: attempt_local1506726918_0001_r_000000_0
2020-11-17 11:52:47  [ Thread-18:1797 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:52:48  [ main:2344 ] - [ INFO ]  Job job_local1506726918_0001 running in uber mode : false
2020-11-17 11:52:48  [ main:2345 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:52:48  [ main:2345 ] - [ INFO ]  Job job_local1506726918_0001 completed successfully
2020-11-17 11:52:48  [ main:2352 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=569176
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 11:52:48  [ main:2354 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-17 11:52:48  [ main:2375 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:52:48  [ main:2379 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:52:48  [ main:2400 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:52:48  [ main:2433 ] - [ INFO ]  number of splits:1
2020-11-17 11:52:48  [ main:2453 ] - [ INFO ]  Submitting tokens for job: job_local851656872_0002
2020-11-17 11:52:48  [ main:2497 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:52:48  [ main:2498 ] - [ INFO ]  Running job: job_local851656872_0002
2020-11-17 11:52:48  [ Thread-46:2498 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:52:48  [ Thread-46:2498 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:52:48  [ Thread-46:2498 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:52:48  [ Thread-46:2509 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2509 ] - [ INFO ]  Starting task: attempt_local851656872_0002_m_000000_0
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2510 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2511 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2511 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2514 ] - [ INFO ]  Processing split: hdfs://master:9000/tmp1633455108/friend1605585165444/part-r-00000:0+142
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:52:48  [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:52:53  [ main:7465 ] - [ INFO ]  Job job_local851656872_0002 running in uber mode : false
2020-11-17 11:52:53  [ main:7465 ] - [ INFO ]   map 0% reduce 0%
2020-11-17 11:52:53  [ LocalJobRunner Map Task Executor #0:7465 ] - [ INFO ]  
2020-11-17 11:52:53  [ LocalJobRunner Map Task Executor #0:7465 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:52:53  [ LocalJobRunner Map Task Executor #0:7468 ] - [ INFO ]  Task:attempt_local851656872_0002_m_000000_0 is done. And is in the process of committing
2020-11-17 11:52:53  [ LocalJobRunner Map Task Executor #0:7483 ] - [ INFO ]  map
2020-11-17 11:52:53  [ LocalJobRunner Map Task Executor #0:7483 ] - [ INFO ]  Task 'attempt_local851656872_0002_m_000000_0' done.
2020-11-17 11:52:53  [ LocalJobRunner Map Task Executor #0:7483 ] - [ INFO ]  Finishing task: attempt_local851656872_0002_m_000000_0
2020-11-17 11:52:53  [ Thread-46:7483 ] - [ INFO ]  map task executor complete.
2020-11-17 11:52:53  [ Thread-46:7484 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:52:53  [ pool-9-thread-1:7484 ] - [ INFO ]  Starting task: attempt_local851656872_0002_r_000000_0
2020-11-17 11:52:53  [ pool-9-thread-1:7485 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:52:53  [ pool-9-thread-1:7486 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:52:53  [ pool-9-thread-1:7486 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:52:53  [ pool-9-thread-1:7486 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@24357089
2020-11-17 11:52:53  [ pool-9-thread-1:7487 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:52:53  [ EventFetcher for fetching Map Completion Events:7487 ] - [ INFO ]  attempt_local851656872_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:52:53  [ localfetcher#2:7489 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local851656872_0002_m_000000_0 decomp: 2 len: 6 to MEMORY
2020-11-17 11:52:53  [ localfetcher#2:7489 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local851656872_0002_m_000000_0
2020-11-17 11:52:53  [ localfetcher#2:7489 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2020-11-17 11:52:53  [ EventFetcher for fetching Map Completion Events:7489 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:52:53  [ pool-9-thread-1:7490 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:52:53  [ pool-9-thread-1:7490 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:52:53  [ pool-9-thread-1:7491 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:52:53  [ pool-9-thread-1:7491 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2020-11-17 11:52:53  [ pool-9-thread-1:7492 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2020-11-17 11:52:53  [ pool-9-thread-1:7492 ] - [ INFO ]  Merging 1 files, 6 bytes from disk
2020-11-17 11:52:53  [ pool-9-thread-1:7492 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:52:53  [ pool-9-thread-1:7492 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:52:53  [ pool-9-thread-1:7492 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2020-11-17 11:52:53  [ pool-9-thread-1:7493 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:52:53  [ pool-9-thread-1:7516 ] - [ INFO ]  Task:attempt_local851656872_0002_r_000000_0 is done. And is in the process of committing
2020-11-17 11:53:05  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 11:53:06  [ main:615 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 11:53:06  [ main:615 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 11:53:06  [ main:885 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:53:06  [ main:890 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:53:06  [ main:904 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:53:06  [ main:980 ] - [ INFO ]  number of splits:1
2020-11-17 11:53:06  [ main:1050 ] - [ INFO ]  Submitting tokens for job: job_local1144721975_0001
2020-11-17 11:53:06  [ main:1152 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:53:06  [ main:1153 ] - [ INFO ]  Running job: job_local1144721975_0001
2020-11-17 11:53:06  [ Thread-18:1153 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:53:06  [ Thread-18:1156 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:53:06  [ Thread-18:1158 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:53:06  [ Thread-18:1199 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1199 ] - [ INFO ]  Starting task: attempt_local1144721975_0001_m_000000_0
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1215 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1219 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1221 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1272 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1272 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1272 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1272 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1272 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1274 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1432 ] - [ INFO ]  
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  Spilling map output
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1434 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1441 ] - [ INFO ]  Finished spill 0
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1444 ] - [ INFO ]  Task:attempt_local1144721975_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1516 ] - [ INFO ]  map
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1516 ] - [ INFO ]  Task 'attempt_local1144721975_0001_m_000000_0' done.
2020-11-17 11:53:06  [ LocalJobRunner Map Task Executor #0:1517 ] - [ INFO ]  Finishing task: attempt_local1144721975_0001_m_000000_0
2020-11-17 11:53:06  [ Thread-18:1517 ] - [ INFO ]  map task executor complete.
2020-11-17 11:53:06  [ Thread-18:1519 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:53:06  [ pool-6-thread-1:1519 ] - [ INFO ]  Starting task: attempt_local1144721975_0001_r_000000_0
2020-11-17 11:53:06  [ pool-6-thread-1:1524 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:53:06  [ pool-6-thread-1:1524 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:53:06  [ pool-6-thread-1:1524 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:53:06  [ pool-6-thread-1:1526 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b325e4
2020-11-17 11:53:06  [ pool-6-thread-1:1535 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:53:06  [ EventFetcher for fetching Map Completion Events:1537 ] - [ INFO ]  attempt_local1144721975_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:53:06  [ localfetcher#1:1559 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1144721975_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 11:53:06  [ localfetcher#1:1563 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local1144721975_0001_m_000000_0
2020-11-17 11:53:06  [ localfetcher#1:1564 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 11:53:06  [ EventFetcher for fetching Map Completion Events:1565 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:53:06  [ pool-6-thread-1:1565 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:53:06  [ pool-6-thread-1:1566 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:53:07  [ pool-6-thread-1:1570 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:53:07  [ pool-6-thread-1:1571 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:53:07  [ pool-6-thread-1:1572 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 11:53:07  [ pool-6-thread-1:1573 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 11:53:07  [ pool-6-thread-1:1573 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:53:07  [ pool-6-thread-1:1573 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:53:07  [ pool-6-thread-1:1573 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 11:53:07  [ pool-6-thread-1:1574 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:53:07  [ pool-6-thread-1:1600 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 11:53:07  [ pool-6-thread-1:1697 ] - [ INFO ]  Task:attempt_local1144721975_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 11:53:07  [ pool-6-thread-1:1706 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:53:07  [ pool-6-thread-1:1706 ] - [ INFO ]  Task attempt_local1144721975_0001_r_000000_0 is allowed to commit now
2020-11-17 11:53:07  [ pool-6-thread-1:1737 ] - [ INFO ]  Saved output of task 'attempt_local1144721975_0001_r_000000_0' to hdfs://master:9000/tmp707732344/friend1605585185023/_temporary/0/task_local1144721975_0001_r_000000
2020-11-17 11:53:07  [ pool-6-thread-1:1737 ] - [ INFO ]  reduce > reduce
2020-11-17 11:53:07  [ pool-6-thread-1:1738 ] - [ INFO ]  Task 'attempt_local1144721975_0001_r_000000_0' done.
2020-11-17 11:53:07  [ pool-6-thread-1:1738 ] - [ INFO ]  Finishing task: attempt_local1144721975_0001_r_000000_0
2020-11-17 11:53:07  [ Thread-18:1738 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:53:07  [ main:2154 ] - [ INFO ]  Job job_local1144721975_0001 running in uber mode : false
2020-11-17 11:53:07  [ main:2155 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:53:07  [ main:2156 ] - [ INFO ]  Job job_local1144721975_0001 completed successfully
2020-11-17 11:53:07  [ main:2163 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=569172
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 11:53:07  [ main:2165 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-17 11:53:07  [ main:2188 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 11:53:07  [ main:2193 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 11:53:07  [ main:2214 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 11:53:07  [ main:2247 ] - [ INFO ]  number of splits:1
2020-11-17 11:53:07  [ main:2267 ] - [ INFO ]  Submitting tokens for job: job_local1279003849_0002
2020-11-17 11:53:07  [ main:2307 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 11:53:07  [ main:2307 ] - [ INFO ]  Running job: job_local1279003849_0002
2020-11-17 11:53:07  [ Thread-46:2307 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 11:53:07  [ Thread-46:2307 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:53:07  [ Thread-46:2307 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 11:53:07  [ Thread-46:2318 ] - [ INFO ]  Waiting for map tasks
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2318 ] - [ INFO ]  Starting task: attempt_local1279003849_0002_m_000000_0
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2319 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2319 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2319 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2320 ] - [ INFO ]  Processing split: hdfs://master:9000/tmp707732344/friend1605585185023/part-r-00000:0+142
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2360 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2361 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2361 ] - [ INFO ]  soft limit at 83886080
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2361 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2361 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2361 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  Starting flush of map output
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  Spilling map output
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  bufstart = 0; bufend = 898; bufvoid = 104857600
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213796(104855184); length = 601/6553600
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2388 ] - [ INFO ]  Finished spill 0
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2389 ] - [ INFO ]  Task:attempt_local1279003849_0002_m_000000_0 is done. And is in the process of committing
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2401 ] - [ INFO ]  map
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2401 ] - [ INFO ]  Task 'attempt_local1279003849_0002_m_000000_0' done.
2020-11-17 11:53:07  [ LocalJobRunner Map Task Executor #0:2401 ] - [ INFO ]  Finishing task: attempt_local1279003849_0002_m_000000_0
2020-11-17 11:53:07  [ Thread-46:2401 ] - [ INFO ]  map task executor complete.
2020-11-17 11:53:07  [ Thread-46:2402 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 11:53:07  [ pool-9-thread-1:2402 ] - [ INFO ]  Starting task: attempt_local1279003849_0002_r_000000_0
2020-11-17 11:53:07  [ pool-9-thread-1:2402 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 11:53:07  [ pool-9-thread-1:2403 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 11:53:07  [ pool-9-thread-1:2403 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 11:53:07  [ pool-9-thread-1:2403 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@31e5afc2
2020-11-17 11:53:07  [ pool-9-thread-1:2403 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 11:53:07  [ EventFetcher for fetching Map Completion Events:2403 ] - [ INFO ]  attempt_local1279003849_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 11:53:07  [ localfetcher#2:2404 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1279003849_0002_m_000000_0 decomp: 1202 len: 1206 to MEMORY
2020-11-17 11:53:07  [ localfetcher#2:2404 ] - [ INFO ]  Read 1202 bytes from map-output for attempt_local1279003849_0002_m_000000_0
2020-11-17 11:53:07  [ localfetcher#2:2404 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 1202, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1202
2020-11-17 11:53:07  [ EventFetcher for fetching Map Completion Events:2405 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 11:53:07  [ pool-9-thread-1:2405 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:53:07  [ pool-9-thread-1:2405 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 11:53:07  [ pool-9-thread-1:2406 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:53:07  [ pool-9-thread-1:2406 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1196 bytes
2020-11-17 11:53:07  [ pool-9-thread-1:2407 ] - [ INFO ]  Merged 1 segments, 1202 bytes to disk to satisfy reduce memory limit
2020-11-17 11:53:07  [ pool-9-thread-1:2407 ] - [ INFO ]  Merging 1 files, 1206 bytes from disk
2020-11-17 11:53:07  [ pool-9-thread-1:2407 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 11:53:07  [ pool-9-thread-1:2407 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 11:53:07  [ pool-9-thread-1:2407 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1196 bytes
2020-11-17 11:53:07  [ pool-9-thread-1:2408 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:53:07  [ pool-9-thread-1:2483 ] - [ INFO ]  Task:attempt_local1279003849_0002_r_000000_0 is done. And is in the process of committing
2020-11-17 11:53:07  [ pool-9-thread-1:2495 ] - [ INFO ]  1 / 1 copied.
2020-11-17 11:53:07  [ pool-9-thread-1:2495 ] - [ INFO ]  Task attempt_local1279003849_0002_r_000000_0 is allowed to commit now
2020-11-17 11:53:07  [ pool-9-thread-1:2526 ] - [ INFO ]  Saved output of task 'attempt_local1279003849_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/findFriend/result2/_temporary/0/task_local1279003849_0002_r_000000
2020-11-17 11:53:07  [ pool-9-thread-1:2527 ] - [ INFO ]  reduce > reduce
2020-11-17 11:53:07  [ pool-9-thread-1:2527 ] - [ INFO ]  Task 'attempt_local1279003849_0002_r_000000_0' done.
2020-11-17 11:53:07  [ pool-9-thread-1:2527 ] - [ INFO ]  Finishing task: attempt_local1279003849_0002_r_000000_0
2020-11-17 11:53:07  [ Thread-46:2527 ] - [ INFO ]  reduce task executor complete.
2020-11-17 11:53:08  [ main:3311 ] - [ INFO ]  Job job_local1279003849_0002 running in uber mode : false
2020-11-17 11:53:08  [ main:3312 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 11:53:08  [ main:3312 ] - [ INFO ]  Job job_local1279003849_0002 completed successfully
2020-11-17 11:53:08  [ main:3315 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=4622
		FILE: Number of bytes written=1141228
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=568
		HDFS: Number of bytes written=888
		HDFS: Number of read operations=43
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=14
		Map output records=151
		Map output bytes=898
		Map output materialized bytes=1206
		Input split bytes=129
		Combine input records=0
		Combine output records=0
		Reduce input groups=77
		Reduce shuffle bytes=1206
		Reduce input records=151
		Reduce output records=77
		Spilled Records=302
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=844103680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=604
2020-11-17 13:19:15  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 13:19:16  [ main:811 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 13:19:16  [ main:811 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 13:19:16  [ main:1025 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 13:19:16  [ main:1030 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 13:19:16  [ main:1057 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 13:19:16  [ main:1138 ] - [ INFO ]  number of splits:1
2020-11-17 13:19:16  [ main:1209 ] - [ INFO ]  Submitting tokens for job: job_local293279427_0001
2020-11-17 13:19:17  [ main:1310 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 13:19:17  [ main:1310 ] - [ INFO ]  Running job: job_local293279427_0001
2020-11-17 13:19:17  [ Thread-18:1311 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 13:19:17  [ Thread-18:1316 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:19:17  [ Thread-18:1317 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 13:19:17  [ Thread-18:1358 ] - [ INFO ]  Waiting for map tasks
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1358 ] - [ INFO ]  Starting task: attempt_local293279427_0001_m_000000_0
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1378 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1385 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1385 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1388 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1452 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1452 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1452 ] - [ INFO ]  soft limit at 83886080
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1452 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1452 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1455 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1551 ] - [ INFO ]  
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1553 ] - [ INFO ]  Starting flush of map output
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1553 ] - [ INFO ]  Spilling map output
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1553 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1553 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1561 ] - [ INFO ]  Finished spill 0
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1563 ] - [ INFO ]  Task:attempt_local293279427_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1580 ] - [ INFO ]  map
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1580 ] - [ INFO ]  Task 'attempt_local293279427_0001_m_000000_0' done.
2020-11-17 13:19:17  [ LocalJobRunner Map Task Executor #0:1580 ] - [ INFO ]  Finishing task: attempt_local293279427_0001_m_000000_0
2020-11-17 13:19:17  [ Thread-18:1580 ] - [ INFO ]  map task executor complete.
2020-11-17 13:19:17  [ Thread-18:1582 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 13:19:17  [ pool-6-thread-1:1582 ] - [ INFO ]  Starting task: attempt_local293279427_0001_r_000000_0
2020-11-17 13:19:17  [ pool-6-thread-1:1587 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:19:17  [ pool-6-thread-1:1588 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:19:17  [ pool-6-thread-1:1588 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:19:17  [ pool-6-thread-1:1591 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f246fee
2020-11-17 13:19:17  [ pool-6-thread-1:1601 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 13:19:17  [ EventFetcher for fetching Map Completion Events:1603 ] - [ INFO ]  attempt_local293279427_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 13:19:17  [ localfetcher#1:1625 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local293279427_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 13:19:17  [ localfetcher#1:1630 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local293279427_0001_m_000000_0
2020-11-17 13:19:17  [ localfetcher#1:1631 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 13:19:17  [ EventFetcher for fetching Map Completion Events:1632 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 13:19:17  [ pool-6-thread-1:1632 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:19:17  [ pool-6-thread-1:1633 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 13:19:17  [ pool-6-thread-1:1638 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:19:17  [ pool-6-thread-1:1639 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 13:19:17  [ pool-6-thread-1:1640 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 13:19:17  [ pool-6-thread-1:1640 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 13:19:17  [ pool-6-thread-1:1641 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 13:19:17  [ pool-6-thread-1:1641 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:19:17  [ pool-6-thread-1:1641 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 13:19:17  [ pool-6-thread-1:1642 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:19:17  [ pool-6-thread-1:1667 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 13:19:17  [ pool-6-thread-1:1792 ] - [ INFO ]  Task:attempt_local293279427_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 13:19:17  [ pool-6-thread-1:1803 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:19:17  [ pool-6-thread-1:1803 ] - [ INFO ]  Task attempt_local293279427_0001_r_000000_0 is allowed to commit now
2020-11-17 13:19:17  [ pool-6-thread-1:1830 ] - [ INFO ]  Saved output of task 'attempt_local293279427_0001_r_000000_0' to hdfs://master:9000/tmp660331530/friend1605590355222/_temporary/0/task_local293279427_0001_r_000000
2020-11-17 13:19:17  [ pool-6-thread-1:1831 ] - [ INFO ]  reduce > reduce
2020-11-17 13:19:17  [ pool-6-thread-1:1831 ] - [ INFO ]  Task 'attempt_local293279427_0001_r_000000_0' done.
2020-11-17 13:19:17  [ pool-6-thread-1:1831 ] - [ INFO ]  Finishing task: attempt_local293279427_0001_r_000000_0
2020-11-17 13:19:17  [ Thread-18:1831 ] - [ INFO ]  reduce task executor complete.
2020-11-17 13:19:18  [ main:2315 ] - [ INFO ]  Job job_local293279427_0001 running in uber mode : false
2020-11-17 13:19:18  [ main:2316 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 13:19:18  [ main:2317 ] - [ INFO ]  Job job_local293279427_0001 completed successfully
2020-11-17 13:19:18  [ main:2323 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=566140
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 13:19:18  [ main:2326 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-17 13:19:18  [ main:2342 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 13:19:18  [ main:2346 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 13:19:18  [ main:2361 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 13:19:18  [ main:2394 ] - [ INFO ]  number of splits:1
2020-11-17 13:19:18  [ main:2414 ] - [ INFO ]  Submitting tokens for job: job_local905846146_0002
2020-11-17 13:19:18  [ main:2460 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 13:19:18  [ main:2460 ] - [ INFO ]  Running job: job_local905846146_0002
2020-11-17 13:19:18  [ Thread-46:2460 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 13:19:18  [ Thread-46:2460 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:19:18  [ Thread-46:2460 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 13:19:18  [ Thread-46:2472 ] - [ INFO ]  Waiting for map tasks
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2472 ] - [ INFO ]  Starting task: attempt_local905846146_0002_m_000000_0
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2472 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2473 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2473 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2474 ] - [ INFO ]  Processing split: hdfs://master:9000/tmp660331530/friend1605590355222/part-r-00000:0+142
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2519 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2519 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2519 ] - [ INFO ]  soft limit at 83886080
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2519 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2520 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2520 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  Starting flush of map output
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  Spilling map output
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  bufstart = 0; bufend = 640; bufvoid = 104857600
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213968(104855872); length = 429/6553600
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2542 ] - [ INFO ]  Finished spill 0
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2543 ] - [ INFO ]  Task:attempt_local905846146_0002_m_000000_0 is done. And is in the process of committing
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2553 ] - [ INFO ]  map
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2553 ] - [ INFO ]  Task 'attempt_local905846146_0002_m_000000_0' done.
2020-11-17 13:19:18  [ LocalJobRunner Map Task Executor #0:2553 ] - [ INFO ]  Finishing task: attempt_local905846146_0002_m_000000_0
2020-11-17 13:19:18  [ Thread-46:2553 ] - [ INFO ]  map task executor complete.
2020-11-17 13:19:18  [ Thread-46:2553 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 13:19:18  [ pool-9-thread-1:2553 ] - [ INFO ]  Starting task: attempt_local905846146_0002_r_000000_0
2020-11-17 13:19:18  [ pool-9-thread-1:2554 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:19:18  [ pool-9-thread-1:2554 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:19:18  [ pool-9-thread-1:2554 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:19:18  [ pool-9-thread-1:2554 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3e2bce43
2020-11-17 13:19:18  [ pool-9-thread-1:2555 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 13:19:18  [ EventFetcher for fetching Map Completion Events:2555 ] - [ INFO ]  attempt_local905846146_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 13:19:18  [ localfetcher#2:2556 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local905846146_0002_m_000000_0 decomp: 858 len: 862 to MEMORY
2020-11-17 13:19:18  [ localfetcher#2:2556 ] - [ INFO ]  Read 858 bytes from map-output for attempt_local905846146_0002_m_000000_0
2020-11-17 13:19:18  [ localfetcher#2:2556 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 858, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->858
2020-11-17 13:19:18  [ EventFetcher for fetching Map Completion Events:2556 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 13:19:18  [ pool-9-thread-1:2557 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:19:18  [ pool-9-thread-1:2557 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 13:19:18  [ pool-9-thread-1:2558 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:19:18  [ pool-9-thread-1:2558 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 852 bytes
2020-11-17 13:19:18  [ pool-9-thread-1:2559 ] - [ INFO ]  Merged 1 segments, 858 bytes to disk to satisfy reduce memory limit
2020-11-17 13:19:18  [ pool-9-thread-1:2559 ] - [ INFO ]  Merging 1 files, 862 bytes from disk
2020-11-17 13:19:18  [ pool-9-thread-1:2559 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 13:19:18  [ pool-9-thread-1:2559 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:19:18  [ pool-9-thread-1:2559 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 852 bytes
2020-11-17 13:19:18  [ pool-9-thread-1:2559 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:19:18  [ pool-9-thread-1:2632 ] - [ INFO ]  Task:attempt_local905846146_0002_r_000000_0 is done. And is in the process of committing
2020-11-17 13:19:18  [ pool-9-thread-1:2644 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:19:18  [ pool-9-thread-1:2644 ] - [ INFO ]  Task attempt_local905846146_0002_r_000000_0 is allowed to commit now
2020-11-17 13:19:18  [ pool-9-thread-1:2666 ] - [ INFO ]  Saved output of task 'attempt_local905846146_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/findFriend/result2/_temporary/0/task_local905846146_0002_r_000000
2020-11-17 13:19:18  [ pool-9-thread-1:2666 ] - [ INFO ]  reduce > reduce
2020-11-17 13:19:18  [ pool-9-thread-1:2666 ] - [ INFO ]  Task 'attempt_local905846146_0002_r_000000_0' done.
2020-11-17 13:19:18  [ pool-9-thread-1:2666 ] - [ INFO ]  Finishing task: attempt_local905846146_0002_r_000000_0
2020-11-17 13:19:18  [ Thread-46:2666 ] - [ INFO ]  reduce task executor complete.
2020-11-17 13:19:19  [ main:3462 ] - [ INFO ]  Job job_local905846146_0002 running in uber mode : false
2020-11-17 13:19:19  [ main:3463 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 13:19:19  [ main:3463 ] - [ INFO ]  Job job_local905846146_0002 completed successfully
2020-11-17 13:19:19  [ main:3466 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=3934
		FILE: Number of bytes written=1134132
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=568
		HDFS: Number of bytes written=706
		HDFS: Number of read operations=43
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=14
		Map output records=108
		Map output bytes=640
		Map output materialized bytes=862
		Input split bytes=129
		Combine input records=0
		Combine output records=0
		Reduce input groups=53
		Reduce shuffle bytes=862
		Reduce input records=108
		Reduce output records=53
		Spilled Records=216
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=422
2020-11-17 13:39:07  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 13:39:08  [ main:728 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 13:39:08  [ main:729 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 13:39:08  [ main:956 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 13:39:08  [ main:961 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 13:39:08  [ main:983 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 13:39:08  [ main:1070 ] - [ INFO ]  number of splits:1
2020-11-17 13:39:08  [ main:1141 ] - [ INFO ]  Submitting tokens for job: job_local577855968_0001
2020-11-17 13:39:09  [ main:1237 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 13:39:09  [ main:1238 ] - [ INFO ]  Running job: job_local577855968_0001
2020-11-17 13:39:09  [ Thread-18:1239 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 13:39:09  [ Thread-18:1243 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:39:09  [ Thread-18:1245 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 13:39:09  [ Thread-18:1281 ] - [ INFO ]  Waiting for map tasks
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1282 ] - [ INFO ]  Starting task: attempt_local577855968_0001_m_000000_0
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1301 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1307 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1308 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1310 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/findFriend/friedn_test.txt:0+142
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  soft limit at 83886080
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1368 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1370 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1505 ] - [ INFO ]  
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1507 ] - [ INFO ]  Starting flush of map output
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1507 ] - [ INFO ]  Spilling map output
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1507 ] - [ INFO ]  bufstart = 0; bufend = 228; bufvoid = 104857600
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1507 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1515 ] - [ INFO ]  Finished spill 0
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1518 ] - [ INFO ]  Task:attempt_local577855968_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1531 ] - [ INFO ]  map
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1531 ] - [ INFO ]  Task 'attempt_local577855968_0001_m_000000_0' done.
2020-11-17 13:39:09  [ LocalJobRunner Map Task Executor #0:1531 ] - [ INFO ]  Finishing task: attempt_local577855968_0001_m_000000_0
2020-11-17 13:39:09  [ Thread-18:1531 ] - [ INFO ]  map task executor complete.
2020-11-17 13:39:09  [ Thread-18:1533 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 13:39:09  [ pool-6-thread-1:1533 ] - [ INFO ]  Starting task: attempt_local577855968_0001_r_000000_0
2020-11-17 13:39:09  [ pool-6-thread-1:1538 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:39:09  [ pool-6-thread-1:1538 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:39:09  [ pool-6-thread-1:1538 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:39:09  [ pool-6-thread-1:1541 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14db7d4a
2020-11-17 13:39:09  [ pool-6-thread-1:1550 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 13:39:09  [ EventFetcher for fetching Map Completion Events:1552 ] - [ INFO ]  attempt_local577855968_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 13:39:09  [ localfetcher#1:1577 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local577855968_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
2020-11-17 13:39:09  [ localfetcher#1:1582 ] - [ INFO ]  Read 344 bytes from map-output for attempt_local577855968_0001_m_000000_0
2020-11-17 13:39:09  [ localfetcher#1:1582 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
2020-11-17 13:39:09  [ EventFetcher for fetching Map Completion Events:1583 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 13:39:09  [ pool-6-thread-1:1584 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:39:09  [ pool-6-thread-1:1584 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 13:39:09  [ pool-6-thread-1:1589 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:39:09  [ pool-6-thread-1:1590 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 13:39:09  [ pool-6-thread-1:1591 ] - [ INFO ]  Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
2020-11-17 13:39:09  [ pool-6-thread-1:1592 ] - [ INFO ]  Merging 1 files, 348 bytes from disk
2020-11-17 13:39:09  [ pool-6-thread-1:1592 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 13:39:09  [ pool-6-thread-1:1592 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:39:09  [ pool-6-thread-1:1592 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 340 bytes
2020-11-17 13:39:09  [ pool-6-thread-1:1593 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:39:09  [ pool-6-thread-1:1615 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 13:39:09  [ pool-6-thread-1:1722 ] - [ INFO ]  Task:attempt_local577855968_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 13:39:09  [ pool-6-thread-1:1733 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:39:09  [ pool-6-thread-1:1733 ] - [ INFO ]  Task attempt_local577855968_0001_r_000000_0 is allowed to commit now
2020-11-17 13:39:09  [ pool-6-thread-1:1771 ] - [ INFO ]  Saved output of task 'attempt_local577855968_0001_r_000000_0' to hdfs://master:9000/tmp1032070304/friend1605591547369/_temporary/0/task_local577855968_0001_r_000000
2020-11-17 13:39:09  [ pool-6-thread-1:1772 ] - [ INFO ]  reduce > reduce
2020-11-17 13:39:09  [ pool-6-thread-1:1772 ] - [ INFO ]  Task 'attempt_local577855968_0001_r_000000_0' done.
2020-11-17 13:39:09  [ pool-6-thread-1:1772 ] - [ INFO ]  Finishing task: attempt_local577855968_0001_r_000000_0
2020-11-17 13:39:09  [ Thread-18:1772 ] - [ INFO ]  reduce task executor complete.
2020-11-17 13:39:10  [ main:2244 ] - [ INFO ]  Job job_local577855968_0001 running in uber mode : false
2020-11-17 13:39:10  [ main:2245 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 13:39:10  [ main:2246 ] - [ INFO ]  Job job_local577855968_0001 completed successfully
2020-11-17 13:39:10  [ main:2253 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1088
		FILE: Number of bytes written=566144
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=284
		HDFS: Number of bytes written=142
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=142
2020-11-17 13:39:10  [ main:2256 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-17 13:39:10  [ main:2283 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 13:39:10  [ main:2288 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 13:39:10  [ main:2304 ] - [ INFO ]  Total input paths to process : 1
2020-11-17 13:39:10  [ main:2335 ] - [ INFO ]  number of splits:1
2020-11-17 13:39:10  [ main:2356 ] - [ INFO ]  Submitting tokens for job: job_local2017355921_0002
2020-11-17 13:39:10  [ main:2407 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 13:39:10  [ Thread-46:2407 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 13:39:10  [ main:2407 ] - [ INFO ]  Running job: job_local2017355921_0002
2020-11-17 13:39:10  [ Thread-46:2408 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:39:10  [ Thread-46:2408 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 13:39:10  [ Thread-46:2417 ] - [ INFO ]  Waiting for map tasks
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2417 ] - [ INFO ]  Starting task: attempt_local2017355921_0002_m_000000_0
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2418 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2418 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2418 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2419 ] - [ INFO ]  Processing split: hdfs://master:9000/tmp1032070304/friend1605591547369/part-r-00000:0+142
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2471 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2471 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2471 ] - [ INFO ]  soft limit at 83886080
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2471 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2471 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2472 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2497 ] - [ INFO ]  
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2497 ] - [ INFO ]  Starting flush of map output
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2497 ] - [ INFO ]  Spilling map output
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2497 ] - [ INFO ]  bufstart = 0; bufend = 624; bufvoid = 104857600
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2497 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26213984(104855936); length = 413/6553600
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2499 ] - [ INFO ]  Finished spill 0
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2501 ] - [ INFO ]  Task:attempt_local2017355921_0002_m_000000_0 is done. And is in the process of committing
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2507 ] - [ INFO ]  map
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2507 ] - [ INFO ]  Task 'attempt_local2017355921_0002_m_000000_0' done.
2020-11-17 13:39:10  [ LocalJobRunner Map Task Executor #0:2508 ] - [ INFO ]  Finishing task: attempt_local2017355921_0002_m_000000_0
2020-11-17 13:39:10  [ Thread-46:2508 ] - [ INFO ]  map task executor complete.
2020-11-17 13:39:10  [ Thread-46:2508 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 13:39:10  [ pool-9-thread-1:2508 ] - [ INFO ]  Starting task: attempt_local2017355921_0002_r_000000_0
2020-11-17 13:39:10  [ pool-9-thread-1:2509 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 13:39:10  [ pool-9-thread-1:2510 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 13:39:10  [ pool-9-thread-1:2510 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 13:39:10  [ pool-9-thread-1:2510 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e985415
2020-11-17 13:39:10  [ pool-9-thread-1:2510 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 13:39:10  [ EventFetcher for fetching Map Completion Events:2511 ] - [ INFO ]  attempt_local2017355921_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 13:39:10  [ localfetcher#2:2512 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local2017355921_0002_m_000000_0 decomp: 834 len: 838 to MEMORY
2020-11-17 13:39:10  [ localfetcher#2:2512 ] - [ INFO ]  Read 834 bytes from map-output for attempt_local2017355921_0002_m_000000_0
2020-11-17 13:39:10  [ localfetcher#2:2512 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 834, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->834
2020-11-17 13:39:10  [ EventFetcher for fetching Map Completion Events:2512 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 13:39:10  [ pool-9-thread-1:2513 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:39:10  [ pool-9-thread-1:2513 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 13:39:10  [ pool-9-thread-1:2514 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:39:10  [ pool-9-thread-1:2514 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 828 bytes
2020-11-17 13:39:10  [ pool-9-thread-1:2515 ] - [ INFO ]  Merged 1 segments, 834 bytes to disk to satisfy reduce memory limit
2020-11-17 13:39:10  [ pool-9-thread-1:2516 ] - [ INFO ]  Merging 1 files, 838 bytes from disk
2020-11-17 13:39:10  [ pool-9-thread-1:2516 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 13:39:10  [ pool-9-thread-1:2516 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 13:39:10  [ pool-9-thread-1:2516 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 828 bytes
2020-11-17 13:39:10  [ pool-9-thread-1:2517 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:39:10  [ pool-9-thread-1:2603 ] - [ INFO ]  Task:attempt_local2017355921_0002_r_000000_0 is done. And is in the process of committing
2020-11-17 13:39:10  [ pool-9-thread-1:2615 ] - [ INFO ]  1 / 1 copied.
2020-11-17 13:39:10  [ pool-9-thread-1:2615 ] - [ INFO ]  Task attempt_local2017355921_0002_r_000000_0 is allowed to commit now
2020-11-17 13:39:10  [ pool-9-thread-1:2646 ] - [ INFO ]  Saved output of task 'attempt_local2017355921_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/findFriend/result2/_temporary/0/task_local2017355921_0002_r_000000
2020-11-17 13:39:10  [ pool-9-thread-1:2646 ] - [ INFO ]  reduce > reduce
2020-11-17 13:39:10  [ pool-9-thread-1:2646 ] - [ INFO ]  Task 'attempt_local2017355921_0002_r_000000_0' done.
2020-11-17 13:39:10  [ pool-9-thread-1:2646 ] - [ INFO ]  Finishing task: attempt_local2017355921_0002_r_000000_0
2020-11-17 13:39:10  [ Thread-46:2646 ] - [ INFO ]  reduce task executor complete.
2020-11-17 13:39:11  [ main:3410 ] - [ INFO ]  Job job_local2017355921_0002 running in uber mode : false
2020-11-17 13:39:11  [ main:3410 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 13:39:11  [ main:3410 ] - [ INFO ]  Job job_local2017355921_0002 completed successfully
2020-11-17 13:39:11  [ main:3413 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=3888
		FILE: Number of bytes written=1137102
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=568
		HDFS: Number of bytes written=692
		HDFS: Number of read operations=43
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=14
		Map output records=104
		Map output bytes=624
		Map output materialized bytes=838
		Input split bytes=130
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=838
		Reduce input records=104
		Reduce output records=50
		Spilled Records=208
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=844103680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=142
	File Output Format Counters 
		Bytes Written=408
2020-11-17 14:12:29  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 14:12:29  [ main:617 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 14:12:29  [ main:618 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 14:12:30  [ main:814 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 14:12:30  [ main:819 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 14:12:30  [ main:865 ] - [ INFO ]  Total input paths to process : 2
2020-11-17 14:12:30  [ main:914 ] - [ INFO ]  number of splits:2
2020-11-17 14:12:30  [ main:974 ] - [ INFO ]  Submitting tokens for job: job_local875237222_0001
2020-11-17 14:12:30  [ main:1062 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 14:12:30  [ main:1063 ] - [ INFO ]  Running job: job_local875237222_0001
2020-11-17 14:12:30  [ Thread-18:1063 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 14:12:30  [ Thread-18:1066 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:12:30  [ Thread-18:1068 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 14:12:30  [ Thread-18:1113 ] - [ INFO ]  Waiting for map tasks
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1114 ] - [ INFO ]  Starting task: attempt_local875237222_0001_m_000000_0
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1129 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1133 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1133 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1135 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/word_count/input/input.txt:0+120
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  soft limit at 83886080
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1189 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1191 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1284 ] - [ INFO ]  
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1286 ] - [ INFO ]  Starting flush of map output
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1286 ] - [ INFO ]  Spilling map output
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1286 ] - [ INFO ]  bufstart = 0; bufend = 280; bufvoid = 104857600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1286 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1292 ] - [ INFO ]  Finished spill 0
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1294 ] - [ INFO ]  Task:attempt_local875237222_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1306 ] - [ INFO ]  map
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1306 ] - [ INFO ]  Task 'attempt_local875237222_0001_m_000000_0' done.
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1306 ] - [ INFO ]  Finishing task: attempt_local875237222_0001_m_000000_0
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1307 ] - [ INFO ]  Starting task: attempt_local875237222_0001_m_000001_0
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1307 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1308 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1308 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1309 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/word_count/input/input1.txt:0+26
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1353 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1354 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1354 ] - [ INFO ]  soft limit at 83886080
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1354 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1354 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1354 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1380 ] - [ INFO ]  
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1380 ] - [ INFO ]  Starting flush of map output
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1380 ] - [ INFO ]  Spilling map output
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  bufstart = 0; bufend = 46; bufvoid = 104857600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1382 ] - [ INFO ]  Finished spill 0
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1383 ] - [ INFO ]  Task:attempt_local875237222_0001_m_000001_0 is done. And is in the process of committing
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1392 ] - [ INFO ]  map
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1392 ] - [ INFO ]  Task 'attempt_local875237222_0001_m_000001_0' done.
2020-11-17 14:12:30  [ LocalJobRunner Map Task Executor #0:1392 ] - [ INFO ]  Finishing task: attempt_local875237222_0001_m_000001_0
2020-11-17 14:12:30  [ Thread-18:1392 ] - [ INFO ]  map task executor complete.
2020-11-17 14:12:30  [ Thread-18:1394 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 14:12:30  [ pool-6-thread-1:1394 ] - [ INFO ]  Starting task: attempt_local875237222_0001_r_000000_0
2020-11-17 14:12:30  [ pool-6-thread-1:1398 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:12:30  [ pool-6-thread-1:1398 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:12:30  [ pool-6-thread-1:1398 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:12:30  [ pool-6-thread-1:1399 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73caf8be
2020-11-17 14:12:30  [ pool-6-thread-1:1407 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 14:12:30  [ EventFetcher for fetching Map Completion Events:1408 ] - [ INFO ]  attempt_local875237222_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 14:12:30  [ localfetcher#1:1427 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local875237222_0001_m_000000_0 decomp: 362 len: 366 to MEMORY
2020-11-17 14:12:30  [ localfetcher#1:1431 ] - [ INFO ]  Read 362 bytes from map-output for attempt_local875237222_0001_m_000000_0
2020-11-17 14:12:30  [ localfetcher#1:1432 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 362, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->362
2020-11-17 14:12:30  [ localfetcher#1:1433 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local875237222_0001_m_000001_0 decomp: 58 len: 62 to MEMORY
2020-11-17 14:12:30  [ localfetcher#1:1434 ] - [ INFO ]  Read 58 bytes from map-output for attempt_local875237222_0001_m_000001_0
2020-11-17 14:12:30  [ localfetcher#1:1434 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 58, inMemoryMapOutputs.size() -> 2, commitMemory -> 362, usedMemory ->420
2020-11-17 14:12:30  [ EventFetcher for fetching Map Completion Events:1434 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 14:12:30  [ pool-6-thread-1:1435 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:12:30  [ pool-6-thread-1:1435 ] - [ INFO ]  finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 14:12:30  [ pool-6-thread-1:1438 ] - [ INFO ]  Merging 2 sorted segments
2020-11-17 14:12:30  [ pool-6-thread-1:1439 ] - [ INFO ]  Down to the last merge-pass, with 2 segments left of total size: 407 bytes
2020-11-17 14:12:30  [ pool-6-thread-1:1440 ] - [ INFO ]  Merged 2 segments, 420 bytes to disk to satisfy reduce memory limit
2020-11-17 14:12:30  [ pool-6-thread-1:1440 ] - [ INFO ]  Merging 1 files, 422 bytes from disk
2020-11-17 14:12:30  [ pool-6-thread-1:1441 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 14:12:30  [ pool-6-thread-1:1441 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 14:12:30  [ pool-6-thread-1:1441 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 413 bytes
2020-11-17 14:12:30  [ pool-6-thread-1:1441 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:12:30  [ pool-6-thread-1:1465 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 14:12:30  [ pool-6-thread-1:1628 ] - [ INFO ]  Task:attempt_local875237222_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 14:12:30  [ pool-6-thread-1:1642 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:12:30  [ pool-6-thread-1:1642 ] - [ INFO ]  Task attempt_local875237222_0001_r_000000_0 is allowed to commit now
2020-11-17 14:12:30  [ pool-6-thread-1:1679 ] - [ INFO ]  Saved output of task 'attempt_local875237222_0001_r_000000_0' to hdfs://master:9000/user/root/mr/word_count/output/_temporary/0/task_local875237222_0001_r_000000
2020-11-17 14:12:30  [ pool-6-thread-1:1680 ] - [ INFO ]  reduce > reduce
2020-11-17 14:12:30  [ pool-6-thread-1:1680 ] - [ INFO ]  Task 'attempt_local875237222_0001_r_000000_0' done.
2020-11-17 14:12:30  [ pool-6-thread-1:1680 ] - [ INFO ]  Finishing task: attempt_local875237222_0001_r_000000_0
2020-11-17 14:12:30  [ Thread-18:1680 ] - [ INFO ]  reduce task executor complete.
2020-11-17 14:12:31  [ main:2068 ] - [ INFO ]  Job job_local875237222_0001 running in uber mode : false
2020-11-17 14:12:31  [ main:2069 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 14:12:31  [ main:2069 ] - [ INFO ]  Job job_local875237222_0001 completed successfully
2020-11-17 14:12:31  [ main:2076 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2373
		FILE: Number of bytes written=849847
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=412
		HDFS: Number of bytes written=77
		HDFS: Number of read operations=28
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=14
		Map output records=45
		Map output bytes=326
		Map output materialized bytes=428
		Input split bytes=247
		Combine input records=0
		Combine output records=0
		Reduce input groups=13
		Reduce shuffle bytes=428
		Reduce input records=45
		Reduce output records=13
		Spilled Records=90
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=1160773632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146
	File Output Format Counters 
		Bytes Written=77
2020-11-17 14:12:51  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 14:13:05  [ main:13419 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 14:13:05  [ main:13420 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 14:13:05  [ main:13640 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 14:13:05  [ main:13645 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 14:13:05  [ main:13695 ] - [ INFO ]  Total input paths to process : 2
2020-11-17 14:13:05  [ main:13748 ] - [ INFO ]  number of splits:2
2020-11-17 14:13:05  [ main:13810 ] - [ INFO ]  Submitting tokens for job: job_local1599100718_0001
2020-11-17 14:13:05  [ main:13904 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 14:13:05  [ main:13905 ] - [ INFO ]  Running job: job_local1599100718_0001
2020-11-17 14:13:05  [ Thread-19:13906 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 14:13:05  [ Thread-19:13910 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:13:05  [ Thread-19:13911 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 14:13:05  [ Thread-19:13956 ] - [ INFO ]  Waiting for map tasks
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:13957 ] - [ INFO ]  Starting task: attempt_local1599100718_0001_m_000000_0
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:13973 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:13977 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:13977 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:13979 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/word_count/input/input.txt:0+120
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:14031 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:14031 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:14032 ] - [ INFO ]  soft limit at 83886080
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:14032 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:14032 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 14:13:05  [ LocalJobRunner Map Task Executor #0:14033 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 14:13:06  [ main:14907 ] - [ INFO ]  Job job_local1599100718_0001 running in uber mode : false
2020-11-17 14:13:06  [ main:14908 ] - [ INFO ]   map 0% reduce 0%
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15167 ] - [ INFO ]  
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15168 ] - [ INFO ]  Starting flush of map output
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15168 ] - [ INFO ]  Spilling map output
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15168 ] - [ INFO ]  bufstart = 0; bufend = 280; bufvoid = 104857600
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15168 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15174 ] - [ INFO ]  Finished spill 0
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15177 ] - [ INFO ]  Task:attempt_local1599100718_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15192 ] - [ INFO ]  map
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15192 ] - [ INFO ]  Task 'attempt_local1599100718_0001_m_000000_0' done.
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15192 ] - [ INFO ]  Finishing task: attempt_local1599100718_0001_m_000000_0
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15192 ] - [ INFO ]  Starting task: attempt_local1599100718_0001_m_000001_0
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15193 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15194 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15194 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15195 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/word_count/input/input1.txt:0+26
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15240 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15240 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15240 ] - [ INFO ]  soft limit at 83886080
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15240 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15240 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 14:13:06  [ LocalJobRunner Map Task Executor #0:15241 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15263 ] - [ INFO ]  
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15263 ] - [ INFO ]  Starting flush of map output
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15263 ] - [ INFO ]  Spilling map output
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15263 ] - [ INFO ]  bufstart = 0; bufend = 46; bufvoid = 104857600
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15263 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15264 ] - [ INFO ]  Finished spill 0
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15266 ] - [ INFO ]  Task:attempt_local1599100718_0001_m_000001_0 is done. And is in the process of committing
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15278 ] - [ INFO ]  map
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15279 ] - [ INFO ]  Task 'attempt_local1599100718_0001_m_000001_0' done.
2020-11-17 14:13:07  [ LocalJobRunner Map Task Executor #0:15279 ] - [ INFO ]  Finishing task: attempt_local1599100718_0001_m_000001_0
2020-11-17 14:13:07  [ Thread-19:15279 ] - [ INFO ]  map task executor complete.
2020-11-17 14:13:07  [ Thread-19:15280 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 14:13:07  [ pool-6-thread-1:15281 ] - [ INFO ]  Starting task: attempt_local1599100718_0001_r_000000_0
2020-11-17 14:13:07  [ pool-6-thread-1:15285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:13:07  [ pool-6-thread-1:15285 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:13:07  [ pool-6-thread-1:15285 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:13:07  [ pool-6-thread-1:15287 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ee0441a
2020-11-17 14:13:07  [ pool-6-thread-1:15295 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 14:13:07  [ EventFetcher for fetching Map Completion Events:15296 ] - [ INFO ]  attempt_local1599100718_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 14:13:07  [ localfetcher#1:15317 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1599100718_0001_m_000000_0 decomp: 362 len: 366 to MEMORY
2020-11-17 14:13:07  [ localfetcher#1:15321 ] - [ INFO ]  Read 362 bytes from map-output for attempt_local1599100718_0001_m_000000_0
2020-11-17 14:13:07  [ localfetcher#1:15322 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 362, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->362
2020-11-17 14:13:07  [ localfetcher#1:15324 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1599100718_0001_m_000001_0 decomp: 58 len: 62 to MEMORY
2020-11-17 14:13:07  [ localfetcher#1:15324 ] - [ INFO ]  Read 58 bytes from map-output for attempt_local1599100718_0001_m_000001_0
2020-11-17 14:13:07  [ localfetcher#1:15324 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 58, inMemoryMapOutputs.size() -> 2, commitMemory -> 362, usedMemory ->420
2020-11-17 14:13:07  [ EventFetcher for fetching Map Completion Events:15325 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 14:13:07  [ pool-6-thread-1:15325 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:13:07  [ pool-6-thread-1:15325 ] - [ INFO ]  finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 14:13:07  [ pool-6-thread-1:15329 ] - [ INFO ]  Merging 2 sorted segments
2020-11-17 14:13:07  [ pool-6-thread-1:15329 ] - [ INFO ]  Down to the last merge-pass, with 2 segments left of total size: 407 bytes
2020-11-17 14:13:07  [ pool-6-thread-1:15331 ] - [ INFO ]  Merged 2 segments, 420 bytes to disk to satisfy reduce memory limit
2020-11-17 14:13:07  [ pool-6-thread-1:15331 ] - [ INFO ]  Merging 1 files, 422 bytes from disk
2020-11-17 14:13:07  [ pool-6-thread-1:15331 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 14:13:07  [ pool-6-thread-1:15331 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 14:13:07  [ pool-6-thread-1:15332 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 413 bytes
2020-11-17 14:13:07  [ pool-6-thread-1:15332 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:13:07  [ pool-6-thread-1:15359 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 14:13:07  [ pool-6-thread-1:15477 ] - [ INFO ]  Task:attempt_local1599100718_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 14:13:07  [ pool-6-thread-1:15489 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:13:07  [ pool-6-thread-1:15489 ] - [ INFO ]  Task attempt_local1599100718_0001_r_000000_0 is allowed to commit now
2020-11-17 14:13:07  [ pool-6-thread-1:15528 ] - [ INFO ]  Saved output of task 'attempt_local1599100718_0001_r_000000_0' to hdfs://master:9000/user/root/mr/word_count/output/_temporary/0/task_local1599100718_0001_r_000000
2020-11-17 14:13:07  [ pool-6-thread-1:15529 ] - [ INFO ]  reduce > reduce
2020-11-17 14:13:07  [ pool-6-thread-1:15529 ] - [ INFO ]  Task 'attempt_local1599100718_0001_r_000000_0' done.
2020-11-17 14:13:07  [ pool-6-thread-1:15529 ] - [ INFO ]  Finishing task: attempt_local1599100718_0001_r_000000_0
2020-11-17 14:13:07  [ Thread-19:15529 ] - [ INFO ]  reduce task executor complete.
2020-11-17 14:13:07  [ main:15913 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 14:13:07  [ main:15913 ] - [ INFO ]  Job job_local1599100718_0001 completed successfully
2020-11-17 14:13:07  [ main:15923 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2373
		FILE: Number of bytes written=854395
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=412
		HDFS: Number of bytes written=77
		HDFS: Number of read operations=28
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=14
		Map output records=45
		Map output bytes=326
		Map output materialized bytes=428
		Input split bytes=247
		Combine input records=0
		Combine output records=0
		Reduce input groups=13
		Reduce shuffle bytes=428
		Reduce input records=45
		Reduce output records=13
		Spilled Records=90
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1003487232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146
	File Output Format Counters 
		Bytes Written=77
2020-11-17 14:13:59  [ main:1 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-17 14:14:06  [ main:7195 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-17 14:14:06  [ main:7196 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-17 14:14:07  [ main:7427 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-17 14:14:07  [ main:7432 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-17 14:14:07  [ main:7482 ] - [ INFO ]  Total input paths to process : 2
2020-11-17 14:14:07  [ main:7534 ] - [ INFO ]  number of splits:2
2020-11-17 14:14:07  [ main:7600 ] - [ INFO ]  Submitting tokens for job: job_local1582528617_0001
2020-11-17 14:14:07  [ main:7694 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-17 14:14:07  [ main:7695 ] - [ INFO ]  Running job: job_local1582528617_0001
2020-11-17 14:14:07  [ Thread-18:7696 ] - [ INFO ]  OutputCommitter set in config null
2020-11-17 14:14:07  [ Thread-18:7700 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:14:07  [ Thread-18:7702 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-17 14:14:07  [ Thread-18:7748 ] - [ INFO ]  Waiting for map tasks
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7749 ] - [ INFO ]  Starting task: attempt_local1582528617_0001_m_000000_0
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7765 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7770 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7770 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7772 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/word_count/input/input.txt:0+120
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7823 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7823 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7823 ] - [ INFO ]  soft limit at 83886080
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7823 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7823 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7826 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7953 ] - [ INFO ]  
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7955 ] - [ INFO ]  Starting flush of map output
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7955 ] - [ INFO ]  Spilling map output
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7955 ] - [ INFO ]  bufstart = 0; bufend = 280; bufvoid = 104857600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7955 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7961 ] - [ INFO ]  Finished spill 0
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:7964 ] - [ INFO ]  Task:attempt_local1582528617_0001_m_000000_0 is done. And is in the process of committing
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8016 ] - [ INFO ]  map
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8016 ] - [ INFO ]  Task 'attempt_local1582528617_0001_m_000000_0' done.
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8016 ] - [ INFO ]  Finishing task: attempt_local1582528617_0001_m_000000_0
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8016 ] - [ INFO ]  Starting task: attempt_local1582528617_0001_m_000001_0
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8017 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8018 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8018 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8019 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/word_count/input/input1.txt:0+26
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8061 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8061 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8061 ] - [ INFO ]  soft limit at 83886080
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8061 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8061 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8061 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8081 ] - [ INFO ]  
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8082 ] - [ INFO ]  Starting flush of map output
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8082 ] - [ INFO ]  Spilling map output
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8082 ] - [ INFO ]  bufstart = 0; bufend = 46; bufvoid = 104857600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8082 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8083 ] - [ INFO ]  Finished spill 0
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8084 ] - [ INFO ]  Task:attempt_local1582528617_0001_m_000001_0 is done. And is in the process of committing
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8095 ] - [ INFO ]  map
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8095 ] - [ INFO ]  Task 'attempt_local1582528617_0001_m_000001_0' done.
2020-11-17 14:14:07  [ LocalJobRunner Map Task Executor #0:8095 ] - [ INFO ]  Finishing task: attempt_local1582528617_0001_m_000001_0
2020-11-17 14:14:07  [ Thread-18:8095 ] - [ INFO ]  map task executor complete.
2020-11-17 14:14:07  [ Thread-18:8097 ] - [ INFO ]  Waiting for reduce tasks
2020-11-17 14:14:07  [ pool-6-thread-1:8097 ] - [ INFO ]  Starting task: attempt_local1582528617_0001_r_000000_0
2020-11-17 14:14:07  [ pool-6-thread-1:8102 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-17 14:14:07  [ pool-6-thread-1:8102 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-17 14:14:07  [ pool-6-thread-1:8102 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-17 14:14:07  [ pool-6-thread-1:8104 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35ccf437
2020-11-17 14:14:07  [ pool-6-thread-1:8111 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-17 14:14:07  [ EventFetcher for fetching Map Completion Events:8113 ] - [ INFO ]  attempt_local1582528617_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-17 14:14:07  [ localfetcher#1:8132 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1582528617_0001_m_000001_0 decomp: 58 len: 62 to MEMORY
2020-11-17 14:14:07  [ localfetcher#1:8136 ] - [ INFO ]  Read 58 bytes from map-output for attempt_local1582528617_0001_m_000001_0
2020-11-17 14:14:07  [ localfetcher#1:8137 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 58, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->58
2020-11-17 14:14:07  [ localfetcher#1:8139 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1582528617_0001_m_000000_0 decomp: 362 len: 366 to MEMORY
2020-11-17 14:14:07  [ localfetcher#1:8139 ] - [ INFO ]  Read 362 bytes from map-output for attempt_local1582528617_0001_m_000000_0
2020-11-17 14:14:07  [ localfetcher#1:8139 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 362, inMemoryMapOutputs.size() -> 2, commitMemory -> 58, usedMemory ->420
2020-11-17 14:14:07  [ EventFetcher for fetching Map Completion Events:8140 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-17 14:14:07  [ pool-6-thread-1:8140 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:14:07  [ pool-6-thread-1:8140 ] - [ INFO ]  finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2020-11-17 14:14:07  [ pool-6-thread-1:8144 ] - [ INFO ]  Merging 2 sorted segments
2020-11-17 14:14:07  [ pool-6-thread-1:8145 ] - [ INFO ]  Down to the last merge-pass, with 2 segments left of total size: 407 bytes
2020-11-17 14:14:07  [ pool-6-thread-1:8146 ] - [ INFO ]  Merged 2 segments, 420 bytes to disk to satisfy reduce memory limit
2020-11-17 14:14:07  [ pool-6-thread-1:8146 ] - [ INFO ]  Merging 1 files, 422 bytes from disk
2020-11-17 14:14:07  [ pool-6-thread-1:8147 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-17 14:14:07  [ pool-6-thread-1:8147 ] - [ INFO ]  Merging 1 sorted segments
2020-11-17 14:14:07  [ pool-6-thread-1:8147 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 413 bytes
2020-11-17 14:14:07  [ pool-6-thread-1:8147 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:14:07  [ pool-6-thread-1:8173 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-17 14:14:27  [ main:28135 ] - [ INFO ]  Job job_local1582528617_0001 running in uber mode : false
2020-11-17 14:14:27  [ main:28137 ] - [ INFO ]   map 100% reduce 0%
2020-11-17 14:14:27  [ pool-6-thread-1:28262 ] - [ INFO ]  Task:attempt_local1582528617_0001_r_000000_0 is done. And is in the process of committing
2020-11-17 14:14:27  [ pool-6-thread-1:28273 ] - [ INFO ]  2 / 2 copied.
2020-11-17 14:14:27  [ pool-6-thread-1:28273 ] - [ INFO ]  Task attempt_local1582528617_0001_r_000000_0 is allowed to commit now
2020-11-17 14:14:27  [ pool-6-thread-1:28345 ] - [ INFO ]  Saved output of task 'attempt_local1582528617_0001_r_000000_0' to hdfs://master:9000/user/root/mr/word_count/output/_temporary/0/task_local1582528617_0001_r_000000
2020-11-17 14:14:27  [ pool-6-thread-1:28345 ] - [ INFO ]  reduce > reduce
2020-11-17 14:14:27  [ pool-6-thread-1:28346 ] - [ INFO ]  Task 'attempt_local1582528617_0001_r_000000_0' done.
2020-11-17 14:14:27  [ pool-6-thread-1:28346 ] - [ INFO ]  Finishing task: attempt_local1582528617_0001_r_000000_0
2020-11-17 14:14:27  [ Thread-18:28346 ] - [ INFO ]  reduce task executor complete.
2020-11-17 14:14:28  [ main:29138 ] - [ INFO ]   map 100% reduce 100%
2020-11-17 14:14:28  [ main:29138 ] - [ INFO ]  Job job_local1582528617_0001 completed successfully
2020-11-17 14:14:28  [ main:29146 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2373
		FILE: Number of bytes written=854395
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=412
		HDFS: Number of bytes written=77
		HDFS: Number of read operations=28
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=14
		Map output records=45
		Map output bytes=326
		Map output materialized bytes=428
		Input split bytes=247
		Combine input records=0
		Combine output records=0
		Reduce input groups=13
		Reduce shuffle bytes=428
		Reduce input records=45
		Reduce output records=13
		Spilled Records=90
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1030225920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146
	File Output Format Counters 
		Bytes Written=77
