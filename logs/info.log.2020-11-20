2020-11-20 10:53:32  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 11:32:19  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 11:32:42  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 11:32:42  [ main:670 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 11:32:42  [ main:671 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 11:32:43  [ main:888 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 11:32:43  [ main:895 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 11:32:43  [ main:925 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 11:32:43  [ main:1039 ] - [ INFO ]  number of splits:1
2020-11-20 11:32:43  [ main:1112 ] - [ INFO ]  Submitting tokens for job: job_local279289326_0001
2020-11-20 11:32:43  [ main:1201 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 11:32:43  [ main:1201 ] - [ INFO ]  Running job: job_local279289326_0001
2020-11-20 11:32:43  [ Thread-18:1202 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 11:32:43  [ Thread-18:1206 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:32:43  [ Thread-18:1208 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 11:32:43  [ Thread-18:1274 ] - [ INFO ]  Waiting for map tasks
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1275 ] - [ INFO ]  Starting task: attempt_local279289326_0001_m_000000_0
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1295 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1301 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1301 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1303 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/test.txt:0+189066
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1369 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1369 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1369 ] - [ INFO ]  soft limit at 83886080
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1369 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1369 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 11:32:43  [ LocalJobRunner Map Task Executor #0:1373 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1935 ] - [ INFO ]  
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1937 ] - [ INFO ]  Starting flush of map output
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1937 ] - [ INFO ]  Spilling map output
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1938 ] - [ INFO ]  bufstart = 0; bufend = 29142; bufvoid = 104857600
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1938 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26174096(104696384); length = 40301/6553600
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1971 ] - [ INFO ]  Finished spill 0
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1975 ] - [ INFO ]  Task:attempt_local279289326_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1990 ] - [ INFO ]  map
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1990 ] - [ INFO ]  Task 'attempt_local279289326_0001_m_000000_0' done.
2020-11-20 11:32:44  [ LocalJobRunner Map Task Executor #0:1991 ] - [ INFO ]  Finishing task: attempt_local279289326_0001_m_000000_0
2020-11-20 11:32:44  [ Thread-18:1991 ] - [ INFO ]  map task executor complete.
2020-11-20 11:32:44  [ Thread-18:1992 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 11:32:44  [ pool-6-thread-1:1993 ] - [ INFO ]  Starting task: attempt_local279289326_0001_r_000000_0
2020-11-20 11:32:44  [ pool-6-thread-1:1997 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:32:44  [ pool-6-thread-1:1997 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:32:44  [ pool-6-thread-1:1998 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:32:44  [ pool-6-thread-1:2000 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2867558f
2020-11-20 11:32:44  [ pool-6-thread-1:2009 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 11:32:44  [ EventFetcher for fetching Map Completion Events:2011 ] - [ INFO ]  attempt_local279289326_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 11:32:44  [ localfetcher#1:2031 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local279289326_0001_m_000000_0 decomp: 500 len: 504 to MEMORY
2020-11-20 11:32:44  [ localfetcher#1:2035 ] - [ INFO ]  Read 500 bytes from map-output for attempt_local279289326_0001_m_000000_0
2020-11-20 11:32:44  [ localfetcher#1:2036 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 500, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->500
2020-11-20 11:32:44  [ EventFetcher for fetching Map Completion Events:2037 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 11:32:44  [ pool-6-thread-1:2038 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:32:44  [ pool-6-thread-1:2038 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 11:32:44  [ pool-6-thread-1:2043 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:32:44  [ pool-6-thread-1:2043 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 496 bytes
2020-11-20 11:32:44  [ pool-6-thread-1:2044 ] - [ INFO ]  Merged 1 segments, 500 bytes to disk to satisfy reduce memory limit
2020-11-20 11:32:44  [ pool-6-thread-1:2044 ] - [ INFO ]  Merging 1 files, 504 bytes from disk
2020-11-20 11:32:44  [ pool-6-thread-1:2044 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 11:32:44  [ pool-6-thread-1:2044 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:32:44  [ pool-6-thread-1:2045 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 496 bytes
2020-11-20 11:32:44  [ pool-6-thread-1:2045 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:32:44  [ pool-6-thread-1:2069 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 11:32:44  [ pool-6-thread-1:2172 ] - [ INFO ]  Task:attempt_local279289326_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 11:32:44  [ pool-6-thread-1:2182 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:32:44  [ pool-6-thread-1:2182 ] - [ INFO ]  Task attempt_local279289326_0001_r_000000_0 is allowed to commit now
2020-11-20 11:32:44  [ main:2206 ] - [ INFO ]  Job job_local279289326_0001 running in uber mode : false
2020-11-20 11:32:44  [ main:2207 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 11:32:44  [ pool-6-thread-1:2213 ] - [ INFO ]  Saved output of task 'attempt_local279289326_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605843161662/_temporary/0/task_local279289326_0001_r_000000
2020-11-20 11:32:44  [ pool-6-thread-1:2213 ] - [ INFO ]  reduce > reduce
2020-11-20 11:32:44  [ pool-6-thread-1:2213 ] - [ INFO ]  Task 'attempt_local279289326_0001_r_000000_0' done.
2020-11-20 11:32:44  [ pool-6-thread-1:2213 ] - [ INFO ]  Finishing task: attempt_local279289326_0001_r_000000_0
2020-11-20 11:32:44  [ Thread-18:2213 ] - [ INFO ]  reduce task executor complete.
2020-11-20 11:32:45  [ main:3209 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 11:32:45  [ main:3209 ] - [ INFO ]  Job job_local279289326_0001 completed successfully
2020-11-20 11:32:45  [ main:3216 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1374
		FILE: Number of bytes written=568282
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=378132
		HDFS: Number of bytes written=296
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=10076
		Map output records=10076
		Map output bytes=29142
		Map output materialized bytes=504
		Input split bytes=113
		Combine input records=10076
		Combine output records=101
		Reduce input groups=101
		Reduce shuffle bytes=504
		Reduce input records=101
		Reduce output records=101
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189066
	File Output Format Counters 
		Bytes Written=296
2020-11-20 11:32:45  [ main:3388 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 11:32:45  [ main:3406 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 11:32:45  [ main:3411 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 11:32:45  [ main:3420 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 11:32:45  [ main:3467 ] - [ INFO ]  number of splits:1
2020-11-20 11:32:45  [ main:3486 ] - [ INFO ]  Submitting tokens for job: job_local1322323031_0002
2020-11-20 11:32:45  [ main:3531 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 11:32:45  [ main:3531 ] - [ INFO ]  Running job: job_local1322323031_0002
2020-11-20 11:32:45  [ Thread-48:3531 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 11:32:45  [ Thread-48:3531 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:32:45  [ Thread-48:3531 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 11:32:45  [ Thread-48:3545 ] - [ INFO ]  Waiting for map tasks
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3545 ] - [ INFO ]  Starting task: attempt_local1322323031_0002_m_000000_0
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3545 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3546 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3546 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3546 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/test.txt:0+189066
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3590 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3590 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3590 ] - [ INFO ]  soft limit at 83886080
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3590 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3590 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 11:32:45  [ LocalJobRunner Map Task Executor #0:3590 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4034 ] - [ INFO ]  
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4034 ] - [ INFO ]  Starting flush of map output
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4034 ] - [ INFO ]  Spilling map output
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4034 ] - [ INFO ]  bufstart = 0; bufend = 39013; bufvoid = 104857600
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4034 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26174096(104696384); length = 40301/6553600
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4046 ] - [ INFO ]  Finished spill 0
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4047 ] - [ INFO ]  Task:attempt_local1322323031_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4066 ] - [ INFO ]  map
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4066 ] - [ INFO ]  Task 'attempt_local1322323031_0002_m_000000_0' done.
2020-11-20 11:32:46  [ LocalJobRunner Map Task Executor #0:4067 ] - [ INFO ]  Finishing task: attempt_local1322323031_0002_m_000000_0
2020-11-20 11:32:46  [ Thread-48:4067 ] - [ INFO ]  map task executor complete.
2020-11-20 11:32:46  [ Thread-48:4067 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 11:32:46  [ pool-9-thread-1:4067 ] - [ INFO ]  Starting task: attempt_local1322323031_0002_r_000000_0
2020-11-20 11:32:46  [ pool-9-thread-1:4068 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:32:46  [ pool-9-thread-1:4069 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:32:46  [ pool-9-thread-1:4069 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:32:46  [ pool-9-thread-1:4069 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2f772a33
2020-11-20 11:32:46  [ pool-9-thread-1:4069 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 11:32:46  [ EventFetcher for fetching Map Completion Events:4070 ] - [ INFO ]  attempt_local1322323031_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 11:32:46  [ localfetcher#2:4071 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1322323031_0002_m_000000_0 decomp: 7451 len: 7455 to MEMORY
2020-11-20 11:32:46  [ localfetcher#2:4071 ] - [ INFO ]  Read 7451 bytes from map-output for attempt_local1322323031_0002_m_000000_0
2020-11-20 11:32:46  [ localfetcher#2:4071 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 7451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7451
2020-11-20 11:32:46  [ EventFetcher for fetching Map Completion Events:4071 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 11:32:46  [ pool-9-thread-1:4072 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:32:46  [ pool-9-thread-1:4072 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 11:32:46  [ pool-9-thread-1:4073 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:32:46  [ pool-9-thread-1:4073 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 7447 bytes
2020-11-20 11:32:46  [ pool-9-thread-1:4076 ] - [ INFO ]  Merged 1 segments, 7451 bytes to disk to satisfy reduce memory limit
2020-11-20 11:32:46  [ pool-9-thread-1:4076 ] - [ INFO ]  Merging 1 files, 7455 bytes from disk
2020-11-20 11:32:46  [ pool-9-thread-1:4076 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 11:32:46  [ pool-9-thread-1:4076 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:32:46  [ pool-9-thread-1:4076 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 7447 bytes
2020-11-20 11:32:46  [ pool-9-thread-1:4077 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:32:46  [ pool-9-thread-1:4176 ] - [ INFO ]  Task:attempt_local1322323031_0002_r_000000_0 is done. And is in the process of committing
2020-11-20 11:32:46  [ pool-9-thread-1:4189 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:32:46  [ pool-9-thread-1:4189 ] - [ INFO ]  Task attempt_local1322323031_0002_r_000000_0 is allowed to commit now
2020-11-20 11:32:46  [ pool-9-thread-1:4224 ] - [ INFO ]  Saved output of task 'attempt_local1322323031_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/item/_temporary/0/task_local1322323031_0002_r_000000
2020-11-20 11:32:46  [ pool-9-thread-1:4225 ] - [ INFO ]  reduce > reduce
2020-11-20 11:32:46  [ pool-9-thread-1:4225 ] - [ INFO ]  Task 'attempt_local1322323031_0002_r_000000_0' done.
2020-11-20 11:32:46  [ pool-9-thread-1:4226 ] - [ INFO ]  Finishing task: attempt_local1322323031_0002_r_000000_0
2020-11-20 11:32:46  [ Thread-48:4226 ] - [ INFO ]  reduce task executor complete.
2020-11-20 11:32:46  [ main:4536 ] - [ INFO ]  Job job_local1322323031_0002 running in uber mode : false
2020-11-20 11:32:46  [ main:4536 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 11:32:46  [ main:4536 ] - [ INFO ]  Job job_local1322323031_0002 completed successfully
2020-11-20 11:32:46  [ main:4542 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=17690
		FILE: Number of bytes written=1160957
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=756856
		HDFS: Number of bytes written=6189
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=10076
		Map output records=10076
		Map output bytes=39013
		Map output materialized bytes=7455
		Input split bytes=113
		Combine input records=10076
		Combine output records=1222
		Reduce input groups=1222
		Reduce shuffle bytes=7455
		Reduce input records=1222
		Reduce output records=1222
		Spilled Records=2444
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189066
	File Output Format Counters 
		Bytes Written=5005
2020-11-20 11:46:37  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 11:46:38  [ main:1020 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 11:46:38  [ main:1021 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 11:46:38  [ main:1400 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 11:46:38  [ main:1404 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 11:46:39  [ main:2062 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 11:46:39  [ main:2266 ] - [ INFO ]  number of splits:1
2020-11-20 11:46:39  [ main:2329 ] - [ INFO ]  Submitting tokens for job: job_local1420899030_0001
2020-11-20 11:46:39  [ main:2412 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 11:46:39  [ main:2412 ] - [ INFO ]  Running job: job_local1420899030_0001
2020-11-20 11:46:39  [ Thread-18:2413 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 11:46:39  [ Thread-18:2417 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:46:39  [ Thread-18:2418 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 11:46:40  [ Thread-18:2501 ] - [ INFO ]  Waiting for map tasks
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2501 ] - [ INFO ]  Starting task: attempt_local1420899030_0001_m_000000_0
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2520 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2526 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2526 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2528 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/test.txt:0+189066
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2578 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2578 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2578 ] - [ INFO ]  soft limit at 83886080
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2578 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2578 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 11:46:40  [ LocalJobRunner Map Task Executor #0:2581 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 11:46:40  [ main:3414 ] - [ INFO ]  Job job_local1420899030_0001 running in uber mode : false
2020-11-20 11:46:40  [ main:3416 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3784 ] - [ INFO ]  
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3786 ] - [ INFO ]  Starting flush of map output
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3786 ] - [ INFO ]  Spilling map output
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3786 ] - [ INFO ]  bufstart = 0; bufend = 29142; bufvoid = 104857600
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3786 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26174096(104696384); length = 40301/6553600
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3822 ] - [ INFO ]  Finished spill 0
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3826 ] - [ INFO ]  Task:attempt_local1420899030_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3846 ] - [ INFO ]  map
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3846 ] - [ INFO ]  Task 'attempt_local1420899030_0001_m_000000_0' done.
2020-11-20 11:46:41  [ LocalJobRunner Map Task Executor #0:3846 ] - [ INFO ]  Finishing task: attempt_local1420899030_0001_m_000000_0
2020-11-20 11:46:41  [ Thread-18:3846 ] - [ INFO ]  map task executor complete.
2020-11-20 11:46:41  [ Thread-18:3848 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 11:46:41  [ pool-6-thread-1:3848 ] - [ INFO ]  Starting task: attempt_local1420899030_0001_r_000000_0
2020-11-20 11:46:41  [ pool-6-thread-1:3852 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:46:41  [ pool-6-thread-1:3853 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:46:41  [ pool-6-thread-1:3853 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:46:41  [ pool-6-thread-1:3855 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4043b80
2020-11-20 11:46:41  [ pool-6-thread-1:3863 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 11:46:41  [ EventFetcher for fetching Map Completion Events:3865 ] - [ INFO ]  attempt_local1420899030_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 11:46:41  [ localfetcher#1:3885 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1420899030_0001_m_000000_0 decomp: 500 len: 504 to MEMORY
2020-11-20 11:46:41  [ localfetcher#1:3888 ] - [ INFO ]  Read 500 bytes from map-output for attempt_local1420899030_0001_m_000000_0
2020-11-20 11:46:41  [ localfetcher#1:3889 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 500, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->500
2020-11-20 11:46:41  [ EventFetcher for fetching Map Completion Events:3890 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 11:46:41  [ pool-6-thread-1:3891 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:46:41  [ pool-6-thread-1:3891 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 11:46:41  [ pool-6-thread-1:3896 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:46:41  [ pool-6-thread-1:3896 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 496 bytes
2020-11-20 11:46:41  [ pool-6-thread-1:3897 ] - [ INFO ]  Merged 1 segments, 500 bytes to disk to satisfy reduce memory limit
2020-11-20 11:46:41  [ pool-6-thread-1:3897 ] - [ INFO ]  Merging 1 files, 504 bytes from disk
2020-11-20 11:46:41  [ pool-6-thread-1:3898 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 11:46:41  [ pool-6-thread-1:3898 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:46:41  [ pool-6-thread-1:3898 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 496 bytes
2020-11-20 11:46:41  [ pool-6-thread-1:3899 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:46:41  [ pool-6-thread-1:3933 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 11:46:41  [ pool-6-thread-1:4289 ] - [ INFO ]  Task:attempt_local1420899030_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 11:46:41  [ pool-6-thread-1:4313 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:46:41  [ pool-6-thread-1:4313 ] - [ INFO ]  Task attempt_local1420899030_0001_r_000000_0 is allowed to commit now
2020-11-20 11:46:41  [ pool-6-thread-1:4405 ] - [ INFO ]  Saved output of task 'attempt_local1420899030_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605843997101/_temporary/0/task_local1420899030_0001_r_000000
2020-11-20 11:46:41  [ pool-6-thread-1:4406 ] - [ INFO ]  reduce > reduce
2020-11-20 11:46:41  [ pool-6-thread-1:4406 ] - [ INFO ]  Task 'attempt_local1420899030_0001_r_000000_0' done.
2020-11-20 11:46:41  [ pool-6-thread-1:4407 ] - [ INFO ]  Finishing task: attempt_local1420899030_0001_r_000000_0
2020-11-20 11:46:41  [ Thread-18:4407 ] - [ INFO ]  reduce task executor complete.
2020-11-20 11:46:41  [ main:4419 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 11:46:42  [ main:5423 ] - [ INFO ]  Job job_local1420899030_0001 completed successfully
2020-11-20 11:46:42  [ main:5433 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1374
		FILE: Number of bytes written=571322
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=378132
		HDFS: Number of bytes written=296
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=10076
		Map output records=10076
		Map output bytes=29142
		Map output materialized bytes=504
		Input split bytes=113
		Combine input records=10076
		Combine output records=101
		Reduce input groups=101
		Reduce shuffle bytes=504
		Reduce input records=101
		Reduce output records=101
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=63
		Total committed heap usage (bytes)=774897664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189066
	File Output Format Counters 
		Bytes Written=296
2020-11-20 11:46:46  [ main:8632 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 11:46:46  [ main:8713 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 11:46:46  [ main:8718 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 11:46:46  [ main:8812 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 11:46:46  [ main:8905 ] - [ INFO ]  number of splits:1
2020-11-20 11:46:46  [ main:8925 ] - [ INFO ]  Submitting tokens for job: job_local1419969814_0002
2020-11-20 11:46:46  [ main:8970 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 11:46:46  [ main:8970 ] - [ INFO ]  Running job: job_local1419969814_0002
2020-11-20 11:46:46  [ Thread-48:8970 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 11:46:46  [ Thread-48:8970 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:46:46  [ Thread-48:8971 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 11:46:46  [ Thread-48:8995 ] - [ INFO ]  Waiting for map tasks
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:8995 ] - [ INFO ]  Starting task: attempt_local1419969814_0002_m_000000_0
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:8996 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:8997 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:8997 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:8998 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/test.txt:0+189066
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:9034 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:9035 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:9035 ] - [ INFO ]  soft limit at 83886080
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:9035 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:9035 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 11:46:46  [ LocalJobRunner Map Task Executor #0:9035 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 11:46:47  [ main:9975 ] - [ INFO ]  Job job_local1419969814_0002 running in uber mode : false
2020-11-20 11:46:47  [ main:9976 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10452 ] - [ INFO ]  
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10452 ] - [ INFO ]  Starting flush of map output
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10452 ] - [ INFO ]  Spilling map output
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10452 ] - [ INFO ]  bufstart = 0; bufend = 39013; bufvoid = 104857600
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10452 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26174096(104696384); length = 40301/6553600
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10465 ] - [ INFO ]  Finished spill 0
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10466 ] - [ INFO ]  Task:attempt_local1419969814_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10944 ] - [ INFO ]  map
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10944 ] - [ INFO ]  Task 'attempt_local1419969814_0002_m_000000_0' done.
2020-11-20 11:46:48  [ LocalJobRunner Map Task Executor #0:10945 ] - [ INFO ]  Finishing task: attempt_local1419969814_0002_m_000000_0
2020-11-20 11:46:48  [ Thread-48:10945 ] - [ INFO ]  map task executor complete.
2020-11-20 11:46:48  [ Thread-48:10946 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 11:46:48  [ pool-9-thread-1:10946 ] - [ INFO ]  Starting task: attempt_local1419969814_0002_r_000000_0
2020-11-20 11:46:48  [ pool-9-thread-1:10947 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 11:46:48  [ pool-9-thread-1:10947 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 11:46:48  [ pool-9-thread-1:10948 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 11:46:48  [ pool-9-thread-1:10948 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5bc233d4
2020-11-20 11:46:48  [ pool-9-thread-1:10948 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 11:46:48  [ EventFetcher for fetching Map Completion Events:10949 ] - [ INFO ]  attempt_local1419969814_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 11:46:48  [ localfetcher#2:10950 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1419969814_0002_m_000000_0 decomp: 7451 len: 7455 to MEMORY
2020-11-20 11:46:48  [ localfetcher#2:10950 ] - [ INFO ]  Read 7451 bytes from map-output for attempt_local1419969814_0002_m_000000_0
2020-11-20 11:46:48  [ localfetcher#2:10951 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 7451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7451
2020-11-20 11:46:48  [ EventFetcher for fetching Map Completion Events:10951 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 11:46:48  [ pool-9-thread-1:10951 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:46:48  [ pool-9-thread-1:10952 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 11:46:48  [ pool-9-thread-1:10952 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:46:48  [ pool-9-thread-1:10953 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 7447 bytes
2020-11-20 11:46:48  [ pool-9-thread-1:10956 ] - [ INFO ]  Merged 1 segments, 7451 bytes to disk to satisfy reduce memory limit
2020-11-20 11:46:48  [ pool-9-thread-1:10957 ] - [ INFO ]  Merging 1 files, 7455 bytes from disk
2020-11-20 11:46:48  [ pool-9-thread-1:10957 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 11:46:48  [ pool-9-thread-1:10957 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 11:46:48  [ pool-9-thread-1:10957 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 7447 bytes
2020-11-20 11:46:48  [ pool-9-thread-1:10957 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:46:48  [ main:10981 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 11:46:48  [ pool-9-thread-1:11418 ] - [ INFO ]  Task:attempt_local1419969814_0002_r_000000_0 is done. And is in the process of committing
2020-11-20 11:46:49  [ pool-9-thread-1:11449 ] - [ INFO ]  1 / 1 copied.
2020-11-20 11:46:49  [ pool-9-thread-1:11450 ] - [ INFO ]  Task attempt_local1419969814_0002_r_000000_0 is allowed to commit now
2020-11-20 11:46:49  [ pool-9-thread-1:11484 ] - [ INFO ]  Saved output of task 'attempt_local1419969814_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/item/_temporary/0/task_local1419969814_0002_r_000000
2020-11-20 11:46:49  [ pool-9-thread-1:11486 ] - [ INFO ]  reduce > reduce
2020-11-20 11:46:49  [ pool-9-thread-1:11486 ] - [ INFO ]  Task 'attempt_local1419969814_0002_r_000000_0' done.
2020-11-20 11:46:49  [ pool-9-thread-1:11486 ] - [ INFO ]  Finishing task: attempt_local1419969814_0002_r_000000_0
2020-11-20 11:46:49  [ Thread-48:11486 ] - [ INFO ]  reduce task executor complete.
2020-11-20 11:46:49  [ main:11987 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 11:46:49  [ main:11987 ] - [ INFO ]  Job job_local1419969814_0002 completed successfully
2020-11-20 11:46:49  [ main:11992 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=17690
		FILE: Number of bytes written=1163997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=756856
		HDFS: Number of bytes written=6189
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=10076
		Map output records=10076
		Map output bytes=39013
		Map output materialized bytes=7455
		Input split bytes=113
		Combine input records=10076
		Combine output records=1222
		Reduce input groups=1222
		Reduce shuffle bytes=7455
		Reduce input records=1222
		Reduce output records=1222
		Spilled Records=2444
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=774897664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189066
	File Output Format Counters 
		Bytes Written=5005
2020-11-20 12:39:55  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 12:39:57  [ main:1131 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 12:39:57  [ main:1132 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 12:39:57  [ main:1366 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:39:57  [ main:1373 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:39:57  [ main:1405 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:39:57  [ main:1494 ] - [ INFO ]  number of splits:1
2020-11-20 12:39:57  [ main:1565 ] - [ INFO ]  Submitting tokens for job: job_local1872961024_0001
2020-11-20 12:39:57  [ main:1662 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:39:57  [ main:1662 ] - [ INFO ]  Running job: job_local1872961024_0001
2020-11-20 12:39:57  [ Thread-18:1663 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:39:57  [ Thread-18:1668 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:39:57  [ Thread-18:1670 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:39:57  [ Thread-18:1970 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:1970 ] - [ INFO ]  Starting task: attempt_local1872961024_0001_m_000000_0
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:1989 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:1995 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:1995 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:1997 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/test.txt:0+189066
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:2049 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:2049 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:2049 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:2049 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:2049 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:39:57  [ LocalJobRunner Map Task Executor #0:2052 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:39:58  [ main:2664 ] - [ INFO ]  Job job_local1872961024_0001 running in uber mode : false
2020-11-20 12:39:58  [ main:2666 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4730 ] - [ INFO ]  
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4732 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4732 ] - [ INFO ]  Spilling map output
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4732 ] - [ INFO ]  bufstart = 0; bufend = 99469; bufvoid = 104857600
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4732 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26174096(104696384); length = 40301/6553600
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4801 ] - [ INFO ]  Finished spill 0
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4805 ] - [ INFO ]  Task:attempt_local1872961024_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4908 ] - [ INFO ]  map
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4908 ] - [ INFO ]  Task 'attempt_local1872961024_0001_m_000000_0' done.
2020-11-20 12:40:00  [ LocalJobRunner Map Task Executor #0:4908 ] - [ INFO ]  Finishing task: attempt_local1872961024_0001_m_000000_0
2020-11-20 12:40:00  [ Thread-18:4908 ] - [ INFO ]  map task executor complete.
2020-11-20 12:40:00  [ Thread-18:4911 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:40:00  [ pool-6-thread-1:4911 ] - [ INFO ]  Starting task: attempt_local1872961024_0001_r_000000_0
2020-11-20 12:40:00  [ pool-6-thread-1:4917 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:40:00  [ pool-6-thread-1:4917 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:40:00  [ pool-6-thread-1:4917 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:40:00  [ pool-6-thread-1:4920 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ef18296
2020-11-20 12:40:00  [ pool-6-thread-1:4930 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:40:00  [ EventFetcher for fetching Map Completion Events:4931 ] - [ INFO ]  attempt_local1872961024_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:40:00  [ localfetcher#1:4949 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1872961024_0001_m_000000_0 decomp: 1387616 len: 1387620 to MEMORY
2020-11-20 12:40:00  [ localfetcher#1:4954 ] - [ INFO ]  Read 1387616 bytes from map-output for attempt_local1872961024_0001_m_000000_0
2020-11-20 12:40:00  [ localfetcher#1:4955 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 1387616, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1387616
2020-11-20 12:40:00  [ EventFetcher for fetching Map Completion Events:4956 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:40:00  [ pool-6-thread-1:4956 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:40:00  [ pool-6-thread-1:4957 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:40:00  [ pool-6-thread-1:4962 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:40:00  [ pool-6-thread-1:4962 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1387608 bytes
2020-11-20 12:40:00  [ pool-6-thread-1:4965 ] - [ INFO ]  Merged 1 segments, 1387616 bytes to disk to satisfy reduce memory limit
2020-11-20 12:40:00  [ pool-6-thread-1:4965 ] - [ INFO ]  Merging 1 files, 1387620 bytes from disk
2020-11-20 12:40:00  [ pool-6-thread-1:4966 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:40:00  [ pool-6-thread-1:4966 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:40:00  [ pool-6-thread-1:4966 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 1387608 bytes
2020-11-20 12:40:00  [ pool-6-thread-1:4966 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:40:00  [ pool-6-thread-1:5040 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 12:40:01  [ main:5671 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:40:03  [ pool-6-thread-1:7237 ] - [ INFO ]  Task:attempt_local1872961024_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 12:40:03  [ pool-6-thread-1:7246 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:40:03  [ pool-6-thread-1:7246 ] - [ INFO ]  Task attempt_local1872961024_0001_r_000000_0 is allowed to commit now
2020-11-20 12:40:03  [ pool-6-thread-1:7312 ] - [ INFO ]  Saved output of task 'attempt_local1872961024_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/_temporary/0/task_local1872961024_0001_r_000000
2020-11-20 12:40:03  [ pool-6-thread-1:7312 ] - [ INFO ]  reduce > reduce
2020-11-20 12:40:03  [ pool-6-thread-1:7312 ] - [ INFO ]  Task 'attempt_local1872961024_0001_r_000000_0' done.
2020-11-20 12:40:03  [ pool-6-thread-1:7313 ] - [ INFO ]  Finishing task: attempt_local1872961024_0001_r_000000_0
2020-11-20 12:40:03  [ Thread-18:7313 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:40:03  [ main:7678 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:40:03  [ main:7679 ] - [ INFO ]  Job job_local1872961024_0001 completed successfully
2020-11-20 12:40:03  [ main:7691 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2775606
		FILE: Number of bytes written=4733026
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=378132
		HDFS: Number of bytes written=1386900
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10076
		Map output records=10076
		Map output bytes=99469
		Map output materialized bytes=1387620
		Input split bytes=113
		Combine input records=10076
		Combine output records=101
		Reduce input groups=101
		Reduce shuffle bytes=1387620
		Reduce input records=101
		Reduce output records=101
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=668991488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189066
	File Output Format Counters 
		Bytes Written=1386900
2020-11-20 12:40:18  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 12:40:37  [ main:19231 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 12:40:37  [ main:19231 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 12:40:37  [ main:19418 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:40:37  [ main:19423 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:40:37  [ main:19486 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:40:37  [ main:19628 ] - [ INFO ]  number of splits:1
2020-11-20 12:40:37  [ main:19693 ] - [ INFO ]  Submitting tokens for job: job_local1389690113_0001
2020-11-20 12:40:38  [ main:19794 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:40:38  [ main:19794 ] - [ INFO ]  Running job: job_local1389690113_0001
2020-11-20 12:40:38  [ Thread-19:19795 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:40:38  [ Thread-19:19798 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:40:38  [ Thread-19:19798 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:40:38  [ Thread-19:19854 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19854 ] - [ INFO ]  Starting task: attempt_local1389690113_0001_m_000000_0
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19868 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19871 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19871 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19873 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19923 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19923 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19923 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19923 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19923 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:40:38  [ LocalJobRunner Map Task Executor #0:19925 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:40:39  [ main:20799 ] - [ INFO ]  Job job_local1389690113_0001 running in uber mode : false
2020-11-20 12:40:39  [ main:20801 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:40:44  [ communication thread:25880 ] - [ INFO ]  map > map
2020-11-20 12:40:45  [ main:26820 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:40:47  [ communication thread:28885 ] - [ INFO ]  map > map
2020-11-20 12:40:48  [ main:29835 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30350 ] - [ INFO ]  map > map
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30352 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30352 ] - [ INFO ]  Spilling map output
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30352 ] - [ INFO ]  bufstart = 0; bufend = 2401; bufvoid = 104857600
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30352 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:40:48  [ Thread-25:30459 ] - [ WARN ]  DataStreamer Exception
java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30461 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30461 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30461 ] - [ INFO ]  Spilling map output
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30461 ] - [ INFO ]  bufstart = 0; bufend = 2401; bufvoid = 104857600
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30461 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:40:48  [ LocalJobRunner Map Task Executor #0:30488 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@36b43887
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-1262837725_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-1262837725_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:40:48  [ Thread-19:30489 ] - [ INFO ]  map task executor complete.
2020-11-20 12:40:48  [ Thread-19:30505 ] - [ WARN ]  job_local1389690113_0001
java.lang.Exception: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 12:40:49  [ main:30836 ] - [ INFO ]  Job job_local1389690113_0001 failed with state FAILED due to: NA
2020-11-20 12:40:49  [ main:30844 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=191
		FILE: Number of bytes written=321691
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2566548
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2401
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=354418688
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:40:49  [ main:30908 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:40:49  [ main:30929 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:40:49  [ main:30935 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:40:49  [ main:30947 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:40:49  [ main:30996 ] - [ INFO ]  number of splits:1
2020-11-20 12:40:49  [ main:31015 ] - [ INFO ]  Submitting tokens for job: job_local1819918342_0002
2020-11-20 12:40:49  [ main:31062 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:40:49  [ main:31063 ] - [ INFO ]  Running job: job_local1819918342_0002
2020-11-20 12:40:49  [ Thread-41:31063 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:40:49  [ Thread-41:31063 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:40:49  [ Thread-41:31063 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:40:49  [ Thread-41:31078 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31078 ] - [ INFO ]  Starting task: attempt_local1819918342_0002_m_000000_0
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31079 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31079 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31079 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31080 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31124 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31124 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31124 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31124 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31124 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:40:49  [ LocalJobRunner Map Task Executor #0:31125 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:40:50  [ communication thread:31888 ] - [ INFO ]  map > sort
2020-11-20 12:40:50  [ main:32068 ] - [ INFO ]  Job job_local1819918342_0002 running in uber mode : false
2020-11-20 12:40:50  [ main:32068 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:40:53  [ communication thread:34891 ] - [ INFO ]  map > sort
2020-11-20 12:40:55  [ communication thread:37088 ] - [ INFO ]  map > map
2020-11-20 12:40:56  [ main:38090 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:40:58  [ communication thread:40090 ] - [ INFO ]  map > map
2020-11-20 12:40:58  [ main:40094 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:40:59  [ Thread-2:41408 ] - [ ERROR ]  Failed to close inode 29185
java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 12:43:25  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 12:43:41  [ main:15707 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 12:43:41  [ main:15708 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 12:43:41  [ main:15912 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:43:41  [ main:15916 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:43:41  [ main:16045 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:43:41  [ main:16134 ] - [ INFO ]  number of splits:1
2020-11-20 12:43:41  [ main:16195 ] - [ INFO ]  Submitting tokens for job: job_local1958536752_0001
2020-11-20 12:43:41  [ main:16288 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:43:41  [ main:16288 ] - [ INFO ]  Running job: job_local1958536752_0001
2020-11-20 12:43:41  [ Thread-19:16289 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:43:41  [ Thread-19:16293 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:43:41  [ Thread-19:16294 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:43:41  [ Thread-19:16362 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:43:41  [ LocalJobRunner Map Task Executor #0:16363 ] - [ INFO ]  Starting task: attempt_local1958536752_0001_m_000000_0
2020-11-20 12:43:41  [ LocalJobRunner Map Task Executor #0:16377 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:43:41  [ LocalJobRunner Map Task Executor #0:16381 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:43:41  [ LocalJobRunner Map Task Executor #0:16381 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:43:41  [ LocalJobRunner Map Task Executor #0:16383 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:43:42  [ LocalJobRunner Map Task Executor #0:16434 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:43:42  [ LocalJobRunner Map Task Executor #0:16434 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:43:42  [ LocalJobRunner Map Task Executor #0:16434 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:43:42  [ LocalJobRunner Map Task Executor #0:16434 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:43:42  [ LocalJobRunner Map Task Executor #0:16434 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:43:42  [ LocalJobRunner Map Task Executor #0:16437 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:43:42  [ main:17295 ] - [ INFO ]  Job job_local1958536752_0001 running in uber mode : false
2020-11-20 12:43:42  [ main:17297 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:43:47  [ communication thread:22393 ] - [ INFO ]  map > map
2020-11-20 12:43:48  [ main:23318 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:43:50  [ communication thread:25397 ] - [ INFO ]  map > map
2020-11-20 12:43:51  [ main:26333 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:43:51  [ LocalJobRunner Map Task Executor #0:26429 ] - [ INFO ]  map > map
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26431 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26431 ] - [ INFO ]  Spilling map output
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26431 ] - [ INFO ]  bufstart = 0; bufend = 2401; bufvoid = 104857600
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26431 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26600 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26600 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26600 ] - [ INFO ]  Spilling map output
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26600 ] - [ INFO ]  bufstart = 0; bufend = 2401; bufvoid = 104857600
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26600 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:43:52  [ LocalJobRunner Map Task Executor #0:26690 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@75f97fff
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because another recovery is in progress by DFSClient_NONMAPREDUCE_-1262837725_1 on 122.224.128.14
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:43:52  [ Thread-19:26693 ] - [ INFO ]  map task executor complete.
2020-11-20 12:43:52  [ Thread-19:26811 ] - [ WARN ]  job_local1958536752_0001
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because lease recovery is in progress. Try again later.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2918)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because lease recovery is in progress. Try again later.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2918)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:43:52  [ main:27338 ] - [ INFO ]  Job job_local1958536752_0001 failed with state FAILED due to: NA
2020-11-20 12:43:52  [ main:27346 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=191
		FILE: Number of bytes written=321687
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2632084
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2401
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=290979840
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:43:53  [ main:27436 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:43:53  [ main:27721 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:43:53  [ main:27727 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:43:53  [ main:27747 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:43:53  [ main:27799 ] - [ INFO ]  number of splits:1
2020-11-20 12:43:53  [ main:27820 ] - [ INFO ]  Submitting tokens for job: job_local855977091_0002
2020-11-20 12:43:53  [ main:27866 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:43:53  [ main:27866 ] - [ INFO ]  Running job: job_local855977091_0002
2020-11-20 12:43:53  [ Thread-39:27866 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:43:53  [ Thread-39:27867 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:43:53  [ Thread-39:27867 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:43:53  [ Thread-39:27889 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27890 ] - [ INFO ]  Starting task: attempt_local855977091_0002_m_000000_0
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27891 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27891 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27891 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27893 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27937 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27937 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27937 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27937 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27937 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:43:53  [ LocalJobRunner Map Task Executor #0:27938 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:43:53  [ communication thread:28402 ] - [ INFO ]  map > sort
2020-11-20 12:43:54  [ main:28870 ] - [ INFO ]  Job job_local855977091_0002 running in uber mode : false
2020-11-20 12:43:54  [ main:28870 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:43:56  [ communication thread:31403 ] - [ INFO ]  map > sort
2020-11-20 12:43:59  [ communication thread:33899 ] - [ INFO ]  map > map
2020-11-20 12:44:00  [ main:34887 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:44:02  [ communication thread:36903 ] - [ INFO ]  map > map
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37691 ] - [ INFO ]  map > map
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37691 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37691 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37691 ] - [ INFO ]  bufstart = 0; bufend = 2372; bufvoid = 104857600
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37692 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:03  [ Thread-43:37779 ] - [ WARN ]  DataStreamer Exception
java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37780 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37780 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37780 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37780 ] - [ INFO ]  bufstart = 0; bufend = 2372; bufvoid = 104857600
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37780 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:03  [ LocalJobRunner Map Task Executor #0:37825 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@6d2e125c
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:03  [ Thread-39:37826 ] - [ INFO ]  map task executor complete.
2020-11-20 12:44:03  [ main:37897 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:44:03  [ Thread-39:37904 ] - [ WARN ]  job_local855977091_0002
java.lang.Exception: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 12:44:04  [ main:38902 ] - [ INFO ]  Job job_local855977091_0002 failed with state FAILED due to: NA
2020-11-20 12:44:04  [ main:38905 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=382
		FILE: Number of bytes written=641940
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4018984
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2372
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=414711808
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:44:04  [ main:38966 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:44:04  [ main:38988 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:44:04  [ main:38992 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:44:04  [ main:39006 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:44:04  [ main:39082 ] - [ INFO ]  number of splits:1
2020-11-20 12:44:04  [ main:39107 ] - [ INFO ]  Submitting tokens for job: job_local1223834179_0003
2020-11-20 12:44:04  [ main:39151 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:44:04  [ main:39151 ] - [ INFO ]  Running job: job_local1223834179_0003
2020-11-20 12:44:04  [ Thread-59:39151 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:44:04  [ Thread-59:39152 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:04  [ Thread-59:39152 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:44:04  [ Thread-59:39166 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39166 ] - [ INFO ]  Starting task: attempt_local1223834179_0003_m_000000_0
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39167 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39167 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39167 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39169 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39214 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39214 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39214 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39214 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39214 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:44:04  [ LocalJobRunner Map Task Executor #0:39215 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:44:05  [ communication thread:39909 ] - [ INFO ]  map > sort
2020-11-20 12:44:05  [ main:40155 ] - [ INFO ]  Job job_local1223834179_0003 running in uber mode : false
2020-11-20 12:44:05  [ main:40155 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:44:08  [ communication thread:42911 ] - [ INFO ]  map > sort
2020-11-20 12:44:10  [ communication thread:45171 ] - [ INFO ]  map > map
2020-11-20 12:44:11  [ main:46175 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:44:13  [ communication thread:48175 ] - [ INFO ]  map > map
2020-11-20 12:44:13  [ main:48181 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48894 ] - [ INFO ]  map > map
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48894 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48895 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48895 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48895 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48912 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48912 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48912 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48912 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48912 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:48928 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@11cd0844
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:14  [ Thread-59:48929 ] - [ INFO ]  map task executor complete.
2020-11-20 12:44:14  [ Thread-59:48935 ] - [ WARN ]  job_local1223834179_0003
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:14  [ main:49186 ] - [ INFO ]  Job job_local1223834179_0003 failed with state FAILED due to: NA
2020-11-20 12:44:14  [ main:49188 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=573
		FILE: Number of bytes written=964421
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5405884
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=12
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2402
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=516947968
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:44:14  [ main:49207 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:44:14  [ main:49222 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:44:14  [ main:49226 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:44:14  [ main:49234 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:44:14  [ main:49272 ] - [ INFO ]  number of splits:1
2020-11-20 12:44:14  [ main:49290 ] - [ INFO ]  Submitting tokens for job: job_local1349636314_0004
2020-11-20 12:44:14  [ main:49335 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:44:14  [ main:49335 ] - [ INFO ]  Running job: job_local1349636314_0004
2020-11-20 12:44:14  [ Thread-77:49335 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:44:14  [ Thread-77:49336 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:14  [ Thread-77:49336 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:44:14  [ Thread-77:49344 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49344 ] - [ INFO ]  Starting task: attempt_local1349636314_0004_m_000000_0
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49345 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49345 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49345 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49346 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49389 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49389 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49389 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49389 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49389 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:44:14  [ LocalJobRunner Map Task Executor #0:49390 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:44:15  [ main:50336 ] - [ INFO ]  Job job_local1349636314_0004 running in uber mode : false
2020-11-20 12:44:15  [ main:50336 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:44:16  [ communication thread:51179 ] - [ INFO ]  map > sort
2020-11-20 12:44:19  [ communication thread:54183 ] - [ INFO ]  map > sort
2020-11-20 12:44:20  [ communication thread:55349 ] - [ INFO ]  map > map
2020-11-20 12:44:20  [ main:55352 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:44:23  [ communication thread:58353 ] - [ INFO ]  map > map
2020-11-20 12:44:23  [ main:58363 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59236 ] - [ INFO ]  map > map
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59236 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59237 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59237 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59237 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59252 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59252 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59252 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59252 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59252 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:24  [ LocalJobRunner Map Task Executor #0:59266 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@25329116
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:24  [ Thread-77:59267 ] - [ INFO ]  map task executor complete.
2020-11-20 12:44:24  [ Thread-77:59274 ] - [ WARN ]  job_local1349636314_0004
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:24  [ main:59368 ] - [ INFO ]  Job job_local1349636314_0004 failed with state FAILED due to: NA
2020-11-20 12:44:24  [ main:59370 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=764
		FILE: Number of bytes written=1287024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6727248
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=17
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=618659840
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:44:24  [ main:59392 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:44:24  [ main:59406 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:44:24  [ main:59411 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:44:24  [ main:59418 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:44:25  [ main:59460 ] - [ INFO ]  number of splits:1
2020-11-20 12:44:25  [ main:59481 ] - [ INFO ]  Submitting tokens for job: job_local1598079828_0005
2020-11-20 12:44:25  [ main:59521 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:44:25  [ main:59521 ] - [ INFO ]  Running job: job_local1598079828_0005
2020-11-20 12:44:25  [ Thread-95:59521 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:44:25  [ Thread-95:59521 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:25  [ Thread-95:59522 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:44:25  [ Thread-95:59531 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59531 ] - [ INFO ]  Starting task: attempt_local1598079828_0005_m_000000_0
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59532 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59532 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59532 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59532 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59587 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59587 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59587 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59587 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59587 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:44:25  [ LocalJobRunner Map Task Executor #0:59588 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:44:26  [ main:60523 ] - [ INFO ]  Job job_local1598079828_0005 running in uber mode : false
2020-11-20 12:44:26  [ main:60524 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:44:26  [ communication thread:61357 ] - [ INFO ]  map > sort
2020-11-20 12:44:29  [ communication thread:64362 ] - [ INFO ]  map > sort
2020-11-20 12:44:31  [ communication thread:65542 ] - [ INFO ]  map > map
2020-11-20 12:44:32  [ main:66544 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:44:34  [ communication thread:68544 ] - [ INFO ]  map > map
2020-11-20 12:44:34  [ main:68548 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69865 ] - [ INFO ]  map > map
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69865 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69865 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69865 ] - [ INFO ]  bufstart = 0; bufend = 2411; bufvoid = 104857600
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69865 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69879 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69879 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69879 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69879 ] - [ INFO ]  bufstart = 0; bufend = 2411; bufvoid = 104857600
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69879 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:35  [ LocalJobRunner Map Task Executor #0:69897 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@2d4f5ef1
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:35  [ Thread-95:69898 ] - [ INFO ]  map task executor complete.
2020-11-20 12:44:35  [ Thread-95:69904 ] - [ WARN ]  job_local1598079828_0005
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:36  [ main:70552 ] - [ INFO ]  Job job_local1598079828_0005 failed with state FAILED due to: NA
2020-11-20 12:44:36  [ main:70554 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=955
		FILE: Number of bytes written=1610333
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8114148
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2411
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=721420288
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:44:36  [ main:70574 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:44:36  [ main:70588 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:44:36  [ main:70593 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:44:36  [ main:70600 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:44:36  [ main:70638 ] - [ INFO ]  number of splits:1
2020-11-20 12:44:36  [ main:70656 ] - [ INFO ]  Submitting tokens for job: job_local432201257_0006
2020-11-20 12:44:36  [ main:70693 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:44:36  [ main:70693 ] - [ INFO ]  Running job: job_local432201257_0006
2020-11-20 12:44:36  [ Thread-113:70694 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:44:36  [ Thread-113:70694 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:36  [ Thread-113:70694 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:44:36  [ Thread-113:70703 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70704 ] - [ INFO ]  Starting task: attempt_local432201257_0006_m_000000_0
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70704 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70705 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70705 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70705 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70773 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70774 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70774 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70774 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70774 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:44:36  [ LocalJobRunner Map Task Executor #0:70774 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:44:37  [ communication thread:71546 ] - [ INFO ]  map > sort
2020-11-20 12:44:37  [ main:71697 ] - [ INFO ]  Job job_local432201257_0006 running in uber mode : false
2020-11-20 12:44:37  [ main:71697 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:44:40  [ communication thread:74547 ] - [ INFO ]  map > sort
2020-11-20 12:44:42  [ communication thread:76715 ] - [ INFO ]  map > map
2020-11-20 12:44:43  [ main:77711 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:44:45  [ communication thread:79717 ] - [ INFO ]  map > map
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80373 ] - [ INFO ]  map > map
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80374 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80374 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80374 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80374 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80395 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80395 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80395 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80395 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80395 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:45  [ LocalJobRunner Map Task Executor #0:80413 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@51b10f36
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:45  [ Thread-113:80414 ] - [ INFO ]  map task executor complete.
2020-11-20 12:44:45  [ Thread-113:80420 ] - [ WARN ]  job_local432201257_0006
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:46  [ main:80719 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:44:46  [ main:80719 ] - [ INFO ]  Job job_local432201257_0006 failed with state FAILED due to: NA
2020-11-20 12:44:46  [ main:80721 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=1146
		FILE: Number of bytes written=1932132
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=9566584
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=49
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=27
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2408
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:44:46  [ main:80753 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:44:46  [ main:80770 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:44:46  [ main:80775 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:44:46  [ main:80785 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:44:46  [ main:80833 ] - [ INFO ]  number of splits:1
2020-11-20 12:44:46  [ main:80851 ] - [ INFO ]  Submitting tokens for job: job_local740018726_0007
2020-11-20 12:44:46  [ main:80890 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:44:46  [ main:80890 ] - [ INFO ]  Running job: job_local740018726_0007
2020-11-20 12:44:46  [ Thread-131:80890 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:44:46  [ Thread-131:80890 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:46  [ Thread-131:80890 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:44:46  [ Thread-131:80899 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80899 ] - [ INFO ]  Starting task: attempt_local740018726_0007_m_000000_0
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80900 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80900 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80900 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80901 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80971 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80971 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80971 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80971 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80971 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:44:46  [ LocalJobRunner Map Task Executor #0:80971 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:44:47  [ main:81894 ] - [ INFO ]  Job job_local740018726_0007 running in uber mode : false
2020-11-20 12:44:47  [ main:81894 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:44:48  [ communication thread:82718 ] - [ INFO ]  map > sort
2020-11-20 12:44:51  [ communication thread:85722 ] - [ INFO ]  map > sort
2020-11-20 12:44:52  [ communication thread:86906 ] - [ INFO ]  map > map
2020-11-20 12:44:53  [ main:87906 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:44:55  [ communication thread:89910 ] - [ INFO ]  map > map
2020-11-20 12:44:55  [ main:89914 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91104 ] - [ INFO ]  map > map
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91105 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91105 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91105 ] - [ INFO ]  bufstart = 0; bufend = 2417; bufvoid = 104857600
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91105 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91131 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91131 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91131 ] - [ INFO ]  Spilling map output
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91131 ] - [ INFO ]  bufstart = 0; bufend = 2417; bufvoid = 104857600
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91131 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:44:56  [ LocalJobRunner Map Task Executor #0:91147 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@21c566ec
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:56  [ Thread-131:91148 ] - [ INFO ]  map task executor complete.
2020-11-20 12:44:56  [ Thread-131:91154 ] - [ WARN ]  job_local740018726_0007
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:44:57  [ main:91919 ] - [ INFO ]  Job job_local740018726_0007 failed with state FAILED due to: NA
2020-11-20 12:44:57  [ main:91921 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=1337
		FILE: Number of bytes written=2254637
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10887948
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=57
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=32
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2417
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=154
		Total committed heap usage (bytes)=946339840
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:44:57  [ main:91941 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:44:57  [ main:91954 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:44:57  [ main:91959 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:44:57  [ main:91965 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:44:57  [ main:92003 ] - [ INFO ]  number of splits:1
2020-11-20 12:44:57  [ main:92021 ] - [ INFO ]  Submitting tokens for job: job_local900916864_0008
2020-11-20 12:44:57  [ main:92059 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:44:57  [ main:92059 ] - [ INFO ]  Running job: job_local900916864_0008
2020-11-20 12:44:57  [ Thread-150:92059 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:44:57  [ Thread-150:92059 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:57  [ Thread-150:92060 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:44:57  [ Thread-150:92070 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92070 ] - [ INFO ]  Starting task: attempt_local900916864_0008_m_000000_0
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92071 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92071 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92071 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92072 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92121 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92121 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92121 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92121 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92121 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:44:57  [ LocalJobRunner Map Task Executor #0:92121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:44:58  [ communication thread:92912 ] - [ INFO ]  map > sort
2020-11-20 12:44:58  [ main:93147 ] - [ INFO ]  Job job_local900916864_0008 running in uber mode : false
2020-11-20 12:44:58  [ main:93148 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:45:01  [ communication thread:95915 ] - [ INFO ]  map > sort
2020-11-20 12:45:03  [ communication thread:98077 ] - [ INFO ]  map > map
2020-11-20 12:45:03  [ main:98160 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:45:06  [ communication thread:101083 ] - [ INFO ]  map > map
2020-11-20 12:45:06  [ main:101169 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101818 ] - [ INFO ]  map > map
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101818 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101818 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101818 ] - [ INFO ]  bufstart = 0; bufend = 2351; bufvoid = 104857600
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101818 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101832 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101832 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101832 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101832 ] - [ INFO ]  bufstart = 0; bufend = 2351; bufvoid = 104857600
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101833 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:101846 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@7795da89
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:07  [ Thread-150:101847 ] - [ INFO ]  map task executor complete.
2020-11-20 12:45:07  [ Thread-150:101853 ] - [ WARN ]  job_local900916864_0008
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:07  [ main:102173 ] - [ INFO ]  Job job_local900916864_0008 failed with state FAILED due to: NA
2020-11-20 12:45:07  [ main:102175 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=1528
		FILE: Number of bytes written=2577734
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=12405920
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=65
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=37
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2351
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=118
		Total committed heap usage (bytes)=1055391744
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:45:07  [ main:102196 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:45:07  [ main:102212 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:45:07  [ main:102217 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:45:07  [ main:102223 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:45:07  [ main:102259 ] - [ INFO ]  number of splits:1
2020-11-20 12:45:07  [ main:102277 ] - [ INFO ]  Submitting tokens for job: job_local1666509511_0009
2020-11-20 12:45:07  [ main:102314 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:45:07  [ main:102314 ] - [ INFO ]  Running job: job_local1666509511_0009
2020-11-20 12:45:07  [ Thread-168:102314 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:45:07  [ Thread-168:102314 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:07  [ Thread-168:102314 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:45:07  [ Thread-168:102323 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102324 ] - [ INFO ]  Starting task: attempt_local1666509511_0009_m_000000_0
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102324 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102324 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102324 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102325 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102403 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102404 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102404 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102404 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102404 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:45:07  [ LocalJobRunner Map Task Executor #0:102404 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:45:08  [ main:103318 ] - [ INFO ]  Job job_local1666509511_0009 running in uber mode : false
2020-11-20 12:45:08  [ main:103319 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:45:09  [ communication thread:104086 ] - [ INFO ]  map > sort
2020-11-20 12:45:12  [ communication thread:107091 ] - [ INFO ]  map > sort
2020-11-20 12:45:13  [ communication thread:108332 ] - [ INFO ]  map > map
2020-11-20 12:45:14  [ main:109333 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:45:16  [ communication thread:111335 ] - [ INFO ]  map > map
2020-11-20 12:45:16  [ main:111338 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111974 ] - [ INFO ]  map > map
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111974 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111974 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111974 ] - [ INFO ]  bufstart = 0; bufend = 2406; bufvoid = 104857600
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111974 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111988 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111988 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111988 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111988 ] - [ INFO ]  bufstart = 0; bufend = 2406; bufvoid = 104857600
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:111988 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:17  [ LocalJobRunner Map Task Executor #0:112002 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@7fc08e78
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:17  [ Thread-168:112003 ] - [ INFO ]  map task executor complete.
2020-11-20 12:45:17  [ Thread-168:112010 ] - [ WARN ]  job_local1666509511_0009
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:17  [ main:112339 ] - [ INFO ]  Job job_local1666509511_0009 failed with state FAILED due to: NA
2020-11-20 12:45:17  [ main:112341 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=1719
		FILE: Number of bytes written=2902413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13727284
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=73
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=42
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2406
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=1158152192
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:45:17  [ main:112359 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:45:17  [ main:112372 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:45:17  [ main:112377 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:45:17  [ main:112383 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:45:17  [ main:112421 ] - [ INFO ]  number of splits:1
2020-11-20 12:45:18  [ main:112439 ] - [ INFO ]  Submitting tokens for job: job_local1035089146_0010
2020-11-20 12:45:18  [ main:112475 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:45:18  [ main:112476 ] - [ INFO ]  Running job: job_local1035089146_0010
2020-11-20 12:45:18  [ Thread-186:112476 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:45:18  [ Thread-186:112476 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:18  [ Thread-186:112476 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:45:18  [ Thread-186:112486 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112487 ] - [ INFO ]  Starting task: attempt_local1035089146_0010_m_000000_0
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112487 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112487 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112487 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112488 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112540 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112540 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112540 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112540 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112540 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:45:18  [ LocalJobRunner Map Task Executor #0:112540 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:45:19  [ main:113480 ] - [ INFO ]  Job job_local1035089146_0010 running in uber mode : false
2020-11-20 12:45:19  [ main:113481 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:45:19  [ communication thread:114341 ] - [ INFO ]  map > sort
2020-11-20 12:45:22  [ communication thread:117344 ] - [ INFO ]  map > sort
2020-11-20 12:45:24  [ communication thread:118492 ] - [ INFO ]  map > map
2020-11-20 12:45:24  [ main:118494 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:45:27  [ communication thread:121495 ] - [ INFO ]  map > map
2020-11-20 12:45:27  [ main:121502 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122617 ] - [ INFO ]  map > map
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122617 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122617 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122617 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122617 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122647 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122647 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122647 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122647 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122647 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:28  [ LocalJobRunner Map Task Executor #0:122668 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@1941d918
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:28  [ Thread-186:122669 ] - [ INFO ]  map task executor complete.
2020-11-20 12:45:28  [ Thread-186:122678 ] - [ WARN ]  job_local1035089146_0010
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:29  [ main:123511 ] - [ INFO ]  Job job_local1035089146_0010 failed with state FAILED due to: NA
2020-11-20 12:45:29  [ main:123512 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=1910
		FILE: Number of bytes written=3227140
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=15114184
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=81
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=47
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2402
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=1245708288
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:45:29  [ main:123542 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:45:29  [ main:123752 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:45:29  [ main:123757 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:45:29  [ main:123765 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:45:29  [ main:123806 ] - [ INFO ]  number of splits:1
2020-11-20 12:45:29  [ main:123824 ] - [ INFO ]  Submitting tokens for job: job_local1400629458_0011
2020-11-20 12:45:29  [ main:123862 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:45:29  [ main:123862 ] - [ INFO ]  Running job: job_local1400629458_0011
2020-11-20 12:45:29  [ Thread-205:123862 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:45:29  [ Thread-205:123862 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:29  [ Thread-205:123863 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:45:29  [ Thread-205:123874 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123874 ] - [ INFO ]  Starting task: attempt_local1400629458_0011_m_000000_0
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123875 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123875 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123875 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123876 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123925 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123925 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123925 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123925 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123925 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:45:29  [ LocalJobRunner Map Task Executor #0:123925 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:45:30  [ communication thread:124500 ] - [ INFO ]  map > sort
2020-11-20 12:45:30  [ main:124864 ] - [ INFO ]  Job job_local1400629458_0011 running in uber mode : false
2020-11-20 12:45:30  [ main:124865 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:45:33  [ communication thread:127502 ] - [ INFO ]  map > sort
2020-11-20 12:45:35  [ communication thread:129885 ] - [ INFO ]  map > map
2020-11-20 12:45:36  [ main:130885 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:45:38  [ communication thread:132890 ] - [ INFO ]  map > map
2020-11-20 12:45:38  [ main:132893 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133338 ] - [ INFO ]  map > map
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133339 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133339 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133339 ] - [ INFO ]  bufstart = 0; bufend = 2387; bufvoid = 104857600
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133339 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133361 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133361 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133361 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133361 ] - [ INFO ]  bufstart = 0; bufend = 2387; bufvoid = 104857600
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133361 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:38  [ LocalJobRunner Map Task Executor #0:133381 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@318ac804
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:38  [ Thread-205:133382 ] - [ INFO ]  map task executor complete.
2020-11-20 12:45:38  [ Thread-205:133391 ] - [ WARN ]  job_local1400629458_0011
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:39  [ main:133894 ] - [ INFO ]  Job job_local1400629458_0011 failed with state FAILED due to: NA
2020-11-20 12:45:39  [ main:133895 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=2101
		FILE: Number of bytes written=3551903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=16501084
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=89
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=52
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2387
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=1362100224
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:45:39  [ main:133922 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:45:39  [ main:133953 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:45:39  [ main:133958 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:45:39  [ main:133966 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:45:39  [ main:134008 ] - [ INFO ]  number of splits:1
2020-11-20 12:45:39  [ main:134026 ] - [ INFO ]  Submitting tokens for job: job_local552393163_0012
2020-11-20 12:45:39  [ main:134066 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:45:39  [ main:134066 ] - [ INFO ]  Running job: job_local552393163_0012
2020-11-20 12:45:39  [ Thread-223:134067 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:45:39  [ Thread-223:134067 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:39  [ Thread-223:134067 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:45:39  [ Thread-223:134079 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134079 ] - [ INFO ]  Starting task: attempt_local552393163_0012_m_000000_0
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134080 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134080 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134080 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134081 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134132 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134132 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134132 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134132 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134132 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:45:39  [ LocalJobRunner Map Task Executor #0:134133 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:45:40  [ main:135067 ] - [ INFO ]  Job job_local552393163_0012 running in uber mode : false
2020-11-20 12:45:40  [ main:135067 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:45:41  [ communication thread:135894 ] - [ INFO ]  map > sort
2020-11-20 12:45:44  [ communication thread:138896 ] - [ INFO ]  map > sort
2020-11-20 12:45:45  [ communication thread:140089 ] - [ INFO ]  map > map
2020-11-20 12:45:46  [ main:141092 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:45:48  [ communication thread:143092 ] - [ INFO ]  map > map
2020-11-20 12:45:48  [ main:143095 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143968 ] - [ INFO ]  map > map
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143969 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143969 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143969 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143969 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143990 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143990 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143990 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143990 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:143990 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144010 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@33b604f1
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:49  [ Thread-223:144011 ] - [ INFO ]  map task executor complete.
2020-11-20 12:45:49  [ Thread-223:144021 ] - [ WARN ]  job_local552393163_0012
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:49  [ main:144097 ] - [ INFO ]  Job job_local552393163_0012 failed with state FAILED due to: NA
2020-11-20 12:45:49  [ main:144098 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=2292
		FILE: Number of bytes written=3848152
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17887984
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=97
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=57
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2394
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=1450180608
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:45:49  [ main:144126 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:45:49  [ main:144144 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:45:49  [ main:144149 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:45:49  [ main:144158 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:45:49  [ main:144204 ] - [ INFO ]  number of splits:1
2020-11-20 12:45:49  [ main:144225 ] - [ INFO ]  Submitting tokens for job: job_local1886083405_0013
2020-11-20 12:45:49  [ main:144266 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:45:49  [ main:144266 ] - [ INFO ]  Running job: job_local1886083405_0013
2020-11-20 12:45:49  [ Thread-241:144266 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:45:49  [ Thread-241:144267 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:49  [ Thread-241:144267 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:45:49  [ Thread-241:144278 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144278 ] - [ INFO ]  Starting task: attempt_local1886083405_0013_m_000000_0
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144279 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144279 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144279 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144280 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144361 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144361 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144361 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144361 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144361 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:45:49  [ LocalJobRunner Map Task Executor #0:144361 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:45:50  [ main:145270 ] - [ INFO ]  Job job_local1886083405_0013 running in uber mode : false
2020-11-20 12:45:50  [ main:145270 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:45:51  [ communication thread:146097 ] - [ INFO ]  map > sort
2020-11-20 12:45:54  [ communication thread:149101 ] - [ INFO ]  map > sort
2020-11-20 12:45:55  [ communication thread:150286 ] - [ INFO ]  map > map
2020-11-20 12:45:56  [ main:151285 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:45:58  [ communication thread:153290 ] - [ INFO ]  map > map
2020-11-20 12:45:59  [ main:154294 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154350 ] - [ INFO ]  map > map
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154350 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154350 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154350 ] - [ INFO ]  bufstart = 0; bufend = 2418; bufvoid = 104857600
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154350 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154372 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154372 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154372 ] - [ INFO ]  Spilling map output
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154372 ] - [ INFO ]  bufstart = 0; bufend = 2418; bufvoid = 104857600
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154372 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:45:59  [ LocalJobRunner Map Task Executor #0:154392 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@5c019a97
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:45:59  [ Thread-241:154393 ] - [ INFO ]  map task executor complete.
2020-11-20 12:45:59  [ Thread-241:154403 ] - [ WARN ]  job_local1886083405_0013
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:00  [ main:155295 ] - [ INFO ]  Job job_local1886083405_0013 failed with state FAILED due to: NA
2020-11-20 12:46:00  [ main:155296 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=2483
		FILE: Number of bytes written=4173137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=19274884
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=105
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=62
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2418
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=44
		Total committed heap usage (bytes)=1563951104
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:46:00  [ main:155326 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:46:00  [ main:155341 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:46:00  [ main:155345 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:46:00  [ main:155354 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:46:00  [ main:155399 ] - [ INFO ]  number of splits:1
2020-11-20 12:46:00  [ main:155420 ] - [ INFO ]  Submitting tokens for job: job_local383817489_0014
2020-11-20 12:46:01  [ main:155458 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:46:01  [ main:155458 ] - [ INFO ]  Running job: job_local383817489_0014
2020-11-20 12:46:01  [ Thread-259:155458 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:46:01  [ Thread-259:155458 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:01  [ Thread-259:155458 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:46:01  [ Thread-259:155476 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155477 ] - [ INFO ]  Starting task: attempt_local383817489_0014_m_000000_0
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155477 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155477 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155477 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155478 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155537 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155537 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155537 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155537 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155537 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:46:01  [ LocalJobRunner Map Task Executor #0:155538 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:46:01  [ communication thread:156295 ] - [ INFO ]  map > sort
2020-11-20 12:46:02  [ main:156462 ] - [ INFO ]  Job job_local383817489_0014 running in uber mode : false
2020-11-20 12:46:02  [ main:156462 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:46:04  [ communication thread:159297 ] - [ INFO ]  map > sort
2020-11-20 12:46:07  [ communication thread:161485 ] - [ INFO ]  map > map
2020-11-20 12:46:08  [ main:162479 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:46:10  [ communication thread:164488 ] - [ INFO ]  map > map
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165195 ] - [ INFO ]  map > map
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165195 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165196 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165196 ] - [ INFO ]  bufstart = 0; bufend = 2385; bufvoid = 104857600
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165196 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165216 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165216 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165216 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165216 ] - [ INFO ]  bufstart = 0; bufend = 2385; bufvoid = 104857600
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165216 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:10  [ LocalJobRunner Map Task Executor #0:165238 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@1abc30c3
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:10  [ Thread-259:165238 ] - [ INFO ]  map task executor complete.
2020-11-20 12:46:10  [ Thread-259:165247 ] - [ WARN ]  job_local383817489_0014
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:11  [ main:165490 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:46:11  [ main:165490 ] - [ INFO ]  Job job_local383817489_0014 failed with state FAILED due to: NA
2020-11-20 12:46:11  [ main:165491 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=2674
		FILE: Number of bytes written=4470512
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=20661784
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=113
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=67
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2385
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=45
		Total committed heap usage (bytes)=1652031488
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:46:11  [ main:165519 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:46:11  [ main:165536 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:46:11  [ main:165541 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:46:11  [ main:165550 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:46:11  [ main:165589 ] - [ INFO ]  number of splits:1
2020-11-20 12:46:11  [ main:165606 ] - [ INFO ]  Submitting tokens for job: job_local493353121_0015
2020-11-20 12:46:11  [ main:165642 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:46:11  [ main:165642 ] - [ INFO ]  Running job: job_local493353121_0015
2020-11-20 12:46:11  [ Thread-277:165642 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:46:11  [ Thread-277:165642 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:11  [ Thread-277:165642 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:46:11  [ Thread-277:165654 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165654 ] - [ INFO ]  Starting task: attempt_local493353121_0015_m_000000_0
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165655 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165655 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165655 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165655 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165704 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165704 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165704 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165704 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165704 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:46:11  [ LocalJobRunner Map Task Executor #0:165705 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:46:12  [ main:166646 ] - [ INFO ]  Job job_local493353121_0015 running in uber mode : false
2020-11-20 12:46:12  [ main:166647 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:46:13  [ communication thread:167493 ] - [ INFO ]  map > sort
2020-11-20 12:46:16  [ communication thread:170497 ] - [ INFO ]  map > sort
2020-11-20 12:46:17  [ communication thread:171662 ] - [ INFO ]  map > map
2020-11-20 12:46:18  [ main:172659 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:46:20  [ communication thread:174668 ] - [ INFO ]  map > map
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175491 ] - [ INFO ]  map > map
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175492 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175492 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175492 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175492 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175512 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175512 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175512 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175512 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175512 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175530 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@7c1bb025
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:21  [ Thread-277:175531 ] - [ INFO ]  map task executor complete.
2020-11-20 12:46:21  [ Thread-277:175541 ] - [ WARN ]  job_local493353121_0015
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:21  [ main:175667 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:46:21  [ main:175668 ] - [ INFO ]  Job job_local493353121_0015 failed with state FAILED due to: NA
2020-11-20 12:46:21  [ main:175669 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=2865
		FILE: Number of bytes written=4768087
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=22048684
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=121
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=72
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=1765801984
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:46:21  [ main:175697 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:46:21  [ main:175713 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:46:21  [ main:175718 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:46:21  [ main:175727 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:46:21  [ main:175769 ] - [ INFO ]  number of splits:1
2020-11-20 12:46:21  [ main:175788 ] - [ INFO ]  Submitting tokens for job: job_local2022072509_0016
2020-11-20 12:46:21  [ main:175826 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:46:21  [ main:175826 ] - [ INFO ]  Running job: job_local2022072509_0016
2020-11-20 12:46:21  [ Thread-295:175827 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:46:21  [ Thread-295:175827 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:21  [ Thread-295:175827 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:46:21  [ Thread-295:175838 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175838 ] - [ INFO ]  Starting task: attempt_local2022072509_0016_m_000000_0
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175839 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175839 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175839 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175839 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175889 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175889 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175889 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175889 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175889 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:46:21  [ LocalJobRunner Map Task Executor #0:175890 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:46:22  [ main:176828 ] - [ INFO ]  Job job_local2022072509_0016 running in uber mode : false
2020-11-20 12:46:22  [ main:176828 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:46:23  [ communication thread:177671 ] - [ INFO ]  map > sort
2020-11-20 12:46:26  [ communication thread:180675 ] - [ INFO ]  map > sort
2020-11-20 12:46:27  [ communication thread:181845 ] - [ INFO ]  map > map
2020-11-20 12:46:28  [ main:182839 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:46:30  [ communication thread:184849 ] - [ INFO ]  map > map
2020-11-20 12:46:31  [ main:185845 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186000 ] - [ INFO ]  map > map
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186000 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186001 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186001 ] - [ INFO ]  bufstart = 0; bufend = 2409; bufvoid = 104857600
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186001 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186063 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186063 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186063 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186063 ] - [ INFO ]  bufstart = 0; bufend = 2409; bufvoid = 104857600
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186063 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:31  [ LocalJobRunner Map Task Executor #0:186157 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@24189b30
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:31  [ Thread-295:186158 ] - [ INFO ]  map task executor complete.
2020-11-20 12:46:31  [ Thread-295:186172 ] - [ WARN ]  job_local2022072509_0016
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:32  [ main:186850 ] - [ INFO ]  Job job_local2022072509_0016 failed with state FAILED due to: NA
2020-11-20 12:46:32  [ main:186850 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=3056
		FILE: Number of bytes written=5072090
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=23370048
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=129
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=77
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2409
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=1868038144
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:46:32  [ main:187329 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:46:32  [ main:187351 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:46:32  [ main:187356 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:46:32  [ main:187368 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:46:33  [ main:187564 ] - [ INFO ]  number of splits:1
2020-11-20 12:46:33  [ main:187582 ] - [ INFO ]  Submitting tokens for job: job_local543482715_0017
2020-11-20 12:46:33  [ main:187621 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:46:33  [ main:187621 ] - [ INFO ]  Running job: job_local543482715_0017
2020-11-20 12:46:33  [ Thread-314:187621 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:46:33  [ Thread-314:187621 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:33  [ Thread-314:187621 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:46:33  [ Thread-314:187704 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187704 ] - [ INFO ]  Starting task: attempt_local543482715_0017_m_000000_0
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187705 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187705 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187705 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187705 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187772 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187773 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187773 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187773 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187773 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:46:33  [ LocalJobRunner Map Task Executor #0:187773 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:46:33  [ communication thread:187852 ] - [ INFO ]  map > sort
2020-11-20 12:46:34  [ main:188626 ] - [ INFO ]  Job job_local543482715_0017 running in uber mode : false
2020-11-20 12:46:34  [ main:188626 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:46:36  [ communication thread:190853 ] - [ INFO ]  map > sort
2020-11-20 12:46:39  [ communication thread:193714 ] - [ INFO ]  map > map
2020-11-20 12:46:40  [ main:194649 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:46:42  [ communication thread:196718 ] - [ INFO ]  map > map
2020-11-20 12:46:43  [ main:197654 ] - [ INFO ]   map 50% reduce 0%
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198677 ] - [ INFO ]  map > map
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198677 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198677 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198677 ] - [ INFO ]  bufstart = 0; bufend = 2377; bufvoid = 104857600
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198677 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198816 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198816 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198816 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198816 ] - [ INFO ]  bufstart = 0; bufend = 2377; bufvoid = 104857600
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198816 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:44  [ LocalJobRunner Map Task Executor #0:198911 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@6d330f13
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:44  [ Thread-314:198911 ] - [ INFO ]  map task executor complete.
2020-11-20 12:46:44  [ Thread-314:198940 ] - [ WARN ]  job_local543482715_0017
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:45  [ main:199662 ] - [ INFO ]  Job job_local543482715_0017 failed with state FAILED due to: NA
2020-11-20 12:46:45  [ main:199662 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=3247
		FILE: Number of bytes written=5374931
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=24625876
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=137
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=82
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2377
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=218
		Total committed heap usage (bytes)=1957167104
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:46:45  [ communication thread:199724 ] - [ INFO ]  map > sort
2020-11-20 12:46:45  [ main:199864 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:46:45  [ main:199923 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:46:45  [ main:199927 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:46:45  [ main:200179 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:46:45  [ main:200410 ] - [ INFO ]  number of splits:1
2020-11-20 12:46:45  [ main:200427 ] - [ INFO ]  Submitting tokens for job: job_local925600254_0018
2020-11-20 12:46:46  [ main:200467 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:46:46  [ main:200467 ] - [ INFO ]  Running job: job_local925600254_0018
2020-11-20 12:46:46  [ Thread-333:200468 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:46:46  [ Thread-333:200468 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:46  [ Thread-333:200468 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:46:46  [ Thread-333:200485 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200485 ] - [ INFO ]  Starting task: attempt_local925600254_0018_m_000000_0
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200486 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200486 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200486 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200487 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200568 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200568 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200568 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200568 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200568 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:46:46  [ LocalJobRunner Map Task Executor #0:200569 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:46:47  [ main:201470 ] - [ INFO ]  Job job_local925600254_0018 running in uber mode : false
2020-11-20 12:46:47  [ main:201470 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:46:48  [ communication thread:202729 ] - [ INFO ]  map > sort
2020-11-20 12:46:52  [ communication thread:206494 ] - [ INFO ]  map > map
2020-11-20 12:46:53  [ main:207491 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:46:55  [ communication thread:209500 ] - [ INFO ]  map > map
2020-11-20 12:46:55  [ main:209500 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210094 ] - [ INFO ]  map > map
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210094 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210094 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210094 ] - [ INFO ]  bufstart = 0; bufend = 2390; bufvoid = 104857600
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210094 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210118 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210118 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210119 ] - [ INFO ]  Spilling map output
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210119 ] - [ INFO ]  bufstart = 0; bufend = 2390; bufvoid = 104857600
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210119 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:46:55  [ LocalJobRunner Map Task Executor #0:210141 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@1d6d4a7f
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:55  [ Thread-333:210141 ] - [ INFO ]  map task executor complete.
2020-11-20 12:46:55  [ Thread-333:210151 ] - [ WARN ]  job_local925600254_0018
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:46:56  [ main:210503 ] - [ INFO ]  Job job_local925600254_0018 failed with state FAILED due to: NA
2020-11-20 12:46:56  [ main:210504 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=3438
		FILE: Number of bytes written=5678450
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=26209384
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=145
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=87
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2390
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=2066743296
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:46:56  [ main:210542 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:46:56  [ main:210563 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:46:56  [ main:210568 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:46:56  [ main:210579 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:46:56  [ main:210622 ] - [ INFO ]  number of splits:1
2020-11-20 12:46:56  [ main:210639 ] - [ INFO ]  Submitting tokens for job: job_local822128577_0019
2020-11-20 12:46:56  [ main:210683 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:46:56  [ main:210683 ] - [ INFO ]  Running job: job_local822128577_0019
2020-11-20 12:46:56  [ Thread-351:210683 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:46:56  [ Thread-351:210684 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:56  [ Thread-351:210684 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:46:56  [ Thread-351:210696 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210696 ] - [ INFO ]  Starting task: attempt_local822128577_0019_m_000000_0
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210696 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210696 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210696 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210697 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210766 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210767 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210767 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210767 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210767 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:46:56  [ LocalJobRunner Map Task Executor #0:210767 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:46:57  [ main:211684 ] - [ INFO ]  Job job_local822128577_0019 running in uber mode : false
2020-11-20 12:46:57  [ main:211684 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:46:58  [ communication thread:212500 ] - [ INFO ]  map > sort
2020-11-20 12:47:01  [ communication thread:215502 ] - [ INFO ]  map > sort
2020-11-20 12:47:02  [ communication thread:216702 ] - [ INFO ]  map > map
2020-11-20 12:47:03  [ main:217704 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:47:05  [ communication thread:219707 ] - [ INFO ]  map > map
2020-11-20 12:47:05  [ main:219712 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220946 ] - [ INFO ]  map > map
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220947 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220947 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220947 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220947 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220969 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220969 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220969 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220969 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220969 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:06  [ LocalJobRunner Map Task Executor #0:220991 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@4c1674fd
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:06  [ Thread-351:220992 ] - [ INFO ]  map task executor complete.
2020-11-20 12:47:06  [ Thread-351:221003 ] - [ WARN ]  job_local822128577_0019
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:07  [ main:221719 ] - [ INFO ]  Job job_local822128577_0019 failed with state FAILED due to: NA
2020-11-20 12:47:07  [ main:221720 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=3629
		FILE: Number of bytes written=5982401
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27530748
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=153
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=92
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2394
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=2168455168
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:47:07  [ main:221755 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:47:07  [ main:221772 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:47:07  [ main:221777 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:47:07  [ main:221786 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:47:07  [ main:221827 ] - [ INFO ]  number of splits:1
2020-11-20 12:47:07  [ main:221844 ] - [ INFO ]  Submitting tokens for job: job_local1945044393_0020
2020-11-20 12:47:07  [ main:221882 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:47:07  [ main:221882 ] - [ INFO ]  Running job: job_local1945044393_0020
2020-11-20 12:47:07  [ Thread-369:221883 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:47:07  [ Thread-369:221883 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:07  [ Thread-369:221883 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:47:07  [ Thread-369:221896 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221896 ] - [ INFO ]  Starting task: attempt_local1945044393_0020_m_000000_0
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221897 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221897 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221897 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221898 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221944 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221944 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221944 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221944 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221945 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:47:07  [ LocalJobRunner Map Task Executor #0:221945 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:47:08  [ communication thread:222712 ] - [ INFO ]  map > sort
2020-11-20 12:47:08  [ main:222883 ] - [ INFO ]  Job job_local1945044393_0020 running in uber mode : false
2020-11-20 12:47:08  [ main:222883 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:47:11  [ communication thread:225714 ] - [ INFO ]  map > sort
2020-11-20 12:47:13  [ communication thread:227908 ] - [ INFO ]  map > map
2020-11-20 12:47:14  [ main:228909 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:47:16  [ communication thread:230912 ] - [ INFO ]  map > map
2020-11-20 12:47:16  [ main:230914 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231512 ] - [ INFO ]  map > map
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231513 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231513 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231513 ] - [ INFO ]  bufstart = 0; bufend = 2388; bufvoid = 104857600
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231513 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231534 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231534 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231534 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231534 ] - [ INFO ]  bufstart = 0; bufend = 2388; bufvoid = 104857600
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231534 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:231554 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@296436dd
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:17  [ Thread-369:231555 ] - [ INFO ]  map task executor complete.
2020-11-20 12:47:17  [ Thread-369:231565 ] - [ WARN ]  job_local1945044393_0020
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:17  [ main:231918 ] - [ INFO ]  Job job_local1945044393_0020 failed with state FAILED due to: NA
2020-11-20 12:47:17  [ main:231920 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=3820
		FILE: Number of bytes written=6287926
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29048720
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=161
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=97
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2388
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=2265972736
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:47:17  [ main:231966 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:47:17  [ main:231986 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:47:17  [ main:231990 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:47:17  [ main:231999 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:47:17  [ main:232039 ] - [ INFO ]  number of splits:1
2020-11-20 12:47:17  [ main:232056 ] - [ INFO ]  Submitting tokens for job: job_local1257917363_0021
2020-11-20 12:47:17  [ main:232093 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:47:17  [ main:232093 ] - [ INFO ]  Running job: job_local1257917363_0021
2020-11-20 12:47:17  [ Thread-387:232093 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:47:17  [ Thread-387:232094 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:17  [ Thread-387:232094 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:47:17  [ Thread-387:232106 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232106 ] - [ INFO ]  Starting task: attempt_local1257917363_0021_m_000000_0
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232106 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232106 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232106 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232107 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232158 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232158 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232159 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232159 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232159 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:47:17  [ LocalJobRunner Map Task Executor #0:232159 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:47:18  [ main:233098 ] - [ INFO ]  Job job_local1257917363_0021 running in uber mode : false
2020-11-20 12:47:18  [ main:233098 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:47:19  [ communication thread:233914 ] - [ INFO ]  map > sort
2020-11-20 12:47:22  [ communication thread:236918 ] - [ INFO ]  map > sort
2020-11-20 12:47:23  [ communication thread:238113 ] - [ INFO ]  map > map
2020-11-20 12:47:24  [ main:239116 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:47:26  [ communication thread:241117 ] - [ INFO ]  map > map
2020-11-20 12:47:26  [ main:241119 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242318 ] - [ INFO ]  map > map
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242318 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242318 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242318 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242318 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242339 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242339 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242339 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242339 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242339 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:27  [ LocalJobRunner Map Task Executor #0:242353 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@7caecda3
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:27  [ Thread-387:242354 ] - [ INFO ]  map task executor complete.
2020-11-20 12:47:27  [ Thread-387:242360 ] - [ WARN ]  job_local1257917363_0021
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:28  [ main:243125 ] - [ INFO ]  Job job_local1257917363_0021 failed with state FAILED due to: NA
2020-11-20 12:47:28  [ main:243125 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=4011
		FILE: Number of bytes written=6594547
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30304548
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=169
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=102
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=2373451776
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:47:28  [ main:243148 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:47:29  [ main:243925 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:47:29  [ main:243930 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:47:29  [ main:243937 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:47:29  [ main:243977 ] - [ INFO ]  number of splits:1
2020-11-20 12:47:29  [ main:243999 ] - [ INFO ]  Submitting tokens for job: job_local823102951_0022
2020-11-20 12:47:29  [ main:244034 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:47:29  [ main:244034 ] - [ INFO ]  Running job: job_local823102951_0022
2020-11-20 12:47:29  [ Thread-406:244034 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:47:29  [ Thread-406:244035 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:29  [ Thread-406:244035 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:47:29  [ Thread-406:244044 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244044 ] - [ INFO ]  Starting task: attempt_local823102951_0022_m_000000_0
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244045 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244045 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244045 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244045 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244101 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244101 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244101 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244101 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244101 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:47:29  [ LocalJobRunner Map Task Executor #0:244102 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:47:29  [ communication thread:244118 ] - [ INFO ]  map > sort
2020-11-20 12:47:30  [ main:245036 ] - [ INFO ]  Job job_local823102951_0022 running in uber mode : false
2020-11-20 12:47:30  [ main:245036 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:47:32  [ communication thread:247123 ] - [ INFO ]  map > sort
2020-11-20 12:47:35  [ communication thread:250052 ] - [ INFO ]  map > map
2020-11-20 12:47:36  [ main:251053 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:47:38  [ communication thread:253053 ] - [ INFO ]  map > map
2020-11-20 12:47:38  [ main:253062 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253481 ] - [ INFO ]  map > map
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253482 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253482 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253482 ] - [ INFO ]  bufstart = 0; bufend = 2399; bufvoid = 104857600
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253482 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253497 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253498 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253498 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253498 ] - [ INFO ]  bufstart = 0; bufend = 2399; bufvoid = 104857600
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253498 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:253510 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@5afe081c
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:39  [ Thread-406:253511 ] - [ INFO ]  map task executor complete.
2020-11-20 12:47:39  [ Thread-406:253517 ] - [ WARN ]  job_local823102951_0022
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:39  [ main:254065 ] - [ INFO ]  Job job_local823102951_0022 failed with state FAILED due to: NA
2020-11-20 12:47:39  [ main:254066 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=4202
		FILE: Number of bytes written=6899682
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=31822520
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=177
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=107
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2399
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=2474115072
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:47:39  [ main:254089 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:47:39  [ main:254110 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:47:39  [ main:254114 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:47:39  [ main:254120 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:47:39  [ main:254157 ] - [ INFO ]  number of splits:1
2020-11-20 12:47:39  [ main:254174 ] - [ INFO ]  Submitting tokens for job: job_local122212446_0023
2020-11-20 12:47:39  [ main:254214 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:47:39  [ main:254214 ] - [ INFO ]  Running job: job_local122212446_0023
2020-11-20 12:47:39  [ Thread-424:254214 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:47:39  [ Thread-424:254215 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:39  [ Thread-424:254215 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:47:39  [ Thread-424:254222 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254223 ] - [ INFO ]  Starting task: attempt_local122212446_0023_m_000000_0
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254223 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254224 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254224 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254224 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254290 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254290 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254290 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254290 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254290 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:47:39  [ LocalJobRunner Map Task Executor #0:254291 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:47:40  [ main:255218 ] - [ INFO ]  Job job_local122212446_0023 running in uber mode : false
2020-11-20 12:47:40  [ main:255219 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:47:41  [ communication thread:256058 ] - [ INFO ]  map > sort
2020-11-20 12:47:44  [ communication thread:259063 ] - [ INFO ]  map > sort
2020-11-20 12:47:45  [ communication thread:260231 ] - [ INFO ]  map > map
2020-11-20 12:47:45  [ main:260233 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:47:48  [ communication thread:263235 ] - [ INFO ]  map > map
2020-11-20 12:47:48  [ main:263240 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264051 ] - [ INFO ]  map > map
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264051 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264051 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264051 ] - [ INFO ]  bufstart = 0; bufend = 2263; bufvoid = 104857600
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264051 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264066 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264066 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264066 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264066 ] - [ INFO ]  bufstart = 0; bufend = 2263; bufvoid = 104857600
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264066 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264081 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@5a10446e
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:49  [ Thread-424:264081 ] - [ INFO ]  map task executor complete.
2020-11-20 12:47:49  [ Thread-424:264088 ] - [ WARN ]  job_local122212446_0023
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:47:49  [ main:264243 ] - [ INFO ]  Job job_local122212446_0023 failed with state FAILED due to: NA
2020-11-20 12:47:49  [ main:264244 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=4393
		FILE: Number of bytes written=7186331
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33143884
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=185
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=112
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2263
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=2580021248
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:47:49  [ main:264264 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:47:49  [ main:264276 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:47:49  [ main:264281 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:47:49  [ main:264287 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:47:49  [ main:264322 ] - [ INFO ]  number of splits:1
2020-11-20 12:47:49  [ main:264339 ] - [ INFO ]  Submitting tokens for job: job_local2058466549_0024
2020-11-20 12:47:49  [ main:264380 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:47:49  [ main:264380 ] - [ INFO ]  Running job: job_local2058466549_0024
2020-11-20 12:47:49  [ Thread-442:264380 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:47:49  [ Thread-442:264381 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:49  [ Thread-442:264381 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:47:49  [ Thread-442:264389 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264389 ] - [ INFO ]  Starting task: attempt_local2058466549_0024_m_000000_0
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264389 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264389 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264389 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:47:49  [ LocalJobRunner Map Task Executor #0:264390 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:47:50  [ LocalJobRunner Map Task Executor #0:264461 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:47:50  [ LocalJobRunner Map Task Executor #0:264461 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:47:50  [ LocalJobRunner Map Task Executor #0:264461 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:47:50  [ LocalJobRunner Map Task Executor #0:264461 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:47:50  [ LocalJobRunner Map Task Executor #0:264461 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:47:50  [ LocalJobRunner Map Task Executor #0:264462 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:47:50  [ main:265383 ] - [ INFO ]  Job job_local2058466549_0024 running in uber mode : false
2020-11-20 12:47:50  [ main:265383 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:47:51  [ communication thread:266240 ] - [ INFO ]  map > sort
2020-11-20 12:47:54  [ communication thread:269242 ] - [ INFO ]  map > sort
2020-11-20 12:47:55  [ communication thread:270395 ] - [ INFO ]  map > map
2020-11-20 12:47:55  [ main:270401 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:47:58  [ communication thread:273401 ] - [ INFO ]  map > map
2020-11-20 12:47:58  [ main:273413 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:47:59  [ LocalJobRunner Map Task Executor #0:274425 ] - [ INFO ]  map > map
2020-11-20 12:47:59  [ LocalJobRunner Map Task Executor #0:274426 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:47:59  [ LocalJobRunner Map Task Executor #0:274426 ] - [ INFO ]  Spilling map output
2020-11-20 12:47:59  [ LocalJobRunner Map Task Executor #0:274426 ] - [ INFO ]  bufstart = 0; bufend = 2249; bufvoid = 104857600
2020-11-20 12:47:59  [ LocalJobRunner Map Task Executor #0:274426 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:00  [ LocalJobRunner Map Task Executor #0:274441 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:00  [ LocalJobRunner Map Task Executor #0:274441 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:48:00  [ LocalJobRunner Map Task Executor #0:274441 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:00  [ LocalJobRunner Map Task Executor #0:274441 ] - [ INFO ]  bufstart = 0; bufend = 2249; bufvoid = 104857600
2020-11-20 12:48:00  [ LocalJobRunner Map Task Executor #0:274441 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:00  [ LocalJobRunner Map Task Executor #0:274454 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@2fbf74c0
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:00  [ Thread-442:274455 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:00  [ Thread-442:274462 ] - [ WARN ]  job_local2058466549_0024
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:00  [ main:275417 ] - [ INFO ]  Job job_local2058466549_0024 failed with state FAILED due to: NA
2020-11-20 12:48:00  [ main:275418 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=4584
		FILE: Number of bytes written=7475060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34465248
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=193
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=117
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2249
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=2681733120
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:48:01  [ main:275438 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:01  [ main:275452 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:01  [ main:275457 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:01  [ main:275469 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:01  [ main:275510 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:01  [ main:275527 ] - [ INFO ]  Submitting tokens for job: job_local2123411035_0025
2020-11-20 12:48:01  [ main:275567 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:01  [ main:275567 ] - [ INFO ]  Running job: job_local2123411035_0025
2020-11-20 12:48:01  [ Thread-460:275568 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:01  [ Thread-460:275568 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:01  [ Thread-460:275568 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:01  [ Thread-460:275576 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275576 ] - [ INFO ]  Starting task: attempt_local2123411035_0025_m_000000_0
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275576 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275576 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275576 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275577 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275635 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275635 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275635 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275635 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275635 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:48:01  [ LocalJobRunner Map Task Executor #0:275636 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:48:01  [ communication thread:276402 ] - [ INFO ]  map > sort
2020-11-20 12:48:02  [ main:276568 ] - [ INFO ]  Job job_local2123411035_0025 running in uber mode : false
2020-11-20 12:48:02  [ main:276569 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:04  [ communication thread:279404 ] - [ INFO ]  map > sort
2020-11-20 12:48:07  [ communication thread:281586 ] - [ INFO ]  map > map
2020-11-20 12:48:07  [ main:281590 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:48:10  [ communication thread:284591 ] - [ INFO ]  map > map
2020-11-20 12:48:10  [ main:284601 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285207 ] - [ INFO ]  map > map
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285207 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285207 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285207 ] - [ INFO ]  bufstart = 0; bufend = 2332; bufvoid = 104857600
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285207 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285223 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285223 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285223 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285223 ] - [ INFO ]  bufstart = 0; bufend = 2332; bufvoid = 104857600
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285223 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:10  [ LocalJobRunner Map Task Executor #0:285236 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@3730a8f
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:10  [ Thread-460:285237 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:10  [ Thread-460:285244 ] - [ WARN ]  job_local2123411035_0025
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:11  [ main:285603 ] - [ INFO ]  Job job_local2123411035_0025 failed with state FAILED due to: NA
2020-11-20 12:48:11  [ main:285605 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=4775
		FILE: Number of bytes written=7764297
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=35917684
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=201
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=122
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2332
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=2786590720
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:48:11  [ main:285631 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:11  [ main:285644 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:11  [ main:285648 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:11  [ main:285654 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:11  [ main:285690 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:11  [ main:285707 ] - [ INFO ]  Submitting tokens for job: job_local1295960993_0026
2020-11-20 12:48:11  [ main:285748 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:11  [ main:285748 ] - [ INFO ]  Running job: job_local1295960993_0026
2020-11-20 12:48:11  [ Thread-478:285748 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:11  [ Thread-478:285748 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:11  [ Thread-478:285748 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:11  [ Thread-478:285757 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285757 ] - [ INFO ]  Starting task: attempt_local1295960993_0026_m_000000_0
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285757 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285758 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285758 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285758 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285816 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285816 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285816 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285816 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285816 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:48:11  [ LocalJobRunner Map Task Executor #0:285817 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:48:12  [ main:286751 ] - [ INFO ]  Job job_local1295960993_0026 running in uber mode : false
2020-11-20 12:48:12  [ main:286751 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:13  [ communication thread:287595 ] - [ INFO ]  map > sort
2020-11-20 12:48:16  [ communication thread:290599 ] - [ INFO ]  map > sort
2020-11-20 12:48:17  [ communication thread:291766 ] - [ INFO ]  map > map
2020-11-20 12:48:17  [ main:291768 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:48:20  [ communication thread:294771 ] - [ INFO ]  map > map
2020-11-20 12:48:20  [ main:294778 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295625 ] - [ INFO ]  map > map
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295626 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295626 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295626 ] - [ INFO ]  bufstart = 0; bufend = 2299; bufvoid = 104857600
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295626 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295642 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295642 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295642 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295642 ] - [ INFO ]  bufstart = 0; bufend = 2299; bufvoid = 104857600
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295642 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295655 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@460b653b
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:21  [ Thread-478:295655 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:21  [ Thread-478:295665 ] - [ WARN ]  job_local1295960993_0026
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:21  [ main:295783 ] - [ INFO ]  Job job_local1295960993_0026 failed with state FAILED due to: NA
2020-11-20 12:48:21  [ main:295783 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=4966
		FILE: Number of bytes written=8053692
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=37304584
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=209
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=127
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2299
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=2888826880
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:48:21  [ main:295800 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:21  [ main:295817 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:21  [ main:295821 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:21  [ main:295826 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:21  [ main:295871 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:21  [ main:295889 ] - [ INFO ]  Submitting tokens for job: job_local93665691_0027
2020-11-20 12:48:21  [ main:295925 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:21  [ main:295925 ] - [ INFO ]  Running job: job_local93665691_0027
2020-11-20 12:48:21  [ Thread-496:295925 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:21  [ Thread-496:295925 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:21  [ Thread-496:295925 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:21  [ Thread-496:295934 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295934 ] - [ INFO ]  Starting task: attempt_local93665691_0027_m_000000_0
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295935 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295935 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295935 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295935 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295999 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295999 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295999 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295999 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:295999 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:48:21  [ LocalJobRunner Map Task Executor #0:296000 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:48:22  [ main:296928 ] - [ INFO ]  Job job_local93665691_0027 running in uber mode : false
2020-11-20 12:48:22  [ main:296929 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:23  [ communication thread:297775 ] - [ INFO ]  map > sort
2020-11-20 12:48:26  [ communication thread:300780 ] - [ INFO ]  map > sort
2020-11-20 12:48:27  [ communication thread:301938 ] - [ INFO ]  map > map
2020-11-20 12:48:27  [ main:301941 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:48:30  [ communication thread:304944 ] - [ INFO ]  map > map
2020-11-20 12:48:30  [ main:304949 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306040 ] - [ INFO ]  map > map
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306041 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306041 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306041 ] - [ INFO ]  bufstart = 0; bufend = 2304; bufvoid = 104857600
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306041 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306066 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306066 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306066 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306066 ] - [ INFO ]  bufstart = 0; bufend = 2304; bufvoid = 104857600
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306066 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:31  [ LocalJobRunner Map Task Executor #0:306080 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@47bbca59
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:31  [ Thread-496:306080 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:31  [ Thread-496:306088 ] - [ WARN ]  job_local93665691_0027
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:32  [ main:306953 ] - [ INFO ]  Job job_local93665691_0027 failed with state FAILED due to: NA
2020-11-20 12:48:32  [ main:306953 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=5157
		FILE: Number of bytes written=8341713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=38625948
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=217
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=132
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2304
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=2907176960
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:48:32  [ main:306979 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:32  [ main:306996 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:32  [ main:307001 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:32  [ main:307008 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:32  [ main:307045 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:32  [ main:307063 ] - [ INFO ]  Submitting tokens for job: job_local1599558431_0028
2020-11-20 12:48:32  [ main:307110 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:32  [ main:307110 ] - [ INFO ]  Running job: job_local1599558431_0028
2020-11-20 12:48:32  [ Thread-515:307110 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:32  [ Thread-515:307110 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:32  [ Thread-515:307111 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:32  [ Thread-515:307119 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:32  [ LocalJobRunner Map Task Executor #0:307119 ] - [ INFO ]  Starting task: attempt_local1599558431_0028_m_000000_0
2020-11-20 12:48:32  [ LocalJobRunner Map Task Executor #0:307120 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:32  [ LocalJobRunner Map Task Executor #0:307120 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:32  [ LocalJobRunner Map Task Executor #0:307120 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:32  [ LocalJobRunner Map Task Executor #0:307120 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:33  [ Thread-515:307715 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:33  [ Thread-515:307871 ] - [ WARN ]  job_local1599558431_0028
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:986)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:698)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:770)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:33  [ communication thread:307949 ] - [ INFO ]  map > sort
2020-11-20 12:48:33  [ main:308113 ] - [ INFO ]  Job job_local1599558431_0028 running in uber mode : false
2020-11-20 12:48:33  [ main:308114 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:33  [ main:308114 ] - [ INFO ]  Job job_local1599558431_0028 failed with state FAILED due to: NA
2020-11-20 12:48:33  [ main:308114 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:33  [ main:308269 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:33  [ main:308287 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:33  [ main:308291 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:34  [ main:308447 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:34  [ main:308486 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:34  [ main:308503 ] - [ INFO ]  Submitting tokens for job: job_local599080240_0029
2020-11-20 12:48:34  [ main:308537 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:34  [ main:308537 ] - [ INFO ]  Running job: job_local599080240_0029
2020-11-20 12:48:34  [ Thread-533:308537 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:34  [ Thread-533:308537 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:34  [ Thread-533:308537 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:34  [ Thread-533:308605 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:34  [ LocalJobRunner Map Task Executor #0:308605 ] - [ INFO ]  Starting task: attempt_local599080240_0029_m_000000_0
2020-11-20 12:48:34  [ LocalJobRunner Map Task Executor #0:308607 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:34  [ LocalJobRunner Map Task Executor #0:308607 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:34  [ LocalJobRunner Map Task Executor #0:308607 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:34  [ LocalJobRunner Map Task Executor #0:308608 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:34  [ Thread-533:308933 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:34  [ Thread-533:308941 ] - [ WARN ]  job_local599080240_0029
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:986)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:698)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:770)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:35  [ main:309540 ] - [ INFO ]  Job job_local599080240_0029 running in uber mode : false
2020-11-20 12:48:35  [ main:309541 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:35  [ main:309541 ] - [ INFO ]  Job job_local599080240_0029 failed with state FAILED due to: NA
2020-11-20 12:48:35  [ main:309541 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:35  [ main:309562 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:35  [ main:309572 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:35  [ main:309577 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:35  [ main:309583 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:35  [ main:309622 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:35  [ main:309639 ] - [ INFO ]  Submitting tokens for job: job_local1786384811_0030
2020-11-20 12:48:35  [ main:309673 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:35  [ main:309673 ] - [ INFO ]  Running job: job_local1786384811_0030
2020-11-20 12:48:35  [ Thread-551:309673 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:35  [ Thread-551:309673 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:35  [ Thread-551:309674 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:35  [ Thread-551:309683 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:35  [ LocalJobRunner Map Task Executor #0:309683 ] - [ INFO ]  Starting task: attempt_local1786384811_0030_m_000000_0
2020-11-20 12:48:35  [ LocalJobRunner Map Task Executor #0:309684 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:35  [ LocalJobRunner Map Task Executor #0:309684 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:35  [ LocalJobRunner Map Task Executor #0:309684 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:35  [ LocalJobRunner Map Task Executor #0:309684 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:35  [ Thread-551:310005 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:35  [ Thread-551:310012 ] - [ WARN ]  job_local1786384811_0030
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:36  [ main:310674 ] - [ INFO ]  Job job_local1786384811_0030 running in uber mode : false
2020-11-20 12:48:36  [ main:310674 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:36  [ main:310674 ] - [ INFO ]  Job job_local1786384811_0030 failed with state FAILED due to: NA
2020-11-20 12:48:36  [ main:310674 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:36  [ main:310697 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:36  [ main:310710 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:36  [ main:310715 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:36  [ main:310720 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:36  [ main:310761 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:36  [ main:310777 ] - [ INFO ]  Submitting tokens for job: job_local1004120412_0031
2020-11-20 12:48:36  [ main:310811 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:36  [ main:310811 ] - [ INFO ]  Running job: job_local1004120412_0031
2020-11-20 12:48:36  [ Thread-569:310812 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:36  [ Thread-569:310812 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:36  [ Thread-569:310812 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:36  [ Thread-569:310822 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:36  [ LocalJobRunner Map Task Executor #0:310822 ] - [ INFO ]  Starting task: attempt_local1004120412_0031_m_000000_0
2020-11-20 12:48:36  [ LocalJobRunner Map Task Executor #0:310823 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:36  [ LocalJobRunner Map Task Executor #0:310823 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:36  [ LocalJobRunner Map Task Executor #0:310823 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:36  [ LocalJobRunner Map Task Executor #0:310824 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:36  [ Thread-569:310891 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:36  [ Thread-569:310905 ] - [ WARN ]  job_local1004120412_0031
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:36  [ communication thread:310953 ] - [ INFO ]  map > sort
2020-11-20 12:48:37  [ main:311815 ] - [ INFO ]  Job job_local1004120412_0031 running in uber mode : false
2020-11-20 12:48:37  [ main:311816 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:37  [ main:311816 ] - [ INFO ]  Job job_local1004120412_0031 failed with state FAILED due to: NA
2020-11-20 12:48:37  [ main:311816 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:37  [ main:311841 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:37  [ main:311862 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:37  [ main:311868 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:37  [ main:311879 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:37  [ main:311942 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:37  [ main:311969 ] - [ INFO ]  Submitting tokens for job: job_local1910377873_0032
2020-11-20 12:48:37  [ main:312014 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:37  [ main:312014 ] - [ INFO ]  Running job: job_local1910377873_0032
2020-11-20 12:48:37  [ Thread-587:312014 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:37  [ Thread-587:312015 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:37  [ Thread-587:312015 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:37  [ Thread-587:312023 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:37  [ LocalJobRunner Map Task Executor #0:312023 ] - [ INFO ]  Starting task: attempt_local1910377873_0032_m_000000_0
2020-11-20 12:48:37  [ LocalJobRunner Map Task Executor #0:312024 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:37  [ LocalJobRunner Map Task Executor #0:312024 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:37  [ LocalJobRunner Map Task Executor #0:312024 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:37  [ LocalJobRunner Map Task Executor #0:312025 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:37  [ Thread-587:312278 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:37  [ Thread-587:312285 ] - [ WARN ]  job_local1910377873_0032
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:38  [ main:313017 ] - [ INFO ]  Job job_local1910377873_0032 running in uber mode : false
2020-11-20 12:48:38  [ main:313017 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:38  [ main:313017 ] - [ INFO ]  Job job_local1910377873_0032 failed with state FAILED due to: NA
2020-11-20 12:48:38  [ main:313017 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:38  [ main:313035 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:38  [ main:313048 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:38  [ main:313054 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:38  [ main:313061 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:38  [ main:313104 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:38  [ main:313125 ] - [ INFO ]  Submitting tokens for job: job_local773120804_0033
2020-11-20 12:48:38  [ main:313170 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:38  [ main:313170 ] - [ INFO ]  Running job: job_local773120804_0033
2020-11-20 12:48:38  [ Thread-605:313170 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:38  [ Thread-605:313170 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:38  [ Thread-605:313170 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:38  [ Thread-605:313179 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:38  [ LocalJobRunner Map Task Executor #0:313179 ] - [ INFO ]  Starting task: attempt_local773120804_0033_m_000000_0
2020-11-20 12:48:38  [ LocalJobRunner Map Task Executor #0:313179 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:38  [ LocalJobRunner Map Task Executor #0:313180 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:38  [ LocalJobRunner Map Task Executor #0:313180 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:38  [ LocalJobRunner Map Task Executor #0:313180 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:38  [ Thread-605:313254 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:38  [ Thread-605:313261 ] - [ WARN ]  job_local773120804_0033
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:39  [ main:314173 ] - [ INFO ]  Job job_local773120804_0033 running in uber mode : false
2020-11-20 12:48:39  [ main:314173 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:39  [ main:314174 ] - [ INFO ]  Job job_local773120804_0033 failed with state FAILED due to: NA
2020-11-20 12:48:39  [ main:314174 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:39  [ main:314192 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:39  [ main:314204 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:39  [ main:314209 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:39  [ main:314215 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:39  [ main:314257 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:39  [ main:314274 ] - [ INFO ]  Submitting tokens for job: job_local1341359372_0034
2020-11-20 12:48:39  [ main:314310 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:39  [ main:314310 ] - [ INFO ]  Running job: job_local1341359372_0034
2020-11-20 12:48:39  [ Thread-623:314310 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:39  [ Thread-623:314310 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:39  [ Thread-623:314310 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:39  [ Thread-623:314321 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:39  [ LocalJobRunner Map Task Executor #0:314321 ] - [ INFO ]  Starting task: attempt_local1341359372_0034_m_000000_0
2020-11-20 12:48:39  [ LocalJobRunner Map Task Executor #0:314321 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:39  [ LocalJobRunner Map Task Executor #0:314322 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:39  [ LocalJobRunner Map Task Executor #0:314322 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:39  [ LocalJobRunner Map Task Executor #0:314322 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:39  [ Thread-623:314394 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:39  [ Thread-623:314402 ] - [ WARN ]  job_local1341359372_0034
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:40  [ main:315314 ] - [ INFO ]  Job job_local1341359372_0034 running in uber mode : false
2020-11-20 12:48:40  [ main:315314 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:40  [ main:315314 ] - [ INFO ]  Job job_local1341359372_0034 failed with state FAILED due to: NA
2020-11-20 12:48:40  [ main:315314 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:40  [ main:315334 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:40  [ main:315346 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:40  [ main:315351 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:40  [ main:315357 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:40  [ main:315396 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:40  [ main:315413 ] - [ INFO ]  Submitting tokens for job: job_local226558276_0035
2020-11-20 12:48:41  [ main:315447 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:41  [ main:315447 ] - [ INFO ]  Running job: job_local226558276_0035
2020-11-20 12:48:41  [ Thread-641:315448 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:41  [ Thread-641:315448 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:41  [ Thread-641:315448 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:41  [ Thread-641:315457 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315458 ] - [ INFO ]  Starting task: attempt_local226558276_0035_m_000000_0
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315459 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315459 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315459 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315459 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315491 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315491 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315491 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315491 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315491 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:48:41  [ LocalJobRunner Map Task Executor #0:315491 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:48:42  [ main:316449 ] - [ INFO ]  Job job_local226558276_0035 running in uber mode : false
2020-11-20 12:48:42  [ main:316449 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:47  [ communication thread:321485 ] - [ INFO ]  map > map
2020-11-20 12:48:48  [ main:322549 ] - [ INFO ]   map 43% reduce 0%
2020-11-20 12:48:50  [ communication thread:324529 ] - [ INFO ]  map > map
2020-11-20 12:48:50  [ main:324598 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:324961 ] - [ INFO ]  map > map
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:324962 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:324962 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:324962 ] - [ INFO ]  bufstart = 0; bufend = 2429; bufvoid = 104857600
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:324962 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:325030 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:325030 ] - [ INFO ]  (RESET) equator 0 kv 26214396(104857584) kvi 26213996(104855984)
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:325030 ] - [ INFO ]  Spilling map output
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:325030 ] - [ INFO ]  bufstart = 0; bufend = 2429; bufvoid = 104857600
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:325030 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:48:50  [ LocalJobRunner Map Task Executor #0:325044 ] - [ INFO ]  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@5216c3bf
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:50  [ Thread-641:325045 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:50  [ Thread-641:325051 ] - [ WARN ]  job_local226558276_0035
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result.txt for DFSClient_NONMAPREDUCE_-772804812_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-772804812_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:88)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserCombiner.reduce(SimilarUserMapReduceJob.java:75)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1688)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1637)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 12:48:51  [ main:325600 ] - [ INFO ]  Job job_local226558276_0035 failed with state FAILED due to: NA
2020-11-20 12:48:51  [ main:325601 ] - [ INFO ]  Counters: 23
	File System Counters
		FILE: Number of bytes read=6685
		FILE: Number of bytes written=10751971
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=40078384
		HDFS: Number of bytes written=2074
		HDFS: Number of read operations=260
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=158
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2429
		Map output materialized bytes=0
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=1527
		Total committed heap usage (bytes)=2973237248
	File Input Format Counters 
		Bytes Read=1386900
2020-11-20 12:48:51  [ main:325620 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:51  [ main:325682 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:51  [ main:325686 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:51  [ main:325692 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:51  [ main:325806 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:51  [ main:325902 ] - [ INFO ]  Submitting tokens for job: job_local996896302_0036
2020-11-20 12:48:51  [ main:326298 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:51  [ main:326299 ] - [ INFO ]  Running job: job_local996896302_0036
2020-11-20 12:48:51  [ Thread-659:326299 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:51  [ Thread-659:326299 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:51  [ Thread-659:326299 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:51  [ Thread-659:326348 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:51  [ LocalJobRunner Map Task Executor #0:326348 ] - [ INFO ]  Starting task: attempt_local996896302_0036_m_000000_0
2020-11-20 12:48:51  [ LocalJobRunner Map Task Executor #0:326348 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:51  [ LocalJobRunner Map Task Executor #0:326348 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:51  [ LocalJobRunner Map Task Executor #0:326348 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:51  [ LocalJobRunner Map Task Executor #0:326349 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:51  [ Thread-659:326426 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:52  [ Thread-659:326433 ] - [ WARN ]  job_local996896302_0036
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:52  [ main:327301 ] - [ INFO ]  Job job_local996896302_0036 running in uber mode : false
2020-11-20 12:48:52  [ main:327302 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:52  [ main:327302 ] - [ INFO ]  Job job_local996896302_0036 failed with state FAILED due to: NA
2020-11-20 12:48:52  [ main:327302 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:52  [ main:327364 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:52  [ main:327392 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:52  [ main:327396 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:53  [ main:327451 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:53  [ communication thread:327535 ] - [ INFO ]  map > sort
2020-11-20 12:48:53  [ main:327535 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:53  [ main:327674 ] - [ INFO ]  Submitting tokens for job: job_local1289056694_0037
2020-11-20 12:48:53  [ main:328030 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:53  [ main:328030 ] - [ INFO ]  Running job: job_local1289056694_0037
2020-11-20 12:48:53  [ Thread-677:328030 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:53  [ Thread-677:328030 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:53  [ Thread-677:328030 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:53  [ Thread-677:328079 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:53  [ LocalJobRunner Map Task Executor #0:328079 ] - [ INFO ]  Starting task: attempt_local1289056694_0037_m_000000_0
2020-11-20 12:48:53  [ LocalJobRunner Map Task Executor #0:328080 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:53  [ LocalJobRunner Map Task Executor #0:328080 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:53  [ LocalJobRunner Map Task Executor #0:328080 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:53  [ LocalJobRunner Map Task Executor #0:328081 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:53  [ Thread-677:328163 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:53  [ Thread-677:328170 ] - [ WARN ]  job_local1289056694_0037
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:54  [ main:329034 ] - [ INFO ]  Job job_local1289056694_0037 running in uber mode : false
2020-11-20 12:48:54  [ main:329035 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:54  [ main:329035 ] - [ INFO ]  Job job_local1289056694_0037 failed with state FAILED due to: NA
2020-11-20 12:48:54  [ main:329035 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:54  [ main:329056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:54  [ main:329068 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:54  [ main:329116 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:54  [ main:329123 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:54  [ main:329197 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:54  [ main:329337 ] - [ INFO ]  Submitting tokens for job: job_local1260418524_0038
2020-11-20 12:48:55  [ main:329703 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:55  [ main:329703 ] - [ INFO ]  Running job: job_local1260418524_0038
2020-11-20 12:48:55  [ Thread-695:329703 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:55  [ Thread-695:329703 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:55  [ Thread-695:329703 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:55  [ Thread-695:329752 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:55  [ LocalJobRunner Map Task Executor #0:329752 ] - [ INFO ]  Starting task: attempt_local1260418524_0038_m_000000_0
2020-11-20 12:48:55  [ LocalJobRunner Map Task Executor #0:329753 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:55  [ LocalJobRunner Map Task Executor #0:329753 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:55  [ LocalJobRunner Map Task Executor #0:329753 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:55  [ LocalJobRunner Map Task Executor #0:329754 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:55  [ Thread-695:329835 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:55  [ Thread-695:329842 ] - [ WARN ]  job_local1260418524_0038
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:56  [ communication thread:330540 ] - [ INFO ]  map > sort
2020-11-20 12:48:56  [ main:330708 ] - [ INFO ]  Job job_local1260418524_0038 running in uber mode : false
2020-11-20 12:48:56  [ main:330708 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:56  [ main:330708 ] - [ INFO ]  Job job_local1260418524_0038 failed with state FAILED due to: NA
2020-11-20 12:48:56  [ main:330708 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:56  [ main:330730 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:56  [ main:330744 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:56  [ main:330793 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:56  [ main:330799 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:56  [ main:330884 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:56  [ main:330981 ] - [ INFO ]  Submitting tokens for job: job_local2127038182_0039
2020-11-20 12:48:56  [ main:331381 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:56  [ main:331381 ] - [ INFO ]  Running job: job_local2127038182_0039
2020-11-20 12:48:56  [ Thread-713:331421 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:56  [ Thread-713:331421 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:56  [ Thread-713:331421 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:57  [ Thread-713:331436 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:57  [ LocalJobRunner Map Task Executor #0:331436 ] - [ INFO ]  Starting task: attempt_local2127038182_0039_m_000000_0
2020-11-20 12:48:57  [ LocalJobRunner Map Task Executor #0:331437 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:57  [ LocalJobRunner Map Task Executor #0:331437 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:57  [ LocalJobRunner Map Task Executor #0:331437 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:57  [ LocalJobRunner Map Task Executor #0:331437 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:57  [ Thread-713:331517 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:57  [ Thread-713:331524 ] - [ WARN ]  job_local2127038182_0039
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:57  [ main:332425 ] - [ INFO ]  Job job_local2127038182_0039 running in uber mode : false
2020-11-20 12:48:57  [ main:332426 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:57  [ main:332426 ] - [ INFO ]  Job job_local2127038182_0039 failed with state FAILED due to: NA
2020-11-20 12:48:57  [ main:332426 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:58  [ main:332445 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:58  [ main:332458 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:58  [ main:332507 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:58  [ main:332513 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:58  [ main:332588 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:58  [ main:332723 ] - [ INFO ]  Submitting tokens for job: job_local471582379_0040
2020-11-20 12:48:58  [ main:333082 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:48:58  [ main:333082 ] - [ INFO ]  Running job: job_local471582379_0040
2020-11-20 12:48:58  [ Thread-731:333082 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:48:58  [ Thread-731:333082 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:58  [ Thread-731:333082 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:48:58  [ Thread-731:333136 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:48:58  [ LocalJobRunner Map Task Executor #0:333137 ] - [ INFO ]  Starting task: attempt_local471582379_0040_m_000000_0
2020-11-20 12:48:58  [ LocalJobRunner Map Task Executor #0:333137 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:48:58  [ LocalJobRunner Map Task Executor #0:333137 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:48:58  [ LocalJobRunner Map Task Executor #0:333137 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:48:58  [ LocalJobRunner Map Task Executor #0:333138 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:48:58  [ Thread-731:333221 ] - [ INFO ]  map task executor complete.
2020-11-20 12:48:58  [ Thread-731:333229 ] - [ WARN ]  job_local471582379_0040
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:48:59  [ main:334084 ] - [ INFO ]  Job job_local471582379_0040 running in uber mode : false
2020-11-20 12:48:59  [ main:334085 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:48:59  [ main:334085 ] - [ INFO ]  Job job_local471582379_0040 failed with state FAILED due to: NA
2020-11-20 12:48:59  [ main:334085 ] - [ INFO ]  Counters: 0
2020-11-20 12:48:59  [ main:334118 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:48:59  [ main:334129 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:48:59  [ main:334177 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:48:59  [ main:334184 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:48:59  [ main:334264 ] - [ INFO ]  number of splits:1
2020-11-20 12:48:59  [ main:334402 ] - [ INFO ]  Submitting tokens for job: job_local83804147_0041
2020-11-20 12:49:00  [ main:334767 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:00  [ main:334767 ] - [ INFO ]  Running job: job_local83804147_0041
2020-11-20 12:49:00  [ Thread-749:334767 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:00  [ Thread-749:334767 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:00  [ Thread-749:334767 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:00  [ Thread-749:334810 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:00  [ LocalJobRunner Map Task Executor #0:334810 ] - [ INFO ]  Starting task: attempt_local83804147_0041_m_000000_0
2020-11-20 12:49:00  [ LocalJobRunner Map Task Executor #0:334811 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:00  [ LocalJobRunner Map Task Executor #0:334811 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:00  [ LocalJobRunner Map Task Executor #0:334811 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:00  [ LocalJobRunner Map Task Executor #0:334812 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:00  [ Thread-749:334883 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:00  [ Thread-749:334891 ] - [ WARN ]  job_local83804147_0041
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:01  [ main:335770 ] - [ INFO ]  Job job_local83804147_0041 running in uber mode : false
2020-11-20 12:49:01  [ main:335770 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:01  [ main:335770 ] - [ INFO ]  Job job_local83804147_0041 failed with state FAILED due to: NA
2020-11-20 12:49:01  [ main:335770 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:01  [ main:335795 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:01  [ main:335813 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:01  [ main:335855 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:01  [ main:335863 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:01  [ main:335938 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:01  [ main:336061 ] - [ INFO ]  Submitting tokens for job: job_local781763543_0042
2020-11-20 12:49:02  [ main:336452 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:02  [ main:336452 ] - [ INFO ]  Running job: job_local781763543_0042
2020-11-20 12:49:02  [ Thread-767:336453 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:02  [ Thread-767:336453 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:02  [ Thread-767:336453 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:02  [ Thread-767:336496 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:02  [ LocalJobRunner Map Task Executor #0:336497 ] - [ INFO ]  Starting task: attempt_local781763543_0042_m_000000_0
2020-11-20 12:49:02  [ LocalJobRunner Map Task Executor #0:336497 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:02  [ LocalJobRunner Map Task Executor #0:336498 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:02  [ LocalJobRunner Map Task Executor #0:336498 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:02  [ LocalJobRunner Map Task Executor #0:336498 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:02  [ Thread-767:336572 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:02  [ Thread-767:336579 ] - [ WARN ]  job_local781763543_0042
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:03  [ main:337457 ] - [ INFO ]  Job job_local781763543_0042 running in uber mode : false
2020-11-20 12:49:03  [ main:337457 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:03  [ main:337457 ] - [ INFO ]  Job job_local781763543_0042 failed with state FAILED due to: NA
2020-11-20 12:49:03  [ main:337458 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:03  [ main:337478 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:03  [ main:337534 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:03  [ main:337538 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:03  [ main:337546 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:03  [ main:337655 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:03  [ main:337780 ] - [ INFO ]  Submitting tokens for job: job_local1120764230_0043
2020-11-20 12:49:03  [ main:338210 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:03  [ main:338210 ] - [ INFO ]  Running job: job_local1120764230_0043
2020-11-20 12:49:03  [ Thread-785:338210 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:03  [ Thread-785:338210 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:03  [ Thread-785:338210 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:03  [ Thread-785:338262 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:03  [ LocalJobRunner Map Task Executor #0:338263 ] - [ INFO ]  Starting task: attempt_local1120764230_0043_m_000000_0
2020-11-20 12:49:03  [ LocalJobRunner Map Task Executor #0:338263 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:03  [ LocalJobRunner Map Task Executor #0:338264 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:03  [ LocalJobRunner Map Task Executor #0:338264 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:03  [ LocalJobRunner Map Task Executor #0:338264 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:03  [ Thread-785:338336 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:03  [ Thread-785:338344 ] - [ WARN ]  job_local1120764230_0043
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:04  [ main:339215 ] - [ INFO ]  Job job_local1120764230_0043 running in uber mode : false
2020-11-20 12:49:04  [ main:339216 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:04  [ main:339216 ] - [ INFO ]  Job job_local1120764230_0043 failed with state FAILED due to: NA
2020-11-20 12:49:04  [ main:339216 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:05  [ main:339465 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:05  [ main:339476 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:05  [ main:339482 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:05  [ main:339488 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:05  [ main:339599 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:05  [ main:339760 ] - [ INFO ]  Submitting tokens for job: job_local399401828_0044
2020-11-20 12:49:05  [ main:340252 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:05  [ main:340252 ] - [ INFO ]  Running job: job_local399401828_0044
2020-11-20 12:49:05  [ Thread-803:340253 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:05  [ Thread-803:340253 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:05  [ Thread-803:340253 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:05  [ Thread-803:340299 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:05  [ LocalJobRunner Map Task Executor #0:340299 ] - [ INFO ]  Starting task: attempt_local399401828_0044_m_000000_0
2020-11-20 12:49:05  [ LocalJobRunner Map Task Executor #0:340300 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:05  [ LocalJobRunner Map Task Executor #0:340300 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:05  [ LocalJobRunner Map Task Executor #0:340300 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:05  [ LocalJobRunner Map Task Executor #0:340301 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:05  [ Thread-803:340375 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:05  [ Thread-803:340396 ] - [ WARN ]  job_local399401828_0044
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:06  [ main:341256 ] - [ INFO ]  Job job_local399401828_0044 running in uber mode : false
2020-11-20 12:49:06  [ main:341256 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:06  [ main:341257 ] - [ INFO ]  Job job_local399401828_0044 failed with state FAILED due to: NA
2020-11-20 12:49:06  [ main:341257 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:06  [ main:341276 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:06  [ main:341288 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:06  [ main:341293 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:06  [ main:341338 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:07  [ main:341445 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:07  [ main:341605 ] - [ INFO ]  Submitting tokens for job: job_local514461381_0045
2020-11-20 12:49:07  [ main:342105 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:07  [ main:342106 ] - [ INFO ]  Running job: job_local514461381_0045
2020-11-20 12:49:07  [ Thread-821:342106 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:07  [ Thread-821:342106 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:07  [ Thread-821:342106 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:07  [ Thread-821:342149 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:07  [ LocalJobRunner Map Task Executor #0:342149 ] - [ INFO ]  Starting task: attempt_local514461381_0045_m_000000_0
2020-11-20 12:49:07  [ LocalJobRunner Map Task Executor #0:342150 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:07  [ LocalJobRunner Map Task Executor #0:342150 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:07  [ LocalJobRunner Map Task Executor #0:342150 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:07  [ LocalJobRunner Map Task Executor #0:342150 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:07  [ Thread-821:342220 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:07  [ Thread-821:342226 ] - [ WARN ]  job_local514461381_0045
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:08  [ main:343108 ] - [ INFO ]  Job job_local514461381_0045 running in uber mode : false
2020-11-20 12:49:08  [ main:343109 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:08  [ main:343109 ] - [ INFO ]  Job job_local514461381_0045 failed with state FAILED due to: NA
2020-11-20 12:49:08  [ main:343109 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:08  [ main:343128 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:08  [ main:343177 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:08  [ main:343182 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:08  [ main:343187 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:08  [ main:343330 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:09  [ main:343563 ] - [ INFO ]  Submitting tokens for job: job_local1339914323_0046
2020-11-20 12:49:09  [ main:344171 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:09  [ main:344171 ] - [ INFO ]  Running job: job_local1339914323_0046
2020-11-20 12:49:09  [ Thread-839:344172 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:09  [ Thread-839:344172 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:09  [ Thread-839:344172 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:09  [ Thread-839:344216 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:09  [ LocalJobRunner Map Task Executor #0:344216 ] - [ INFO ]  Starting task: attempt_local1339914323_0046_m_000000_0
2020-11-20 12:49:09  [ LocalJobRunner Map Task Executor #0:344217 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:09  [ LocalJobRunner Map Task Executor #0:344217 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:09  [ LocalJobRunner Map Task Executor #0:344217 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:09  [ LocalJobRunner Map Task Executor #0:344218 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:09  [ Thread-839:344288 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:09  [ Thread-839:344295 ] - [ WARN ]  job_local1339914323_0046
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:10  [ main:345173 ] - [ INFO ]  Job job_local1339914323_0046 running in uber mode : false
2020-11-20 12:49:10  [ main:345174 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:10  [ main:345174 ] - [ INFO ]  Job job_local1339914323_0046 failed with state FAILED due to: NA
2020-11-20 12:49:10  [ main:345174 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:10  [ main:345194 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:10  [ main:345245 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:10  [ main:345250 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:10  [ main:345255 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:11  [ main:345436 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:11  [ main:345674 ] - [ INFO ]  Submitting tokens for job: job_local1599109912_0047
2020-11-20 12:49:12  [ main:346525 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:12  [ Thread-857:346525 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:12  [ main:346526 ] - [ INFO ]  Running job: job_local1599109912_0047
2020-11-20 12:49:12  [ Thread-857:346526 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:12  [ Thread-857:346526 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:12  [ Thread-857:346570 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:12  [ LocalJobRunner Map Task Executor #0:346570 ] - [ INFO ]  Starting task: attempt_local1599109912_0047_m_000000_0
2020-11-20 12:49:12  [ LocalJobRunner Map Task Executor #0:346571 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:12  [ LocalJobRunner Map Task Executor #0:346571 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:12  [ LocalJobRunner Map Task Executor #0:346571 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:12  [ LocalJobRunner Map Task Executor #0:346609 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:12  [ Thread-857:346684 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:12  [ Thread-857:346692 ] - [ WARN ]  job_local1599109912_0047
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:13  [ main:347531 ] - [ INFO ]  Job job_local1599109912_0047 running in uber mode : false
2020-11-20 12:49:13  [ main:347531 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:13  [ main:347531 ] - [ INFO ]  Job job_local1599109912_0047 failed with state FAILED due to: NA
2020-11-20 12:49:13  [ main:347531 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:13  [ main:347591 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:13  [ main:347607 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:13  [ main:347647 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:13  [ main:347654 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:13  [ main:347870 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:13  [ main:348174 ] - [ INFO ]  Submitting tokens for job: job_local1039663830_0048
2020-11-20 12:49:22  [ main:356900 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:22  [ Thread-875:356934 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:22  [ main:357011 ] - [ INFO ]  Running job: job_local1039663830_0048
2020-11-20 12:49:22  [ Thread-875:357011 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:22  [ Thread-875:357011 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:22  [ Thread-875:357024 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:22  [ LocalJobRunner Map Task Executor #0:357024 ] - [ INFO ]  Starting task: attempt_local1039663830_0048_m_000000_0
2020-11-20 12:49:22  [ LocalJobRunner Map Task Executor #0:357026 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:22  [ LocalJobRunner Map Task Executor #0:357026 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:22  [ LocalJobRunner Map Task Executor #0:357026 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:22  [ LocalJobRunner Map Task Executor #0:357027 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:22  [ Thread-875:357106 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:22  [ Thread-875:357124 ] - [ WARN ]  job_local1039663830_0048
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:23  [ main:358014 ] - [ INFO ]  Job job_local1039663830_0048 running in uber mode : false
2020-11-20 12:49:23  [ main:358015 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:23  [ main:358015 ] - [ INFO ]  Job job_local1039663830_0048 failed with state FAILED due to: NA
2020-11-20 12:49:23  [ main:358015 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:23  [ main:358075 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:23  [ main:358141 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:23  [ main:358182 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:23  [ main:358188 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:24  [ main:358512 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:24  [ main:358954 ] - [ INFO ]  Submitting tokens for job: job_local1258203655_0049
2020-11-20 12:49:41  [ main:376167 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:49:41  [ Thread-893:376167 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:49:41  [ main:376167 ] - [ INFO ]  Running job: job_local1258203655_0049
2020-11-20 12:49:41  [ Thread-893:376238 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:41  [ Thread-893:376238 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:49:41  [ Thread-893:376302 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:49:41  [ LocalJobRunner Map Task Executor #0:376302 ] - [ INFO ]  Starting task: attempt_local1258203655_0049_m_000000_0
2020-11-20 12:49:41  [ LocalJobRunner Map Task Executor #0:376342 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:49:41  [ LocalJobRunner Map Task Executor #0:376342 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:49:41  [ LocalJobRunner Map Task Executor #0:376342 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:49:41  [ LocalJobRunner Map Task Executor #0:376343 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:49:41  [ Thread-893:376416 ] - [ INFO ]  map task executor complete.
2020-11-20 12:49:41  [ Thread-893:376428 ] - [ WARN ]  job_local1258203655_0049
java.lang.Exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.OutOfMemoryError: Java heap space
2020-11-20 12:49:42  [ main:377242 ] - [ INFO ]  Job job_local1258203655_0049 running in uber mode : false
2020-11-20 12:49:42  [ main:377243 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:49:42  [ main:377243 ] - [ INFO ]  Job job_local1258203655_0049 failed with state FAILED due to: NA
2020-11-20 12:49:42  [ main:377243 ] - [ INFO ]  Counters: 0
2020-11-20 12:49:42  [ main:377310 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:49:43  [ main:377557 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:49:43  [ main:377597 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:49:43  [ main:377608 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:49:43  [ main:377940 ] - [ INFO ]  number of splits:1
2020-11-20 12:49:44  [ main:378726 ] - [ INFO ]  Submitting tokens for job: job_local1451208937_0050
2020-11-20 12:52:22  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 12:52:33  [ main:10131 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 12:52:33  [ main:10131 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 12:52:33  [ main:10287 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:52:33  [ main:10292 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:52:33  [ main:10303 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:52:33  [ main:10360 ] - [ INFO ]  number of splits:1
2020-11-20 12:52:33  [ main:10421 ] - [ INFO ]  Submitting tokens for job: job_local891161806_0001
2020-11-20 12:52:33  [ main:10511 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:52:33  [ main:10512 ] - [ INFO ]  Running job: job_local891161806_0001
2020-11-20 12:52:33  [ Thread-18:10513 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:52:33  [ Thread-18:10516 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:33  [ Thread-18:10517 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:52:33  [ Thread-18:10548 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10548 ] - [ INFO ]  Starting task: attempt_local891161806_0001_m_000000_0
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10561 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10565 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10566 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10568 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10615 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10615 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10615 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10615 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10615 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:52:33  [ LocalJobRunner Map Task Executor #0:10617 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:52:34  [ main:11519 ] - [ INFO ]  Job job_local891161806_0001 running in uber mode : false
2020-11-20 12:52:34  [ main:11520 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:52:39  [ communication thread:16576 ] - [ INFO ]  map > map
2020-11-20 12:52:40  [ main:17544 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:52:42  [ communication thread:19579 ] - [ INFO ]  map > map
2020-11-20 12:52:43  [ main:20549 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20739 ] - [ INFO ]  map > map
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20741 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20741 ] - [ INFO ]  Spilling map output
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20741 ] - [ INFO ]  bufstart = 0; bufend = 2401; bufvoid = 104857600
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20741 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20762 ] - [ INFO ]  Finished spill 0
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20764 ] - [ INFO ]  Task:attempt_local891161806_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20785 ] - [ INFO ]  map
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20785 ] - [ INFO ]  Task 'attempt_local891161806_0001_m_000000_0' done.
2020-11-20 12:52:43  [ LocalJobRunner Map Task Executor #0:20785 ] - [ INFO ]  Finishing task: attempt_local891161806_0001_m_000000_0
2020-11-20 12:52:43  [ Thread-18:20786 ] - [ INFO ]  map task executor complete.
2020-11-20 12:52:43  [ Thread-18:20787 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:52:43  [ pool-6-thread-1:20787 ] - [ INFO ]  Starting task: attempt_local891161806_0001_r_000000_0
2020-11-20 12:52:43  [ pool-6-thread-1:20791 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:43  [ pool-6-thread-1:20792 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:52:43  [ pool-6-thread-1:20792 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:52:43  [ pool-6-thread-1:20793 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6863df09
2020-11-20 12:52:43  [ pool-6-thread-1:20802 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:52:43  [ EventFetcher for fetching Map Completion Events:20803 ] - [ INFO ]  attempt_local891161806_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:52:43  [ localfetcher#1:20821 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local891161806_0001_m_000000_0 decomp: 2112 len: 2116 to MEMORY
2020-11-20 12:52:43  [ localfetcher#1:20825 ] - [ INFO ]  Read 2112 bytes from map-output for attempt_local891161806_0001_m_000000_0
2020-11-20 12:52:43  [ localfetcher#1:20825 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2112, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2112
2020-11-20 12:52:43  [ EventFetcher for fetching Map Completion Events:20826 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:52:43  [ pool-6-thread-1:20827 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:52:43  [ pool-6-thread-1:20827 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:52:43  [ pool-6-thread-1:20831 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:52:43  [ pool-6-thread-1:20831 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2105 bytes
2020-11-20 12:52:43  [ pool-6-thread-1:20831 ] - [ INFO ]  Merged 1 segments, 2112 bytes to disk to satisfy reduce memory limit
2020-11-20 12:52:43  [ pool-6-thread-1:20832 ] - [ INFO ]  Merging 1 files, 2116 bytes from disk
2020-11-20 12:52:43  [ pool-6-thread-1:20832 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:52:43  [ pool-6-thread-1:20832 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:52:43  [ pool-6-thread-1:20832 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2105 bytes
2020-11-20 12:52:43  [ pool-6-thread-1:20833 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:52:43  [ pool-6-thread-1:20855 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 12:52:43  [ pool-6-thread-1:20986 ] - [ INFO ]  Task:attempt_local891161806_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 12:52:43  [ pool-6-thread-1:20996 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:52:43  [ pool-6-thread-1:20997 ] - [ INFO ]  Task attempt_local891161806_0001_r_000000_0 is allowed to commit now
2020-11-20 12:52:44  [ pool-6-thread-1:21029 ] - [ INFO ]  Saved output of task 'attempt_local891161806_0001_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local891161806_0001_r_000000
2020-11-20 12:52:44  [ pool-6-thread-1:21030 ] - [ INFO ]  reduce > reduce
2020-11-20 12:52:44  [ pool-6-thread-1:21030 ] - [ INFO ]  Task 'attempt_local891161806_0001_r_000000_0' done.
2020-11-20 12:52:44  [ pool-6-thread-1:21030 ] - [ INFO ]  Finishing task: attempt_local891161806_0001_r_000000_0
2020-11-20 12:52:44  [ Thread-18:21030 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:52:44  [ main:21553 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:52:44  [ main:21554 ] - [ INFO ]  Job job_local891161806_0001 completed successfully
2020-11-20 12:52:44  [ main:21564 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=4646
		FILE: Number of bytes written=646742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5547600
		HDFS: Number of bytes written=2103
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2401
		Map output materialized bytes=2116
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2116
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=708837376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:52:44  [ main:21594 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:52:44  [ main:21609 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:52:44  [ main:21614 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:52:44  [ main:21624 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:52:44  [ main:21672 ] - [ INFO ]  number of splits:1
2020-11-20 12:52:44  [ main:21691 ] - [ INFO ]  Submitting tokens for job: job_local2001687756_0002
2020-11-20 12:52:44  [ main:21736 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:52:44  [ main:21736 ] - [ INFO ]  Running job: job_local2001687756_0002
2020-11-20 12:52:44  [ Thread-48:21736 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:52:44  [ Thread-48:21736 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:44  [ Thread-48:21737 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:52:44  [ Thread-48:21747 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21748 ] - [ INFO ]  Starting task: attempt_local2001687756_0002_m_000000_0
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21748 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21749 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21749 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21749 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21789 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21789 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21789 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21789 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21789 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:52:44  [ LocalJobRunner Map Task Executor #0:21790 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:52:45  [ main:22737 ] - [ INFO ]  Job job_local2001687756_0002 running in uber mode : false
2020-11-20 12:52:45  [ main:22738 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:52:50  [ communication thread:27752 ] - [ INFO ]  map > map
2020-11-20 12:52:51  [ main:28752 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:52:53  [ communication thread:30758 ] - [ INFO ]  map > map
2020-11-20 12:52:53  [ main:30759 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31362 ] - [ INFO ]  map > map
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31363 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31363 ] - [ INFO ]  Spilling map output
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31363 ] - [ INFO ]  bufstart = 0; bufend = 2372; bufvoid = 104857600
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31363 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31367 ] - [ INFO ]  Finished spill 0
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31368 ] - [ INFO ]  Task:attempt_local2001687756_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31378 ] - [ INFO ]  map
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31378 ] - [ INFO ]  Task 'attempt_local2001687756_0002_m_000000_0' done.
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31378 ] - [ INFO ]  Finishing task: attempt_local2001687756_0002_m_000000_0
2020-11-20 12:52:54  [ Thread-48:31379 ] - [ INFO ]  map task executor complete.
2020-11-20 12:52:54  [ Thread-48:31379 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:52:54  [ pool-9-thread-1:31379 ] - [ INFO ]  Starting task: attempt_local2001687756_0002_r_000000_0
2020-11-20 12:52:54  [ pool-9-thread-1:31380 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:54  [ pool-9-thread-1:31380 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:52:54  [ pool-9-thread-1:31380 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:52:54  [ pool-9-thread-1:31380 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@387ef943
2020-11-20 12:52:54  [ pool-9-thread-1:31381 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:52:54  [ EventFetcher for fetching Map Completion Events:31381 ] - [ INFO ]  attempt_local2001687756_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:52:54  [ localfetcher#2:31382 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local2001687756_0002_m_000000_0 decomp: 2083 len: 2087 to MEMORY
2020-11-20 12:52:54  [ localfetcher#2:31383 ] - [ INFO ]  Read 2083 bytes from map-output for attempt_local2001687756_0002_m_000000_0
2020-11-20 12:52:54  [ localfetcher#2:31383 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2083, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2083
2020-11-20 12:52:54  [ EventFetcher for fetching Map Completion Events:31383 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:52:54  [ pool-9-thread-1:31383 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:52:54  [ pool-9-thread-1:31383 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:52:54  [ pool-9-thread-1:31384 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:52:54  [ pool-9-thread-1:31384 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2076 bytes
2020-11-20 12:52:54  [ pool-9-thread-1:31385 ] - [ INFO ]  Merged 1 segments, 2083 bytes to disk to satisfy reduce memory limit
2020-11-20 12:52:54  [ pool-9-thread-1:31385 ] - [ INFO ]  Merging 1 files, 2087 bytes from disk
2020-11-20 12:52:54  [ pool-9-thread-1:31385 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:52:54  [ pool-9-thread-1:31385 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:52:54  [ pool-9-thread-1:31385 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2076 bytes
2020-11-20 12:52:54  [ pool-9-thread-1:31385 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:52:54  [ pool-9-thread-1:31498 ] - [ INFO ]  Task:attempt_local2001687756_0002_r_000000_0 is done. And is in the process of committing
2020-11-20 12:52:54  [ pool-9-thread-1:31508 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:52:54  [ pool-9-thread-1:31508 ] - [ INFO ]  Task attempt_local2001687756_0002_r_000000_0 is allowed to commit now
2020-11-20 12:52:54  [ pool-9-thread-1:31537 ] - [ INFO ]  Saved output of task 'attempt_local2001687756_0002_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2001687756_0002_r_000000
2020-11-20 12:52:54  [ pool-9-thread-1:31537 ] - [ INFO ]  reduce > reduce
2020-11-20 12:52:54  [ pool-9-thread-1:31538 ] - [ INFO ]  Task 'attempt_local2001687756_0002_r_000000_0' done.
2020-11-20 12:52:54  [ pool-9-thread-1:31538 ] - [ INFO ]  Finishing task: attempt_local2001687756_0002_r_000000_0
2020-11-20 12:52:54  [ Thread-48:31538 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:52:54  [ main:31764 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:52:54  [ main:31764 ] - [ INFO ]  Job job_local2001687756_0002 completed successfully
2020-11-20 12:52:54  [ main:31768 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=13498
		FILE: Number of bytes written=1298709
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8321400
		HDFS: Number of bytes written=6280
		HDFS: Number of read operations=54
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=21
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2372
		Map output materialized bytes=2087
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2087
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=931135488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:52:54  [ main:31800 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:52:54  [ main:31813 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:52:54  [ main:31817 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:52:54  [ main:31827 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:52:54  [ main:31870 ] - [ INFO ]  number of splits:1
2020-11-20 12:52:54  [ main:31892 ] - [ INFO ]  Submitting tokens for job: job_local969965148_0003
2020-11-20 12:52:54  [ main:31937 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:52:54  [ main:31937 ] - [ INFO ]  Running job: job_local969965148_0003
2020-11-20 12:52:54  [ Thread-75:31937 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:52:54  [ Thread-75:31938 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:54  [ Thread-75:31938 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:52:54  [ Thread-75:31949 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31949 ] - [ INFO ]  Starting task: attempt_local969965148_0003_m_000000_0
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31950 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31950 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31951 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31952 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31991 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31992 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31992 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31992 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31992 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:52:54  [ LocalJobRunner Map Task Executor #0:31992 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:52:55  [ main:32941 ] - [ INFO ]  Job job_local969965148_0003 running in uber mode : false
2020-11-20 12:52:55  [ main:32942 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:53:00  [ communication thread:37954 ] - [ INFO ]  map > map
2020-11-20 12:53:01  [ main:38955 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:53:03  [ communication thread:40958 ] - [ INFO ]  map > map
2020-11-20 12:53:03  [ main:40963 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41636 ] - [ INFO ]  map > map
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41636 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41636 ] - [ INFO ]  Spilling map output
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41636 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41636 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41640 ] - [ INFO ]  Finished spill 0
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41641 ] - [ INFO ]  Task:attempt_local969965148_0003_m_000000_0 is done. And is in the process of committing
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41650 ] - [ INFO ]  map
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41650 ] - [ INFO ]  Task 'attempt_local969965148_0003_m_000000_0' done.
2020-11-20 12:53:04  [ LocalJobRunner Map Task Executor #0:41651 ] - [ INFO ]  Finishing task: attempt_local969965148_0003_m_000000_0
2020-11-20 12:53:04  [ Thread-75:41651 ] - [ INFO ]  map task executor complete.
2020-11-20 12:53:04  [ Thread-75:41651 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:53:04  [ pool-12-thread-1:41651 ] - [ INFO ]  Starting task: attempt_local969965148_0003_r_000000_0
2020-11-20 12:53:04  [ pool-12-thread-1:41652 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:04  [ pool-12-thread-1:41652 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:04  [ pool-12-thread-1:41652 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:04  [ pool-12-thread-1:41652 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@336514e1
2020-11-20 12:53:04  [ pool-12-thread-1:41653 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:53:04  [ EventFetcher for fetching Map Completion Events:41654 ] - [ INFO ]  attempt_local969965148_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:53:04  [ localfetcher#3:41655 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local969965148_0003_m_000000_0 decomp: 2113 len: 2117 to MEMORY
2020-11-20 12:53:04  [ localfetcher#3:41655 ] - [ INFO ]  Read 2113 bytes from map-output for attempt_local969965148_0003_m_000000_0
2020-11-20 12:53:04  [ localfetcher#3:41655 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2113, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2113
2020-11-20 12:53:04  [ EventFetcher for fetching Map Completion Events:41655 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:53:04  [ pool-12-thread-1:41656 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:04  [ pool-12-thread-1:41656 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:53:04  [ pool-12-thread-1:41656 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  Merged 1 segments, 2113 bytes to disk to satisfy reduce memory limit
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  Merging 1 files, 2117 bytes from disk
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 12:53:04  [ pool-12-thread-1:41657 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:04  [ pool-12-thread-1:41807 ] - [ INFO ]  Task:attempt_local969965148_0003_r_000000_0 is done. And is in the process of committing
2020-11-20 12:53:04  [ pool-12-thread-1:41831 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:04  [ pool-12-thread-1:41831 ] - [ INFO ]  Task attempt_local969965148_0003_r_000000_0 is allowed to commit now
2020-11-20 12:53:04  [ pool-12-thread-1:41864 ] - [ INFO ]  Saved output of task 'attempt_local969965148_0003_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local969965148_0003_r_000000
2020-11-20 12:53:04  [ pool-12-thread-1:41865 ] - [ INFO ]  reduce > reduce
2020-11-20 12:53:04  [ pool-12-thread-1:41865 ] - [ INFO ]  Task 'attempt_local969965148_0003_r_000000_0' done.
2020-11-20 12:53:04  [ pool-12-thread-1:41865 ] - [ INFO ]  Finishing task: attempt_local969965148_0003_r_000000_0
2020-11-20 12:53:04  [ Thread-75:41865 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:53:04  [ main:41964 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:53:04  [ main:41964 ] - [ INFO ]  Job job_local969965148_0003 completed successfully
2020-11-20 12:53:04  [ main:41966 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=22352
		FILE: Number of bytes written=1949105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=11095200
		HDFS: Number of bytes written=10458
		HDFS: Number of read operations=84
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=37
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2402
		Map output materialized bytes=2117
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2117
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1129316352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:53:04  [ main:41997 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:53:05  [ main:42220 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:53:05  [ main:42225 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:53:05  [ main:42235 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:53:05  [ main:42276 ] - [ INFO ]  number of splits:1
2020-11-20 12:53:05  [ main:42294 ] - [ INFO ]  Submitting tokens for job: job_local652717483_0004
2020-11-20 12:53:05  [ main:42335 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:53:05  [ main:42335 ] - [ INFO ]  Running job: job_local652717483_0004
2020-11-20 12:53:05  [ Thread-102:42335 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:53:05  [ Thread-102:42336 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:05  [ Thread-102:42336 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:53:05  [ Thread-102:42348 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42348 ] - [ INFO ]  Starting task: attempt_local652717483_0004_m_000000_0
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42349 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42349 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42349 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42350 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42357 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42358 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42358 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42358 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42358 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:53:05  [ LocalJobRunner Map Task Executor #0:42358 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:53:06  [ main:43337 ] - [ INFO ]  Job job_local652717483_0004 running in uber mode : false
2020-11-20 12:53:06  [ main:43338 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:53:11  [ communication thread:48353 ] - [ INFO ]  map > map
2020-11-20 12:53:11  [ main:48359 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:53:14  [ communication thread:51354 ] - [ INFO ]  map > map
2020-11-20 12:53:14  [ main:51367 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51995 ] - [ INFO ]  map > map
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51995 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51995 ] - [ INFO ]  Spilling map output
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51995 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51995 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51998 ] - [ INFO ]  Finished spill 0
2020-11-20 12:53:14  [ LocalJobRunner Map Task Executor #0:51999 ] - [ INFO ]  Task:attempt_local652717483_0004_m_000000_0 is done. And is in the process of committing
2020-11-20 12:53:15  [ LocalJobRunner Map Task Executor #0:52007 ] - [ INFO ]  map
2020-11-20 12:53:15  [ LocalJobRunner Map Task Executor #0:52008 ] - [ INFO ]  Task 'attempt_local652717483_0004_m_000000_0' done.
2020-11-20 12:53:15  [ LocalJobRunner Map Task Executor #0:52008 ] - [ INFO ]  Finishing task: attempt_local652717483_0004_m_000000_0
2020-11-20 12:53:15  [ Thread-102:52008 ] - [ INFO ]  map task executor complete.
2020-11-20 12:53:15  [ Thread-102:52008 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:53:15  [ pool-15-thread-1:52008 ] - [ INFO ]  Starting task: attempt_local652717483_0004_r_000000_0
2020-11-20 12:53:15  [ pool-15-thread-1:52009 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:15  [ pool-15-thread-1:52010 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:15  [ pool-15-thread-1:52010 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:15  [ pool-15-thread-1:52010 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59437fd5
2020-11-20 12:53:15  [ pool-15-thread-1:52011 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:53:15  [ EventFetcher for fetching Map Completion Events:52011 ] - [ INFO ]  attempt_local652717483_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:53:15  [ localfetcher#4:52012 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local652717483_0004_m_000000_0 decomp: 2104 len: 2108 to MEMORY
2020-11-20 12:53:15  [ localfetcher#4:52012 ] - [ INFO ]  Read 2104 bytes from map-output for attempt_local652717483_0004_m_000000_0
2020-11-20 12:53:15  [ localfetcher#4:52012 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2104
2020-11-20 12:53:15  [ EventFetcher for fetching Map Completion Events:52012 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:53:15  [ pool-15-thread-1:52013 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:15  [ pool-15-thread-1:52013 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:53:15  [ pool-15-thread-1:52013 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:15  [ pool-15-thread-1:52013 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 12:53:15  [ pool-15-thread-1:52014 ] - [ INFO ]  Merged 1 segments, 2104 bytes to disk to satisfy reduce memory limit
2020-11-20 12:53:15  [ pool-15-thread-1:52014 ] - [ INFO ]  Merging 1 files, 2108 bytes from disk
2020-11-20 12:53:15  [ pool-15-thread-1:52014 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:53:15  [ pool-15-thread-1:52014 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:15  [ pool-15-thread-1:52014 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 12:53:15  [ pool-15-thread-1:52014 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:15  [ main:52372 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:53:15  [ pool-15-thread-1:52400 ] - [ INFO ]  Task:attempt_local652717483_0004_r_000000_0 is done. And is in the process of committing
2020-11-20 12:53:15  [ pool-15-thread-1:52410 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:15  [ pool-15-thread-1:52410 ] - [ INFO ]  Task attempt_local652717483_0004_r_000000_0 is allowed to commit now
2020-11-20 12:53:15  [ pool-15-thread-1:52438 ] - [ INFO ]  Saved output of task 'attempt_local652717483_0004_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local652717483_0004_r_000000
2020-11-20 12:53:15  [ pool-15-thread-1:52439 ] - [ INFO ]  reduce > reduce
2020-11-20 12:53:15  [ pool-15-thread-1:52439 ] - [ INFO ]  Task 'attempt_local652717483_0004_r_000000_0' done.
2020-11-20 12:53:15  [ pool-15-thread-1:52439 ] - [ INFO ]  Finishing task: attempt_local652717483_0004_r_000000_0
2020-11-20 12:53:15  [ Thread-102:52439 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:53:16  [ main:53377 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:53:16  [ main:53377 ] - [ INFO ]  Job job_local652717483_0004 completed successfully
2020-11-20 12:53:16  [ main:53381 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=31248
		FILE: Number of bytes written=2599748
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13869000
		HDFS: Number of bytes written=14657
		HDFS: Number of read operations=114
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=53
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=2108
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2108
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=108
		Total committed heap usage (bytes)=964689920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:53:16  [ main:53415 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:53:16  [ main:53432 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:53:16  [ main:53437 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:53:16  [ main:53446 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:53:16  [ main:53488 ] - [ INFO ]  number of splits:1
2020-11-20 12:53:16  [ main:53508 ] - [ INFO ]  Submitting tokens for job: job_local1070921778_0005
2020-11-20 12:53:16  [ main:53549 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:53:16  [ main:53550 ] - [ INFO ]  Running job: job_local1070921778_0005
2020-11-20 12:53:16  [ Thread-129:53550 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:53:16  [ Thread-129:53550 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:16  [ Thread-129:53550 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:53:16  [ Thread-129:53561 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53562 ] - [ INFO ]  Starting task: attempt_local1070921778_0005_m_000000_0
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53562 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53562 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53562 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53563 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53572 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53572 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53572 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53572 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53572 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:53:16  [ LocalJobRunner Map Task Executor #0:53572 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:53:17  [ main:54553 ] - [ INFO ]  Job job_local1070921778_0005 running in uber mode : false
2020-11-20 12:53:17  [ main:54553 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:53:22  [ communication thread:59566 ] - [ INFO ]  map > map
2020-11-20 12:53:23  [ main:60567 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:53:25  [ communication thread:62571 ] - [ INFO ]  map > map
2020-11-20 12:53:25  [ main:62574 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63288 ] - [ INFO ]  map > map
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63289 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63289 ] - [ INFO ]  Spilling map output
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63289 ] - [ INFO ]  bufstart = 0; bufend = 2411; bufvoid = 104857600
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63289 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63292 ] - [ INFO ]  Finished spill 0
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63293 ] - [ INFO ]  Task:attempt_local1070921778_0005_m_000000_0 is done. And is in the process of committing
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63303 ] - [ INFO ]  map
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63303 ] - [ INFO ]  Task 'attempt_local1070921778_0005_m_000000_0' done.
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63303 ] - [ INFO ]  Finishing task: attempt_local1070921778_0005_m_000000_0
2020-11-20 12:53:26  [ Thread-129:63303 ] - [ INFO ]  map task executor complete.
2020-11-20 12:53:26  [ Thread-129:63303 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:53:26  [ pool-18-thread-1:63303 ] - [ INFO ]  Starting task: attempt_local1070921778_0005_r_000000_0
2020-11-20 12:53:26  [ pool-18-thread-1:63304 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:26  [ pool-18-thread-1:63304 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:26  [ pool-18-thread-1:63304 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:26  [ pool-18-thread-1:63304 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@58e199d1
2020-11-20 12:53:26  [ pool-18-thread-1:63305 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:53:26  [ EventFetcher for fetching Map Completion Events:63306 ] - [ INFO ]  attempt_local1070921778_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:53:26  [ localfetcher#5:63306 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local1070921778_0005_m_000000_0 decomp: 2122 len: 2126 to MEMORY
2020-11-20 12:53:26  [ localfetcher#5:63307 ] - [ INFO ]  Read 2122 bytes from map-output for attempt_local1070921778_0005_m_000000_0
2020-11-20 12:53:26  [ localfetcher#5:63307 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2122
2020-11-20 12:53:26  [ EventFetcher for fetching Map Completion Events:63307 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:53:26  [ pool-18-thread-1:63307 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:26  [ pool-18-thread-1:63307 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:53:26  [ pool-18-thread-1:63308 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:26  [ pool-18-thread-1:63308 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2115 bytes
2020-11-20 12:53:26  [ pool-18-thread-1:63309 ] - [ INFO ]  Merged 1 segments, 2122 bytes to disk to satisfy reduce memory limit
2020-11-20 12:53:26  [ pool-18-thread-1:63309 ] - [ INFO ]  Merging 1 files, 2126 bytes from disk
2020-11-20 12:53:26  [ pool-18-thread-1:63309 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:53:26  [ pool-18-thread-1:63309 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:26  [ pool-18-thread-1:63309 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2115 bytes
2020-11-20 12:53:26  [ pool-18-thread-1:63309 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:26  [ pool-18-thread-1:63436 ] - [ INFO ]  Task:attempt_local1070921778_0005_r_000000_0 is done. And is in the process of committing
2020-11-20 12:53:26  [ pool-18-thread-1:63447 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:26  [ pool-18-thread-1:63447 ] - [ INFO ]  Task attempt_local1070921778_0005_r_000000_0 is allowed to commit now
2020-11-20 12:53:26  [ pool-18-thread-1:63476 ] - [ INFO ]  Saved output of task 'attempt_local1070921778_0005_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1070921778_0005_r_000000
2020-11-20 12:53:26  [ pool-18-thread-1:63477 ] - [ INFO ]  reduce > reduce
2020-11-20 12:53:26  [ pool-18-thread-1:63477 ] - [ INFO ]  Task 'attempt_local1070921778_0005_r_000000_0' done.
2020-11-20 12:53:26  [ pool-18-thread-1:63478 ] - [ INFO ]  Finishing task: attempt_local1070921778_0005_r_000000_0
2020-11-20 12:53:26  [ Thread-129:63478 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:53:26  [ main:63577 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:53:26  [ main:63577 ] - [ INFO ]  Job job_local1070921778_0005 completed successfully
2020-11-20 12:53:26  [ main:63580 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=40162
		FILE: Number of bytes written=3254892
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=16642800
		HDFS: Number of bytes written=18865
		HDFS: Number of read operations=144
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=69
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2411
		Map output materialized bytes=2126
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2126
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1227882496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:53:26  [ main:63614 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:53:26  [ main:63633 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:53:26  [ main:63638 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:53:26  [ main:63647 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:53:26  [ main:63689 ] - [ INFO ]  number of splits:1
2020-11-20 12:53:26  [ main:63706 ] - [ INFO ]  Submitting tokens for job: job_local1847470529_0006
2020-11-20 12:53:26  [ main:63745 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:53:26  [ main:63745 ] - [ INFO ]  Running job: job_local1847470529_0006
2020-11-20 12:53:26  [ Thread-156:63746 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:53:26  [ Thread-156:63746 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:26  [ Thread-156:63746 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:53:26  [ Thread-156:63757 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63758 ] - [ INFO ]  Starting task: attempt_local1847470529_0006_m_000000_0
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63759 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63759 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63759 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63760 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63768 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63768 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63768 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63768 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63768 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:53:26  [ LocalJobRunner Map Task Executor #0:63769 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:53:27  [ main:64748 ] - [ INFO ]  Job job_local1847470529_0006 running in uber mode : false
2020-11-20 12:53:27  [ main:64748 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:53:32  [ communication thread:69765 ] - [ INFO ]  map > map
2020-11-20 12:53:33  [ main:70760 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:53:35  [ communication thread:72770 ] - [ INFO ]  map > map
2020-11-20 12:53:36  [ main:73764 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73786 ] - [ INFO ]  map > map
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73786 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73786 ] - [ INFO ]  Spilling map output
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73786 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73786 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73788 ] - [ INFO ]  Finished spill 0
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73789 ] - [ INFO ]  Task:attempt_local1847470529_0006_m_000000_0 is done. And is in the process of committing
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73802 ] - [ INFO ]  map
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73803 ] - [ INFO ]  Task 'attempt_local1847470529_0006_m_000000_0' done.
2020-11-20 12:53:36  [ LocalJobRunner Map Task Executor #0:73803 ] - [ INFO ]  Finishing task: attempt_local1847470529_0006_m_000000_0
2020-11-20 12:53:36  [ Thread-156:73803 ] - [ INFO ]  map task executor complete.
2020-11-20 12:53:36  [ Thread-156:73804 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:53:36  [ pool-21-thread-1:73804 ] - [ INFO ]  Starting task: attempt_local1847470529_0006_r_000000_0
2020-11-20 12:53:36  [ pool-21-thread-1:73804 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:36  [ pool-21-thread-1:73805 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:36  [ pool-21-thread-1:73805 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:36  [ pool-21-thread-1:73805 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76b2a40
2020-11-20 12:53:36  [ pool-21-thread-1:73806 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:53:36  [ EventFetcher for fetching Map Completion Events:73806 ] - [ INFO ]  attempt_local1847470529_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:53:36  [ localfetcher#6:73807 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local1847470529_0006_m_000000_0 decomp: 2119 len: 2123 to MEMORY
2020-11-20 12:53:36  [ localfetcher#6:73807 ] - [ INFO ]  Read 2119 bytes from map-output for attempt_local1847470529_0006_m_000000_0
2020-11-20 12:53:36  [ localfetcher#6:73807 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2119
2020-11-20 12:53:36  [ EventFetcher for fetching Map Completion Events:73808 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:53:36  [ pool-21-thread-1:73808 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:36  [ pool-21-thread-1:73808 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:53:36  [ pool-21-thread-1:73809 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:36  [ pool-21-thread-1:73809 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 12:53:36  [ pool-21-thread-1:73809 ] - [ INFO ]  Merged 1 segments, 2119 bytes to disk to satisfy reduce memory limit
2020-11-20 12:53:36  [ pool-21-thread-1:73810 ] - [ INFO ]  Merging 1 files, 2123 bytes from disk
2020-11-20 12:53:36  [ pool-21-thread-1:73810 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:53:36  [ pool-21-thread-1:73810 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:36  [ pool-21-thread-1:73810 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 12:53:36  [ pool-21-thread-1:73810 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:36  [ pool-21-thread-1:73913 ] - [ INFO ]  Task:attempt_local1847470529_0006_r_000000_0 is done. And is in the process of committing
2020-11-20 12:53:36  [ pool-21-thread-1:73919 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:36  [ pool-21-thread-1:73919 ] - [ INFO ]  Task attempt_local1847470529_0006_r_000000_0 is allowed to commit now
2020-11-20 12:53:36  [ pool-21-thread-1:73940 ] - [ INFO ]  Saved output of task 'attempt_local1847470529_0006_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1847470529_0006_r_000000
2020-11-20 12:53:36  [ pool-21-thread-1:73940 ] - [ INFO ]  reduce > reduce
2020-11-20 12:53:36  [ pool-21-thread-1:73940 ] - [ INFO ]  Task 'attempt_local1847470529_0006_r_000000_0' done.
2020-11-20 12:53:36  [ pool-21-thread-1:73940 ] - [ INFO ]  Finishing task: attempt_local1847470529_0006_r_000000_0
2020-11-20 12:53:36  [ Thread-156:73940 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:53:37  [ main:74767 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:53:37  [ main:74767 ] - [ INFO ]  Job job_local1847470529_0006 completed successfully
2020-11-20 12:53:37  [ main:74770 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=49106
		FILE: Number of bytes written=3910069
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=19416600
		HDFS: Number of bytes written=23088
		HDFS: Number of read operations=174
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=85
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2408
		Map output materialized bytes=2123
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2123
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1368391680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:53:37  [ main:74793 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:53:37  [ main:74811 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:53:37  [ main:74815 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:53:37  [ main:74826 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:53:37  [ main:74864 ] - [ INFO ]  number of splits:1
2020-11-20 12:53:37  [ main:74881 ] - [ INFO ]  Submitting tokens for job: job_local1422883105_0007
2020-11-20 12:53:37  [ main:74919 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:53:37  [ main:74919 ] - [ INFO ]  Running job: job_local1422883105_0007
2020-11-20 12:53:37  [ Thread-184:74919 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:53:37  [ Thread-184:74919 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:37  [ Thread-184:74919 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:53:37  [ Thread-184:74928 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74928 ] - [ INFO ]  Starting task: attempt_local1422883105_0007_m_000000_0
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74929 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74929 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74929 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74930 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74938 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74938 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74938 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74938 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74938 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:53:37  [ LocalJobRunner Map Task Executor #0:74939 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:53:38  [ main:75921 ] - [ INFO ]  Job job_local1422883105_0007 running in uber mode : false
2020-11-20 12:53:38  [ main:75921 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:53:43  [ communication thread:80932 ] - [ INFO ]  map > map
2020-11-20 12:53:43  [ main:80936 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:53:46  [ communication thread:83935 ] - [ INFO ]  map > map
2020-11-20 12:53:46  [ main:83943 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84377 ] - [ INFO ]  map > map
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84378 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84378 ] - [ INFO ]  Spilling map output
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84378 ] - [ INFO ]  bufstart = 0; bufend = 2417; bufvoid = 104857600
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84378 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84380 ] - [ INFO ]  Finished spill 0
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84381 ] - [ INFO ]  Task:attempt_local1422883105_0007_m_000000_0 is done. And is in the process of committing
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84388 ] - [ INFO ]  map
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84388 ] - [ INFO ]  Task 'attempt_local1422883105_0007_m_000000_0' done.
2020-11-20 12:53:47  [ LocalJobRunner Map Task Executor #0:84388 ] - [ INFO ]  Finishing task: attempt_local1422883105_0007_m_000000_0
2020-11-20 12:53:47  [ Thread-184:84388 ] - [ INFO ]  map task executor complete.
2020-11-20 12:53:47  [ Thread-184:84389 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:53:47  [ pool-24-thread-1:84389 ] - [ INFO ]  Starting task: attempt_local1422883105_0007_r_000000_0
2020-11-20 12:53:47  [ pool-24-thread-1:84390 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:47  [ pool-24-thread-1:84390 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:47  [ pool-24-thread-1:84390 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:47  [ pool-24-thread-1:84390 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@102c3277
2020-11-20 12:53:47  [ pool-24-thread-1:84391 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:53:47  [ EventFetcher for fetching Map Completion Events:84392 ] - [ INFO ]  attempt_local1422883105_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:53:47  [ localfetcher#7:84392 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local1422883105_0007_m_000000_0 decomp: 2128 len: 2132 to MEMORY
2020-11-20 12:53:47  [ localfetcher#7:84393 ] - [ INFO ]  Read 2128 bytes from map-output for attempt_local1422883105_0007_m_000000_0
2020-11-20 12:53:47  [ localfetcher#7:84393 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2128, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2128
2020-11-20 12:53:47  [ EventFetcher for fetching Map Completion Events:84393 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:53:47  [ pool-24-thread-1:84393 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:47  [ pool-24-thread-1:84393 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:53:47  [ pool-24-thread-1:84394 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:47  [ pool-24-thread-1:84394 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2121 bytes
2020-11-20 12:53:47  [ pool-24-thread-1:84395 ] - [ INFO ]  Merged 1 segments, 2128 bytes to disk to satisfy reduce memory limit
2020-11-20 12:53:47  [ pool-24-thread-1:84395 ] - [ INFO ]  Merging 1 files, 2132 bytes from disk
2020-11-20 12:53:47  [ pool-24-thread-1:84395 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:53:47  [ pool-24-thread-1:84395 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:47  [ pool-24-thread-1:84395 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2121 bytes
2020-11-20 12:53:47  [ pool-24-thread-1:84395 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:47  [ pool-24-thread-1:84506 ] - [ INFO ]  Task:attempt_local1422883105_0007_r_000000_0 is done. And is in the process of committing
2020-11-20 12:53:47  [ pool-24-thread-1:84514 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:47  [ pool-24-thread-1:84514 ] - [ INFO ]  Task attempt_local1422883105_0007_r_000000_0 is allowed to commit now
2020-11-20 12:53:47  [ pool-24-thread-1:84533 ] - [ INFO ]  Saved output of task 'attempt_local1422883105_0007_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1422883105_0007_r_000000
2020-11-20 12:53:47  [ pool-24-thread-1:84533 ] - [ INFO ]  reduce > reduce
2020-11-20 12:53:47  [ pool-24-thread-1:84533 ] - [ INFO ]  Task 'attempt_local1422883105_0007_r_000000_0' done.
2020-11-20 12:53:47  [ pool-24-thread-1:84533 ] - [ INFO ]  Finishing task: attempt_local1422883105_0007_r_000000_0
2020-11-20 12:53:47  [ Thread-184:84533 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:53:47  [ main:84946 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:53:47  [ main:84947 ] - [ INFO ]  Job job_local1422883105_0007 completed successfully
2020-11-20 12:53:47  [ main:84949 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=58062
		FILE: Number of bytes written=4566682
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=22190400
		HDFS: Number of bytes written=27317
		HDFS: Number of read operations=204
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=101
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2417
		Map output materialized bytes=2132
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2132
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=82
		Total committed heap usage (bytes)=1527775232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:53:47  [ main:84970 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:53:47  [ main:84980 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:53:47  [ main:84985 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:53:47  [ main:84991 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:53:48  [ main:85027 ] - [ INFO ]  number of splits:1
2020-11-20 12:53:48  [ main:85044 ] - [ INFO ]  Submitting tokens for job: job_local710987084_0008
2020-11-20 12:53:48  [ main:85080 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:53:48  [ main:85080 ] - [ INFO ]  Running job: job_local710987084_0008
2020-11-20 12:53:48  [ Thread-211:85081 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:53:48  [ Thread-211:85081 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:48  [ Thread-211:85081 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:53:48  [ Thread-211:85088 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85088 ] - [ INFO ]  Starting task: attempt_local710987084_0008_m_000000_0
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85088 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85088 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85088 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85089 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85097 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85097 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85097 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85097 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85097 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:53:48  [ LocalJobRunner Map Task Executor #0:85097 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:53:49  [ main:86084 ] - [ INFO ]  Job job_local710987084_0008 running in uber mode : false
2020-11-20 12:53:49  [ main:86084 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:53:54  [ communication thread:91116 ] - [ INFO ]  map > map
2020-11-20 12:53:55  [ main:92119 ] - [ INFO ]   map 39% reduce 0%
2020-11-20 12:53:57  [ communication thread:94120 ] - [ INFO ]  map > map
2020-11-20 12:53:57  [ main:94125 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95031 ] - [ INFO ]  map > map
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95032 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95032 ] - [ INFO ]  Spilling map output
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95032 ] - [ INFO ]  bufstart = 0; bufend = 2351; bufvoid = 104857600
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95032 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95034 ] - [ INFO ]  Finished spill 0
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95035 ] - [ INFO ]  Task:attempt_local710987084_0008_m_000000_0 is done. And is in the process of committing
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95042 ] - [ INFO ]  map
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95042 ] - [ INFO ]  Task 'attempt_local710987084_0008_m_000000_0' done.
2020-11-20 12:53:58  [ LocalJobRunner Map Task Executor #0:95042 ] - [ INFO ]  Finishing task: attempt_local710987084_0008_m_000000_0
2020-11-20 12:53:58  [ Thread-211:95042 ] - [ INFO ]  map task executor complete.
2020-11-20 12:53:58  [ Thread-211:95043 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:53:58  [ pool-27-thread-1:95043 ] - [ INFO ]  Starting task: attempt_local710987084_0008_r_000000_0
2020-11-20 12:53:58  [ pool-27-thread-1:95044 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:58  [ pool-27-thread-1:95044 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:58  [ pool-27-thread-1:95044 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:58  [ pool-27-thread-1:95044 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@47d28325
2020-11-20 12:53:58  [ pool-27-thread-1:95045 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:53:58  [ EventFetcher for fetching Map Completion Events:95046 ] - [ INFO ]  attempt_local710987084_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:53:58  [ localfetcher#8:95046 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local710987084_0008_m_000000_0 decomp: 2062 len: 2066 to MEMORY
2020-11-20 12:53:58  [ localfetcher#8:95047 ] - [ INFO ]  Read 2062 bytes from map-output for attempt_local710987084_0008_m_000000_0
2020-11-20 12:53:58  [ localfetcher#8:95047 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2062, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2062
2020-11-20 12:53:58  [ EventFetcher for fetching Map Completion Events:95047 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:53:58  [ pool-27-thread-1:95047 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:58  [ pool-27-thread-1:95047 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:53:58  [ pool-27-thread-1:95048 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:58  [ pool-27-thread-1:95048 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2055 bytes
2020-11-20 12:53:58  [ pool-27-thread-1:95049 ] - [ INFO ]  Merged 1 segments, 2062 bytes to disk to satisfy reduce memory limit
2020-11-20 12:53:58  [ pool-27-thread-1:95049 ] - [ INFO ]  Merging 1 files, 2066 bytes from disk
2020-11-20 12:53:58  [ pool-27-thread-1:95049 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:53:58  [ pool-27-thread-1:95049 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:53:58  [ pool-27-thread-1:95049 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2055 bytes
2020-11-20 12:53:58  [ pool-27-thread-1:95049 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:58  [ main:95126 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:53:58  [ pool-27-thread-1:95147 ] - [ INFO ]  Task:attempt_local710987084_0008_r_000000_0 is done. And is in the process of committing
2020-11-20 12:53:58  [ pool-27-thread-1:95158 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:53:58  [ pool-27-thread-1:95158 ] - [ INFO ]  Task attempt_local710987084_0008_r_000000_0 is allowed to commit now
2020-11-20 12:53:58  [ pool-27-thread-1:95177 ] - [ INFO ]  Saved output of task 'attempt_local710987084_0008_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local710987084_0008_r_000000
2020-11-20 12:53:58  [ pool-27-thread-1:95178 ] - [ INFO ]  reduce > reduce
2020-11-20 12:53:58  [ pool-27-thread-1:95178 ] - [ INFO ]  Task 'attempt_local710987084_0008_r_000000_0' done.
2020-11-20 12:53:58  [ pool-27-thread-1:95178 ] - [ INFO ]  Finishing task: attempt_local710987084_0008_r_000000_0
2020-11-20 12:53:58  [ Thread-211:95178 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:53:59  [ main:96130 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:53:59  [ main:96130 ] - [ INFO ]  Job job_local710987084_0008 completed successfully
2020-11-20 12:53:59  [ main:96132 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=66904
		FILE: Number of bytes written=5221246
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=24964200
		HDFS: Number of bytes written=31489
		HDFS: Number of read operations=234
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=117
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2351
		Map output materialized bytes=2066
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2066
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=1855979520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:53:59  [ main:96154 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:53:59  [ main:96166 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:53:59  [ main:96171 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:53:59  [ main:96177 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:53:59  [ main:96214 ] - [ INFO ]  number of splits:1
2020-11-20 12:53:59  [ main:96232 ] - [ INFO ]  Submitting tokens for job: job_local960788051_0009
2020-11-20 12:53:59  [ main:96268 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:53:59  [ main:96268 ] - [ INFO ]  Running job: job_local960788051_0009
2020-11-20 12:53:59  [ Thread-238:96268 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:53:59  [ Thread-238:96269 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:59  [ Thread-238:96269 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:53:59  [ Thread-238:96277 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96278 ] - [ INFO ]  Starting task: attempt_local960788051_0009_m_000000_0
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96278 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96278 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96278 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96279 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96286 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96286 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96286 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96286 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96286 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:53:59  [ LocalJobRunner Map Task Executor #0:96287 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:54:00  [ main:97269 ] - [ INFO ]  Job job_local960788051_0009 running in uber mode : false
2020-11-20 12:54:00  [ main:97269 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:54:05  [ communication thread:102286 ] - [ INFO ]  map > map
2020-11-20 12:54:06  [ main:103286 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:54:08  [ communication thread:105287 ] - [ INFO ]  map > map
2020-11-20 12:54:08  [ main:105296 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106040 ] - [ INFO ]  map > map
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106040 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106040 ] - [ INFO ]  Spilling map output
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106040 ] - [ INFO ]  bufstart = 0; bufend = 2406; bufvoid = 104857600
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106040 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106042 ] - [ INFO ]  Finished spill 0
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106044 ] - [ INFO ]  Task:attempt_local960788051_0009_m_000000_0 is done. And is in the process of committing
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106050 ] - [ INFO ]  map
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106050 ] - [ INFO ]  Task 'attempt_local960788051_0009_m_000000_0' done.
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106050 ] - [ INFO ]  Finishing task: attempt_local960788051_0009_m_000000_0
2020-11-20 12:54:09  [ Thread-238:106050 ] - [ INFO ]  map task executor complete.
2020-11-20 12:54:09  [ Thread-238:106050 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:54:09  [ pool-30-thread-1:106050 ] - [ INFO ]  Starting task: attempt_local960788051_0009_r_000000_0
2020-11-20 12:54:09  [ pool-30-thread-1:106051 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:09  [ pool-30-thread-1:106051 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:09  [ pool-30-thread-1:106051 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:09  [ pool-30-thread-1:106051 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@219be24c
2020-11-20 12:54:09  [ pool-30-thread-1:106052 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:54:09  [ EventFetcher for fetching Map Completion Events:106052 ] - [ INFO ]  attempt_local960788051_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:54:09  [ localfetcher#9:106053 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local960788051_0009_m_000000_0 decomp: 2117 len: 2121 to MEMORY
2020-11-20 12:54:09  [ localfetcher#9:106053 ] - [ INFO ]  Read 2117 bytes from map-output for attempt_local960788051_0009_m_000000_0
2020-11-20 12:54:09  [ localfetcher#9:106053 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2117, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2117
2020-11-20 12:54:09  [ EventFetcher for fetching Map Completion Events:106054 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:54:09  [ pool-30-thread-1:106054 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:09  [ pool-30-thread-1:106054 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:54:09  [ pool-30-thread-1:106054 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2110 bytes
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  Merged 1 segments, 2117 bytes to disk to satisfy reduce memory limit
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  Merging 1 files, 2121 bytes from disk
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2110 bytes
2020-11-20 12:54:09  [ pool-30-thread-1:106055 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:09  [ pool-30-thread-1:106149 ] - [ INFO ]  Task:attempt_local960788051_0009_r_000000_0 is done. And is in the process of committing
2020-11-20 12:54:09  [ pool-30-thread-1:106160 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:09  [ pool-30-thread-1:106161 ] - [ INFO ]  Task attempt_local960788051_0009_r_000000_0 is allowed to commit now
2020-11-20 12:54:09  [ pool-30-thread-1:106182 ] - [ INFO ]  Saved output of task 'attempt_local960788051_0009_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local960788051_0009_r_000000
2020-11-20 12:54:09  [ pool-30-thread-1:106182 ] - [ INFO ]  reduce > reduce
2020-11-20 12:54:09  [ pool-30-thread-1:106182 ] - [ INFO ]  Task 'attempt_local960788051_0009_r_000000_0' done.
2020-11-20 12:54:09  [ pool-30-thread-1:106182 ] - [ INFO ]  Finishing task: attempt_local960788051_0009_r_000000_0
2020-11-20 12:54:09  [ Thread-238:106182 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:54:09  [ main:106300 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:54:09  [ main:106301 ] - [ INFO ]  Job job_local960788051_0009 completed successfully
2020-11-20 12:54:09  [ main:106303 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=75724
		FILE: Number of bytes written=5876029
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27738000
		HDFS: Number of bytes written=35650
		HDFS: Number of read operations=264
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=133
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2406
		Map output materialized bytes=2121
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2121
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1855979520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:54:09  [ main:106321 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:54:09  [ main:106331 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:54:09  [ main:106335 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:54:09  [ main:106341 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:54:09  [ main:106379 ] - [ INFO ]  number of splits:1
2020-11-20 12:54:09  [ main:106399 ] - [ INFO ]  Submitting tokens for job: job_local1487388559_0010
2020-11-20 12:54:09  [ main:106440 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:54:09  [ main:106440 ] - [ INFO ]  Running job: job_local1487388559_0010
2020-11-20 12:54:09  [ Thread-265:106440 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:54:09  [ Thread-265:106440 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:09  [ Thread-265:106440 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:54:09  [ Thread-265:106454 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106454 ] - [ INFO ]  Starting task: attempt_local1487388559_0010_m_000000_0
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106455 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106455 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106455 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106455 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106463 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106463 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106463 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106463 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106463 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:54:09  [ LocalJobRunner Map Task Executor #0:106464 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:54:10  [ main:107444 ] - [ INFO ]  Job job_local1487388559_0010 running in uber mode : false
2020-11-20 12:54:10  [ main:107444 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:54:15  [ communication thread:112461 ] - [ INFO ]  map > map
2020-11-20 12:54:16  [ main:113463 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:54:18  [ communication thread:115466 ] - [ INFO ]  map > map
2020-11-20 12:54:18  [ main:115469 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116318 ] - [ INFO ]  map > map
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116319 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116319 ] - [ INFO ]  Spilling map output
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116319 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116319 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116321 ] - [ INFO ]  Finished spill 0
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116322 ] - [ INFO ]  Task:attempt_local1487388559_0010_m_000000_0 is done. And is in the process of committing
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116331 ] - [ INFO ]  map
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116331 ] - [ INFO ]  Task 'attempt_local1487388559_0010_m_000000_0' done.
2020-11-20 12:54:19  [ LocalJobRunner Map Task Executor #0:116331 ] - [ INFO ]  Finishing task: attempt_local1487388559_0010_m_000000_0
2020-11-20 12:54:19  [ Thread-265:116331 ] - [ INFO ]  map task executor complete.
2020-11-20 12:54:19  [ Thread-265:116332 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:54:19  [ pool-33-thread-1:116332 ] - [ INFO ]  Starting task: attempt_local1487388559_0010_r_000000_0
2020-11-20 12:54:19  [ pool-33-thread-1:116332 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:19  [ pool-33-thread-1:116333 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:19  [ pool-33-thread-1:116333 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:19  [ pool-33-thread-1:116333 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73f95f2c
2020-11-20 12:54:19  [ pool-33-thread-1:116334 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:54:19  [ EventFetcher for fetching Map Completion Events:116334 ] - [ INFO ]  attempt_local1487388559_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:54:19  [ localfetcher#10:116335 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1487388559_0010_m_000000_0 decomp: 2113 len: 2117 to MEMORY
2020-11-20 12:54:19  [ localfetcher#10:116335 ] - [ INFO ]  Read 2113 bytes from map-output for attempt_local1487388559_0010_m_000000_0
2020-11-20 12:54:19  [ localfetcher#10:116335 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2113, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2113
2020-11-20 12:54:19  [ EventFetcher for fetching Map Completion Events:116336 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:54:19  [ pool-33-thread-1:116336 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:19  [ pool-33-thread-1:116336 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:54:19  [ pool-33-thread-1:116337 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:19  [ pool-33-thread-1:116337 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 12:54:19  [ pool-33-thread-1:116337 ] - [ INFO ]  Merged 1 segments, 2113 bytes to disk to satisfy reduce memory limit
2020-11-20 12:54:19  [ pool-33-thread-1:116338 ] - [ INFO ]  Merging 1 files, 2117 bytes from disk
2020-11-20 12:54:19  [ pool-33-thread-1:116338 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:54:19  [ pool-33-thread-1:116338 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:19  [ pool-33-thread-1:116338 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 12:54:19  [ pool-33-thread-1:116338 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:19  [ main:116473 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:54:19  [ pool-33-thread-1:116478 ] - [ INFO ]  Task:attempt_local1487388559_0010_r_000000_0 is done. And is in the process of committing
2020-11-20 12:54:19  [ pool-33-thread-1:116484 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:19  [ pool-33-thread-1:116484 ] - [ INFO ]  Task attempt_local1487388559_0010_r_000000_0 is allowed to commit now
2020-11-20 12:54:19  [ pool-33-thread-1:116503 ] - [ INFO ]  Saved output of task 'attempt_local1487388559_0010_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1487388559_0010_r_000000
2020-11-20 12:54:19  [ pool-33-thread-1:116504 ] - [ INFO ]  reduce > reduce
2020-11-20 12:54:19  [ pool-33-thread-1:116504 ] - [ INFO ]  Task 'attempt_local1487388559_0010_r_000000_0' done.
2020-11-20 12:54:19  [ pool-33-thread-1:116504 ] - [ INFO ]  Finishing task: attempt_local1487388559_0010_r_000000_0
2020-11-20 12:54:19  [ Thread-265:116504 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:54:20  [ main:117476 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:54:20  [ main:117476 ] - [ INFO ]  Job job_local1487388559_0010 completed successfully
2020-11-20 12:54:20  [ main:117478 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=84646
		FILE: Number of bytes written=6533995
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30511800
		HDFS: Number of bytes written=39862
		HDFS: Number of read operations=294
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=149
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2402
		Map output materialized bytes=2117
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2117
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1805647872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:54:20  [ main:117497 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:54:20  [ main:117511 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:54:20  [ main:117516 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:54:20  [ main:117523 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:54:20  [ main:117559 ] - [ INFO ]  number of splits:1
2020-11-20 12:54:20  [ main:117577 ] - [ INFO ]  Submitting tokens for job: job_local1272182666_0011
2020-11-20 12:54:20  [ main:117613 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:54:20  [ main:117613 ] - [ INFO ]  Running job: job_local1272182666_0011
2020-11-20 12:54:20  [ Thread-292:117613 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:54:20  [ Thread-292:117613 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:20  [ Thread-292:117613 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:54:20  [ Thread-292:117636 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117636 ] - [ INFO ]  Starting task: attempt_local1272182666_0011_m_000000_0
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117637 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117637 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117637 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117638 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117648 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117648 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117648 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117648 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117648 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:54:20  [ LocalJobRunner Map Task Executor #0:117649 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:54:21  [ main:118617 ] - [ INFO ]  Job job_local1272182666_0011 running in uber mode : false
2020-11-20 12:54:21  [ main:118617 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:54:26  [ communication thread:123645 ] - [ INFO ]  map > map
2020-11-20 12:54:27  [ main:124634 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:54:29  [ communication thread:126648 ] - [ INFO ]  map > map
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127135 ] - [ INFO ]  map > map
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127136 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127136 ] - [ INFO ]  Spilling map output
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127136 ] - [ INFO ]  bufstart = 0; bufend = 2387; bufvoid = 104857600
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127136 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127138 ] - [ INFO ]  Finished spill 0
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127139 ] - [ INFO ]  Task:attempt_local1272182666_0011_m_000000_0 is done. And is in the process of committing
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127145 ] - [ INFO ]  map
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  Task 'attempt_local1272182666_0011_m_000000_0' done.
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127146 ] - [ INFO ]  Finishing task: attempt_local1272182666_0011_m_000000_0
2020-11-20 12:54:30  [ Thread-292:127146 ] - [ INFO ]  map task executor complete.
2020-11-20 12:54:30  [ Thread-292:127146 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:54:30  [ pool-36-thread-1:127146 ] - [ INFO ]  Starting task: attempt_local1272182666_0011_r_000000_0
2020-11-20 12:54:30  [ pool-36-thread-1:127147 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:30  [ pool-36-thread-1:127147 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:30  [ pool-36-thread-1:127147 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:30  [ pool-36-thread-1:127147 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b125938
2020-11-20 12:54:30  [ pool-36-thread-1:127149 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:54:30  [ EventFetcher for fetching Map Completion Events:127149 ] - [ INFO ]  attempt_local1272182666_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:54:30  [ localfetcher#11:127150 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local1272182666_0011_m_000000_0 decomp: 2098 len: 2102 to MEMORY
2020-11-20 12:54:30  [ localfetcher#11:127150 ] - [ INFO ]  Read 2098 bytes from map-output for attempt_local1272182666_0011_m_000000_0
2020-11-20 12:54:30  [ localfetcher#11:127150 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2098, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2098
2020-11-20 12:54:30  [ EventFetcher for fetching Map Completion Events:127150 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:54:30  [ pool-36-thread-1:127151 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:30  [ pool-36-thread-1:127151 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:54:30  [ pool-36-thread-1:127151 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2091 bytes
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  Merged 1 segments, 2098 bytes to disk to satisfy reduce memory limit
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  Merging 1 files, 2102 bytes from disk
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2091 bytes
2020-11-20 12:54:30  [ pool-36-thread-1:127152 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:30  [ pool-36-thread-1:127238 ] - [ INFO ]  Task:attempt_local1272182666_0011_r_000000_0 is done. And is in the process of committing
2020-11-20 12:54:30  [ pool-36-thread-1:127245 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:30  [ pool-36-thread-1:127245 ] - [ INFO ]  Task attempt_local1272182666_0011_r_000000_0 is allowed to commit now
2020-11-20 12:54:30  [ pool-36-thread-1:127263 ] - [ INFO ]  Saved output of task 'attempt_local1272182666_0011_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1272182666_0011_r_000000
2020-11-20 12:54:30  [ pool-36-thread-1:127264 ] - [ INFO ]  reduce > reduce
2020-11-20 12:54:30  [ pool-36-thread-1:127264 ] - [ INFO ]  Task 'attempt_local1272182666_0011_r_000000_0' done.
2020-11-20 12:54:30  [ pool-36-thread-1:127264 ] - [ INFO ]  Finishing task: attempt_local1272182666_0011_r_000000_0
2020-11-20 12:54:30  [ Thread-292:127264 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:54:30  [ main:127637 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:54:30  [ main:127638 ] - [ INFO ]  Job job_local1272182666_0011 completed successfully
2020-11-20 12:54:30  [ main:127640 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=93530
		FILE: Number of bytes written=7191984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33285600
		HDFS: Number of bytes written=44055
		HDFS: Number of read operations=324
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=165
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2387
		Map output materialized bytes=2102
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2102
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1789919232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:54:30  [ main:127664 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:54:30  [ main:127674 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:54:30  [ main:127678 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:54:30  [ main:127685 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:54:30  [ main:127723 ] - [ INFO ]  number of splits:1
2020-11-20 12:54:30  [ main:127740 ] - [ INFO ]  Submitting tokens for job: job_local1405889408_0012
2020-11-20 12:54:30  [ main:127775 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:54:30  [ main:127775 ] - [ INFO ]  Running job: job_local1405889408_0012
2020-11-20 12:54:30  [ Thread-319:127776 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:54:30  [ Thread-319:127776 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:30  [ Thread-319:127776 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:54:30  [ Thread-319:127784 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127784 ] - [ INFO ]  Starting task: attempt_local1405889408_0012_m_000000_0
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127785 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127785 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127785 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127785 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127795 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127795 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127795 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127795 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127795 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:54:30  [ LocalJobRunner Map Task Executor #0:127795 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:54:31  [ main:128780 ] - [ INFO ]  Job job_local1405889408_0012 running in uber mode : false
2020-11-20 12:54:31  [ main:128780 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:54:36  [ communication thread:133795 ] - [ INFO ]  map > map
2020-11-20 12:54:37  [ main:134797 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:54:39  [ communication thread:136796 ] - [ INFO ]  map > map
2020-11-20 12:54:39  [ main:136802 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137720 ] - [ INFO ]  map > map
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137721 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137721 ] - [ INFO ]  Spilling map output
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137721 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137721 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137723 ] - [ INFO ]  Finished spill 0
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137724 ] - [ INFO ]  Task:attempt_local1405889408_0012_m_000000_0 is done. And is in the process of committing
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137731 ] - [ INFO ]  map
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137732 ] - [ INFO ]  Task 'attempt_local1405889408_0012_m_000000_0' done.
2020-11-20 12:54:40  [ LocalJobRunner Map Task Executor #0:137732 ] - [ INFO ]  Finishing task: attempt_local1405889408_0012_m_000000_0
2020-11-20 12:54:40  [ Thread-319:137732 ] - [ INFO ]  map task executor complete.
2020-11-20 12:54:40  [ Thread-319:137732 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:54:40  [ pool-39-thread-1:137732 ] - [ INFO ]  Starting task: attempt_local1405889408_0012_r_000000_0
2020-11-20 12:54:40  [ pool-39-thread-1:137733 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:40  [ pool-39-thread-1:137733 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:40  [ pool-39-thread-1:137733 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:40  [ pool-39-thread-1:137733 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@617a408b
2020-11-20 12:54:40  [ pool-39-thread-1:137734 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:54:40  [ EventFetcher for fetching Map Completion Events:137734 ] - [ INFO ]  attempt_local1405889408_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:54:40  [ localfetcher#12:137735 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local1405889408_0012_m_000000_0 decomp: 2105 len: 2109 to MEMORY
2020-11-20 12:54:40  [ localfetcher#12:137735 ] - [ INFO ]  Read 2105 bytes from map-output for attempt_local1405889408_0012_m_000000_0
2020-11-20 12:54:40  [ localfetcher#12:137735 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2105
2020-11-20 12:54:40  [ EventFetcher for fetching Map Completion Events:137735 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:54:40  [ pool-39-thread-1:137735 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:40  [ pool-39-thread-1:137735 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:54:40  [ pool-39-thread-1:137736 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:40  [ pool-39-thread-1:137736 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2098 bytes
2020-11-20 12:54:40  [ pool-39-thread-1:137737 ] - [ INFO ]  Merged 1 segments, 2105 bytes to disk to satisfy reduce memory limit
2020-11-20 12:54:40  [ pool-39-thread-1:137737 ] - [ INFO ]  Merging 1 files, 2109 bytes from disk
2020-11-20 12:54:40  [ pool-39-thread-1:137737 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:54:40  [ pool-39-thread-1:137737 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:40  [ pool-39-thread-1:137737 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2098 bytes
2020-11-20 12:54:40  [ pool-39-thread-1:137737 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:40  [ main:137805 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:54:40  [ pool-39-thread-1:137814 ] - [ INFO ]  Task:attempt_local1405889408_0012_r_000000_0 is done. And is in the process of committing
2020-11-20 12:54:40  [ pool-39-thread-1:137821 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:40  [ pool-39-thread-1:137821 ] - [ INFO ]  Task attempt_local1405889408_0012_r_000000_0 is allowed to commit now
2020-11-20 12:54:40  [ pool-39-thread-1:137841 ] - [ INFO ]  Saved output of task 'attempt_local1405889408_0012_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1405889408_0012_r_000000
2020-11-20 12:54:40  [ pool-39-thread-1:137841 ] - [ INFO ]  reduce > reduce
2020-11-20 12:54:40  [ pool-39-thread-1:137841 ] - [ INFO ]  Task 'attempt_local1405889408_0012_r_000000_0' done.
2020-11-20 12:54:40  [ pool-39-thread-1:137841 ] - [ INFO ]  Finishing task: attempt_local1405889408_0012_r_000000_0
2020-11-20 12:54:40  [ Thread-319:137841 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:54:41  [ main:138810 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:54:41  [ main:138810 ] - [ INFO ]  Job job_local1405889408_0012 completed successfully
2020-11-20 12:54:41  [ main:138811 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=102398
		FILE: Number of bytes written=7795995
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=36059400
		HDFS: Number of bytes written=48240
		HDFS: Number of read operations=354
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=181
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2394
		Map output materialized bytes=2109
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2109
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1763704832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:54:41  [ main:138832 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:54:41  [ main:138843 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:54:41  [ main:138848 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:54:41  [ main:138854 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:54:41  [ main:138890 ] - [ INFO ]  number of splits:1
2020-11-20 12:54:41  [ main:138908 ] - [ INFO ]  Submitting tokens for job: job_local7815534_0013
2020-11-20 12:54:41  [ main:138944 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:54:41  [ main:138944 ] - [ INFO ]  Running job: job_local7815534_0013
2020-11-20 12:54:41  [ Thread-346:138945 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:54:41  [ Thread-346:138945 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:41  [ Thread-346:138945 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:54:41  [ Thread-346:138954 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138955 ] - [ INFO ]  Starting task: attempt_local7815534_0013_m_000000_0
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138956 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138956 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138956 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138957 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138969 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138969 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138969 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138969 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138969 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:54:41  [ LocalJobRunner Map Task Executor #0:138969 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:54:42  [ main:139945 ] - [ INFO ]  Job job_local7815534_0013 running in uber mode : false
2020-11-20 12:54:42  [ main:139945 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:54:47  [ communication thread:144964 ] - [ INFO ]  map > map
2020-11-20 12:54:48  [ main:145966 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:54:50  [ communication thread:147965 ] - [ INFO ]  map > map
2020-11-20 12:54:50  [ main:147968 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148566 ] - [ INFO ]  map > map
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148566 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148566 ] - [ INFO ]  Spilling map output
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148566 ] - [ INFO ]  bufstart = 0; bufend = 2418; bufvoid = 104857600
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148566 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148568 ] - [ INFO ]  Finished spill 0
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148569 ] - [ INFO ]  Task:attempt_local7815534_0013_m_000000_0 is done. And is in the process of committing
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148576 ] - [ INFO ]  map
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148576 ] - [ INFO ]  Task 'attempt_local7815534_0013_m_000000_0' done.
2020-11-20 12:54:51  [ LocalJobRunner Map Task Executor #0:148576 ] - [ INFO ]  Finishing task: attempt_local7815534_0013_m_000000_0
2020-11-20 12:54:51  [ Thread-346:148576 ] - [ INFO ]  map task executor complete.
2020-11-20 12:54:51  [ Thread-346:148576 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:54:51  [ pool-42-thread-1:148576 ] - [ INFO ]  Starting task: attempt_local7815534_0013_r_000000_0
2020-11-20 12:54:51  [ pool-42-thread-1:148577 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:51  [ pool-42-thread-1:148577 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:51  [ pool-42-thread-1:148577 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:51  [ pool-42-thread-1:148577 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76437660
2020-11-20 12:54:51  [ pool-42-thread-1:148578 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:54:51  [ EventFetcher for fetching Map Completion Events:148579 ] - [ INFO ]  attempt_local7815534_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:54:51  [ localfetcher#13:148579 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local7815534_0013_m_000000_0 decomp: 2129 len: 2133 to MEMORY
2020-11-20 12:54:51  [ localfetcher#13:148579 ] - [ INFO ]  Read 2129 bytes from map-output for attempt_local7815534_0013_m_000000_0
2020-11-20 12:54:51  [ localfetcher#13:148579 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2129, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2129
2020-11-20 12:54:51  [ EventFetcher for fetching Map Completion Events:148580 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:54:51  [ pool-42-thread-1:148580 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:51  [ pool-42-thread-1:148580 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:54:51  [ pool-42-thread-1:148581 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:51  [ pool-42-thread-1:148581 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2122 bytes
2020-11-20 12:54:51  [ pool-42-thread-1:148581 ] - [ INFO ]  Merged 1 segments, 2129 bytes to disk to satisfy reduce memory limit
2020-11-20 12:54:51  [ pool-42-thread-1:148581 ] - [ INFO ]  Merging 1 files, 2133 bytes from disk
2020-11-20 12:54:51  [ pool-42-thread-1:148581 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:54:51  [ pool-42-thread-1:148581 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:54:51  [ pool-42-thread-1:148582 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2122 bytes
2020-11-20 12:54:51  [ pool-42-thread-1:148582 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:51  [ pool-42-thread-1:148667 ] - [ INFO ]  Task:attempt_local7815534_0013_r_000000_0 is done. And is in the process of committing
2020-11-20 12:54:51  [ pool-42-thread-1:148674 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:54:51  [ pool-42-thread-1:148674 ] - [ INFO ]  Task attempt_local7815534_0013_r_000000_0 is allowed to commit now
2020-11-20 12:54:51  [ pool-42-thread-1:148693 ] - [ INFO ]  Saved output of task 'attempt_local7815534_0013_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local7815534_0013_r_000000
2020-11-20 12:54:51  [ pool-42-thread-1:148694 ] - [ INFO ]  reduce > reduce
2020-11-20 12:54:51  [ pool-42-thread-1:148694 ] - [ INFO ]  Task 'attempt_local7815534_0013_r_000000_0' done.
2020-11-20 12:54:51  [ pool-42-thread-1:148694 ] - [ INFO ]  Finishing task: attempt_local7815534_0013_r_000000_0
2020-11-20 12:54:51  [ Thread-346:148694 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:54:51  [ main:148970 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:54:51  [ main:148970 ] - [ INFO ]  Job job_local7815534_0013 completed successfully
2020-11-20 12:54:51  [ main:148971 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=111328
		FILE: Number of bytes written=8445381
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=38833200
		HDFS: Number of bytes written=52456
		HDFS: Number of read operations=384
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=197
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2418
		Map output materialized bytes=2133
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2133
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1744830464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:54:51  [ main:148990 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:54:52  [ main:149002 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:54:52  [ main:149007 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:54:52  [ main:149013 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:54:52  [ main:149055 ] - [ INFO ]  number of splits:1
2020-11-20 12:54:52  [ main:149072 ] - [ INFO ]  Submitting tokens for job: job_local337374620_0014
2020-11-20 12:54:52  [ main:149108 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:54:52  [ main:149108 ] - [ INFO ]  Running job: job_local337374620_0014
2020-11-20 12:54:52  [ Thread-373:149108 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:54:52  [ Thread-373:149108 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:52  [ Thread-373:149108 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:54:52  [ Thread-373:149116 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149117 ] - [ INFO ]  Starting task: attempt_local337374620_0014_m_000000_0
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149117 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149117 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149117 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149118 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149127 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149127 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149127 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149127 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149127 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:54:52  [ LocalJobRunner Map Task Executor #0:149127 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:54:53  [ main:150109 ] - [ INFO ]  Job job_local337374620_0014 running in uber mode : false
2020-11-20 12:54:53  [ main:150109 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:54:58  [ communication thread:155120 ] - [ INFO ]  map > map
2020-11-20 12:54:59  [ main:156120 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:55:01  [ communication thread:158126 ] - [ INFO ]  map > map
2020-11-20 12:55:01  [ main:158130 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158894 ] - [ INFO ]  map > map
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158894 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158895 ] - [ INFO ]  Spilling map output
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158895 ] - [ INFO ]  bufstart = 0; bufend = 2385; bufvoid = 104857600
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158895 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158897 ] - [ INFO ]  Finished spill 0
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158898 ] - [ INFO ]  Task:attempt_local337374620_0014_m_000000_0 is done. And is in the process of committing
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158904 ] - [ INFO ]  map
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158904 ] - [ INFO ]  Task 'attempt_local337374620_0014_m_000000_0' done.
2020-11-20 12:55:01  [ LocalJobRunner Map Task Executor #0:158904 ] - [ INFO ]  Finishing task: attempt_local337374620_0014_m_000000_0
2020-11-20 12:55:01  [ Thread-373:158904 ] - [ INFO ]  map task executor complete.
2020-11-20 12:55:01  [ Thread-373:158905 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:55:01  [ pool-45-thread-1:158905 ] - [ INFO ]  Starting task: attempt_local337374620_0014_r_000000_0
2020-11-20 12:55:01  [ pool-45-thread-1:158905 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:01  [ pool-45-thread-1:158906 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:01  [ pool-45-thread-1:158906 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:01  [ pool-45-thread-1:158906 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7b8a173d
2020-11-20 12:55:01  [ pool-45-thread-1:158907 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:55:01  [ EventFetcher for fetching Map Completion Events:158907 ] - [ INFO ]  attempt_local337374620_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:55:01  [ localfetcher#14:158908 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local337374620_0014_m_000000_0 decomp: 2096 len: 2100 to MEMORY
2020-11-20 12:55:01  [ localfetcher#14:158908 ] - [ INFO ]  Read 2096 bytes from map-output for attempt_local337374620_0014_m_000000_0
2020-11-20 12:55:01  [ localfetcher#14:158908 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2096, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2096
2020-11-20 12:55:01  [ EventFetcher for fetching Map Completion Events:158908 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:55:01  [ pool-45-thread-1:158909 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:01  [ pool-45-thread-1:158909 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:55:01  [ pool-45-thread-1:158909 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:01  [ pool-45-thread-1:158909 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2089 bytes
2020-11-20 12:55:01  [ pool-45-thread-1:158910 ] - [ INFO ]  Merged 1 segments, 2096 bytes to disk to satisfy reduce memory limit
2020-11-20 12:55:01  [ pool-45-thread-1:158910 ] - [ INFO ]  Merging 1 files, 2100 bytes from disk
2020-11-20 12:55:01  [ pool-45-thread-1:158910 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:55:01  [ pool-45-thread-1:158910 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:01  [ pool-45-thread-1:158910 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2089 bytes
2020-11-20 12:55:01  [ pool-45-thread-1:158910 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:02  [ pool-45-thread-1:159002 ] - [ INFO ]  Task:attempt_local337374620_0014_r_000000_0 is done. And is in the process of committing
2020-11-20 12:55:02  [ pool-45-thread-1:159009 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:02  [ pool-45-thread-1:159009 ] - [ INFO ]  Task attempt_local337374620_0014_r_000000_0 is allowed to commit now
2020-11-20 12:55:02  [ pool-45-thread-1:159036 ] - [ INFO ]  Saved output of task 'attempt_local337374620_0014_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local337374620_0014_r_000000
2020-11-20 12:55:02  [ pool-45-thread-1:159036 ] - [ INFO ]  reduce > reduce
2020-11-20 12:55:02  [ pool-45-thread-1:159036 ] - [ INFO ]  Task 'attempt_local337374620_0014_r_000000_0' done.
2020-11-20 12:55:02  [ pool-45-thread-1:159037 ] - [ INFO ]  Finishing task: attempt_local337374620_0014_r_000000_0
2020-11-20 12:55:02  [ Thread-373:159037 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:55:02  [ main:159130 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:55:02  [ main:159131 ] - [ INFO ]  Job job_local337374620_0014 completed successfully
2020-11-20 12:55:02  [ main:159132 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=120240
		FILE: Number of bytes written=9048604
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=41607000
		HDFS: Number of bytes written=56663
		HDFS: Number of read operations=414
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=213
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2385
		Map output materialized bytes=2100
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2100
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1727004672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:55:02  [ main:159155 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:55:02  [ main:159168 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:55:02  [ main:159172 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:55:02  [ main:159179 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:55:02  [ main:159217 ] - [ INFO ]  number of splits:1
2020-11-20 12:55:02  [ main:159234 ] - [ INFO ]  Submitting tokens for job: job_local2097649338_0015
2020-11-20 12:55:02  [ main:159269 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:55:02  [ main:159270 ] - [ INFO ]  Running job: job_local2097649338_0015
2020-11-20 12:55:02  [ Thread-400:159270 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:55:02  [ Thread-400:159270 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:02  [ Thread-400:159270 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:55:02  [ Thread-400:159277 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159277 ] - [ INFO ]  Starting task: attempt_local2097649338_0015_m_000000_0
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159277 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159277 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159277 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159278 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159287 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159287 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159287 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159287 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159287 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:55:02  [ LocalJobRunner Map Task Executor #0:159287 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:55:03  [ main:160275 ] - [ INFO ]  Job job_local2097649338_0015 running in uber mode : false
2020-11-20 12:55:03  [ main:160275 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:55:08  [ communication thread:165282 ] - [ INFO ]  map > map
2020-11-20 12:55:08  [ main:165289 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:55:11  [ communication thread:168283 ] - [ INFO ]  map > map
2020-11-20 12:55:11  [ main:168304 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169559 ] - [ INFO ]  map > map
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169559 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169559 ] - [ INFO ]  Spilling map output
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169559 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169559 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169561 ] - [ INFO ]  Finished spill 0
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169562 ] - [ INFO ]  Task:attempt_local2097649338_0015_m_000000_0 is done. And is in the process of committing
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169575 ] - [ INFO ]  map
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169576 ] - [ INFO ]  Task 'attempt_local2097649338_0015_m_000000_0' done.
2020-11-20 12:55:12  [ LocalJobRunner Map Task Executor #0:169576 ] - [ INFO ]  Finishing task: attempt_local2097649338_0015_m_000000_0
2020-11-20 12:55:12  [ Thread-400:169576 ] - [ INFO ]  map task executor complete.
2020-11-20 12:55:12  [ Thread-400:169576 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:55:12  [ pool-48-thread-1:169576 ] - [ INFO ]  Starting task: attempt_local2097649338_0015_r_000000_0
2020-11-20 12:55:12  [ pool-48-thread-1:169577 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:12  [ pool-48-thread-1:169577 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:12  [ pool-48-thread-1:169577 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:12  [ pool-48-thread-1:169577 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b08ced9
2020-11-20 12:55:12  [ pool-48-thread-1:169578 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:55:12  [ EventFetcher for fetching Map Completion Events:169579 ] - [ INFO ]  attempt_local2097649338_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:55:12  [ localfetcher#15:169579 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local2097649338_0015_m_000000_0 decomp: 2104 len: 2108 to MEMORY
2020-11-20 12:55:12  [ localfetcher#15:169580 ] - [ INFO ]  Read 2104 bytes from map-output for attempt_local2097649338_0015_m_000000_0
2020-11-20 12:55:12  [ localfetcher#15:169580 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2104
2020-11-20 12:55:12  [ EventFetcher for fetching Map Completion Events:169580 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:55:12  [ pool-48-thread-1:169580 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:12  [ pool-48-thread-1:169580 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:55:12  [ pool-48-thread-1:169581 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:12  [ pool-48-thread-1:169581 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 12:55:12  [ pool-48-thread-1:169581 ] - [ INFO ]  Merged 1 segments, 2104 bytes to disk to satisfy reduce memory limit
2020-11-20 12:55:12  [ pool-48-thread-1:169582 ] - [ INFO ]  Merging 1 files, 2108 bytes from disk
2020-11-20 12:55:12  [ pool-48-thread-1:169582 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:55:12  [ pool-48-thread-1:169582 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:12  [ pool-48-thread-1:169582 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 12:55:12  [ pool-48-thread-1:169582 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:12  [ pool-48-thread-1:169689 ] - [ INFO ]  Task:attempt_local2097649338_0015_r_000000_0 is done. And is in the process of committing
2020-11-20 12:55:12  [ pool-48-thread-1:169695 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:12  [ pool-48-thread-1:169695 ] - [ INFO ]  Task attempt_local2097649338_0015_r_000000_0 is allowed to commit now
2020-11-20 12:55:12  [ pool-48-thread-1:169714 ] - [ INFO ]  Saved output of task 'attempt_local2097649338_0015_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2097649338_0015_r_000000
2020-11-20 12:55:12  [ pool-48-thread-1:169715 ] - [ INFO ]  reduce > reduce
2020-11-20 12:55:12  [ pool-48-thread-1:169715 ] - [ INFO ]  Task 'attempt_local2097649338_0015_r_000000_0' done.
2020-11-20 12:55:12  [ pool-48-thread-1:169715 ] - [ INFO ]  Finishing task: attempt_local2097649338_0015_r_000000_0
2020-11-20 12:55:12  [ Thread-400:169715 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:55:13  [ main:170309 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:55:13  [ main:170309 ] - [ INFO ]  Job job_local2097649338_0015 completed successfully
2020-11-20 12:55:13  [ main:170311 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=129102
		FILE: Number of bytes written=9655262
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44380800
		HDFS: Number of bytes written=60845
		HDFS: Number of read operations=444
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=229
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=2108
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2108
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1710227456
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:55:13  [ main:170330 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:55:13  [ main:170341 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:55:13  [ main:170346 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:55:13  [ main:170352 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:55:13  [ main:170390 ] - [ INFO ]  number of splits:1
2020-11-20 12:55:13  [ main:170407 ] - [ INFO ]  Submitting tokens for job: job_local1906762135_0016
2020-11-20 12:55:13  [ main:170442 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:55:13  [ main:170442 ] - [ INFO ]  Running job: job_local1906762135_0016
2020-11-20 12:55:13  [ Thread-428:170443 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:55:13  [ Thread-428:170443 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:13  [ Thread-428:170443 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:55:13  [ Thread-428:170450 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170450 ] - [ INFO ]  Starting task: attempt_local1906762135_0016_m_000000_0
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170451 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170451 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170451 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170451 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170461 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170461 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170461 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170461 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170461 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:55:13  [ LocalJobRunner Map Task Executor #0:170461 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:55:14  [ main:171446 ] - [ INFO ]  Job job_local1906762135_0016 running in uber mode : false
2020-11-20 12:55:14  [ main:171447 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:55:19  [ communication thread:176460 ] - [ INFO ]  map > map
2020-11-20 12:55:20  [ main:177463 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:55:22  [ communication thread:179464 ] - [ INFO ]  map > map
2020-11-20 12:55:22  [ main:179470 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179991 ] - [ INFO ]  map > map
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179992 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179992 ] - [ INFO ]  Spilling map output
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179992 ] - [ INFO ]  bufstart = 0; bufend = 2409; bufvoid = 104857600
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179992 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179994 ] - [ INFO ]  Finished spill 0
2020-11-20 12:55:22  [ LocalJobRunner Map Task Executor #0:179995 ] - [ INFO ]  Task:attempt_local1906762135_0016_m_000000_0 is done. And is in the process of committing
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180003 ] - [ INFO ]  map
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180003 ] - [ INFO ]  Task 'attempt_local1906762135_0016_m_000000_0' done.
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180003 ] - [ INFO ]  Finishing task: attempt_local1906762135_0016_m_000000_0
2020-11-20 12:55:23  [ Thread-428:180003 ] - [ INFO ]  map task executor complete.
2020-11-20 12:55:23  [ Thread-428:180003 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:55:23  [ pool-51-thread-1:180003 ] - [ INFO ]  Starting task: attempt_local1906762135_0016_r_000000_0
2020-11-20 12:55:23  [ pool-51-thread-1:180004 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:23  [ pool-51-thread-1:180004 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:23  [ pool-51-thread-1:180004 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:23  [ pool-51-thread-1:180004 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d66222c
2020-11-20 12:55:23  [ pool-51-thread-1:180005 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:55:23  [ EventFetcher for fetching Map Completion Events:180006 ] - [ INFO ]  attempt_local1906762135_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:55:23  [ localfetcher#16:180007 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local1906762135_0016_m_000000_0 decomp: 2120 len: 2124 to MEMORY
2020-11-20 12:55:23  [ localfetcher#16:180007 ] - [ INFO ]  Read 2120 bytes from map-output for attempt_local1906762135_0016_m_000000_0
2020-11-20 12:55:23  [ localfetcher#16:180007 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2120, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2120
2020-11-20 12:55:23  [ EventFetcher for fetching Map Completion Events:180007 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:55:23  [ pool-51-thread-1:180007 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:23  [ pool-51-thread-1:180007 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:55:23  [ pool-51-thread-1:180008 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:23  [ pool-51-thread-1:180008 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2113 bytes
2020-11-20 12:55:23  [ pool-51-thread-1:180009 ] - [ INFO ]  Merged 1 segments, 2120 bytes to disk to satisfy reduce memory limit
2020-11-20 12:55:23  [ pool-51-thread-1:180009 ] - [ INFO ]  Merging 1 files, 2124 bytes from disk
2020-11-20 12:55:23  [ pool-51-thread-1:180009 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:55:23  [ pool-51-thread-1:180009 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:23  [ pool-51-thread-1:180009 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2113 bytes
2020-11-20 12:55:23  [ pool-51-thread-1:180009 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:23  [ pool-51-thread-1:180123 ] - [ INFO ]  Task:attempt_local1906762135_0016_r_000000_0 is done. And is in the process of committing
2020-11-20 12:55:23  [ pool-51-thread-1:180129 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:23  [ pool-51-thread-1:180129 ] - [ INFO ]  Task attempt_local1906762135_0016_r_000000_0 is allowed to commit now
2020-11-20 12:55:23  [ pool-51-thread-1:180151 ] - [ INFO ]  Saved output of task 'attempt_local1906762135_0016_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1906762135_0016_r_000000
2020-11-20 12:55:23  [ pool-51-thread-1:180152 ] - [ INFO ]  reduce > reduce
2020-11-20 12:55:23  [ pool-51-thread-1:180152 ] - [ INFO ]  Task 'attempt_local1906762135_0016_r_000000_0' done.
2020-11-20 12:55:23  [ pool-51-thread-1:180152 ] - [ INFO ]  Finishing task: attempt_local1906762135_0016_r_000000_0
2020-11-20 12:55:23  [ Thread-428:180152 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:55:23  [ main:180475 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:55:23  [ main:180475 ] - [ INFO ]  Job job_local1906762135_0016 completed successfully
2020-11-20 12:55:23  [ main:180477 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=138012
		FILE: Number of bytes written=10271788
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=47154600
		HDFS: Number of bytes written=65051
		HDFS: Number of read operations=474
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=245
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2409
		Map output materialized bytes=2124
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2124
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1693450240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:55:23  [ main:180548 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:55:23  [ main:180559 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:55:23  [ main:180564 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:55:23  [ main:180575 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:55:23  [ main:180616 ] - [ INFO ]  number of splits:1
2020-11-20 12:55:23  [ main:180633 ] - [ INFO ]  Submitting tokens for job: job_local1242991605_0017
2020-11-20 12:55:23  [ main:180668 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:55:23  [ main:180669 ] - [ INFO ]  Running job: job_local1242991605_0017
2020-11-20 12:55:23  [ Thread-455:180669 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:55:23  [ Thread-455:180669 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:23  [ Thread-455:180669 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:55:23  [ Thread-455:180680 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180680 ] - [ INFO ]  Starting task: attempt_local1242991605_0017_m_000000_0
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180680 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180680 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180680 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180681 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180690 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180690 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180690 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180690 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180690 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:55:23  [ LocalJobRunner Map Task Executor #0:180690 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:55:24  [ main:181670 ] - [ INFO ]  Job job_local1242991605_0017 running in uber mode : false
2020-11-20 12:55:24  [ main:181670 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:55:29  [ communication thread:186685 ] - [ INFO ]  map > map
2020-11-20 12:55:29  [ main:186688 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:55:32  [ communication thread:189691 ] - [ INFO ]  map > map
2020-11-20 12:55:32  [ main:189697 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190407 ] - [ INFO ]  map > map
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190408 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190408 ] - [ INFO ]  Spilling map output
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190408 ] - [ INFO ]  bufstart = 0; bufend = 2377; bufvoid = 104857600
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190408 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190410 ] - [ INFO ]  Finished spill 0
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190411 ] - [ INFO ]  Task:attempt_local1242991605_0017_m_000000_0 is done. And is in the process of committing
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190418 ] - [ INFO ]  map
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190419 ] - [ INFO ]  Task 'attempt_local1242991605_0017_m_000000_0' done.
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190419 ] - [ INFO ]  Finishing task: attempt_local1242991605_0017_m_000000_0
2020-11-20 12:55:33  [ Thread-455:190419 ] - [ INFO ]  map task executor complete.
2020-11-20 12:55:33  [ Thread-455:190419 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:55:33  [ pool-54-thread-1:190419 ] - [ INFO ]  Starting task: attempt_local1242991605_0017_r_000000_0
2020-11-20 12:55:33  [ pool-54-thread-1:190420 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:33  [ pool-54-thread-1:190420 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:33  [ pool-54-thread-1:190420 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:33  [ pool-54-thread-1:190420 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@242b3235
2020-11-20 12:55:33  [ pool-54-thread-1:190421 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:55:33  [ EventFetcher for fetching Map Completion Events:190422 ] - [ INFO ]  attempt_local1242991605_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:55:33  [ localfetcher#17:190422 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local1242991605_0017_m_000000_0 decomp: 2088 len: 2092 to MEMORY
2020-11-20 12:55:33  [ localfetcher#17:190423 ] - [ INFO ]  Read 2088 bytes from map-output for attempt_local1242991605_0017_m_000000_0
2020-11-20 12:55:33  [ localfetcher#17:190423 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2088, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2088
2020-11-20 12:55:33  [ EventFetcher for fetching Map Completion Events:190423 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:55:33  [ pool-54-thread-1:190423 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:33  [ pool-54-thread-1:190423 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:55:33  [ pool-54-thread-1:190424 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:33  [ pool-54-thread-1:190424 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2081 bytes
2020-11-20 12:55:33  [ pool-54-thread-1:190425 ] - [ INFO ]  Merged 1 segments, 2088 bytes to disk to satisfy reduce memory limit
2020-11-20 12:55:33  [ pool-54-thread-1:190425 ] - [ INFO ]  Merging 1 files, 2092 bytes from disk
2020-11-20 12:55:33  [ pool-54-thread-1:190425 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:55:33  [ pool-54-thread-1:190425 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:33  [ pool-54-thread-1:190425 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2081 bytes
2020-11-20 12:55:33  [ pool-54-thread-1:190425 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:33  [ pool-54-thread-1:190509 ] - [ INFO ]  Task:attempt_local1242991605_0017_r_000000_0 is done. And is in the process of committing
2020-11-20 12:55:33  [ pool-54-thread-1:190515 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:33  [ pool-54-thread-1:190515 ] - [ INFO ]  Task attempt_local1242991605_0017_r_000000_0 is allowed to commit now
2020-11-20 12:55:33  [ pool-54-thread-1:190535 ] - [ INFO ]  Saved output of task 'attempt_local1242991605_0017_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1242991605_0017_r_000000
2020-11-20 12:55:33  [ pool-54-thread-1:190536 ] - [ INFO ]  reduce > reduce
2020-11-20 12:55:33  [ pool-54-thread-1:190536 ] - [ INFO ]  Task 'attempt_local1242991605_0017_r_000000_0' done.
2020-11-20 12:55:33  [ pool-54-thread-1:190536 ] - [ INFO ]  Finishing task: attempt_local1242991605_0017_r_000000_0
2020-11-20 12:55:33  [ Thread-455:190536 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:55:33  [ main:190698 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:55:33  [ main:190699 ] - [ INFO ]  Job job_local1242991605_0017 completed successfully
2020-11-20 12:55:33  [ main:190700 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=146890
		FILE: Number of bytes written=10888954
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=49928400
		HDFS: Number of bytes written=69241
		HDFS: Number of read operations=504
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=261
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2377
		Map output materialized bytes=2092
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2092
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1677721600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:55:33  [ main:190719 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:55:33  [ main:190731 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:55:33  [ main:190735 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:55:33  [ main:190742 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:55:33  [ main:190779 ] - [ INFO ]  number of splits:1
2020-11-20 12:55:33  [ main:190796 ] - [ INFO ]  Submitting tokens for job: job_local400873340_0018
2020-11-20 12:55:33  [ main:190831 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:55:33  [ main:190831 ] - [ INFO ]  Running job: job_local400873340_0018
2020-11-20 12:55:33  [ Thread-482:190831 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:55:33  [ Thread-482:190831 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:33  [ Thread-482:190831 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:55:33  [ Thread-482:190840 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190841 ] - [ INFO ]  Starting task: attempt_local400873340_0018_m_000000_0
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190841 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190842 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190842 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190842 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190852 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190852 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190852 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190852 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190852 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:55:33  [ LocalJobRunner Map Task Executor #0:190852 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:55:34  [ main:191831 ] - [ INFO ]  Job job_local400873340_0018 running in uber mode : false
2020-11-20 12:55:34  [ main:191831 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:55:39  [ communication thread:196851 ] - [ INFO ]  map > map
2020-11-20 12:55:40  [ main:197853 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:55:42  [ communication thread:199856 ] - [ INFO ]  map > map
2020-11-20 12:55:42  [ main:199858 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201111 ] - [ INFO ]  map > map
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201111 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201112 ] - [ INFO ]  Spilling map output
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201112 ] - [ INFO ]  bufstart = 0; bufend = 2390; bufvoid = 104857600
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201112 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201114 ] - [ INFO ]  Finished spill 0
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201115 ] - [ INFO ]  Task:attempt_local400873340_0018_m_000000_0 is done. And is in the process of committing
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201135 ] - [ INFO ]  map
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201135 ] - [ INFO ]  Task 'attempt_local400873340_0018_m_000000_0' done.
2020-11-20 12:55:44  [ LocalJobRunner Map Task Executor #0:201135 ] - [ INFO ]  Finishing task: attempt_local400873340_0018_m_000000_0
2020-11-20 12:55:44  [ Thread-482:201135 ] - [ INFO ]  map task executor complete.
2020-11-20 12:55:44  [ Thread-482:201136 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:55:44  [ pool-57-thread-1:201136 ] - [ INFO ]  Starting task: attempt_local400873340_0018_r_000000_0
2020-11-20 12:55:44  [ pool-57-thread-1:201136 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:44  [ pool-57-thread-1:201137 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:44  [ pool-57-thread-1:201137 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:44  [ pool-57-thread-1:201137 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19f402f6
2020-11-20 12:55:44  [ pool-57-thread-1:201138 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:55:44  [ EventFetcher for fetching Map Completion Events:201138 ] - [ INFO ]  attempt_local400873340_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:55:44  [ localfetcher#18:201139 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local400873340_0018_m_000000_0 decomp: 2101 len: 2105 to MEMORY
2020-11-20 12:55:44  [ localfetcher#18:201139 ] - [ INFO ]  Read 2101 bytes from map-output for attempt_local400873340_0018_m_000000_0
2020-11-20 12:55:44  [ localfetcher#18:201140 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2101
2020-11-20 12:55:44  [ EventFetcher for fetching Map Completion Events:201140 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:55:44  [ pool-57-thread-1:201141 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:44  [ pool-57-thread-1:201141 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:55:44  [ pool-57-thread-1:201142 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:44  [ pool-57-thread-1:201142 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 12:55:44  [ pool-57-thread-1:201142 ] - [ INFO ]  Merged 1 segments, 2101 bytes to disk to satisfy reduce memory limit
2020-11-20 12:55:44  [ pool-57-thread-1:201142 ] - [ INFO ]  Merging 1 files, 2105 bytes from disk
2020-11-20 12:55:44  [ pool-57-thread-1:201142 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:55:44  [ pool-57-thread-1:201142 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:44  [ pool-57-thread-1:201147 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 12:55:44  [ pool-57-thread-1:201147 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:44  [ pool-57-thread-1:201255 ] - [ INFO ]  Task:attempt_local400873340_0018_r_000000_0 is done. And is in the process of committing
2020-11-20 12:55:44  [ pool-57-thread-1:201266 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:44  [ pool-57-thread-1:201266 ] - [ INFO ]  Task attempt_local400873340_0018_r_000000_0 is allowed to commit now
2020-11-20 12:55:44  [ pool-57-thread-1:201297 ] - [ INFO ]  Saved output of task 'attempt_local400873340_0018_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local400873340_0018_r_000000
2020-11-20 12:55:44  [ pool-57-thread-1:201298 ] - [ INFO ]  reduce > reduce
2020-11-20 12:55:44  [ pool-57-thread-1:201298 ] - [ INFO ]  Task 'attempt_local400873340_0018_r_000000_0' done.
2020-11-20 12:55:44  [ pool-57-thread-1:201298 ] - [ INFO ]  Finishing task: attempt_local400873340_0018_r_000000_0
2020-11-20 12:55:44  [ Thread-482:201298 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:55:44  [ main:201863 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:55:44  [ main:201863 ] - [ INFO ]  Job job_local400873340_0018 completed successfully
2020-11-20 12:55:44  [ main:201865 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=155730
		FILE: Number of bytes written=11504439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=52702200
		HDFS: Number of bytes written=73412
		HDFS: Number of read operations=534
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=277
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2390
		Map output materialized bytes=2105
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2105
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1661992960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:55:44  [ main:201896 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:55:44  [ main:201913 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:55:44  [ main:201917 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:55:44  [ main:201926 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:55:44  [ main:201965 ] - [ INFO ]  number of splits:1
2020-11-20 12:55:44  [ main:201982 ] - [ INFO ]  Submitting tokens for job: job_local472319552_0019
2020-11-20 12:55:45  [ main:202017 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:55:45  [ main:202017 ] - [ INFO ]  Running job: job_local472319552_0019
2020-11-20 12:55:45  [ Thread-510:202017 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:55:45  [ Thread-510:202017 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:45  [ Thread-510:202017 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:55:45  [ Thread-510:202028 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202028 ] - [ INFO ]  Starting task: attempt_local472319552_0019_m_000000_0
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202029 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202029 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202029 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202029 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202039 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202039 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202039 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202039 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202039 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:55:45  [ LocalJobRunner Map Task Executor #0:202039 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:55:46  [ main:203019 ] - [ INFO ]  Job job_local472319552_0019 running in uber mode : false
2020-11-20 12:55:46  [ main:203019 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:55:51  [ communication thread:208036 ] - [ INFO ]  map > map
2020-11-20 12:55:52  [ main:209036 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:55:54  [ communication thread:211040 ] - [ INFO ]  map > map
2020-11-20 12:55:54  [ main:211045 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212106 ] - [ INFO ]  map > map
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212106 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212106 ] - [ INFO ]  Spilling map output
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212106 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212106 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212108 ] - [ INFO ]  Finished spill 0
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212109 ] - [ INFO ]  Task:attempt_local472319552_0019_m_000000_0 is done. And is in the process of committing
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212149 ] - [ INFO ]  map
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212149 ] - [ INFO ]  Task 'attempt_local472319552_0019_m_000000_0' done.
2020-11-20 12:55:55  [ LocalJobRunner Map Task Executor #0:212149 ] - [ INFO ]  Finishing task: attempt_local472319552_0019_m_000000_0
2020-11-20 12:55:55  [ Thread-510:212149 ] - [ INFO ]  map task executor complete.
2020-11-20 12:55:55  [ Thread-510:212150 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:55:55  [ pool-60-thread-1:212150 ] - [ INFO ]  Starting task: attempt_local472319552_0019_r_000000_0
2020-11-20 12:55:55  [ pool-60-thread-1:212150 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:55  [ pool-60-thread-1:212150 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:55  [ pool-60-thread-1:212150 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:55  [ pool-60-thread-1:212150 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@293af31
2020-11-20 12:55:55  [ pool-60-thread-1:212152 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:55:55  [ EventFetcher for fetching Map Completion Events:212152 ] - [ INFO ]  attempt_local472319552_0019_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:55:55  [ localfetcher#19:212153 ] - [ INFO ]  localfetcher#19 about to shuffle output of map attempt_local472319552_0019_m_000000_0 decomp: 2105 len: 2109 to MEMORY
2020-11-20 12:55:55  [ localfetcher#19:212153 ] - [ INFO ]  Read 2105 bytes from map-output for attempt_local472319552_0019_m_000000_0
2020-11-20 12:55:55  [ localfetcher#19:212153 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2105
2020-11-20 12:55:55  [ EventFetcher for fetching Map Completion Events:212153 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:55:55  [ pool-60-thread-1:212154 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:55  [ pool-60-thread-1:212154 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:55:55  [ pool-60-thread-1:212154 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2098 bytes
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  Merged 1 segments, 2105 bytes to disk to satisfy reduce memory limit
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  Merging 1 files, 2109 bytes from disk
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2098 bytes
2020-11-20 12:55:55  [ pool-60-thread-1:212155 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:55  [ pool-60-thread-1:212355 ] - [ INFO ]  Task:attempt_local472319552_0019_r_000000_0 is done. And is in the process of committing
2020-11-20 12:55:55  [ pool-60-thread-1:212376 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:55:55  [ pool-60-thread-1:212376 ] - [ INFO ]  Task attempt_local472319552_0019_r_000000_0 is allowed to commit now
2020-11-20 12:55:55  [ pool-60-thread-1:212448 ] - [ INFO ]  Saved output of task 'attempt_local472319552_0019_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local472319552_0019_r_000000
2020-11-20 12:55:55  [ pool-60-thread-1:212449 ] - [ INFO ]  reduce > reduce
2020-11-20 12:55:55  [ pool-60-thread-1:212449 ] - [ INFO ]  Task 'attempt_local472319552_0019_r_000000_0' done.
2020-11-20 12:55:55  [ pool-60-thread-1:212449 ] - [ INFO ]  Finishing task: attempt_local472319552_0019_r_000000_0
2020-11-20 12:55:55  [ Thread-510:212449 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:55:56  [ main:213049 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:55:56  [ main:213050 ] - [ INFO ]  Job job_local472319552_0019 completed successfully
2020-11-20 12:55:56  [ main:213052 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=164604
		FILE: Number of bytes written=12120813
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=55476000
		HDFS: Number of bytes written=77600
		HDFS: Number of read operations=564
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=293
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2394
		Map output materialized bytes=2109
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2109
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1647312896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:55:56  [ main:213119 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:55:56  [ main:213136 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:55:56  [ main:213141 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:55:56  [ main:213159 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:55:56  [ main:213217 ] - [ INFO ]  number of splits:1
2020-11-20 12:55:56  [ main:213234 ] - [ INFO ]  Submitting tokens for job: job_local2039313467_0020
2020-11-20 12:55:56  [ main:213271 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:55:56  [ main:213271 ] - [ INFO ]  Running job: job_local2039313467_0020
2020-11-20 12:55:56  [ Thread-538:213272 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:55:56  [ Thread-538:213272 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:56  [ Thread-538:213272 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:55:56  [ Thread-538:213295 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213295 ] - [ INFO ]  Starting task: attempt_local2039313467_0020_m_000000_0
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213296 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213296 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213296 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213296 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213304 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213304 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213304 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213304 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213304 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:55:56  [ LocalJobRunner Map Task Executor #0:213304 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:55:57  [ main:214274 ] - [ INFO ]  Job job_local2039313467_0020 running in uber mode : false
2020-11-20 12:55:57  [ main:214274 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:56:02  [ communication thread:219299 ] - [ INFO ]  map > map
2020-11-20 12:56:03  [ main:220284 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:56:05  [ communication thread:222304 ] - [ INFO ]  map > map
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222708 ] - [ INFO ]  map > map
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222708 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222708 ] - [ INFO ]  Spilling map output
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222708 ] - [ INFO ]  bufstart = 0; bufend = 2388; bufvoid = 104857600
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222708 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222710 ] - [ INFO ]  Finished spill 0
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222712 ] - [ INFO ]  Task:attempt_local2039313467_0020_m_000000_0 is done. And is in the process of committing
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222722 ] - [ INFO ]  map
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222722 ] - [ INFO ]  Task 'attempt_local2039313467_0020_m_000000_0' done.
2020-11-20 12:56:05  [ LocalJobRunner Map Task Executor #0:222722 ] - [ INFO ]  Finishing task: attempt_local2039313467_0020_m_000000_0
2020-11-20 12:56:05  [ Thread-538:222722 ] - [ INFO ]  map task executor complete.
2020-11-20 12:56:05  [ Thread-538:222723 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:56:05  [ pool-63-thread-1:222723 ] - [ INFO ]  Starting task: attempt_local2039313467_0020_r_000000_0
2020-11-20 12:56:05  [ pool-63-thread-1:222724 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:05  [ pool-63-thread-1:222724 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:05  [ pool-63-thread-1:222724 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:05  [ pool-63-thread-1:222724 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@619565ed
2020-11-20 12:56:05  [ pool-63-thread-1:222726 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:56:05  [ EventFetcher for fetching Map Completion Events:222726 ] - [ INFO ]  attempt_local2039313467_0020_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:56:05  [ localfetcher#20:222727 ] - [ INFO ]  localfetcher#20 about to shuffle output of map attempt_local2039313467_0020_m_000000_0 decomp: 2099 len: 2103 to MEMORY
2020-11-20 12:56:05  [ localfetcher#20:222727 ] - [ INFO ]  Read 2099 bytes from map-output for attempt_local2039313467_0020_m_000000_0
2020-11-20 12:56:05  [ localfetcher#20:222727 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2099, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2099
2020-11-20 12:56:05  [ EventFetcher for fetching Map Completion Events:222727 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:56:05  [ pool-63-thread-1:222728 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:05  [ pool-63-thread-1:222728 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:56:05  [ pool-63-thread-1:222729 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:05  [ pool-63-thread-1:222729 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2092 bytes
2020-11-20 12:56:05  [ pool-63-thread-1:222729 ] - [ INFO ]  Merged 1 segments, 2099 bytes to disk to satisfy reduce memory limit
2020-11-20 12:56:05  [ pool-63-thread-1:222729 ] - [ INFO ]  Merging 1 files, 2103 bytes from disk
2020-11-20 12:56:05  [ pool-63-thread-1:222729 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:56:05  [ pool-63-thread-1:222729 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:05  [ pool-63-thread-1:222730 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2092 bytes
2020-11-20 12:56:05  [ pool-63-thread-1:222730 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:05  [ pool-63-thread-1:222875 ] - [ INFO ]  Task:attempt_local2039313467_0020_r_000000_0 is done. And is in the process of committing
2020-11-20 12:56:05  [ pool-63-thread-1:222892 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:05  [ pool-63-thread-1:222892 ] - [ INFO ]  Task attempt_local2039313467_0020_r_000000_0 is allowed to commit now
2020-11-20 12:56:05  [ pool-63-thread-1:222957 ] - [ INFO ]  Saved output of task 'attempt_local2039313467_0020_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2039313467_0020_r_000000
2020-11-20 12:56:05  [ pool-63-thread-1:222958 ] - [ INFO ]  reduce > reduce
2020-11-20 12:56:05  [ pool-63-thread-1:222958 ] - [ INFO ]  Task 'attempt_local2039313467_0020_r_000000_0' done.
2020-11-20 12:56:05  [ pool-63-thread-1:222958 ] - [ INFO ]  Finishing task: attempt_local2039313467_0020_r_000000_0
2020-11-20 12:56:05  [ Thread-538:222958 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:56:06  [ main:223292 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:56:06  [ main:223293 ] - [ INFO ]  Job job_local2039313467_0020 completed successfully
2020-11-20 12:56:06  [ main:223295 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=173474
		FILE: Number of bytes written=12740321
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58249800
		HDFS: Number of bytes written=81786
		HDFS: Number of read operations=594
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=309
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2388
		Map output materialized bytes=2103
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2103
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1633681408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:56:06  [ main:223384 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:56:06  [ main:223417 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:56:06  [ main:223421 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:56:06  [ main:223431 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:56:06  [ main:223476 ] - [ INFO ]  number of splits:1
2020-11-20 12:56:06  [ main:223493 ] - [ INFO ]  Submitting tokens for job: job_local503849466_0021
2020-11-20 12:56:06  [ main:223530 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:56:06  [ main:223530 ] - [ INFO ]  Running job: job_local503849466_0021
2020-11-20 12:56:06  [ Thread-565:223531 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:56:06  [ Thread-565:223531 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:06  [ Thread-565:223531 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:56:06  [ Thread-565:223548 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223548 ] - [ INFO ]  Starting task: attempt_local503849466_0021_m_000000_0
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223549 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223549 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223549 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223549 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223558 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223558 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223558 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223558 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223558 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:56:06  [ LocalJobRunner Map Task Executor #0:223558 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:56:07  [ main:224535 ] - [ INFO ]  Job job_local503849466_0021 running in uber mode : false
2020-11-20 12:56:07  [ main:224535 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:56:12  [ communication thread:229558 ] - [ INFO ]  map > map
2020-11-20 12:56:13  [ main:230552 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:56:15  [ communication thread:232562 ] - [ INFO ]  map > map
2020-11-20 12:56:16  [ main:233558 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233581 ] - [ INFO ]  map > map
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233582 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233582 ] - [ INFO ]  Spilling map output
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233582 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233582 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233584 ] - [ INFO ]  Finished spill 0
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233585 ] - [ INFO ]  Task:attempt_local503849466_0021_m_000000_0 is done. And is in the process of committing
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233611 ] - [ INFO ]  map
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233611 ] - [ INFO ]  Task 'attempt_local503849466_0021_m_000000_0' done.
2020-11-20 12:56:16  [ LocalJobRunner Map Task Executor #0:233611 ] - [ INFO ]  Finishing task: attempt_local503849466_0021_m_000000_0
2020-11-20 12:56:16  [ Thread-565:233611 ] - [ INFO ]  map task executor complete.
2020-11-20 12:56:16  [ Thread-565:233611 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:56:16  [ pool-66-thread-1:233611 ] - [ INFO ]  Starting task: attempt_local503849466_0021_r_000000_0
2020-11-20 12:56:16  [ pool-66-thread-1:233612 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:16  [ pool-66-thread-1:233612 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:16  [ pool-66-thread-1:233612 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:16  [ pool-66-thread-1:233612 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12f840b
2020-11-20 12:56:16  [ pool-66-thread-1:233614 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:56:16  [ EventFetcher for fetching Map Completion Events:233614 ] - [ INFO ]  attempt_local503849466_0021_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:56:16  [ localfetcher#21:233615 ] - [ INFO ]  localfetcher#21 about to shuffle output of map attempt_local503849466_0021_m_000000_0 decomp: 2104 len: 2108 to MEMORY
2020-11-20 12:56:16  [ localfetcher#21:233615 ] - [ INFO ]  Read 2104 bytes from map-output for attempt_local503849466_0021_m_000000_0
2020-11-20 12:56:16  [ localfetcher#21:233615 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2104
2020-11-20 12:56:16  [ EventFetcher for fetching Map Completion Events:233616 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:56:16  [ pool-66-thread-1:233616 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:16  [ pool-66-thread-1:233616 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:56:16  [ pool-66-thread-1:233617 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:16  [ pool-66-thread-1:233617 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 12:56:16  [ pool-66-thread-1:233617 ] - [ INFO ]  Merged 1 segments, 2104 bytes to disk to satisfy reduce memory limit
2020-11-20 12:56:16  [ pool-66-thread-1:233617 ] - [ INFO ]  Merging 1 files, 2108 bytes from disk
2020-11-20 12:56:16  [ pool-66-thread-1:233617 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:56:16  [ pool-66-thread-1:233617 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:16  [ pool-66-thread-1:233618 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 12:56:16  [ pool-66-thread-1:233618 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:16  [ pool-66-thread-1:233751 ] - [ INFO ]  Task:attempt_local503849466_0021_r_000000_0 is done. And is in the process of committing
2020-11-20 12:56:16  [ pool-66-thread-1:233761 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:16  [ pool-66-thread-1:233761 ] - [ INFO ]  Task attempt_local503849466_0021_r_000000_0 is allowed to commit now
2020-11-20 12:56:16  [ pool-66-thread-1:233797 ] - [ INFO ]  Saved output of task 'attempt_local503849466_0021_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local503849466_0021_r_000000
2020-11-20 12:56:16  [ pool-66-thread-1:233798 ] - [ INFO ]  reduce > reduce
2020-11-20 12:56:16  [ pool-66-thread-1:233798 ] - [ INFO ]  Task 'attempt_local503849466_0021_r_000000_0' done.
2020-11-20 12:56:16  [ pool-66-thread-1:233798 ] - [ INFO ]  Finishing task: attempt_local503849466_0021_r_000000_0
2020-11-20 12:56:16  [ Thread-565:233798 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:56:17  [ main:234559 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:56:17  [ main:234559 ] - [ INFO ]  Job job_local503849466_0021 completed successfully
2020-11-20 12:56:17  [ main:234561 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=182342
		FILE: Number of bytes written=13358986
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=61023600
		HDFS: Number of bytes written=85971
		HDFS: Number of read operations=624
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=325
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=2108
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2108
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1620049920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:56:17  [ main:234599 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:56:17  [ main:234614 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:56:17  [ main:234619 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:56:17  [ main:234627 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:56:17  [ main:234669 ] - [ INFO ]  number of splits:1
2020-11-20 12:56:17  [ main:234686 ] - [ INFO ]  Submitting tokens for job: job_local666463844_0022
2020-11-20 12:56:17  [ main:234721 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:56:17  [ main:234721 ] - [ INFO ]  Running job: job_local666463844_0022
2020-11-20 12:56:17  [ Thread-593:234721 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:56:17  [ Thread-593:234722 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:17  [ Thread-593:234722 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:56:17  [ Thread-593:234732 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234732 ] - [ INFO ]  Starting task: attempt_local666463844_0022_m_000000_0
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234732 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234732 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234732 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234733 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234740 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234740 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234740 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234740 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234740 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:56:17  [ LocalJobRunner Map Task Executor #0:234740 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:56:18  [ main:235725 ] - [ INFO ]  Job job_local666463844_0022 running in uber mode : false
2020-11-20 12:56:18  [ main:235725 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:56:23  [ communication thread:240742 ] - [ INFO ]  map > map
2020-11-20 12:56:24  [ main:241732 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:56:26  [ communication thread:243746 ] - [ INFO ]  map > map
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244232 ] - [ INFO ]  map > map
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244232 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244232 ] - [ INFO ]  Spilling map output
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244232 ] - [ INFO ]  bufstart = 0; bufend = 2399; bufvoid = 104857600
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244232 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244234 ] - [ INFO ]  Finished spill 0
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244235 ] - [ INFO ]  Task:attempt_local666463844_0022_m_000000_0 is done. And is in the process of committing
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244245 ] - [ INFO ]  map
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244245 ] - [ INFO ]  Task 'attempt_local666463844_0022_m_000000_0' done.
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244245 ] - [ INFO ]  Finishing task: attempt_local666463844_0022_m_000000_0
2020-11-20 12:56:27  [ Thread-593:244245 ] - [ INFO ]  map task executor complete.
2020-11-20 12:56:27  [ Thread-593:244245 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:56:27  [ pool-69-thread-1:244246 ] - [ INFO ]  Starting task: attempt_local666463844_0022_r_000000_0
2020-11-20 12:56:27  [ pool-69-thread-1:244246 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:27  [ pool-69-thread-1:244247 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:27  [ pool-69-thread-1:244247 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:27  [ pool-69-thread-1:244247 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69233967
2020-11-20 12:56:27  [ pool-69-thread-1:244248 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:56:27  [ EventFetcher for fetching Map Completion Events:244248 ] - [ INFO ]  attempt_local666463844_0022_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:56:27  [ localfetcher#22:244249 ] - [ INFO ]  localfetcher#22 about to shuffle output of map attempt_local666463844_0022_m_000000_0 decomp: 2110 len: 2114 to MEMORY
2020-11-20 12:56:27  [ localfetcher#22:244249 ] - [ INFO ]  Read 2110 bytes from map-output for attempt_local666463844_0022_m_000000_0
2020-11-20 12:56:27  [ localfetcher#22:244249 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2110, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2110
2020-11-20 12:56:27  [ EventFetcher for fetching Map Completion Events:244250 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:56:27  [ pool-69-thread-1:244250 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:27  [ pool-69-thread-1:244250 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:56:27  [ pool-69-thread-1:244251 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:27  [ pool-69-thread-1:244251 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2103 bytes
2020-11-20 12:56:27  [ pool-69-thread-1:244251 ] - [ INFO ]  Merged 1 segments, 2110 bytes to disk to satisfy reduce memory limit
2020-11-20 12:56:27  [ pool-69-thread-1:244252 ] - [ INFO ]  Merging 1 files, 2114 bytes from disk
2020-11-20 12:56:27  [ pool-69-thread-1:244252 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:56:27  [ pool-69-thread-1:244252 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:27  [ pool-69-thread-1:244252 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2103 bytes
2020-11-20 12:56:27  [ pool-69-thread-1:244252 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:27  [ pool-69-thread-1:244355 ] - [ INFO ]  Task:attempt_local666463844_0022_r_000000_0 is done. And is in the process of committing
2020-11-20 12:56:27  [ pool-69-thread-1:244364 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:27  [ pool-69-thread-1:244365 ] - [ INFO ]  Task attempt_local666463844_0022_r_000000_0 is allowed to commit now
2020-11-20 12:56:27  [ pool-69-thread-1:244391 ] - [ INFO ]  Saved output of task 'attempt_local666463844_0022_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local666463844_0022_r_000000
2020-11-20 12:56:27  [ pool-69-thread-1:244392 ] - [ INFO ]  reduce > reduce
2020-11-20 12:56:27  [ pool-69-thread-1:244392 ] - [ INFO ]  Task 'attempt_local666463844_0022_r_000000_0' done.
2020-11-20 12:56:27  [ pool-69-thread-1:244392 ] - [ INFO ]  Finishing task: attempt_local666463844_0022_r_000000_0
2020-11-20 12:56:27  [ Thread-593:244392 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:56:27  [ main:244745 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:56:27  [ main:244745 ] - [ INFO ]  Job job_local666463844_0022 completed successfully
2020-11-20 12:56:27  [ main:244748 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=191232
		FILE: Number of bytes written=13977746
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=63797400
		HDFS: Number of bytes written=90167
		HDFS: Number of read operations=654
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=341
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2399
		Map output materialized bytes=2114
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2114
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=1595932672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:56:27  [ main:244778 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:56:27  [ main:244791 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:56:27  [ main:244796 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:56:27  [ main:244803 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:56:27  [ main:244852 ] - [ INFO ]  number of splits:1
2020-11-20 12:56:27  [ main:244869 ] - [ INFO ]  Submitting tokens for job: job_local1704945756_0023
2020-11-20 12:56:27  [ main:244903 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:56:27  [ main:244903 ] - [ INFO ]  Running job: job_local1704945756_0023
2020-11-20 12:56:27  [ Thread-620:244904 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:56:27  [ Thread-620:244904 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:27  [ Thread-620:244904 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:56:27  [ Thread-620:244922 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244922 ] - [ INFO ]  Starting task: attempt_local1704945756_0023_m_000000_0
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244923 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244923 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244923 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244924 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244933 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244933 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244933 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244933 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244933 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:56:27  [ LocalJobRunner Map Task Executor #0:244933 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:56:28  [ main:245907 ] - [ INFO ]  Job job_local1704945756_0023 running in uber mode : false
2020-11-20 12:56:28  [ main:245907 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:56:33  [ communication thread:250926 ] - [ INFO ]  map > map
2020-11-20 12:56:34  [ main:251914 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:56:36  [ communication thread:253930 ] - [ INFO ]  map > map
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254687 ] - [ INFO ]  map > map
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254688 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254688 ] - [ INFO ]  Spilling map output
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254688 ] - [ INFO ]  bufstart = 0; bufend = 2263; bufvoid = 104857600
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254688 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254690 ] - [ INFO ]  Finished spill 0
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254690 ] - [ INFO ]  Task:attempt_local1704945756_0023_m_000000_0 is done. And is in the process of committing
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254700 ] - [ INFO ]  map
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254701 ] - [ INFO ]  Task 'attempt_local1704945756_0023_m_000000_0' done.
2020-11-20 12:56:37  [ LocalJobRunner Map Task Executor #0:254701 ] - [ INFO ]  Finishing task: attempt_local1704945756_0023_m_000000_0
2020-11-20 12:56:37  [ Thread-620:254701 ] - [ INFO ]  map task executor complete.
2020-11-20 12:56:37  [ Thread-620:254701 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:56:37  [ pool-72-thread-1:254701 ] - [ INFO ]  Starting task: attempt_local1704945756_0023_r_000000_0
2020-11-20 12:56:37  [ pool-72-thread-1:254702 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:37  [ pool-72-thread-1:254702 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:37  [ pool-72-thread-1:254702 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:37  [ pool-72-thread-1:254702 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@630a3ca
2020-11-20 12:56:37  [ pool-72-thread-1:254703 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:56:37  [ EventFetcher for fetching Map Completion Events:254703 ] - [ INFO ]  attempt_local1704945756_0023_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:56:37  [ localfetcher#23:254704 ] - [ INFO ]  localfetcher#23 about to shuffle output of map attempt_local1704945756_0023_m_000000_0 decomp: 2073 len: 2077 to MEMORY
2020-11-20 12:56:37  [ localfetcher#23:254704 ] - [ INFO ]  Read 2073 bytes from map-output for attempt_local1704945756_0023_m_000000_0
2020-11-20 12:56:37  [ localfetcher#23:254704 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2073, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2073
2020-11-20 12:56:37  [ EventFetcher for fetching Map Completion Events:254705 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:56:37  [ pool-72-thread-1:254705 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:37  [ pool-72-thread-1:254705 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:56:37  [ pool-72-thread-1:254705 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:37  [ pool-72-thread-1:254706 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2067 bytes
2020-11-20 12:56:37  [ pool-72-thread-1:254706 ] - [ INFO ]  Merged 1 segments, 2073 bytes to disk to satisfy reduce memory limit
2020-11-20 12:56:37  [ pool-72-thread-1:254706 ] - [ INFO ]  Merging 1 files, 2077 bytes from disk
2020-11-20 12:56:37  [ pool-72-thread-1:254706 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:56:37  [ pool-72-thread-1:254706 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:37  [ pool-72-thread-1:254706 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2067 bytes
2020-11-20 12:56:37  [ pool-72-thread-1:254707 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:37  [ main:254923 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:56:38  [ pool-72-thread-1:255112 ] - [ INFO ]  Task:attempt_local1704945756_0023_r_000000_0 is done. And is in the process of committing
2020-11-20 12:56:38  [ pool-72-thread-1:255120 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:38  [ pool-72-thread-1:255120 ] - [ INFO ]  Task attempt_local1704945756_0023_r_000000_0 is allowed to commit now
2020-11-20 12:56:38  [ pool-72-thread-1:255146 ] - [ INFO ]  Saved output of task 'attempt_local1704945756_0023_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1704945756_0023_r_000000
2020-11-20 12:56:38  [ pool-72-thread-1:255147 ] - [ INFO ]  reduce > reduce
2020-11-20 12:56:38  [ pool-72-thread-1:255147 ] - [ INFO ]  Task 'attempt_local1704945756_0023_r_000000_0' done.
2020-11-20 12:56:38  [ pool-72-thread-1:255147 ] - [ INFO ]  Finishing task: attempt_local1704945756_0023_r_000000_0
2020-11-20 12:56:38  [ Thread-620:255147 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:56:38  [ main:255927 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:56:38  [ main:255927 ] - [ INFO ]  Job job_local1704945756_0023 completed successfully
2020-11-20 12:56:38  [ main:255929 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=200060
		FILE: Number of bytes written=14562473
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=66571200
		HDFS: Number of bytes written=94332
		HDFS: Number of read operations=684
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=357
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2263
		Map output materialized bytes=2077
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2077
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=88
		Total committed heap usage (bytes)=1559232512
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:56:38  [ main:255956 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:56:38  [ main:255971 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:56:38  [ main:255975 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:56:38  [ main:255983 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:56:39  [ main:256027 ] - [ INFO ]  number of splits:1
2020-11-20 12:56:39  [ main:256044 ] - [ INFO ]  Submitting tokens for job: job_local720693326_0024
2020-11-20 12:56:39  [ main:256078 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:56:39  [ main:256078 ] - [ INFO ]  Running job: job_local720693326_0024
2020-11-20 12:56:39  [ Thread-647:256078 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:56:39  [ Thread-647:256078 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:39  [ Thread-647:256079 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:56:39  [ Thread-647:256088 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256088 ] - [ INFO ]  Starting task: attempt_local720693326_0024_m_000000_0
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256089 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256089 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256089 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256089 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256097 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256097 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256097 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256097 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256097 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:56:39  [ LocalJobRunner Map Task Executor #0:256097 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:56:40  [ main:257079 ] - [ INFO ]  Job job_local720693326_0024 running in uber mode : false
2020-11-20 12:56:40  [ main:257079 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:56:45  [ communication thread:262093 ] - [ INFO ]  map > map
2020-11-20 12:56:46  [ main:263096 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:56:48  [ communication thread:265094 ] - [ INFO ]  map > map
2020-11-20 12:56:48  [ main:265101 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265697 ] - [ INFO ]  map > map
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265697 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265697 ] - [ INFO ]  Spilling map output
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265697 ] - [ INFO ]  bufstart = 0; bufend = 2249; bufvoid = 104857600
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265697 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265700 ] - [ INFO ]  Finished spill 0
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265701 ] - [ INFO ]  Task:attempt_local720693326_0024_m_000000_0 is done. And is in the process of committing
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265715 ] - [ INFO ]  map
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265715 ] - [ INFO ]  Task 'attempt_local720693326_0024_m_000000_0' done.
2020-11-20 12:56:48  [ LocalJobRunner Map Task Executor #0:265715 ] - [ INFO ]  Finishing task: attempt_local720693326_0024_m_000000_0
2020-11-20 12:56:48  [ Thread-647:265715 ] - [ INFO ]  map task executor complete.
2020-11-20 12:56:48  [ Thread-647:265716 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:56:48  [ pool-75-thread-1:265716 ] - [ INFO ]  Starting task: attempt_local720693326_0024_r_000000_0
2020-11-20 12:56:48  [ pool-75-thread-1:265717 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:48  [ pool-75-thread-1:265717 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:48  [ pool-75-thread-1:265717 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:48  [ pool-75-thread-1:265717 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2667a058
2020-11-20 12:56:48  [ pool-75-thread-1:265718 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:56:48  [ EventFetcher for fetching Map Completion Events:265718 ] - [ INFO ]  attempt_local720693326_0024_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:56:48  [ localfetcher#24:265719 ] - [ INFO ]  localfetcher#24 about to shuffle output of map attempt_local720693326_0024_m_000000_0 decomp: 2059 len: 2063 to MEMORY
2020-11-20 12:56:48  [ localfetcher#24:265719 ] - [ INFO ]  Read 2059 bytes from map-output for attempt_local720693326_0024_m_000000_0
2020-11-20 12:56:48  [ localfetcher#24:265720 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2059, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2059
2020-11-20 12:56:48  [ EventFetcher for fetching Map Completion Events:265720 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:56:48  [ pool-75-thread-1:265720 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:48  [ pool-75-thread-1:265720 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:56:48  [ pool-75-thread-1:265721 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:48  [ pool-75-thread-1:265721 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2053 bytes
2020-11-20 12:56:48  [ pool-75-thread-1:265721 ] - [ INFO ]  Merged 1 segments, 2059 bytes to disk to satisfy reduce memory limit
2020-11-20 12:56:48  [ pool-75-thread-1:265722 ] - [ INFO ]  Merging 1 files, 2063 bytes from disk
2020-11-20 12:56:48  [ pool-75-thread-1:265722 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:56:48  [ pool-75-thread-1:265722 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:48  [ pool-75-thread-1:265722 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2053 bytes
2020-11-20 12:56:48  [ pool-75-thread-1:265722 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:48  [ pool-75-thread-1:265878 ] - [ INFO ]  Task:attempt_local720693326_0024_r_000000_0 is done. And is in the process of committing
2020-11-20 12:56:48  [ pool-75-thread-1:265888 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:48  [ pool-75-thread-1:265888 ] - [ INFO ]  Task attempt_local720693326_0024_r_000000_0 is allowed to commit now
2020-11-20 12:56:48  [ pool-75-thread-1:265919 ] - [ INFO ]  Saved output of task 'attempt_local720693326_0024_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local720693326_0024_r_000000
2020-11-20 12:56:48  [ pool-75-thread-1:265920 ] - [ INFO ]  reduce > reduce
2020-11-20 12:56:48  [ pool-75-thread-1:265920 ] - [ INFO ]  Task 'attempt_local720693326_0024_r_000000_0' done.
2020-11-20 12:56:48  [ pool-75-thread-1:265920 ] - [ INFO ]  Finishing task: attempt_local720693326_0024_r_000000_0
2020-11-20 12:56:48  [ Thread-647:265920 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:56:49  [ main:266101 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:56:49  [ main:266101 ] - [ INFO ]  Job job_local720693326_0024 completed successfully
2020-11-20 12:56:49  [ main:266103 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=208786
		FILE: Number of bytes written=15145193
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=69345000
		HDFS: Number of bytes written=98446
		HDFS: Number of read operations=714
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=373
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2249
		Map output materialized bytes=2063
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2063
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=1619001344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:56:49  [ main:266131 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:56:49  [ main:266146 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:56:49  [ main:266151 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:56:49  [ main:266159 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:56:49  [ main:266199 ] - [ INFO ]  number of splits:1
2020-11-20 12:56:49  [ main:266215 ] - [ INFO ]  Submitting tokens for job: job_local1793950215_0025
2020-11-20 12:56:49  [ main:266251 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:56:49  [ main:266251 ] - [ INFO ]  Running job: job_local1793950215_0025
2020-11-20 12:56:49  [ Thread-674:266251 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:56:49  [ Thread-674:266251 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:49  [ Thread-674:266251 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:56:49  [ Thread-674:266262 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266263 ] - [ INFO ]  Starting task: attempt_local1793950215_0025_m_000000_0
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266263 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266263 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266263 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266264 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266274 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266274 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266274 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266274 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266274 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:56:49  [ LocalJobRunner Map Task Executor #0:266275 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:56:50  [ main:267254 ] - [ INFO ]  Job job_local1793950215_0025 running in uber mode : false
2020-11-20 12:56:50  [ main:267254 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:56:55  [ communication thread:272275 ] - [ INFO ]  map > map
2020-11-20 12:56:56  [ main:273264 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:56:58  [ communication thread:275280 ] - [ INFO ]  map > map
2020-11-20 12:56:59  [ main:276269 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276304 ] - [ INFO ]  map > map
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276304 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276304 ] - [ INFO ]  Spilling map output
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276304 ] - [ INFO ]  bufstart = 0; bufend = 2332; bufvoid = 104857600
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276305 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276307 ] - [ INFO ]  Finished spill 0
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276308 ] - [ INFO ]  Task:attempt_local1793950215_0025_m_000000_0 is done. And is in the process of committing
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276321 ] - [ INFO ]  map
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276321 ] - [ INFO ]  Task 'attempt_local1793950215_0025_m_000000_0' done.
2020-11-20 12:56:59  [ LocalJobRunner Map Task Executor #0:276321 ] - [ INFO ]  Finishing task: attempt_local1793950215_0025_m_000000_0
2020-11-20 12:56:59  [ Thread-674:276321 ] - [ INFO ]  map task executor complete.
2020-11-20 12:56:59  [ Thread-674:276321 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:56:59  [ pool-78-thread-1:276321 ] - [ INFO ]  Starting task: attempt_local1793950215_0025_r_000000_0
2020-11-20 12:56:59  [ pool-78-thread-1:276322 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:56:59  [ pool-78-thread-1:276322 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:56:59  [ pool-78-thread-1:276322 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:56:59  [ pool-78-thread-1:276322 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30d07b10
2020-11-20 12:56:59  [ pool-78-thread-1:276324 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:56:59  [ EventFetcher for fetching Map Completion Events:276324 ] - [ INFO ]  attempt_local1793950215_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:56:59  [ localfetcher#25:276325 ] - [ INFO ]  localfetcher#25 about to shuffle output of map attempt_local1793950215_0025_m_000000_0 decomp: 2142 len: 2146 to MEMORY
2020-11-20 12:56:59  [ localfetcher#25:276325 ] - [ INFO ]  Read 2142 bytes from map-output for attempt_local1793950215_0025_m_000000_0
2020-11-20 12:56:59  [ localfetcher#25:276325 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2142, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2142
2020-11-20 12:56:59  [ EventFetcher for fetching Map Completion Events:276325 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:56:59  [ pool-78-thread-1:276325 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:59  [ pool-78-thread-1:276325 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:56:59  [ pool-78-thread-1:276328 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:59  [ pool-78-thread-1:276328 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2136 bytes
2020-11-20 12:56:59  [ pool-78-thread-1:276329 ] - [ INFO ]  Merged 1 segments, 2142 bytes to disk to satisfy reduce memory limit
2020-11-20 12:56:59  [ pool-78-thread-1:276329 ] - [ INFO ]  Merging 1 files, 2146 bytes from disk
2020-11-20 12:56:59  [ pool-78-thread-1:276329 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:56:59  [ pool-78-thread-1:276329 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:56:59  [ pool-78-thread-1:276329 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2136 bytes
2020-11-20 12:56:59  [ pool-78-thread-1:276329 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:59  [ pool-78-thread-1:276431 ] - [ INFO ]  Task:attempt_local1793950215_0025_r_000000_0 is done. And is in the process of committing
2020-11-20 12:56:59  [ pool-78-thread-1:276441 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:56:59  [ pool-78-thread-1:276441 ] - [ INFO ]  Task attempt_local1793950215_0025_r_000000_0 is allowed to commit now
2020-11-20 12:56:59  [ pool-78-thread-1:276474 ] - [ INFO ]  Saved output of task 'attempt_local1793950215_0025_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1793950215_0025_r_000000
2020-11-20 12:56:59  [ pool-78-thread-1:276474 ] - [ INFO ]  reduce > reduce
2020-11-20 12:56:59  [ pool-78-thread-1:276474 ] - [ INFO ]  Task 'attempt_local1793950215_0025_r_000000_0' done.
2020-11-20 12:56:59  [ pool-78-thread-1:276474 ] - [ INFO ]  Finishing task: attempt_local1793950215_0025_r_000000_0
2020-11-20 12:56:59  [ Thread-674:276474 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:57:00  [ main:277273 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:57:00  [ main:277274 ] - [ INFO ]  Job job_local1793950215_0025 completed successfully
2020-11-20 12:57:00  [ main:277276 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=217650
		FILE: Number of bytes written=15732208
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72118800
		HDFS: Number of bytes written=102629
		HDFS: Number of read operations=744
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=389
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2332
		Map output materialized bytes=2146
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2146
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=1601699840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:57:00  [ main:277296 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:57:00  [ main:277310 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:57:00  [ main:277315 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:57:00  [ main:277327 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:57:00  [ main:277371 ] - [ INFO ]  number of splits:1
2020-11-20 12:57:00  [ main:277387 ] - [ INFO ]  Submitting tokens for job: job_local187508059_0026
2020-11-20 12:57:00  [ main:277422 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:57:00  [ main:277422 ] - [ INFO ]  Running job: job_local187508059_0026
2020-11-20 12:57:00  [ Thread-702:277422 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:57:00  [ Thread-702:277422 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:00  [ Thread-702:277423 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:57:00  [ Thread-702:277434 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277434 ] - [ INFO ]  Starting task: attempt_local187508059_0026_m_000000_0
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277435 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277435 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277435 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277436 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277445 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277445 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277445 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277445 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277445 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:57:00  [ LocalJobRunner Map Task Executor #0:277445 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:57:01  [ main:278424 ] - [ INFO ]  Job job_local187508059_0026 running in uber mode : false
2020-11-20 12:57:01  [ main:278424 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:57:06  [ communication thread:283441 ] - [ INFO ]  map > map
2020-11-20 12:57:07  [ main:284435 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:57:09  [ communication thread:286447 ] - [ INFO ]  map > map
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286902 ] - [ INFO ]  map > map
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286903 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286903 ] - [ INFO ]  Spilling map output
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286903 ] - [ INFO ]  bufstart = 0; bufend = 2299; bufvoid = 104857600
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286903 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286905 ] - [ INFO ]  Finished spill 0
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286906 ] - [ INFO ]  Task:attempt_local187508059_0026_m_000000_0 is done. And is in the process of committing
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286910 ] - [ INFO ]  map
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286910 ] - [ INFO ]  Task 'attempt_local187508059_0026_m_000000_0' done.
2020-11-20 12:57:09  [ LocalJobRunner Map Task Executor #0:286910 ] - [ INFO ]  Finishing task: attempt_local187508059_0026_m_000000_0
2020-11-20 12:57:09  [ Thread-702:286910 ] - [ INFO ]  map task executor complete.
2020-11-20 12:57:09  [ Thread-702:286911 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:57:09  [ pool-81-thread-1:286911 ] - [ INFO ]  Starting task: attempt_local187508059_0026_r_000000_0
2020-11-20 12:57:09  [ pool-81-thread-1:286911 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:09  [ pool-81-thread-1:286912 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:09  [ pool-81-thread-1:286912 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:09  [ pool-81-thread-1:286912 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fea7d2e
2020-11-20 12:57:09  [ pool-81-thread-1:286913 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:57:09  [ EventFetcher for fetching Map Completion Events:286913 ] - [ INFO ]  attempt_local187508059_0026_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:57:09  [ localfetcher#26:286914 ] - [ INFO ]  localfetcher#26 about to shuffle output of map attempt_local187508059_0026_m_000000_0 decomp: 2109 len: 2113 to MEMORY
2020-11-20 12:57:09  [ localfetcher#26:286914 ] - [ INFO ]  Read 2109 bytes from map-output for attempt_local187508059_0026_m_000000_0
2020-11-20 12:57:09  [ localfetcher#26:286914 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2109, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2109
2020-11-20 12:57:09  [ EventFetcher for fetching Map Completion Events:286914 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:57:09  [ pool-81-thread-1:286914 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:09  [ pool-81-thread-1:286914 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:57:09  [ pool-81-thread-1:286915 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:09  [ pool-81-thread-1:286915 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2103 bytes
2020-11-20 12:57:09  [ pool-81-thread-1:286916 ] - [ INFO ]  Merged 1 segments, 2109 bytes to disk to satisfy reduce memory limit
2020-11-20 12:57:09  [ pool-81-thread-1:286916 ] - [ INFO ]  Merging 1 files, 2113 bytes from disk
2020-11-20 12:57:09  [ pool-81-thread-1:286916 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:57:09  [ pool-81-thread-1:286916 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:09  [ pool-81-thread-1:286916 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2103 bytes
2020-11-20 12:57:09  [ pool-81-thread-1:286916 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:10  [ pool-81-thread-1:287007 ] - [ INFO ]  Task:attempt_local187508059_0026_r_000000_0 is done. And is in the process of committing
2020-11-20 12:57:10  [ pool-81-thread-1:287013 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:10  [ pool-81-thread-1:287013 ] - [ INFO ]  Task attempt_local187508059_0026_r_000000_0 is allowed to commit now
2020-11-20 12:57:10  [ pool-81-thread-1:287031 ] - [ INFO ]  Saved output of task 'attempt_local187508059_0026_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local187508059_0026_r_000000
2020-11-20 12:57:10  [ pool-81-thread-1:287031 ] - [ INFO ]  reduce > reduce
2020-11-20 12:57:10  [ pool-81-thread-1:287032 ] - [ INFO ]  Task 'attempt_local187508059_0026_r_000000_0' done.
2020-11-20 12:57:10  [ pool-81-thread-1:287032 ] - [ INFO ]  Finishing task: attempt_local187508059_0026_r_000000_0
2020-11-20 12:57:10  [ Thread-702:287032 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:57:10  [ main:287446 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:57:10  [ main:287447 ] - [ INFO ]  Job job_local187508059_0026 completed successfully
2020-11-20 12:57:10  [ main:287449 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=226614
		FILE: Number of bytes written=16316479
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=74892600
		HDFS: Number of bytes written=106862
		HDFS: Number of read operations=774
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=405
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2299
		Map output materialized bytes=2113
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2113
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=1614807040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:57:10  [ main:287479 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:57:10  [ main:287492 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:57:10  [ main:287496 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:57:10  [ main:287502 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:57:10  [ main:287540 ] - [ INFO ]  number of splits:1
2020-11-20 12:57:10  [ main:287557 ] - [ INFO ]  Submitting tokens for job: job_local473011020_0027
2020-11-20 12:57:10  [ main:287592 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:57:10  [ main:287592 ] - [ INFO ]  Running job: job_local473011020_0027
2020-11-20 12:57:10  [ Thread-729:287592 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:57:10  [ Thread-729:287592 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:10  [ Thread-729:287592 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:57:10  [ Thread-729:287606 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287606 ] - [ INFO ]  Starting task: attempt_local473011020_0027_m_000000_0
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287606 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287606 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287606 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287607 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287614 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287614 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287614 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287614 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287614 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:57:10  [ LocalJobRunner Map Task Executor #0:287615 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:57:11  [ main:288596 ] - [ INFO ]  Job job_local473011020_0027 running in uber mode : false
2020-11-20 12:57:11  [ main:288597 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:57:16  [ communication thread:293611 ] - [ INFO ]  map > map
2020-11-20 12:57:17  [ main:294612 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:57:19  [ communication thread:296615 ] - [ INFO ]  map > map
2020-11-20 12:57:19  [ main:296618 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297631 ] - [ INFO ]  map > map
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297631 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297631 ] - [ INFO ]  Spilling map output
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297631 ] - [ INFO ]  bufstart = 0; bufend = 2304; bufvoid = 104857600
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297631 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297633 ] - [ INFO ]  Finished spill 0
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297634 ] - [ INFO ]  Task:attempt_local473011020_0027_m_000000_0 is done. And is in the process of committing
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297647 ] - [ INFO ]  map
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297647 ] - [ INFO ]  Task 'attempt_local473011020_0027_m_000000_0' done.
2020-11-20 12:57:20  [ LocalJobRunner Map Task Executor #0:297647 ] - [ INFO ]  Finishing task: attempt_local473011020_0027_m_000000_0
2020-11-20 12:57:20  [ Thread-729:297647 ] - [ INFO ]  map task executor complete.
2020-11-20 12:57:20  [ Thread-729:297647 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:57:20  [ pool-84-thread-1:297648 ] - [ INFO ]  Starting task: attempt_local473011020_0027_r_000000_0
2020-11-20 12:57:20  [ pool-84-thread-1:297648 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:20  [ pool-84-thread-1:297648 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:20  [ pool-84-thread-1:297648 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:20  [ pool-84-thread-1:297648 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51ba303f
2020-11-20 12:57:20  [ pool-84-thread-1:297650 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:57:20  [ EventFetcher for fetching Map Completion Events:297650 ] - [ INFO ]  attempt_local473011020_0027_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:57:20  [ localfetcher#27:297651 ] - [ INFO ]  localfetcher#27 about to shuffle output of map attempt_local473011020_0027_m_000000_0 decomp: 2114 len: 2118 to MEMORY
2020-11-20 12:57:20  [ localfetcher#27:297651 ] - [ INFO ]  Read 2114 bytes from map-output for attempt_local473011020_0027_m_000000_0
2020-11-20 12:57:20  [ localfetcher#27:297651 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2114, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2114
2020-11-20 12:57:20  [ EventFetcher for fetching Map Completion Events:297651 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:57:20  [ pool-84-thread-1:297651 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:20  [ pool-84-thread-1:297651 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:57:20  [ pool-84-thread-1:297652 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:20  [ pool-84-thread-1:297652 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 12:57:20  [ pool-84-thread-1:297652 ] - [ INFO ]  Merged 1 segments, 2114 bytes to disk to satisfy reduce memory limit
2020-11-20 12:57:20  [ pool-84-thread-1:297653 ] - [ INFO ]  Merging 1 files, 2118 bytes from disk
2020-11-20 12:57:20  [ pool-84-thread-1:297653 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:57:20  [ pool-84-thread-1:297653 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:20  [ pool-84-thread-1:297653 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 12:57:20  [ pool-84-thread-1:297653 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:20  [ pool-84-thread-1:297734 ] - [ INFO ]  Task:attempt_local473011020_0027_r_000000_0 is done. And is in the process of committing
2020-11-20 12:57:20  [ pool-84-thread-1:297740 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:20  [ pool-84-thread-1:297740 ] - [ INFO ]  Task attempt_local473011020_0027_r_000000_0 is allowed to commit now
2020-11-20 12:57:20  [ pool-84-thread-1:297761 ] - [ INFO ]  Saved output of task 'attempt_local473011020_0027_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local473011020_0027_r_000000
2020-11-20 12:57:20  [ pool-84-thread-1:297761 ] - [ INFO ]  reduce > reduce
2020-11-20 12:57:20  [ pool-84-thread-1:297761 ] - [ INFO ]  Task 'attempt_local473011020_0027_r_000000_0' done.
2020-11-20 12:57:20  [ pool-84-thread-1:297761 ] - [ INFO ]  Finishing task: attempt_local473011020_0027_r_000000_0
2020-11-20 12:57:20  [ Thread-729:297762 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:57:21  [ main:298624 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:57:21  [ main:298625 ] - [ INFO ]  Job job_local473011020_0027 completed successfully
2020-11-20 12:57:21  [ main:298627 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=235522
		FILE: Number of bytes written=16904072
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=77666400
		HDFS: Number of bytes written=111067
		HDFS: Number of read operations=804
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=421
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2304
		Map output materialized bytes=2118
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2118
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=1654652928
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:57:21  [ main:298646 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:57:21  [ main:298657 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:57:21  [ main:298662 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:57:21  [ main:298668 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:57:21  [ main:298708 ] - [ INFO ]  number of splits:1
2020-11-20 12:57:21  [ main:298725 ] - [ INFO ]  Submitting tokens for job: job_local27748927_0028
2020-11-20 12:57:21  [ main:298759 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:57:21  [ main:298759 ] - [ INFO ]  Running job: job_local27748927_0028
2020-11-20 12:57:21  [ Thread-757:298759 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:57:21  [ Thread-757:298759 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:21  [ Thread-757:298760 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:57:21  [ Thread-757:298767 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298767 ] - [ INFO ]  Starting task: attempt_local27748927_0028_m_000000_0
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298767 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298767 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298767 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298768 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298775 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298775 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298775 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298775 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298775 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:57:21  [ LocalJobRunner Map Task Executor #0:298776 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:57:22  [ main:299763 ] - [ INFO ]  Job job_local27748927_0028 running in uber mode : false
2020-11-20 12:57:22  [ main:299763 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:57:27  [ communication thread:304773 ] - [ INFO ]  map > map
2020-11-20 12:57:27  [ main:304774 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:57:30  [ communication thread:307775 ] - [ INFO ]  map > map
2020-11-20 12:57:30  [ main:307783 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308375 ] - [ INFO ]  map > map
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308375 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308375 ] - [ INFO ]  Spilling map output
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308375 ] - [ INFO ]  bufstart = 0; bufend = 2250; bufvoid = 104857600
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308375 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308377 ] - [ INFO ]  Finished spill 0
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308378 ] - [ INFO ]  Task:attempt_local27748927_0028_m_000000_0 is done. And is in the process of committing
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308384 ] - [ INFO ]  map
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308384 ] - [ INFO ]  Task 'attempt_local27748927_0028_m_000000_0' done.
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308384 ] - [ INFO ]  Finishing task: attempt_local27748927_0028_m_000000_0
2020-11-20 12:57:31  [ Thread-757:308385 ] - [ INFO ]  map task executor complete.
2020-11-20 12:57:31  [ Thread-757:308385 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:57:31  [ pool-87-thread-1:308385 ] - [ INFO ]  Starting task: attempt_local27748927_0028_r_000000_0
2020-11-20 12:57:31  [ pool-87-thread-1:308386 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:31  [ pool-87-thread-1:308386 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:31  [ pool-87-thread-1:308386 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:31  [ pool-87-thread-1:308386 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5ece4ef7
2020-11-20 12:57:31  [ pool-87-thread-1:308387 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:57:31  [ EventFetcher for fetching Map Completion Events:308387 ] - [ INFO ]  attempt_local27748927_0028_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:57:31  [ localfetcher#28:308388 ] - [ INFO ]  localfetcher#28 about to shuffle output of map attempt_local27748927_0028_m_000000_0 decomp: 2060 len: 2064 to MEMORY
2020-11-20 12:57:31  [ localfetcher#28:308388 ] - [ INFO ]  Read 2060 bytes from map-output for attempt_local27748927_0028_m_000000_0
2020-11-20 12:57:31  [ localfetcher#28:308388 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2060, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2060
2020-11-20 12:57:31  [ EventFetcher for fetching Map Completion Events:308388 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:57:31  [ pool-87-thread-1:308388 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:31  [ pool-87-thread-1:308388 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:57:31  [ pool-87-thread-1:308389 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:31  [ pool-87-thread-1:308389 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2054 bytes
2020-11-20 12:57:31  [ pool-87-thread-1:308390 ] - [ INFO ]  Merged 1 segments, 2060 bytes to disk to satisfy reduce memory limit
2020-11-20 12:57:31  [ pool-87-thread-1:308390 ] - [ INFO ]  Merging 1 files, 2064 bytes from disk
2020-11-20 12:57:31  [ pool-87-thread-1:308390 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:57:31  [ pool-87-thread-1:308390 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:31  [ pool-87-thread-1:308390 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2054 bytes
2020-11-20 12:57:31  [ pool-87-thread-1:308390 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:31  [ pool-87-thread-1:308503 ] - [ INFO ]  Task:attempt_local27748927_0028_r_000000_0 is done. And is in the process of committing
2020-11-20 12:57:31  [ pool-87-thread-1:308508 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:31  [ pool-87-thread-1:308508 ] - [ INFO ]  Task attempt_local27748927_0028_r_000000_0 is allowed to commit now
2020-11-20 12:57:31  [ pool-87-thread-1:308526 ] - [ INFO ]  Saved output of task 'attempt_local27748927_0028_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local27748927_0028_r_000000
2020-11-20 12:57:31  [ pool-87-thread-1:308527 ] - [ INFO ]  reduce > reduce
2020-11-20 12:57:31  [ pool-87-thread-1:308527 ] - [ INFO ]  Task 'attempt_local27748927_0028_r_000000_0' done.
2020-11-20 12:57:31  [ pool-87-thread-1:308527 ] - [ INFO ]  Finishing task: attempt_local27748927_0028_r_000000_0
2020-11-20 12:57:31  [ Thread-757:308528 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:57:31  [ main:308785 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:57:31  [ main:308785 ] - [ INFO ]  Job job_local27748927_0028 completed successfully
2020-11-20 12:57:31  [ main:308786 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=244332
		FILE: Number of bytes written=17492208
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=80440200
		HDFS: Number of bytes written=115223
		HDFS: Number of read operations=834
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=437
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2250
		Map output materialized bytes=2064
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2064
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1645215744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:57:31  [ main:308805 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:57:31  [ main:308816 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:57:31  [ main:308820 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:57:31  [ main:308825 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:57:31  [ main:308860 ] - [ INFO ]  number of splits:1
2020-11-20 12:57:31  [ main:308877 ] - [ INFO ]  Submitting tokens for job: job_local1897636798_0029
2020-11-20 12:57:31  [ main:308910 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:57:31  [ main:308910 ] - [ INFO ]  Running job: job_local1897636798_0029
2020-11-20 12:57:31  [ Thread-784:308910 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:57:31  [ Thread-784:308911 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:31  [ Thread-784:308911 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:57:31  [ Thread-784:308918 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308918 ] - [ INFO ]  Starting task: attempt_local1897636798_0029_m_000000_0
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308919 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308919 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308919 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308919 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308927 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308927 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308927 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308927 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308927 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:57:31  [ LocalJobRunner Map Task Executor #0:308927 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:57:32  [ main:309911 ] - [ INFO ]  Job job_local1897636798_0029 running in uber mode : false
2020-11-20 12:57:32  [ main:309911 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:57:37  [ communication thread:314924 ] - [ INFO ]  map > map
2020-11-20 12:57:38  [ main:315924 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:57:40  [ communication thread:317927 ] - [ INFO ]  map > map
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318911 ] - [ INFO ]  map > map
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318911 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318911 ] - [ INFO ]  Spilling map output
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318911 ] - [ INFO ]  bufstart = 0; bufend = 2304; bufvoid = 104857600
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318911 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318913 ] - [ INFO ]  Finished spill 0
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318915 ] - [ INFO ]  Task:attempt_local1897636798_0029_m_000000_0 is done. And is in the process of committing
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318924 ] - [ INFO ]  map
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318924 ] - [ INFO ]  Task 'attempt_local1897636798_0029_m_000000_0' done.
2020-11-20 12:57:41  [ LocalJobRunner Map Task Executor #0:318924 ] - [ INFO ]  Finishing task: attempt_local1897636798_0029_m_000000_0
2020-11-20 12:57:41  [ Thread-784:318925 ] - [ INFO ]  map task executor complete.
2020-11-20 12:57:41  [ Thread-784:318925 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:57:41  [ pool-90-thread-1:318925 ] - [ INFO ]  Starting task: attempt_local1897636798_0029_r_000000_0
2020-11-20 12:57:41  [ pool-90-thread-1:318926 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:41  [ pool-90-thread-1:318926 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:41  [ pool-90-thread-1:318926 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:41  [ pool-90-thread-1:318926 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55c15779
2020-11-20 12:57:41  [ pool-90-thread-1:318928 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:57:41  [ EventFetcher for fetching Map Completion Events:318928 ] - [ INFO ]  attempt_local1897636798_0029_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:57:41  [ localfetcher#29:318929 ] - [ INFO ]  localfetcher#29 about to shuffle output of map attempt_local1897636798_0029_m_000000_0 decomp: 2114 len: 2118 to MEMORY
2020-11-20 12:57:41  [ localfetcher#29:318929 ] - [ INFO ]  Read 2114 bytes from map-output for attempt_local1897636798_0029_m_000000_0
2020-11-20 12:57:41  [ localfetcher#29:318929 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2114, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2114
2020-11-20 12:57:41  [ EventFetcher for fetching Map Completion Events:318929 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:57:41  [ pool-90-thread-1:318930 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:41  [ main:318930 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:57:41  [ pool-90-thread-1:318930 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Merged 1 segments, 2114 bytes to disk to satisfy reduce memory limit
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Merging 1 files, 2118 bytes from disk
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:41  [ pool-90-thread-1:318931 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 12:57:41  [ pool-90-thread-1:318932 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:42  [ pool-90-thread-1:319037 ] - [ INFO ]  Task:attempt_local1897636798_0029_r_000000_0 is done. And is in the process of committing
2020-11-20 12:57:42  [ pool-90-thread-1:319043 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:42  [ pool-90-thread-1:319043 ] - [ INFO ]  Task attempt_local1897636798_0029_r_000000_0 is allowed to commit now
2020-11-20 12:57:42  [ pool-90-thread-1:319078 ] - [ INFO ]  Saved output of task 'attempt_local1897636798_0029_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1897636798_0029_r_000000
2020-11-20 12:57:42  [ pool-90-thread-1:319078 ] - [ INFO ]  reduce > reduce
2020-11-20 12:57:42  [ pool-90-thread-1:319078 ] - [ INFO ]  Task 'attempt_local1897636798_0029_r_000000_0' done.
2020-11-20 12:57:42  [ pool-90-thread-1:319078 ] - [ INFO ]  Finishing task: attempt_local1897636798_0029_r_000000_0
2020-11-20 12:57:42  [ Thread-784:319079 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:57:42  [ main:319932 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:57:42  [ main:319932 ] - [ INFO ]  Job job_local1897636798_0029 completed successfully
2020-11-20 12:57:42  [ main:319935 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=253142
		FILE: Number of bytes written=18093744
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=83214000
		HDFS: Number of bytes written=119379
		HDFS: Number of read operations=864
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=453
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2304
		Map output materialized bytes=2118
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2118
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=31
		Total committed heap usage (bytes)=1586495488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:57:42  [ main:319991 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:57:43  [ main:320011 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:57:43  [ main:320016 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:57:43  [ main:320027 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:57:43  [ main:320074 ] - [ INFO ]  number of splits:1
2020-11-20 12:57:43  [ main:320091 ] - [ INFO ]  Submitting tokens for job: job_local1331029323_0030
2020-11-20 12:57:43  [ main:320125 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:57:43  [ main:320125 ] - [ INFO ]  Running job: job_local1331029323_0030
2020-11-20 12:57:43  [ Thread-811:320125 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:57:43  [ Thread-811:320125 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:43  [ Thread-811:320125 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:57:43  [ Thread-811:320132 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320132 ] - [ INFO ]  Starting task: attempt_local1331029323_0030_m_000000_0
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320133 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320133 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320133 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320133 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320142 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320142 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320142 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320142 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320142 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:57:43  [ LocalJobRunner Map Task Executor #0:320142 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:57:44  [ main:321130 ] - [ INFO ]  Job job_local1331029323_0030 running in uber mode : false
2020-11-20 12:57:44  [ main:321130 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:57:49  [ communication thread:326135 ] - [ INFO ]  map > map
2020-11-20 12:57:49  [ main:326143 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:57:52  [ communication thread:329140 ] - [ INFO ]  map > map
2020-11-20 12:57:52  [ main:329148 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329787 ] - [ INFO ]  map > map
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329787 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329787 ] - [ INFO ]  Spilling map output
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329787 ] - [ INFO ]  bufstart = 0; bufend = 2328; bufvoid = 104857600
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329787 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329789 ] - [ INFO ]  Finished spill 0
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329790 ] - [ INFO ]  Task:attempt_local1331029323_0030_m_000000_0 is done. And is in the process of committing
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329797 ] - [ INFO ]  map
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329797 ] - [ INFO ]  Task 'attempt_local1331029323_0030_m_000000_0' done.
2020-11-20 12:57:52  [ LocalJobRunner Map Task Executor #0:329797 ] - [ INFO ]  Finishing task: attempt_local1331029323_0030_m_000000_0
2020-11-20 12:57:52  [ Thread-811:329797 ] - [ INFO ]  map task executor complete.
2020-11-20 12:57:52  [ Thread-811:329798 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:57:52  [ pool-93-thread-1:329798 ] - [ INFO ]  Starting task: attempt_local1331029323_0030_r_000000_0
2020-11-20 12:57:52  [ pool-93-thread-1:329799 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:52  [ pool-93-thread-1:329799 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:52  [ pool-93-thread-1:329799 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:52  [ pool-93-thread-1:329799 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e921091
2020-11-20 12:57:52  [ pool-93-thread-1:329800 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:57:52  [ EventFetcher for fetching Map Completion Events:329800 ] - [ INFO ]  attempt_local1331029323_0030_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:57:52  [ localfetcher#30:329801 ] - [ INFO ]  localfetcher#30 about to shuffle output of map attempt_local1331029323_0030_m_000000_0 decomp: 2138 len: 2142 to MEMORY
2020-11-20 12:57:52  [ localfetcher#30:329802 ] - [ INFO ]  Read 2138 bytes from map-output for attempt_local1331029323_0030_m_000000_0
2020-11-20 12:57:52  [ localfetcher#30:329802 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2138, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2138
2020-11-20 12:57:52  [ EventFetcher for fetching Map Completion Events:329802 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:57:52  [ pool-93-thread-1:329802 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:52  [ pool-93-thread-1:329802 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:57:52  [ pool-93-thread-1:329803 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:52  [ pool-93-thread-1:329803 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2132 bytes
2020-11-20 12:57:52  [ pool-93-thread-1:329804 ] - [ INFO ]  Merged 1 segments, 2138 bytes to disk to satisfy reduce memory limit
2020-11-20 12:57:52  [ pool-93-thread-1:329804 ] - [ INFO ]  Merging 1 files, 2142 bytes from disk
2020-11-20 12:57:52  [ pool-93-thread-1:329804 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:57:52  [ pool-93-thread-1:329804 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:57:52  [ pool-93-thread-1:329804 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2132 bytes
2020-11-20 12:57:52  [ pool-93-thread-1:329804 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:52  [ pool-93-thread-1:329897 ] - [ INFO ]  Task:attempt_local1331029323_0030_r_000000_0 is done. And is in the process of committing
2020-11-20 12:57:52  [ pool-93-thread-1:329903 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:57:52  [ pool-93-thread-1:329903 ] - [ INFO ]  Task attempt_local1331029323_0030_r_000000_0 is allowed to commit now
2020-11-20 12:57:52  [ pool-93-thread-1:329928 ] - [ INFO ]  Saved output of task 'attempt_local1331029323_0030_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1331029323_0030_r_000000
2020-11-20 12:57:52  [ pool-93-thread-1:329929 ] - [ INFO ]  reduce > reduce
2020-11-20 12:57:52  [ pool-93-thread-1:329929 ] - [ INFO ]  Task 'attempt_local1331029323_0030_r_000000_0' done.
2020-11-20 12:57:52  [ pool-93-thread-1:329929 ] - [ INFO ]  Finishing task: attempt_local1331029323_0030_r_000000_0
2020-11-20 12:57:52  [ Thread-811:329930 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:57:53  [ main:330149 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:57:53  [ main:330149 ] - [ INFO ]  Job job_local1331029323_0030 completed successfully
2020-11-20 12:57:53  [ main:330151 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=262108
		FILE: Number of bytes written=18695858
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=85987800
		HDFS: Number of bytes written=123613
		HDFS: Number of read operations=894
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=469
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2328
		Map output materialized bytes=2142
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2142
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=1628438528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:57:53  [ main:330170 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:57:53  [ main:330182 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:57:53  [ main:330186 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:57:53  [ main:330192 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:57:53  [ main:330229 ] - [ INFO ]  number of splits:1
2020-11-20 12:57:53  [ main:330245 ] - [ INFO ]  Submitting tokens for job: job_local1514518015_0031
2020-11-20 12:57:53  [ main:330279 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:57:53  [ main:330280 ] - [ INFO ]  Running job: job_local1514518015_0031
2020-11-20 12:57:53  [ Thread-838:330280 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:57:53  [ Thread-838:330280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:53  [ Thread-838:330280 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:57:53  [ Thread-838:330289 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330290 ] - [ INFO ]  Starting task: attempt_local1514518015_0031_m_000000_0
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330290 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330291 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330291 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330291 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330300 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330300 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330300 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330300 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330300 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:57:53  [ LocalJobRunner Map Task Executor #0:330300 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:57:54  [ main:331284 ] - [ INFO ]  Job job_local1514518015_0031 running in uber mode : false
2020-11-20 12:57:54  [ main:331284 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:57:59  [ communication thread:336298 ] - [ INFO ]  map > map
2020-11-20 12:57:59  [ main:336301 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:58:02  [ communication thread:339303 ] - [ INFO ]  map > map
2020-11-20 12:58:02  [ main:339313 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339995 ] - [ INFO ]  map > map
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339995 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339995 ] - [ INFO ]  Spilling map output
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339995 ] - [ INFO ]  bufstart = 0; bufend = 2322; bufvoid = 104857600
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339995 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339997 ] - [ INFO ]  Finished spill 0
2020-11-20 12:58:02  [ LocalJobRunner Map Task Executor #0:339998 ] - [ INFO ]  Task:attempt_local1514518015_0031_m_000000_0 is done. And is in the process of committing
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340007 ] - [ INFO ]  map
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340007 ] - [ INFO ]  Task 'attempt_local1514518015_0031_m_000000_0' done.
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340007 ] - [ INFO ]  Finishing task: attempt_local1514518015_0031_m_000000_0
2020-11-20 12:58:03  [ Thread-838:340008 ] - [ INFO ]  map task executor complete.
2020-11-20 12:58:03  [ Thread-838:340008 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:58:03  [ pool-96-thread-1:340008 ] - [ INFO ]  Starting task: attempt_local1514518015_0031_r_000000_0
2020-11-20 12:58:03  [ pool-96-thread-1:340009 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:03  [ pool-96-thread-1:340009 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:03  [ pool-96-thread-1:340009 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:03  [ pool-96-thread-1:340009 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1cb8221b
2020-11-20 12:58:03  [ pool-96-thread-1:340010 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:58:03  [ EventFetcher for fetching Map Completion Events:340010 ] - [ INFO ]  attempt_local1514518015_0031_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:58:03  [ localfetcher#31:340011 ] - [ INFO ]  localfetcher#31 about to shuffle output of map attempt_local1514518015_0031_m_000000_0 decomp: 2132 len: 2136 to MEMORY
2020-11-20 12:58:03  [ localfetcher#31:340011 ] - [ INFO ]  Read 2132 bytes from map-output for attempt_local1514518015_0031_m_000000_0
2020-11-20 12:58:03  [ localfetcher#31:340011 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2132
2020-11-20 12:58:03  [ EventFetcher for fetching Map Completion Events:340011 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:58:03  [ pool-96-thread-1:340012 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:03  [ pool-96-thread-1:340012 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:58:03  [ pool-96-thread-1:340012 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:03  [ pool-96-thread-1:340012 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2126 bytes
2020-11-20 12:58:03  [ pool-96-thread-1:340013 ] - [ INFO ]  Merged 1 segments, 2132 bytes to disk to satisfy reduce memory limit
2020-11-20 12:58:03  [ pool-96-thread-1:340013 ] - [ INFO ]  Merging 1 files, 2136 bytes from disk
2020-11-20 12:58:03  [ pool-96-thread-1:340013 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:58:03  [ pool-96-thread-1:340013 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:03  [ pool-96-thread-1:340013 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2126 bytes
2020-11-20 12:58:03  [ pool-96-thread-1:340013 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:03  [ pool-96-thread-1:340130 ] - [ INFO ]  Task:attempt_local1514518015_0031_r_000000_0 is done. And is in the process of committing
2020-11-20 12:58:03  [ pool-96-thread-1:340141 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:03  [ pool-96-thread-1:340141 ] - [ INFO ]  Task attempt_local1514518015_0031_r_000000_0 is allowed to commit now
2020-11-20 12:58:03  [ pool-96-thread-1:340167 ] - [ INFO ]  Saved output of task 'attempt_local1514518015_0031_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1514518015_0031_r_000000
2020-11-20 12:58:03  [ pool-96-thread-1:340167 ] - [ INFO ]  reduce > reduce
2020-11-20 12:58:03  [ pool-96-thread-1:340167 ] - [ INFO ]  Task 'attempt_local1514518015_0031_r_000000_0' done.
2020-11-20 12:58:03  [ pool-96-thread-1:340167 ] - [ INFO ]  Finishing task: attempt_local1514518015_0031_r_000000_0
2020-11-20 12:58:03  [ Thread-838:340167 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:58:03  [ main:340316 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:58:03  [ main:340317 ] - [ INFO ]  Job job_local1514518015_0031 completed successfully
2020-11-20 12:58:03  [ main:340319 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=271110
		FILE: Number of bytes written=19298098
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=88761600
		HDFS: Number of bytes written=127865
		HDFS: Number of read operations=924
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=485
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2322
		Map output materialized bytes=2136
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2136
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1620049920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:58:03  [ main:340344 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:58:03  [ main:340355 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:58:03  [ main:340359 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:58:03  [ main:340366 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:58:03  [ main:340404 ] - [ INFO ]  number of splits:1
2020-11-20 12:58:03  [ main:340420 ] - [ INFO ]  Submitting tokens for job: job_local1665540923_0032
2020-11-20 12:58:03  [ main:340454 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:58:03  [ main:340454 ] - [ INFO ]  Running job: job_local1665540923_0032
2020-11-20 12:58:03  [ Thread-865:340454 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:58:03  [ Thread-865:340454 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:03  [ Thread-865:340454 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:58:03  [ Thread-865:340463 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340463 ] - [ INFO ]  Starting task: attempt_local1665540923_0032_m_000000_0
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340464 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340464 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340464 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340465 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340472 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340472 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340472 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340472 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340472 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:58:03  [ LocalJobRunner Map Task Executor #0:340472 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:58:04  [ main:341455 ] - [ INFO ]  Job job_local1665540923_0032 running in uber mode : false
2020-11-20 12:58:04  [ main:341455 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:58:09  [ communication thread:346472 ] - [ INFO ]  map > map
2020-11-20 12:58:10  [ main:347477 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 12:58:12  [ communication thread:349475 ] - [ INFO ]  map > map
2020-11-20 12:58:12  [ main:349484 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350617 ] - [ INFO ]  map > map
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350618 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350618 ] - [ INFO ]  Spilling map output
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350618 ] - [ INFO ]  bufstart = 0; bufend = 2427; bufvoid = 104857600
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350618 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350620 ] - [ INFO ]  Finished spill 0
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350621 ] - [ INFO ]  Task:attempt_local1665540923_0032_m_000000_0 is done. And is in the process of committing
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350633 ] - [ INFO ]  map
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350633 ] - [ INFO ]  Task 'attempt_local1665540923_0032_m_000000_0' done.
2020-11-20 12:58:13  [ LocalJobRunner Map Task Executor #0:350633 ] - [ INFO ]  Finishing task: attempt_local1665540923_0032_m_000000_0
2020-11-20 12:58:13  [ Thread-865:350633 ] - [ INFO ]  map task executor complete.
2020-11-20 12:58:13  [ Thread-865:350634 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:58:13  [ pool-99-thread-1:350634 ] - [ INFO ]  Starting task: attempt_local1665540923_0032_r_000000_0
2020-11-20 12:58:13  [ pool-99-thread-1:350634 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:13  [ pool-99-thread-1:350634 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:13  [ pool-99-thread-1:350634 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:13  [ pool-99-thread-1:350635 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b28462e
2020-11-20 12:58:13  [ pool-99-thread-1:350636 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:58:13  [ EventFetcher for fetching Map Completion Events:350636 ] - [ INFO ]  attempt_local1665540923_0032_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:58:13  [ localfetcher#32:350637 ] - [ INFO ]  localfetcher#32 about to shuffle output of map attempt_local1665540923_0032_m_000000_0 decomp: 2138 len: 2142 to MEMORY
2020-11-20 12:58:13  [ localfetcher#32:350637 ] - [ INFO ]  Read 2138 bytes from map-output for attempt_local1665540923_0032_m_000000_0
2020-11-20 12:58:13  [ localfetcher#32:350637 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2138, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2138
2020-11-20 12:58:13  [ EventFetcher for fetching Map Completion Events:350637 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:58:13  [ pool-99-thread-1:350637 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:13  [ pool-99-thread-1:350637 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:58:13  [ pool-99-thread-1:350638 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:13  [ pool-99-thread-1:350638 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2131 bytes
2020-11-20 12:58:13  [ pool-99-thread-1:350639 ] - [ INFO ]  Merged 1 segments, 2138 bytes to disk to satisfy reduce memory limit
2020-11-20 12:58:13  [ pool-99-thread-1:350639 ] - [ INFO ]  Merging 1 files, 2142 bytes from disk
2020-11-20 12:58:13  [ pool-99-thread-1:350639 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:58:13  [ pool-99-thread-1:350639 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:13  [ pool-99-thread-1:350639 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2131 bytes
2020-11-20 12:58:13  [ pool-99-thread-1:350639 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:13  [ pool-99-thread-1:350727 ] - [ INFO ]  Task:attempt_local1665540923_0032_r_000000_0 is done. And is in the process of committing
2020-11-20 12:58:13  [ pool-99-thread-1:350734 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:13  [ pool-99-thread-1:350734 ] - [ INFO ]  Task attempt_local1665540923_0032_r_000000_0 is allowed to commit now
2020-11-20 12:58:13  [ pool-99-thread-1:350754 ] - [ INFO ]  Saved output of task 'attempt_local1665540923_0032_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1665540923_0032_r_000000
2020-11-20 12:58:13  [ pool-99-thread-1:350755 ] - [ INFO ]  reduce > reduce
2020-11-20 12:58:13  [ pool-99-thread-1:350755 ] - [ INFO ]  Task 'attempt_local1665540923_0032_r_000000_0' done.
2020-11-20 12:58:13  [ pool-99-thread-1:350755 ] - [ INFO ]  Finishing task: attempt_local1665540923_0032_r_000000_0
2020-11-20 12:58:13  [ Thread-865:350755 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:58:14  [ main:351494 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:58:14  [ main:351494 ] - [ INFO ]  Job job_local1665540923_0032 completed successfully
2020-11-20 12:58:14  [ main:351496 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=280112
		FILE: Number of bytes written=19920362
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=91535400
		HDFS: Number of bytes written=132117
		HDFS: Number of read operations=954
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=501
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2427
		Map output materialized bytes=2142
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2142
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=1557135360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:58:14  [ main:351517 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:58:14  [ main:351530 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:58:14  [ main:351535 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:58:14  [ main:351540 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:58:14  [ main:351578 ] - [ INFO ]  number of splits:1
2020-11-20 12:58:14  [ main:351595 ] - [ INFO ]  Submitting tokens for job: job_local27917522_0033
2020-11-20 12:58:14  [ main:351629 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:58:14  [ main:351629 ] - [ INFO ]  Running job: job_local27917522_0033
2020-11-20 12:58:14  [ Thread-893:351629 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:58:14  [ Thread-893:351629 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:14  [ Thread-893:351629 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:58:14  [ Thread-893:351637 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351637 ] - [ INFO ]  Starting task: attempt_local27917522_0033_m_000000_0
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351637 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351637 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351637 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351638 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351646 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351646 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351646 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351646 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351646 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:58:14  [ LocalJobRunner Map Task Executor #0:351646 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:58:15  [ main:352632 ] - [ INFO ]  Job job_local27917522_0033 running in uber mode : false
2020-11-20 12:58:15  [ main:352632 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:58:20  [ communication thread:357648 ] - [ INFO ]  map > map
2020-11-20 12:58:21  [ main:358651 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 12:58:23  [ communication thread:360651 ] - [ INFO ]  map > map
2020-11-20 12:58:23  [ main:360658 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360991 ] - [ INFO ]  map > map
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360991 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360991 ] - [ INFO ]  Spilling map output
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360991 ] - [ INFO ]  bufstart = 0; bufend = 2413; bufvoid = 104857600
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360991 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360993 ] - [ INFO ]  Finished spill 0
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360994 ] - [ INFO ]  Task:attempt_local27917522_0033_m_000000_0 is done. And is in the process of committing
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360999 ] - [ INFO ]  map
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360999 ] - [ INFO ]  Task 'attempt_local27917522_0033_m_000000_0' done.
2020-11-20 12:58:23  [ LocalJobRunner Map Task Executor #0:360999 ] - [ INFO ]  Finishing task: attempt_local27917522_0033_m_000000_0
2020-11-20 12:58:23  [ Thread-893:360999 ] - [ INFO ]  map task executor complete.
2020-11-20 12:58:23  [ Thread-893:360999 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:58:23  [ pool-102-thread-1:361000 ] - [ INFO ]  Starting task: attempt_local27917522_0033_r_000000_0
2020-11-20 12:58:23  [ pool-102-thread-1:361000 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:23  [ pool-102-thread-1:361000 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:23  [ pool-102-thread-1:361000 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:23  [ pool-102-thread-1:361000 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21c4a830
2020-11-20 12:58:24  [ pool-102-thread-1:361001 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:58:24  [ EventFetcher for fetching Map Completion Events:361002 ] - [ INFO ]  attempt_local27917522_0033_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:58:24  [ localfetcher#33:361002 ] - [ INFO ]  localfetcher#33 about to shuffle output of map attempt_local27917522_0033_m_000000_0 decomp: 2124 len: 2128 to MEMORY
2020-11-20 12:58:24  [ localfetcher#33:361002 ] - [ INFO ]  Read 2124 bytes from map-output for attempt_local27917522_0033_m_000000_0
2020-11-20 12:58:24  [ localfetcher#33:361002 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2124, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2124
2020-11-20 12:58:24  [ EventFetcher for fetching Map Completion Events:361003 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:58:24  [ pool-102-thread-1:361003 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:24  [ pool-102-thread-1:361003 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2117 bytes
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Merged 1 segments, 2124 bytes to disk to satisfy reduce memory limit
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Merging 1 files, 2128 bytes from disk
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:24  [ pool-102-thread-1:361004 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2117 bytes
2020-11-20 12:58:24  [ pool-102-thread-1:361005 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:24  [ pool-102-thread-1:361094 ] - [ INFO ]  Task:attempt_local27917522_0033_r_000000_0 is done. And is in the process of committing
2020-11-20 12:58:24  [ pool-102-thread-1:361099 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:24  [ pool-102-thread-1:361099 ] - [ INFO ]  Task attempt_local27917522_0033_r_000000_0 is allowed to commit now
2020-11-20 12:58:24  [ pool-102-thread-1:361121 ] - [ INFO ]  Saved output of task 'attempt_local27917522_0033_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local27917522_0033_r_000000
2020-11-20 12:58:24  [ pool-102-thread-1:361121 ] - [ INFO ]  reduce > reduce
2020-11-20 12:58:24  [ pool-102-thread-1:361121 ] - [ INFO ]  Task 'attempt_local27917522_0033_r_000000_0' done.
2020-11-20 12:58:24  [ pool-102-thread-1:361122 ] - [ INFO ]  Finishing task: attempt_local27917522_0033_r_000000_0
2020-11-20 12:58:24  [ Thread-893:361122 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:58:24  [ main:361659 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:58:24  [ main:361659 ] - [ INFO ]  Job job_local27917522_0033 completed successfully
2020-11-20 12:58:24  [ main:361661 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=289098
		FILE: Number of bytes written=20538598
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=94309200
		HDFS: Number of bytes written=136361
		HDFS: Number of read operations=984
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=517
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2413
		Map output materialized bytes=2128
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2128
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=46
		Total committed heap usage (bytes)=1601175552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:58:24  [ main:361681 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:58:24  [ main:361693 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:58:24  [ main:361698 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:58:24  [ main:361703 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:58:24  [ main:361743 ] - [ INFO ]  number of splits:1
2020-11-20 12:58:24  [ main:361760 ] - [ INFO ]  Submitting tokens for job: job_local1390323548_0034
2020-11-20 12:58:24  [ main:361794 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:58:24  [ main:361794 ] - [ INFO ]  Running job: job_local1390323548_0034
2020-11-20 12:58:24  [ Thread-920:361794 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:58:24  [ Thread-920:361794 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:24  [ Thread-920:361794 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:58:24  [ Thread-920:361802 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361802 ] - [ INFO ]  Starting task: attempt_local1390323548_0034_m_000000_0
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361802 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361802 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361802 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361803 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361810 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361810 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361810 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361810 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361810 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:58:24  [ LocalJobRunner Map Task Executor #0:361810 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:58:25  [ main:362797 ] - [ INFO ]  Job job_local1390323548_0034 running in uber mode : false
2020-11-20 12:58:25  [ main:362797 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:58:30  [ communication thread:367806 ] - [ INFO ]  map > map
2020-11-20 12:58:30  [ main:367815 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:58:33  [ communication thread:370813 ] - [ INFO ]  map > map
2020-11-20 12:58:33  [ main:370824 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371612 ] - [ INFO ]  map > map
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371612 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371612 ] - [ INFO ]  Spilling map output
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371612 ] - [ INFO ]  bufstart = 0; bufend = 2391; bufvoid = 104857600
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371612 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371615 ] - [ INFO ]  Finished spill 0
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371616 ] - [ INFO ]  Task:attempt_local1390323548_0034_m_000000_0 is done. And is in the process of committing
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371622 ] - [ INFO ]  map
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371622 ] - [ INFO ]  Task 'attempt_local1390323548_0034_m_000000_0' done.
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371622 ] - [ INFO ]  Finishing task: attempt_local1390323548_0034_m_000000_0
2020-11-20 12:58:34  [ Thread-920:371623 ] - [ INFO ]  map task executor complete.
2020-11-20 12:58:34  [ Thread-920:371623 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:58:34  [ pool-105-thread-1:371623 ] - [ INFO ]  Starting task: attempt_local1390323548_0034_r_000000_0
2020-11-20 12:58:34  [ pool-105-thread-1:371624 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:34  [ pool-105-thread-1:371624 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:34  [ pool-105-thread-1:371624 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:34  [ pool-105-thread-1:371624 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ce0527f
2020-11-20 12:58:34  [ pool-105-thread-1:371626 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:58:34  [ EventFetcher for fetching Map Completion Events:371626 ] - [ INFO ]  attempt_local1390323548_0034_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:58:34  [ localfetcher#34:371627 ] - [ INFO ]  localfetcher#34 about to shuffle output of map attempt_local1390323548_0034_m_000000_0 decomp: 2102 len: 2106 to MEMORY
2020-11-20 12:58:34  [ localfetcher#34:371627 ] - [ INFO ]  Read 2102 bytes from map-output for attempt_local1390323548_0034_m_000000_0
2020-11-20 12:58:34  [ localfetcher#34:371627 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2102
2020-11-20 12:58:34  [ EventFetcher for fetching Map Completion Events:371628 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:58:34  [ pool-105-thread-1:371628 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:34  [ pool-105-thread-1:371628 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:58:34  [ pool-105-thread-1:371629 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:34  [ pool-105-thread-1:371629 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2095 bytes
2020-11-20 12:58:34  [ pool-105-thread-1:371629 ] - [ INFO ]  Merged 1 segments, 2102 bytes to disk to satisfy reduce memory limit
2020-11-20 12:58:34  [ pool-105-thread-1:371629 ] - [ INFO ]  Merging 1 files, 2106 bytes from disk
2020-11-20 12:58:34  [ pool-105-thread-1:371629 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:58:34  [ pool-105-thread-1:371629 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:34  [ pool-105-thread-1:371630 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2095 bytes
2020-11-20 12:58:34  [ pool-105-thread-1:371630 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:34  [ pool-105-thread-1:371736 ] - [ INFO ]  Task:attempt_local1390323548_0034_r_000000_0 is done. And is in the process of committing
2020-11-20 12:58:34  [ pool-105-thread-1:371744 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:34  [ pool-105-thread-1:371744 ] - [ INFO ]  Task attempt_local1390323548_0034_r_000000_0 is allowed to commit now
2020-11-20 12:58:34  [ pool-105-thread-1:371764 ] - [ INFO ]  Saved output of task 'attempt_local1390323548_0034_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1390323548_0034_r_000000
2020-11-20 12:58:34  [ pool-105-thread-1:371764 ] - [ INFO ]  reduce > reduce
2020-11-20 12:58:34  [ pool-105-thread-1:371764 ] - [ INFO ]  Task 'attempt_local1390323548_0034_r_000000_0' done.
2020-11-20 12:58:34  [ pool-105-thread-1:371764 ] - [ INFO ]  Finishing task: attempt_local1390323548_0034_r_000000_0
2020-11-20 12:58:34  [ Thread-920:371765 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:58:34  [ main:371830 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:58:34  [ main:371831 ] - [ INFO ]  Job job_local1390323548_0034 completed successfully
2020-11-20 12:58:34  [ main:371832 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=298012
		FILE: Number of bytes written=21163846
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=97083000
		HDFS: Number of bytes written=140569
		HDFS: Number of read operations=1014
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=533
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2391
		Map output materialized bytes=2106
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2106
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1592786944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:58:34  [ main:371853 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:58:34  [ main:371863 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:58:34  [ main:371868 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:58:34  [ main:371876 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:58:34  [ main:371913 ] - [ INFO ]  number of splits:1
2020-11-20 12:58:34  [ main:371930 ] - [ INFO ]  Submitting tokens for job: job_local1285328802_0035
2020-11-20 12:58:34  [ main:371965 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:58:34  [ main:371965 ] - [ INFO ]  Running job: job_local1285328802_0035
2020-11-20 12:58:34  [ Thread-947:371965 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:58:34  [ Thread-947:371965 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:34  [ Thread-947:371965 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:58:34  [ Thread-947:371972 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371973 ] - [ INFO ]  Starting task: attempt_local1285328802_0035_m_000000_0
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371973 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371973 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371973 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371974 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371981 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371981 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371981 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371981 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371981 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:58:34  [ LocalJobRunner Map Task Executor #0:371982 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:58:35  [ main:372972 ] - [ INFO ]  Job job_local1285328802_0035 running in uber mode : false
2020-11-20 12:58:35  [ main:372972 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:58:40  [ communication thread:377983 ] - [ INFO ]  map > map
2020-11-20 12:58:40  [ main:377991 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:58:43  [ communication thread:380989 ] - [ INFO ]  map > map
2020-11-20 12:58:44  [ main:381015 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381990 ] - [ INFO ]  map > map
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381990 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381990 ] - [ INFO ]  Spilling map output
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381990 ] - [ INFO ]  bufstart = 0; bufend = 2429; bufvoid = 104857600
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381990 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381992 ] - [ INFO ]  Finished spill 0
2020-11-20 12:58:44  [ LocalJobRunner Map Task Executor #0:381993 ] - [ INFO ]  Task:attempt_local1285328802_0035_m_000000_0 is done. And is in the process of committing
2020-11-20 12:58:45  [ LocalJobRunner Map Task Executor #0:382014 ] - [ INFO ]  map
2020-11-20 12:58:45  [ LocalJobRunner Map Task Executor #0:382014 ] - [ INFO ]  Task 'attempt_local1285328802_0035_m_000000_0' done.
2020-11-20 12:58:45  [ LocalJobRunner Map Task Executor #0:382014 ] - [ INFO ]  Finishing task: attempt_local1285328802_0035_m_000000_0
2020-11-20 12:58:45  [ Thread-947:382014 ] - [ INFO ]  map task executor complete.
2020-11-20 12:58:45  [ Thread-947:382014 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:58:45  [ pool-108-thread-1:382014 ] - [ INFO ]  Starting task: attempt_local1285328802_0035_r_000000_0
2020-11-20 12:58:45  [ pool-108-thread-1:382015 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:45  [ pool-108-thread-1:382015 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:45  [ pool-108-thread-1:382015 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:45  [ pool-108-thread-1:382015 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@743c0a4d
2020-11-20 12:58:45  [ main:382016 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:58:45  [ pool-108-thread-1:382016 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:58:45  [ EventFetcher for fetching Map Completion Events:382016 ] - [ INFO ]  attempt_local1285328802_0035_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:58:45  [ localfetcher#35:382017 ] - [ INFO ]  localfetcher#35 about to shuffle output of map attempt_local1285328802_0035_m_000000_0 decomp: 2140 len: 2144 to MEMORY
2020-11-20 12:58:45  [ localfetcher#35:382017 ] - [ INFO ]  Read 2140 bytes from map-output for attempt_local1285328802_0035_m_000000_0
2020-11-20 12:58:45  [ localfetcher#35:382017 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2140, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2140
2020-11-20 12:58:45  [ EventFetcher for fetching Map Completion Events:382018 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:58:45  [ pool-108-thread-1:382018 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:45  [ pool-108-thread-1:382018 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:58:45  [ pool-108-thread-1:382018 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2133 bytes
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  Merged 1 segments, 2140 bytes to disk to satisfy reduce memory limit
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  Merging 1 files, 2144 bytes from disk
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2133 bytes
2020-11-20 12:58:45  [ pool-108-thread-1:382019 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:45  [ pool-108-thread-1:382134 ] - [ INFO ]  Task:attempt_local1285328802_0035_r_000000_0 is done. And is in the process of committing
2020-11-20 12:58:45  [ pool-108-thread-1:382145 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:45  [ pool-108-thread-1:382145 ] - [ INFO ]  Task attempt_local1285328802_0035_r_000000_0 is allowed to commit now
2020-11-20 12:58:45  [ pool-108-thread-1:382183 ] - [ INFO ]  Saved output of task 'attempt_local1285328802_0035_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1285328802_0035_r_000000
2020-11-20 12:58:45  [ pool-108-thread-1:382184 ] - [ INFO ]  reduce > reduce
2020-11-20 12:58:45  [ pool-108-thread-1:382184 ] - [ INFO ]  Task 'attempt_local1285328802_0035_r_000000_0' done.
2020-11-20 12:58:45  [ pool-108-thread-1:382184 ] - [ INFO ]  Finishing task: attempt_local1285328802_0035_r_000000_0
2020-11-20 12:58:45  [ Thread-947:382184 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:58:46  [ main:383026 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:58:46  [ main:383026 ] - [ INFO ]  Job job_local1285328802_0035 completed successfully
2020-11-20 12:58:46  [ main:383027 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=306958
		FILE: Number of bytes written=21789926
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=99856800
		HDFS: Number of bytes written=144793
		HDFS: Number of read operations=1044
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=549
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2429
		Map output materialized bytes=2144
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2144
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=1527775232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:58:46  [ main:383056 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:58:46  [ main:383071 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:58:46  [ main:383075 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:58:46  [ main:383085 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:58:46  [ main:383127 ] - [ INFO ]  number of splits:1
2020-11-20 12:58:46  [ main:383142 ] - [ INFO ]  Submitting tokens for job: job_local1359673037_0036
2020-11-20 12:58:46  [ main:383175 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:58:46  [ main:383175 ] - [ INFO ]  Running job: job_local1359673037_0036
2020-11-20 12:58:46  [ Thread-975:383176 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:58:46  [ Thread-975:383176 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:46  [ Thread-975:383176 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:58:46  [ Thread-975:383189 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383189 ] - [ INFO ]  Starting task: attempt_local1359673037_0036_m_000000_0
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383189 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383190 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383190 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383190 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383199 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383199 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383199 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383199 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383199 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:58:46  [ LocalJobRunner Map Task Executor #0:383199 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:58:47  [ main:384182 ] - [ INFO ]  Job job_local1359673037_0036 running in uber mode : false
2020-11-20 12:58:47  [ main:384182 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:58:52  [ communication thread:389195 ] - [ INFO ]  map > map
2020-11-20 12:58:52  [ main:389221 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:58:55  [ communication thread:392206 ] - [ INFO ]  map > map
2020-11-20 12:58:55  [ main:392230 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392658 ] - [ INFO ]  map > map
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392658 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392659 ] - [ INFO ]  Spilling map output
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392659 ] - [ INFO ]  bufstart = 0; bufend = 2381; bufvoid = 104857600
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392659 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392661 ] - [ INFO ]  Finished spill 0
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392661 ] - [ INFO ]  Task:attempt_local1359673037_0036_m_000000_0 is done. And is in the process of committing
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392676 ] - [ INFO ]  map
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392677 ] - [ INFO ]  Task 'attempt_local1359673037_0036_m_000000_0' done.
2020-11-20 12:58:55  [ LocalJobRunner Map Task Executor #0:392677 ] - [ INFO ]  Finishing task: attempt_local1359673037_0036_m_000000_0
2020-11-20 12:58:55  [ Thread-975:392677 ] - [ INFO ]  map task executor complete.
2020-11-20 12:58:55  [ Thread-975:392677 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:58:55  [ pool-111-thread-1:392677 ] - [ INFO ]  Starting task: attempt_local1359673037_0036_r_000000_0
2020-11-20 12:58:55  [ pool-111-thread-1:392678 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:55  [ pool-111-thread-1:392678 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:55  [ pool-111-thread-1:392678 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:55  [ pool-111-thread-1:392678 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16b20b12
2020-11-20 12:58:55  [ pool-111-thread-1:392680 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:58:55  [ EventFetcher for fetching Map Completion Events:392680 ] - [ INFO ]  attempt_local1359673037_0036_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:58:55  [ localfetcher#36:392681 ] - [ INFO ]  localfetcher#36 about to shuffle output of map attempt_local1359673037_0036_m_000000_0 decomp: 2092 len: 2096 to MEMORY
2020-11-20 12:58:55  [ localfetcher#36:392681 ] - [ INFO ]  Read 2092 bytes from map-output for attempt_local1359673037_0036_m_000000_0
2020-11-20 12:58:55  [ localfetcher#36:392681 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2092, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2092
2020-11-20 12:58:55  [ EventFetcher for fetching Map Completion Events:392681 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:58:55  [ pool-111-thread-1:392682 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:55  [ pool-111-thread-1:392682 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:58:55  [ pool-111-thread-1:392682 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  Merged 1 segments, 2092 bytes to disk to satisfy reduce memory limit
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  Merging 1 files, 2096 bytes from disk
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 12:58:55  [ pool-111-thread-1:392683 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:55  [ pool-111-thread-1:392840 ] - [ INFO ]  Task:attempt_local1359673037_0036_r_000000_0 is done. And is in the process of committing
2020-11-20 12:58:55  [ pool-111-thread-1:392851 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:58:55  [ pool-111-thread-1:392851 ] - [ INFO ]  Task attempt_local1359673037_0036_r_000000_0 is allowed to commit now
2020-11-20 12:58:55  [ pool-111-thread-1:392906 ] - [ INFO ]  Saved output of task 'attempt_local1359673037_0036_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1359673037_0036_r_000000
2020-11-20 12:58:55  [ pool-111-thread-1:392907 ] - [ INFO ]  reduce > reduce
2020-11-20 12:58:55  [ pool-111-thread-1:392907 ] - [ INFO ]  Task 'attempt_local1359673037_0036_r_000000_0' done.
2020-11-20 12:58:55  [ pool-111-thread-1:392907 ] - [ INFO ]  Finishing task: attempt_local1359673037_0036_r_000000_0
2020-11-20 12:58:55  [ Thread-975:392907 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:58:56  [ main:393235 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:58:56  [ main:393235 ] - [ INFO ]  Job job_local1359673037_0036 completed successfully
2020-11-20 12:58:56  [ main:393236 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=315884
		FILE: Number of bytes written=22416068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=102630600
		HDFS: Number of bytes written=149007
		HDFS: Number of read operations=1074
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=565
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2381
		Map output materialized bytes=2096
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2096
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1520435200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:58:56  [ main:393316 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:58:56  [ main:393336 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:58:56  [ main:393341 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:58:56  [ main:393357 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:58:56  [ main:393405 ] - [ INFO ]  number of splits:1
2020-11-20 12:58:56  [ main:393422 ] - [ INFO ]  Submitting tokens for job: job_local316697847_0037
2020-11-20 12:58:56  [ main:393456 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:58:56  [ main:393456 ] - [ INFO ]  Running job: job_local316697847_0037
2020-11-20 12:58:56  [ Thread-1002:393456 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:58:56  [ Thread-1002:393456 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:56  [ Thread-1002:393456 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:58:56  [ Thread-1002:393479 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393479 ] - [ INFO ]  Starting task: attempt_local316697847_0037_m_000000_0
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393480 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393480 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393480 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393481 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393490 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393490 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393490 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393490 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393490 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:58:56  [ LocalJobRunner Map Task Executor #0:393490 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:58:57  [ main:394459 ] - [ INFO ]  Job job_local316697847_0037 running in uber mode : false
2020-11-20 12:58:57  [ main:394459 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:59:02  [ communication thread:399487 ] - [ INFO ]  map > map
2020-11-20 12:59:03  [ main:400480 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:59:05  [ communication thread:402491 ] - [ INFO ]  map > map
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403079 ] - [ INFO ]  map > map
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403079 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403079 ] - [ INFO ]  Spilling map output
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403079 ] - [ INFO ]  bufstart = 0; bufend = 2405; bufvoid = 104857600
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403079 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403081 ] - [ INFO ]  Finished spill 0
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403082 ] - [ INFO ]  Task:attempt_local316697847_0037_m_000000_0 is done. And is in the process of committing
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403093 ] - [ INFO ]  map
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403093 ] - [ INFO ]  Task 'attempt_local316697847_0037_m_000000_0' done.
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403093 ] - [ INFO ]  Finishing task: attempt_local316697847_0037_m_000000_0
2020-11-20 12:59:06  [ Thread-1002:403093 ] - [ INFO ]  map task executor complete.
2020-11-20 12:59:06  [ Thread-1002:403093 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:59:06  [ pool-114-thread-1:403093 ] - [ INFO ]  Starting task: attempt_local316697847_0037_r_000000_0
2020-11-20 12:59:06  [ pool-114-thread-1:403093 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:06  [ pool-114-thread-1:403094 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:06  [ pool-114-thread-1:403094 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:06  [ pool-114-thread-1:403094 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2d3ff00
2020-11-20 12:59:06  [ pool-114-thread-1:403094 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:59:06  [ EventFetcher for fetching Map Completion Events:403095 ] - [ INFO ]  attempt_local316697847_0037_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:59:06  [ localfetcher#37:403095 ] - [ INFO ]  localfetcher#37 about to shuffle output of map attempt_local316697847_0037_m_000000_0 decomp: 2116 len: 2120 to MEMORY
2020-11-20 12:59:06  [ localfetcher#37:403095 ] - [ INFO ]  Read 2116 bytes from map-output for attempt_local316697847_0037_m_000000_0
2020-11-20 12:59:06  [ localfetcher#37:403095 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2116, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2116
2020-11-20 12:59:06  [ EventFetcher for fetching Map Completion Events:403096 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:59:06  [ pool-114-thread-1:403096 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:06  [ pool-114-thread-1:403096 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2109 bytes
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Merged 1 segments, 2116 bytes to disk to satisfy reduce memory limit
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Merging 1 files, 2120 bytes from disk
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2109 bytes
2020-11-20 12:59:06  [ pool-114-thread-1:403097 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:06  [ pool-114-thread-1:403319 ] - [ INFO ]  Task:attempt_local316697847_0037_r_000000_0 is done. And is in the process of committing
2020-11-20 12:59:06  [ pool-114-thread-1:403329 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:06  [ pool-114-thread-1:403329 ] - [ INFO ]  Task attempt_local316697847_0037_r_000000_0 is allowed to commit now
2020-11-20 12:59:06  [ pool-114-thread-1:403361 ] - [ INFO ]  Saved output of task 'attempt_local316697847_0037_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local316697847_0037_r_000000
2020-11-20 12:59:06  [ pool-114-thread-1:403362 ] - [ INFO ]  reduce > reduce
2020-11-20 12:59:06  [ pool-114-thread-1:403362 ] - [ INFO ]  Task 'attempt_local316697847_0037_r_000000_0' done.
2020-11-20 12:59:06  [ pool-114-thread-1:403362 ] - [ INFO ]  Finishing task: attempt_local316697847_0037_r_000000_0
2020-11-20 12:59:06  [ Thread-1002:403362 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:59:06  [ main:403487 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:59:06  [ main:403488 ] - [ INFO ]  Job job_local316697847_0037 completed successfully
2020-11-20 12:59:06  [ main:403490 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=324762
		FILE: Number of bytes written=23039438
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=105404400
		HDFS: Number of bytes written=153197
		HDFS: Number of read operations=1104
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=581
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2405
		Map output materialized bytes=2120
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2120
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=1449132032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:59:06  [ main:403796 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:59:06  [ main:403810 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:59:06  [ main:403815 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:59:06  [ main:403824 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:59:06  [ main:403868 ] - [ INFO ]  number of splits:1
2020-11-20 12:59:06  [ main:403884 ] - [ INFO ]  Submitting tokens for job: job_local2004012351_0038
2020-11-20 12:59:06  [ main:403918 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:59:06  [ main:403918 ] - [ INFO ]  Running job: job_local2004012351_0038
2020-11-20 12:59:06  [ Thread-1029:403919 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:59:06  [ Thread-1029:403919 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:06  [ Thread-1029:403919 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:59:06  [ Thread-1029:403931 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403931 ] - [ INFO ]  Starting task: attempt_local2004012351_0038_m_000000_0
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403932 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403932 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403932 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403932 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403940 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403940 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403940 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403940 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403940 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:59:06  [ LocalJobRunner Map Task Executor #0:403940 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:59:07  [ main:404922 ] - [ INFO ]  Job job_local2004012351_0038 running in uber mode : false
2020-11-20 12:59:07  [ main:404922 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:59:12  [ communication thread:409936 ] - [ INFO ]  map > map
2020-11-20 12:59:13  [ main:410938 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:59:15  [ communication thread:412938 ] - [ INFO ]  map > map
2020-11-20 12:59:15  [ main:412943 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413635 ] - [ INFO ]  map > map
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413635 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413636 ] - [ INFO ]  Spilling map output
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413636 ] - [ INFO ]  bufstart = 0; bufend = 2397; bufvoid = 104857600
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413636 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413637 ] - [ INFO ]  Finished spill 0
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413638 ] - [ INFO ]  Task:attempt_local2004012351_0038_m_000000_0 is done. And is in the process of committing
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413654 ] - [ INFO ]  map
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413654 ] - [ INFO ]  Task 'attempt_local2004012351_0038_m_000000_0' done.
2020-11-20 12:59:16  [ LocalJobRunner Map Task Executor #0:413654 ] - [ INFO ]  Finishing task: attempt_local2004012351_0038_m_000000_0
2020-11-20 12:59:16  [ Thread-1029:413654 ] - [ INFO ]  map task executor complete.
2020-11-20 12:59:16  [ Thread-1029:413655 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:59:16  [ pool-117-thread-1:413655 ] - [ INFO ]  Starting task: attempt_local2004012351_0038_r_000000_0
2020-11-20 12:59:16  [ pool-117-thread-1:413656 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:16  [ pool-117-thread-1:413656 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:16  [ pool-117-thread-1:413656 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:16  [ pool-117-thread-1:413656 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@58257b78
2020-11-20 12:59:16  [ pool-117-thread-1:413657 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:59:16  [ EventFetcher for fetching Map Completion Events:413658 ] - [ INFO ]  attempt_local2004012351_0038_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:59:16  [ localfetcher#38:413659 ] - [ INFO ]  localfetcher#38 about to shuffle output of map attempt_local2004012351_0038_m_000000_0 decomp: 2108 len: 2112 to MEMORY
2020-11-20 12:59:16  [ localfetcher#38:413659 ] - [ INFO ]  Read 2108 bytes from map-output for attempt_local2004012351_0038_m_000000_0
2020-11-20 12:59:16  [ localfetcher#38:413659 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2108, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2108
2020-11-20 12:59:16  [ EventFetcher for fetching Map Completion Events:413659 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:59:16  [ pool-117-thread-1:413660 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:16  [ pool-117-thread-1:413660 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:59:16  [ pool-117-thread-1:413660 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:16  [ pool-117-thread-1:413660 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2101 bytes
2020-11-20 12:59:16  [ pool-117-thread-1:413661 ] - [ INFO ]  Merged 1 segments, 2108 bytes to disk to satisfy reduce memory limit
2020-11-20 12:59:16  [ pool-117-thread-1:413661 ] - [ INFO ]  Merging 1 files, 2112 bytes from disk
2020-11-20 12:59:16  [ pool-117-thread-1:413661 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:59:16  [ pool-117-thread-1:413661 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:16  [ pool-117-thread-1:413661 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2101 bytes
2020-11-20 12:59:16  [ pool-117-thread-1:413661 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:16  [ main:413946 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:59:17  [ pool-117-thread-1:414044 ] - [ INFO ]  Task:attempt_local2004012351_0038_r_000000_0 is done. And is in the process of committing
2020-11-20 12:59:17  [ pool-117-thread-1:414053 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:17  [ pool-117-thread-1:414053 ] - [ INFO ]  Task attempt_local2004012351_0038_r_000000_0 is allowed to commit now
2020-11-20 12:59:17  [ pool-117-thread-1:414293 ] - [ INFO ]  Saved output of task 'attempt_local2004012351_0038_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2004012351_0038_r_000000
2020-11-20 12:59:17  [ pool-117-thread-1:414293 ] - [ INFO ]  reduce > reduce
2020-11-20 12:59:17  [ pool-117-thread-1:414294 ] - [ INFO ]  Task 'attempt_local2004012351_0038_r_000000_0' done.
2020-11-20 12:59:17  [ pool-117-thread-1:414294 ] - [ INFO ]  Finishing task: attempt_local2004012351_0038_r_000000_0
2020-11-20 12:59:17  [ Thread-1029:414294 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:59:17  [ main:414948 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:59:17  [ main:414949 ] - [ INFO ]  Job job_local2004012351_0038 completed successfully
2020-11-20 12:59:17  [ main:414950 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=333672
		FILE: Number of bytes written=23666648
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108178200
		HDFS: Number of bytes written=157403
		HDFS: Number of read operations=1134
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=597
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2397
		Map output materialized bytes=2112
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2112
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1441792000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:59:17  [ main:414981 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:59:17  [ main:414996 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:59:17  [ main:415000 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:59:18  [ main:415010 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:59:18  [ main:415048 ] - [ INFO ]  number of splits:1
2020-11-20 12:59:18  [ main:415065 ] - [ INFO ]  Submitting tokens for job: job_local1968486881_0039
2020-11-20 12:59:18  [ main:415100 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:59:18  [ main:415100 ] - [ INFO ]  Running job: job_local1968486881_0039
2020-11-20 12:59:18  [ Thread-1056:415100 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:59:18  [ Thread-1056:415100 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:18  [ Thread-1056:415100 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:59:18  [ Thread-1056:415112 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415112 ] - [ INFO ]  Starting task: attempt_local1968486881_0039_m_000000_0
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415112 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415112 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415112 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415113 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415120 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415120 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415120 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415120 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415120 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:59:18  [ LocalJobRunner Map Task Executor #0:415121 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:59:19  [ main:416101 ] - [ INFO ]  Job job_local1968486881_0039 running in uber mode : false
2020-11-20 12:59:19  [ main:416102 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:59:24  [ communication thread:421116 ] - [ INFO ]  map > map
2020-11-20 12:59:25  [ main:422117 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:59:27  [ communication thread:424121 ] - [ INFO ]  map > map
2020-11-20 12:59:27  [ main:424125 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424611 ] - [ INFO ]  map > map
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424611 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424611 ] - [ INFO ]  Spilling map output
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424611 ] - [ INFO ]  bufstart = 0; bufend = 2383; bufvoid = 104857600
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424611 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424613 ] - [ INFO ]  Finished spill 0
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424614 ] - [ INFO ]  Task:attempt_local1968486881_0039_m_000000_0 is done. And is in the process of committing
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424624 ] - [ INFO ]  map
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424624 ] - [ INFO ]  Task 'attempt_local1968486881_0039_m_000000_0' done.
2020-11-20 12:59:27  [ LocalJobRunner Map Task Executor #0:424624 ] - [ INFO ]  Finishing task: attempt_local1968486881_0039_m_000000_0
2020-11-20 12:59:27  [ Thread-1056:424624 ] - [ INFO ]  map task executor complete.
2020-11-20 12:59:27  [ Thread-1056:424625 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:59:27  [ pool-120-thread-1:424625 ] - [ INFO ]  Starting task: attempt_local1968486881_0039_r_000000_0
2020-11-20 12:59:27  [ pool-120-thread-1:424625 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:27  [ pool-120-thread-1:424626 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:27  [ pool-120-thread-1:424626 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:27  [ pool-120-thread-1:424626 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3712fcf9
2020-11-20 12:59:27  [ pool-120-thread-1:424627 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:59:27  [ EventFetcher for fetching Map Completion Events:424627 ] - [ INFO ]  attempt_local1968486881_0039_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:59:27  [ localfetcher#39:424628 ] - [ INFO ]  localfetcher#39 about to shuffle output of map attempt_local1968486881_0039_m_000000_0 decomp: 2094 len: 2098 to MEMORY
2020-11-20 12:59:27  [ localfetcher#39:424628 ] - [ INFO ]  Read 2094 bytes from map-output for attempt_local1968486881_0039_m_000000_0
2020-11-20 12:59:27  [ localfetcher#39:424628 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2094, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2094
2020-11-20 12:59:27  [ EventFetcher for fetching Map Completion Events:424628 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:59:27  [ pool-120-thread-1:424628 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:27  [ pool-120-thread-1:424629 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:59:27  [ pool-120-thread-1:424629 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:27  [ pool-120-thread-1:424629 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2087 bytes
2020-11-20 12:59:27  [ pool-120-thread-1:424630 ] - [ INFO ]  Merged 1 segments, 2094 bytes to disk to satisfy reduce memory limit
2020-11-20 12:59:27  [ pool-120-thread-1:424630 ] - [ INFO ]  Merging 1 files, 2098 bytes from disk
2020-11-20 12:59:27  [ pool-120-thread-1:424630 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:59:27  [ pool-120-thread-1:424630 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:27  [ pool-120-thread-1:424630 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2087 bytes
2020-11-20 12:59:27  [ pool-120-thread-1:424630 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:27  [ pool-120-thread-1:424742 ] - [ INFO ]  Task:attempt_local1968486881_0039_r_000000_0 is done. And is in the process of committing
2020-11-20 12:59:27  [ pool-120-thread-1:424752 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:27  [ pool-120-thread-1:424752 ] - [ INFO ]  Task attempt_local1968486881_0039_r_000000_0 is allowed to commit now
2020-11-20 12:59:27  [ pool-120-thread-1:424785 ] - [ INFO ]  Saved output of task 'attempt_local1968486881_0039_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1968486881_0039_r_000000
2020-11-20 12:59:27  [ pool-120-thread-1:424785 ] - [ INFO ]  reduce > reduce
2020-11-20 12:59:27  [ pool-120-thread-1:424785 ] - [ INFO ]  Task 'attempt_local1968486881_0039_r_000000_0' done.
2020-11-20 12:59:27  [ pool-120-thread-1:424785 ] - [ INFO ]  Finishing task: attempt_local1968486881_0039_r_000000_0
2020-11-20 12:59:27  [ Thread-1056:424785 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:59:28  [ main:425130 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:59:28  [ main:425130 ] - [ INFO ]  Job job_local1968486881_0039 completed successfully
2020-11-20 12:59:28  [ main:425131 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=342538
		FILE: Number of bytes written=24293908
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=110952000
		HDFS: Number of bytes written=161587
		HDFS: Number of read operations=1164
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=613
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2383
		Map output materialized bytes=2098
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2098
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=1370488832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:59:28  [ main:425166 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:59:28  [ main:425180 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:59:28  [ main:425183 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:59:28  [ main:425192 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:59:28  [ main:425232 ] - [ INFO ]  number of splits:1
2020-11-20 12:59:28  [ main:425250 ] - [ INFO ]  Submitting tokens for job: job_local1994119893_0040
2020-11-20 12:59:28  [ main:425285 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:59:28  [ main:425285 ] - [ INFO ]  Running job: job_local1994119893_0040
2020-11-20 12:59:28  [ Thread-1083:425285 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:59:28  [ Thread-1083:425285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:28  [ Thread-1083:425286 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:59:28  [ Thread-1083:425359 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425359 ] - [ INFO ]  Starting task: attempt_local1994119893_0040_m_000000_0
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425360 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425360 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425360 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425360 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425368 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425368 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425369 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425369 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425369 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:59:28  [ LocalJobRunner Map Task Executor #0:425369 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:59:29  [ main:426288 ] - [ INFO ]  Job job_local1994119893_0040 running in uber mode : false
2020-11-20 12:59:29  [ main:426288 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:59:34  [ communication thread:431363 ] - [ INFO ]  map > map
2020-11-20 12:59:35  [ main:432308 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:59:37  [ communication thread:434365 ] - [ INFO ]  map > map
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435247 ] - [ INFO ]  map > map
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435247 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435247 ] - [ INFO ]  Spilling map output
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435247 ] - [ INFO ]  bufstart = 0; bufend = 2426; bufvoid = 104857600
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435247 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435249 ] - [ INFO ]  Finished spill 0
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435250 ] - [ INFO ]  Task:attempt_local1994119893_0040_m_000000_0 is done. And is in the process of committing
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435261 ] - [ INFO ]  map
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435261 ] - [ INFO ]  Task 'attempt_local1994119893_0040_m_000000_0' done.
2020-11-20 12:59:38  [ LocalJobRunner Map Task Executor #0:435261 ] - [ INFO ]  Finishing task: attempt_local1994119893_0040_m_000000_0
2020-11-20 12:59:38  [ Thread-1083:435261 ] - [ INFO ]  map task executor complete.
2020-11-20 12:59:38  [ Thread-1083:435262 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:59:38  [ pool-123-thread-1:435262 ] - [ INFO ]  Starting task: attempt_local1994119893_0040_r_000000_0
2020-11-20 12:59:38  [ pool-123-thread-1:435263 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:38  [ pool-123-thread-1:435263 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:38  [ pool-123-thread-1:435263 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:38  [ pool-123-thread-1:435263 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d71e2ac
2020-11-20 12:59:38  [ pool-123-thread-1:435264 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:59:38  [ EventFetcher for fetching Map Completion Events:435264 ] - [ INFO ]  attempt_local1994119893_0040_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:59:38  [ localfetcher#40:435265 ] - [ INFO ]  localfetcher#40 about to shuffle output of map attempt_local1994119893_0040_m_000000_0 decomp: 2137 len: 2141 to MEMORY
2020-11-20 12:59:38  [ localfetcher#40:435265 ] - [ INFO ]  Read 2137 bytes from map-output for attempt_local1994119893_0040_m_000000_0
2020-11-20 12:59:38  [ localfetcher#40:435266 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2137, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2137
2020-11-20 12:59:38  [ EventFetcher for fetching Map Completion Events:435266 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:59:38  [ pool-123-thread-1:435266 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:38  [ pool-123-thread-1:435266 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:59:38  [ pool-123-thread-1:435267 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:38  [ pool-123-thread-1:435267 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2130 bytes
2020-11-20 12:59:38  [ pool-123-thread-1:435267 ] - [ INFO ]  Merged 1 segments, 2137 bytes to disk to satisfy reduce memory limit
2020-11-20 12:59:38  [ pool-123-thread-1:435268 ] - [ INFO ]  Merging 1 files, 2141 bytes from disk
2020-11-20 12:59:38  [ pool-123-thread-1:435268 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:59:38  [ pool-123-thread-1:435268 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:38  [ pool-123-thread-1:435268 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2130 bytes
2020-11-20 12:59:38  [ pool-123-thread-1:435268 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:38  [ main:435315 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:59:38  [ pool-123-thread-1:435513 ] - [ INFO ]  Task:attempt_local1994119893_0040_r_000000_0 is done. And is in the process of committing
2020-11-20 12:59:38  [ pool-123-thread-1:435523 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:38  [ pool-123-thread-1:435523 ] - [ INFO ]  Task attempt_local1994119893_0040_r_000000_0 is allowed to commit now
2020-11-20 12:59:38  [ pool-123-thread-1:435553 ] - [ INFO ]  Saved output of task 'attempt_local1994119893_0040_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1994119893_0040_r_000000
2020-11-20 12:59:38  [ pool-123-thread-1:435554 ] - [ INFO ]  reduce > reduce
2020-11-20 12:59:38  [ pool-123-thread-1:435554 ] - [ INFO ]  Task 'attempt_local1994119893_0040_r_000000_0' done.
2020-11-20 12:59:38  [ pool-123-thread-1:435554 ] - [ INFO ]  Finishing task: attempt_local1994119893_0040_r_000000_0
2020-11-20 12:59:38  [ Thread-1083:435554 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:59:39  [ main:436320 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:59:39  [ main:436320 ] - [ INFO ]  Job job_local1994119893_0040 completed successfully
2020-11-20 12:59:39  [ main:436321 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=351462
		FILE: Number of bytes written=24921547
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=113725800
		HDFS: Number of bytes written=165800
		HDFS: Number of read operations=1194
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=629
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2426
		Map output materialized bytes=2141
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2141
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=1364197376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:59:39  [ main:436352 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:59:39  [ main:436369 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:59:39  [ main:436374 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:59:39  [ main:436384 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:59:39  [ main:436426 ] - [ INFO ]  number of splits:1
2020-11-20 12:59:39  [ main:436443 ] - [ INFO ]  Submitting tokens for job: job_local238423934_0041
2020-11-20 12:59:39  [ main:436477 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:59:39  [ main:436477 ] - [ INFO ]  Running job: job_local238423934_0041
2020-11-20 12:59:39  [ Thread-1110:436477 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:59:39  [ Thread-1110:436477 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:39  [ Thread-1110:436477 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:59:39  [ Thread-1110:436497 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436497 ] - [ INFO ]  Starting task: attempt_local238423934_0041_m_000000_0
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436498 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436498 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436498 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436499 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436507 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436507 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436507 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436507 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436507 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:59:39  [ LocalJobRunner Map Task Executor #0:436508 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:59:40  [ main:437477 ] - [ INFO ]  Job job_local238423934_0041 running in uber mode : false
2020-11-20 12:59:40  [ main:437477 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:59:45  [ communication thread:442505 ] - [ INFO ]  map > map
2020-11-20 12:59:46  [ main:443501 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:59:48  [ communication thread:445509 ] - [ INFO ]  map > map
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446029 ] - [ INFO ]  map > map
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446029 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446029 ] - [ INFO ]  Spilling map output
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446029 ] - [ INFO ]  bufstart = 0; bufend = 2352; bufvoid = 104857600
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446029 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446031 ] - [ INFO ]  Finished spill 0
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446032 ] - [ INFO ]  Task:attempt_local238423934_0041_m_000000_0 is done. And is in the process of committing
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446043 ] - [ INFO ]  map
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446043 ] - [ INFO ]  Task 'attempt_local238423934_0041_m_000000_0' done.
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446043 ] - [ INFO ]  Finishing task: attempt_local238423934_0041_m_000000_0
2020-11-20 12:59:49  [ Thread-1110:446043 ] - [ INFO ]  map task executor complete.
2020-11-20 12:59:49  [ Thread-1110:446043 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:59:49  [ pool-126-thread-1:446043 ] - [ INFO ]  Starting task: attempt_local238423934_0041_r_000000_0
2020-11-20 12:59:49  [ pool-126-thread-1:446044 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:49  [ pool-126-thread-1:446044 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:49  [ pool-126-thread-1:446044 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:49  [ pool-126-thread-1:446044 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@260877d3
2020-11-20 12:59:49  [ pool-126-thread-1:446045 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:59:49  [ EventFetcher for fetching Map Completion Events:446045 ] - [ INFO ]  attempt_local238423934_0041_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:59:49  [ localfetcher#41:446046 ] - [ INFO ]  localfetcher#41 about to shuffle output of map attempt_local238423934_0041_m_000000_0 decomp: 2063 len: 2067 to MEMORY
2020-11-20 12:59:49  [ localfetcher#41:446046 ] - [ INFO ]  Read 2063 bytes from map-output for attempt_local238423934_0041_m_000000_0
2020-11-20 12:59:49  [ localfetcher#41:446046 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2063, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2063
2020-11-20 12:59:49  [ EventFetcher for fetching Map Completion Events:446046 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:59:49  [ pool-126-thread-1:446046 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:49  [ pool-126-thread-1:446046 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:59:49  [ pool-126-thread-1:446047 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:49  [ pool-126-thread-1:446047 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2056 bytes
2020-11-20 12:59:49  [ pool-126-thread-1:446048 ] - [ INFO ]  Merged 1 segments, 2063 bytes to disk to satisfy reduce memory limit
2020-11-20 12:59:49  [ pool-126-thread-1:446048 ] - [ INFO ]  Merging 1 files, 2067 bytes from disk
2020-11-20 12:59:49  [ pool-126-thread-1:446048 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:59:49  [ pool-126-thread-1:446048 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:49  [ pool-126-thread-1:446048 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2056 bytes
2020-11-20 12:59:49  [ pool-126-thread-1:446048 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:49  [ pool-126-thread-1:446217 ] - [ INFO ]  Task:attempt_local238423934_0041_r_000000_0 is done. And is in the process of committing
2020-11-20 12:59:49  [ pool-126-thread-1:446231 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:49  [ pool-126-thread-1:446231 ] - [ INFO ]  Task attempt_local238423934_0041_r_000000_0 is allowed to commit now
2020-11-20 12:59:49  [ pool-126-thread-1:446267 ] - [ INFO ]  Saved output of task 'attempt_local238423934_0041_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local238423934_0041_r_000000
2020-11-20 12:59:49  [ pool-126-thread-1:446268 ] - [ INFO ]  reduce > reduce
2020-11-20 12:59:49  [ pool-126-thread-1:446268 ] - [ INFO ]  Task 'attempt_local238423934_0041_r_000000_0' done.
2020-11-20 12:59:49  [ pool-126-thread-1:446268 ] - [ INFO ]  Finishing task: attempt_local238423934_0041_r_000000_0
2020-11-20 12:59:49  [ Thread-1110:446268 ] - [ INFO ]  reduce task executor complete.
2020-11-20 12:59:49  [ main:446512 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 12:59:49  [ main:446512 ] - [ INFO ]  Job job_local238423934_0041 completed successfully
2020-11-20 12:59:49  [ main:446514 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=360324
		FILE: Number of bytes written=25546039
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=116499600
		HDFS: Number of bytes written=169982
		HDFS: Number of read operations=1224
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=645
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2352
		Map output materialized bytes=2067
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2067
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=1294991360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 12:59:49  [ main:446545 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 12:59:49  [ main:446563 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 12:59:49  [ main:446568 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 12:59:49  [ main:446579 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 12:59:49  [ main:446629 ] - [ INFO ]  number of splits:1
2020-11-20 12:59:49  [ main:446649 ] - [ INFO ]  Submitting tokens for job: job_local557910831_0042
2020-11-20 12:59:49  [ main:446689 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 12:59:49  [ main:446689 ] - [ INFO ]  Running job: job_local557910831_0042
2020-11-20 12:59:49  [ Thread-1137:446689 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 12:59:49  [ Thread-1137:446689 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:49  [ Thread-1137:446689 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 12:59:49  [ Thread-1137:446706 ] - [ INFO ]  Waiting for map tasks
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446707 ] - [ INFO ]  Starting task: attempt_local557910831_0042_m_000000_0
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446707 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446707 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446707 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446708 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446720 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446720 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446720 ] - [ INFO ]  soft limit at 83886080
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446720 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446720 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 12:59:49  [ LocalJobRunner Map Task Executor #0:446720 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 12:59:50  [ main:447692 ] - [ INFO ]  Job job_local557910831_0042 running in uber mode : false
2020-11-20 12:59:50  [ main:447692 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 12:59:55  [ communication thread:452713 ] - [ INFO ]  map > map
2020-11-20 12:59:56  [ main:453713 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 12:59:58  [ communication thread:455718 ] - [ INFO ]  map > map
2020-11-20 12:59:58  [ main:455720 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456424 ] - [ INFO ]  map > map
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456424 ] - [ INFO ]  Starting flush of map output
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456424 ] - [ INFO ]  Spilling map output
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456424 ] - [ INFO ]  bufstart = 0; bufend = 2392; bufvoid = 104857600
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456424 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456426 ] - [ INFO ]  Finished spill 0
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456427 ] - [ INFO ]  Task:attempt_local557910831_0042_m_000000_0 is done. And is in the process of committing
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456648 ] - [ INFO ]  map
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456648 ] - [ INFO ]  Task 'attempt_local557910831_0042_m_000000_0' done.
2020-11-20 12:59:59  [ LocalJobRunner Map Task Executor #0:456648 ] - [ INFO ]  Finishing task: attempt_local557910831_0042_m_000000_0
2020-11-20 12:59:59  [ Thread-1137:456648 ] - [ INFO ]  map task executor complete.
2020-11-20 12:59:59  [ Thread-1137:456648 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 12:59:59  [ pool-129-thread-1:456648 ] - [ INFO ]  Starting task: attempt_local557910831_0042_r_000000_0
2020-11-20 12:59:59  [ pool-129-thread-1:456649 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 12:59:59  [ pool-129-thread-1:456649 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 12:59:59  [ pool-129-thread-1:456649 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 12:59:59  [ pool-129-thread-1:456649 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71b19eb6
2020-11-20 12:59:59  [ pool-129-thread-1:456650 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 12:59:59  [ EventFetcher for fetching Map Completion Events:456650 ] - [ INFO ]  attempt_local557910831_0042_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 12:59:59  [ localfetcher#42:456651 ] - [ INFO ]  localfetcher#42 about to shuffle output of map attempt_local557910831_0042_m_000000_0 decomp: 2103 len: 2107 to MEMORY
2020-11-20 12:59:59  [ localfetcher#42:456651 ] - [ INFO ]  Read 2103 bytes from map-output for attempt_local557910831_0042_m_000000_0
2020-11-20 12:59:59  [ localfetcher#42:456651 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2103, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2103
2020-11-20 12:59:59  [ EventFetcher for fetching Map Completion Events:456651 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 12:59:59  [ pool-129-thread-1:456652 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:59  [ pool-129-thread-1:456652 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 12:59:59  [ pool-129-thread-1:456652 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:59  [ pool-129-thread-1:456652 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2096 bytes
2020-11-20 12:59:59  [ pool-129-thread-1:456653 ] - [ INFO ]  Merged 1 segments, 2103 bytes to disk to satisfy reduce memory limit
2020-11-20 12:59:59  [ pool-129-thread-1:456653 ] - [ INFO ]  Merging 1 files, 2107 bytes from disk
2020-11-20 12:59:59  [ pool-129-thread-1:456653 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 12:59:59  [ pool-129-thread-1:456653 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 12:59:59  [ pool-129-thread-1:456653 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2096 bytes
2020-11-20 12:59:59  [ pool-129-thread-1:456653 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:59  [ main:456720 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 12:59:59  [ pool-129-thread-1:456787 ] - [ INFO ]  Task:attempt_local557910831_0042_r_000000_0 is done. And is in the process of committing
2020-11-20 12:59:59  [ pool-129-thread-1:456799 ] - [ INFO ]  1 / 1 copied.
2020-11-20 12:59:59  [ pool-129-thread-1:456799 ] - [ INFO ]  Task attempt_local557910831_0042_r_000000_0 is allowed to commit now
2020-11-20 12:59:59  [ pool-129-thread-1:456828 ] - [ INFO ]  Saved output of task 'attempt_local557910831_0042_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local557910831_0042_r_000000
2020-11-20 12:59:59  [ pool-129-thread-1:456829 ] - [ INFO ]  reduce > reduce
2020-11-20 12:59:59  [ pool-129-thread-1:456829 ] - [ INFO ]  Task 'attempt_local557910831_0042_r_000000_0' done.
2020-11-20 12:59:59  [ pool-129-thread-1:456829 ] - [ INFO ]  Finishing task: attempt_local557910831_0042_r_000000_0
2020-11-20 12:59:59  [ Thread-1137:456829 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:00:00  [ main:457723 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:00:00  [ main:457723 ] - [ INFO ]  Job job_local557910831_0042 completed successfully
2020-11-20 13:00:00  [ main:457724 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=369118
		FILE: Number of bytes written=26170733
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=119273400
		HDFS: Number of bytes written=174130
		HDFS: Number of read operations=1254
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=661
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2392
		Map output materialized bytes=2107
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2107
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1289748480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:00:00  [ main:457757 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:00:00  [ main:457771 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:00:00  [ main:457775 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:00:00  [ main:457785 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:00:00  [ main:457827 ] - [ INFO ]  number of splits:1
2020-11-20 13:00:00  [ main:457845 ] - [ INFO ]  Submitting tokens for job: job_local1791849321_0043
2020-11-20 13:00:00  [ main:457881 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:00:00  [ main:457881 ] - [ INFO ]  Running job: job_local1791849321_0043
2020-11-20 13:00:00  [ Thread-1164:457881 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:00:00  [ Thread-1164:457881 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:00  [ Thread-1164:457881 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:00:00  [ Thread-1164:457896 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457896 ] - [ INFO ]  Starting task: attempt_local1791849321_0043_m_000000_0
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457896 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457896 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457896 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457897 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457904 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457904 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457904 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457904 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457904 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:00:00  [ LocalJobRunner Map Task Executor #0:457904 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:00:01  [ main:458881 ] - [ INFO ]  Job job_local1791849321_0043 running in uber mode : false
2020-11-20 13:00:01  [ main:458881 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:00:06  [ communication thread:463905 ] - [ INFO ]  map > map
2020-11-20 13:00:07  [ main:464894 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:00:09  [ communication thread:466908 ] - [ INFO ]  map > map
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467555 ] - [ INFO ]  map > map
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467555 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467555 ] - [ INFO ]  Spilling map output
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467555 ] - [ INFO ]  bufstart = 0; bufend = 2398; bufvoid = 104857600
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467555 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467557 ] - [ INFO ]  Finished spill 0
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467558 ] - [ INFO ]  Task:attempt_local1791849321_0043_m_000000_0 is done. And is in the process of committing
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467569 ] - [ INFO ]  map
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467569 ] - [ INFO ]  Task 'attempt_local1791849321_0043_m_000000_0' done.
2020-11-20 13:00:10  [ LocalJobRunner Map Task Executor #0:467569 ] - [ INFO ]  Finishing task: attempt_local1791849321_0043_m_000000_0
2020-11-20 13:00:10  [ Thread-1164:467569 ] - [ INFO ]  map task executor complete.
2020-11-20 13:00:10  [ Thread-1164:467569 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:00:10  [ pool-132-thread-1:467569 ] - [ INFO ]  Starting task: attempt_local1791849321_0043_r_000000_0
2020-11-20 13:00:10  [ pool-132-thread-1:467570 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:10  [ pool-132-thread-1:467570 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:10  [ pool-132-thread-1:467570 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:10  [ pool-132-thread-1:467570 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68dfaa73
2020-11-20 13:00:10  [ pool-132-thread-1:467572 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:00:10  [ EventFetcher for fetching Map Completion Events:467572 ] - [ INFO ]  attempt_local1791849321_0043_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:00:10  [ localfetcher#43:467573 ] - [ INFO ]  localfetcher#43 about to shuffle output of map attempt_local1791849321_0043_m_000000_0 decomp: 2109 len: 2113 to MEMORY
2020-11-20 13:00:10  [ localfetcher#43:467573 ] - [ INFO ]  Read 2109 bytes from map-output for attempt_local1791849321_0043_m_000000_0
2020-11-20 13:00:10  [ localfetcher#43:467573 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2109, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2109
2020-11-20 13:00:10  [ EventFetcher for fetching Map Completion Events:467573 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:00:10  [ pool-132-thread-1:467573 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:10  [ pool-132-thread-1:467573 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:00:10  [ pool-132-thread-1:467574 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:10  [ pool-132-thread-1:467574 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2102 bytes
2020-11-20 13:00:10  [ pool-132-thread-1:467575 ] - [ INFO ]  Merged 1 segments, 2109 bytes to disk to satisfy reduce memory limit
2020-11-20 13:00:10  [ pool-132-thread-1:467575 ] - [ INFO ]  Merging 1 files, 2113 bytes from disk
2020-11-20 13:00:10  [ pool-132-thread-1:467575 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:00:10  [ pool-132-thread-1:467575 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:10  [ pool-132-thread-1:467575 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2102 bytes
2020-11-20 13:00:10  [ pool-132-thread-1:467575 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:10  [ pool-132-thread-1:467742 ] - [ INFO ]  Task:attempt_local1791849321_0043_r_000000_0 is done. And is in the process of committing
2020-11-20 13:00:10  [ pool-132-thread-1:467752 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:10  [ pool-132-thread-1:467752 ] - [ INFO ]  Task attempt_local1791849321_0043_r_000000_0 is allowed to commit now
2020-11-20 13:00:10  [ pool-132-thread-1:467785 ] - [ INFO ]  Saved output of task 'attempt_local1791849321_0043_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1791849321_0043_r_000000
2020-11-20 13:00:10  [ pool-132-thread-1:467786 ] - [ INFO ]  reduce > reduce
2020-11-20 13:00:10  [ pool-132-thread-1:467786 ] - [ INFO ]  Task 'attempt_local1791849321_0043_r_000000_0' done.
2020-11-20 13:00:10  [ pool-132-thread-1:467786 ] - [ INFO ]  Finishing task: attempt_local1791849321_0043_r_000000_0
2020-11-20 13:00:10  [ Thread-1164:467786 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:00:10  [ main:467904 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:00:10  [ main:467905 ] - [ INFO ]  Job job_local1791849321_0043 completed successfully
2020-11-20 13:00:10  [ main:467905 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=378004
		FILE: Number of bytes written=26798805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=122047200
		HDFS: Number of bytes written=178324
		HDFS: Number of read operations=1284
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=677
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2398
		Map output materialized bytes=2113
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2113
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=1223688192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:00:10  [ main:467935 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:00:10  [ main:467951 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:00:10  [ main:467956 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:00:10  [ main:467966 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:00:11  [ main:468011 ] - [ INFO ]  number of splits:1
2020-11-20 13:00:11  [ main:468028 ] - [ INFO ]  Submitting tokens for job: job_local1908980227_0044
2020-11-20 13:00:11  [ main:468062 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:00:11  [ main:468062 ] - [ INFO ]  Running job: job_local1908980227_0044
2020-11-20 13:00:11  [ Thread-1191:468062 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:00:11  [ Thread-1191:468063 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:11  [ Thread-1191:468063 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:00:11  [ Thread-1191:468075 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468075 ] - [ INFO ]  Starting task: attempt_local1908980227_0044_m_000000_0
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468076 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468076 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468076 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468076 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468084 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468084 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468084 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468084 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468084 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:00:11  [ LocalJobRunner Map Task Executor #0:468084 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:00:12  [ main:469067 ] - [ INFO ]  Job job_local1908980227_0044 running in uber mode : false
2020-11-20 13:00:12  [ main:469067 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:00:17  [ communication thread:474082 ] - [ INFO ]  map > map
2020-11-20 13:00:17  [ main:474087 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:00:20  [ communication thread:477083 ] - [ INFO ]  map > map
2020-11-20 13:00:20  [ main:477102 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478019 ] - [ INFO ]  map > map
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478020 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478020 ] - [ INFO ]  Spilling map output
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478020 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478020 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478022 ] - [ INFO ]  Finished spill 0
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478023 ] - [ INFO ]  Task:attempt_local1908980227_0044_m_000000_0 is done. And is in the process of committing
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478031 ] - [ INFO ]  map
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478031 ] - [ INFO ]  Task 'attempt_local1908980227_0044_m_000000_0' done.
2020-11-20 13:00:21  [ LocalJobRunner Map Task Executor #0:478031 ] - [ INFO ]  Finishing task: attempt_local1908980227_0044_m_000000_0
2020-11-20 13:00:21  [ Thread-1191:478031 ] - [ INFO ]  map task executor complete.
2020-11-20 13:00:21  [ Thread-1191:478032 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:00:21  [ pool-135-thread-1:478032 ] - [ INFO ]  Starting task: attempt_local1908980227_0044_r_000000_0
2020-11-20 13:00:21  [ pool-135-thread-1:478032 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:21  [ pool-135-thread-1:478032 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:21  [ pool-135-thread-1:478032 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:21  [ pool-135-thread-1:478032 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@122d9292
2020-11-20 13:00:21  [ pool-135-thread-1:478033 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:00:21  [ EventFetcher for fetching Map Completion Events:478033 ] - [ INFO ]  attempt_local1908980227_0044_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:00:21  [ localfetcher#44:478034 ] - [ INFO ]  localfetcher#44 about to shuffle output of map attempt_local1908980227_0044_m_000000_0 decomp: 2113 len: 2117 to MEMORY
2020-11-20 13:00:21  [ localfetcher#44:478034 ] - [ INFO ]  Read 2113 bytes from map-output for attempt_local1908980227_0044_m_000000_0
2020-11-20 13:00:21  [ localfetcher#44:478034 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2113, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2113
2020-11-20 13:00:21  [ EventFetcher for fetching Map Completion Events:478034 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:00:21  [ pool-135-thread-1:478034 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:21  [ pool-135-thread-1:478034 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:00:21  [ pool-135-thread-1:478035 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:21  [ pool-135-thread-1:478035 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 13:00:21  [ pool-135-thread-1:478035 ] - [ INFO ]  Merged 1 segments, 2113 bytes to disk to satisfy reduce memory limit
2020-11-20 13:00:21  [ pool-135-thread-1:478035 ] - [ INFO ]  Merging 1 files, 2117 bytes from disk
2020-11-20 13:00:21  [ pool-135-thread-1:478035 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:00:21  [ pool-135-thread-1:478035 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:21  [ pool-135-thread-1:478036 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 13:00:21  [ pool-135-thread-1:478036 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:21  [ main:478106 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:00:21  [ pool-135-thread-1:478174 ] - [ INFO ]  Task:attempt_local1908980227_0044_r_000000_0 is done. And is in the process of committing
2020-11-20 13:00:21  [ pool-135-thread-1:478203 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:21  [ pool-135-thread-1:478203 ] - [ INFO ]  Task attempt_local1908980227_0044_r_000000_0 is allowed to commit now
2020-11-20 13:00:21  [ pool-135-thread-1:478237 ] - [ INFO ]  Saved output of task 'attempt_local1908980227_0044_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1908980227_0044_r_000000
2020-11-20 13:00:21  [ pool-135-thread-1:478237 ] - [ INFO ]  reduce > reduce
2020-11-20 13:00:21  [ pool-135-thread-1:478237 ] - [ INFO ]  Task 'attempt_local1908980227_0044_r_000000_0' done.
2020-11-20 13:00:21  [ pool-135-thread-1:478237 ] - [ INFO ]  Finishing task: attempt_local1908980227_0044_r_000000_0
2020-11-20 13:00:21  [ Thread-1191:478237 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:00:22  [ main:479108 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:00:22  [ main:479108 ] - [ INFO ]  Job job_local1908980227_0044 completed successfully
2020-11-20 13:00:22  [ main:479110 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=386910
		FILE: Number of bytes written=27427119
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=124821000
		HDFS: Number of bytes written=182528
		HDFS: Number of read operations=1314
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=693
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2402
		Map output materialized bytes=2117
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2117
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=1217396736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:00:22  [ main:479140 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:00:22  [ main:479154 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:00:22  [ main:479158 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:00:22  [ main:479167 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:00:22  [ main:479209 ] - [ INFO ]  number of splits:1
2020-11-20 13:00:22  [ main:479225 ] - [ INFO ]  Submitting tokens for job: job_local2135210667_0045
2020-11-20 13:00:22  [ main:479261 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:00:22  [ main:479261 ] - [ INFO ]  Running job: job_local2135210667_0045
2020-11-20 13:00:22  [ Thread-1218:479261 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:00:22  [ Thread-1218:479261 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:22  [ Thread-1218:479261 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:00:22  [ Thread-1218:479272 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479272 ] - [ INFO ]  Starting task: attempt_local2135210667_0045_m_000000_0
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479272 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479272 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479272 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479273 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479281 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479281 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479281 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479281 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479281 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:00:22  [ LocalJobRunner Map Task Executor #0:479281 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:00:23  [ main:480264 ] - [ INFO ]  Job job_local2135210667_0045 running in uber mode : false
2020-11-20 13:00:23  [ main:480264 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:00:28  [ communication thread:485275 ] - [ INFO ]  map > map
2020-11-20 13:00:28  [ main:485277 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:00:31  [ communication thread:488280 ] - [ INFO ]  map > map
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488782 ] - [ INFO ]  map > map
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488782 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488782 ] - [ INFO ]  Spilling map output
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488782 ] - [ INFO ]  bufstart = 0; bufend = 2404; bufvoid = 104857600
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488782 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488783 ] - [ INFO ]  Finished spill 0
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488784 ] - [ INFO ]  Task:attempt_local2135210667_0045_m_000000_0 is done. And is in the process of committing
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488793 ] - [ INFO ]  map
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488793 ] - [ INFO ]  Task 'attempt_local2135210667_0045_m_000000_0' done.
2020-11-20 13:00:31  [ LocalJobRunner Map Task Executor #0:488793 ] - [ INFO ]  Finishing task: attempt_local2135210667_0045_m_000000_0
2020-11-20 13:00:31  [ Thread-1218:488794 ] - [ INFO ]  map task executor complete.
2020-11-20 13:00:31  [ Thread-1218:488794 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:00:31  [ pool-138-thread-1:488794 ] - [ INFO ]  Starting task: attempt_local2135210667_0045_r_000000_0
2020-11-20 13:00:31  [ pool-138-thread-1:488794 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:31  [ pool-138-thread-1:488794 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:31  [ pool-138-thread-1:488794 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:31  [ pool-138-thread-1:488794 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23a210a3
2020-11-20 13:00:31  [ pool-138-thread-1:488795 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:00:31  [ EventFetcher for fetching Map Completion Events:488795 ] - [ INFO ]  attempt_local2135210667_0045_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:00:31  [ localfetcher#45:488796 ] - [ INFO ]  localfetcher#45 about to shuffle output of map attempt_local2135210667_0045_m_000000_0 decomp: 2115 len: 2119 to MEMORY
2020-11-20 13:00:31  [ localfetcher#45:488796 ] - [ INFO ]  Read 2115 bytes from map-output for attempt_local2135210667_0045_m_000000_0
2020-11-20 13:00:31  [ localfetcher#45:488796 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2115, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2115
2020-11-20 13:00:31  [ EventFetcher for fetching Map Completion Events:488796 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:00:31  [ pool-138-thread-1:488796 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:31  [ pool-138-thread-1:488796 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:00:31  [ pool-138-thread-1:488797 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:31  [ pool-138-thread-1:488797 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 13:00:31  [ pool-138-thread-1:488798 ] - [ INFO ]  Merged 1 segments, 2115 bytes to disk to satisfy reduce memory limit
2020-11-20 13:00:31  [ pool-138-thread-1:488798 ] - [ INFO ]  Merging 1 files, 2119 bytes from disk
2020-11-20 13:00:31  [ pool-138-thread-1:488798 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:00:31  [ pool-138-thread-1:488798 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:31  [ pool-138-thread-1:488798 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 13:00:31  [ pool-138-thread-1:488798 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:31  [ pool-138-thread-1:488931 ] - [ INFO ]  Task:attempt_local2135210667_0045_r_000000_0 is done. And is in the process of committing
2020-11-20 13:00:31  [ pool-138-thread-1:488940 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:31  [ pool-138-thread-1:488940 ] - [ INFO ]  Task attempt_local2135210667_0045_r_000000_0 is allowed to commit now
2020-11-20 13:00:31  [ pool-138-thread-1:488973 ] - [ INFO ]  Saved output of task 'attempt_local2135210667_0045_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2135210667_0045_r_000000
2020-11-20 13:00:31  [ pool-138-thread-1:488974 ] - [ INFO ]  reduce > reduce
2020-11-20 13:00:31  [ pool-138-thread-1:488974 ] - [ INFO ]  Task 'attempt_local2135210667_0045_r_000000_0' done.
2020-11-20 13:00:31  [ pool-138-thread-1:488974 ] - [ INFO ]  Finishing task: attempt_local2135210667_0045_r_000000_0
2020-11-20 13:00:31  [ Thread-1218:488974 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:00:32  [ main:489284 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:00:32  [ main:489284 ] - [ INFO ]  Job job_local2135210667_0045 completed successfully
2020-11-20 13:00:32  [ main:489285 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=395828
		FILE: Number of bytes written=28055515
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=127594800
		HDFS: Number of bytes written=186738
		HDFS: Number of read operations=1344
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=709
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2404
		Map output materialized bytes=2119
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2119
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=1328545792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:00:32  [ main:489323 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:00:32  [ main:489337 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:00:32  [ main:489341 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:00:32  [ main:489352 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:00:32  [ main:489397 ] - [ INFO ]  number of splits:1
2020-11-20 13:00:32  [ main:489413 ] - [ INFO ]  Submitting tokens for job: job_local1964756167_0046
2020-11-20 13:00:32  [ main:489447 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:00:32  [ main:489447 ] - [ INFO ]  Running job: job_local1964756167_0046
2020-11-20 13:00:32  [ Thread-1245:489447 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:00:32  [ Thread-1245:489447 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:32  [ Thread-1245:489447 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:00:32  [ Thread-1245:489460 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489460 ] - [ INFO ]  Starting task: attempt_local1964756167_0046_m_000000_0
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489461 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489461 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489461 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489461 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489470 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489470 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489470 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489470 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489470 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:00:32  [ LocalJobRunner Map Task Executor #0:489470 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:00:33  [ main:490449 ] - [ INFO ]  Job job_local1964756167_0046 running in uber mode : false
2020-11-20 13:00:33  [ main:490449 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:00:38  [ communication thread:495469 ] - [ INFO ]  map > map
2020-11-20 13:00:39  [ main:496471 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:00:41  [ communication thread:498471 ] - [ INFO ]  map > map
2020-11-20 13:00:41  [ main:498478 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499175 ] - [ INFO ]  map > map
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499175 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499175 ] - [ INFO ]  Spilling map output
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499175 ] - [ INFO ]  bufstart = 0; bufend = 2395; bufvoid = 104857600
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499175 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499176 ] - [ INFO ]  Finished spill 0
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499177 ] - [ INFO ]  Task:attempt_local1964756167_0046_m_000000_0 is done. And is in the process of committing
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499187 ] - [ INFO ]  map
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499187 ] - [ INFO ]  Task 'attempt_local1964756167_0046_m_000000_0' done.
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499187 ] - [ INFO ]  Finishing task: attempt_local1964756167_0046_m_000000_0
2020-11-20 13:00:42  [ Thread-1245:499187 ] - [ INFO ]  map task executor complete.
2020-11-20 13:00:42  [ Thread-1245:499187 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:00:42  [ pool-141-thread-1:499187 ] - [ INFO ]  Starting task: attempt_local1964756167_0046_r_000000_0
2020-11-20 13:00:42  [ pool-141-thread-1:499188 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:42  [ pool-141-thread-1:499188 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:42  [ pool-141-thread-1:499188 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:42  [ pool-141-thread-1:499188 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b721872
2020-11-20 13:00:42  [ pool-141-thread-1:499189 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:00:42  [ EventFetcher for fetching Map Completion Events:499189 ] - [ INFO ]  attempt_local1964756167_0046_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:00:42  [ localfetcher#46:499190 ] - [ INFO ]  localfetcher#46 about to shuffle output of map attempt_local1964756167_0046_m_000000_0 decomp: 2106 len: 2110 to MEMORY
2020-11-20 13:00:42  [ localfetcher#46:499190 ] - [ INFO ]  Read 2106 bytes from map-output for attempt_local1964756167_0046_m_000000_0
2020-11-20 13:00:42  [ localfetcher#46:499190 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2106, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2106
2020-11-20 13:00:42  [ EventFetcher for fetching Map Completion Events:499190 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:00:42  [ pool-141-thread-1:499190 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:42  [ pool-141-thread-1:499190 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:00:42  [ pool-141-thread-1:499191 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:42  [ pool-141-thread-1:499191 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2099 bytes
2020-11-20 13:00:42  [ pool-141-thread-1:499191 ] - [ INFO ]  Merged 1 segments, 2106 bytes to disk to satisfy reduce memory limit
2020-11-20 13:00:42  [ pool-141-thread-1:499191 ] - [ INFO ]  Merging 1 files, 2110 bytes from disk
2020-11-20 13:00:42  [ pool-141-thread-1:499191 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:00:42  [ pool-141-thread-1:499191 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:42  [ pool-141-thread-1:499192 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2099 bytes
2020-11-20 13:00:42  [ pool-141-thread-1:499192 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:42  [ pool-141-thread-1:499313 ] - [ INFO ]  Task:attempt_local1964756167_0046_r_000000_0 is done. And is in the process of committing
2020-11-20 13:00:42  [ pool-141-thread-1:499323 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:42  [ pool-141-thread-1:499323 ] - [ INFO ]  Task attempt_local1964756167_0046_r_000000_0 is allowed to commit now
2020-11-20 13:00:42  [ pool-141-thread-1:499354 ] - [ INFO ]  Saved output of task 'attempt_local1964756167_0046_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1964756167_0046_r_000000
2020-11-20 13:00:42  [ pool-141-thread-1:499355 ] - [ INFO ]  reduce > reduce
2020-11-20 13:00:42  [ pool-141-thread-1:499355 ] - [ INFO ]  Task 'attempt_local1964756167_0046_r_000000_0' done.
2020-11-20 13:00:42  [ pool-141-thread-1:499355 ] - [ INFO ]  Finishing task: attempt_local1964756167_0046_r_000000_0
2020-11-20 13:00:42  [ Thread-1245:499355 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:00:42  [ main:499478 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:00:42  [ main:499479 ] - [ INFO ]  Job job_local1964756167_0046 completed successfully
2020-11-20 13:00:42  [ main:499481 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=404732
		FILE: Number of bytes written=28684042
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=130368600
		HDFS: Number of bytes written=190941
		HDFS: Number of read operations=1374
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=725
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2395
		Map output materialized bytes=2110
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2110
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1321205760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:00:42  [ main:499510 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:00:42  [ main:499526 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:00:42  [ main:499530 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:00:42  [ main:499542 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:00:42  [ main:499587 ] - [ INFO ]  number of splits:1
2020-11-20 13:00:42  [ main:499603 ] - [ INFO ]  Submitting tokens for job: job_local1555304503_0047
2020-11-20 13:00:42  [ main:499637 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:00:42  [ main:499637 ] - [ INFO ]  Running job: job_local1555304503_0047
2020-11-20 13:00:42  [ Thread-1272:499637 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:00:42  [ Thread-1272:499638 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:42  [ Thread-1272:499638 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:00:42  [ Thread-1272:499650 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499650 ] - [ INFO ]  Starting task: attempt_local1555304503_0047_m_000000_0
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499651 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499651 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499651 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499651 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499658 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499659 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499659 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499659 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499659 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:00:42  [ LocalJobRunner Map Task Executor #0:499659 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:00:43  [ main:500641 ] - [ INFO ]  Job job_local1555304503_0047 running in uber mode : false
2020-11-20 13:00:43  [ main:500641 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:00:48  [ communication thread:505655 ] - [ INFO ]  map > map
2020-11-20 13:00:48  [ main:505661 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:00:51  [ communication thread:508657 ] - [ INFO ]  map > map
2020-11-20 13:00:51  [ main:508672 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509718 ] - [ INFO ]  map > map
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509719 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509719 ] - [ INFO ]  Spilling map output
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509719 ] - [ INFO ]  bufstart = 0; bufend = 2387; bufvoid = 104857600
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509719 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509720 ] - [ INFO ]  Finished spill 0
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509721 ] - [ INFO ]  Task:attempt_local1555304503_0047_m_000000_0 is done. And is in the process of committing
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509740 ] - [ INFO ]  map
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509740 ] - [ INFO ]  Task 'attempt_local1555304503_0047_m_000000_0' done.
2020-11-20 13:00:52  [ LocalJobRunner Map Task Executor #0:509740 ] - [ INFO ]  Finishing task: attempt_local1555304503_0047_m_000000_0
2020-11-20 13:00:52  [ Thread-1272:509740 ] - [ INFO ]  map task executor complete.
2020-11-20 13:00:52  [ Thread-1272:509740 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:00:52  [ pool-144-thread-1:509740 ] - [ INFO ]  Starting task: attempt_local1555304503_0047_r_000000_0
2020-11-20 13:00:52  [ pool-144-thread-1:509741 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:52  [ pool-144-thread-1:509741 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:52  [ pool-144-thread-1:509741 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:52  [ pool-144-thread-1:509741 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50537b5b
2020-11-20 13:00:52  [ pool-144-thread-1:509742 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:00:52  [ EventFetcher for fetching Map Completion Events:509742 ] - [ INFO ]  attempt_local1555304503_0047_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:00:52  [ localfetcher#47:509743 ] - [ INFO ]  localfetcher#47 about to shuffle output of map attempt_local1555304503_0047_m_000000_0 decomp: 2098 len: 2102 to MEMORY
2020-11-20 13:00:52  [ localfetcher#47:509743 ] - [ INFO ]  Read 2098 bytes from map-output for attempt_local1555304503_0047_m_000000_0
2020-11-20 13:00:52  [ localfetcher#47:509743 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2098, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2098
2020-11-20 13:00:52  [ EventFetcher for fetching Map Completion Events:509743 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:00:52  [ pool-144-thread-1:509743 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:52  [ pool-144-thread-1:509743 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2091 bytes
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Merged 1 segments, 2098 bytes to disk to satisfy reduce memory limit
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Merging 1 files, 2102 bytes from disk
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2091 bytes
2020-11-20 13:00:52  [ pool-144-thread-1:509744 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:52  [ pool-144-thread-1:509903 ] - [ INFO ]  Task:attempt_local1555304503_0047_r_000000_0 is done. And is in the process of committing
2020-11-20 13:00:52  [ pool-144-thread-1:509913 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:00:52  [ pool-144-thread-1:509913 ] - [ INFO ]  Task attempt_local1555304503_0047_r_000000_0 is allowed to commit now
2020-11-20 13:00:52  [ pool-144-thread-1:509945 ] - [ INFO ]  Saved output of task 'attempt_local1555304503_0047_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1555304503_0047_r_000000
2020-11-20 13:00:52  [ pool-144-thread-1:509945 ] - [ INFO ]  reduce > reduce
2020-11-20 13:00:52  [ pool-144-thread-1:509945 ] - [ INFO ]  Task 'attempt_local1555304503_0047_r_000000_0' done.
2020-11-20 13:00:52  [ pool-144-thread-1:509945 ] - [ INFO ]  Finishing task: attempt_local1555304503_0047_r_000000_0
2020-11-20 13:00:52  [ Thread-1272:509945 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:00:53  [ main:510675 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:00:53  [ main:510675 ] - [ INFO ]  Job job_local1555304503_0047 completed successfully
2020-11-20 13:00:53  [ main:510677 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=413602
		FILE: Number of bytes written=29312608
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=133142400
		HDFS: Number of bytes written=195127
		HDFS: Number of read operations=1404
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=741
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2387
		Map output materialized bytes=2102
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2102
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=32
		Total committed heap usage (bytes)=1262485504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:00:53  [ main:510707 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:00:53  [ main:510722 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:00:53  [ main:510726 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:00:53  [ main:510735 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:00:53  [ main:510776 ] - [ INFO ]  number of splits:1
2020-11-20 13:00:53  [ main:510793 ] - [ INFO ]  Submitting tokens for job: job_local1794595095_0048
2020-11-20 13:00:53  [ main:510830 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:00:53  [ main:510830 ] - [ INFO ]  Running job: job_local1794595095_0048
2020-11-20 13:00:53  [ Thread-1300:510830 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:00:53  [ Thread-1300:510830 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:53  [ Thread-1300:510830 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:00:53  [ Thread-1300:510842 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510842 ] - [ INFO ]  Starting task: attempt_local1794595095_0048_m_000000_0
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510842 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510842 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510842 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510843 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510851 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510851 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510851 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510851 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510851 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:00:53  [ LocalJobRunner Map Task Executor #0:510852 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:00:54  [ main:511834 ] - [ INFO ]  Job job_local1794595095_0048 running in uber mode : false
2020-11-20 13:00:54  [ main:511834 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:00:59  [ communication thread:516848 ] - [ INFO ]  map > map
2020-11-20 13:01:00  [ main:517849 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:01:02  [ communication thread:519853 ] - [ INFO ]  map > map
2020-11-20 13:01:02  [ main:519853 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520357 ] - [ INFO ]  map > map
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520357 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520357 ] - [ INFO ]  Spilling map output
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520357 ] - [ INFO ]  bufstart = 0; bufend = 2383; bufvoid = 104857600
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520357 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520358 ] - [ INFO ]  Finished spill 0
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520359 ] - [ INFO ]  Task:attempt_local1794595095_0048_m_000000_0 is done. And is in the process of committing
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520382 ] - [ INFO ]  map
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520382 ] - [ INFO ]  Task 'attempt_local1794595095_0048_m_000000_0' done.
2020-11-20 13:01:03  [ LocalJobRunner Map Task Executor #0:520382 ] - [ INFO ]  Finishing task: attempt_local1794595095_0048_m_000000_0
2020-11-20 13:01:03  [ Thread-1300:520382 ] - [ INFO ]  map task executor complete.
2020-11-20 13:01:03  [ Thread-1300:520382 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:01:03  [ pool-147-thread-1:520382 ] - [ INFO ]  Starting task: attempt_local1794595095_0048_r_000000_0
2020-11-20 13:01:03  [ pool-147-thread-1:520383 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:03  [ pool-147-thread-1:520383 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:03  [ pool-147-thread-1:520383 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:03  [ pool-147-thread-1:520383 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17d9996b
2020-11-20 13:01:03  [ pool-147-thread-1:520384 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:01:03  [ EventFetcher for fetching Map Completion Events:520385 ] - [ INFO ]  attempt_local1794595095_0048_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:01:03  [ localfetcher#48:520385 ] - [ INFO ]  localfetcher#48 about to shuffle output of map attempt_local1794595095_0048_m_000000_0 decomp: 2094 len: 2098 to MEMORY
2020-11-20 13:01:03  [ localfetcher#48:520385 ] - [ INFO ]  Read 2094 bytes from map-output for attempt_local1794595095_0048_m_000000_0
2020-11-20 13:01:03  [ localfetcher#48:520386 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2094, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2094
2020-11-20 13:01:03  [ EventFetcher for fetching Map Completion Events:520386 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:01:03  [ pool-147-thread-1:520386 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:03  [ pool-147-thread-1:520386 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:01:03  [ pool-147-thread-1:520387 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:03  [ pool-147-thread-1:520387 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2087 bytes
2020-11-20 13:01:03  [ pool-147-thread-1:520387 ] - [ INFO ]  Merged 1 segments, 2094 bytes to disk to satisfy reduce memory limit
2020-11-20 13:01:03  [ pool-147-thread-1:520388 ] - [ INFO ]  Merging 1 files, 2098 bytes from disk
2020-11-20 13:01:03  [ pool-147-thread-1:520388 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:01:03  [ pool-147-thread-1:520388 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:03  [ pool-147-thread-1:520388 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2087 bytes
2020-11-20 13:01:03  [ pool-147-thread-1:520388 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:03  [ pool-147-thread-1:520595 ] - [ INFO ]  Task:attempt_local1794595095_0048_r_000000_0 is done. And is in the process of committing
2020-11-20 13:01:03  [ pool-147-thread-1:520818 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:03  [ pool-147-thread-1:520818 ] - [ INFO ]  Task attempt_local1794595095_0048_r_000000_0 is allowed to commit now
2020-11-20 13:01:03  [ main:520856 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:01:03  [ pool-147-thread-1:520859 ] - [ INFO ]  Saved output of task 'attempt_local1794595095_0048_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1794595095_0048_r_000000
2020-11-20 13:01:03  [ pool-147-thread-1:520862 ] - [ INFO ]  reduce > reduce
2020-11-20 13:01:03  [ pool-147-thread-1:520862 ] - [ INFO ]  Task 'attempt_local1794595095_0048_r_000000_0' done.
2020-11-20 13:01:03  [ pool-147-thread-1:520862 ] - [ INFO ]  Finishing task: attempt_local1794595095_0048_r_000000_0
2020-11-20 13:01:03  [ Thread-1300:520862 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:01:04  [ main:521859 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:01:04  [ main:521859 ] - [ INFO ]  Job job_local1794595095_0048 completed successfully
2020-11-20 13:01:04  [ main:521860 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=422448
		FILE: Number of bytes written=29941278
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=135916200
		HDFS: Number of bytes written=199301
		HDFS: Number of read operations=1434
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=757
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2383
		Map output materialized bytes=2098
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2098
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=48
		Total committed heap usage (bytes)=1319108608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:01:04  [ main:521893 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:01:04  [ main:521906 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:01:04  [ main:521911 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:01:04  [ main:521921 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:01:05  [ main:522010 ] - [ INFO ]  number of splits:1
2020-11-20 13:01:05  [ main:522028 ] - [ INFO ]  Submitting tokens for job: job_local1081159644_0049
2020-11-20 13:01:05  [ main:522063 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:01:05  [ main:522063 ] - [ INFO ]  Running job: job_local1081159644_0049
2020-11-20 13:01:05  [ Thread-1327:522063 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:01:05  [ Thread-1327:522064 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:05  [ Thread-1327:522064 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:01:05  [ Thread-1327:522075 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522075 ] - [ INFO ]  Starting task: attempt_local1081159644_0049_m_000000_0
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522076 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522076 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522076 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522076 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522084 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522084 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522084 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522084 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522084 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:01:05  [ LocalJobRunner Map Task Executor #0:522084 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:01:06  [ main:523068 ] - [ INFO ]  Job job_local1081159644_0049 running in uber mode : false
2020-11-20 13:01:06  [ main:523068 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:01:11  [ communication thread:528083 ] - [ INFO ]  map > map
2020-11-20 13:01:12  [ main:529086 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:01:14  [ communication thread:531087 ] - [ INFO ]  map > map
2020-11-20 13:01:14  [ main:531091 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531560 ] - [ INFO ]  map > map
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531560 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531560 ] - [ INFO ]  Spilling map output
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531560 ] - [ INFO ]  bufstart = 0; bufend = 2368; bufvoid = 104857600
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531560 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531562 ] - [ INFO ]  Finished spill 0
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531563 ] - [ INFO ]  Task:attempt_local1081159644_0049_m_000000_0 is done. And is in the process of committing
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531572 ] - [ INFO ]  map
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531572 ] - [ INFO ]  Task 'attempt_local1081159644_0049_m_000000_0' done.
2020-11-20 13:01:14  [ LocalJobRunner Map Task Executor #0:531572 ] - [ INFO ]  Finishing task: attempt_local1081159644_0049_m_000000_0
2020-11-20 13:01:14  [ Thread-1327:531573 ] - [ INFO ]  map task executor complete.
2020-11-20 13:01:14  [ Thread-1327:531573 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:01:14  [ pool-150-thread-1:531573 ] - [ INFO ]  Starting task: attempt_local1081159644_0049_r_000000_0
2020-11-20 13:01:14  [ pool-150-thread-1:531574 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:14  [ pool-150-thread-1:531574 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:14  [ pool-150-thread-1:531574 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:14  [ pool-150-thread-1:531574 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@501870ea
2020-11-20 13:01:14  [ pool-150-thread-1:531575 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:01:14  [ EventFetcher for fetching Map Completion Events:531575 ] - [ INFO ]  attempt_local1081159644_0049_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:01:14  [ localfetcher#49:531576 ] - [ INFO ]  localfetcher#49 about to shuffle output of map attempt_local1081159644_0049_m_000000_0 decomp: 2079 len: 2083 to MEMORY
2020-11-20 13:01:14  [ localfetcher#49:531576 ] - [ INFO ]  Read 2079 bytes from map-output for attempt_local1081159644_0049_m_000000_0
2020-11-20 13:01:14  [ localfetcher#49:531576 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2079, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2079
2020-11-20 13:01:14  [ EventFetcher for fetching Map Completion Events:531576 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:01:14  [ pool-150-thread-1:531576 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:14  [ pool-150-thread-1:531576 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:01:14  [ pool-150-thread-1:531577 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:14  [ pool-150-thread-1:531577 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2072 bytes
2020-11-20 13:01:14  [ pool-150-thread-1:531577 ] - [ INFO ]  Merged 1 segments, 2079 bytes to disk to satisfy reduce memory limit
2020-11-20 13:01:14  [ pool-150-thread-1:531578 ] - [ INFO ]  Merging 1 files, 2083 bytes from disk
2020-11-20 13:01:14  [ pool-150-thread-1:531578 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:01:14  [ pool-150-thread-1:531578 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:14  [ pool-150-thread-1:531578 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2072 bytes
2020-11-20 13:01:14  [ pool-150-thread-1:531578 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:14  [ pool-150-thread-1:531689 ] - [ INFO ]  Task:attempt_local1081159644_0049_r_000000_0 is done. And is in the process of committing
2020-11-20 13:01:14  [ pool-150-thread-1:531698 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:14  [ pool-150-thread-1:531698 ] - [ INFO ]  Task attempt_local1081159644_0049_r_000000_0 is allowed to commit now
2020-11-20 13:01:14  [ pool-150-thread-1:531725 ] - [ INFO ]  Saved output of task 'attempt_local1081159644_0049_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1081159644_0049_r_000000
2020-11-20 13:01:14  [ pool-150-thread-1:531725 ] - [ INFO ]  reduce > reduce
2020-11-20 13:01:14  [ pool-150-thread-1:531725 ] - [ INFO ]  Task 'attempt_local1081159644_0049_r_000000_0' done.
2020-11-20 13:01:14  [ pool-150-thread-1:531725 ] - [ INFO ]  Finishing task: attempt_local1081159644_0049_r_000000_0
2020-11-20 13:01:14  [ Thread-1327:531725 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:01:15  [ main:532097 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:01:15  [ main:532097 ] - [ INFO ]  Job job_local1081159644_0049 completed successfully
2020-11-20 13:01:15  [ main:532099 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=431256
		FILE: Number of bytes written=30570135
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=138690000
		HDFS: Number of bytes written=203456
		HDFS: Number of read operations=1464
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=773
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2368
		Map output materialized bytes=2083
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2083
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1312817152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:01:15  [ main:532133 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:01:15  [ main:532147 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:01:15  [ main:532151 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:01:15  [ main:532177 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:01:15  [ main:532220 ] - [ INFO ]  number of splits:1
2020-11-20 13:01:15  [ main:532237 ] - [ INFO ]  Submitting tokens for job: job_local1312535392_0050
2020-11-20 13:01:15  [ main:532276 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:01:15  [ main:532276 ] - [ INFO ]  Running job: job_local1312535392_0050
2020-11-20 13:01:15  [ Thread-1354:532276 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:01:15  [ Thread-1354:532276 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:15  [ Thread-1354:532276 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:01:15  [ Thread-1354:532287 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532287 ] - [ INFO ]  Starting task: attempt_local1312535392_0050_m_000000_0
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532287 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532287 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532287 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532288 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532296 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532296 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532296 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532296 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532296 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:01:15  [ LocalJobRunner Map Task Executor #0:532296 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:01:16  [ main:533278 ] - [ INFO ]  Job job_local1312535392_0050 running in uber mode : false
2020-11-20 13:01:16  [ main:533278 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:01:21  [ communication thread:538298 ] - [ INFO ]  map > map
2020-11-20 13:01:22  [ main:539292 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:01:24  [ communication thread:541303 ] - [ INFO ]  map > map
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542123 ] - [ INFO ]  map > map
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542123 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542123 ] - [ INFO ]  Spilling map output
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542123 ] - [ INFO ]  bufstart = 0; bufend = 2381; bufvoid = 104857600
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542123 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542125 ] - [ INFO ]  Finished spill 0
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542126 ] - [ INFO ]  Task:attempt_local1312535392_0050_m_000000_0 is done. And is in the process of committing
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542137 ] - [ INFO ]  map
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542137 ] - [ INFO ]  Task 'attempt_local1312535392_0050_m_000000_0' done.
2020-11-20 13:01:25  [ LocalJobRunner Map Task Executor #0:542137 ] - [ INFO ]  Finishing task: attempt_local1312535392_0050_m_000000_0
2020-11-20 13:01:25  [ Thread-1354:542137 ] - [ INFO ]  map task executor complete.
2020-11-20 13:01:25  [ Thread-1354:542137 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:01:25  [ pool-153-thread-1:542138 ] - [ INFO ]  Starting task: attempt_local1312535392_0050_r_000000_0
2020-11-20 13:01:25  [ pool-153-thread-1:542138 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:25  [ pool-153-thread-1:542138 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:25  [ pool-153-thread-1:542138 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:25  [ pool-153-thread-1:542138 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4745a445
2020-11-20 13:01:25  [ pool-153-thread-1:542140 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:01:25  [ EventFetcher for fetching Map Completion Events:542140 ] - [ INFO ]  attempt_local1312535392_0050_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:01:25  [ localfetcher#50:542141 ] - [ INFO ]  localfetcher#50 about to shuffle output of map attempt_local1312535392_0050_m_000000_0 decomp: 2092 len: 2096 to MEMORY
2020-11-20 13:01:25  [ localfetcher#50:542141 ] - [ INFO ]  Read 2092 bytes from map-output for attempt_local1312535392_0050_m_000000_0
2020-11-20 13:01:25  [ localfetcher#50:542141 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2092, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2092
2020-11-20 13:01:25  [ EventFetcher for fetching Map Completion Events:542141 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:01:25  [ pool-153-thread-1:542142 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:25  [ pool-153-thread-1:542142 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:01:25  [ pool-153-thread-1:542142 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  Merged 1 segments, 2092 bytes to disk to satisfy reduce memory limit
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  Merging 1 files, 2096 bytes from disk
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 13:01:25  [ pool-153-thread-1:542143 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:25  [ pool-153-thread-1:542301 ] - [ INFO ]  Task:attempt_local1312535392_0050_r_000000_0 is done. And is in the process of committing
2020-11-20 13:01:25  [ main:542303 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:01:25  [ pool-153-thread-1:542311 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:25  [ pool-153-thread-1:542311 ] - [ INFO ]  Task attempt_local1312535392_0050_r_000000_0 is allowed to commit now
2020-11-20 13:01:25  [ pool-153-thread-1:542373 ] - [ INFO ]  Saved output of task 'attempt_local1312535392_0050_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1312535392_0050_r_000000
2020-11-20 13:01:25  [ pool-153-thread-1:542373 ] - [ INFO ]  reduce > reduce
2020-11-20 13:01:25  [ pool-153-thread-1:542373 ] - [ INFO ]  Task 'attempt_local1312535392_0050_r_000000_0' done.
2020-11-20 13:01:25  [ pool-153-thread-1:542373 ] - [ INFO ]  Finishing task: attempt_local1312535392_0050_r_000000_0
2020-11-20 13:01:25  [ Thread-1354:542373 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:01:26  [ main:543308 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:01:26  [ main:543308 ] - [ INFO ]  Job job_local1312535392_0050 completed successfully
2020-11-20 13:01:26  [ main:543310 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=440060
		FILE: Number of bytes written=31200536
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=141463800
		HDFS: Number of bytes written=207609
		HDFS: Number of read operations=1494
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=789
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2381
		Map output materialized bytes=2096
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2096
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=1337982976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:01:26  [ main:543339 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:01:26  [ main:543355 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:01:26  [ main:543360 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:01:26  [ main:543369 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:01:26  [ main:543413 ] - [ INFO ]  number of splits:1
2020-11-20 13:01:26  [ main:543430 ] - [ INFO ]  Submitting tokens for job: job_local1988165477_0051
2020-11-20 13:01:26  [ main:543465 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:01:26  [ main:543465 ] - [ INFO ]  Running job: job_local1988165477_0051
2020-11-20 13:01:26  [ Thread-1381:543465 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:01:26  [ Thread-1381:543465 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:26  [ Thread-1381:543465 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:01:26  [ Thread-1381:543476 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543476 ] - [ INFO ]  Starting task: attempt_local1988165477_0051_m_000000_0
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543476 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543477 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543477 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543477 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543485 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543485 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543485 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543485 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543485 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:01:26  [ LocalJobRunner Map Task Executor #0:543486 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:01:27  [ main:544469 ] - [ INFO ]  Job job_local1988165477_0051 running in uber mode : false
2020-11-20 13:01:27  [ main:544469 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:01:32  [ communication thread:549486 ] - [ INFO ]  map > map
2020-11-20 13:01:33  [ main:550487 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:01:35  [ communication thread:552487 ] - [ INFO ]  map > map
2020-11-20 13:01:35  [ main:552493 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553136 ] - [ INFO ]  map > map
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553136 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553136 ] - [ INFO ]  Spilling map output
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553136 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553136 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553138 ] - [ INFO ]  Finished spill 0
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553138 ] - [ INFO ]  Task:attempt_local1988165477_0051_m_000000_0 is done. And is in the process of committing
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553149 ] - [ INFO ]  map
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553149 ] - [ INFO ]  Task 'attempt_local1988165477_0051_m_000000_0' done.
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553149 ] - [ INFO ]  Finishing task: attempt_local1988165477_0051_m_000000_0
2020-11-20 13:01:36  [ Thread-1381:553149 ] - [ INFO ]  map task executor complete.
2020-11-20 13:01:36  [ Thread-1381:553149 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:01:36  [ pool-156-thread-1:553149 ] - [ INFO ]  Starting task: attempt_local1988165477_0051_r_000000_0
2020-11-20 13:01:36  [ pool-156-thread-1:553150 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:36  [ pool-156-thread-1:553150 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:36  [ pool-156-thread-1:553150 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:36  [ pool-156-thread-1:553150 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@752a2993
2020-11-20 13:01:36  [ pool-156-thread-1:553152 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:01:36  [ EventFetcher for fetching Map Completion Events:553152 ] - [ INFO ]  attempt_local1988165477_0051_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:01:36  [ localfetcher#51:553153 ] - [ INFO ]  localfetcher#51 about to shuffle output of map attempt_local1988165477_0051_m_000000_0 decomp: 2119 len: 2123 to MEMORY
2020-11-20 13:01:36  [ localfetcher#51:553153 ] - [ INFO ]  Read 2119 bytes from map-output for attempt_local1988165477_0051_m_000000_0
2020-11-20 13:01:36  [ localfetcher#51:553153 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2119
2020-11-20 13:01:36  [ EventFetcher for fetching Map Completion Events:553153 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:01:36  [ pool-156-thread-1:553153 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:36  [ pool-156-thread-1:553153 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:01:36  [ pool-156-thread-1:553154 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:36  [ pool-156-thread-1:553154 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:01:36  [ pool-156-thread-1:553154 ] - [ INFO ]  Merged 1 segments, 2119 bytes to disk to satisfy reduce memory limit
2020-11-20 13:01:36  [ pool-156-thread-1:553154 ] - [ INFO ]  Merging 1 files, 2123 bytes from disk
2020-11-20 13:01:36  [ pool-156-thread-1:553154 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:01:36  [ pool-156-thread-1:553155 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:36  [ pool-156-thread-1:553155 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:01:36  [ pool-156-thread-1:553155 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:36  [ pool-156-thread-1:553294 ] - [ INFO ]  Task:attempt_local1988165477_0051_r_000000_0 is done. And is in the process of committing
2020-11-20 13:01:36  [ pool-156-thread-1:553310 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:36  [ pool-156-thread-1:553310 ] - [ INFO ]  Task attempt_local1988165477_0051_r_000000_0 is allowed to commit now
2020-11-20 13:01:36  [ pool-156-thread-1:553365 ] - [ INFO ]  Saved output of task 'attempt_local1988165477_0051_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1988165477_0051_r_000000
2020-11-20 13:01:36  [ pool-156-thread-1:553366 ] - [ INFO ]  reduce > reduce
2020-11-20 13:01:36  [ pool-156-thread-1:553366 ] - [ INFO ]  Task 'attempt_local1988165477_0051_r_000000_0' done.
2020-11-20 13:01:36  [ pool-156-thread-1:553366 ] - [ INFO ]  Finishing task: attempt_local1988165477_0051_r_000000_0
2020-11-20 13:01:36  [ Thread-1381:553366 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:01:36  [ main:553494 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:01:36  [ main:553494 ] - [ INFO ]  Job job_local1988165477_0051 completed successfully
2020-11-20 13:01:36  [ main:553496 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=448944
		FILE: Number of bytes written=31831111
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=144237600
		HDFS: Number of bytes written=211802
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=805
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2408
		Map output materialized bytes=2123
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2123
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=1375731712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:01:36  [ main:553528 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:01:36  [ main:553547 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:01:36  [ main:553551 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:01:36  [ main:553569 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:01:36  [ main:553624 ] - [ INFO ]  number of splits:1
2020-11-20 13:01:36  [ main:553641 ] - [ INFO ]  Submitting tokens for job: job_local1197024672_0052
2020-11-20 13:01:36  [ main:553675 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:01:36  [ main:553675 ] - [ INFO ]  Running job: job_local1197024672_0052
2020-11-20 13:01:36  [ Thread-1408:553676 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:01:36  [ Thread-1408:553676 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:36  [ Thread-1408:553676 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:01:36  [ Thread-1408:553692 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553692 ] - [ INFO ]  Starting task: attempt_local1197024672_0052_m_000000_0
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553692 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553693 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553693 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553693 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553701 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553701 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553701 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553701 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553701 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:01:36  [ LocalJobRunner Map Task Executor #0:553702 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:01:37  [ main:554678 ] - [ INFO ]  Job job_local1197024672_0052 running in uber mode : false
2020-11-20 13:01:37  [ main:554679 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:01:42  [ communication thread:559699 ] - [ INFO ]  map > map
2020-11-20 13:01:43  [ main:560697 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:01:45  [ communication thread:562703 ] - [ INFO ]  map > map
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563404 ] - [ INFO ]  map > map
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563404 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563404 ] - [ INFO ]  Spilling map output
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563404 ] - [ INFO ]  bufstart = 0; bufend = 2394; bufvoid = 104857600
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563404 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563406 ] - [ INFO ]  Finished spill 0
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563407 ] - [ INFO ]  Task:attempt_local1197024672_0052_m_000000_0 is done. And is in the process of committing
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563418 ] - [ INFO ]  map
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563418 ] - [ INFO ]  Task 'attempt_local1197024672_0052_m_000000_0' done.
2020-11-20 13:01:46  [ LocalJobRunner Map Task Executor #0:563418 ] - [ INFO ]  Finishing task: attempt_local1197024672_0052_m_000000_0
2020-11-20 13:01:46  [ Thread-1408:563418 ] - [ INFO ]  map task executor complete.
2020-11-20 13:01:46  [ Thread-1408:563418 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:01:46  [ pool-159-thread-1:563418 ] - [ INFO ]  Starting task: attempt_local1197024672_0052_r_000000_0
2020-11-20 13:01:46  [ pool-159-thread-1:563419 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:46  [ pool-159-thread-1:563419 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:46  [ pool-159-thread-1:563419 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:46  [ pool-159-thread-1:563419 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b06bf4c
2020-11-20 13:01:46  [ pool-159-thread-1:563420 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:01:46  [ EventFetcher for fetching Map Completion Events:563420 ] - [ INFO ]  attempt_local1197024672_0052_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:01:46  [ localfetcher#52:563421 ] - [ INFO ]  localfetcher#52 about to shuffle output of map attempt_local1197024672_0052_m_000000_0 decomp: 2105 len: 2109 to MEMORY
2020-11-20 13:01:46  [ localfetcher#52:563421 ] - [ INFO ]  Read 2105 bytes from map-output for attempt_local1197024672_0052_m_000000_0
2020-11-20 13:01:46  [ localfetcher#52:563421 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2105, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2105
2020-11-20 13:01:46  [ EventFetcher for fetching Map Completion Events:563422 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:01:46  [ pool-159-thread-1:563422 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:46  [ pool-159-thread-1:563422 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2098 bytes
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Merged 1 segments, 2105 bytes to disk to satisfy reduce memory limit
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Merging 1 files, 2109 bytes from disk
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2098 bytes
2020-11-20 13:01:46  [ pool-159-thread-1:563423 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:46  [ pool-159-thread-1:563544 ] - [ INFO ]  Task:attempt_local1197024672_0052_r_000000_0 is done. And is in the process of committing
2020-11-20 13:01:46  [ pool-159-thread-1:563554 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:46  [ pool-159-thread-1:563554 ] - [ INFO ]  Task attempt_local1197024672_0052_r_000000_0 is allowed to commit now
2020-11-20 13:01:46  [ pool-159-thread-1:563588 ] - [ INFO ]  Saved output of task 'attempt_local1197024672_0052_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1197024672_0052_r_000000
2020-11-20 13:01:46  [ pool-159-thread-1:563588 ] - [ INFO ]  reduce > reduce
2020-11-20 13:01:46  [ pool-159-thread-1:563588 ] - [ INFO ]  Task 'attempt_local1197024672_0052_r_000000_0' done.
2020-11-20 13:01:46  [ pool-159-thread-1:563588 ] - [ INFO ]  Finishing task: attempt_local1197024672_0052_r_000000_0
2020-11-20 13:01:46  [ Thread-1408:563588 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:01:46  [ main:563708 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:01:47  [ main:564713 ] - [ INFO ]  Job job_local1197024672_0052 completed successfully
2020-11-20 13:01:47  [ main:564715 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=457854
		FILE: Number of bytes written=32461915
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=147011400
		HDFS: Number of bytes written=216008
		HDFS: Number of read operations=1554
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=821
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2394
		Map output materialized bytes=2109
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2109
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=72
		Total committed heap usage (bytes)=1463812096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:01:48  [ main:565026 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:01:48  [ main:565043 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:01:48  [ main:565047 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:01:48  [ main:565057 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:01:48  [ main:565098 ] - [ INFO ]  number of splits:1
2020-11-20 13:01:48  [ main:565114 ] - [ INFO ]  Submitting tokens for job: job_local158646836_0053
2020-11-20 13:01:48  [ main:565151 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:01:48  [ main:565151 ] - [ INFO ]  Running job: job_local158646836_0053
2020-11-20 13:01:48  [ Thread-1435:565152 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:01:48  [ Thread-1435:565152 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:48  [ Thread-1435:565152 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:01:48  [ Thread-1435:565166 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565166 ] - [ INFO ]  Starting task: attempt_local158646836_0053_m_000000_0
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565166 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565166 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565166 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565167 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565175 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565175 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565175 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565175 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565175 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:01:48  [ LocalJobRunner Map Task Executor #0:565176 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:01:49  [ main:566153 ] - [ INFO ]  Job job_local158646836_0053 running in uber mode : false
2020-11-20 13:01:49  [ main:566153 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:01:54  [ communication thread:571171 ] - [ INFO ]  map > map
2020-11-20 13:01:55  [ main:572164 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:01:57  [ communication thread:574174 ] - [ INFO ]  map > map
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574716 ] - [ INFO ]  map > map
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574716 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574716 ] - [ INFO ]  Spilling map output
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574716 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574716 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574718 ] - [ INFO ]  Finished spill 0
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574719 ] - [ INFO ]  Task:attempt_local158646836_0053_m_000000_0 is done. And is in the process of committing
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574735 ] - [ INFO ]  map
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574735 ] - [ INFO ]  Task 'attempt_local158646836_0053_m_000000_0' done.
2020-11-20 13:01:57  [ LocalJobRunner Map Task Executor #0:574735 ] - [ INFO ]  Finishing task: attempt_local158646836_0053_m_000000_0
2020-11-20 13:01:57  [ Thread-1435:574735 ] - [ INFO ]  map task executor complete.
2020-11-20 13:01:57  [ Thread-1435:574735 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:01:57  [ pool-162-thread-1:574736 ] - [ INFO ]  Starting task: attempt_local158646836_0053_r_000000_0
2020-11-20 13:01:57  [ pool-162-thread-1:574736 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:57  [ pool-162-thread-1:574736 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:57  [ pool-162-thread-1:574736 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:57  [ pool-162-thread-1:574736 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6d78155d
2020-11-20 13:01:57  [ pool-162-thread-1:574737 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:01:57  [ EventFetcher for fetching Map Completion Events:574738 ] - [ INFO ]  attempt_local158646836_0053_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:01:57  [ localfetcher#53:574738 ] - [ INFO ]  localfetcher#53 about to shuffle output of map attempt_local158646836_0053_m_000000_0 decomp: 2104 len: 2108 to MEMORY
2020-11-20 13:01:57  [ localfetcher#53:574738 ] - [ INFO ]  Read 2104 bytes from map-output for attempt_local158646836_0053_m_000000_0
2020-11-20 13:01:57  [ localfetcher#53:574738 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2104
2020-11-20 13:01:57  [ EventFetcher for fetching Map Completion Events:574739 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:01:57  [ pool-162-thread-1:574739 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:57  [ pool-162-thread-1:574739 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Merged 1 segments, 2104 bytes to disk to satisfy reduce memory limit
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Merging 1 files, 2108 bytes from disk
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 13:01:57  [ pool-162-thread-1:574740 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:57  [ pool-162-thread-1:574893 ] - [ INFO ]  Task:attempt_local158646836_0053_r_000000_0 is done. And is in the process of committing
2020-11-20 13:01:57  [ pool-162-thread-1:574902 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:01:57  [ pool-162-thread-1:574902 ] - [ INFO ]  Task attempt_local158646836_0053_r_000000_0 is allowed to commit now
2020-11-20 13:01:57  [ pool-162-thread-1:574935 ] - [ INFO ]  Saved output of task 'attempt_local158646836_0053_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local158646836_0053_r_000000
2020-11-20 13:01:57  [ pool-162-thread-1:574936 ] - [ INFO ]  reduce > reduce
2020-11-20 13:01:57  [ pool-162-thread-1:574936 ] - [ INFO ]  Task 'attempt_local158646836_0053_r_000000_0' done.
2020-11-20 13:01:57  [ pool-162-thread-1:574936 ] - [ INFO ]  Finishing task: attempt_local158646836_0053_r_000000_0
2020-11-20 13:01:57  [ Thread-1435:574936 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:01:58  [ main:575171 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:01:58  [ main:575171 ] - [ INFO ]  Job job_local158646836_0053 completed successfully
2020-11-20 13:01:58  [ main:575172 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=466734
		FILE: Number of bytes written=33089734
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=149785200
		HDFS: Number of bytes written=220199
		HDFS: Number of read operations=1584
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=837
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=2108
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2108
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=1619001344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:01:58  [ main:575202 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:01:58  [ main:575217 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:01:58  [ main:575221 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:01:58  [ main:575229 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:01:58  [ main:575269 ] - [ INFO ]  number of splits:1
2020-11-20 13:01:58  [ main:575285 ] - [ INFO ]  Submitting tokens for job: job_local716443604_0054
2020-11-20 13:01:58  [ main:575317 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:01:58  [ main:575317 ] - [ INFO ]  Running job: job_local716443604_0054
2020-11-20 13:01:58  [ Thread-1462:575317 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:01:58  [ Thread-1462:575318 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:58  [ Thread-1462:575318 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:01:58  [ Thread-1462:575329 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575329 ] - [ INFO ]  Starting task: attempt_local716443604_0054_m_000000_0
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575329 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575329 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575329 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575330 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575337 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575337 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575337 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575337 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575337 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:01:58  [ LocalJobRunner Map Task Executor #0:575338 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:01:59  [ main:576319 ] - [ INFO ]  Job job_local716443604_0054 running in uber mode : false
2020-11-20 13:01:59  [ main:576319 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:02:04  [ communication thread:581337 ] - [ INFO ]  map > map
2020-11-20 13:02:05  [ main:582341 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:02:07  [ communication thread:584339 ] - [ INFO ]  map > map
2020-11-20 13:02:07  [ main:584347 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585244 ] - [ INFO ]  map > map
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585244 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585244 ] - [ INFO ]  Spilling map output
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585244 ] - [ INFO ]  bufstart = 0; bufend = 2400; bufvoid = 104857600
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585244 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585246 ] - [ INFO ]  Finished spill 0
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585247 ] - [ INFO ]  Task:attempt_local716443604_0054_m_000000_0 is done. And is in the process of committing
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585256 ] - [ INFO ]  map
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585256 ] - [ INFO ]  Task 'attempt_local716443604_0054_m_000000_0' done.
2020-11-20 13:02:08  [ LocalJobRunner Map Task Executor #0:585256 ] - [ INFO ]  Finishing task: attempt_local716443604_0054_m_000000_0
2020-11-20 13:02:08  [ Thread-1462:585257 ] - [ INFO ]  map task executor complete.
2020-11-20 13:02:08  [ Thread-1462:585257 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:02:08  [ pool-165-thread-1:585257 ] - [ INFO ]  Starting task: attempt_local716443604_0054_r_000000_0
2020-11-20 13:02:08  [ pool-165-thread-1:585257 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:08  [ pool-165-thread-1:585258 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:08  [ pool-165-thread-1:585258 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:08  [ pool-165-thread-1:585258 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52a2655b
2020-11-20 13:02:08  [ pool-165-thread-1:585259 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:02:08  [ EventFetcher for fetching Map Completion Events:585259 ] - [ INFO ]  attempt_local716443604_0054_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:02:08  [ localfetcher#54:585260 ] - [ INFO ]  localfetcher#54 about to shuffle output of map attempt_local716443604_0054_m_000000_0 decomp: 2111 len: 2115 to MEMORY
2020-11-20 13:02:08  [ localfetcher#54:585260 ] - [ INFO ]  Read 2111 bytes from map-output for attempt_local716443604_0054_m_000000_0
2020-11-20 13:02:08  [ localfetcher#54:585260 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2111, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2111
2020-11-20 13:02:08  [ EventFetcher for fetching Map Completion Events:585260 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:02:08  [ pool-165-thread-1:585260 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:08  [ pool-165-thread-1:585261 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:02:08  [ pool-165-thread-1:585261 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2104 bytes
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  Merged 1 segments, 2111 bytes to disk to satisfy reduce memory limit
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  Merging 1 files, 2115 bytes from disk
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2104 bytes
2020-11-20 13:02:08  [ pool-165-thread-1:585262 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:08  [ main:585351 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:02:08  [ pool-165-thread-1:585390 ] - [ INFO ]  Task:attempt_local716443604_0054_r_000000_0 is done. And is in the process of committing
2020-11-20 13:02:08  [ pool-165-thread-1:585400 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:08  [ pool-165-thread-1:585400 ] - [ INFO ]  Task attempt_local716443604_0054_r_000000_0 is allowed to commit now
2020-11-20 13:02:08  [ pool-165-thread-1:585431 ] - [ INFO ]  Saved output of task 'attempt_local716443604_0054_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local716443604_0054_r_000000
2020-11-20 13:02:08  [ pool-165-thread-1:585431 ] - [ INFO ]  reduce > reduce
2020-11-20 13:02:08  [ pool-165-thread-1:585431 ] - [ INFO ]  Task 'attempt_local716443604_0054_r_000000_0' done.
2020-11-20 13:02:08  [ pool-165-thread-1:585431 ] - [ INFO ]  Finishing task: attempt_local716443604_0054_r_000000_0
2020-11-20 13:02:08  [ Thread-1462:585432 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:02:09  [ main:586354 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:02:09  [ main:586355 ] - [ INFO ]  Job job_local716443604_0054 completed successfully
2020-11-20 13:02:09  [ main:586356 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=475626
		FILE: Number of bytes written=33719013
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=152559000
		HDFS: Number of bytes written=224396
		HDFS: Number of read operations=1614
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=853
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2400
		Map output materialized bytes=2115
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2115
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1619001344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:02:09  [ main:586424 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:02:09  [ main:586444 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:02:09  [ main:586448 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:02:09  [ main:586466 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:02:09  [ main:586515 ] - [ INFO ]  number of splits:1
2020-11-20 13:02:09  [ main:586532 ] - [ INFO ]  Submitting tokens for job: job_local981891442_0055
2020-11-20 13:02:09  [ main:586566 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:02:09  [ main:586566 ] - [ INFO ]  Running job: job_local981891442_0055
2020-11-20 13:02:09  [ Thread-1489:586566 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:02:09  [ Thread-1489:586566 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:09  [ Thread-1489:586566 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:02:09  [ Thread-1489:586578 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586578 ] - [ INFO ]  Starting task: attempt_local981891442_0055_m_000000_0
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586579 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586579 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586579 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586579 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586589 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586589 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586589 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586589 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586589 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:02:09  [ LocalJobRunner Map Task Executor #0:586589 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:02:10  [ main:587569 ] - [ INFO ]  Job job_local981891442_0055 running in uber mode : false
2020-11-20 13:02:10  [ main:587569 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:02:15  [ communication thread:592586 ] - [ INFO ]  map > map
2020-11-20 13:02:16  [ main:593585 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:02:18  [ communication thread:595587 ] - [ INFO ]  map > map
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596315 ] - [ INFO ]  map > map
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596315 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596315 ] - [ INFO ]  Spilling map output
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596315 ] - [ INFO ]  bufstart = 0; bufend = 2393; bufvoid = 104857600
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596315 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596317 ] - [ INFO ]  Finished spill 0
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596318 ] - [ INFO ]  Task:attempt_local981891442_0055_m_000000_0 is done. And is in the process of committing
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596328 ] - [ INFO ]  map
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596328 ] - [ INFO ]  Task 'attempt_local981891442_0055_m_000000_0' done.
2020-11-20 13:02:19  [ LocalJobRunner Map Task Executor #0:596328 ] - [ INFO ]  Finishing task: attempt_local981891442_0055_m_000000_0
2020-11-20 13:02:19  [ Thread-1489:596328 ] - [ INFO ]  map task executor complete.
2020-11-20 13:02:19  [ Thread-1489:596328 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:02:19  [ pool-168-thread-1:596329 ] - [ INFO ]  Starting task: attempt_local981891442_0055_r_000000_0
2020-11-20 13:02:19  [ pool-168-thread-1:596329 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:19  [ pool-168-thread-1:596329 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:19  [ pool-168-thread-1:596329 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:19  [ pool-168-thread-1:596329 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57042111
2020-11-20 13:02:19  [ pool-168-thread-1:596331 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:02:19  [ EventFetcher for fetching Map Completion Events:596331 ] - [ INFO ]  attempt_local981891442_0055_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:02:19  [ localfetcher#55:596332 ] - [ INFO ]  localfetcher#55 about to shuffle output of map attempt_local981891442_0055_m_000000_0 decomp: 2104 len: 2108 to MEMORY
2020-11-20 13:02:19  [ localfetcher#55:596332 ] - [ INFO ]  Read 2104 bytes from map-output for attempt_local981891442_0055_m_000000_0
2020-11-20 13:02:19  [ localfetcher#55:596332 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2104
2020-11-20 13:02:19  [ EventFetcher for fetching Map Completion Events:596332 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:02:19  [ pool-168-thread-1:596333 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:19  [ pool-168-thread-1:596333 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:02:19  [ pool-168-thread-1:596333 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:19  [ pool-168-thread-1:596333 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 13:02:19  [ pool-168-thread-1:596334 ] - [ INFO ]  Merged 1 segments, 2104 bytes to disk to satisfy reduce memory limit
2020-11-20 13:02:19  [ pool-168-thread-1:596334 ] - [ INFO ]  Merging 1 files, 2108 bytes from disk
2020-11-20 13:02:19  [ pool-168-thread-1:596334 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:02:19  [ pool-168-thread-1:596334 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:19  [ pool-168-thread-1:596334 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2097 bytes
2020-11-20 13:02:19  [ pool-168-thread-1:596334 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:19  [ main:596590 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:02:19  [ pool-168-thread-1:596660 ] - [ INFO ]  Task:attempt_local981891442_0055_r_000000_0 is done. And is in the process of committing
2020-11-20 13:02:19  [ pool-168-thread-1:596670 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:19  [ pool-168-thread-1:596671 ] - [ INFO ]  Task attempt_local981891442_0055_r_000000_0 is allowed to commit now
2020-11-20 13:02:19  [ pool-168-thread-1:596698 ] - [ INFO ]  Saved output of task 'attempt_local981891442_0055_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local981891442_0055_r_000000
2020-11-20 13:02:19  [ pool-168-thread-1:596699 ] - [ INFO ]  reduce > reduce
2020-11-20 13:02:19  [ pool-168-thread-1:596699 ] - [ INFO ]  Task 'attempt_local981891442_0055_r_000000_0' done.
2020-11-20 13:02:19  [ pool-168-thread-1:596699 ] - [ INFO ]  Finishing task: attempt_local981891442_0055_r_000000_0
2020-11-20 13:02:19  [ Thread-1489:596699 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:02:20  [ main:597593 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:02:20  [ main:597594 ] - [ INFO ]  Job job_local981891442_0055 completed successfully
2020-11-20 13:02:20  [ main:597595 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=484518
		FILE: Number of bytes written=34349610
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155332800
		HDFS: Number of bytes written=228593
		HDFS: Number of read operations=1644
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=869
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2393
		Map output materialized bytes=2108
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2108
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		Total committed heap usage (bytes)=1723858944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:02:20  [ main:597625 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:02:20  [ main:597641 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:02:20  [ main:597645 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:02:20  [ main:597655 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:02:20  [ main:597697 ] - [ INFO ]  number of splits:1
2020-11-20 13:02:20  [ main:597713 ] - [ INFO ]  Submitting tokens for job: job_local1188512366_0056
2020-11-20 13:02:20  [ main:597746 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:02:20  [ main:597746 ] - [ INFO ]  Running job: job_local1188512366_0056
2020-11-20 13:02:20  [ Thread-1516:597746 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:02:20  [ Thread-1516:597746 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:20  [ Thread-1516:597746 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:02:20  [ Thread-1516:597758 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597759 ] - [ INFO ]  Starting task: attempt_local1188512366_0056_m_000000_0
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597759 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597759 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597759 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597760 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597775 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597775 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597775 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597775 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597775 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:02:20  [ LocalJobRunner Map Task Executor #0:597775 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:02:21  [ main:598747 ] - [ INFO ]  Job job_local1188512366_0056 running in uber mode : false
2020-11-20 13:02:21  [ main:598747 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:02:26  [ communication thread:603765 ] - [ INFO ]  map > map
2020-11-20 13:02:27  [ main:604763 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:02:29  [ communication thread:606769 ] - [ INFO ]  map > map
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607388 ] - [ INFO ]  map > map
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607388 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607388 ] - [ INFO ]  Spilling map output
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607388 ] - [ INFO ]  bufstart = 0; bufend = 2413; bufvoid = 104857600
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607388 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607390 ] - [ INFO ]  Finished spill 0
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607391 ] - [ INFO ]  Task:attempt_local1188512366_0056_m_000000_0 is done. And is in the process of committing
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607402 ] - [ INFO ]  map
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607402 ] - [ INFO ]  Task 'attempt_local1188512366_0056_m_000000_0' done.
2020-11-20 13:02:30  [ LocalJobRunner Map Task Executor #0:607402 ] - [ INFO ]  Finishing task: attempt_local1188512366_0056_m_000000_0
2020-11-20 13:02:30  [ Thread-1516:607402 ] - [ INFO ]  map task executor complete.
2020-11-20 13:02:30  [ Thread-1516:607403 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:02:30  [ pool-171-thread-1:607403 ] - [ INFO ]  Starting task: attempt_local1188512366_0056_r_000000_0
2020-11-20 13:02:30  [ pool-171-thread-1:607403 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:30  [ pool-171-thread-1:607403 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:30  [ pool-171-thread-1:607403 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:30  [ pool-171-thread-1:607403 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29a806ca
2020-11-20 13:02:30  [ pool-171-thread-1:607405 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:02:30  [ EventFetcher for fetching Map Completion Events:607405 ] - [ INFO ]  attempt_local1188512366_0056_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:02:30  [ localfetcher#56:607406 ] - [ INFO ]  localfetcher#56 about to shuffle output of map attempt_local1188512366_0056_m_000000_0 decomp: 2124 len: 2128 to MEMORY
2020-11-20 13:02:30  [ localfetcher#56:607406 ] - [ INFO ]  Read 2124 bytes from map-output for attempt_local1188512366_0056_m_000000_0
2020-11-20 13:02:30  [ localfetcher#56:607406 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2124, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2124
2020-11-20 13:02:30  [ EventFetcher for fetching Map Completion Events:607406 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:02:30  [ pool-171-thread-1:607406 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:30  [ pool-171-thread-1:607406 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:02:30  [ pool-171-thread-1:607407 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:30  [ pool-171-thread-1:607407 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2117 bytes
2020-11-20 13:02:30  [ pool-171-thread-1:607407 ] - [ INFO ]  Merged 1 segments, 2124 bytes to disk to satisfy reduce memory limit
2020-11-20 13:02:30  [ pool-171-thread-1:607408 ] - [ INFO ]  Merging 1 files, 2128 bytes from disk
2020-11-20 13:02:30  [ pool-171-thread-1:607408 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:02:30  [ pool-171-thread-1:607408 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:30  [ pool-171-thread-1:607408 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2117 bytes
2020-11-20 13:02:30  [ pool-171-thread-1:607408 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:30  [ pool-171-thread-1:607528 ] - [ INFO ]  Task:attempt_local1188512366_0056_r_000000_0 is done. And is in the process of committing
2020-11-20 13:02:30  [ pool-171-thread-1:607538 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:30  [ pool-171-thread-1:607538 ] - [ INFO ]  Task attempt_local1188512366_0056_r_000000_0 is allowed to commit now
2020-11-20 13:02:30  [ pool-171-thread-1:607566 ] - [ INFO ]  Saved output of task 'attempt_local1188512366_0056_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1188512366_0056_r_000000
2020-11-20 13:02:30  [ pool-171-thread-1:607567 ] - [ INFO ]  reduce > reduce
2020-11-20 13:02:30  [ pool-171-thread-1:607567 ] - [ INFO ]  Task 'attempt_local1188512366_0056_r_000000_0' done.
2020-11-20 13:02:30  [ pool-171-thread-1:607567 ] - [ INFO ]  Finishing task: attempt_local1188512366_0056_r_000000_0
2020-11-20 13:02:30  [ Thread-1516:607567 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:02:30  [ main:607769 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:02:30  [ main:607770 ] - [ INFO ]  Job job_local1188512366_0056 completed successfully
2020-11-20 13:02:30  [ main:607771 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=493436
		FILE: Number of bytes written=34983844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=158106600
		HDFS: Number of bytes written=232803
		HDFS: Number of read operations=1674
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=885
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2413
		Map output materialized bytes=2128
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2128
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=48
		Total committed heap usage (bytes)=1778384896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:02:30  [ main:607859 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:02:30  [ main:607888 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:02:30  [ main:607893 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:02:30  [ main:607906 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:02:30  [ main:607978 ] - [ INFO ]  number of splits:1
2020-11-20 13:02:30  [ main:607994 ] - [ INFO ]  Submitting tokens for job: job_local1347325099_0057
2020-11-20 13:02:31  [ main:608029 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:02:31  [ main:608029 ] - [ INFO ]  Running job: job_local1347325099_0057
2020-11-20 13:02:31  [ Thread-1543:608029 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:02:31  [ Thread-1543:608029 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:31  [ Thread-1543:608029 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:02:31  [ Thread-1543:608056 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608056 ] - [ INFO ]  Starting task: attempt_local1347325099_0057_m_000000_0
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608057 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608057 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608057 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608057 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608068 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608068 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608068 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608068 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608068 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:02:31  [ LocalJobRunner Map Task Executor #0:608069 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:02:32  [ main:609034 ] - [ INFO ]  Job job_local1347325099_0057 running in uber mode : false
2020-11-20 13:02:32  [ main:609034 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:02:37  [ communication thread:614063 ] - [ INFO ]  map > map
2020-11-20 13:02:38  [ main:615045 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:02:40  [ communication thread:617066 ] - [ INFO ]  map > map
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617774 ] - [ INFO ]  map > map
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617774 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617774 ] - [ INFO ]  Spilling map output
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617774 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617774 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617776 ] - [ INFO ]  Finished spill 0
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617777 ] - [ INFO ]  Task:attempt_local1347325099_0057_m_000000_0 is done. And is in the process of committing
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617786 ] - [ INFO ]  map
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617786 ] - [ INFO ]  Task 'attempt_local1347325099_0057_m_000000_0' done.
2020-11-20 13:02:40  [ LocalJobRunner Map Task Executor #0:617786 ] - [ INFO ]  Finishing task: attempt_local1347325099_0057_m_000000_0
2020-11-20 13:02:40  [ Thread-1543:617786 ] - [ INFO ]  map task executor complete.
2020-11-20 13:02:40  [ Thread-1543:617787 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:02:40  [ pool-174-thread-1:617787 ] - [ INFO ]  Starting task: attempt_local1347325099_0057_r_000000_0
2020-11-20 13:02:40  [ pool-174-thread-1:617787 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:40  [ pool-174-thread-1:617787 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:40  [ pool-174-thread-1:617788 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:40  [ pool-174-thread-1:617788 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cfcf5e0
2020-11-20 13:02:40  [ pool-174-thread-1:617789 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:02:40  [ EventFetcher for fetching Map Completion Events:617789 ] - [ INFO ]  attempt_local1347325099_0057_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:02:40  [ localfetcher#57:617790 ] - [ INFO ]  localfetcher#57 about to shuffle output of map attempt_local1347325099_0057_m_000000_0 decomp: 2119 len: 2123 to MEMORY
2020-11-20 13:02:40  [ localfetcher#57:617790 ] - [ INFO ]  Read 2119 bytes from map-output for attempt_local1347325099_0057_m_000000_0
2020-11-20 13:02:40  [ localfetcher#57:617790 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2119
2020-11-20 13:02:40  [ EventFetcher for fetching Map Completion Events:617790 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:02:40  [ pool-174-thread-1:617791 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:40  [ pool-174-thread-1:617791 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:02:40  [ pool-174-thread-1:617791 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:40  [ pool-174-thread-1:617791 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:02:40  [ pool-174-thread-1:617792 ] - [ INFO ]  Merged 1 segments, 2119 bytes to disk to satisfy reduce memory limit
2020-11-20 13:02:40  [ pool-174-thread-1:617792 ] - [ INFO ]  Merging 1 files, 2123 bytes from disk
2020-11-20 13:02:40  [ pool-174-thread-1:617792 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:02:40  [ pool-174-thread-1:617792 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:40  [ pool-174-thread-1:617792 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:02:40  [ pool-174-thread-1:617792 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:40  [ pool-174-thread-1:617901 ] - [ INFO ]  Task:attempt_local1347325099_0057_r_000000_0 is done. And is in the process of committing
2020-11-20 13:02:40  [ pool-174-thread-1:617909 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:40  [ pool-174-thread-1:617909 ] - [ INFO ]  Task attempt_local1347325099_0057_r_000000_0 is allowed to commit now
2020-11-20 13:02:40  [ pool-174-thread-1:617936 ] - [ INFO ]  Saved output of task 'attempt_local1347325099_0057_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1347325099_0057_r_000000
2020-11-20 13:02:40  [ pool-174-thread-1:617937 ] - [ INFO ]  reduce > reduce
2020-11-20 13:02:40  [ pool-174-thread-1:617937 ] - [ INFO ]  Task 'attempt_local1347325099_0057_r_000000_0' done.
2020-11-20 13:02:40  [ pool-174-thread-1:617937 ] - [ INFO ]  Finishing task: attempt_local1347325099_0057_r_000000_0
2020-11-20 13:02:40  [ Thread-1543:617937 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:02:41  [ main:618054 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:02:41  [ main:618055 ] - [ INFO ]  Job job_local1347325099_0057 completed successfully
2020-11-20 13:02:41  [ main:618055 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=502384
		FILE: Number of bytes written=35618383
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=160880400
		HDFS: Number of bytes written=237028
		HDFS: Number of read operations=1704
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=901
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2408
		Map output materialized bytes=2123
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2123
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1763704832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:02:41  [ main:618088 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:02:41  [ main:618103 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:02:41  [ main:618107 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:02:41  [ main:618117 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:02:41  [ main:618159 ] - [ INFO ]  number of splits:1
2020-11-20 13:02:41  [ main:618175 ] - [ INFO ]  Submitting tokens for job: job_local89264613_0058
2020-11-20 13:02:41  [ main:618209 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:02:41  [ main:618209 ] - [ INFO ]  Running job: job_local89264613_0058
2020-11-20 13:02:41  [ Thread-1570:618210 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:02:41  [ Thread-1570:618210 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:41  [ Thread-1570:618210 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:02:41  [ Thread-1570:618221 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618221 ] - [ INFO ]  Starting task: attempt_local89264613_0058_m_000000_0
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618221 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618221 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618221 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618222 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618230 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618230 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618230 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618230 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618230 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:02:41  [ LocalJobRunner Map Task Executor #0:618230 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:02:42  [ main:619210 ] - [ INFO ]  Job job_local89264613_0058 running in uber mode : false
2020-11-20 13:02:42  [ main:619210 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:02:47  [ communication thread:624231 ] - [ INFO ]  map > map
2020-11-20 13:02:48  [ main:625290 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:02:50  [ communication thread:627236 ] - [ INFO ]  map > map
2020-11-20 13:02:50  [ main:627297 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628264 ] - [ INFO ]  map > map
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628264 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628264 ] - [ INFO ]  Spilling map output
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628264 ] - [ INFO ]  bufstart = 0; bufend = 2397; bufvoid = 104857600
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628264 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628266 ] - [ INFO ]  Finished spill 0
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628267 ] - [ INFO ]  Task:attempt_local89264613_0058_m_000000_0 is done. And is in the process of committing
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628281 ] - [ INFO ]  map
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628281 ] - [ INFO ]  Task 'attempt_local89264613_0058_m_000000_0' done.
2020-11-20 13:02:51  [ LocalJobRunner Map Task Executor #0:628281 ] - [ INFO ]  Finishing task: attempt_local89264613_0058_m_000000_0
2020-11-20 13:02:51  [ Thread-1570:628281 ] - [ INFO ]  map task executor complete.
2020-11-20 13:02:51  [ Thread-1570:628281 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:02:51  [ pool-177-thread-1:628282 ] - [ INFO ]  Starting task: attempt_local89264613_0058_r_000000_0
2020-11-20 13:02:51  [ pool-177-thread-1:628282 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:51  [ pool-177-thread-1:628282 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:51  [ pool-177-thread-1:628282 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:51  [ pool-177-thread-1:628282 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63bbc471
2020-11-20 13:02:51  [ pool-177-thread-1:628283 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:02:51  [ EventFetcher for fetching Map Completion Events:628283 ] - [ INFO ]  attempt_local89264613_0058_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:02:51  [ localfetcher#58:628284 ] - [ INFO ]  localfetcher#58 about to shuffle output of map attempt_local89264613_0058_m_000000_0 decomp: 2108 len: 2112 to MEMORY
2020-11-20 13:02:51  [ localfetcher#58:628284 ] - [ INFO ]  Read 2108 bytes from map-output for attempt_local89264613_0058_m_000000_0
2020-11-20 13:02:51  [ localfetcher#58:628284 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2108, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2108
2020-11-20 13:02:51  [ EventFetcher for fetching Map Completion Events:628285 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:02:51  [ pool-177-thread-1:628285 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:51  [ pool-177-thread-1:628285 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:02:51  [ pool-177-thread-1:628286 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:51  [ pool-177-thread-1:628286 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2101 bytes
2020-11-20 13:02:51  [ pool-177-thread-1:628286 ] - [ INFO ]  Merged 1 segments, 2108 bytes to disk to satisfy reduce memory limit
2020-11-20 13:02:51  [ pool-177-thread-1:628286 ] - [ INFO ]  Merging 1 files, 2112 bytes from disk
2020-11-20 13:02:51  [ pool-177-thread-1:628286 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:02:51  [ pool-177-thread-1:628286 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:02:51  [ pool-177-thread-1:628287 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2101 bytes
2020-11-20 13:02:51  [ pool-177-thread-1:628287 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:51  [ main:628302 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:02:51  [ pool-177-thread-1:628369 ] - [ INFO ]  Task:attempt_local89264613_0058_r_000000_0 is done. And is in the process of committing
2020-11-20 13:02:51  [ pool-177-thread-1:628375 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:02:51  [ pool-177-thread-1:628375 ] - [ INFO ]  Task attempt_local89264613_0058_r_000000_0 is allowed to commit now
2020-11-20 13:02:51  [ pool-177-thread-1:628395 ] - [ INFO ]  Saved output of task 'attempt_local89264613_0058_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local89264613_0058_r_000000
2020-11-20 13:02:51  [ pool-177-thread-1:628395 ] - [ INFO ]  reduce > reduce
2020-11-20 13:02:51  [ pool-177-thread-1:628395 ] - [ INFO ]  Task 'attempt_local89264613_0058_r_000000_0' done.
2020-11-20 13:02:51  [ pool-177-thread-1:628395 ] - [ INFO ]  Finishing task: attempt_local89264613_0058_r_000000_0
2020-11-20 13:02:51  [ Thread-1570:628395 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:02:52  [ main:629305 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:02:52  [ main:629305 ] - [ INFO ]  Job job_local89264613_0058 completed successfully
2020-11-20 13:02:52  [ main:629306 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=511300
		FILE: Number of bytes written=36246876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=163654200
		HDFS: Number of bytes written=241237
		HDFS: Number of read operations=1734
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=917
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2397
		Map output materialized bytes=2112
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2112
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=1733296128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:02:52  [ main:629325 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:02:52  [ main:629337 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:02:52  [ main:629341 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:02:52  [ main:629347 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:02:52  [ main:629385 ] - [ INFO ]  number of splits:1
2020-11-20 13:02:52  [ main:629402 ] - [ INFO ]  Submitting tokens for job: job_local1512240743_0059
2020-11-20 13:02:52  [ main:629438 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:02:52  [ main:629438 ] - [ INFO ]  Running job: job_local1512240743_0059
2020-11-20 13:02:52  [ Thread-1598:629438 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:02:52  [ Thread-1598:629438 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:52  [ Thread-1598:629439 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:02:52  [ Thread-1598:629447 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629447 ] - [ INFO ]  Starting task: attempt_local1512240743_0059_m_000000_0
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629447 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629447 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629447 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629448 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629456 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629456 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629456 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629456 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629456 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:02:52  [ LocalJobRunner Map Task Executor #0:629456 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:02:53  [ main:630441 ] - [ INFO ]  Job job_local1512240743_0059 running in uber mode : false
2020-11-20 13:02:53  [ main:630441 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:02:58  [ communication thread:635456 ] - [ INFO ]  map > map
2020-11-20 13:02:58  [ main:635460 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:03:01  [ communication thread:638460 ] - [ INFO ]  map > map
2020-11-20 13:03:01  [ main:638469 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638911 ] - [ INFO ]  map > map
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638911 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638911 ] - [ INFO ]  Spilling map output
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638911 ] - [ INFO ]  bufstart = 0; bufend = 2421; bufvoid = 104857600
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638911 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638913 ] - [ INFO ]  Finished spill 0
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638914 ] - [ INFO ]  Task:attempt_local1512240743_0059_m_000000_0 is done. And is in the process of committing
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638919 ] - [ INFO ]  map
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638920 ] - [ INFO ]  Task 'attempt_local1512240743_0059_m_000000_0' done.
2020-11-20 13:03:01  [ LocalJobRunner Map Task Executor #0:638920 ] - [ INFO ]  Finishing task: attempt_local1512240743_0059_m_000000_0
2020-11-20 13:03:01  [ Thread-1598:638920 ] - [ INFO ]  map task executor complete.
2020-11-20 13:03:01  [ Thread-1598:638920 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:03:01  [ pool-180-thread-1:638920 ] - [ INFO ]  Starting task: attempt_local1512240743_0059_r_000000_0
2020-11-20 13:03:01  [ pool-180-thread-1:638921 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:01  [ pool-180-thread-1:638921 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:01  [ pool-180-thread-1:638921 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:01  [ pool-180-thread-1:638921 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f64d311
2020-11-20 13:03:01  [ pool-180-thread-1:638922 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:03:01  [ EventFetcher for fetching Map Completion Events:638922 ] - [ INFO ]  attempt_local1512240743_0059_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:03:01  [ localfetcher#59:638923 ] - [ INFO ]  localfetcher#59 about to shuffle output of map attempt_local1512240743_0059_m_000000_0 decomp: 2132 len: 2136 to MEMORY
2020-11-20 13:03:01  [ localfetcher#59:638923 ] - [ INFO ]  Read 2132 bytes from map-output for attempt_local1512240743_0059_m_000000_0
2020-11-20 13:03:01  [ localfetcher#59:638923 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2132
2020-11-20 13:03:01  [ EventFetcher for fetching Map Completion Events:638923 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:03:01  [ pool-180-thread-1:638923 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:01  [ pool-180-thread-1:638923 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:03:01  [ pool-180-thread-1:638924 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:01  [ pool-180-thread-1:638924 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2125 bytes
2020-11-20 13:03:01  [ pool-180-thread-1:638925 ] - [ INFO ]  Merged 1 segments, 2132 bytes to disk to satisfy reduce memory limit
2020-11-20 13:03:01  [ pool-180-thread-1:638925 ] - [ INFO ]  Merging 1 files, 2136 bytes from disk
2020-11-20 13:03:01  [ pool-180-thread-1:638925 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:03:01  [ pool-180-thread-1:638925 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:01  [ pool-180-thread-1:638925 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2125 bytes
2020-11-20 13:03:01  [ pool-180-thread-1:638925 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:02  [ pool-180-thread-1:639017 ] - [ INFO ]  Task:attempt_local1512240743_0059_r_000000_0 is done. And is in the process of committing
2020-11-20 13:03:02  [ pool-180-thread-1:639023 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:02  [ pool-180-thread-1:639024 ] - [ INFO ]  Task attempt_local1512240743_0059_r_000000_0 is allowed to commit now
2020-11-20 13:03:02  [ pool-180-thread-1:639041 ] - [ INFO ]  Saved output of task 'attempt_local1512240743_0059_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1512240743_0059_r_000000
2020-11-20 13:03:02  [ pool-180-thread-1:639042 ] - [ INFO ]  reduce > reduce
2020-11-20 13:03:02  [ pool-180-thread-1:639042 ] - [ INFO ]  Task 'attempt_local1512240743_0059_r_000000_0' done.
2020-11-20 13:03:02  [ pool-180-thread-1:639042 ] - [ INFO ]  Finishing task: attempt_local1512240743_0059_r_000000_0
2020-11-20 13:03:02  [ Thread-1598:639042 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:03:02  [ main:639471 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:03:02  [ main:639471 ] - [ INFO ]  Job job_local1512240743_0059 completed successfully
2020-11-20 13:03:02  [ main:639472 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=520242
		FILE: Number of bytes written=36881586
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166428000
		HDFS: Number of bytes written=245459
		HDFS: Number of read operations=1764
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=933
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2421
		Map output materialized bytes=2136
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2136
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=1745879040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:03:02  [ main:639494 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:03:02  [ main:639506 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:03:02  [ main:639511 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:03:02  [ main:639517 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:03:02  [ main:639556 ] - [ INFO ]  number of splits:1
2020-11-20 13:03:02  [ main:639572 ] - [ INFO ]  Submitting tokens for job: job_local228693609_0060
2020-11-20 13:03:02  [ main:639604 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:03:02  [ main:639604 ] - [ INFO ]  Running job: job_local228693609_0060
2020-11-20 13:03:02  [ Thread-1625:639605 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:03:02  [ Thread-1625:639605 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:02  [ Thread-1625:639605 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:03:02  [ Thread-1625:639613 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639613 ] - [ INFO ]  Starting task: attempt_local228693609_0060_m_000000_0
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639614 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639614 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639614 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639615 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639623 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639623 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639623 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639623 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639623 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:03:02  [ LocalJobRunner Map Task Executor #0:639623 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:03:03  [ main:640609 ] - [ INFO ]  Job job_local228693609_0060 running in uber mode : false
2020-11-20 13:03:03  [ main:640610 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:03:08  [ communication thread:645619 ] - [ INFO ]  map > map
2020-11-20 13:03:08  [ main:645624 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:03:11  [ communication thread:648623 ] - [ INFO ]  map > map
2020-11-20 13:03:11  [ main:648635 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649532 ] - [ INFO ]  map > map
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649533 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649533 ] - [ INFO ]  Spilling map output
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649533 ] - [ INFO ]  bufstart = 0; bufend = 2411; bufvoid = 104857600
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649533 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649535 ] - [ INFO ]  Finished spill 0
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649536 ] - [ INFO ]  Task:attempt_local228693609_0060_m_000000_0 is done. And is in the process of committing
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649543 ] - [ INFO ]  map
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649543 ] - [ INFO ]  Task 'attempt_local228693609_0060_m_000000_0' done.
2020-11-20 13:03:12  [ LocalJobRunner Map Task Executor #0:649543 ] - [ INFO ]  Finishing task: attempt_local228693609_0060_m_000000_0
2020-11-20 13:03:12  [ Thread-1625:649544 ] - [ INFO ]  map task executor complete.
2020-11-20 13:03:12  [ Thread-1625:649544 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:03:12  [ pool-183-thread-1:649545 ] - [ INFO ]  Starting task: attempt_local228693609_0060_r_000000_0
2020-11-20 13:03:12  [ pool-183-thread-1:649545 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:12  [ pool-183-thread-1:649546 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:12  [ pool-183-thread-1:649546 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:12  [ pool-183-thread-1:649546 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@13e14de0
2020-11-20 13:03:12  [ pool-183-thread-1:649547 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:03:12  [ EventFetcher for fetching Map Completion Events:649548 ] - [ INFO ]  attempt_local228693609_0060_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:03:12  [ localfetcher#60:649549 ] - [ INFO ]  localfetcher#60 about to shuffle output of map attempt_local228693609_0060_m_000000_0 decomp: 2122 len: 2126 to MEMORY
2020-11-20 13:03:12  [ localfetcher#60:649549 ] - [ INFO ]  Read 2122 bytes from map-output for attempt_local228693609_0060_m_000000_0
2020-11-20 13:03:12  [ localfetcher#60:649549 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2122
2020-11-20 13:03:12  [ EventFetcher for fetching Map Completion Events:649549 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:03:12  [ pool-183-thread-1:649549 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:12  [ pool-183-thread-1:649549 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:03:12  [ pool-183-thread-1:649550 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:12  [ pool-183-thread-1:649550 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2115 bytes
2020-11-20 13:03:12  [ pool-183-thread-1:649551 ] - [ INFO ]  Merged 1 segments, 2122 bytes to disk to satisfy reduce memory limit
2020-11-20 13:03:12  [ pool-183-thread-1:649551 ] - [ INFO ]  Merging 1 files, 2126 bytes from disk
2020-11-20 13:03:12  [ pool-183-thread-1:649551 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:03:12  [ pool-183-thread-1:649551 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:12  [ pool-183-thread-1:649551 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2115 bytes
2020-11-20 13:03:12  [ pool-183-thread-1:649551 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:12  [ main:649639 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:03:12  [ pool-183-thread-1:649842 ] - [ INFO ]  Task:attempt_local228693609_0060_r_000000_0 is done. And is in the process of committing
2020-11-20 13:03:12  [ pool-183-thread-1:649848 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:12  [ pool-183-thread-1:649848 ] - [ INFO ]  Task attempt_local228693609_0060_r_000000_0 is allowed to commit now
2020-11-20 13:03:12  [ pool-183-thread-1:649871 ] - [ INFO ]  Saved output of task 'attempt_local228693609_0060_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local228693609_0060_r_000000
2020-11-20 13:03:12  [ pool-183-thread-1:649871 ] - [ INFO ]  reduce > reduce
2020-11-20 13:03:12  [ pool-183-thread-1:649871 ] - [ INFO ]  Task 'attempt_local228693609_0060_r_000000_0' done.
2020-11-20 13:03:12  [ pool-183-thread-1:649871 ] - [ INFO ]  Finishing task: attempt_local228693609_0060_r_000000_0
2020-11-20 13:03:12  [ Thread-1625:649871 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:03:13  [ main:650644 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:03:13  [ main:650644 ] - [ INFO ]  Job job_local228693609_0060 completed successfully
2020-11-20 13:03:13  [ main:650645 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=529212
		FILE: Number of bytes written=37513478
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=169201800
		HDFS: Number of bytes written=249695
		HDFS: Number of read operations=1794
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=949
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2411
		Map output materialized bytes=2126
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2126
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1734344704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:03:13  [ main:650666 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:03:13  [ main:650680 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:03:13  [ main:650684 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:03:13  [ main:650690 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:03:13  [ main:650730 ] - [ INFO ]  number of splits:1
2020-11-20 13:03:13  [ main:650748 ] - [ INFO ]  Submitting tokens for job: job_local57080544_0061
2020-11-20 13:03:13  [ main:650783 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:03:13  [ main:650783 ] - [ INFO ]  Running job: job_local57080544_0061
2020-11-20 13:03:13  [ Thread-1652:650783 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:03:13  [ Thread-1652:650783 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:13  [ Thread-1652:650783 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:03:13  [ Thread-1652:650791 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650791 ] - [ INFO ]  Starting task: attempt_local57080544_0061_m_000000_0
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650791 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650791 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650792 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650792 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650800 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650800 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650800 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650800 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650800 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:03:13  [ LocalJobRunner Map Task Executor #0:650800 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:03:14  [ main:651785 ] - [ INFO ]  Job job_local57080544_0061 running in uber mode : false
2020-11-20 13:03:14  [ main:651785 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:03:19  [ communication thread:656797 ] - [ INFO ]  map > map
2020-11-20 13:03:20  [ main:657801 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:03:22  [ communication thread:659802 ] - [ INFO ]  map > map
2020-11-20 13:03:22  [ main:659809 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660622 ] - [ INFO ]  map > map
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660622 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660622 ] - [ INFO ]  Spilling map output
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660622 ] - [ INFO ]  bufstart = 0; bufend = 2430; bufvoid = 104857600
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660622 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660624 ] - [ INFO ]  Finished spill 0
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660625 ] - [ INFO ]  Task:attempt_local57080544_0061_m_000000_0 is done. And is in the process of committing
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660642 ] - [ INFO ]  map
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660642 ] - [ INFO ]  Task 'attempt_local57080544_0061_m_000000_0' done.
2020-11-20 13:03:23  [ LocalJobRunner Map Task Executor #0:660643 ] - [ INFO ]  Finishing task: attempt_local57080544_0061_m_000000_0
2020-11-20 13:03:23  [ Thread-1652:660643 ] - [ INFO ]  map task executor complete.
2020-11-20 13:03:23  [ Thread-1652:660643 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:03:23  [ pool-186-thread-1:660643 ] - [ INFO ]  Starting task: attempt_local57080544_0061_r_000000_0
2020-11-20 13:03:23  [ pool-186-thread-1:660644 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:23  [ pool-186-thread-1:660644 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:23  [ pool-186-thread-1:660644 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:23  [ pool-186-thread-1:660644 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3497f1d3
2020-11-20 13:03:23  [ pool-186-thread-1:660645 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:03:23  [ EventFetcher for fetching Map Completion Events:660646 ] - [ INFO ]  attempt_local57080544_0061_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:03:23  [ localfetcher#61:660646 ] - [ INFO ]  localfetcher#61 about to shuffle output of map attempt_local57080544_0061_m_000000_0 decomp: 2141 len: 2145 to MEMORY
2020-11-20 13:03:23  [ localfetcher#61:660647 ] - [ INFO ]  Read 2141 bytes from map-output for attempt_local57080544_0061_m_000000_0
2020-11-20 13:03:23  [ localfetcher#61:660647 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2141, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2141
2020-11-20 13:03:23  [ EventFetcher for fetching Map Completion Events:660647 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:03:23  [ pool-186-thread-1:660647 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:23  [ pool-186-thread-1:660647 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:03:23  [ pool-186-thread-1:660648 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:23  [ pool-186-thread-1:660648 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2134 bytes
2020-11-20 13:03:23  [ pool-186-thread-1:660649 ] - [ INFO ]  Merged 1 segments, 2141 bytes to disk to satisfy reduce memory limit
2020-11-20 13:03:23  [ pool-186-thread-1:660649 ] - [ INFO ]  Merging 1 files, 2145 bytes from disk
2020-11-20 13:03:23  [ pool-186-thread-1:660649 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:03:23  [ pool-186-thread-1:660649 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:23  [ pool-186-thread-1:660649 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2134 bytes
2020-11-20 13:03:23  [ pool-186-thread-1:660649 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:23  [ main:660813 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:03:24  [ pool-186-thread-1:661042 ] - [ INFO ]  Task:attempt_local57080544_0061_r_000000_0 is done. And is in the process of committing
2020-11-20 13:03:24  [ pool-186-thread-1:661050 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:24  [ pool-186-thread-1:661050 ] - [ INFO ]  Task attempt_local57080544_0061_r_000000_0 is allowed to commit now
2020-11-20 13:03:24  [ pool-186-thread-1:661067 ] - [ INFO ]  Saved output of task 'attempt_local57080544_0061_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local57080544_0061_r_000000
2020-11-20 13:03:24  [ pool-186-thread-1:661067 ] - [ INFO ]  reduce > reduce
2020-11-20 13:03:24  [ pool-186-thread-1:661068 ] - [ INFO ]  Task 'attempt_local57080544_0061_r_000000_0' done.
2020-11-20 13:03:24  [ pool-186-thread-1:661068 ] - [ INFO ]  Finishing task: attempt_local57080544_0061_r_000000_0
2020-11-20 13:03:24  [ Thread-1652:661068 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:03:24  [ main:661818 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:03:24  [ main:661818 ] - [ INFO ]  Job job_local57080544_0061 completed successfully
2020-11-20 13:03:24  [ main:661820 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=538200
		FILE: Number of bytes written=38144597
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=171975600
		HDFS: Number of bytes written=253940
		HDFS: Number of read operations=1824
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=965
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2430
		Map output materialized bytes=2145
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2145
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=1727004672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:03:24  [ main:661838 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:03:24  [ main:661850 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:03:24  [ main:661854 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:03:24  [ main:661860 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:03:24  [ main:661898 ] - [ INFO ]  number of splits:1
2020-11-20 13:03:24  [ main:661915 ] - [ INFO ]  Submitting tokens for job: job_local983125278_0062
2020-11-20 13:03:24  [ main:661948 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:03:24  [ main:661948 ] - [ INFO ]  Running job: job_local983125278_0062
2020-11-20 13:03:24  [ Thread-1679:661948 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:03:24  [ Thread-1679:661948 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:24  [ Thread-1679:661948 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:03:24  [ Thread-1679:661955 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661955 ] - [ INFO ]  Starting task: attempt_local983125278_0062_m_000000_0
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661955 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661955 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661955 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661955 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661963 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661963 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661963 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661963 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661963 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:03:24  [ LocalJobRunner Map Task Executor #0:661963 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:03:25  [ main:662951 ] - [ INFO ]  Job job_local983125278_0062 running in uber mode : false
2020-11-20 13:03:25  [ main:662951 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:03:30  [ communication thread:667959 ] - [ INFO ]  map > map
2020-11-20 13:03:31  [ main:668963 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:03:33  [ communication thread:670963 ] - [ INFO ]  map > map
2020-11-20 13:03:33  [ main:670968 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671338 ] - [ INFO ]  map > map
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671338 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671338 ] - [ INFO ]  Spilling map output
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671338 ] - [ INFO ]  bufstart = 0; bufend = 2382; bufvoid = 104857600
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671338 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671340 ] - [ INFO ]  Finished spill 0
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671341 ] - [ INFO ]  Task:attempt_local983125278_0062_m_000000_0 is done. And is in the process of committing
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671348 ] - [ INFO ]  map
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671348 ] - [ INFO ]  Task 'attempt_local983125278_0062_m_000000_0' done.
2020-11-20 13:03:34  [ LocalJobRunner Map Task Executor #0:671348 ] - [ INFO ]  Finishing task: attempt_local983125278_0062_m_000000_0
2020-11-20 13:03:34  [ Thread-1679:671348 ] - [ INFO ]  map task executor complete.
2020-11-20 13:03:34  [ Thread-1679:671349 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:03:34  [ pool-189-thread-1:671349 ] - [ INFO ]  Starting task: attempt_local983125278_0062_r_000000_0
2020-11-20 13:03:34  [ pool-189-thread-1:671350 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:34  [ pool-189-thread-1:671350 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:34  [ pool-189-thread-1:671350 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:34  [ pool-189-thread-1:671350 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@661d0ac5
2020-11-20 13:03:34  [ pool-189-thread-1:671351 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:03:34  [ EventFetcher for fetching Map Completion Events:671352 ] - [ INFO ]  attempt_local983125278_0062_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:03:34  [ localfetcher#62:671352 ] - [ INFO ]  localfetcher#62 about to shuffle output of map attempt_local983125278_0062_m_000000_0 decomp: 2093 len: 2097 to MEMORY
2020-11-20 13:03:34  [ localfetcher#62:671352 ] - [ INFO ]  Read 2093 bytes from map-output for attempt_local983125278_0062_m_000000_0
2020-11-20 13:03:34  [ localfetcher#62:671353 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2093, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2093
2020-11-20 13:03:34  [ EventFetcher for fetching Map Completion Events:671353 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:03:34  [ pool-189-thread-1:671353 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:34  [ pool-189-thread-1:671353 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:03:34  [ pool-189-thread-1:671354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:34  [ pool-189-thread-1:671354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2086 bytes
2020-11-20 13:03:34  [ pool-189-thread-1:671354 ] - [ INFO ]  Merged 1 segments, 2093 bytes to disk to satisfy reduce memory limit
2020-11-20 13:03:34  [ pool-189-thread-1:671355 ] - [ INFO ]  Merging 1 files, 2097 bytes from disk
2020-11-20 13:03:34  [ pool-189-thread-1:671355 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:03:34  [ pool-189-thread-1:671355 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:34  [ pool-189-thread-1:671355 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2086 bytes
2020-11-20 13:03:34  [ pool-189-thread-1:671355 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:34  [ pool-189-thread-1:671455 ] - [ INFO ]  Task:attempt_local983125278_0062_r_000000_0 is done. And is in the process of committing
2020-11-20 13:03:34  [ pool-189-thread-1:671460 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:34  [ pool-189-thread-1:671461 ] - [ INFO ]  Task attempt_local983125278_0062_r_000000_0 is allowed to commit now
2020-11-20 13:03:34  [ pool-189-thread-1:671481 ] - [ INFO ]  Saved output of task 'attempt_local983125278_0062_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local983125278_0062_r_000000
2020-11-20 13:03:34  [ pool-189-thread-1:671481 ] - [ INFO ]  reduce > reduce
2020-11-20 13:03:34  [ pool-189-thread-1:671481 ] - [ INFO ]  Task 'attempt_local983125278_0062_r_000000_0' done.
2020-11-20 13:03:34  [ pool-189-thread-1:671481 ] - [ INFO ]  Finishing task: attempt_local983125278_0062_r_000000_0
2020-11-20 13:03:34  [ Thread-1679:671481 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:03:34  [ main:671972 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:03:34  [ main:671973 ] - [ INFO ]  Job job_local983125278_0062 completed successfully
2020-11-20 13:03:34  [ main:671974 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=547130
		FILE: Number of bytes written=38778831
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=174749400
		HDFS: Number of bytes written=258156
		HDFS: Number of read operations=1854
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=981
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2382
		Map output materialized bytes=2097
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2097
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1716518912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:03:34  [ main:671993 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:03:35  [ main:672003 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:03:35  [ main:672008 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:03:35  [ main:672013 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:03:35  [ main:672051 ] - [ INFO ]  number of splits:1
2020-11-20 13:03:35  [ main:672067 ] - [ INFO ]  Submitting tokens for job: job_local850572350_0063
2020-11-20 13:03:35  [ main:672100 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:03:35  [ main:672100 ] - [ INFO ]  Running job: job_local850572350_0063
2020-11-20 13:03:35  [ Thread-1706:672100 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:03:35  [ Thread-1706:672100 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:35  [ Thread-1706:672100 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:03:35  [ Thread-1706:672108 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672108 ] - [ INFO ]  Starting task: attempt_local850572350_0063_m_000000_0
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672109 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672109 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672109 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672109 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672117 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672117 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672117 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672117 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672117 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:03:35  [ LocalJobRunner Map Task Executor #0:672117 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:03:36  [ main:673101 ] - [ INFO ]  Job job_local850572350_0063 running in uber mode : false
2020-11-20 13:03:36  [ main:673102 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:03:41  [ communication thread:678110 ] - [ INFO ]  map > map
2020-11-20 13:03:42  [ main:679110 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:03:44  [ communication thread:681111 ] - [ INFO ]  map > map
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681882 ] - [ INFO ]  map > map
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681883 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681883 ] - [ INFO ]  Spilling map output
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681883 ] - [ INFO ]  bufstart = 0; bufend = 2399; bufvoid = 104857600
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681883 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681885 ] - [ INFO ]  Finished spill 0
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681886 ] - [ INFO ]  Task:attempt_local850572350_0063_m_000000_0 is done. And is in the process of committing
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681893 ] - [ INFO ]  map
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681893 ] - [ INFO ]  Task 'attempt_local850572350_0063_m_000000_0' done.
2020-11-20 13:03:44  [ LocalJobRunner Map Task Executor #0:681893 ] - [ INFO ]  Finishing task: attempt_local850572350_0063_m_000000_0
2020-11-20 13:03:44  [ Thread-1706:681894 ] - [ INFO ]  map task executor complete.
2020-11-20 13:03:44  [ Thread-1706:681894 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:03:44  [ pool-192-thread-1:681894 ] - [ INFO ]  Starting task: attempt_local850572350_0063_r_000000_0
2020-11-20 13:03:44  [ pool-192-thread-1:681895 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:44  [ pool-192-thread-1:681895 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:44  [ pool-192-thread-1:681895 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:44  [ pool-192-thread-1:681895 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2690976
2020-11-20 13:03:44  [ pool-192-thread-1:681896 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:03:44  [ EventFetcher for fetching Map Completion Events:681897 ] - [ INFO ]  attempt_local850572350_0063_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:03:44  [ localfetcher#63:681897 ] - [ INFO ]  localfetcher#63 about to shuffle output of map attempt_local850572350_0063_m_000000_0 decomp: 2110 len: 2114 to MEMORY
2020-11-20 13:03:44  [ localfetcher#63:681897 ] - [ INFO ]  Read 2110 bytes from map-output for attempt_local850572350_0063_m_000000_0
2020-11-20 13:03:44  [ localfetcher#63:681898 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2110, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2110
2020-11-20 13:03:44  [ EventFetcher for fetching Map Completion Events:681898 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:03:44  [ pool-192-thread-1:681898 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:44  [ pool-192-thread-1:681898 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:03:44  [ pool-192-thread-1:681899 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:44  [ pool-192-thread-1:681899 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2103 bytes
2020-11-20 13:03:44  [ pool-192-thread-1:681900 ] - [ INFO ]  Merged 1 segments, 2110 bytes to disk to satisfy reduce memory limit
2020-11-20 13:03:44  [ pool-192-thread-1:681900 ] - [ INFO ]  Merging 1 files, 2114 bytes from disk
2020-11-20 13:03:44  [ pool-192-thread-1:681900 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:03:44  [ pool-192-thread-1:681900 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:44  [ pool-192-thread-1:681900 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2103 bytes
2020-11-20 13:03:44  [ pool-192-thread-1:681900 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:44  [ pool-192-thread-1:681989 ] - [ INFO ]  Task:attempt_local850572350_0063_r_000000_0 is done. And is in the process of committing
2020-11-20 13:03:44  [ pool-192-thread-1:681995 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:44  [ pool-192-thread-1:681995 ] - [ INFO ]  Task attempt_local850572350_0063_r_000000_0 is allowed to commit now
2020-11-20 13:03:45  [ pool-192-thread-1:682013 ] - [ INFO ]  Saved output of task 'attempt_local850572350_0063_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local850572350_0063_r_000000
2020-11-20 13:03:45  [ pool-192-thread-1:682013 ] - [ INFO ]  reduce > reduce
2020-11-20 13:03:45  [ pool-192-thread-1:682013 ] - [ INFO ]  Task 'attempt_local850572350_0063_r_000000_0' done.
2020-11-20 13:03:45  [ pool-192-thread-1:682014 ] - [ INFO ]  Finishing task: attempt_local850572350_0063_r_000000_0
2020-11-20 13:03:45  [ Thread-1706:682014 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:03:45  [ main:682111 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:03:45  [ main:682111 ] - [ INFO ]  Job job_local850572350_0063 completed successfully
2020-11-20 13:03:45  [ main:682112 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=555998
		FILE: Number of bytes written=39413164
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=177523200
		HDFS: Number of bytes written=262341
		HDFS: Number of read operations=1884
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=997
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2399
		Map output materialized bytes=2114
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2114
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=36
		Total committed heap usage (bytes)=1656750080
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:03:45  [ main:682132 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:03:45  [ main:682143 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:03:45  [ main:682147 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:03:45  [ main:682152 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:03:45  [ main:682187 ] - [ INFO ]  number of splits:1
2020-11-20 13:03:45  [ main:682203 ] - [ INFO ]  Submitting tokens for job: job_local2045596370_0064
2020-11-20 13:03:45  [ main:682237 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:03:45  [ main:682237 ] - [ INFO ]  Running job: job_local2045596370_0064
2020-11-20 13:03:45  [ Thread-1733:682237 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:03:45  [ Thread-1733:682237 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:45  [ Thread-1733:682237 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:03:45  [ Thread-1733:682245 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682245 ] - [ INFO ]  Starting task: attempt_local2045596370_0064_m_000000_0
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682245 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682245 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682245 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682246 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682254 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682254 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682254 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682254 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682254 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:03:45  [ LocalJobRunner Map Task Executor #0:682255 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:03:46  [ main:683239 ] - [ INFO ]  Job job_local2045596370_0064 running in uber mode : false
2020-11-20 13:03:46  [ main:683239 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:03:51  [ communication thread:688252 ] - [ INFO ]  map > map
2020-11-20 13:03:51  [ main:688261 ] - [ INFO ]   map 39% reduce 0%
2020-11-20 13:03:54  [ communication thread:691256 ] - [ INFO ]  map > map
2020-11-20 13:03:54  [ main:691267 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692245 ] - [ INFO ]  map > map
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692246 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692246 ] - [ INFO ]  Spilling map output
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692246 ] - [ INFO ]  bufstart = 0; bufend = 2377; bufvoid = 104857600
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692246 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692248 ] - [ INFO ]  Finished spill 0
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692249 ] - [ INFO ]  Task:attempt_local2045596370_0064_m_000000_0 is done. And is in the process of committing
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692257 ] - [ INFO ]  map
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692257 ] - [ INFO ]  Task 'attempt_local2045596370_0064_m_000000_0' done.
2020-11-20 13:03:55  [ LocalJobRunner Map Task Executor #0:692257 ] - [ INFO ]  Finishing task: attempt_local2045596370_0064_m_000000_0
2020-11-20 13:03:55  [ Thread-1733:692258 ] - [ INFO ]  map task executor complete.
2020-11-20 13:03:55  [ Thread-1733:692258 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:03:55  [ pool-195-thread-1:692258 ] - [ INFO ]  Starting task: attempt_local2045596370_0064_r_000000_0
2020-11-20 13:03:55  [ pool-195-thread-1:692259 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:55  [ pool-195-thread-1:692259 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:55  [ pool-195-thread-1:692259 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:55  [ pool-195-thread-1:692259 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3aa18fdf
2020-11-20 13:03:55  [ pool-195-thread-1:692260 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:03:55  [ EventFetcher for fetching Map Completion Events:692260 ] - [ INFO ]  attempt_local2045596370_0064_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:03:55  [ localfetcher#64:692261 ] - [ INFO ]  localfetcher#64 about to shuffle output of map attempt_local2045596370_0064_m_000000_0 decomp: 2088 len: 2092 to MEMORY
2020-11-20 13:03:55  [ localfetcher#64:692261 ] - [ INFO ]  Read 2088 bytes from map-output for attempt_local2045596370_0064_m_000000_0
2020-11-20 13:03:55  [ localfetcher#64:692261 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2088, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2088
2020-11-20 13:03:55  [ EventFetcher for fetching Map Completion Events:692261 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:03:55  [ pool-195-thread-1:692262 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:55  [ pool-195-thread-1:692262 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:03:55  [ pool-195-thread-1:692262 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:55  [ pool-195-thread-1:692262 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2081 bytes
2020-11-20 13:03:55  [ pool-195-thread-1:692263 ] - [ INFO ]  Merged 1 segments, 2088 bytes to disk to satisfy reduce memory limit
2020-11-20 13:03:55  [ pool-195-thread-1:692263 ] - [ INFO ]  Merging 1 files, 2092 bytes from disk
2020-11-20 13:03:55  [ pool-195-thread-1:692263 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:03:55  [ pool-195-thread-1:692263 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:03:55  [ pool-195-thread-1:692263 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2081 bytes
2020-11-20 13:03:55  [ pool-195-thread-1:692263 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:55  [ main:692271 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:03:55  [ pool-195-thread-1:692362 ] - [ INFO ]  Task:attempt_local2045596370_0064_r_000000_0 is done. And is in the process of committing
2020-11-20 13:03:55  [ pool-195-thread-1:692371 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:03:55  [ pool-195-thread-1:692371 ] - [ INFO ]  Task attempt_local2045596370_0064_r_000000_0 is allowed to commit now
2020-11-20 13:03:55  [ pool-195-thread-1:692388 ] - [ INFO ]  Saved output of task 'attempt_local2045596370_0064_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2045596370_0064_r_000000
2020-11-20 13:03:55  [ pool-195-thread-1:692389 ] - [ INFO ]  reduce > reduce
2020-11-20 13:03:55  [ pool-195-thread-1:692389 ] - [ INFO ]  Task 'attempt_local2045596370_0064_r_000000_0' done.
2020-11-20 13:03:55  [ pool-195-thread-1:692389 ] - [ INFO ]  Finishing task: attempt_local2045596370_0064_r_000000_0
2020-11-20 13:03:55  [ Thread-1733:692389 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:03:56  [ main:693275 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:03:56  [ main:693276 ] - [ INFO ]  Job job_local2045596370_0064 completed successfully
2020-11-20 13:03:56  [ main:693278 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=564856
		FILE: Number of bytes written=40050596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=180297000
		HDFS: Number of bytes written=266521
		HDFS: Number of read operations=1914
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1013
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2377
		Map output materialized bytes=2092
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2092
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=1676673024
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:03:56  [ main:693298 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:03:56  [ main:693310 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:03:56  [ main:693314 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:03:56  [ main:693320 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:03:56  [ main:693355 ] - [ INFO ]  number of splits:1
2020-11-20 13:03:56  [ main:693372 ] - [ INFO ]  Submitting tokens for job: job_local1381806389_0065
2020-11-20 13:03:56  [ main:693405 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:03:56  [ main:693405 ] - [ INFO ]  Running job: job_local1381806389_0065
2020-11-20 13:03:56  [ Thread-1760:693405 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:03:56  [ Thread-1760:693405 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:56  [ Thread-1760:693405 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:03:56  [ Thread-1760:693414 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693414 ] - [ INFO ]  Starting task: attempt_local1381806389_0065_m_000000_0
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693414 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693414 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693414 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693415 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693422 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693422 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693422 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693422 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693422 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:03:56  [ LocalJobRunner Map Task Executor #0:693422 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:03:57  [ main:694406 ] - [ INFO ]  Job job_local1381806389_0065 running in uber mode : false
2020-11-20 13:03:57  [ main:694406 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:04:02  [ communication thread:699419 ] - [ INFO ]  map > map
2020-11-20 13:04:03  [ main:700417 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:04:05  [ communication thread:702422 ] - [ INFO ]  map > map
2020-11-20 13:04:05  [ main:702425 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702940 ] - [ INFO ]  map > map
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702940 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702940 ] - [ INFO ]  Spilling map output
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702940 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702940 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702942 ] - [ INFO ]  Finished spill 0
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702943 ] - [ INFO ]  Task:attempt_local1381806389_0065_m_000000_0 is done. And is in the process of committing
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702951 ] - [ INFO ]  map
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702951 ] - [ INFO ]  Task 'attempt_local1381806389_0065_m_000000_0' done.
2020-11-20 13:04:05  [ LocalJobRunner Map Task Executor #0:702951 ] - [ INFO ]  Finishing task: attempt_local1381806389_0065_m_000000_0
2020-11-20 13:04:05  [ Thread-1760:702951 ] - [ INFO ]  map task executor complete.
2020-11-20 13:04:05  [ Thread-1760:702951 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:04:05  [ pool-198-thread-1:702951 ] - [ INFO ]  Starting task: attempt_local1381806389_0065_r_000000_0
2020-11-20 13:04:05  [ pool-198-thread-1:702952 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:05  [ pool-198-thread-1:702952 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:05  [ pool-198-thread-1:702952 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:05  [ pool-198-thread-1:702952 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72e6e416
2020-11-20 13:04:05  [ pool-198-thread-1:702953 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:04:05  [ EventFetcher for fetching Map Completion Events:702954 ] - [ INFO ]  attempt_local1381806389_0065_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:04:05  [ localfetcher#65:702955 ] - [ INFO ]  localfetcher#65 about to shuffle output of map attempt_local1381806389_0065_m_000000_0 decomp: 2119 len: 2123 to MEMORY
2020-11-20 13:04:05  [ localfetcher#65:702955 ] - [ INFO ]  Read 2119 bytes from map-output for attempt_local1381806389_0065_m_000000_0
2020-11-20 13:04:05  [ localfetcher#65:702955 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2119
2020-11-20 13:04:05  [ EventFetcher for fetching Map Completion Events:702955 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:04:05  [ pool-198-thread-1:702955 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:05  [ pool-198-thread-1:702955 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:04:05  [ pool-198-thread-1:702956 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:05  [ pool-198-thread-1:702956 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:04:05  [ pool-198-thread-1:702957 ] - [ INFO ]  Merged 1 segments, 2119 bytes to disk to satisfy reduce memory limit
2020-11-20 13:04:05  [ pool-198-thread-1:702957 ] - [ INFO ]  Merging 1 files, 2123 bytes from disk
2020-11-20 13:04:05  [ pool-198-thread-1:702957 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:04:05  [ pool-198-thread-1:702957 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:05  [ pool-198-thread-1:702957 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:04:05  [ pool-198-thread-1:702957 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:06  [ pool-198-thread-1:703056 ] - [ INFO ]  Task:attempt_local1381806389_0065_r_000000_0 is done. And is in the process of committing
2020-11-20 13:04:06  [ pool-198-thread-1:703061 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:06  [ pool-198-thread-1:703061 ] - [ INFO ]  Task attempt_local1381806389_0065_r_000000_0 is allowed to commit now
2020-11-20 13:04:06  [ pool-198-thread-1:703079 ] - [ INFO ]  Saved output of task 'attempt_local1381806389_0065_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1381806389_0065_r_000000
2020-11-20 13:04:06  [ pool-198-thread-1:703079 ] - [ INFO ]  reduce > reduce
2020-11-20 13:04:06  [ pool-198-thread-1:703079 ] - [ INFO ]  Task 'attempt_local1381806389_0065_r_000000_0' done.
2020-11-20 13:04:06  [ pool-198-thread-1:703079 ] - [ INFO ]  Finishing task: attempt_local1381806389_0065_r_000000_0
2020-11-20 13:04:06  [ Thread-1760:703079 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:04:06  [ main:703430 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:04:06  [ main:703430 ] - [ INFO ]  Job job_local1381806389_0065 completed successfully
2020-11-20 13:04:06  [ main:703432 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=573732
		FILE: Number of bytes written=40688151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=183070800
		HDFS: Number of bytes written=270710
		HDFS: Number of read operations=1944
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1029
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2408
		Map output materialized bytes=2123
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2123
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1668284416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:04:06  [ main:703458 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:04:06  [ main:703473 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:04:06  [ main:703478 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:04:06  [ main:703484 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:04:06  [ main:703521 ] - [ INFO ]  number of splits:1
2020-11-20 13:04:06  [ main:703537 ] - [ INFO ]  Submitting tokens for job: job_local1777677108_0066
2020-11-20 13:04:06  [ main:703570 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:04:06  [ main:703570 ] - [ INFO ]  Running job: job_local1777677108_0066
2020-11-20 13:04:06  [ Thread-1787:703571 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:04:06  [ Thread-1787:703571 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:06  [ Thread-1787:703571 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:04:06  [ Thread-1787:703583 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703583 ] - [ INFO ]  Starting task: attempt_local1777677108_0066_m_000000_0
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703583 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703583 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703583 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703584 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703591 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703591 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703591 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703591 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703591 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:04:06  [ LocalJobRunner Map Task Executor #0:703591 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:04:07  [ main:704575 ] - [ INFO ]  Job job_local1777677108_0066 running in uber mode : false
2020-11-20 13:04:07  [ main:704576 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:04:12  [ communication thread:709589 ] - [ INFO ]  map > map
2020-11-20 13:04:12  [ main:709591 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:04:15  [ communication thread:712592 ] - [ INFO ]  map > map
2020-11-20 13:04:15  [ main:712600 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713530 ] - [ INFO ]  map > map
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713530 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713530 ] - [ INFO ]  Spilling map output
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713530 ] - [ INFO ]  bufstart = 0; bufend = 2381; bufvoid = 104857600
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713530 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713533 ] - [ INFO ]  Finished spill 0
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713534 ] - [ INFO ]  Task:attempt_local1777677108_0066_m_000000_0 is done. And is in the process of committing
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713541 ] - [ INFO ]  map
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713541 ] - [ INFO ]  Task 'attempt_local1777677108_0066_m_000000_0' done.
2020-11-20 13:04:16  [ LocalJobRunner Map Task Executor #0:713541 ] - [ INFO ]  Finishing task: attempt_local1777677108_0066_m_000000_0
2020-11-20 13:04:16  [ Thread-1787:713541 ] - [ INFO ]  map task executor complete.
2020-11-20 13:04:16  [ Thread-1787:713541 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:04:16  [ pool-201-thread-1:713541 ] - [ INFO ]  Starting task: attempt_local1777677108_0066_r_000000_0
2020-11-20 13:04:16  [ pool-201-thread-1:713542 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:16  [ pool-201-thread-1:713542 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:16  [ pool-201-thread-1:713542 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:16  [ pool-201-thread-1:713542 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3c6203e4
2020-11-20 13:04:16  [ pool-201-thread-1:713543 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:04:16  [ EventFetcher for fetching Map Completion Events:713543 ] - [ INFO ]  attempt_local1777677108_0066_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:04:16  [ localfetcher#66:713544 ] - [ INFO ]  localfetcher#66 about to shuffle output of map attempt_local1777677108_0066_m_000000_0 decomp: 2092 len: 2096 to MEMORY
2020-11-20 13:04:16  [ localfetcher#66:713544 ] - [ INFO ]  Read 2092 bytes from map-output for attempt_local1777677108_0066_m_000000_0
2020-11-20 13:04:16  [ localfetcher#66:713544 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2092, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2092
2020-11-20 13:04:16  [ EventFetcher for fetching Map Completion Events:713544 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:04:16  [ pool-201-thread-1:713544 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:16  [ pool-201-thread-1:713544 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:04:16  [ pool-201-thread-1:713545 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:16  [ pool-201-thread-1:713545 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 13:04:16  [ pool-201-thread-1:713545 ] - [ INFO ]  Merged 1 segments, 2092 bytes to disk to satisfy reduce memory limit
2020-11-20 13:04:16  [ pool-201-thread-1:713546 ] - [ INFO ]  Merging 1 files, 2096 bytes from disk
2020-11-20 13:04:16  [ pool-201-thread-1:713546 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:04:16  [ pool-201-thread-1:713546 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:16  [ pool-201-thread-1:713546 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 13:04:16  [ pool-201-thread-1:713546 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:16  [ main:713600 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:04:16  [ pool-201-thread-1:713726 ] - [ INFO ]  Task:attempt_local1777677108_0066_r_000000_0 is done. And is in the process of committing
2020-11-20 13:04:16  [ pool-201-thread-1:713739 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:16  [ pool-201-thread-1:713739 ] - [ INFO ]  Task attempt_local1777677108_0066_r_000000_0 is allowed to commit now
2020-11-20 13:04:16  [ pool-201-thread-1:713782 ] - [ INFO ]  Saved output of task 'attempt_local1777677108_0066_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1777677108_0066_r_000000
2020-11-20 13:04:16  [ pool-201-thread-1:713783 ] - [ INFO ]  reduce > reduce
2020-11-20 13:04:16  [ pool-201-thread-1:713783 ] - [ INFO ]  Task 'attempt_local1777677108_0066_r_000000_0' done.
2020-11-20 13:04:16  [ pool-201-thread-1:713783 ] - [ INFO ]  Finishing task: attempt_local1777677108_0066_r_000000_0
2020-11-20 13:04:16  [ Thread-1787:713783 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:04:17  [ main:714602 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:04:17  [ main:714602 ] - [ INFO ]  Job job_local1777677108_0066 completed successfully
2020-11-20 13:04:17  [ main:714604 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=582616
		FILE: Number of bytes written=41325956
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=185844600
		HDFS: Number of bytes written=274903
		HDFS: Number of read operations=1974
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1045
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2381
		Map output materialized bytes=2096
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2096
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=1602224128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:04:17  [ main:714642 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:04:17  [ main:714654 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:04:17  [ main:714657 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:04:17  [ main:714665 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:04:17  [ main:714701 ] - [ INFO ]  number of splits:1
2020-11-20 13:04:17  [ main:714717 ] - [ INFO ]  Submitting tokens for job: job_local1243412555_0067
2020-11-20 13:04:17  [ main:714749 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:04:17  [ main:714749 ] - [ INFO ]  Running job: job_local1243412555_0067
2020-11-20 13:04:17  [ Thread-1814:714749 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:04:17  [ Thread-1814:714749 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:17  [ Thread-1814:714749 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:04:17  [ Thread-1814:714764 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714764 ] - [ INFO ]  Starting task: attempt_local1243412555_0067_m_000000_0
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714765 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714765 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714765 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714765 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714773 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714773 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714773 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714773 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714773 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:04:17  [ LocalJobRunner Map Task Executor #0:714773 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:04:18  [ main:715750 ] - [ INFO ]  Job job_local1243412555_0067 running in uber mode : false
2020-11-20 13:04:18  [ main:715750 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:04:23  [ communication thread:720770 ] - [ INFO ]  map > map
2020-11-20 13:04:24  [ main:721771 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:04:26  [ communication thread:723775 ] - [ INFO ]  map > map
2020-11-20 13:04:26  [ main:723780 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724326 ] - [ INFO ]  map > map
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724327 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724327 ] - [ INFO ]  Spilling map output
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724327 ] - [ INFO ]  bufstart = 0; bufend = 2381; bufvoid = 104857600
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724327 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724329 ] - [ INFO ]  Finished spill 0
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724330 ] - [ INFO ]  Task:attempt_local1243412555_0067_m_000000_0 is done. And is in the process of committing
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724337 ] - [ INFO ]  map
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724337 ] - [ INFO ]  Task 'attempt_local1243412555_0067_m_000000_0' done.
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724337 ] - [ INFO ]  Finishing task: attempt_local1243412555_0067_m_000000_0
2020-11-20 13:04:27  [ Thread-1814:724337 ] - [ INFO ]  map task executor complete.
2020-11-20 13:04:27  [ Thread-1814:724337 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:04:27  [ pool-204-thread-1:724337 ] - [ INFO ]  Starting task: attempt_local1243412555_0067_r_000000_0
2020-11-20 13:04:27  [ pool-204-thread-1:724338 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:27  [ pool-204-thread-1:724338 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:27  [ pool-204-thread-1:724338 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:27  [ pool-204-thread-1:724338 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ec24d5e
2020-11-20 13:04:27  [ pool-204-thread-1:724339 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:04:27  [ EventFetcher for fetching Map Completion Events:724339 ] - [ INFO ]  attempt_local1243412555_0067_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:04:27  [ localfetcher#67:724340 ] - [ INFO ]  localfetcher#67 about to shuffle output of map attempt_local1243412555_0067_m_000000_0 decomp: 2092 len: 2096 to MEMORY
2020-11-20 13:04:27  [ localfetcher#67:724340 ] - [ INFO ]  Read 2092 bytes from map-output for attempt_local1243412555_0067_m_000000_0
2020-11-20 13:04:27  [ localfetcher#67:724340 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2092, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2092
2020-11-20 13:04:27  [ EventFetcher for fetching Map Completion Events:724341 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:04:27  [ pool-204-thread-1:724341 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:27  [ pool-204-thread-1:724341 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Merged 1 segments, 2092 bytes to disk to satisfy reduce memory limit
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Merging 1 files, 2096 bytes from disk
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2085 bytes
2020-11-20 13:04:27  [ pool-204-thread-1:724342 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:27  [ pool-204-thread-1:724426 ] - [ INFO ]  Task:attempt_local1243412555_0067_r_000000_0 is done. And is in the process of committing
2020-11-20 13:04:27  [ pool-204-thread-1:724432 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:27  [ pool-204-thread-1:724432 ] - [ INFO ]  Task attempt_local1243412555_0067_r_000000_0 is allowed to commit now
2020-11-20 13:04:27  [ pool-204-thread-1:724450 ] - [ INFO ]  Saved output of task 'attempt_local1243412555_0067_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1243412555_0067_r_000000
2020-11-20 13:04:27  [ pool-204-thread-1:724450 ] - [ INFO ]  reduce > reduce
2020-11-20 13:04:27  [ pool-204-thread-1:724450 ] - [ INFO ]  Task 'attempt_local1243412555_0067_r_000000_0' done.
2020-11-20 13:04:27  [ pool-204-thread-1:724450 ] - [ INFO ]  Finishing task: attempt_local1243412555_0067_r_000000_0
2020-11-20 13:04:27  [ Thread-1814:724450 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:04:27  [ main:724784 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:04:27  [ main:724784 ] - [ INFO ]  Job job_local1243412555_0067 completed successfully
2020-11-20 13:04:27  [ main:724786 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=591446
		FILE: Number of bytes written=41963734
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=188618400
		HDFS: Number of bytes written=279069
		HDFS: Number of read operations=2004
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1061
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2381
		Map output materialized bytes=2096
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2096
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1594884096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:04:27  [ main:724804 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:04:27  [ main:724816 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:04:27  [ main:724820 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:04:27  [ main:724826 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:04:27  [ main:724862 ] - [ INFO ]  number of splits:1
2020-11-20 13:04:27  [ main:724878 ] - [ INFO ]  Submitting tokens for job: job_local944875824_0068
2020-11-20 13:04:27  [ main:724910 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:04:27  [ main:724910 ] - [ INFO ]  Running job: job_local944875824_0068
2020-11-20 13:04:27  [ Thread-1841:724911 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:04:27  [ Thread-1841:724911 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:27  [ Thread-1841:724911 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:04:27  [ Thread-1841:724918 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724918 ] - [ INFO ]  Starting task: attempt_local944875824_0068_m_000000_0
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724918 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724918 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724918 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724919 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724926 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724926 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724926 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724926 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724926 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:04:27  [ LocalJobRunner Map Task Executor #0:724927 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:04:28  [ main:725911 ] - [ INFO ]  Job job_local944875824_0068 running in uber mode : false
2020-11-20 13:04:28  [ main:725911 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:04:33  [ communication thread:730926 ] - [ INFO ]  map > map
2020-11-20 13:04:34  [ main:731927 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:04:36  [ communication thread:733931 ] - [ INFO ]  map > map
2020-11-20 13:04:36  [ main:733933 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735071 ] - [ INFO ]  map > map
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735071 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735071 ] - [ INFO ]  Spilling map output
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735071 ] - [ INFO ]  bufstart = 0; bufend = 2415; bufvoid = 104857600
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735071 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735073 ] - [ INFO ]  Finished spill 0
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735074 ] - [ INFO ]  Task:attempt_local944875824_0068_m_000000_0 is done. And is in the process of committing
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735114 ] - [ INFO ]  map
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735114 ] - [ INFO ]  Task 'attempt_local944875824_0068_m_000000_0' done.
2020-11-20 13:04:38  [ LocalJobRunner Map Task Executor #0:735114 ] - [ INFO ]  Finishing task: attempt_local944875824_0068_m_000000_0
2020-11-20 13:04:38  [ Thread-1841:735114 ] - [ INFO ]  map task executor complete.
2020-11-20 13:04:38  [ Thread-1841:735115 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:04:38  [ pool-207-thread-1:735115 ] - [ INFO ]  Starting task: attempt_local944875824_0068_r_000000_0
2020-11-20 13:04:38  [ pool-207-thread-1:735116 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:38  [ pool-207-thread-1:735116 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:38  [ pool-207-thread-1:735116 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:38  [ pool-207-thread-1:735116 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68415489
2020-11-20 13:04:38  [ pool-207-thread-1:735117 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:04:38  [ EventFetcher for fetching Map Completion Events:735117 ] - [ INFO ]  attempt_local944875824_0068_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:04:38  [ localfetcher#68:735118 ] - [ INFO ]  localfetcher#68 about to shuffle output of map attempt_local944875824_0068_m_000000_0 decomp: 2126 len: 2130 to MEMORY
2020-11-20 13:04:38  [ localfetcher#68:735118 ] - [ INFO ]  Read 2126 bytes from map-output for attempt_local944875824_0068_m_000000_0
2020-11-20 13:04:38  [ localfetcher#68:735118 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2126, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2126
2020-11-20 13:04:38  [ EventFetcher for fetching Map Completion Events:735119 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:04:38  [ pool-207-thread-1:735119 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:38  [ pool-207-thread-1:735119 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:04:38  [ pool-207-thread-1:735120 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:38  [ pool-207-thread-1:735120 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2119 bytes
2020-11-20 13:04:38  [ pool-207-thread-1:735120 ] - [ INFO ]  Merged 1 segments, 2126 bytes to disk to satisfy reduce memory limit
2020-11-20 13:04:38  [ pool-207-thread-1:735120 ] - [ INFO ]  Merging 1 files, 2130 bytes from disk
2020-11-20 13:04:38  [ pool-207-thread-1:735120 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:04:38  [ pool-207-thread-1:735120 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:38  [ pool-207-thread-1:735121 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2119 bytes
2020-11-20 13:04:38  [ pool-207-thread-1:735121 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:38  [ main:735934 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:04:39  [ pool-207-thread-1:736170 ] - [ INFO ]  Task:attempt_local944875824_0068_r_000000_0 is done. And is in the process of committing
2020-11-20 13:04:39  [ pool-207-thread-1:736182 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:39  [ pool-207-thread-1:736183 ] - [ INFO ]  Task attempt_local944875824_0068_r_000000_0 is allowed to commit now
2020-11-20 13:04:39  [ pool-207-thread-1:736339 ] - [ INFO ]  Saved output of task 'attempt_local944875824_0068_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local944875824_0068_r_000000
2020-11-20 13:04:39  [ pool-207-thread-1:736339 ] - [ INFO ]  reduce > reduce
2020-11-20 13:04:39  [ pool-207-thread-1:736340 ] - [ INFO ]  Task 'attempt_local944875824_0068_r_000000_0' done.
2020-11-20 13:04:39  [ pool-207-thread-1:736340 ] - [ INFO ]  Finishing task: attempt_local944875824_0068_r_000000_0
2020-11-20 13:04:39  [ Thread-1841:736340 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:04:39  [ main:736939 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:04:39  [ main:736939 ] - [ INFO ]  Job job_local944875824_0068 completed successfully
2020-11-20 13:04:39  [ main:736940 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=600344
		FILE: Number of bytes written=42599478
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=191392200
		HDFS: Number of bytes written=283269
		HDFS: Number of read operations=2034
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1077
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2415
		Map output materialized bytes=2130
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2130
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=1525678080
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:04:40  [ main:737047 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:04:40  [ main:737063 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:04:40  [ main:737068 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:04:40  [ main:737078 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:04:40  [ main:737119 ] - [ INFO ]  number of splits:1
2020-11-20 13:04:40  [ main:737136 ] - [ INFO ]  Submitting tokens for job: job_local1866367840_0069
2020-11-20 13:04:40  [ main:737170 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:04:40  [ main:737170 ] - [ INFO ]  Running job: job_local1866367840_0069
2020-11-20 13:04:40  [ Thread-1869:737170 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:04:40  [ Thread-1869:737170 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:40  [ Thread-1869:737170 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:04:40  [ Thread-1869:737180 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737180 ] - [ INFO ]  Starting task: attempt_local1866367840_0069_m_000000_0
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737181 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737181 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737181 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737181 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737190 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737190 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737190 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737190 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737190 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:04:40  [ LocalJobRunner Map Task Executor #0:737190 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:04:41  [ main:738175 ] - [ INFO ]  Job job_local1866367840_0069 running in uber mode : false
2020-11-20 13:04:41  [ main:738175 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:04:46  [ communication thread:743187 ] - [ INFO ]  map > map
2020-11-20 13:04:46  [ main:743195 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:04:49  [ communication thread:746191 ] - [ INFO ]  map > map
2020-11-20 13:04:49  [ main:746203 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746625 ] - [ INFO ]  map > map
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746626 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746626 ] - [ INFO ]  Spilling map output
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746626 ] - [ INFO ]  bufstart = 0; bufend = 2430; bufvoid = 104857600
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746626 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746628 ] - [ INFO ]  Finished spill 0
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746628 ] - [ INFO ]  Task:attempt_local1866367840_0069_m_000000_0 is done. And is in the process of committing
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746638 ] - [ INFO ]  map
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746638 ] - [ INFO ]  Task 'attempt_local1866367840_0069_m_000000_0' done.
2020-11-20 13:04:49  [ LocalJobRunner Map Task Executor #0:746638 ] - [ INFO ]  Finishing task: attempt_local1866367840_0069_m_000000_0
2020-11-20 13:04:49  [ Thread-1869:746638 ] - [ INFO ]  map task executor complete.
2020-11-20 13:04:49  [ Thread-1869:746638 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:04:49  [ pool-210-thread-1:746639 ] - [ INFO ]  Starting task: attempt_local1866367840_0069_r_000000_0
2020-11-20 13:04:49  [ pool-210-thread-1:746639 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:49  [ pool-210-thread-1:746639 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:49  [ pool-210-thread-1:746639 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:49  [ pool-210-thread-1:746639 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56bad934
2020-11-20 13:04:49  [ pool-210-thread-1:746640 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:04:49  [ EventFetcher for fetching Map Completion Events:746641 ] - [ INFO ]  attempt_local1866367840_0069_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:04:49  [ localfetcher#69:746641 ] - [ INFO ]  localfetcher#69 about to shuffle output of map attempt_local1866367840_0069_m_000000_0 decomp: 2141 len: 2145 to MEMORY
2020-11-20 13:04:49  [ localfetcher#69:746642 ] - [ INFO ]  Read 2141 bytes from map-output for attempt_local1866367840_0069_m_000000_0
2020-11-20 13:04:49  [ localfetcher#69:746642 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2141, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2141
2020-11-20 13:04:49  [ EventFetcher for fetching Map Completion Events:746642 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:04:49  [ pool-210-thread-1:746642 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:49  [ pool-210-thread-1:746642 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:04:49  [ pool-210-thread-1:746643 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:49  [ pool-210-thread-1:746643 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2134 bytes
2020-11-20 13:04:49  [ pool-210-thread-1:746643 ] - [ INFO ]  Merged 1 segments, 2141 bytes to disk to satisfy reduce memory limit
2020-11-20 13:04:49  [ pool-210-thread-1:746643 ] - [ INFO ]  Merging 1 files, 2145 bytes from disk
2020-11-20 13:04:49  [ pool-210-thread-1:746643 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:04:49  [ pool-210-thread-1:746643 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:49  [ pool-210-thread-1:746644 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2134 bytes
2020-11-20 13:04:49  [ pool-210-thread-1:746644 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:49  [ pool-210-thread-1:746752 ] - [ INFO ]  Task:attempt_local1866367840_0069_r_000000_0 is done. And is in the process of committing
2020-11-20 13:04:49  [ pool-210-thread-1:746762 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:49  [ pool-210-thread-1:746762 ] - [ INFO ]  Task attempt_local1866367840_0069_r_000000_0 is allowed to commit now
2020-11-20 13:04:49  [ pool-210-thread-1:746789 ] - [ INFO ]  Saved output of task 'attempt_local1866367840_0069_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1866367840_0069_r_000000
2020-11-20 13:04:49  [ pool-210-thread-1:746789 ] - [ INFO ]  reduce > reduce
2020-11-20 13:04:49  [ pool-210-thread-1:746790 ] - [ INFO ]  Task 'attempt_local1866367840_0069_r_000000_0' done.
2020-11-20 13:04:49  [ pool-210-thread-1:746790 ] - [ INFO ]  Finishing task: attempt_local1866367840_0069_r_000000_0
2020-11-20 13:04:49  [ Thread-1869:746790 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:04:50  [ main:747208 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:04:50  [ main:747208 ] - [ INFO ]  Job job_local1866367840_0069 completed successfully
2020-11-20 13:04:50  [ main:747209 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=609340
		FILE: Number of bytes written=43238901
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=194166000
		HDFS: Number of bytes written=287518
		HDFS: Number of read operations=2064
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1093
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2430
		Map output materialized bytes=2145
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2145
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=1563426816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:04:50  [ main:747237 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:04:50  [ main:747251 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:04:50  [ main:747255 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:04:50  [ main:747264 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:04:50  [ main:747306 ] - [ INFO ]  number of splits:1
2020-11-20 13:04:50  [ main:747322 ] - [ INFO ]  Submitting tokens for job: job_local860649291_0070
2020-11-20 13:04:50  [ main:747355 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:04:50  [ main:747355 ] - [ INFO ]  Running job: job_local860649291_0070
2020-11-20 13:04:50  [ Thread-1896:747355 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:04:50  [ Thread-1896:747355 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:50  [ Thread-1896:747355 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:04:50  [ Thread-1896:747366 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747366 ] - [ INFO ]  Starting task: attempt_local860649291_0070_m_000000_0
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747366 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747366 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747366 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747367 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747374 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747374 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747374 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747374 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747374 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:04:50  [ LocalJobRunner Map Task Executor #0:747374 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:04:51  [ main:748359 ] - [ INFO ]  Job job_local860649291_0070 running in uber mode : false
2020-11-20 13:04:51  [ main:748359 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:04:56  [ communication thread:753375 ] - [ INFO ]  map > map
2020-11-20 13:04:56  [ main:753377 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:04:59  [ communication thread:756378 ] - [ INFO ]  map > map
2020-11-20 13:04:59  [ main:756388 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756962 ] - [ INFO ]  map > map
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756962 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756962 ] - [ INFO ]  Spilling map output
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756962 ] - [ INFO ]  bufstart = 0; bufend = 2408; bufvoid = 104857600
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756962 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756964 ] - [ INFO ]  Finished spill 0
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756965 ] - [ INFO ]  Task:attempt_local860649291_0070_m_000000_0 is done. And is in the process of committing
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756974 ] - [ INFO ]  map
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756974 ] - [ INFO ]  Task 'attempt_local860649291_0070_m_000000_0' done.
2020-11-20 13:04:59  [ LocalJobRunner Map Task Executor #0:756974 ] - [ INFO ]  Finishing task: attempt_local860649291_0070_m_000000_0
2020-11-20 13:04:59  [ Thread-1896:756974 ] - [ INFO ]  map task executor complete.
2020-11-20 13:04:59  [ Thread-1896:756974 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:04:59  [ pool-213-thread-1:756975 ] - [ INFO ]  Starting task: attempt_local860649291_0070_r_000000_0
2020-11-20 13:04:59  [ pool-213-thread-1:756975 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:04:59  [ pool-213-thread-1:756975 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:04:59  [ pool-213-thread-1:756975 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:04:59  [ pool-213-thread-1:756975 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f04d135
2020-11-20 13:04:59  [ pool-213-thread-1:756976 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:04:59  [ EventFetcher for fetching Map Completion Events:756977 ] - [ INFO ]  attempt_local860649291_0070_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:04:59  [ localfetcher#70:756977 ] - [ INFO ]  localfetcher#70 about to shuffle output of map attempt_local860649291_0070_m_000000_0 decomp: 2119 len: 2123 to MEMORY
2020-11-20 13:04:59  [ localfetcher#70:756978 ] - [ INFO ]  Read 2119 bytes from map-output for attempt_local860649291_0070_m_000000_0
2020-11-20 13:04:59  [ localfetcher#70:756978 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2119
2020-11-20 13:04:59  [ EventFetcher for fetching Map Completion Events:756978 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:04:59  [ pool-213-thread-1:756978 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:04:59  [ pool-213-thread-1:756978 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Merged 1 segments, 2119 bytes to disk to satisfy reduce memory limit
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Merging 1 files, 2123 bytes from disk
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:04:59  [ pool-213-thread-1:756979 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2112 bytes
2020-11-20 13:04:59  [ pool-213-thread-1:756980 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:00  [ pool-213-thread-1:757383 ] - [ INFO ]  Task:attempt_local860649291_0070_r_000000_0 is done. And is in the process of committing
2020-11-20 13:05:00  [ main:757389 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:05:00  [ pool-213-thread-1:757393 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:00  [ pool-213-thread-1:757393 ] - [ INFO ]  Task attempt_local860649291_0070_r_000000_0 is allowed to commit now
2020-11-20 13:05:00  [ pool-213-thread-1:757459 ] - [ INFO ]  Saved output of task 'attempt_local860649291_0070_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local860649291_0070_r_000000
2020-11-20 13:05:00  [ pool-213-thread-1:757459 ] - [ INFO ]  reduce > reduce
2020-11-20 13:05:00  [ pool-213-thread-1:757459 ] - [ INFO ]  Task 'attempt_local860649291_0070_r_000000_0' done.
2020-11-20 13:05:00  [ pool-213-thread-1:757459 ] - [ INFO ]  Finishing task: attempt_local860649291_0070_r_000000_0
2020-11-20 13:05:00  [ Thread-1896:757459 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:05:01  [ main:758390 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:05:01  [ main:758390 ] - [ INFO ]  Job job_local860649291_0070 completed successfully
2020-11-20 13:05:01  [ main:758391 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=618322
		FILE: Number of bytes written=43876249
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=196939800
		HDFS: Number of bytes written=291760
		HDFS: Number of read operations=2094
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1109
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2408
		Map output materialized bytes=2123
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2123
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1
		Total committed heap usage (bytes)=1553989632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:05:01  [ main:758418 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:05:01  [ main:758429 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:05:01  [ main:758433 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:05:01  [ main:758442 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:05:01  [ main:758480 ] - [ INFO ]  number of splits:1
2020-11-20 13:05:01  [ main:758496 ] - [ INFO ]  Submitting tokens for job: job_local377508264_0071
2020-11-20 13:05:01  [ main:758529 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:05:01  [ main:758529 ] - [ INFO ]  Running job: job_local377508264_0071
2020-11-20 13:05:01  [ Thread-1923:758529 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:05:01  [ Thread-1923:758530 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:01  [ Thread-1923:758530 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:05:01  [ Thread-1923:758540 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758540 ] - [ INFO ]  Starting task: attempt_local377508264_0071_m_000000_0
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758541 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758541 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758541 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758541 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758549 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758550 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758550 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758550 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758550 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:05:01  [ LocalJobRunner Map Task Executor #0:758550 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:05:02  [ main:759533 ] - [ INFO ]  Job job_local377508264_0071 running in uber mode : false
2020-11-20 13:05:02  [ main:759533 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:05:07  [ communication thread:764547 ] - [ INFO ]  map > map
2020-11-20 13:05:08  [ main:765549 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:05:10  [ communication thread:767553 ] - [ INFO ]  map > map
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768079 ] - [ INFO ]  map > map
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768079 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768079 ] - [ INFO ]  Spilling map output
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768080 ] - [ INFO ]  bufstart = 0; bufend = 2389; bufvoid = 104857600
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768080 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768081 ] - [ INFO ]  Finished spill 0
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768082 ] - [ INFO ]  Task:attempt_local377508264_0071_m_000000_0 is done. And is in the process of committing
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768091 ] - [ INFO ]  map
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768091 ] - [ INFO ]  Task 'attempt_local377508264_0071_m_000000_0' done.
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768091 ] - [ INFO ]  Finishing task: attempt_local377508264_0071_m_000000_0
2020-11-20 13:05:11  [ Thread-1923:768091 ] - [ INFO ]  map task executor complete.
2020-11-20 13:05:11  [ Thread-1923:768092 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:05:11  [ pool-216-thread-1:768092 ] - [ INFO ]  Starting task: attempt_local377508264_0071_r_000000_0
2020-11-20 13:05:11  [ pool-216-thread-1:768092 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:11  [ pool-216-thread-1:768093 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:11  [ pool-216-thread-1:768093 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:11  [ pool-216-thread-1:768093 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56f97d3
2020-11-20 13:05:11  [ pool-216-thread-1:768094 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:05:11  [ EventFetcher for fetching Map Completion Events:768094 ] - [ INFO ]  attempt_local377508264_0071_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:05:11  [ localfetcher#71:768094 ] - [ INFO ]  localfetcher#71 about to shuffle output of map attempt_local377508264_0071_m_000000_0 decomp: 2100 len: 2104 to MEMORY
2020-11-20 13:05:11  [ localfetcher#71:768094 ] - [ INFO ]  Read 2100 bytes from map-output for attempt_local377508264_0071_m_000000_0
2020-11-20 13:05:11  [ localfetcher#71:768094 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2100, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2100
2020-11-20 13:05:11  [ EventFetcher for fetching Map Completion Events:768095 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:05:11  [ pool-216-thread-1:768095 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:11  [ pool-216-thread-1:768095 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:05:11  [ pool-216-thread-1:768095 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:11  [ pool-216-thread-1:768095 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2093 bytes
2020-11-20 13:05:11  [ pool-216-thread-1:768096 ] - [ INFO ]  Merged 1 segments, 2100 bytes to disk to satisfy reduce memory limit
2020-11-20 13:05:11  [ pool-216-thread-1:768096 ] - [ INFO ]  Merging 1 files, 2104 bytes from disk
2020-11-20 13:05:11  [ pool-216-thread-1:768096 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:05:11  [ pool-216-thread-1:768096 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:11  [ pool-216-thread-1:768096 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2093 bytes
2020-11-20 13:05:11  [ pool-216-thread-1:768096 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:11  [ pool-216-thread-1:768198 ] - [ INFO ]  Task:attempt_local377508264_0071_r_000000_0 is done. And is in the process of committing
2020-11-20 13:05:11  [ pool-216-thread-1:768206 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:11  [ pool-216-thread-1:768206 ] - [ INFO ]  Task attempt_local377508264_0071_r_000000_0 is allowed to commit now
2020-11-20 13:05:11  [ pool-216-thread-1:768233 ] - [ INFO ]  Saved output of task 'attempt_local377508264_0071_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local377508264_0071_r_000000
2020-11-20 13:05:11  [ pool-216-thread-1:768234 ] - [ INFO ]  reduce > reduce
2020-11-20 13:05:11  [ pool-216-thread-1:768234 ] - [ INFO ]  Task 'attempt_local377508264_0071_r_000000_0' done.
2020-11-20 13:05:11  [ pool-216-thread-1:768234 ] - [ INFO ]  Finishing task: attempt_local377508264_0071_r_000000_0
2020-11-20 13:05:11  [ Thread-1923:768234 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:05:11  [ main:768558 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:05:11  [ main:768558 ] - [ INFO ]  Job job_local377508264_0071 completed successfully
2020-11-20 13:05:11  [ main:768559 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=627222
		FILE: Number of bytes written=44515382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=199713600
		HDFS: Number of bytes written=295961
		HDFS: Number of read operations=2124
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1125
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2389
		Map output materialized bytes=2104
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2104
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=1485832192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:05:11  [ main:768606 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:05:11  [ main:768628 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:05:11  [ main:768634 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:05:11  [ main:768643 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:05:11  [ main:768683 ] - [ INFO ]  number of splits:1
2020-11-20 13:05:11  [ main:768702 ] - [ INFO ]  Submitting tokens for job: job_local1097634921_0072
2020-11-20 13:05:11  [ main:768737 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:05:11  [ main:768737 ] - [ INFO ]  Running job: job_local1097634921_0072
2020-11-20 13:05:11  [ Thread-1950:768737 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:05:11  [ Thread-1950:768738 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:11  [ Thread-1950:768738 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:05:11  [ Thread-1950:768748 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768748 ] - [ INFO ]  Starting task: attempt_local1097634921_0072_m_000000_0
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768748 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768749 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768749 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768749 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768758 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768758 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768758 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768758 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768758 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:05:11  [ LocalJobRunner Map Task Executor #0:768758 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:05:12  [ main:769741 ] - [ INFO ]  Job job_local1097634921_0072 running in uber mode : false
2020-11-20 13:05:12  [ main:769741 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:05:17  [ communication thread:774753 ] - [ INFO ]  map > map
2020-11-20 13:05:18  [ main:775750 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:05:20  [ communication thread:777758 ] - [ INFO ]  map > map
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778485 ] - [ INFO ]  map > map
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778485 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778485 ] - [ INFO ]  Spilling map output
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778485 ] - [ INFO ]  bufstart = 0; bufend = 2377; bufvoid = 104857600
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778485 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778487 ] - [ INFO ]  Finished spill 0
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778487 ] - [ INFO ]  Task:attempt_local1097634921_0072_m_000000_0 is done. And is in the process of committing
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778496 ] - [ INFO ]  map
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778496 ] - [ INFO ]  Task 'attempt_local1097634921_0072_m_000000_0' done.
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778496 ] - [ INFO ]  Finishing task: attempt_local1097634921_0072_m_000000_0
2020-11-20 13:05:21  [ Thread-1950:778496 ] - [ INFO ]  map task executor complete.
2020-11-20 13:05:21  [ Thread-1950:778497 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:05:21  [ pool-219-thread-1:778497 ] - [ INFO ]  Starting task: attempt_local1097634921_0072_r_000000_0
2020-11-20 13:05:21  [ pool-219-thread-1:778497 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:21  [ pool-219-thread-1:778497 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:21  [ pool-219-thread-1:778497 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:21  [ pool-219-thread-1:778497 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ee22257
2020-11-20 13:05:21  [ pool-219-thread-1:778498 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:05:21  [ EventFetcher for fetching Map Completion Events:778498 ] - [ INFO ]  attempt_local1097634921_0072_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:05:21  [ localfetcher#72:778499 ] - [ INFO ]  localfetcher#72 about to shuffle output of map attempt_local1097634921_0072_m_000000_0 decomp: 2088 len: 2092 to MEMORY
2020-11-20 13:05:21  [ localfetcher#72:778499 ] - [ INFO ]  Read 2088 bytes from map-output for attempt_local1097634921_0072_m_000000_0
2020-11-20 13:05:21  [ localfetcher#72:778499 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2088, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2088
2020-11-20 13:05:21  [ EventFetcher for fetching Map Completion Events:778499 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:05:21  [ pool-219-thread-1:778500 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:21  [ pool-219-thread-1:778500 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:05:21  [ pool-219-thread-1:778500 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:21  [ pool-219-thread-1:778500 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2081 bytes
2020-11-20 13:05:21  [ pool-219-thread-1:778501 ] - [ INFO ]  Merged 1 segments, 2088 bytes to disk to satisfy reduce memory limit
2020-11-20 13:05:21  [ pool-219-thread-1:778501 ] - [ INFO ]  Merging 1 files, 2092 bytes from disk
2020-11-20 13:05:21  [ pool-219-thread-1:778501 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:05:21  [ pool-219-thread-1:778501 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:21  [ pool-219-thread-1:778501 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2081 bytes
2020-11-20 13:05:21  [ pool-219-thread-1:778501 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:21  [ pool-219-thread-1:778640 ] - [ INFO ]  Task:attempt_local1097634921_0072_r_000000_0 is done. And is in the process of committing
2020-11-20 13:05:21  [ pool-219-thread-1:778657 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:21  [ pool-219-thread-1:778657 ] - [ INFO ]  Task attempt_local1097634921_0072_r_000000_0 is allowed to commit now
2020-11-20 13:05:21  [ pool-219-thread-1:778688 ] - [ INFO ]  Saved output of task 'attempt_local1097634921_0072_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1097634921_0072_r_000000
2020-11-20 13:05:21  [ pool-219-thread-1:778689 ] - [ INFO ]  reduce > reduce
2020-11-20 13:05:21  [ pool-219-thread-1:778689 ] - [ INFO ]  Task 'attempt_local1097634921_0072_r_000000_0' done.
2020-11-20 13:05:21  [ pool-219-thread-1:778689 ] - [ INFO ]  Finishing task: attempt_local1097634921_0072_r_000000_0
2020-11-20 13:05:21  [ Thread-1950:778689 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:05:21  [ main:778761 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:05:21  [ main:778761 ] - [ INFO ]  Job job_local1097634921_0072 completed successfully
2020-11-20 13:05:21  [ main:778762 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=636060
		FILE: Number of bytes written=45158392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=202487400
		HDFS: Number of bytes written=300131
		HDFS: Number of read operations=2154
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1141
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2377
		Map output materialized bytes=2092
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2092
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1477443584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:05:21  [ main:778792 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:05:21  [ main:778805 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:05:21  [ main:778809 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:05:21  [ main:778817 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:05:21  [ main:778859 ] - [ INFO ]  number of splits:1
2020-11-20 13:05:21  [ main:778875 ] - [ INFO ]  Submitting tokens for job: job_local1685596291_0073
2020-11-20 13:05:21  [ main:778908 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:05:21  [ main:778908 ] - [ INFO ]  Running job: job_local1685596291_0073
2020-11-20 13:05:21  [ Thread-1977:778908 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:05:21  [ Thread-1977:778908 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:21  [ Thread-1977:778908 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:05:21  [ Thread-1977:778919 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778919 ] - [ INFO ]  Starting task: attempt_local1685596291_0073_m_000000_0
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778920 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778920 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778920 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778928 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778928 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778928 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778928 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778928 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:05:21  [ LocalJobRunner Map Task Executor #0:778929 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:05:22  [ main:779912 ] - [ INFO ]  Job job_local1685596291_0073 running in uber mode : false
2020-11-20 13:05:22  [ main:779912 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:05:27  [ communication thread:784925 ] - [ INFO ]  map > map
2020-11-20 13:05:28  [ main:785929 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:05:30  [ communication thread:787930 ] - [ INFO ]  map > map
2020-11-20 13:05:30  [ main:787932 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789162 ] - [ INFO ]  map > map
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789162 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789162 ] - [ INFO ]  Spilling map output
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789162 ] - [ INFO ]  bufstart = 0; bufend = 2386; bufvoid = 104857600
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789162 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789164 ] - [ INFO ]  Finished spill 0
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789165 ] - [ INFO ]  Task:attempt_local1685596291_0073_m_000000_0 is done. And is in the process of committing
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789178 ] - [ INFO ]  map
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789178 ] - [ INFO ]  Task 'attempt_local1685596291_0073_m_000000_0' done.
2020-11-20 13:05:32  [ LocalJobRunner Map Task Executor #0:789178 ] - [ INFO ]  Finishing task: attempt_local1685596291_0073_m_000000_0
2020-11-20 13:05:32  [ Thread-1977:789178 ] - [ INFO ]  map task executor complete.
2020-11-20 13:05:32  [ Thread-1977:789178 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:05:32  [ pool-222-thread-1:789178 ] - [ INFO ]  Starting task: attempt_local1685596291_0073_r_000000_0
2020-11-20 13:05:32  [ pool-222-thread-1:789179 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:32  [ pool-222-thread-1:789179 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:32  [ pool-222-thread-1:789179 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:32  [ pool-222-thread-1:789179 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1eae7e38
2020-11-20 13:05:32  [ pool-222-thread-1:789180 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:05:32  [ EventFetcher for fetching Map Completion Events:789181 ] - [ INFO ]  attempt_local1685596291_0073_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:05:32  [ localfetcher#73:789182 ] - [ INFO ]  localfetcher#73 about to shuffle output of map attempt_local1685596291_0073_m_000000_0 decomp: 2097 len: 2101 to MEMORY
2020-11-20 13:05:32  [ localfetcher#73:789182 ] - [ INFO ]  Read 2097 bytes from map-output for attempt_local1685596291_0073_m_000000_0
2020-11-20 13:05:32  [ localfetcher#73:789182 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2097, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2097
2020-11-20 13:05:32  [ EventFetcher for fetching Map Completion Events:789182 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:05:32  [ pool-222-thread-1:789182 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:32  [ pool-222-thread-1:789182 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:05:32  [ pool-222-thread-1:789183 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:32  [ pool-222-thread-1:789183 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2090 bytes
2020-11-20 13:05:32  [ pool-222-thread-1:789184 ] - [ INFO ]  Merged 1 segments, 2097 bytes to disk to satisfy reduce memory limit
2020-11-20 13:05:32  [ pool-222-thread-1:789184 ] - [ INFO ]  Merging 1 files, 2101 bytes from disk
2020-11-20 13:05:32  [ pool-222-thread-1:789184 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:05:32  [ pool-222-thread-1:789184 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:32  [ pool-222-thread-1:789184 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2090 bytes
2020-11-20 13:05:32  [ pool-222-thread-1:789184 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:32  [ pool-222-thread-1:789262 ] - [ INFO ]  Task:attempt_local1685596291_0073_r_000000_0 is done. And is in the process of committing
2020-11-20 13:05:32  [ pool-222-thread-1:789268 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:32  [ pool-222-thread-1:789268 ] - [ INFO ]  Task attempt_local1685596291_0073_r_000000_0 is allowed to commit now
2020-11-20 13:05:32  [ pool-222-thread-1:789286 ] - [ INFO ]  Saved output of task 'attempt_local1685596291_0073_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1685596291_0073_r_000000
2020-11-20 13:05:32  [ pool-222-thread-1:789287 ] - [ INFO ]  reduce > reduce
2020-11-20 13:05:32  [ pool-222-thread-1:789287 ] - [ INFO ]  Task 'attempt_local1685596291_0073_r_000000_0' done.
2020-11-20 13:05:32  [ pool-222-thread-1:789287 ] - [ INFO ]  Finishing task: attempt_local1685596291_0073_r_000000_0
2020-11-20 13:05:32  [ Thread-1977:789287 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:05:32  [ main:789937 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:05:32  [ main:789938 ] - [ INFO ]  Job job_local1685596291_0073 completed successfully
2020-11-20 13:05:32  [ main:789938 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=644892
		FILE: Number of bytes written=45801441
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=205261200
		HDFS: Number of bytes written=304298
		HDFS: Number of read operations=2184
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1157
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2386
		Map output materialized bytes=2101
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2101
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=1402994688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:05:32  [ main:789962 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:05:32  [ main:789971 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:05:32  [ main:789975 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:05:32  [ main:789980 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:05:33  [ main:790014 ] - [ INFO ]  number of splits:1
2020-11-20 13:05:33  [ main:790030 ] - [ INFO ]  Submitting tokens for job: job_local193112046_0074
2020-11-20 13:05:33  [ main:790065 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:05:33  [ main:790065 ] - [ INFO ]  Running job: job_local193112046_0074
2020-11-20 13:05:33  [ Thread-2005:790065 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:05:33  [ Thread-2005:790066 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:33  [ Thread-2005:790066 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:05:33  [ Thread-2005:790073 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790073 ] - [ INFO ]  Starting task: attempt_local193112046_0074_m_000000_0
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790073 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790073 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790074 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790074 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790082 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790082 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790082 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790082 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790082 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:05:33  [ LocalJobRunner Map Task Executor #0:790083 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:05:34  [ main:791068 ] - [ INFO ]  Job job_local193112046_0074 running in uber mode : false
2020-11-20 13:05:34  [ main:791068 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:05:39  [ communication thread:796082 ] - [ INFO ]  map > map
2020-11-20 13:05:39  [ main:796084 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:05:42  [ communication thread:799084 ] - [ INFO ]  map > map
2020-11-20 13:05:42  [ main:799091 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799739 ] - [ INFO ]  map > map
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799740 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799740 ] - [ INFO ]  Spilling map output
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799740 ] - [ INFO ]  bufstart = 0; bufend = 2389; bufvoid = 104857600
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799740 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799741 ] - [ INFO ]  Finished spill 0
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799742 ] - [ INFO ]  Task:attempt_local193112046_0074_m_000000_0 is done. And is in the process of committing
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799754 ] - [ INFO ]  map
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799754 ] - [ INFO ]  Task 'attempt_local193112046_0074_m_000000_0' done.
2020-11-20 13:05:42  [ LocalJobRunner Map Task Executor #0:799754 ] - [ INFO ]  Finishing task: attempt_local193112046_0074_m_000000_0
2020-11-20 13:05:42  [ Thread-2005:799754 ] - [ INFO ]  map task executor complete.
2020-11-20 13:05:42  [ Thread-2005:799754 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:05:42  [ pool-225-thread-1:799754 ] - [ INFO ]  Starting task: attempt_local193112046_0074_r_000000_0
2020-11-20 13:05:42  [ pool-225-thread-1:799755 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:42  [ pool-225-thread-1:799755 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:42  [ pool-225-thread-1:799755 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:42  [ pool-225-thread-1:799755 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41e14c53
2020-11-20 13:05:42  [ pool-225-thread-1:799755 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:05:42  [ EventFetcher for fetching Map Completion Events:799756 ] - [ INFO ]  attempt_local193112046_0074_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:05:42  [ localfetcher#74:799756 ] - [ INFO ]  localfetcher#74 about to shuffle output of map attempt_local193112046_0074_m_000000_0 decomp: 2100 len: 2104 to MEMORY
2020-11-20 13:05:42  [ localfetcher#74:799756 ] - [ INFO ]  Read 2100 bytes from map-output for attempt_local193112046_0074_m_000000_0
2020-11-20 13:05:42  [ localfetcher#74:799756 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2100, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2100
2020-11-20 13:05:42  [ EventFetcher for fetching Map Completion Events:799757 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:05:42  [ pool-225-thread-1:799757 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:42  [ pool-225-thread-1:799757 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:05:42  [ pool-225-thread-1:799757 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:42  [ pool-225-thread-1:799757 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2093 bytes
2020-11-20 13:05:42  [ pool-225-thread-1:799758 ] - [ INFO ]  Merged 1 segments, 2100 bytes to disk to satisfy reduce memory limit
2020-11-20 13:05:42  [ pool-225-thread-1:799758 ] - [ INFO ]  Merging 1 files, 2104 bytes from disk
2020-11-20 13:05:42  [ pool-225-thread-1:799758 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:05:42  [ pool-225-thread-1:799758 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:42  [ pool-225-thread-1:799758 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2093 bytes
2020-11-20 13:05:42  [ pool-225-thread-1:799758 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:42  [ pool-225-thread-1:799948 ] - [ INFO ]  Task:attempt_local193112046_0074_r_000000_0 is done. And is in the process of committing
2020-11-20 13:05:42  [ pool-225-thread-1:799954 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:42  [ pool-225-thread-1:799954 ] - [ INFO ]  Task attempt_local193112046_0074_r_000000_0 is allowed to commit now
2020-11-20 13:05:42  [ pool-225-thread-1:799972 ] - [ INFO ]  Saved output of task 'attempt_local193112046_0074_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local193112046_0074_r_000000
2020-11-20 13:05:42  [ pool-225-thread-1:799972 ] - [ INFO ]  reduce > reduce
2020-11-20 13:05:42  [ pool-225-thread-1:799972 ] - [ INFO ]  Task 'attempt_local193112046_0074_r_000000_0' done.
2020-11-20 13:05:42  [ pool-225-thread-1:799972 ] - [ INFO ]  Finishing task: attempt_local193112046_0074_r_000000_0
2020-11-20 13:05:42  [ Thread-2005:799972 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:05:43  [ main:800091 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:05:43  [ main:800091 ] - [ INFO ]  Job job_local193112046_0074 completed successfully
2020-11-20 13:05:43  [ main:800092 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=653748
		FILE: Number of bytes written=46442764
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=208035000
		HDFS: Number of bytes written=308477
		HDFS: Number of read operations=2214
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1173
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2389
		Map output materialized bytes=2104
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2104
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=1425014784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:05:43  [ main:800112 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:05:43  [ main:800123 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:05:43  [ main:800127 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:05:43  [ main:800133 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:05:43  [ main:800168 ] - [ INFO ]  number of splits:1
2020-11-20 13:05:43  [ main:800185 ] - [ INFO ]  Submitting tokens for job: job_local855449821_0075
2020-11-20 13:05:43  [ main:800218 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:05:43  [ main:800218 ] - [ INFO ]  Running job: job_local855449821_0075
2020-11-20 13:05:43  [ Thread-2032:800218 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:05:43  [ Thread-2032:800218 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:43  [ Thread-2032:800218 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:05:43  [ Thread-2032:800226 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800226 ] - [ INFO ]  Starting task: attempt_local855449821_0075_m_000000_0
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800226 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800226 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800226 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800227 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800234 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800234 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800234 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800234 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800234 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:05:43  [ LocalJobRunner Map Task Executor #0:800234 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:05:44  [ main:801221 ] - [ INFO ]  Job job_local855449821_0075 running in uber mode : false
2020-11-20 13:05:44  [ main:801221 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:05:49  [ communication thread:806232 ] - [ INFO ]  map > map
2020-11-20 13:05:49  [ main:806234 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:05:52  [ communication thread:809237 ] - [ INFO ]  map > map
2020-11-20 13:05:52  [ main:809242 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810543 ] - [ INFO ]  map > map
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810543 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810543 ] - [ INFO ]  Spilling map output
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810543 ] - [ INFO ]  bufstart = 0; bufend = 2376; bufvoid = 104857600
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810543 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810545 ] - [ INFO ]  Finished spill 0
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810546 ] - [ INFO ]  Task:attempt_local855449821_0075_m_000000_0 is done. And is in the process of committing
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810560 ] - [ INFO ]  map
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810560 ] - [ INFO ]  Task 'attempt_local855449821_0075_m_000000_0' done.
2020-11-20 13:05:53  [ LocalJobRunner Map Task Executor #0:810560 ] - [ INFO ]  Finishing task: attempt_local855449821_0075_m_000000_0
2020-11-20 13:05:53  [ Thread-2032:810560 ] - [ INFO ]  map task executor complete.
2020-11-20 13:05:53  [ Thread-2032:810560 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:05:53  [ pool-228-thread-1:810560 ] - [ INFO ]  Starting task: attempt_local855449821_0075_r_000000_0
2020-11-20 13:05:53  [ pool-228-thread-1:810561 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:53  [ pool-228-thread-1:810561 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:53  [ pool-228-thread-1:810561 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:53  [ pool-228-thread-1:810561 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66fe1f0
2020-11-20 13:05:53  [ pool-228-thread-1:810562 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:05:53  [ EventFetcher for fetching Map Completion Events:810563 ] - [ INFO ]  attempt_local855449821_0075_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:05:53  [ localfetcher#75:810563 ] - [ INFO ]  localfetcher#75 about to shuffle output of map attempt_local855449821_0075_m_000000_0 decomp: 2087 len: 2091 to MEMORY
2020-11-20 13:05:53  [ localfetcher#75:810563 ] - [ INFO ]  Read 2087 bytes from map-output for attempt_local855449821_0075_m_000000_0
2020-11-20 13:05:53  [ localfetcher#75:810563 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2087, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2087
2020-11-20 13:05:53  [ EventFetcher for fetching Map Completion Events:810564 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:05:53  [ pool-228-thread-1:810564 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:53  [ pool-228-thread-1:810564 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:05:53  [ pool-228-thread-1:810565 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:53  [ pool-228-thread-1:810565 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2080 bytes
2020-11-20 13:05:53  [ pool-228-thread-1:810565 ] - [ INFO ]  Merged 1 segments, 2087 bytes to disk to satisfy reduce memory limit
2020-11-20 13:05:53  [ pool-228-thread-1:810565 ] - [ INFO ]  Merging 1 files, 2091 bytes from disk
2020-11-20 13:05:53  [ pool-228-thread-1:810566 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:05:53  [ pool-228-thread-1:810566 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:05:53  [ pool-228-thread-1:810566 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2080 bytes
2020-11-20 13:05:53  [ pool-228-thread-1:810566 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:53  [ pool-228-thread-1:810649 ] - [ INFO ]  Task:attempt_local855449821_0075_r_000000_0 is done. And is in the process of committing
2020-11-20 13:05:53  [ pool-228-thread-1:810654 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:05:53  [ pool-228-thread-1:810654 ] - [ INFO ]  Task attempt_local855449821_0075_r_000000_0 is allowed to commit now
2020-11-20 13:05:53  [ pool-228-thread-1:810670 ] - [ INFO ]  Saved output of task 'attempt_local855449821_0075_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local855449821_0075_r_000000
2020-11-20 13:05:53  [ pool-228-thread-1:810671 ] - [ INFO ]  reduce > reduce
2020-11-20 13:05:53  [ pool-228-thread-1:810671 ] - [ INFO ]  Task 'attempt_local855449821_0075_r_000000_0' done.
2020-11-20 13:05:53  [ pool-228-thread-1:810671 ] - [ INFO ]  Finishing task: attempt_local855449821_0075_r_000000_0
2020-11-20 13:05:53  [ Thread-2032:810671 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:05:54  [ main:811250 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:05:54  [ main:811250 ] - [ INFO ]  Job job_local855449821_0075 completed successfully
2020-11-20 13:05:54  [ main:811252 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=662584
		FILE: Number of bytes written=47084275
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=210808800
		HDFS: Number of bytes written=312646
		HDFS: Number of read operations=2244
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1189
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2376
		Map output materialized bytes=2091
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2091
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1418723328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:05:54  [ main:811270 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:05:54  [ main:811281 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:05:54  [ main:811285 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:05:54  [ main:811292 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:05:54  [ main:811328 ] - [ INFO ]  number of splits:1
2020-11-20 13:05:54  [ main:811344 ] - [ INFO ]  Submitting tokens for job: job_local1065491118_0076
2020-11-20 13:05:54  [ main:811379 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:05:54  [ main:811379 ] - [ INFO ]  Running job: job_local1065491118_0076
2020-11-20 13:05:54  [ Thread-2060:811379 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:05:54  [ Thread-2060:811379 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:54  [ Thread-2060:811379 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:05:54  [ Thread-2060:811390 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811391 ] - [ INFO ]  Starting task: attempt_local1065491118_0076_m_000000_0
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811391 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811391 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811391 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811392 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811400 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811400 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811400 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811400 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811400 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:05:54  [ LocalJobRunner Map Task Executor #0:811400 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:05:55  [ main:812382 ] - [ INFO ]  Job job_local1065491118_0076 running in uber mode : false
2020-11-20 13:05:55  [ main:812382 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:06:00  [ communication thread:817395 ] - [ INFO ]  map > map
2020-11-20 13:06:01  [ main:818399 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:06:03  [ communication thread:820398 ] - [ INFO ]  map > map
2020-11-20 13:06:03  [ main:820408 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821194 ] - [ INFO ]  map > map
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821194 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821194 ] - [ INFO ]  Spilling map output
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821194 ] - [ INFO ]  bufstart = 0; bufend = 2390; bufvoid = 104857600
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821194 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821196 ] - [ INFO ]  Finished spill 0
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821197 ] - [ INFO ]  Task:attempt_local1065491118_0076_m_000000_0 is done. And is in the process of committing
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821204 ] - [ INFO ]  map
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821204 ] - [ INFO ]  Task 'attempt_local1065491118_0076_m_000000_0' done.
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821204 ] - [ INFO ]  Finishing task: attempt_local1065491118_0076_m_000000_0
2020-11-20 13:06:04  [ Thread-2060:821204 ] - [ INFO ]  map task executor complete.
2020-11-20 13:06:04  [ Thread-2060:821204 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:06:04  [ pool-231-thread-1:821204 ] - [ INFO ]  Starting task: attempt_local1065491118_0076_r_000000_0
2020-11-20 13:06:04  [ pool-231-thread-1:821205 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:04  [ pool-231-thread-1:821205 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:04  [ pool-231-thread-1:821205 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:04  [ pool-231-thread-1:821205 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@70e060ae
2020-11-20 13:06:04  [ pool-231-thread-1:821206 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:06:04  [ EventFetcher for fetching Map Completion Events:821206 ] - [ INFO ]  attempt_local1065491118_0076_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:06:04  [ localfetcher#76:821207 ] - [ INFO ]  localfetcher#76 about to shuffle output of map attempt_local1065491118_0076_m_000000_0 decomp: 2101 len: 2105 to MEMORY
2020-11-20 13:06:04  [ localfetcher#76:821207 ] - [ INFO ]  Read 2101 bytes from map-output for attempt_local1065491118_0076_m_000000_0
2020-11-20 13:06:04  [ localfetcher#76:821207 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2101
2020-11-20 13:06:04  [ EventFetcher for fetching Map Completion Events:821207 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:06:04  [ pool-231-thread-1:821208 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:04  [ pool-231-thread-1:821208 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:06:04  [ pool-231-thread-1:821208 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:04  [ pool-231-thread-1:821208 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 13:06:04  [ pool-231-thread-1:821209 ] - [ INFO ]  Merged 1 segments, 2101 bytes to disk to satisfy reduce memory limit
2020-11-20 13:06:04  [ pool-231-thread-1:821209 ] - [ INFO ]  Merging 1 files, 2105 bytes from disk
2020-11-20 13:06:04  [ pool-231-thread-1:821209 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:06:04  [ pool-231-thread-1:821209 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:04  [ pool-231-thread-1:821209 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 13:06:04  [ pool-231-thread-1:821209 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:04  [ pool-231-thread-1:821312 ] - [ INFO ]  Task:attempt_local1065491118_0076_r_000000_0 is done. And is in the process of committing
2020-11-20 13:06:04  [ pool-231-thread-1:821318 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:04  [ pool-231-thread-1:821318 ] - [ INFO ]  Task attempt_local1065491118_0076_r_000000_0 is allowed to commit now
2020-11-20 13:06:04  [ pool-231-thread-1:821346 ] - [ INFO ]  Saved output of task 'attempt_local1065491118_0076_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1065491118_0076_r_000000
2020-11-20 13:06:04  [ pool-231-thread-1:821346 ] - [ INFO ]  reduce > reduce
2020-11-20 13:06:04  [ pool-231-thread-1:821346 ] - [ INFO ]  Task 'attempt_local1065491118_0076_r_000000_0' done.
2020-11-20 13:06:04  [ pool-231-thread-1:821346 ] - [ INFO ]  Finishing task: attempt_local1065491118_0076_r_000000_0
2020-11-20 13:06:04  [ Thread-2060:821346 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:06:04  [ main:821413 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:06:04  [ main:821413 ] - [ INFO ]  Job job_local1065491118_0076 completed successfully
2020-11-20 13:06:04  [ main:821414 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=671422
		FILE: Number of bytes written=47729399
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=213582600
		HDFS: Number of bytes written=316816
		HDFS: Number of read operations=2274
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1205
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2390
		Map output materialized bytes=2105
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2105
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=1409286144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:06:04  [ main:821432 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:06:04  [ main:821442 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:06:04  [ main:821446 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:06:04  [ main:821453 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:06:04  [ main:821490 ] - [ INFO ]  number of splits:1
2020-11-20 13:06:04  [ main:821507 ] - [ INFO ]  Submitting tokens for job: job_local1609985813_0077
2020-11-20 13:06:04  [ main:821541 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:06:04  [ main:821542 ] - [ INFO ]  Running job: job_local1609985813_0077
2020-11-20 13:06:04  [ Thread-2087:821542 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:06:04  [ Thread-2087:821542 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:04  [ Thread-2087:821542 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:06:04  [ Thread-2087:821549 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821550 ] - [ INFO ]  Starting task: attempt_local1609985813_0077_m_000000_0
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821550 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821550 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821550 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821550 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821558 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821558 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821558 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821558 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821558 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:06:04  [ LocalJobRunner Map Task Executor #0:821558 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:06:05  [ main:822546 ] - [ INFO ]  Job job_local1609985813_0077 running in uber mode : false
2020-11-20 13:06:05  [ main:822546 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:06:10  [ communication thread:827560 ] - [ INFO ]  map > map
2020-11-20 13:06:11  [ main:828559 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:06:13  [ communication thread:830564 ] - [ INFO ]  map > map
2020-11-20 13:06:14  [ main:831565 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831566 ] - [ INFO ]  map > map
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831566 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831566 ] - [ INFO ]  Spilling map output
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831566 ] - [ INFO ]  bufstart = 0; bufend = 2361; bufvoid = 104857600
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831566 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831568 ] - [ INFO ]  Finished spill 0
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831568 ] - [ INFO ]  Task:attempt_local1609985813_0077_m_000000_0 is done. And is in the process of committing
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831581 ] - [ INFO ]  map
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831581 ] - [ INFO ]  Task 'attempt_local1609985813_0077_m_000000_0' done.
2020-11-20 13:06:14  [ LocalJobRunner Map Task Executor #0:831581 ] - [ INFO ]  Finishing task: attempt_local1609985813_0077_m_000000_0
2020-11-20 13:06:14  [ Thread-2087:831581 ] - [ INFO ]  map task executor complete.
2020-11-20 13:06:14  [ Thread-2087:831581 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:06:14  [ pool-234-thread-1:831581 ] - [ INFO ]  Starting task: attempt_local1609985813_0077_r_000000_0
2020-11-20 13:06:14  [ pool-234-thread-1:831582 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:14  [ pool-234-thread-1:831582 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:14  [ pool-234-thread-1:831582 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:14  [ pool-234-thread-1:831582 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@689de402
2020-11-20 13:06:14  [ pool-234-thread-1:831584 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:06:14  [ EventFetcher for fetching Map Completion Events:831584 ] - [ INFO ]  attempt_local1609985813_0077_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:06:14  [ localfetcher#77:831585 ] - [ INFO ]  localfetcher#77 about to shuffle output of map attempt_local1609985813_0077_m_000000_0 decomp: 2072 len: 2076 to MEMORY
2020-11-20 13:06:14  [ localfetcher#77:831585 ] - [ INFO ]  Read 2072 bytes from map-output for attempt_local1609985813_0077_m_000000_0
2020-11-20 13:06:14  [ localfetcher#77:831585 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2072, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2072
2020-11-20 13:06:14  [ EventFetcher for fetching Map Completion Events:831585 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:06:14  [ pool-234-thread-1:831586 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:14  [ pool-234-thread-1:831586 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:06:14  [ pool-234-thread-1:831586 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:14  [ pool-234-thread-1:831586 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2065 bytes
2020-11-20 13:06:14  [ pool-234-thread-1:831587 ] - [ INFO ]  Merged 1 segments, 2072 bytes to disk to satisfy reduce memory limit
2020-11-20 13:06:14  [ pool-234-thread-1:831587 ] - [ INFO ]  Merging 1 files, 2076 bytes from disk
2020-11-20 13:06:14  [ pool-234-thread-1:831587 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:06:14  [ pool-234-thread-1:831587 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:14  [ pool-234-thread-1:831587 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2065 bytes
2020-11-20 13:06:14  [ pool-234-thread-1:831587 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:14  [ pool-234-thread-1:831669 ] - [ INFO ]  Task:attempt_local1609985813_0077_r_000000_0 is done. And is in the process of committing
2020-11-20 13:06:14  [ pool-234-thread-1:831675 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:14  [ pool-234-thread-1:831676 ] - [ INFO ]  Task attempt_local1609985813_0077_r_000000_0 is allowed to commit now
2020-11-20 13:06:14  [ pool-234-thread-1:831692 ] - [ INFO ]  Saved output of task 'attempt_local1609985813_0077_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1609985813_0077_r_000000
2020-11-20 13:06:14  [ pool-234-thread-1:831692 ] - [ INFO ]  reduce > reduce
2020-11-20 13:06:14  [ pool-234-thread-1:831692 ] - [ INFO ]  Task 'attempt_local1609985813_0077_r_000000_0' done.
2020-11-20 13:06:14  [ pool-234-thread-1:831692 ] - [ INFO ]  Finishing task: attempt_local1609985813_0077_r_000000_0
2020-11-20 13:06:14  [ Thread-2087:831693 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:06:15  [ main:832565 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:06:15  [ main:832566 ] - [ INFO ]  Job job_local1609985813_0077 completed successfully
2020-11-20 13:06:15  [ main:832567 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=680230
		FILE: Number of bytes written=48374602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=216356400
		HDFS: Number of bytes written=320971
		HDFS: Number of read operations=2304
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1221
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2361
		Map output materialized bytes=2076
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2076
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=1561329664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:06:15  [ main:832585 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:06:15  [ main:832596 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:06:15  [ main:832600 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:06:15  [ main:832608 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:06:15  [ main:832647 ] - [ INFO ]  number of splits:1
2020-11-20 13:06:15  [ main:832663 ] - [ INFO ]  Submitting tokens for job: job_local1093641287_0078
2020-11-20 13:06:15  [ main:832698 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:06:15  [ main:832698 ] - [ INFO ]  Running job: job_local1093641287_0078
2020-11-20 13:06:15  [ Thread-2115:832698 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:06:15  [ Thread-2115:832699 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:15  [ Thread-2115:832699 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:06:15  [ Thread-2115:832707 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832707 ] - [ INFO ]  Starting task: attempt_local1093641287_0078_m_000000_0
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832707 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832708 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832708 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832708 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832717 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832717 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832717 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832717 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832717 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:06:15  [ LocalJobRunner Map Task Executor #0:832717 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:06:16  [ main:833702 ] - [ INFO ]  Job job_local1093641287_0078 running in uber mode : false
2020-11-20 13:06:16  [ main:833702 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:06:21  [ communication thread:838713 ] - [ INFO ]  map > map
2020-11-20 13:06:21  [ main:838715 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:06:24  [ communication thread:841714 ] - [ INFO ]  map > map
2020-11-20 13:06:24  [ main:841725 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842327 ] - [ INFO ]  map > map
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842327 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842327 ] - [ INFO ]  Spilling map output
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842327 ] - [ INFO ]  bufstart = 0; bufend = 2374; bufvoid = 104857600
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842327 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842329 ] - [ INFO ]  Finished spill 0
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842330 ] - [ INFO ]  Task:attempt_local1093641287_0078_m_000000_0 is done. And is in the process of committing
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842337 ] - [ INFO ]  map
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842337 ] - [ INFO ]  Task 'attempt_local1093641287_0078_m_000000_0' done.
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842337 ] - [ INFO ]  Finishing task: attempt_local1093641287_0078_m_000000_0
2020-11-20 13:06:25  [ Thread-2115:842337 ] - [ INFO ]  map task executor complete.
2020-11-20 13:06:25  [ Thread-2115:842337 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:06:25  [ pool-237-thread-1:842337 ] - [ INFO ]  Starting task: attempt_local1093641287_0078_r_000000_0
2020-11-20 13:06:25  [ pool-237-thread-1:842338 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:25  [ pool-237-thread-1:842338 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:25  [ pool-237-thread-1:842338 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:25  [ pool-237-thread-1:842338 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e904a6
2020-11-20 13:06:25  [ pool-237-thread-1:842339 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:06:25  [ EventFetcher for fetching Map Completion Events:842340 ] - [ INFO ]  attempt_local1093641287_0078_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:06:25  [ localfetcher#78:842340 ] - [ INFO ]  localfetcher#78 about to shuffle output of map attempt_local1093641287_0078_m_000000_0 decomp: 2085 len: 2089 to MEMORY
2020-11-20 13:06:25  [ localfetcher#78:842341 ] - [ INFO ]  Read 2085 bytes from map-output for attempt_local1093641287_0078_m_000000_0
2020-11-20 13:06:25  [ localfetcher#78:842341 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2085, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2085
2020-11-20 13:06:25  [ EventFetcher for fetching Map Completion Events:842341 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:06:25  [ pool-237-thread-1:842341 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:25  [ pool-237-thread-1:842341 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:06:25  [ pool-237-thread-1:842342 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:25  [ pool-237-thread-1:842342 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2078 bytes
2020-11-20 13:06:25  [ pool-237-thread-1:842342 ] - [ INFO ]  Merged 1 segments, 2085 bytes to disk to satisfy reduce memory limit
2020-11-20 13:06:25  [ pool-237-thread-1:842343 ] - [ INFO ]  Merging 1 files, 2089 bytes from disk
2020-11-20 13:06:25  [ pool-237-thread-1:842343 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:06:25  [ pool-237-thread-1:842343 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:25  [ pool-237-thread-1:842343 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2078 bytes
2020-11-20 13:06:25  [ pool-237-thread-1:842343 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:25  [ pool-237-thread-1:842434 ] - [ INFO ]  Task:attempt_local1093641287_0078_r_000000_0 is done. And is in the process of committing
2020-11-20 13:06:25  [ pool-237-thread-1:842439 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:25  [ pool-237-thread-1:842439 ] - [ INFO ]  Task attempt_local1093641287_0078_r_000000_0 is allowed to commit now
2020-11-20 13:06:25  [ pool-237-thread-1:842456 ] - [ INFO ]  Saved output of task 'attempt_local1093641287_0078_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1093641287_0078_r_000000
2020-11-20 13:06:25  [ pool-237-thread-1:842457 ] - [ INFO ]  reduce > reduce
2020-11-20 13:06:25  [ pool-237-thread-1:842457 ] - [ INFO ]  Task 'attempt_local1093641287_0078_r_000000_0' done.
2020-11-20 13:06:25  [ pool-237-thread-1:842457 ] - [ INFO ]  Finishing task: attempt_local1093641287_0078_r_000000_0
2020-11-20 13:06:25  [ Thread-2115:842457 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:06:25  [ main:842730 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:06:25  [ main:842730 ] - [ INFO ]  Job job_local1093641287_0078 completed successfully
2020-11-20 13:06:25  [ main:842731 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=689006
		FILE: Number of bytes written=49019939
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=219130200
		HDFS: Number of bytes written=325110
		HDFS: Number of read operations=2334
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1237
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2374
		Map output materialized bytes=2089
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2089
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1540358144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:06:25  [ main:842750 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:06:25  [ main:842761 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:06:25  [ main:842765 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:06:25  [ main:842771 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:06:25  [ main:842808 ] - [ INFO ]  number of splits:1
2020-11-20 13:06:25  [ main:842825 ] - [ INFO ]  Submitting tokens for job: job_local1555549518_0079
2020-11-20 13:06:25  [ main:842857 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:06:25  [ main:842857 ] - [ INFO ]  Running job: job_local1555549518_0079
2020-11-20 13:06:25  [ Thread-2142:842857 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:06:25  [ Thread-2142:842858 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:25  [ Thread-2142:842858 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:06:25  [ Thread-2142:842865 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842865 ] - [ INFO ]  Starting task: attempt_local1555549518_0079_m_000000_0
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842866 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842866 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842866 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842866 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842873 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842873 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842873 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842873 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842873 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:06:25  [ LocalJobRunner Map Task Executor #0:842873 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:06:26  [ main:843859 ] - [ INFO ]  Job job_local1555549518_0079 running in uber mode : false
2020-11-20 13:06:26  [ main:843859 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:06:31  [ communication thread:848874 ] - [ INFO ]  map > map
2020-11-20 13:06:31  [ main:848877 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:06:34  [ communication thread:851879 ] - [ INFO ]  map > map
2020-11-20 13:06:34  [ main:851885 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852618 ] - [ INFO ]  map > map
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852618 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852618 ] - [ INFO ]  Spilling map output
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852618 ] - [ INFO ]  bufstart = 0; bufend = 2390; bufvoid = 104857600
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852618 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852620 ] - [ INFO ]  Finished spill 0
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852621 ] - [ INFO ]  Task:attempt_local1555549518_0079_m_000000_0 is done. And is in the process of committing
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852627 ] - [ INFO ]  map
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852627 ] - [ INFO ]  Task 'attempt_local1555549518_0079_m_000000_0' done.
2020-11-20 13:06:35  [ LocalJobRunner Map Task Executor #0:852627 ] - [ INFO ]  Finishing task: attempt_local1555549518_0079_m_000000_0
2020-11-20 13:06:35  [ Thread-2142:852627 ] - [ INFO ]  map task executor complete.
2020-11-20 13:06:35  [ Thread-2142:852628 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:06:35  [ pool-240-thread-1:852628 ] - [ INFO ]  Starting task: attempt_local1555549518_0079_r_000000_0
2020-11-20 13:06:35  [ pool-240-thread-1:852628 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:35  [ pool-240-thread-1:852628 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:35  [ pool-240-thread-1:852628 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:35  [ pool-240-thread-1:852628 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@760a1962
2020-11-20 13:06:35  [ pool-240-thread-1:852630 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:06:35  [ EventFetcher for fetching Map Completion Events:852630 ] - [ INFO ]  attempt_local1555549518_0079_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:06:35  [ localfetcher#79:852631 ] - [ INFO ]  localfetcher#79 about to shuffle output of map attempt_local1555549518_0079_m_000000_0 decomp: 2101 len: 2105 to MEMORY
2020-11-20 13:06:35  [ localfetcher#79:852631 ] - [ INFO ]  Read 2101 bytes from map-output for attempt_local1555549518_0079_m_000000_0
2020-11-20 13:06:35  [ localfetcher#79:852631 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2101
2020-11-20 13:06:35  [ EventFetcher for fetching Map Completion Events:852631 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:06:35  [ pool-240-thread-1:852631 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:35  [ pool-240-thread-1:852631 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:06:35  [ pool-240-thread-1:852632 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:35  [ pool-240-thread-1:852632 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 13:06:35  [ pool-240-thread-1:852633 ] - [ INFO ]  Merged 1 segments, 2101 bytes to disk to satisfy reduce memory limit
2020-11-20 13:06:35  [ pool-240-thread-1:852633 ] - [ INFO ]  Merging 1 files, 2105 bytes from disk
2020-11-20 13:06:35  [ pool-240-thread-1:852633 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:06:35  [ pool-240-thread-1:852633 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:35  [ pool-240-thread-1:852633 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 13:06:35  [ pool-240-thread-1:852633 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:35  [ pool-240-thread-1:852709 ] - [ INFO ]  Task:attempt_local1555549518_0079_r_000000_0 is done. And is in the process of committing
2020-11-20 13:06:35  [ pool-240-thread-1:852715 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:35  [ pool-240-thread-1:852715 ] - [ INFO ]  Task attempt_local1555549518_0079_r_000000_0 is allowed to commit now
2020-11-20 13:06:35  [ pool-240-thread-1:852732 ] - [ INFO ]  Saved output of task 'attempt_local1555549518_0079_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1555549518_0079_r_000000
2020-11-20 13:06:35  [ pool-240-thread-1:852733 ] - [ INFO ]  reduce > reduce
2020-11-20 13:06:35  [ pool-240-thread-1:852733 ] - [ INFO ]  Task 'attempt_local1555549518_0079_r_000000_0' done.
2020-11-20 13:06:35  [ pool-240-thread-1:852733 ] - [ INFO ]  Finishing task: attempt_local1555549518_0079_r_000000_0
2020-11-20 13:06:35  [ Thread-2142:852733 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:06:35  [ main:852889 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:06:35  [ main:852889 ] - [ INFO ]  Job job_local1555549518_0079 completed successfully
2020-11-20 13:06:35  [ main:852891 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=697840
		FILE: Number of bytes written=49665413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=221904000
		HDFS: Number of bytes written=329278
		HDFS: Number of read operations=2364
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1253
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2390
		Map output materialized bytes=2105
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2105
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=1320157184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:06:35  [ main:852911 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:06:35  [ main:852922 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:06:35  [ main:852926 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:06:35  [ main:852932 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:06:35  [ main:852969 ] - [ INFO ]  number of splits:1
2020-11-20 13:06:35  [ main:852985 ] - [ INFO ]  Submitting tokens for job: job_local998907_0080
2020-11-20 13:06:36  [ main:853018 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:06:36  [ main:853018 ] - [ INFO ]  Running job: job_local998907_0080
2020-11-20 13:06:36  [ Thread-2169:853018 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:06:36  [ Thread-2169:853018 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:36  [ Thread-2169:853018 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:06:36  [ Thread-2169:853028 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853028 ] - [ INFO ]  Starting task: attempt_local998907_0080_m_000000_0
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853029 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853029 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853029 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853029 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853037 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853037 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853037 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853037 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853037 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:06:36  [ LocalJobRunner Map Task Executor #0:853037 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:06:37  [ main:854021 ] - [ INFO ]  Job job_local998907_0080 running in uber mode : false
2020-11-20 13:06:37  [ main:854021 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:06:42  [ communication thread:859033 ] - [ INFO ]  map > map
2020-11-20 13:06:43  [ main:860034 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:06:45  [ communication thread:862038 ] - [ INFO ]  map > map
2020-11-20 13:06:45  [ main:862041 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863060 ] - [ INFO ]  map > map
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863061 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863061 ] - [ INFO ]  Spilling map output
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863061 ] - [ INFO ]  bufstart = 0; bufend = 2385; bufvoid = 104857600
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863061 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863063 ] - [ INFO ]  Finished spill 0
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863063 ] - [ INFO ]  Task:attempt_local998907_0080_m_000000_0 is done. And is in the process of committing
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863077 ] - [ INFO ]  map
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863077 ] - [ INFO ]  Task 'attempt_local998907_0080_m_000000_0' done.
2020-11-20 13:06:46  [ LocalJobRunner Map Task Executor #0:863077 ] - [ INFO ]  Finishing task: attempt_local998907_0080_m_000000_0
2020-11-20 13:06:46  [ Thread-2169:863077 ] - [ INFO ]  map task executor complete.
2020-11-20 13:06:46  [ Thread-2169:863078 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:06:46  [ pool-243-thread-1:863078 ] - [ INFO ]  Starting task: attempt_local998907_0080_r_000000_0
2020-11-20 13:06:46  [ pool-243-thread-1:863079 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:46  [ pool-243-thread-1:863079 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:46  [ pool-243-thread-1:863079 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:46  [ pool-243-thread-1:863079 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@188c0e36
2020-11-20 13:06:46  [ pool-243-thread-1:863080 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:06:46  [ EventFetcher for fetching Map Completion Events:863080 ] - [ INFO ]  attempt_local998907_0080_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:06:46  [ localfetcher#80:863081 ] - [ INFO ]  localfetcher#80 about to shuffle output of map attempt_local998907_0080_m_000000_0 decomp: 2096 len: 2100 to MEMORY
2020-11-20 13:06:46  [ localfetcher#80:863081 ] - [ INFO ]  Read 2096 bytes from map-output for attempt_local998907_0080_m_000000_0
2020-11-20 13:06:46  [ localfetcher#80:863082 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2096, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2096
2020-11-20 13:06:46  [ EventFetcher for fetching Map Completion Events:863082 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:06:46  [ pool-243-thread-1:863082 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:46  [ pool-243-thread-1:863082 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:06:46  [ pool-243-thread-1:863083 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:46  [ pool-243-thread-1:863083 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2089 bytes
2020-11-20 13:06:46  [ pool-243-thread-1:863083 ] - [ INFO ]  Merged 1 segments, 2096 bytes to disk to satisfy reduce memory limit
2020-11-20 13:06:46  [ pool-243-thread-1:863083 ] - [ INFO ]  Merging 1 files, 2100 bytes from disk
2020-11-20 13:06:46  [ pool-243-thread-1:863083 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:06:46  [ pool-243-thread-1:863084 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:46  [ pool-243-thread-1:863084 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2089 bytes
2020-11-20 13:06:46  [ pool-243-thread-1:863084 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:46  [ pool-243-thread-1:863250 ] - [ INFO ]  Task:attempt_local998907_0080_r_000000_0 is done. And is in the process of committing
2020-11-20 13:06:46  [ pool-243-thread-1:863257 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:46  [ pool-243-thread-1:863257 ] - [ INFO ]  Task attempt_local998907_0080_r_000000_0 is allowed to commit now
2020-11-20 13:06:46  [ pool-243-thread-1:863276 ] - [ INFO ]  Saved output of task 'attempt_local998907_0080_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local998907_0080_r_000000
2020-11-20 13:06:46  [ pool-243-thread-1:863276 ] - [ INFO ]  reduce > reduce
2020-11-20 13:06:46  [ pool-243-thread-1:863276 ] - [ INFO ]  Task 'attempt_local998907_0080_r_000000_0' done.
2020-11-20 13:06:46  [ pool-243-thread-1:863276 ] - [ INFO ]  Finishing task: attempt_local998907_0080_r_000000_0
2020-11-20 13:06:46  [ Thread-2169:863276 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:06:47  [ main:864047 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:06:47  [ main:864048 ] - [ INFO ]  Job job_local998907_0080 completed successfully
2020-11-20 13:06:47  [ main:864049 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=706696
		FILE: Number of bytes written=50298760
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=224677800
		HDFS: Number of bytes written=333457
		HDFS: Number of read operations=2394
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1269
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2385
		Map output materialized bytes=2100
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2100
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=1427111936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:06:47  [ main:864075 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:06:47  [ main:864089 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:06:47  [ main:864093 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:06:47  [ main:864098 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:06:47  [ main:864136 ] - [ INFO ]  number of splits:1
2020-11-20 13:06:47  [ main:864152 ] - [ INFO ]  Submitting tokens for job: job_local213320975_0081
2020-11-20 13:06:47  [ main:864187 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:06:47  [ main:864187 ] - [ INFO ]  Running job: job_local213320975_0081
2020-11-20 13:06:47  [ Thread-2197:864188 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:06:47  [ Thread-2197:864188 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:47  [ Thread-2197:864188 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:06:47  [ Thread-2197:864196 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864196 ] - [ INFO ]  Starting task: attempt_local213320975_0081_m_000000_0
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864197 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864197 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864197 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864197 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864204 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864204 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864204 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864204 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864205 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:06:47  [ LocalJobRunner Map Task Executor #0:864205 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:06:48  [ main:865188 ] - [ INFO ]  Job job_local213320975_0081 running in uber mode : false
2020-11-20 13:06:48  [ main:865188 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:06:53  [ communication thread:870199 ] - [ INFO ]  map > map
2020-11-20 13:06:53  [ main:870206 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:06:56  [ communication thread:873203 ] - [ INFO ]  map > map
2020-11-20 13:06:56  [ main:873219 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873590 ] - [ INFO ]  map > map
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873590 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873590 ] - [ INFO ]  Spilling map output
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873590 ] - [ INFO ]  bufstart = 0; bufend = 2388; bufvoid = 104857600
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873590 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873592 ] - [ INFO ]  Finished spill 0
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873593 ] - [ INFO ]  Task:attempt_local213320975_0081_m_000000_0 is done. And is in the process of committing
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873601 ] - [ INFO ]  map
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873601 ] - [ INFO ]  Task 'attempt_local213320975_0081_m_000000_0' done.
2020-11-20 13:06:56  [ LocalJobRunner Map Task Executor #0:873601 ] - [ INFO ]  Finishing task: attempt_local213320975_0081_m_000000_0
2020-11-20 13:06:56  [ Thread-2197:873601 ] - [ INFO ]  map task executor complete.
2020-11-20 13:06:56  [ Thread-2197:873602 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:06:56  [ pool-246-thread-1:873602 ] - [ INFO ]  Starting task: attempt_local213320975_0081_r_000000_0
2020-11-20 13:06:56  [ pool-246-thread-1:873602 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:56  [ pool-246-thread-1:873602 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:56  [ pool-246-thread-1:873602 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:56  [ pool-246-thread-1:873602 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ccccb4d
2020-11-20 13:06:56  [ pool-246-thread-1:873604 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:06:56  [ EventFetcher for fetching Map Completion Events:873604 ] - [ INFO ]  attempt_local213320975_0081_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:06:56  [ localfetcher#81:873605 ] - [ INFO ]  localfetcher#81 about to shuffle output of map attempt_local213320975_0081_m_000000_0 decomp: 2099 len: 2103 to MEMORY
2020-11-20 13:06:56  [ localfetcher#81:873605 ] - [ INFO ]  Read 2099 bytes from map-output for attempt_local213320975_0081_m_000000_0
2020-11-20 13:06:56  [ localfetcher#81:873605 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2099, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2099
2020-11-20 13:06:56  [ EventFetcher for fetching Map Completion Events:873605 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:06:56  [ pool-246-thread-1:873605 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:56  [ pool-246-thread-1:873605 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:06:56  [ pool-246-thread-1:873606 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:56  [ pool-246-thread-1:873606 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2092 bytes
2020-11-20 13:06:56  [ pool-246-thread-1:873606 ] - [ INFO ]  Merged 1 segments, 2099 bytes to disk to satisfy reduce memory limit
2020-11-20 13:06:56  [ pool-246-thread-1:873607 ] - [ INFO ]  Merging 1 files, 2103 bytes from disk
2020-11-20 13:06:56  [ pool-246-thread-1:873607 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:06:56  [ pool-246-thread-1:873607 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:06:56  [ pool-246-thread-1:873607 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2092 bytes
2020-11-20 13:06:56  [ pool-246-thread-1:873607 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:56  [ pool-246-thread-1:873760 ] - [ INFO ]  Task:attempt_local213320975_0081_r_000000_0 is done. And is in the process of committing
2020-11-20 13:06:56  [ pool-246-thread-1:873775 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:06:56  [ pool-246-thread-1:873775 ] - [ INFO ]  Task attempt_local213320975_0081_r_000000_0 is allowed to commit now
2020-11-20 13:06:56  [ pool-246-thread-1:873805 ] - [ INFO ]  Saved output of task 'attempt_local213320975_0081_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local213320975_0081_r_000000
2020-11-20 13:06:56  [ pool-246-thread-1:873805 ] - [ INFO ]  reduce > reduce
2020-11-20 13:06:56  [ pool-246-thread-1:873806 ] - [ INFO ]  Task 'attempt_local213320975_0081_r_000000_0' done.
2020-11-20 13:06:56  [ pool-246-thread-1:873806 ] - [ INFO ]  Finishing task: attempt_local213320975_0081_r_000000_0
2020-11-20 13:06:56  [ Thread-2197:873806 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:06:57  [ main:874219 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:06:57  [ main:874219 ] - [ INFO ]  Job job_local213320975_0081 completed successfully
2020-11-20 13:06:57  [ main:874222 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=715548
		FILE: Number of bytes written=50941503
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=227451600
		HDFS: Number of bytes written=337634
		HDFS: Number of read operations=2424
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1285
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2388
		Map output materialized bytes=2103
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2103
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=1311768576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:06:57  [ main:874241 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:06:57  [ main:874253 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:06:57  [ main:874257 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:06:57  [ main:874263 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:06:57  [ main:874301 ] - [ INFO ]  number of splits:1
2020-11-20 13:06:57  [ main:874318 ] - [ INFO ]  Submitting tokens for job: job_local116824701_0082
2020-11-20 13:06:57  [ main:874351 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:06:57  [ main:874351 ] - [ INFO ]  Running job: job_local116824701_0082
2020-11-20 13:06:57  [ Thread-2224:874351 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:06:57  [ Thread-2224:874351 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:57  [ Thread-2224:874351 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:06:57  [ Thread-2224:874358 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874358 ] - [ INFO ]  Starting task: attempt_local116824701_0082_m_000000_0
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874358 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874358 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874359 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874359 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874367 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874367 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874367 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874367 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874367 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:06:57  [ LocalJobRunner Map Task Executor #0:874367 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:06:58  [ main:875354 ] - [ INFO ]  Job job_local116824701_0082 running in uber mode : false
2020-11-20 13:06:58  [ main:875354 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:07:03  [ communication thread:880365 ] - [ INFO ]  map > map
2020-11-20 13:07:03  [ main:880367 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:07:06  [ communication thread:883365 ] - [ INFO ]  map > map
2020-11-20 13:07:06  [ main:883372 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884151 ] - [ INFO ]  map > map
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884152 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884152 ] - [ INFO ]  Spilling map output
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884152 ] - [ INFO ]  bufstart = 0; bufend = 2388; bufvoid = 104857600
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884152 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884153 ] - [ INFO ]  Finished spill 0
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884154 ] - [ INFO ]  Task:attempt_local116824701_0082_m_000000_0 is done. And is in the process of committing
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884173 ] - [ INFO ]  map
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884173 ] - [ INFO ]  Task 'attempt_local116824701_0082_m_000000_0' done.
2020-11-20 13:07:07  [ LocalJobRunner Map Task Executor #0:884173 ] - [ INFO ]  Finishing task: attempt_local116824701_0082_m_000000_0
2020-11-20 13:07:07  [ Thread-2224:884173 ] - [ INFO ]  map task executor complete.
2020-11-20 13:07:07  [ Thread-2224:884174 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:07:07  [ pool-249-thread-1:884174 ] - [ INFO ]  Starting task: attempt_local116824701_0082_r_000000_0
2020-11-20 13:07:07  [ pool-249-thread-1:884175 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:07  [ pool-249-thread-1:884175 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:07  [ pool-249-thread-1:884175 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:07  [ pool-249-thread-1:884175 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a1b4aa
2020-11-20 13:07:07  [ pool-249-thread-1:884176 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:07:07  [ EventFetcher for fetching Map Completion Events:884177 ] - [ INFO ]  attempt_local116824701_0082_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:07:07  [ localfetcher#82:884177 ] - [ INFO ]  localfetcher#82 about to shuffle output of map attempt_local116824701_0082_m_000000_0 decomp: 2099 len: 2103 to MEMORY
2020-11-20 13:07:07  [ localfetcher#82:884177 ] - [ INFO ]  Read 2099 bytes from map-output for attempt_local116824701_0082_m_000000_0
2020-11-20 13:07:07  [ localfetcher#82:884177 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2099, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2099
2020-11-20 13:07:07  [ EventFetcher for fetching Map Completion Events:884178 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:07:07  [ pool-249-thread-1:884178 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:07  [ pool-249-thread-1:884178 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:07:07  [ pool-249-thread-1:884179 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:07  [ pool-249-thread-1:884179 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2092 bytes
2020-11-20 13:07:07  [ pool-249-thread-1:884179 ] - [ INFO ]  Merged 1 segments, 2099 bytes to disk to satisfy reduce memory limit
2020-11-20 13:07:07  [ pool-249-thread-1:884179 ] - [ INFO ]  Merging 1 files, 2103 bytes from disk
2020-11-20 13:07:07  [ pool-249-thread-1:884180 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:07:07  [ pool-249-thread-1:884180 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:07  [ pool-249-thread-1:884180 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2092 bytes
2020-11-20 13:07:07  [ pool-249-thread-1:884180 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:07  [ pool-249-thread-1:884300 ] - [ INFO ]  Task:attempt_local116824701_0082_r_000000_0 is done. And is in the process of committing
2020-11-20 13:07:07  [ pool-249-thread-1:884306 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:07  [ pool-249-thread-1:884306 ] - [ INFO ]  Task attempt_local116824701_0082_r_000000_0 is allowed to commit now
2020-11-20 13:07:07  [ pool-249-thread-1:884331 ] - [ INFO ]  Saved output of task 'attempt_local116824701_0082_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local116824701_0082_r_000000
2020-11-20 13:07:07  [ pool-249-thread-1:884331 ] - [ INFO ]  reduce > reduce
2020-11-20 13:07:07  [ pool-249-thread-1:884331 ] - [ INFO ]  Task 'attempt_local116824701_0082_r_000000_0' done.
2020-11-20 13:07:07  [ pool-249-thread-1:884332 ] - [ INFO ]  Finishing task: attempt_local116824701_0082_r_000000_0
2020-11-20 13:07:07  [ Thread-2224:884332 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:07:07  [ main:884372 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:07:08  [ main:885374 ] - [ INFO ]  Job job_local116824701_0082 completed successfully
2020-11-20 13:07:08  [ main:885376 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=724406
		FILE: Number of bytes written=51584461
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=230225400
		HDFS: Number of bytes written=341814
		HDFS: Number of read operations=2454
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1301
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2388
		Map output materialized bytes=2103
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2103
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1206910976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:07:08  [ main:885443 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:07:08  [ main:885454 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:07:08  [ main:885458 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:07:08  [ main:885464 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:07:08  [ main:885501 ] - [ INFO ]  number of splits:1
2020-11-20 13:07:08  [ main:885518 ] - [ INFO ]  Submitting tokens for job: job_local1587666569_0083
2020-11-20 13:07:08  [ main:885550 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:07:08  [ main:885550 ] - [ INFO ]  Running job: job_local1587666569_0083
2020-11-20 13:07:08  [ Thread-2251:885550 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:07:08  [ Thread-2251:885550 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:08  [ Thread-2251:885550 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:07:08  [ Thread-2251:885560 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885560 ] - [ INFO ]  Starting task: attempt_local1587666569_0083_m_000000_0
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885560 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885560 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885560 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885561 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885568 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885568 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885568 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885568 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885568 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:07:08  [ LocalJobRunner Map Task Executor #0:885569 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:07:09  [ main:886552 ] - [ INFO ]  Job job_local1587666569_0083 running in uber mode : false
2020-11-20 13:07:09  [ main:886553 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:07:14  [ communication thread:891567 ] - [ INFO ]  map > map
2020-11-20 13:07:15  [ main:892568 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:07:17  [ communication thread:894569 ] - [ INFO ]  map > map
2020-11-20 13:07:17  [ main:894575 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895096 ] - [ INFO ]  map > map
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895096 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895096 ] - [ INFO ]  Spilling map output
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895096 ] - [ INFO ]  bufstart = 0; bufend = 2397; bufvoid = 104857600
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895096 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895098 ] - [ INFO ]  Finished spill 0
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895099 ] - [ INFO ]  Task:attempt_local1587666569_0083_m_000000_0 is done. And is in the process of committing
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895106 ] - [ INFO ]  map
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895106 ] - [ INFO ]  Task 'attempt_local1587666569_0083_m_000000_0' done.
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895106 ] - [ INFO ]  Finishing task: attempt_local1587666569_0083_m_000000_0
2020-11-20 13:07:18  [ Thread-2251:895107 ] - [ INFO ]  map task executor complete.
2020-11-20 13:07:18  [ Thread-2251:895107 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:07:18  [ pool-252-thread-1:895107 ] - [ INFO ]  Starting task: attempt_local1587666569_0083_r_000000_0
2020-11-20 13:07:18  [ pool-252-thread-1:895108 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:18  [ pool-252-thread-1:895108 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:18  [ pool-252-thread-1:895108 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:18  [ pool-252-thread-1:895108 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b557879
2020-11-20 13:07:18  [ pool-252-thread-1:895109 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:07:18  [ EventFetcher for fetching Map Completion Events:895110 ] - [ INFO ]  attempt_local1587666569_0083_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:07:18  [ localfetcher#83:895110 ] - [ INFO ]  localfetcher#83 about to shuffle output of map attempt_local1587666569_0083_m_000000_0 decomp: 2108 len: 2112 to MEMORY
2020-11-20 13:07:18  [ localfetcher#83:895111 ] - [ INFO ]  Read 2108 bytes from map-output for attempt_local1587666569_0083_m_000000_0
2020-11-20 13:07:18  [ localfetcher#83:895111 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2108, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2108
2020-11-20 13:07:18  [ EventFetcher for fetching Map Completion Events:895111 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:07:18  [ pool-252-thread-1:895111 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:18  [ pool-252-thread-1:895111 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:07:18  [ pool-252-thread-1:895112 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:18  [ pool-252-thread-1:895112 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2101 bytes
2020-11-20 13:07:18  [ pool-252-thread-1:895112 ] - [ INFO ]  Merged 1 segments, 2108 bytes to disk to satisfy reduce memory limit
2020-11-20 13:07:18  [ pool-252-thread-1:895113 ] - [ INFO ]  Merging 1 files, 2112 bytes from disk
2020-11-20 13:07:18  [ pool-252-thread-1:895113 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:07:18  [ pool-252-thread-1:895113 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:18  [ pool-252-thread-1:895113 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2101 bytes
2020-11-20 13:07:18  [ pool-252-thread-1:895113 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:18  [ pool-252-thread-1:895198 ] - [ INFO ]  Task:attempt_local1587666569_0083_r_000000_0 is done. And is in the process of committing
2020-11-20 13:07:18  [ pool-252-thread-1:895205 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:18  [ pool-252-thread-1:895205 ] - [ INFO ]  Task attempt_local1587666569_0083_r_000000_0 is allowed to commit now
2020-11-20 13:07:18  [ pool-252-thread-1:895225 ] - [ INFO ]  Saved output of task 'attempt_local1587666569_0083_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1587666569_0083_r_000000
2020-11-20 13:07:18  [ pool-252-thread-1:895226 ] - [ INFO ]  reduce > reduce
2020-11-20 13:07:18  [ pool-252-thread-1:895226 ] - [ INFO ]  Task 'attempt_local1587666569_0083_r_000000_0' done.
2020-11-20 13:07:18  [ pool-252-thread-1:895226 ] - [ INFO ]  Finishing task: attempt_local1587666569_0083_r_000000_0
2020-11-20 13:07:18  [ Thread-2251:895226 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:07:18  [ main:895577 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:07:18  [ main:895578 ] - [ INFO ]  Job job_local1587666569_0083 completed successfully
2020-11-20 13:07:18  [ main:895579 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=733282
		FILE: Number of bytes written=52230562
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=232999200
		HDFS: Number of bytes written=346003
		HDFS: Number of read operations=2484
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1317
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2397
		Map output materialized bytes=2112
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2112
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=1134559232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:07:18  [ main:895600 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:07:18  [ main:895612 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:07:18  [ main:895616 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:07:18  [ main:895622 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:07:18  [ main:895659 ] - [ INFO ]  number of splits:1
2020-11-20 13:07:18  [ main:895675 ] - [ INFO ]  Submitting tokens for job: job_local1601573954_0084
2020-11-20 13:07:18  [ main:895709 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:07:18  [ main:895709 ] - [ INFO ]  Running job: job_local1601573954_0084
2020-11-20 13:07:18  [ Thread-2278:895709 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:07:18  [ Thread-2278:895709 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:18  [ Thread-2278:895709 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:07:18  [ Thread-2278:895717 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895717 ] - [ INFO ]  Starting task: attempt_local1601573954_0084_m_000000_0
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895717 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895718 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895718 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895718 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895725 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895725 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895725 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895725 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895725 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:07:18  [ LocalJobRunner Map Task Executor #0:895725 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:07:19  [ main:896713 ] - [ INFO ]  Job job_local1601573954_0084 running in uber mode : false
2020-11-20 13:07:19  [ main:896714 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:07:24  [ communication thread:901723 ] - [ INFO ]  map > map
2020-11-20 13:07:25  [ main:902724 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:07:27  [ communication thread:904729 ] - [ INFO ]  map > map
2020-11-20 13:07:27  [ main:904732 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905567 ] - [ INFO ]  map > map
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905568 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905568 ] - [ INFO ]  Spilling map output
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905568 ] - [ INFO ]  bufstart = 0; bufend = 2404; bufvoid = 104857600
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905568 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905569 ] - [ INFO ]  Finished spill 0
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905570 ] - [ INFO ]  Task:attempt_local1601573954_0084_m_000000_0 is done. And is in the process of committing
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905579 ] - [ INFO ]  map
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905579 ] - [ INFO ]  Task 'attempt_local1601573954_0084_m_000000_0' done.
2020-11-20 13:07:28  [ LocalJobRunner Map Task Executor #0:905579 ] - [ INFO ]  Finishing task: attempt_local1601573954_0084_m_000000_0
2020-11-20 13:07:28  [ Thread-2278:905579 ] - [ INFO ]  map task executor complete.
2020-11-20 13:07:28  [ Thread-2278:905580 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:07:28  [ pool-255-thread-1:905580 ] - [ INFO ]  Starting task: attempt_local1601573954_0084_r_000000_0
2020-11-20 13:07:28  [ pool-255-thread-1:905581 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:28  [ pool-255-thread-1:905582 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:28  [ pool-255-thread-1:905582 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:28  [ pool-255-thread-1:905582 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61fba1ba
2020-11-20 13:07:28  [ pool-255-thread-1:905583 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:07:28  [ EventFetcher for fetching Map Completion Events:905583 ] - [ INFO ]  attempt_local1601573954_0084_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:07:28  [ localfetcher#84:905584 ] - [ INFO ]  localfetcher#84 about to shuffle output of map attempt_local1601573954_0084_m_000000_0 decomp: 2115 len: 2119 to MEMORY
2020-11-20 13:07:28  [ localfetcher#84:905585 ] - [ INFO ]  Read 2115 bytes from map-output for attempt_local1601573954_0084_m_000000_0
2020-11-20 13:07:28  [ localfetcher#84:905585 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2115, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2115
2020-11-20 13:07:28  [ EventFetcher for fetching Map Completion Events:905585 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:07:28  [ pool-255-thread-1:905585 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:28  [ pool-255-thread-1:905585 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:07:28  [ pool-255-thread-1:905586 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:28  [ pool-255-thread-1:905586 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 13:07:28  [ pool-255-thread-1:905587 ] - [ INFO ]  Merged 1 segments, 2115 bytes to disk to satisfy reduce memory limit
2020-11-20 13:07:28  [ pool-255-thread-1:905587 ] - [ INFO ]  Merging 1 files, 2119 bytes from disk
2020-11-20 13:07:28  [ pool-255-thread-1:905587 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:07:28  [ pool-255-thread-1:905587 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:28  [ pool-255-thread-1:905587 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2108 bytes
2020-11-20 13:07:28  [ pool-255-thread-1:905587 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:28  [ pool-255-thread-1:905697 ] - [ INFO ]  Task:attempt_local1601573954_0084_r_000000_0 is done. And is in the process of committing
2020-11-20 13:07:28  [ pool-255-thread-1:905716 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:28  [ pool-255-thread-1:905716 ] - [ INFO ]  Task attempt_local1601573954_0084_r_000000_0 is allowed to commit now
2020-11-20 13:07:28  [ main:905736 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:07:28  [ pool-255-thread-1:905753 ] - [ INFO ]  Saved output of task 'attempt_local1601573954_0084_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1601573954_0084_r_000000
2020-11-20 13:07:28  [ pool-255-thread-1:905754 ] - [ INFO ]  reduce > reduce
2020-11-20 13:07:28  [ pool-255-thread-1:905754 ] - [ INFO ]  Task 'attempt_local1601573954_0084_r_000000_0' done.
2020-11-20 13:07:28  [ pool-255-thread-1:905754 ] - [ INFO ]  Finishing task: attempt_local1601573954_0084_r_000000_0
2020-11-20 13:07:28  [ Thread-2278:905754 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:07:29  [ main:906740 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:07:29  [ main:906740 ] - [ INFO ]  Job job_local1601573954_0084 completed successfully
2020-11-20 13:07:29  [ main:906741 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=742190
		FILE: Number of bytes written=52877089
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=235773000
		HDFS: Number of bytes written=350208
		HDFS: Number of read operations=2514
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1333
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2404
		Map output materialized bytes=2119
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2119
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1209008128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:07:29  [ main:906759 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:07:29  [ main:906770 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:07:29  [ main:906775 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:07:29  [ main:906782 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:07:29  [ main:906818 ] - [ INFO ]  number of splits:1
2020-11-20 13:07:29  [ main:906834 ] - [ INFO ]  Submitting tokens for job: job_local166409142_0085
2020-11-20 13:07:29  [ main:906867 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:07:29  [ main:906867 ] - [ INFO ]  Running job: job_local166409142_0085
2020-11-20 13:07:29  [ Thread-2305:906867 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:07:29  [ Thread-2305:906867 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:29  [ Thread-2305:906867 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:07:29  [ Thread-2305:906874 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906874 ] - [ INFO ]  Starting task: attempt_local166409142_0085_m_000000_0
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906875 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906875 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906875 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906875 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906883 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906883 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906883 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906883 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906883 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:07:29  [ LocalJobRunner Map Task Executor #0:906883 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:07:30  [ main:907868 ] - [ INFO ]  Job job_local166409142_0085 running in uber mode : false
2020-11-20 13:07:30  [ main:907868 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:07:35  [ communication thread:912885 ] - [ INFO ]  map > map
2020-11-20 13:07:36  [ main:913889 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:07:38  [ communication thread:915886 ] - [ INFO ]  map > map
2020-11-20 13:07:38  [ main:915892 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916307 ] - [ INFO ]  map > map
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916307 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916307 ] - [ INFO ]  Spilling map output
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916307 ] - [ INFO ]  bufstart = 0; bufend = 2410; bufvoid = 104857600
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916307 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916309 ] - [ INFO ]  Finished spill 0
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916310 ] - [ INFO ]  Task:attempt_local166409142_0085_m_000000_0 is done. And is in the process of committing
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916315 ] - [ INFO ]  map
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916315 ] - [ INFO ]  Task 'attempt_local166409142_0085_m_000000_0' done.
2020-11-20 13:07:39  [ LocalJobRunner Map Task Executor #0:916315 ] - [ INFO ]  Finishing task: attempt_local166409142_0085_m_000000_0
2020-11-20 13:07:39  [ Thread-2305:916315 ] - [ INFO ]  map task executor complete.
2020-11-20 13:07:39  [ Thread-2305:916316 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:07:39  [ pool-258-thread-1:916316 ] - [ INFO ]  Starting task: attempt_local166409142_0085_r_000000_0
2020-11-20 13:07:39  [ pool-258-thread-1:916316 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:39  [ pool-258-thread-1:916317 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:39  [ pool-258-thread-1:916317 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:39  [ pool-258-thread-1:916317 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f48ee5e
2020-11-20 13:07:39  [ pool-258-thread-1:916318 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:07:39  [ EventFetcher for fetching Map Completion Events:916318 ] - [ INFO ]  attempt_local166409142_0085_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:07:39  [ localfetcher#85:916319 ] - [ INFO ]  localfetcher#85 about to shuffle output of map attempt_local166409142_0085_m_000000_0 decomp: 2121 len: 2125 to MEMORY
2020-11-20 13:07:39  [ localfetcher#85:916319 ] - [ INFO ]  Read 2121 bytes from map-output for attempt_local166409142_0085_m_000000_0
2020-11-20 13:07:39  [ localfetcher#85:916319 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2121
2020-11-20 13:07:39  [ EventFetcher for fetching Map Completion Events:916319 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:07:39  [ pool-258-thread-1:916319 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:39  [ pool-258-thread-1:916319 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:07:39  [ pool-258-thread-1:916320 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:39  [ pool-258-thread-1:916320 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2114 bytes
2020-11-20 13:07:39  [ pool-258-thread-1:916320 ] - [ INFO ]  Merged 1 segments, 2121 bytes to disk to satisfy reduce memory limit
2020-11-20 13:07:39  [ pool-258-thread-1:916320 ] - [ INFO ]  Merging 1 files, 2125 bytes from disk
2020-11-20 13:07:39  [ pool-258-thread-1:916320 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:07:39  [ pool-258-thread-1:916320 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:39  [ pool-258-thread-1:916321 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2114 bytes
2020-11-20 13:07:39  [ pool-258-thread-1:916321 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:39  [ pool-258-thread-1:916561 ] - [ INFO ]  Task:attempt_local166409142_0085_r_000000_0 is done. And is in the process of committing
2020-11-20 13:07:39  [ pool-258-thread-1:916567 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:39  [ pool-258-thread-1:916567 ] - [ INFO ]  Task attempt_local166409142_0085_r_000000_0 is allowed to commit now
2020-11-20 13:07:39  [ pool-258-thread-1:916586 ] - [ INFO ]  Saved output of task 'attempt_local166409142_0085_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local166409142_0085_r_000000
2020-11-20 13:07:39  [ pool-258-thread-1:916587 ] - [ INFO ]  reduce > reduce
2020-11-20 13:07:39  [ pool-258-thread-1:916587 ] - [ INFO ]  Task 'attempt_local166409142_0085_r_000000_0' done.
2020-11-20 13:07:39  [ pool-258-thread-1:916587 ] - [ INFO ]  Finishing task: attempt_local166409142_0085_r_000000_0
2020-11-20 13:07:39  [ Thread-2305:916587 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:07:39  [ main:916893 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:07:39  [ main:916893 ] - [ INFO ]  Job job_local166409142_0085 completed successfully
2020-11-20 13:07:39  [ main:916895 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=751124
		FILE: Number of bytes written=53520737
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=238546800
		HDFS: Number of bytes written=354426
		HDFS: Number of read operations=2544
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1349
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2410
		Map output materialized bytes=2125
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2125
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=36
		Total committed heap usage (bytes)=1107296256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:07:40  [ main:917102 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:07:40  [ main:917114 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:07:40  [ main:917118 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:07:40  [ main:917123 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:07:40  [ main:917160 ] - [ INFO ]  number of splits:1
2020-11-20 13:07:40  [ main:917176 ] - [ INFO ]  Submitting tokens for job: job_local445513063_0086
2020-11-20 13:07:40  [ main:917210 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:07:40  [ main:917210 ] - [ INFO ]  Running job: job_local445513063_0086
2020-11-20 13:07:40  [ Thread-2332:917210 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:07:40  [ Thread-2332:917210 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:40  [ Thread-2332:917210 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:07:40  [ Thread-2332:917317 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917317 ] - [ INFO ]  Starting task: attempt_local445513063_0086_m_000000_0
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917318 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917318 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917318 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917319 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917327 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917327 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917327 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917327 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917327 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:07:40  [ LocalJobRunner Map Task Executor #0:917327 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:07:41  [ main:918214 ] - [ INFO ]  Job job_local445513063_0086 running in uber mode : false
2020-11-20 13:07:41  [ main:918214 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:07:46  [ communication thread:923324 ] - [ INFO ]  map > map
2020-11-20 13:07:47  [ main:924231 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:07:49  [ communication thread:926327 ] - [ INFO ]  map > map
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926916 ] - [ INFO ]  map > map
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926917 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926917 ] - [ INFO ]  Spilling map output
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926917 ] - [ INFO ]  bufstart = 0; bufend = 2406; bufvoid = 104857600
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926917 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926919 ] - [ INFO ]  Finished spill 0
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926920 ] - [ INFO ]  Task:attempt_local445513063_0086_m_000000_0 is done. And is in the process of committing
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926927 ] - [ INFO ]  map
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926927 ] - [ INFO ]  Task 'attempt_local445513063_0086_m_000000_0' done.
2020-11-20 13:07:49  [ LocalJobRunner Map Task Executor #0:926927 ] - [ INFO ]  Finishing task: attempt_local445513063_0086_m_000000_0
2020-11-20 13:07:49  [ Thread-2332:926927 ] - [ INFO ]  map task executor complete.
2020-11-20 13:07:49  [ Thread-2332:926927 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:07:49  [ pool-261-thread-1:926928 ] - [ INFO ]  Starting task: attempt_local445513063_0086_r_000000_0
2020-11-20 13:07:49  [ pool-261-thread-1:926928 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:49  [ pool-261-thread-1:926928 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:49  [ pool-261-thread-1:926928 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:49  [ pool-261-thread-1:926928 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f2408bc
2020-11-20 13:07:49  [ pool-261-thread-1:926930 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:07:49  [ EventFetcher for fetching Map Completion Events:926930 ] - [ INFO ]  attempt_local445513063_0086_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:07:49  [ localfetcher#86:926931 ] - [ INFO ]  localfetcher#86 about to shuffle output of map attempt_local445513063_0086_m_000000_0 decomp: 2117 len: 2121 to MEMORY
2020-11-20 13:07:49  [ localfetcher#86:926931 ] - [ INFO ]  Read 2117 bytes from map-output for attempt_local445513063_0086_m_000000_0
2020-11-20 13:07:49  [ localfetcher#86:926931 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2117, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2117
2020-11-20 13:07:49  [ EventFetcher for fetching Map Completion Events:926932 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:07:49  [ pool-261-thread-1:926932 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:49  [ pool-261-thread-1:926932 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:07:49  [ pool-261-thread-1:926933 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:49  [ pool-261-thread-1:926933 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2110 bytes
2020-11-20 13:07:49  [ pool-261-thread-1:926933 ] - [ INFO ]  Merged 1 segments, 2117 bytes to disk to satisfy reduce memory limit
2020-11-20 13:07:49  [ pool-261-thread-1:926934 ] - [ INFO ]  Merging 1 files, 2121 bytes from disk
2020-11-20 13:07:49  [ pool-261-thread-1:926934 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:07:49  [ pool-261-thread-1:926934 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:07:49  [ pool-261-thread-1:926934 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2110 bytes
2020-11-20 13:07:49  [ pool-261-thread-1:926934 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:50  [ pool-261-thread-1:927040 ] - [ INFO ]  Task:attempt_local445513063_0086_r_000000_0 is done. And is in the process of committing
2020-11-20 13:07:50  [ pool-261-thread-1:927047 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:07:50  [ pool-261-thread-1:927047 ] - [ INFO ]  Task attempt_local445513063_0086_r_000000_0 is allowed to commit now
2020-11-20 13:07:50  [ pool-261-thread-1:927066 ] - [ INFO ]  Saved output of task 'attempt_local445513063_0086_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local445513063_0086_r_000000
2020-11-20 13:07:50  [ pool-261-thread-1:927067 ] - [ INFO ]  reduce > reduce
2020-11-20 13:07:50  [ pool-261-thread-1:927067 ] - [ INFO ]  Task 'attempt_local445513063_0086_r_000000_0' done.
2020-11-20 13:07:50  [ pool-261-thread-1:927067 ] - [ INFO ]  Finishing task: attempt_local445513063_0086_r_000000_0
2020-11-20 13:07:50  [ Thread-2332:927067 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:07:50  [ main:927236 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:07:50  [ main:927236 ] - [ INFO ]  Job job_local445513063_0086 completed successfully
2020-11-20 13:07:50  [ main:927238 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=760062
		FILE: Number of bytes written=54164475
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=241320600
		HDFS: Number of bytes written=358646
		HDFS: Number of read operations=2574
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1365
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2406
		Map output materialized bytes=2121
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2121
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1035993088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:07:50  [ main:927331 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:07:50  [ main:927342 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:07:50  [ main:927346 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:07:50  [ main:927354 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:07:50  [ main:927391 ] - [ INFO ]  number of splits:1
2020-11-20 13:07:50  [ main:927407 ] - [ INFO ]  Submitting tokens for job: job_local1694009415_0087
2020-11-20 13:07:50  [ main:927443 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:07:50  [ main:927443 ] - [ INFO ]  Running job: job_local1694009415_0087
2020-11-20 13:07:50  [ Thread-2359:927443 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:07:50  [ Thread-2359:927444 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:50  [ Thread-2359:927444 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:07:50  [ Thread-2359:927452 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927452 ] - [ INFO ]  Starting task: attempt_local1694009415_0087_m_000000_0
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927452 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927452 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927453 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927453 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927460 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927460 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927460 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927460 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927460 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:07:50  [ LocalJobRunner Map Task Executor #0:927460 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:07:51  [ main:928447 ] - [ INFO ]  Job job_local1694009415_0087 running in uber mode : false
2020-11-20 13:07:51  [ main:928447 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:07:56  [ communication thread:933462 ] - [ INFO ]  map > map
2020-11-20 13:07:57  [ main:934463 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:07:59  [ communication thread:936464 ] - [ INFO ]  map > map
2020-11-20 13:07:59  [ main:936464 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937280 ] - [ INFO ]  map > map
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937280 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937280 ] - [ INFO ]  Spilling map output
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937280 ] - [ INFO ]  bufstart = 0; bufend = 2428; bufvoid = 104857600
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937280 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937282 ] - [ INFO ]  Finished spill 0
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937283 ] - [ INFO ]  Task:attempt_local1694009415_0087_m_000000_0 is done. And is in the process of committing
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937290 ] - [ INFO ]  map
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937290 ] - [ INFO ]  Task 'attempt_local1694009415_0087_m_000000_0' done.
2020-11-20 13:08:00  [ LocalJobRunner Map Task Executor #0:937290 ] - [ INFO ]  Finishing task: attempt_local1694009415_0087_m_000000_0
2020-11-20 13:08:00  [ Thread-2359:937290 ] - [ INFO ]  map task executor complete.
2020-11-20 13:08:00  [ Thread-2359:937291 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:08:00  [ pool-264-thread-1:937291 ] - [ INFO ]  Starting task: attempt_local1694009415_0087_r_000000_0
2020-11-20 13:08:00  [ pool-264-thread-1:937292 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:00  [ pool-264-thread-1:937292 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:00  [ pool-264-thread-1:937292 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:00  [ pool-264-thread-1:937292 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@144a9473
2020-11-20 13:08:00  [ main:937469 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:08:01  [ pool-264-thread-1:938060 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:08:01  [ EventFetcher for fetching Map Completion Events:938061 ] - [ INFO ]  attempt_local1694009415_0087_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:08:01  [ localfetcher#87:938062 ] - [ INFO ]  localfetcher#87 about to shuffle output of map attempt_local1694009415_0087_m_000000_0 decomp: 2139 len: 2143 to MEMORY
2020-11-20 13:08:01  [ localfetcher#87:938062 ] - [ INFO ]  Read 2139 bytes from map-output for attempt_local1694009415_0087_m_000000_0
2020-11-20 13:08:01  [ localfetcher#87:938062 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2139, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2139
2020-11-20 13:08:01  [ EventFetcher for fetching Map Completion Events:938062 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:08:01  [ pool-264-thread-1:938063 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:01  [ pool-264-thread-1:938063 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:08:01  [ pool-264-thread-1:938064 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:01  [ pool-264-thread-1:938064 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2132 bytes
2020-11-20 13:08:01  [ pool-264-thread-1:938064 ] - [ INFO ]  Merged 1 segments, 2139 bytes to disk to satisfy reduce memory limit
2020-11-20 13:08:01  [ pool-264-thread-1:938065 ] - [ INFO ]  Merging 1 files, 2143 bytes from disk
2020-11-20 13:08:01  [ pool-264-thread-1:938065 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:08:01  [ pool-264-thread-1:938065 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:01  [ pool-264-thread-1:938065 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2132 bytes
2020-11-20 13:08:01  [ pool-264-thread-1:938065 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:01  [ pool-264-thread-1:938153 ] - [ INFO ]  Task:attempt_local1694009415_0087_r_000000_0 is done. And is in the process of committing
2020-11-20 13:08:01  [ pool-264-thread-1:938159 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:01  [ pool-264-thread-1:938159 ] - [ INFO ]  Task attempt_local1694009415_0087_r_000000_0 is allowed to commit now
2020-11-20 13:08:01  [ pool-264-thread-1:938176 ] - [ INFO ]  Saved output of task 'attempt_local1694009415_0087_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1694009415_0087_r_000000
2020-11-20 13:08:01  [ pool-264-thread-1:938177 ] - [ INFO ]  reduce > reduce
2020-11-20 13:08:01  [ pool-264-thread-1:938177 ] - [ INFO ]  Task 'attempt_local1694009415_0087_r_000000_0' done.
2020-11-20 13:08:01  [ pool-264-thread-1:938177 ] - [ INFO ]  Finishing task: attempt_local1694009415_0087_r_000000_0
2020-11-20 13:08:01  [ Thread-2359:938177 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:08:01  [ main:938471 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:08:01  [ main:938472 ] - [ INFO ]  Job job_local1694009415_0087 completed successfully
2020-11-20 13:08:01  [ main:938474 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=769036
		FILE: Number of bytes written=54811623
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=244094400
		HDFS: Number of bytes written=362884
		HDFS: Number of read operations=2604
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1381
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2428
		Map output materialized bytes=2143
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2143
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=62
		Total committed heap usage (bytes)=934281216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:08:01  [ main:938493 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:08:01  [ main:938504 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:08:01  [ main:938508 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:08:01  [ main:938514 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:08:01  [ main:938553 ] - [ INFO ]  number of splits:1
2020-11-20 13:08:01  [ main:938570 ] - [ INFO ]  Submitting tokens for job: job_local1607015677_0088
2020-11-20 13:08:01  [ main:938602 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:08:01  [ main:938602 ] - [ INFO ]  Running job: job_local1607015677_0088
2020-11-20 13:08:01  [ Thread-2386:938602 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:08:01  [ Thread-2386:938602 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:01  [ Thread-2386:938602 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:08:01  [ Thread-2386:938610 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938610 ] - [ INFO ]  Starting task: attempt_local1607015677_0088_m_000000_0
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938611 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938611 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938611 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938611 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938619 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938619 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938619 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938619 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938619 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:08:01  [ LocalJobRunner Map Task Executor #0:938620 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:08:02  [ main:939606 ] - [ INFO ]  Job job_local1607015677_0088 running in uber mode : false
2020-11-20 13:08:02  [ main:939607 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:08:07  [ communication thread:944616 ] - [ INFO ]  map > map
2020-11-20 13:08:07  [ main:944624 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:08:10  [ communication thread:947618 ] - [ INFO ]  map > map
2020-11-20 13:08:10  [ main:947632 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948191 ] - [ INFO ]  map > map
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948191 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948191 ] - [ INFO ]  Spilling map output
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948191 ] - [ INFO ]  bufstart = 0; bufend = 2416; bufvoid = 104857600
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948191 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948193 ] - [ INFO ]  Finished spill 0
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948194 ] - [ INFO ]  Task:attempt_local1607015677_0088_m_000000_0 is done. And is in the process of committing
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948202 ] - [ INFO ]  map
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948202 ] - [ INFO ]  Task 'attempt_local1607015677_0088_m_000000_0' done.
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948202 ] - [ INFO ]  Finishing task: attempt_local1607015677_0088_m_000000_0
2020-11-20 13:08:11  [ Thread-2386:948202 ] - [ INFO ]  map task executor complete.
2020-11-20 13:08:11  [ Thread-2386:948202 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:08:11  [ pool-267-thread-1:948202 ] - [ INFO ]  Starting task: attempt_local1607015677_0088_r_000000_0
2020-11-20 13:08:11  [ pool-267-thread-1:948203 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:11  [ pool-267-thread-1:948203 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:11  [ pool-267-thread-1:948204 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:11  [ pool-267-thread-1:948204 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5203ac50
2020-11-20 13:08:11  [ pool-267-thread-1:948205 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:08:11  [ EventFetcher for fetching Map Completion Events:948205 ] - [ INFO ]  attempt_local1607015677_0088_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:08:11  [ localfetcher#88:948206 ] - [ INFO ]  localfetcher#88 about to shuffle output of map attempt_local1607015677_0088_m_000000_0 decomp: 2127 len: 2131 to MEMORY
2020-11-20 13:08:11  [ localfetcher#88:948206 ] - [ INFO ]  Read 2127 bytes from map-output for attempt_local1607015677_0088_m_000000_0
2020-11-20 13:08:11  [ localfetcher#88:948206 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2127, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2127
2020-11-20 13:08:11  [ EventFetcher for fetching Map Completion Events:948207 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:08:11  [ pool-267-thread-1:948207 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:11  [ pool-267-thread-1:948207 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2120 bytes
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Merged 1 segments, 2127 bytes to disk to satisfy reduce memory limit
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Merging 1 files, 2131 bytes from disk
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2120 bytes
2020-11-20 13:08:11  [ pool-267-thread-1:948208 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:11  [ pool-267-thread-1:948291 ] - [ INFO ]  Task:attempt_local1607015677_0088_r_000000_0 is done. And is in the process of committing
2020-11-20 13:08:11  [ pool-267-thread-1:948298 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:11  [ pool-267-thread-1:948298 ] - [ INFO ]  Task attempt_local1607015677_0088_r_000000_0 is allowed to commit now
2020-11-20 13:08:11  [ pool-267-thread-1:948318 ] - [ INFO ]  Saved output of task 'attempt_local1607015677_0088_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1607015677_0088_r_000000
2020-11-20 13:08:11  [ pool-267-thread-1:948318 ] - [ INFO ]  reduce > reduce
2020-11-20 13:08:11  [ pool-267-thread-1:948318 ] - [ INFO ]  Task 'attempt_local1607015677_0088_r_000000_0' done.
2020-11-20 13:08:11  [ pool-267-thread-1:948318 ] - [ INFO ]  Finishing task: attempt_local1607015677_0088_r_000000_0
2020-11-20 13:08:11  [ Thread-2386:948318 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:08:11  [ main:948633 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:08:11  [ main:948634 ] - [ INFO ]  Job job_local1607015677_0088 completed successfully
2020-11-20 13:08:11  [ main:948634 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=778030
		FILE: Number of bytes written=55459349
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=246868200
		HDFS: Number of bytes written=367132
		HDFS: Number of read operations=2634
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1397
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2416
		Map output materialized bytes=2131
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2131
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=926941184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:08:11  [ main:948653 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:08:11  [ main:948665 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:08:11  [ main:948669 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:08:11  [ main:948676 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:08:11  [ main:948717 ] - [ INFO ]  number of splits:1
2020-11-20 13:08:11  [ main:948734 ] - [ INFO ]  Submitting tokens for job: job_local321765027_0089
2020-11-20 13:08:11  [ main:948766 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:08:11  [ main:948766 ] - [ INFO ]  Running job: job_local321765027_0089
2020-11-20 13:08:11  [ Thread-2413:948766 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:08:11  [ Thread-2413:948766 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:11  [ Thread-2413:948767 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:08:11  [ Thread-2413:948774 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948774 ] - [ INFO ]  Starting task: attempt_local321765027_0089_m_000000_0
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948774 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948774 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948774 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948775 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948783 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948783 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948783 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948783 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948783 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:08:11  [ LocalJobRunner Map Task Executor #0:948783 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:08:12  [ main:949771 ] - [ INFO ]  Job job_local321765027_0089 running in uber mode : false
2020-11-20 13:08:12  [ main:949771 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:08:17  [ communication thread:954779 ] - [ INFO ]  map > map
2020-11-20 13:08:17  [ main:954785 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:08:20  [ communication thread:957783 ] - [ INFO ]  map > map
2020-11-20 13:08:20  [ main:957792 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958622 ] - [ INFO ]  map > map
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958622 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958622 ] - [ INFO ]  Spilling map output
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958622 ] - [ INFO ]  bufstart = 0; bufend = 2367; bufvoid = 104857600
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958622 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958624 ] - [ INFO ]  Finished spill 0
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958625 ] - [ INFO ]  Task:attempt_local321765027_0089_m_000000_0 is done. And is in the process of committing
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958632 ] - [ INFO ]  map
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958632 ] - [ INFO ]  Task 'attempt_local321765027_0089_m_000000_0' done.
2020-11-20 13:08:21  [ LocalJobRunner Map Task Executor #0:958632 ] - [ INFO ]  Finishing task: attempt_local321765027_0089_m_000000_0
2020-11-20 13:08:21  [ Thread-2413:958632 ] - [ INFO ]  map task executor complete.
2020-11-20 13:08:21  [ Thread-2413:958632 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:08:21  [ pool-270-thread-1:958632 ] - [ INFO ]  Starting task: attempt_local321765027_0089_r_000000_0
2020-11-20 13:08:21  [ pool-270-thread-1:958633 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:21  [ pool-270-thread-1:958633 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:21  [ pool-270-thread-1:958633 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:21  [ pool-270-thread-1:958633 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@cd3de59
2020-11-20 13:08:21  [ pool-270-thread-1:958634 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:08:21  [ EventFetcher for fetching Map Completion Events:958634 ] - [ INFO ]  attempt_local321765027_0089_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:08:21  [ localfetcher#89:958635 ] - [ INFO ]  localfetcher#89 about to shuffle output of map attempt_local321765027_0089_m_000000_0 decomp: 2078 len: 2082 to MEMORY
2020-11-20 13:08:21  [ localfetcher#89:958635 ] - [ INFO ]  Read 2078 bytes from map-output for attempt_local321765027_0089_m_000000_0
2020-11-20 13:08:21  [ localfetcher#89:958635 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2078, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2078
2020-11-20 13:08:21  [ EventFetcher for fetching Map Completion Events:958635 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:08:21  [ pool-270-thread-1:958635 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:21  [ pool-270-thread-1:958635 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:08:21  [ pool-270-thread-1:958636 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:21  [ pool-270-thread-1:958636 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2071 bytes
2020-11-20 13:08:21  [ pool-270-thread-1:958636 ] - [ INFO ]  Merged 1 segments, 2078 bytes to disk to satisfy reduce memory limit
2020-11-20 13:08:21  [ pool-270-thread-1:958637 ] - [ INFO ]  Merging 1 files, 2082 bytes from disk
2020-11-20 13:08:21  [ pool-270-thread-1:958637 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:08:21  [ pool-270-thread-1:958637 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:21  [ pool-270-thread-1:958637 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2071 bytes
2020-11-20 13:08:21  [ pool-270-thread-1:958637 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:21  [ pool-270-thread-1:958722 ] - [ INFO ]  Task:attempt_local321765027_0089_r_000000_0 is done. And is in the process of committing
2020-11-20 13:08:21  [ pool-270-thread-1:958728 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:21  [ pool-270-thread-1:958728 ] - [ INFO ]  Task attempt_local321765027_0089_r_000000_0 is allowed to commit now
2020-11-20 13:08:21  [ pool-270-thread-1:958750 ] - [ INFO ]  Saved output of task 'attempt_local321765027_0089_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local321765027_0089_r_000000
2020-11-20 13:08:21  [ pool-270-thread-1:958750 ] - [ INFO ]  reduce > reduce
2020-11-20 13:08:21  [ pool-270-thread-1:958750 ] - [ INFO ]  Task 'attempt_local321765027_0089_r_000000_0' done.
2020-11-20 13:08:21  [ pool-270-thread-1:958750 ] - [ INFO ]  Finishing task: attempt_local321765027_0089_r_000000_0
2020-11-20 13:08:21  [ Thread-2413:958750 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:08:21  [ main:958792 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:08:22  [ main:959797 ] - [ INFO ]  Job job_local321765027_0089 completed successfully
2020-11-20 13:08:22  [ main:959799 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=786902
		FILE: Number of bytes written=56103992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=249642000
		HDFS: Number of bytes written=371319
		HDFS: Number of read operations=2664
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1413
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2367
		Map output materialized bytes=2082
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2082
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=882900992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:08:22  [ main:959820 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:08:22  [ main:959833 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:08:22  [ main:959837 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:08:22  [ main:959843 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:08:22  [ main:959885 ] - [ INFO ]  number of splits:1
2020-11-20 13:08:22  [ main:959902 ] - [ INFO ]  Submitting tokens for job: job_local2104257606_0090
2020-11-20 13:08:22  [ main:959935 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:08:22  [ main:959935 ] - [ INFO ]  Running job: job_local2104257606_0090
2020-11-20 13:08:22  [ Thread-2440:959935 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:08:22  [ Thread-2440:959935 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:22  [ Thread-2440:959935 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:08:22  [ Thread-2440:959943 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959943 ] - [ INFO ]  Starting task: attempt_local2104257606_0090_m_000000_0
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959943 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959943 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959943 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959944 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959951 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959952 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959952 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959952 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959952 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:08:22  [ LocalJobRunner Map Task Executor #0:959952 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:08:23  [ main:960938 ] - [ INFO ]  Job job_local2104257606_0090 running in uber mode : false
2020-11-20 13:08:23  [ main:960939 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:08:28  [ communication thread:965949 ] - [ INFO ]  map > map
2020-11-20 13:08:28  [ main:965952 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:08:31  [ communication thread:968952 ] - [ INFO ]  map > map
2020-11-20 13:08:31  [ main:968963 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969565 ] - [ INFO ]  map > map
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969565 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969565 ] - [ INFO ]  Spilling map output
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969565 ] - [ INFO ]  bufstart = 0; bufend = 2382; bufvoid = 104857600
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969565 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969567 ] - [ INFO ]  Finished spill 0
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969568 ] - [ INFO ]  Task:attempt_local2104257606_0090_m_000000_0 is done. And is in the process of committing
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969574 ] - [ INFO ]  map
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969575 ] - [ INFO ]  Task 'attempt_local2104257606_0090_m_000000_0' done.
2020-11-20 13:08:32  [ LocalJobRunner Map Task Executor #0:969575 ] - [ INFO ]  Finishing task: attempt_local2104257606_0090_m_000000_0
2020-11-20 13:08:32  [ Thread-2440:969575 ] - [ INFO ]  map task executor complete.
2020-11-20 13:08:32  [ Thread-2440:969575 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:08:32  [ pool-273-thread-1:969575 ] - [ INFO ]  Starting task: attempt_local2104257606_0090_r_000000_0
2020-11-20 13:08:32  [ pool-273-thread-1:969576 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:32  [ pool-273-thread-1:969576 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:32  [ pool-273-thread-1:969576 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:32  [ pool-273-thread-1:969576 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e1634b2
2020-11-20 13:08:32  [ pool-273-thread-1:969577 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:08:32  [ EventFetcher for fetching Map Completion Events:969578 ] - [ INFO ]  attempt_local2104257606_0090_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:08:32  [ localfetcher#90:969578 ] - [ INFO ]  localfetcher#90 about to shuffle output of map attempt_local2104257606_0090_m_000000_0 decomp: 2093 len: 2097 to MEMORY
2020-11-20 13:08:32  [ localfetcher#90:969578 ] - [ INFO ]  Read 2093 bytes from map-output for attempt_local2104257606_0090_m_000000_0
2020-11-20 13:08:32  [ localfetcher#90:969578 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2093, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2093
2020-11-20 13:08:32  [ EventFetcher for fetching Map Completion Events:969579 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:08:32  [ pool-273-thread-1:969579 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:32  [ pool-273-thread-1:969579 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:08:32  [ pool-273-thread-1:969579 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2086 bytes
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  Merged 1 segments, 2093 bytes to disk to satisfy reduce memory limit
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  Merging 1 files, 2097 bytes from disk
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2086 bytes
2020-11-20 13:08:32  [ pool-273-thread-1:969580 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:32  [ pool-273-thread-1:969700 ] - [ INFO ]  Task:attempt_local2104257606_0090_r_000000_0 is done. And is in the process of committing
2020-11-20 13:08:32  [ pool-273-thread-1:969706 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:32  [ pool-273-thread-1:969707 ] - [ INFO ]  Task attempt_local2104257606_0090_r_000000_0 is allowed to commit now
2020-11-20 13:08:32  [ pool-273-thread-1:969726 ] - [ INFO ]  Saved output of task 'attempt_local2104257606_0090_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2104257606_0090_r_000000
2020-11-20 13:08:32  [ pool-273-thread-1:969726 ] - [ INFO ]  reduce > reduce
2020-11-20 13:08:32  [ pool-273-thread-1:969726 ] - [ INFO ]  Task 'attempt_local2104257606_0090_r_000000_0' done.
2020-11-20 13:08:32  [ pool-273-thread-1:969726 ] - [ INFO ]  Finishing task: attempt_local2104257606_0090_r_000000_0
2020-11-20 13:08:32  [ Thread-2440:969726 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:08:32  [ main:969967 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:08:32  [ main:969967 ] - [ INFO ]  Job job_local2104257606_0090 completed successfully
2020-11-20 13:08:32  [ main:969968 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=795706
		FILE: Number of bytes written=56751723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=252415800
		HDFS: Number of bytes written=375472
		HDFS: Number of read operations=2694
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1429
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2382
		Map output materialized bytes=2097
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2097
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=877658112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:08:32  [ main:969988 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:08:32  [ main:969999 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:08:33  [ main:970003 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:08:33  [ main:970009 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:08:33  [ main:970046 ] - [ INFO ]  number of splits:1
2020-11-20 13:08:33  [ main:970063 ] - [ INFO ]  Submitting tokens for job: job_local1496449473_0091
2020-11-20 13:08:33  [ main:970099 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:08:33  [ main:970099 ] - [ INFO ]  Running job: job_local1496449473_0091
2020-11-20 13:08:33  [ Thread-2467:970099 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:08:33  [ Thread-2467:970099 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:33  [ Thread-2467:970099 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:08:33  [ Thread-2467:970107 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970107 ] - [ INFO ]  Starting task: attempt_local1496449473_0091_m_000000_0
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970108 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970108 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970108 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970108 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970116 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970116 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970116 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970116 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970116 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:08:33  [ LocalJobRunner Map Task Executor #0:970116 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:08:34  [ main:971103 ] - [ INFO ]  Job job_local1496449473_0091 running in uber mode : false
2020-11-20 13:08:34  [ main:971104 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:08:39  [ communication thread:976115 ] - [ INFO ]  map > map
2020-11-20 13:08:40  [ main:977118 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:08:42  [ communication thread:979120 ] - [ INFO ]  map > map
2020-11-20 13:08:42  [ main:979123 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979992 ] - [ INFO ]  map > map
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979992 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979992 ] - [ INFO ]  Spilling map output
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979992 ] - [ INFO ]  bufstart = 0; bufend = 2372; bufvoid = 104857600
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979992 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979994 ] - [ INFO ]  Finished spill 0
2020-11-20 13:08:42  [ LocalJobRunner Map Task Executor #0:979994 ] - [ INFO ]  Task:attempt_local1496449473_0091_m_000000_0 is done. And is in the process of committing
2020-11-20 13:08:43  [ LocalJobRunner Map Task Executor #0:980001 ] - [ INFO ]  map
2020-11-20 13:08:43  [ LocalJobRunner Map Task Executor #0:980001 ] - [ INFO ]  Task 'attempt_local1496449473_0091_m_000000_0' done.
2020-11-20 13:08:43  [ LocalJobRunner Map Task Executor #0:980001 ] - [ INFO ]  Finishing task: attempt_local1496449473_0091_m_000000_0
2020-11-20 13:08:43  [ Thread-2467:980001 ] - [ INFO ]  map task executor complete.
2020-11-20 13:08:43  [ Thread-2467:980001 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:08:43  [ pool-276-thread-1:980001 ] - [ INFO ]  Starting task: attempt_local1496449473_0091_r_000000_0
2020-11-20 13:08:43  [ pool-276-thread-1:980002 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:43  [ pool-276-thread-1:980002 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:43  [ pool-276-thread-1:980002 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:43  [ pool-276-thread-1:980002 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@416608c1
2020-11-20 13:08:43  [ pool-276-thread-1:980003 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:08:43  [ EventFetcher for fetching Map Completion Events:980003 ] - [ INFO ]  attempt_local1496449473_0091_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:08:43  [ localfetcher#91:980004 ] - [ INFO ]  localfetcher#91 about to shuffle output of map attempt_local1496449473_0091_m_000000_0 decomp: 2083 len: 2087 to MEMORY
2020-11-20 13:08:43  [ localfetcher#91:980004 ] - [ INFO ]  Read 2083 bytes from map-output for attempt_local1496449473_0091_m_000000_0
2020-11-20 13:08:43  [ localfetcher#91:980004 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2083, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2083
2020-11-20 13:08:43  [ EventFetcher for fetching Map Completion Events:980005 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:08:43  [ pool-276-thread-1:980005 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:43  [ pool-276-thread-1:980005 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:08:43  [ pool-276-thread-1:980005 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2076 bytes
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  Merged 1 segments, 2083 bytes to disk to satisfy reduce memory limit
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  Merging 1 files, 2087 bytes from disk
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2076 bytes
2020-11-20 13:08:43  [ pool-276-thread-1:980006 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:43  [ pool-276-thread-1:980087 ] - [ INFO ]  Task:attempt_local1496449473_0091_r_000000_0 is done. And is in the process of committing
2020-11-20 13:08:43  [ pool-276-thread-1:980094 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:43  [ pool-276-thread-1:980094 ] - [ INFO ]  Task attempt_local1496449473_0091_r_000000_0 is allowed to commit now
2020-11-20 13:08:43  [ pool-276-thread-1:980113 ] - [ INFO ]  Saved output of task 'attempt_local1496449473_0091_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1496449473_0091_r_000000
2020-11-20 13:08:43  [ pool-276-thread-1:980114 ] - [ INFO ]  reduce > reduce
2020-11-20 13:08:43  [ pool-276-thread-1:980114 ] - [ INFO ]  Task 'attempt_local1496449473_0091_r_000000_0' done.
2020-11-20 13:08:43  [ pool-276-thread-1:980114 ] - [ INFO ]  Finishing task: attempt_local1496449473_0091_r_000000_0
2020-11-20 13:08:43  [ Thread-2467:980115 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:08:43  [ main:980128 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:08:44  [ main:981130 ] - [ INFO ]  Job job_local1496449473_0091 completed successfully
2020-11-20 13:08:44  [ main:981132 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=804520
		FILE: Number of bytes written=57399651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=255189600
		HDFS: Number of bytes written=379630
		HDFS: Number of read operations=2724
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1445
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2372
		Map output materialized bytes=2087
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2087
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=37
		Total committed heap usage (bytes)=856686592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:08:44  [ main:981154 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:08:44  [ main:981167 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:08:44  [ main:981174 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:08:44  [ main:981181 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:08:44  [ main:981224 ] - [ INFO ]  number of splits:1
2020-11-20 13:08:44  [ main:981242 ] - [ INFO ]  Submitting tokens for job: job_local959571423_0092
2020-11-20 13:08:44  [ main:981279 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:08:44  [ main:981279 ] - [ INFO ]  Running job: job_local959571423_0092
2020-11-20 13:08:44  [ Thread-2494:981280 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:08:44  [ Thread-2494:981280 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:44  [ Thread-2494:981280 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:08:44  [ Thread-2494:981288 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981288 ] - [ INFO ]  Starting task: attempt_local959571423_0092_m_000000_0
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981288 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981288 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981289 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981289 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981296 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981296 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981297 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981297 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981297 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:08:44  [ LocalJobRunner Map Task Executor #0:981297 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:08:45  [ main:982282 ] - [ INFO ]  Job job_local959571423_0092 running in uber mode : false
2020-11-20 13:08:45  [ main:982283 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:08:50  [ communication thread:987298 ] - [ INFO ]  map > map
2020-11-20 13:08:51  [ main:988302 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:08:53  [ communication thread:990298 ] - [ INFO ]  map > map
2020-11-20 13:08:53  [ main:990306 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990952 ] - [ INFO ]  map > map
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990952 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990952 ] - [ INFO ]  Spilling map output
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990952 ] - [ INFO ]  bufstart = 0; bufend = 2510; bufvoid = 104857600
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990952 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990954 ] - [ INFO ]  Finished spill 0
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990955 ] - [ INFO ]  Task:attempt_local959571423_0092_m_000000_0 is done. And is in the process of committing
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990962 ] - [ INFO ]  map
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990962 ] - [ INFO ]  Task 'attempt_local959571423_0092_m_000000_0' done.
2020-11-20 13:08:53  [ LocalJobRunner Map Task Executor #0:990962 ] - [ INFO ]  Finishing task: attempt_local959571423_0092_m_000000_0
2020-11-20 13:08:53  [ Thread-2494:990962 ] - [ INFO ]  map task executor complete.
2020-11-20 13:08:53  [ Thread-2494:990963 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:08:53  [ pool-279-thread-1:990963 ] - [ INFO ]  Starting task: attempt_local959571423_0092_r_000000_0
2020-11-20 13:08:53  [ pool-279-thread-1:990964 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:53  [ pool-279-thread-1:990964 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:53  [ pool-279-thread-1:990964 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:53  [ pool-279-thread-1:990964 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@769a8133
2020-11-20 13:08:53  [ pool-279-thread-1:990966 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:08:53  [ EventFetcher for fetching Map Completion Events:990966 ] - [ INFO ]  attempt_local959571423_0092_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:08:53  [ localfetcher#92:990967 ] - [ INFO ]  localfetcher#92 about to shuffle output of map attempt_local959571423_0092_m_000000_0 decomp: 2122 len: 2126 to MEMORY
2020-11-20 13:08:53  [ localfetcher#92:990967 ] - [ INFO ]  Read 2122 bytes from map-output for attempt_local959571423_0092_m_000000_0
2020-11-20 13:08:53  [ localfetcher#92:990967 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2122
2020-11-20 13:08:53  [ EventFetcher for fetching Map Completion Events:990967 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:08:53  [ pool-279-thread-1:990967 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:53  [ pool-279-thread-1:990967 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:08:53  [ pool-279-thread-1:990968 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:53  [ pool-279-thread-1:990968 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2114 bytes
2020-11-20 13:08:53  [ pool-279-thread-1:990968 ] - [ INFO ]  Merged 1 segments, 2122 bytes to disk to satisfy reduce memory limit
2020-11-20 13:08:53  [ pool-279-thread-1:990969 ] - [ INFO ]  Merging 1 files, 2126 bytes from disk
2020-11-20 13:08:53  [ pool-279-thread-1:990969 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:08:53  [ pool-279-thread-1:990969 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:08:53  [ pool-279-thread-1:990969 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2114 bytes
2020-11-20 13:08:53  [ pool-279-thread-1:990969 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:54  [ pool-279-thread-1:991055 ] - [ INFO ]  Task:attempt_local959571423_0092_r_000000_0 is done. And is in the process of committing
2020-11-20 13:08:54  [ pool-279-thread-1:991061 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:08:54  [ pool-279-thread-1:991061 ] - [ INFO ]  Task attempt_local959571423_0092_r_000000_0 is allowed to commit now
2020-11-20 13:08:54  [ pool-279-thread-1:991078 ] - [ INFO ]  Saved output of task 'attempt_local959571423_0092_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local959571423_0092_r_000000
2020-11-20 13:08:54  [ pool-279-thread-1:991078 ] - [ INFO ]  reduce > reduce
2020-11-20 13:08:54  [ pool-279-thread-1:991078 ] - [ INFO ]  Task 'attempt_local959571423_0092_r_000000_0' done.
2020-11-20 13:08:54  [ pool-279-thread-1:991078 ] - [ INFO ]  Finishing task: attempt_local959571423_0092_r_000000_0
2020-11-20 13:08:54  [ Thread-2494:991078 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:08:54  [ main:991308 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:08:54  [ main:991309 ] - [ INFO ]  Job job_local959571423_0092 completed successfully
2020-11-20 13:08:54  [ main:991310 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=813392
		FILE: Number of bytes written=58055574
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=257963400
		HDFS: Number of bytes written=383817
		HDFS: Number of read operations=2754
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1461
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2510
		Map output materialized bytes=2126
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2126
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=844103680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:08:54  [ main:991327 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:08:54  [ main:991336 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:08:54  [ main:991341 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:08:54  [ main:991346 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:08:54  [ main:991381 ] - [ INFO ]  number of splits:1
2020-11-20 13:08:54  [ main:991396 ] - [ INFO ]  Submitting tokens for job: job_local945022166_0093
2020-11-20 13:08:54  [ main:991428 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:08:54  [ main:991428 ] - [ INFO ]  Running job: job_local945022166_0093
2020-11-20 13:08:54  [ Thread-2521:991428 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:08:54  [ Thread-2521:991428 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:54  [ Thread-2521:991428 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:08:54  [ Thread-2521:991435 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991435 ] - [ INFO ]  Starting task: attempt_local945022166_0093_m_000000_0
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991435 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991435 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991435 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991436 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991443 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991443 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991443 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991443 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991443 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:08:54  [ LocalJobRunner Map Task Executor #0:991443 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:08:55  [ main:992431 ] - [ INFO ]  Job job_local945022166_0093 running in uber mode : false
2020-11-20 13:08:55  [ main:992431 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:09:00  [ communication thread:997439 ] - [ INFO ]  map > map
2020-11-20 13:09:00  [ main:997447 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:09:03  [ communication thread:1000443 ] - [ INFO ]  map > map
2020-11-20 13:09:03  [ main:1000454 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001262 ] - [ INFO ]  map > map
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001262 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001262 ] - [ INFO ]  Spilling map output
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001263 ] - [ INFO ]  bufstart = 0; bufend = 2444; bufvoid = 104857600
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001263 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001265 ] - [ INFO ]  Finished spill 0
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001266 ] - [ INFO ]  Task:attempt_local945022166_0093_m_000000_0 is done. And is in the process of committing
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001271 ] - [ INFO ]  map
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001271 ] - [ INFO ]  Task 'attempt_local945022166_0093_m_000000_0' done.
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001271 ] - [ INFO ]  Finishing task: attempt_local945022166_0093_m_000000_0
2020-11-20 13:09:04  [ Thread-2521:1001271 ] - [ INFO ]  map task executor complete.
2020-11-20 13:09:04  [ Thread-2521:1001272 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:09:04  [ pool-282-thread-1:1001272 ] - [ INFO ]  Starting task: attempt_local945022166_0093_r_000000_0
2020-11-20 13:09:04  [ pool-282-thread-1:1001273 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:04  [ pool-282-thread-1:1001273 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:04  [ pool-282-thread-1:1001273 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:04  [ pool-282-thread-1:1001273 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21107ead
2020-11-20 13:09:04  [ pool-282-thread-1:1001274 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:09:04  [ EventFetcher for fetching Map Completion Events:1001274 ] - [ INFO ]  attempt_local945022166_0093_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:09:04  [ localfetcher#93:1001275 ] - [ INFO ]  localfetcher#93 about to shuffle output of map attempt_local945022166_0093_m_000000_0 decomp: 2056 len: 2060 to MEMORY
2020-11-20 13:09:04  [ localfetcher#93:1001275 ] - [ INFO ]  Read 2056 bytes from map-output for attempt_local945022166_0093_m_000000_0
2020-11-20 13:09:04  [ localfetcher#93:1001275 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2056, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2056
2020-11-20 13:09:04  [ EventFetcher for fetching Map Completion Events:1001275 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:09:04  [ pool-282-thread-1:1001276 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:04  [ pool-282-thread-1:1001276 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:09:04  [ pool-282-thread-1:1001276 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:04  [ pool-282-thread-1:1001276 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2048 bytes
2020-11-20 13:09:04  [ pool-282-thread-1:1001277 ] - [ INFO ]  Merged 1 segments, 2056 bytes to disk to satisfy reduce memory limit
2020-11-20 13:09:04  [ pool-282-thread-1:1001277 ] - [ INFO ]  Merging 1 files, 2060 bytes from disk
2020-11-20 13:09:04  [ pool-282-thread-1:1001277 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:09:04  [ pool-282-thread-1:1001277 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:04  [ pool-282-thread-1:1001277 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2048 bytes
2020-11-20 13:09:04  [ pool-282-thread-1:1001277 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:04  [ pool-282-thread-1:1001373 ] - [ INFO ]  Task:attempt_local945022166_0093_r_000000_0 is done. And is in the process of committing
2020-11-20 13:09:04  [ pool-282-thread-1:1001379 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:04  [ pool-282-thread-1:1001380 ] - [ INFO ]  Task attempt_local945022166_0093_r_000000_0 is allowed to commit now
2020-11-20 13:09:04  [ pool-282-thread-1:1001397 ] - [ INFO ]  Saved output of task 'attempt_local945022166_0093_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local945022166_0093_r_000000
2020-11-20 13:09:04  [ pool-282-thread-1:1001397 ] - [ INFO ]  reduce > reduce
2020-11-20 13:09:04  [ pool-282-thread-1:1001397 ] - [ INFO ]  Task 'attempt_local945022166_0093_r_000000_0' done.
2020-11-20 13:09:04  [ pool-282-thread-1:1001397 ] - [ INFO ]  Finishing task: attempt_local945022166_0093_r_000000_0
2020-11-20 13:09:04  [ Thread-2521:1001397 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:09:04  [ main:1001458 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:09:04  [ main:1001458 ] - [ INFO ]  Job job_local945022166_0093 completed successfully
2020-11-20 13:09:04  [ main:1001459 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=822210
		FILE: Number of bytes written=58711546
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=260737200
		HDFS: Number of bytes written=387977
		HDFS: Number of read operations=2784
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1477
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2444
		Map output materialized bytes=2060
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2060
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=37
		Total committed heap usage (bytes)=775946240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:09:04  [ main:1001476 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:09:04  [ main:1001485 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:09:04  [ main:1001490 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:09:04  [ main:1001495 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:09:04  [ main:1001531 ] - [ INFO ]  number of splits:1
2020-11-20 13:09:04  [ main:1001547 ] - [ INFO ]  Submitting tokens for job: job_local1571994614_0094
2020-11-20 13:09:04  [ main:1001581 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:09:04  [ main:1001581 ] - [ INFO ]  Running job: job_local1571994614_0094
2020-11-20 13:09:04  [ Thread-2548:1001581 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:09:04  [ Thread-2548:1001581 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:04  [ Thread-2548:1001581 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:09:04  [ Thread-2548:1001589 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001589 ] - [ INFO ]  Starting task: attempt_local1571994614_0094_m_000000_0
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001589 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001589 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001589 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001590 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001597 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001597 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001597 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001597 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001597 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:09:04  [ LocalJobRunner Map Task Executor #0:1001597 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:09:05  [ main:1002581 ] - [ INFO ]  Job job_local1571994614_0094 running in uber mode : false
2020-11-20 13:09:05  [ main:1002582 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:09:10  [ communication thread:1007598 ] - [ INFO ]  map > map
2020-11-20 13:09:11  [ main:1008597 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:09:13  [ communication thread:1010603 ] - [ INFO ]  map > map
2020-11-20 13:09:13  [ main:1010604 ] - [ INFO ]   map 53% reduce 0%
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011672 ] - [ INFO ]  map > map
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011672 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011672 ] - [ INFO ]  Spilling map output
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011672 ] - [ INFO ]  bufstart = 0; bufend = 2362; bufvoid = 104857600
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011672 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011674 ] - [ INFO ]  Finished spill 0
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011675 ] - [ INFO ]  Task:attempt_local1571994614_0094_m_000000_0 is done. And is in the process of committing
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011711 ] - [ INFO ]  map
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011711 ] - [ INFO ]  Task 'attempt_local1571994614_0094_m_000000_0' done.
2020-11-20 13:09:14  [ LocalJobRunner Map Task Executor #0:1011711 ] - [ INFO ]  Finishing task: attempt_local1571994614_0094_m_000000_0
2020-11-20 13:09:14  [ Thread-2548:1011711 ] - [ INFO ]  map task executor complete.
2020-11-20 13:09:14  [ Thread-2548:1011712 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:09:14  [ pool-285-thread-1:1011712 ] - [ INFO ]  Starting task: attempt_local1571994614_0094_r_000000_0
2020-11-20 13:09:14  [ pool-285-thread-1:1011713 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:14  [ pool-285-thread-1:1011713 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:14  [ pool-285-thread-1:1011713 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:14  [ pool-285-thread-1:1011713 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3cb62acd
2020-11-20 13:09:14  [ pool-285-thread-1:1011714 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:09:14  [ EventFetcher for fetching Map Completion Events:1011715 ] - [ INFO ]  attempt_local1571994614_0094_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:09:14  [ localfetcher#94:1011715 ] - [ INFO ]  localfetcher#94 about to shuffle output of map attempt_local1571994614_0094_m_000000_0 decomp: 2073 len: 2077 to MEMORY
2020-11-20 13:09:14  [ localfetcher#94:1011716 ] - [ INFO ]  Read 2073 bytes from map-output for attempt_local1571994614_0094_m_000000_0
2020-11-20 13:09:14  [ localfetcher#94:1011716 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2073, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2073
2020-11-20 13:09:14  [ EventFetcher for fetching Map Completion Events:1011716 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:09:14  [ pool-285-thread-1:1011716 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:14  [ pool-285-thread-1:1011716 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2066 bytes
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Merged 1 segments, 2073 bytes to disk to satisfy reduce memory limit
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Merging 1 files, 2077 bytes from disk
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2066 bytes
2020-11-20 13:09:14  [ pool-285-thread-1:1011717 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:15  [ pool-285-thread-1:1012039 ] - [ INFO ]  Task:attempt_local1571994614_0094_r_000000_0 is done. And is in the process of committing
2020-11-20 13:09:15  [ pool-285-thread-1:1012052 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:15  [ pool-285-thread-1:1012052 ] - [ INFO ]  Task attempt_local1571994614_0094_r_000000_0 is allowed to commit now
2020-11-20 13:09:15  [ pool-285-thread-1:1012126 ] - [ INFO ]  Saved output of task 'attempt_local1571994614_0094_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1571994614_0094_r_000000
2020-11-20 13:09:15  [ pool-285-thread-1:1012126 ] - [ INFO ]  reduce > reduce
2020-11-20 13:09:15  [ pool-285-thread-1:1012126 ] - [ INFO ]  Task 'attempt_local1571994614_0094_r_000000_0' done.
2020-11-20 13:09:15  [ pool-285-thread-1:1012126 ] - [ INFO ]  Finishing task: attempt_local1571994614_0094_r_000000_0
2020-11-20 13:09:15  [ Thread-2548:1012127 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:09:15  [ main:1012608 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:09:15  [ main:1012609 ] - [ INFO ]  Job job_local1571994614_0094 completed successfully
2020-11-20 13:09:15  [ main:1012610 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=830930
		FILE: Number of bytes written=59359431
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=263511000
		HDFS: Number of bytes written=392088
		HDFS: Number of read operations=2814
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1493
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2362
		Map output materialized bytes=2077
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2077
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=771751936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:09:15  [ main:1012651 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:09:15  [ main:1012681 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:09:15  [ main:1012686 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:09:15  [ main:1012699 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:09:15  [ main:1012746 ] - [ INFO ]  number of splits:1
2020-11-20 13:09:15  [ main:1012762 ] - [ INFO ]  Submitting tokens for job: job_local1818775657_0095
2020-11-20 13:09:15  [ main:1012796 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:09:15  [ main:1012796 ] - [ INFO ]  Running job: job_local1818775657_0095
2020-11-20 13:09:15  [ Thread-2576:1012796 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:09:15  [ Thread-2576:1012797 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:15  [ Thread-2576:1012797 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:09:15  [ Thread-2576:1012817 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012818 ] - [ INFO ]  Starting task: attempt_local1818775657_0095_m_000000_0
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012818 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012818 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012818 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012819 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012831 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012831 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012831 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012832 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012832 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:09:15  [ LocalJobRunner Map Task Executor #0:1012832 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:09:16  [ main:1013797 ] - [ INFO ]  Job job_local1818775657_0095 running in uber mode : false
2020-11-20 13:09:16  [ main:1013797 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:09:21  [ communication thread:1018825 ] - [ INFO ]  map > map
2020-11-20 13:09:22  [ main:1019813 ] - [ INFO ]   map 44% reduce 0%
2020-11-20 13:09:24  [ communication thread:1021830 ] - [ INFO ]  map > map
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022540 ] - [ INFO ]  map > map
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022541 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022541 ] - [ INFO ]  Spilling map output
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022541 ] - [ INFO ]  bufstart = 0; bufend = 2390; bufvoid = 104857600
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022541 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022543 ] - [ INFO ]  Finished spill 0
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022543 ] - [ INFO ]  Task:attempt_local1818775657_0095_m_000000_0 is done. And is in the process of committing
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022555 ] - [ INFO ]  map
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022555 ] - [ INFO ]  Task 'attempt_local1818775657_0095_m_000000_0' done.
2020-11-20 13:09:25  [ LocalJobRunner Map Task Executor #0:1022555 ] - [ INFO ]  Finishing task: attempt_local1818775657_0095_m_000000_0
2020-11-20 13:09:25  [ Thread-2576:1022555 ] - [ INFO ]  map task executor complete.
2020-11-20 13:09:25  [ Thread-2576:1022556 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:09:25  [ pool-288-thread-1:1022556 ] - [ INFO ]  Starting task: attempt_local1818775657_0095_r_000000_0
2020-11-20 13:09:25  [ pool-288-thread-1:1022556 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:25  [ pool-288-thread-1:1022556 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:25  [ pool-288-thread-1:1022556 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:25  [ pool-288-thread-1:1022557 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@435b24bc
2020-11-20 13:09:25  [ pool-288-thread-1:1022558 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:09:25  [ EventFetcher for fetching Map Completion Events:1022558 ] - [ INFO ]  attempt_local1818775657_0095_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:09:25  [ localfetcher#95:1022559 ] - [ INFO ]  localfetcher#95 about to shuffle output of map attempt_local1818775657_0095_m_000000_0 decomp: 2101 len: 2105 to MEMORY
2020-11-20 13:09:25  [ localfetcher#95:1022559 ] - [ INFO ]  Read 2101 bytes from map-output for attempt_local1818775657_0095_m_000000_0
2020-11-20 13:09:25  [ localfetcher#95:1022559 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2101
2020-11-20 13:09:25  [ EventFetcher for fetching Map Completion Events:1022560 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:09:25  [ pool-288-thread-1:1022560 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:25  [ pool-288-thread-1:1022560 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:09:25  [ pool-288-thread-1:1022560 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  Merged 1 segments, 2101 bytes to disk to satisfy reduce memory limit
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  Merging 1 files, 2105 bytes from disk
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2094 bytes
2020-11-20 13:09:25  [ pool-288-thread-1:1022561 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:25  [ pool-288-thread-1:1022760 ] - [ INFO ]  Task:attempt_local1818775657_0095_r_000000_0 is done. And is in the process of committing
2020-11-20 13:09:25  [ pool-288-thread-1:1022770 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:25  [ pool-288-thread-1:1022770 ] - [ INFO ]  Task attempt_local1818775657_0095_r_000000_0 is allowed to commit now
2020-11-20 13:09:25  [ pool-288-thread-1:1022805 ] - [ INFO ]  Saved output of task 'attempt_local1818775657_0095_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1818775657_0095_r_000000
2020-11-20 13:09:25  [ pool-288-thread-1:1022806 ] - [ INFO ]  reduce > reduce
2020-11-20 13:09:25  [ pool-288-thread-1:1022806 ] - [ INFO ]  Task 'attempt_local1818775657_0095_r_000000_0' done.
2020-11-20 13:09:25  [ pool-288-thread-1:1022806 ] - [ INFO ]  Finishing task: attempt_local1818775657_0095_r_000000_0
2020-11-20 13:09:25  [ Thread-2576:1022806 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:09:25  [ main:1022823 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:09:26  [ main:1023825 ] - [ INFO ]  Job job_local1818775657_0095 completed successfully
2020-11-20 13:09:26  [ main:1023827 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=839740
		FILE: Number of bytes written=60007537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=266284800
		HDFS: Number of bytes written=396244
		HDFS: Number of read operations=2844
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1509
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2390
		Map output materialized bytes=2105
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2105
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=978321408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:09:26  [ main:1023918 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:09:26  [ main:1023960 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:09:26  [ main:1023965 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:09:27  [ main:1024014 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:09:27  [ main:1024084 ] - [ INFO ]  number of splits:1
2020-11-20 13:09:27  [ main:1024101 ] - [ INFO ]  Submitting tokens for job: job_local464250808_0096
2020-11-20 13:09:27  [ main:1024135 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:09:27  [ main:1024136 ] - [ INFO ]  Running job: job_local464250808_0096
2020-11-20 13:09:27  [ Thread-2603:1024136 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:09:27  [ Thread-2603:1024136 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:27  [ Thread-2603:1024136 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:09:27  [ Thread-2603:1024152 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024152 ] - [ INFO ]  Starting task: attempt_local464250808_0096_m_000000_0
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024153 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024153 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024153 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024154 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024195 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024195 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024195 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024195 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024195 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:09:27  [ LocalJobRunner Map Task Executor #0:1024195 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:09:28  [ main:1025140 ] - [ INFO ]  Job job_local464250808_0096 running in uber mode : false
2020-11-20 13:09:28  [ main:1025140 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:09:33  [ communication thread:1030158 ] - [ INFO ]  map > map
2020-11-20 13:09:34  [ main:1031154 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:09:36  [ communication thread:1033163 ] - [ INFO ]  map > map
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033682 ] - [ INFO ]  map > map
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033682 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033682 ] - [ INFO ]  Spilling map output
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033682 ] - [ INFO ]  bufstart = 0; bufend = 2412; bufvoid = 104857600
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033682 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033684 ] - [ INFO ]  Finished spill 0
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033685 ] - [ INFO ]  Task:attempt_local464250808_0096_m_000000_0 is done. And is in the process of committing
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033694 ] - [ INFO ]  map
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033694 ] - [ INFO ]  Task 'attempt_local464250808_0096_m_000000_0' done.
2020-11-20 13:09:36  [ LocalJobRunner Map Task Executor #0:1033694 ] - [ INFO ]  Finishing task: attempt_local464250808_0096_m_000000_0
2020-11-20 13:09:36  [ Thread-2603:1033694 ] - [ INFO ]  map task executor complete.
2020-11-20 13:09:36  [ Thread-2603:1033694 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:09:36  [ pool-291-thread-1:1033694 ] - [ INFO ]  Starting task: attempt_local464250808_0096_r_000000_0
2020-11-20 13:09:36  [ pool-291-thread-1:1033695 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:36  [ pool-291-thread-1:1033695 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:36  [ pool-291-thread-1:1033695 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:36  [ pool-291-thread-1:1033695 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5ab02b70
2020-11-20 13:09:36  [ pool-291-thread-1:1033696 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:09:36  [ EventFetcher for fetching Map Completion Events:1033697 ] - [ INFO ]  attempt_local464250808_0096_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:09:36  [ localfetcher#96:1033697 ] - [ INFO ]  localfetcher#96 about to shuffle output of map attempt_local464250808_0096_m_000000_0 decomp: 2123 len: 2127 to MEMORY
2020-11-20 13:09:36  [ localfetcher#96:1033698 ] - [ INFO ]  Read 2123 bytes from map-output for attempt_local464250808_0096_m_000000_0
2020-11-20 13:09:36  [ localfetcher#96:1033698 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2123, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2123
2020-11-20 13:09:36  [ EventFetcher for fetching Map Completion Events:1033698 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:09:36  [ pool-291-thread-1:1033698 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:36  [ pool-291-thread-1:1033698 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:09:36  [ pool-291-thread-1:1033699 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:36  [ pool-291-thread-1:1033699 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2116 bytes
2020-11-20 13:09:36  [ pool-291-thread-1:1033699 ] - [ INFO ]  Merged 1 segments, 2123 bytes to disk to satisfy reduce memory limit
2020-11-20 13:09:36  [ pool-291-thread-1:1033700 ] - [ INFO ]  Merging 1 files, 2127 bytes from disk
2020-11-20 13:09:36  [ pool-291-thread-1:1033700 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:09:36  [ pool-291-thread-1:1033700 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:36  [ pool-291-thread-1:1033700 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2116 bytes
2020-11-20 13:09:36  [ pool-291-thread-1:1033700 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:36  [ pool-291-thread-1:1033801 ] - [ INFO ]  Task:attempt_local464250808_0096_r_000000_0 is done. And is in the process of committing
2020-11-20 13:09:36  [ pool-291-thread-1:1033810 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:36  [ pool-291-thread-1:1033811 ] - [ INFO ]  Task attempt_local464250808_0096_r_000000_0 is allowed to commit now
2020-11-20 13:09:36  [ pool-291-thread-1:1033840 ] - [ INFO ]  Saved output of task 'attempt_local464250808_0096_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local464250808_0096_r_000000
2020-11-20 13:09:36  [ pool-291-thread-1:1033841 ] - [ INFO ]  reduce > reduce
2020-11-20 13:09:36  [ pool-291-thread-1:1033841 ] - [ INFO ]  Task 'attempt_local464250808_0096_r_000000_0' done.
2020-11-20 13:09:36  [ pool-291-thread-1:1033841 ] - [ INFO ]  Finishing task: attempt_local464250808_0096_r_000000_0
2020-11-20 13:09:36  [ Thread-2603:1033841 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:09:37  [ main:1034163 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:09:37  [ main:1034163 ] - [ INFO ]  Job job_local464250808_0096 completed successfully
2020-11-20 13:09:37  [ main:1034165 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=848650
		FILE: Number of bytes written=60653253
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=269058600
		HDFS: Number of bytes written=400450
		HDFS: Number of read operations=2874
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1525
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2412
		Map output materialized bytes=2127
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2127
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=1184890880
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:09:37  [ main:1034194 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:09:37  [ main:1034208 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:09:37  [ main:1034213 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:09:37  [ main:1034222 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:09:37  [ main:1034262 ] - [ INFO ]  number of splits:1
2020-11-20 13:09:37  [ main:1034278 ] - [ INFO ]  Submitting tokens for job: job_local782452397_0097
2020-11-20 13:09:37  [ main:1034314 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:09:37  [ main:1034314 ] - [ INFO ]  Running job: job_local782452397_0097
2020-11-20 13:09:37  [ Thread-2630:1034315 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:09:37  [ Thread-2630:1034315 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:37  [ Thread-2630:1034315 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:09:37  [ Thread-2630:1034331 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034331 ] - [ INFO ]  Starting task: attempt_local782452397_0097_m_000000_0
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034332 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034332 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034332 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034333 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034374 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034374 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034374 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034374 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034374 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:09:37  [ LocalJobRunner Map Task Executor #0:1034374 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:09:38  [ main:1035315 ] - [ INFO ]  Job job_local782452397_0097 running in uber mode : false
2020-11-20 13:09:38  [ main:1035315 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:09:43  [ communication thread:1040336 ] - [ INFO ]  map > map
2020-11-20 13:09:44  [ main:1041329 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:09:46  [ communication thread:1043337 ] - [ INFO ]  map > map
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044198 ] - [ INFO ]  map > map
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044198 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044198 ] - [ INFO ]  Spilling map output
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044198 ] - [ INFO ]  bufstart = 0; bufend = 2391; bufvoid = 104857600
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044198 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044200 ] - [ INFO ]  Finished spill 0
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044201 ] - [ INFO ]  Task:attempt_local782452397_0097_m_000000_0 is done. And is in the process of committing
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044211 ] - [ INFO ]  map
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044211 ] - [ INFO ]  Task 'attempt_local782452397_0097_m_000000_0' done.
2020-11-20 13:09:47  [ LocalJobRunner Map Task Executor #0:1044212 ] - [ INFO ]  Finishing task: attempt_local782452397_0097_m_000000_0
2020-11-20 13:09:47  [ Thread-2630:1044212 ] - [ INFO ]  map task executor complete.
2020-11-20 13:09:47  [ Thread-2630:1044212 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:09:47  [ pool-294-thread-1:1044212 ] - [ INFO ]  Starting task: attempt_local782452397_0097_r_000000_0
2020-11-20 13:09:47  [ pool-294-thread-1:1044213 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:47  [ pool-294-thread-1:1044213 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:47  [ pool-294-thread-1:1044213 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:47  [ pool-294-thread-1:1044213 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20c63313
2020-11-20 13:09:47  [ pool-294-thread-1:1044215 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:09:47  [ EventFetcher for fetching Map Completion Events:1044215 ] - [ INFO ]  attempt_local782452397_0097_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:09:47  [ localfetcher#97:1044216 ] - [ INFO ]  localfetcher#97 about to shuffle output of map attempt_local782452397_0097_m_000000_0 decomp: 2102 len: 2106 to MEMORY
2020-11-20 13:09:47  [ localfetcher#97:1044216 ] - [ INFO ]  Read 2102 bytes from map-output for attempt_local782452397_0097_m_000000_0
2020-11-20 13:09:47  [ localfetcher#97:1044216 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2102
2020-11-20 13:09:47  [ EventFetcher for fetching Map Completion Events:1044216 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:09:47  [ pool-294-thread-1:1044216 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:47  [ pool-294-thread-1:1044217 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:09:47  [ pool-294-thread-1:1044220 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:47  [ pool-294-thread-1:1044220 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2095 bytes
2020-11-20 13:09:47  [ pool-294-thread-1:1044220 ] - [ INFO ]  Merged 1 segments, 2102 bytes to disk to satisfy reduce memory limit
2020-11-20 13:09:47  [ pool-294-thread-1:1044220 ] - [ INFO ]  Merging 1 files, 2106 bytes from disk
2020-11-20 13:09:47  [ pool-294-thread-1:1044220 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:09:47  [ pool-294-thread-1:1044220 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:47  [ pool-294-thread-1:1044221 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2095 bytes
2020-11-20 13:09:47  [ pool-294-thread-1:1044221 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:47  [ main:1044337 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:09:47  [ pool-294-thread-1:1044343 ] - [ INFO ]  Task:attempt_local782452397_0097_r_000000_0 is done. And is in the process of committing
2020-11-20 13:09:47  [ pool-294-thread-1:1044352 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:47  [ pool-294-thread-1:1044352 ] - [ INFO ]  Task attempt_local782452397_0097_r_000000_0 is allowed to commit now
2020-11-20 13:09:47  [ pool-294-thread-1:1044384 ] - [ INFO ]  Saved output of task 'attempt_local782452397_0097_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local782452397_0097_r_000000
2020-11-20 13:09:47  [ pool-294-thread-1:1044384 ] - [ INFO ]  reduce > reduce
2020-11-20 13:09:47  [ pool-294-thread-1:1044384 ] - [ INFO ]  Task 'attempt_local782452397_0097_r_000000_0' done.
2020-11-20 13:09:47  [ pool-294-thread-1:1044384 ] - [ INFO ]  Finishing task: attempt_local782452397_0097_r_000000_0
2020-11-20 13:09:47  [ Thread-2630:1044384 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:09:48  [ main:1045341 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:09:48  [ main:1045341 ] - [ INFO ]  Job job_local782452397_0097 completed successfully
2020-11-20 13:09:48  [ main:1045343 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=857562
		FILE: Number of bytes written=61299676
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=271832400
		HDFS: Number of bytes written=404657
		HDFS: Number of read operations=2904
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1541
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2391
		Map output materialized bytes=2106
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2106
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=1397227520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:09:48  [ main:1045378 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:09:48  [ main:1045393 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:09:48  [ main:1045397 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:09:48  [ main:1045407 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:09:48  [ main:1045448 ] - [ INFO ]  number of splits:1
2020-11-20 13:09:48  [ main:1045464 ] - [ INFO ]  Submitting tokens for job: job_local2015788809_0098
2020-11-20 13:09:48  [ main:1045497 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:09:48  [ main:1045497 ] - [ INFO ]  Running job: job_local2015788809_0098
2020-11-20 13:09:48  [ Thread-2657:1045497 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:09:48  [ Thread-2657:1045497 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:48  [ Thread-2657:1045497 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:09:48  [ Thread-2657:1045510 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045510 ] - [ INFO ]  Starting task: attempt_local2015788809_0098_m_000000_0
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045510 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045511 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045511 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045511 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045554 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045554 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045554 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045554 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045554 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:09:48  [ LocalJobRunner Map Task Executor #0:1045554 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:09:49  [ main:1046498 ] - [ INFO ]  Job job_local2015788809_0098 running in uber mode : false
2020-11-20 13:09:49  [ main:1046498 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:09:54  [ communication thread:1051514 ] - [ INFO ]  map > map
2020-11-20 13:09:55  [ main:1052514 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:09:57  [ communication thread:1054515 ] - [ INFO ]  map > map
2020-11-20 13:09:57  [ main:1054516 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055745 ] - [ INFO ]  map > map
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055745 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055745 ] - [ INFO ]  Spilling map output
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055745 ] - [ INFO ]  bufstart = 0; bufend = 2435; bufvoid = 104857600
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055745 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055747 ] - [ INFO ]  Finished spill 0
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055748 ] - [ INFO ]  Task:attempt_local2015788809_0098_m_000000_0 is done. And is in the process of committing
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055839 ] - [ INFO ]  map
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055839 ] - [ INFO ]  Task 'attempt_local2015788809_0098_m_000000_0' done.
2020-11-20 13:09:58  [ LocalJobRunner Map Task Executor #0:1055839 ] - [ INFO ]  Finishing task: attempt_local2015788809_0098_m_000000_0
2020-11-20 13:09:58  [ Thread-2657:1055839 ] - [ INFO ]  map task executor complete.
2020-11-20 13:09:58  [ Thread-2657:1055840 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:09:58  [ pool-297-thread-1:1055840 ] - [ INFO ]  Starting task: attempt_local2015788809_0098_r_000000_0
2020-11-20 13:09:58  [ pool-297-thread-1:1055841 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:58  [ pool-297-thread-1:1055841 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:58  [ pool-297-thread-1:1055841 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:58  [ pool-297-thread-1:1055841 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b212d99
2020-11-20 13:09:58  [ pool-297-thread-1:1055842 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:09:58  [ EventFetcher for fetching Map Completion Events:1055843 ] - [ INFO ]  attempt_local2015788809_0098_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:09:58  [ localfetcher#98:1055843 ] - [ INFO ]  localfetcher#98 about to shuffle output of map attempt_local2015788809_0098_m_000000_0 decomp: 2146 len: 2150 to MEMORY
2020-11-20 13:09:58  [ localfetcher#98:1055843 ] - [ INFO ]  Read 2146 bytes from map-output for attempt_local2015788809_0098_m_000000_0
2020-11-20 13:09:58  [ localfetcher#98:1055844 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2146, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2146
2020-11-20 13:09:58  [ EventFetcher for fetching Map Completion Events:1055844 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:09:58  [ pool-297-thread-1:1055844 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:58  [ pool-297-thread-1:1055844 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:09:58  [ pool-297-thread-1:1055845 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:58  [ pool-297-thread-1:1055845 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2139 bytes
2020-11-20 13:09:58  [ pool-297-thread-1:1055845 ] - [ INFO ]  Merged 1 segments, 2146 bytes to disk to satisfy reduce memory limit
2020-11-20 13:09:58  [ pool-297-thread-1:1055845 ] - [ INFO ]  Merging 1 files, 2150 bytes from disk
2020-11-20 13:09:58  [ pool-297-thread-1:1055846 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:09:58  [ pool-297-thread-1:1055846 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:09:58  [ pool-297-thread-1:1055846 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2139 bytes
2020-11-20 13:09:58  [ pool-297-thread-1:1055846 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:59  [ pool-297-thread-1:1056045 ] - [ INFO ]  Task:attempt_local2015788809_0098_r_000000_0 is done. And is in the process of committing
2020-11-20 13:09:59  [ pool-297-thread-1:1056079 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:09:59  [ pool-297-thread-1:1056079 ] - [ INFO ]  Task attempt_local2015788809_0098_r_000000_0 is allowed to commit now
2020-11-20 13:09:59  [ pool-297-thread-1:1056157 ] - [ INFO ]  Saved output of task 'attempt_local2015788809_0098_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2015788809_0098_r_000000
2020-11-20 13:09:59  [ pool-297-thread-1:1056158 ] - [ INFO ]  reduce > reduce
2020-11-20 13:09:59  [ pool-297-thread-1:1056158 ] - [ INFO ]  Task 'attempt_local2015788809_0098_r_000000_0' done.
2020-11-20 13:09:59  [ pool-297-thread-1:1056158 ] - [ INFO ]  Finishing task: attempt_local2015788809_0098_r_000000_0
2020-11-20 13:09:59  [ Thread-2657:1056158 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:09:59  [ main:1056524 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:09:59  [ main:1056524 ] - [ INFO ]  Job job_local2015788809_0098 completed successfully
2020-11-20 13:09:59  [ main:1056526 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=866520
		FILE: Number of bytes written=61949350
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274606200
		HDFS: Number of bytes written=408887
		HDFS: Number of read operations=2934
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1557
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2435
		Map output materialized bytes=2150
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2150
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=1606418432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:09:59  [ main:1056584 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:09:59  [ main:1056609 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:09:59  [ main:1056614 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:09:59  [ main:1056624 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:09:59  [ main:1056678 ] - [ INFO ]  number of splits:1
2020-11-20 13:09:59  [ main:1056694 ] - [ INFO ]  Submitting tokens for job: job_local105199871_0099
2020-11-20 13:09:59  [ main:1056727 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:09:59  [ main:1056727 ] - [ INFO ]  Running job: job_local105199871_0099
2020-11-20 13:09:59  [ Thread-2685:1056727 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:09:59  [ Thread-2685:1056727 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:59  [ Thread-2685:1056727 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:09:59  [ Thread-2685:1056757 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056757 ] - [ INFO ]  Starting task: attempt_local105199871_0099_m_000000_0
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056757 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056757 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056757 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056758 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056799 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056799 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056799 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056799 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056799 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:09:59  [ LocalJobRunner Map Task Executor #0:1056799 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:10:00  [ main:1057730 ] - [ INFO ]  Job job_local105199871_0099 running in uber mode : false
2020-11-20 13:10:00  [ main:1057730 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:10:05  [ communication thread:1062763 ] - [ INFO ]  map > map
2020-11-20 13:10:06  [ main:1063744 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:10:08  [ communication thread:1065764 ] - [ INFO ]  map > map
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066555 ] - [ INFO ]  map > map
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066555 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066555 ] - [ INFO ]  Spilling map output
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066555 ] - [ INFO ]  bufstart = 0; bufend = 2434; bufvoid = 104857600
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066555 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066558 ] - [ INFO ]  Finished spill 0
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066559 ] - [ INFO ]  Task:attempt_local105199871_0099_m_000000_0 is done. And is in the process of committing
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066568 ] - [ INFO ]  map
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066568 ] - [ INFO ]  Task 'attempt_local105199871_0099_m_000000_0' done.
2020-11-20 13:10:09  [ LocalJobRunner Map Task Executor #0:1066568 ] - [ INFO ]  Finishing task: attempt_local105199871_0099_m_000000_0
2020-11-20 13:10:09  [ Thread-2685:1066568 ] - [ INFO ]  map task executor complete.
2020-11-20 13:10:09  [ Thread-2685:1066569 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:10:09  [ pool-300-thread-1:1066569 ] - [ INFO ]  Starting task: attempt_local105199871_0099_r_000000_0
2020-11-20 13:10:09  [ pool-300-thread-1:1066570 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:09  [ pool-300-thread-1:1066570 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:10:09  [ pool-300-thread-1:1066570 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:10:09  [ pool-300-thread-1:1066570 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@24ea14d9
2020-11-20 13:10:09  [ pool-300-thread-1:1066571 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:10:09  [ EventFetcher for fetching Map Completion Events:1066571 ] - [ INFO ]  attempt_local105199871_0099_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:10:09  [ localfetcher#99:1066572 ] - [ INFO ]  localfetcher#99 about to shuffle output of map attempt_local105199871_0099_m_000000_0 decomp: 2145 len: 2149 to MEMORY
2020-11-20 13:10:09  [ localfetcher#99:1066572 ] - [ INFO ]  Read 2145 bytes from map-output for attempt_local105199871_0099_m_000000_0
2020-11-20 13:10:09  [ localfetcher#99:1066572 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2145, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2145
2020-11-20 13:10:09  [ EventFetcher for fetching Map Completion Events:1066572 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:10:09  [ pool-300-thread-1:1066573 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:09  [ pool-300-thread-1:1066573 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:10:09  [ pool-300-thread-1:1066573 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:10:09  [ pool-300-thread-1:1066573 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2138 bytes
2020-11-20 13:10:09  [ pool-300-thread-1:1066574 ] - [ INFO ]  Merged 1 segments, 2145 bytes to disk to satisfy reduce memory limit
2020-11-20 13:10:09  [ pool-300-thread-1:1066574 ] - [ INFO ]  Merging 1 files, 2149 bytes from disk
2020-11-20 13:10:09  [ pool-300-thread-1:1066574 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:10:09  [ pool-300-thread-1:1066574 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:10:09  [ pool-300-thread-1:1066574 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2138 bytes
2020-11-20 13:10:09  [ pool-300-thread-1:1066574 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:09  [ main:1066749 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:10:09  [ pool-300-thread-1:1066910 ] - [ INFO ]  Task:attempt_local105199871_0099_r_000000_0 is done. And is in the process of committing
2020-11-20 13:10:09  [ pool-300-thread-1:1066919 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:09  [ pool-300-thread-1:1066919 ] - [ INFO ]  Task attempt_local105199871_0099_r_000000_0 is allowed to commit now
2020-11-20 13:10:09  [ pool-300-thread-1:1066946 ] - [ INFO ]  Saved output of task 'attempt_local105199871_0099_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local105199871_0099_r_000000
2020-11-20 13:10:09  [ pool-300-thread-1:1066947 ] - [ INFO ]  reduce > reduce
2020-11-20 13:10:09  [ pool-300-thread-1:1066947 ] - [ INFO ]  Task 'attempt_local105199871_0099_r_000000_0' done.
2020-11-20 13:10:09  [ pool-300-thread-1:1066947 ] - [ INFO ]  Finishing task: attempt_local105199871_0099_r_000000_0
2020-11-20 13:10:09  [ Thread-2685:1066947 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:10:10  [ main:1067752 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:10:10  [ main:1067752 ] - [ INFO ]  Job job_local105199871_0099 completed successfully
2020-11-20 13:10:10  [ main:1067755 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=875564
		FILE: Number of bytes written=62597137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=277380000
		HDFS: Number of bytes written=413160
		HDFS: Number of read operations=2964
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1573
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2434
		Map output materialized bytes=2149
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2149
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=1810890752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:10:10  [ main:1067785 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:10:10  [ main:1067801 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:10:10  [ main:1067805 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:10:10  [ main:1067814 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:10:10  [ main:1067858 ] - [ INFO ]  number of splits:1
2020-11-20 13:10:10  [ main:1067875 ] - [ INFO ]  Submitting tokens for job: job_local600917755_0100
2020-11-20 13:10:10  [ main:1067909 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:10:10  [ main:1067910 ] - [ INFO ]  Running job: job_local600917755_0100
2020-11-20 13:10:10  [ Thread-2712:1067910 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:10:10  [ Thread-2712:1067910 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:10  [ Thread-2712:1067910 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:10:10  [ Thread-2712:1067920 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067920 ] - [ INFO ]  Starting task: attempt_local600917755_0100_m_000000_0
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067920 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067921 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067921 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067921 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067962 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067962 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067962 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067962 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067962 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:10:10  [ LocalJobRunner Map Task Executor #0:1067963 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:10:11  [ main:1068913 ] - [ INFO ]  Job job_local600917755_0100 running in uber mode : false
2020-11-20 13:10:11  [ main:1068913 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:10:16  [ communication thread:1073929 ] - [ INFO ]  map > map
2020-11-20 13:10:17  [ main:1074929 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:10:19  [ communication thread:1076930 ] - [ INFO ]  map > map
2020-11-20 13:10:19  [ main:1076932 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077664 ] - [ INFO ]  map > map
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077664 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077664 ] - [ INFO ]  Spilling map output
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077664 ] - [ INFO ]  bufstart = 0; bufend = 2402; bufvoid = 104857600
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077664 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077666 ] - [ INFO ]  Finished spill 0
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077667 ] - [ INFO ]  Task:attempt_local600917755_0100_m_000000_0 is done. And is in the process of committing
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077677 ] - [ INFO ]  map
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077677 ] - [ INFO ]  Task 'attempt_local600917755_0100_m_000000_0' done.
2020-11-20 13:10:20  [ LocalJobRunner Map Task Executor #0:1077677 ] - [ INFO ]  Finishing task: attempt_local600917755_0100_m_000000_0
2020-11-20 13:10:20  [ Thread-2712:1077677 ] - [ INFO ]  map task executor complete.
2020-11-20 13:10:20  [ Thread-2712:1077678 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:10:20  [ pool-303-thread-1:1077678 ] - [ INFO ]  Starting task: attempt_local600917755_0100_r_000000_0
2020-11-20 13:10:20  [ pool-303-thread-1:1077679 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:20  [ pool-303-thread-1:1077679 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:10:20  [ pool-303-thread-1:1077679 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:10:20  [ pool-303-thread-1:1077679 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1bdd2c08
2020-11-20 13:10:20  [ pool-303-thread-1:1077681 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:10:20  [ EventFetcher for fetching Map Completion Events:1077681 ] - [ INFO ]  attempt_local600917755_0100_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:10:20  [ localfetcher#100:1077682 ] - [ INFO ]  localfetcher#100 about to shuffle output of map attempt_local600917755_0100_m_000000_0 decomp: 2113 len: 2117 to MEMORY
2020-11-20 13:10:20  [ localfetcher#100:1077682 ] - [ INFO ]  Read 2113 bytes from map-output for attempt_local600917755_0100_m_000000_0
2020-11-20 13:10:20  [ localfetcher#100:1077682 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2113, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2113
2020-11-20 13:10:20  [ EventFetcher for fetching Map Completion Events:1077683 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:10:20  [ pool-303-thread-1:1077683 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:20  [ pool-303-thread-1:1077683 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:10:20  [ pool-303-thread-1:1077684 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:10:20  [ pool-303-thread-1:1077684 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 13:10:20  [ pool-303-thread-1:1077684 ] - [ INFO ]  Merged 1 segments, 2113 bytes to disk to satisfy reduce memory limit
2020-11-20 13:10:20  [ pool-303-thread-1:1077684 ] - [ INFO ]  Merging 1 files, 2117 bytes from disk
2020-11-20 13:10:20  [ pool-303-thread-1:1077684 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:10:20  [ pool-303-thread-1:1077684 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:10:20  [ pool-303-thread-1:1077685 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2106 bytes
2020-11-20 13:10:20  [ pool-303-thread-1:1077685 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:20  [ pool-303-thread-1:1077796 ] - [ INFO ]  Task:attempt_local600917755_0100_r_000000_0 is done. And is in the process of committing
2020-11-20 13:10:20  [ pool-303-thread-1:1077804 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:20  [ pool-303-thread-1:1077805 ] - [ INFO ]  Task attempt_local600917755_0100_r_000000_0 is allowed to commit now
2020-11-20 13:10:20  [ pool-303-thread-1:1077878 ] - [ INFO ]  Saved output of task 'attempt_local600917755_0100_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local600917755_0100_r_000000
2020-11-20 13:10:20  [ pool-303-thread-1:1077879 ] - [ INFO ]  reduce > reduce
2020-11-20 13:10:20  [ pool-303-thread-1:1077879 ] - [ INFO ]  Task 'attempt_local600917755_0100_r_000000_0' done.
2020-11-20 13:10:20  [ pool-303-thread-1:1077879 ] - [ INFO ]  Finishing task: attempt_local600917755_0100_r_000000_0
2020-11-20 13:10:20  [ Thread-2712:1077879 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:10:20  [ main:1077937 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:10:21  [ main:1078941 ] - [ INFO ]  Job job_local600917755_0100 completed successfully
2020-11-20 13:10:21  [ main:1078943 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=884542
		FILE: Number of bytes written=63244903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=280153800
		HDFS: Number of bytes written=417400
		HDFS: Number of read operations=2994
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1589
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2402
		Map output materialized bytes=2117
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2117
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=2006974464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:10:21  [ main:1078974 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:10:21  [ main:1078988 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:10:21  [ main:1078992 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:10:21  [ main:1079000 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:10:22  [ main:1079041 ] - [ INFO ]  number of splits:1
2020-11-20 13:10:22  [ main:1079058 ] - [ INFO ]  Submitting tokens for job: job_local638380870_0101
2020-11-20 13:10:22  [ main:1079090 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:10:22  [ main:1079090 ] - [ INFO ]  Running job: job_local638380870_0101
2020-11-20 13:10:22  [ Thread-2739:1079091 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:10:22  [ Thread-2739:1079091 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:22  [ Thread-2739:1079091 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:10:22  [ Thread-2739:1079101 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079101 ] - [ INFO ]  Starting task: attempt_local638380870_0101_m_000000_0
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079102 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079102 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079102 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079102 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079143 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079143 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079143 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079143 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079143 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:10:22  [ LocalJobRunner Map Task Executor #0:1079143 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:10:23  [ main:1080095 ] - [ INFO ]  Job job_local638380870_0101 running in uber mode : false
2020-11-20 13:10:23  [ main:1080095 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:10:28  [ communication thread:1085105 ] - [ INFO ]  map > map
2020-11-20 13:10:29  [ main:1086104 ] - [ INFO ]   map 41% reduce 0%
2020-11-20 13:10:31  [ communication thread:1088108 ] - [ INFO ]  map > map
2020-11-20 13:10:31  [ main:1088114 ] - [ INFO ]   map 59% reduce 0%
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088485 ] - [ INFO ]  map > map
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088486 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088486 ] - [ INFO ]  Spilling map output
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088486 ] - [ INFO ]  bufstart = 0; bufend = 2417; bufvoid = 104857600
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088486 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088487 ] - [ INFO ]  Finished spill 0
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088488 ] - [ INFO ]  Task:attempt_local638380870_0101_m_000000_0 is done. And is in the process of committing
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088496 ] - [ INFO ]  map
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088497 ] - [ INFO ]  Task 'attempt_local638380870_0101_m_000000_0' done.
2020-11-20 13:10:31  [ LocalJobRunner Map Task Executor #0:1088497 ] - [ INFO ]  Finishing task: attempt_local638380870_0101_m_000000_0
2020-11-20 13:10:31  [ Thread-2739:1088497 ] - [ INFO ]  map task executor complete.
2020-11-20 13:10:31  [ Thread-2739:1088497 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:10:31  [ pool-306-thread-1:1088497 ] - [ INFO ]  Starting task: attempt_local638380870_0101_r_000000_0
2020-11-20 13:10:31  [ pool-306-thread-1:1088498 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:10:31  [ pool-306-thread-1:1088498 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:10:31  [ pool-306-thread-1:1088498 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:10:31  [ pool-306-thread-1:1088498 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@650da275
2020-11-20 13:10:31  [ pool-306-thread-1:1088499 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:10:31  [ EventFetcher for fetching Map Completion Events:1088499 ] - [ INFO ]  attempt_local638380870_0101_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:10:31  [ localfetcher#101:1088500 ] - [ INFO ]  localfetcher#101 about to shuffle output of map attempt_local638380870_0101_m_000000_0 decomp: 2128 len: 2132 to MEMORY
2020-11-20 13:10:31  [ localfetcher#101:1088500 ] - [ INFO ]  Read 2128 bytes from map-output for attempt_local638380870_0101_m_000000_0
2020-11-20 13:10:31  [ localfetcher#101:1088500 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2128, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2128
2020-11-20 13:10:31  [ EventFetcher for fetching Map Completion Events:1088500 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:10:31  [ pool-306-thread-1:1088501 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:31  [ pool-306-thread-1:1088501 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:10:31  [ pool-306-thread-1:1088501 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:10:31  [ pool-306-thread-1:1088501 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2121 bytes
2020-11-20 13:10:31  [ pool-306-thread-1:1088502 ] - [ INFO ]  Merged 1 segments, 2128 bytes to disk to satisfy reduce memory limit
2020-11-20 13:10:31  [ pool-306-thread-1:1088502 ] - [ INFO ]  Merging 1 files, 2132 bytes from disk
2020-11-20 13:10:31  [ pool-306-thread-1:1088502 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:10:31  [ pool-306-thread-1:1088502 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:10:31  [ pool-306-thread-1:1088502 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 2121 bytes
2020-11-20 13:10:31  [ pool-306-thread-1:1088502 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:31  [ pool-306-thread-1:1088622 ] - [ INFO ]  Task:attempt_local638380870_0101_r_000000_0 is done. And is in the process of committing
2020-11-20 13:10:31  [ pool-306-thread-1:1088630 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:10:31  [ pool-306-thread-1:1088630 ] - [ INFO ]  Task attempt_local638380870_0101_r_000000_0 is allowed to commit now
2020-11-20 13:10:31  [ pool-306-thread-1:1088660 ] - [ INFO ]  Saved output of task 'attempt_local638380870_0101_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local638380870_0101_r_000000
2020-11-20 13:10:31  [ pool-306-thread-1:1088661 ] - [ INFO ]  reduce > reduce
2020-11-20 13:10:31  [ pool-306-thread-1:1088661 ] - [ INFO ]  Task 'attempt_local638380870_0101_r_000000_0' done.
2020-11-20 13:10:31  [ pool-306-thread-1:1088661 ] - [ INFO ]  Finishing task: attempt_local638380870_0101_r_000000_0
2020-11-20 13:10:31  [ Thread-2739:1088661 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:10:32  [ main:1089116 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:10:32  [ main:1089116 ] - [ INFO ]  Job job_local638380870_0101 completed successfully
2020-11-20 13:10:32  [ main:1089117 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=893486
		FILE: Number of bytes written=63893710
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=282927600
		HDFS: Number of bytes written=421623
		HDFS: Number of read operations=3024
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1605
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2417
		Map output materialized bytes=2132
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=2132
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=2213543936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:18:42  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:18:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:19:05  [ main:11537 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 13:19:05  [ main:11538 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 13:19:05  [ main:11731 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:19:05  [ main:11736 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:19:05  [ main:11861 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:19:05  [ main:11979 ] - [ INFO ]  number of splits:1
2020-11-20 13:19:05  [ main:12042 ] - [ INFO ]  Submitting tokens for job: job_local1039298369_0001
2020-11-20 13:19:05  [ main:12142 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:19:05  [ main:12143 ] - [ INFO ]  Running job: job_local1039298369_0001
2020-11-20 13:19:05  [ Thread-19:12144 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:19:05  [ Thread-19:12146 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:05  [ Thread-19:12147 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:19:05  [ Thread-19:12194 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:19:05  [ LocalJobRunner Map Task Executor #0:12194 ] - [ INFO ]  Starting task: attempt_local1039298369_0001_m_000000_0
2020-11-20 13:19:05  [ LocalJobRunner Map Task Executor #0:12209 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:05  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:19:05  [ LocalJobRunner Map Task Executor #0:12213 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:19:05  [ LocalJobRunner Map Task Executor #0:12215 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:19:06  [ LocalJobRunner Map Task Executor #0:12263 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:19:06  [ LocalJobRunner Map Task Executor #0:12263 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:19:06  [ LocalJobRunner Map Task Executor #0:12263 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:19:06  [ LocalJobRunner Map Task Executor #0:12263 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:19:06  [ LocalJobRunner Map Task Executor #0:12263 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:19:06  [ LocalJobRunner Map Task Executor #0:12265 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:19:06  [ main:13147 ] - [ INFO ]  Job job_local1039298369_0001 running in uber mode : false
2020-11-20 13:19:06  [ main:13149 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:19:11  [ communication thread:18220 ] - [ INFO ]  map > map
2020-11-20 13:19:12  [ main:19173 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:19:15  [ communication thread:21225 ] - [ INFO ]  map > map
2020-11-20 13:19:15  [ main:22186 ] - [ INFO ]   map 53% reduce 0%
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22963 ] - [ INFO ]  map > map
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22965 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22965 ] - [ INFO ]  Spilling map output
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22965 ] - [ INFO ]  bufstart = 0; bufend = 2401; bufvoid = 104857600
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22965 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22987 ] - [ INFO ]  Finished spill 0
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:22990 ] - [ INFO ]  Task:attempt_local1039298369_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:23043 ] - [ INFO ]  map
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:23043 ] - [ INFO ]  Task 'attempt_local1039298369_0001_m_000000_0' done.
2020-11-20 13:19:16  [ LocalJobRunner Map Task Executor #0:23044 ] - [ INFO ]  Finishing task: attempt_local1039298369_0001_m_000000_0
2020-11-20 13:19:16  [ Thread-19:23044 ] - [ INFO ]  map task executor complete.
2020-11-20 13:19:16  [ Thread-19:23046 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:19:16  [ pool-6-thread-1:23046 ] - [ INFO ]  Starting task: attempt_local1039298369_0001_r_000000_0
2020-11-20 13:19:16  [ pool-6-thread-1:23051 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:16  [ pool-6-thread-1:23052 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:19:16  [ pool-6-thread-1:23052 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:19:16  [ pool-6-thread-1:23054 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2343378b
2020-11-20 13:19:16  [ pool-6-thread-1:23063 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:19:16  [ EventFetcher for fetching Map Completion Events:23065 ] - [ INFO ]  attempt_local1039298369_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:19:16  [ localfetcher#1:23084 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1039298369_0001_m_000000_0 decomp: 223 len: 227 to MEMORY
2020-11-20 13:19:16  [ localfetcher#1:23088 ] - [ INFO ]  Read 223 bytes from map-output for attempt_local1039298369_0001_m_000000_0
2020-11-20 13:19:16  [ localfetcher#1:23089 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 223, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->223
2020-11-20 13:19:16  [ EventFetcher for fetching Map Completion Events:23090 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:19:16  [ pool-6-thread-1:23090 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:19:16  [ pool-6-thread-1:23090 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:19:16  [ pool-6-thread-1:23094 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:19:16  [ pool-6-thread-1:23094 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 217 bytes
2020-11-20 13:19:16  [ pool-6-thread-1:23095 ] - [ INFO ]  Merged 1 segments, 223 bytes to disk to satisfy reduce memory limit
2020-11-20 13:19:16  [ pool-6-thread-1:23095 ] - [ INFO ]  Merging 1 files, 227 bytes from disk
2020-11-20 13:19:16  [ pool-6-thread-1:23095 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:19:16  [ pool-6-thread-1:23095 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:19:16  [ pool-6-thread-1:23095 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 217 bytes
2020-11-20 13:19:16  [ pool-6-thread-1:23096 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:19:16  [ pool-6-thread-1:23137 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 13:19:16  [ main:23189 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:19:17  [ Thread-19:23254 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:19:17  [ Thread-19:23281 ] - [ WARN ]  job_local1039298369_0001
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result1.txt
 for DFSClient_NONMAPREDUCE_826170336_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_826170336_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result1.txt
 for DFSClient_NONMAPREDUCE_826170336_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_826170336_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:19:17  [ main:24193 ] - [ INFO ]  Job job_local1039298369_0001 failed with state FAILED due to: NA
2020-11-20 13:19:17  [ main:24203 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=191
		FILE: Number of bytes written=322614
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2773800
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2401
		Map output materialized bytes=227
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=227
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=354942976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:19:18  [ main:24345 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:19:18  [ main:24412 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:19:18  [ main:24417 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:19:18  [ main:24456 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:19:18  [ main:24542 ] - [ INFO ]  number of splits:1
2020-11-20 13:19:18  [ main:24561 ] - [ INFO ]  Submitting tokens for job: job_local484665760_0002
2020-11-20 13:19:18  [ main:24606 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:19:18  [ main:24606 ] - [ INFO ]  Running job: job_local484665760_0002
2020-11-20 13:19:18  [ Thread-47:24606 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:19:18  [ Thread-47:24607 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:18  [ Thread-47:24607 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:19:18  [ Thread-47:24626 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24626 ] - [ INFO ]  Starting task: attempt_local484665760_0002_m_000000_0
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24627 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24627 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24627 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24628 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24671 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24671 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24671 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24671 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24671 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:19:18  [ LocalJobRunner Map Task Executor #0:24671 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:19:19  [ main:25609 ] - [ INFO ]  Job job_local484665760_0002 running in uber mode : false
2020-11-20 13:19:19  [ main:25610 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:19:22  [ communication thread:29059 ] - [ INFO ]  reduce > reduce
2020-11-20 13:19:24  [ communication thread:30634 ] - [ INFO ]  map > map
2020-11-20 13:19:25  [ main:31630 ] - [ INFO ]   map 37% reduce 0%
2020-11-20 13:19:27  [ communication thread:33640 ] - [ INFO ]  map > map
2020-11-20 13:19:28  [ main:34639 ] - [ INFO ]   map 56% reduce 0%
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34804 ] - [ INFO ]  map > map
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34804 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34804 ] - [ INFO ]  Spilling map output
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34804 ] - [ INFO ]  bufstart = 0; bufend = 2372; bufvoid = 104857600
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34804 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34808 ] - [ INFO ]  Finished spill 0
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:34809 ] - [ INFO ]  Task:attempt_local484665760_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:35094 ] - [ INFO ]  map
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:35094 ] - [ INFO ]  Task 'attempt_local484665760_0002_m_000000_0' done.
2020-11-20 13:19:28  [ LocalJobRunner Map Task Executor #0:35094 ] - [ INFO ]  Finishing task: attempt_local484665760_0002_m_000000_0
2020-11-20 13:19:28  [ Thread-47:35094 ] - [ INFO ]  map task executor complete.
2020-11-20 13:19:28  [ Thread-47:35095 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:19:28  [ pool-9-thread-1:35095 ] - [ INFO ]  Starting task: attempt_local484665760_0002_r_000000_0
2020-11-20 13:19:28  [ pool-9-thread-1:35096 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:28  [ pool-9-thread-1:35097 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:19:28  [ pool-9-thread-1:35097 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:19:28  [ pool-9-thread-1:35097 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@467b80d9
2020-11-20 13:19:28  [ pool-9-thread-1:35098 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:19:28  [ EventFetcher for fetching Map Completion Events:35099 ] - [ INFO ]  attempt_local484665760_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:19:28  [ localfetcher#2:35100 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local484665760_0002_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:19:28  [ localfetcher#2:35100 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local484665760_0002_m_000000_0
2020-11-20 13:19:28  [ localfetcher#2:35100 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:19:28  [ EventFetcher for fetching Map Completion Events:35101 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:19:28  [ pool-9-thread-1:35101 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:19:28  [ pool-9-thread-1:35101 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:19:28  [ pool-9-thread-1:35102 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:19:28  [ pool-9-thread-1:35102 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:19:28  [ pool-9-thread-1:35102 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:19:28  [ pool-9-thread-1:35103 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:19:28  [ pool-9-thread-1:35103 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:19:28  [ pool-9-thread-1:35103 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:19:28  [ pool-9-thread-1:35103 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:19:28  [ pool-9-thread-1:35103 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:19:29  [ Thread-47:35436 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:19:29  [ Thread-47:35453 ] - [ WARN ]  job_local484665760_0002
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result1.txt
 for DFSClient_NONMAPREDUCE_826170336_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_826170336_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/sim_result1.txt
 for DFSClient_NONMAPREDUCE_826170336_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_826170336_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:19:29  [ main:35643 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:19:29  [ main:35643 ] - [ INFO ]  Job job_local484665760_0002 failed with state FAILED due to: NA
2020-11-20 13:19:29  [ main:35647 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=868
		FILE: Number of bytes written=644003
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4160700
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=101
		Map output records=100
		Map output bytes=2372
		Map output materialized bytes=225
		Input split bytes=137
		Combine input records=100
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=225
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=462422016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1386900
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:19:29  [ main:35723 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:19:29  [ main:35734 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:19:29  [ main:35739 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:19:29  [ main:35751 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:19:29  [ main:35791 ] - [ INFO ]  number of splits:1
2020-11-20 13:19:29  [ main:35812 ] - [ INFO ]  Submitting tokens for job: job_local1309622185_0003
2020-11-20 13:19:29  [ main:35852 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:19:29  [ main:35852 ] - [ INFO ]  Running job: job_local1309622185_0003
2020-11-20 13:19:29  [ Thread-72:35852 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:19:29  [ Thread-72:35853 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:29  [ Thread-72:35853 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:19:29  [ Thread-72:35885 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35885 ] - [ INFO ]  Starting task: attempt_local1309622185_0003_m_000000_0
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35886 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35887 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35887 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35888 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/result/score_matrix/part-r-00000:0+1386900
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35927 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35927 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35927 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35927 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35927 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:19:29  [ LocalJobRunner Map Task Executor #0:35928 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:19:30  [ main:36856 ] - [ INFO ]  Job job_local1309622185_0003 running in uber mode : false
2020-11-20 13:19:30  [ main:36856 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:28:12  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:28:13  [ main:598 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 13:28:13  [ main:598 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 13:28:13  [ main:800 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:28:13  [ main:806 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:28:13  [ main:821 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:28:13  [ main:907 ] - [ INFO ]  number of splits:1
2020-11-20 13:28:13  [ main:977 ] - [ INFO ]  Submitting tokens for job: job_local481849223_0001
2020-11-20 13:28:13  [ main:1067 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:28:13  [ main:1068 ] - [ INFO ]  Running job: job_local481849223_0001
2020-11-20 13:28:13  [ Thread-18:1068 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:28:13  [ Thread-18:1071 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:28:13  [ Thread-18:1073 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:28:13  [ Thread-18:1118 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1118 ] - [ INFO ]  Starting task: attempt_local481849223_0001_m_000000_0
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1134 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1138 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1138 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1140 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/test.txt:0+90316
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1190 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1190 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1190 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1190 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1190 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1193 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1316 ] - [ INFO ]  
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1318 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1318 ] - [ INFO ]  Spilling map output
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1318 ] - [ INFO ]  bufstart = 0; bufend = 13373; bufvoid = 104857600
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1318 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26194980(104779920); length = 19417/6553600
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1339 ] - [ INFO ]  Finished spill 0
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1342 ] - [ INFO ]  Task:attempt_local481849223_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1356 ] - [ INFO ]  map
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1357 ] - [ INFO ]  Task 'attempt_local481849223_0001_m_000000_0' done.
2020-11-20 13:28:13  [ LocalJobRunner Map Task Executor #0:1357 ] - [ INFO ]  Finishing task: attempt_local481849223_0001_m_000000_0
2020-11-20 13:28:13  [ Thread-18:1357 ] - [ INFO ]  map task executor complete.
2020-11-20 13:28:13  [ Thread-18:1359 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:28:13  [ pool-6-thread-1:1359 ] - [ INFO ]  Starting task: attempt_local481849223_0001_r_000000_0
2020-11-20 13:28:13  [ pool-6-thread-1:1364 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:28:13  [ pool-6-thread-1:1365 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:28:13  [ pool-6-thread-1:1365 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:28:13  [ pool-6-thread-1:1367 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17c2decc
2020-11-20 13:28:13  [ pool-6-thread-1:1377 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:28:13  [ EventFetcher for fetching Map Completion Events:1379 ] - [ INFO ]  attempt_local481849223_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:28:13  [ localfetcher#1:1400 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local481849223_0001_m_000000_0 decomp: 248 len: 252 to MEMORY
2020-11-20 13:28:14  [ localfetcher#1:1404 ] - [ INFO ]  Read 248 bytes from map-output for attempt_local481849223_0001_m_000000_0
2020-11-20 13:28:14  [ localfetcher#1:1405 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 248, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->248
2020-11-20 13:28:14  [ EventFetcher for fetching Map Completion Events:1406 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:28:14  [ pool-6-thread-1:1406 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:28:14  [ pool-6-thread-1:1406 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:28:14  [ pool-6-thread-1:1412 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:28:14  [ pool-6-thread-1:1412 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 244 bytes
2020-11-20 13:28:14  [ pool-6-thread-1:1413 ] - [ INFO ]  Merged 1 segments, 248 bytes to disk to satisfy reduce memory limit
2020-11-20 13:28:14  [ pool-6-thread-1:1413 ] - [ INFO ]  Merging 1 files, 252 bytes from disk
2020-11-20 13:28:14  [ pool-6-thread-1:1413 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:28:14  [ pool-6-thread-1:1414 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:28:14  [ pool-6-thread-1:1414 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 244 bytes
2020-11-20 13:28:14  [ pool-6-thread-1:1414 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:28:14  [ pool-6-thread-1:1437 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 13:28:14  [ pool-6-thread-1:1528 ] - [ INFO ]  Task:attempt_local481849223_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 13:28:14  [ pool-6-thread-1:1537 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:28:14  [ pool-6-thread-1:1537 ] - [ INFO ]  Task attempt_local481849223_0001_r_000000_0 is allowed to commit now
2020-11-20 13:28:14  [ pool-6-thread-1:1564 ] - [ INFO ]  Saved output of task 'attempt_local481849223_0001_r_000000_0' to hdfs://master:9000/tmp2147483647/output1605850092160/_temporary/0/task_local481849223_0001_r_000000
2020-11-20 13:28:14  [ pool-6-thread-1:1565 ] - [ INFO ]  reduce > reduce
2020-11-20 13:28:14  [ pool-6-thread-1:1565 ] - [ INFO ]  Task 'attempt_local481849223_0001_r_000000_0' done.
2020-11-20 13:28:14  [ pool-6-thread-1:1565 ] - [ INFO ]  Finishing task: attempt_local481849223_0001_r_000000_0
2020-11-20 13:28:14  [ Thread-18:1565 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:28:14  [ main:2071 ] - [ INFO ]  Job job_local481849223_0001 running in uber mode : false
2020-11-20 13:28:14  [ main:2073 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:28:14  [ main:2074 ] - [ INFO ]  Job job_local481849223_0001 completed successfully
2020-11-20 13:28:14  [ main:2082 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=880
		FILE: Number of bytes written=567548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=180632
		HDFS: Number of bytes written=144
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=4855
		Map output records=4855
		Map output bytes=13373
		Map output materialized bytes=252
		Input split bytes=118
		Combine input records=4855
		Combine output records=51
		Reduce input groups=51
		Reduce shuffle bytes=252
		Reduce input records=51
		Reduce output records=51
		Spilled Records=102
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=90316
	File Output Format Counters 
		Bytes Written=144
2020-11-20 13:28:14  [ main:2197 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:28:14  [ main:2212 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:28:14  [ main:2217 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:28:14  [ main:2225 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:28:14  [ main:2266 ] - [ INFO ]  number of splits:1
2020-11-20 13:28:14  [ main:2286 ] - [ INFO ]  Submitting tokens for job: job_local1319235877_0002
2020-11-20 13:28:14  [ main:2330 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:28:14  [ main:2330 ] - [ INFO ]  Running job: job_local1319235877_0002
2020-11-20 13:28:14  [ Thread-48:2330 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:28:14  [ Thread-48:2330 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:28:14  [ Thread-48:2331 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:28:14  [ Thread-48:2341 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2342 ] - [ INFO ]  Starting task: attempt_local1319235877_0002_m_000000_0
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2342 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2342 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2342 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2343 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/test.txt:0+90316
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2386 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:28:14  [ LocalJobRunner Map Task Executor #0:2387 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2614 ] - [ INFO ]  
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2614 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2614 ] - [ INFO ]  Spilling map output
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2614 ] - [ INFO ]  bufstart = 0; bufend = 18684; bufvoid = 104857600
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2615 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26194980(104779920); length = 19417/6553600
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2629 ] - [ INFO ]  Finished spill 0
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2631 ] - [ INFO ]  Task:attempt_local1319235877_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2640 ] - [ INFO ]  map
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2641 ] - [ INFO ]  Task 'attempt_local1319235877_0002_m_000000_0' done.
2020-11-20 13:28:15  [ LocalJobRunner Map Task Executor #0:2641 ] - [ INFO ]  Finishing task: attempt_local1319235877_0002_m_000000_0
2020-11-20 13:28:15  [ Thread-48:2641 ] - [ INFO ]  map task executor complete.
2020-11-20 13:28:15  [ Thread-48:2641 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:28:15  [ pool-9-thread-1:2641 ] - [ INFO ]  Starting task: attempt_local1319235877_0002_r_000000_0
2020-11-20 13:28:15  [ pool-9-thread-1:2642 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:28:15  [ pool-9-thread-1:2643 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:28:15  [ pool-9-thread-1:2643 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:28:15  [ pool-9-thread-1:2643 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fe00676
2020-11-20 13:28:15  [ pool-9-thread-1:2644 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:28:15  [ EventFetcher for fetching Map Completion Events:2644 ] - [ INFO ]  attempt_local1319235877_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:28:15  [ localfetcher#2:2645 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1319235877_0002_m_000000_0 decomp: 6411 len: 6415 to MEMORY
2020-11-20 13:28:15  [ localfetcher#2:2645 ] - [ INFO ]  Read 6411 bytes from map-output for attempt_local1319235877_0002_m_000000_0
2020-11-20 13:28:15  [ localfetcher#2:2645 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 6411, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6411
2020-11-20 13:28:15  [ EventFetcher for fetching Map Completion Events:2646 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:28:15  [ pool-9-thread-1:2646 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:28:15  [ pool-9-thread-1:2646 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:28:15  [ pool-9-thread-1:2647 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:28:15  [ pool-9-thread-1:2647 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 6407 bytes
2020-11-20 13:28:15  [ pool-9-thread-1:2651 ] - [ INFO ]  Merged 1 segments, 6411 bytes to disk to satisfy reduce memory limit
2020-11-20 13:28:15  [ pool-9-thread-1:2651 ] - [ INFO ]  Merging 1 files, 6415 bytes from disk
2020-11-20 13:28:15  [ pool-9-thread-1:2651 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:28:15  [ pool-9-thread-1:2651 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:28:15  [ pool-9-thread-1:2652 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 6407 bytes
2020-11-20 13:28:15  [ pool-9-thread-1:2652 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:28:15  [ pool-9-thread-1:2718 ] - [ INFO ]  Task:attempt_local1319235877_0002_r_000000_0 is done. And is in the process of committing
2020-11-20 13:28:15  [ pool-9-thread-1:2735 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:28:15  [ pool-9-thread-1:2735 ] - [ INFO ]  Task attempt_local1319235877_0002_r_000000_0 is allowed to commit now
2020-11-20 13:28:15  [ pool-9-thread-1:2767 ] - [ INFO ]  Saved output of task 'attempt_local1319235877_0002_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/data/result/item/_temporary/0/task_local1319235877_0002_r_000000
2020-11-20 13:28:15  [ pool-9-thread-1:2767 ] - [ INFO ]  reduce > reduce
2020-11-20 13:28:15  [ pool-9-thread-1:2767 ] - [ INFO ]  Task 'attempt_local1319235877_0002_r_000000_0' done.
2020-11-20 13:28:15  [ pool-9-thread-1:2767 ] - [ INFO ]  Finishing task: attempt_local1319235877_0002_r_000000_0
2020-11-20 13:28:15  [ Thread-48:2767 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:28:15  [ main:3333 ] - [ INFO ]  Job job_local1319235877_0002 running in uber mode : false
2020-11-20 13:28:15  [ main:3333 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:28:15  [ main:3334 ] - [ INFO ]  Job job_local1319235877_0002 completed successfully
2020-11-20 13:28:15  [ main:3336 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=14622
		FILE: Number of bytes written=1156893
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=361552
		HDFS: Number of bytes written=4839
		HDFS: Number of read operations=55
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=4855
		Map output records=4855
		Map output bytes=18684
		Map output materialized bytes=6415
		Input split bytes=118
		Combine input records=4855
		Combine output records=1073
		Reduce input groups=1073
		Reduce shuffle bytes=6415
		Reduce input records=1073
		Reduce output records=1073
		Spilled Records=2146
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=90316
	File Output Format Counters 
		Bytes Written=4263
2020-11-20 13:29:47  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:29:48  [ main:576 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 13:29:48  [ main:576 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 13:29:48  [ main:778 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:29:48  [ main:784 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:29:48  [ main:807 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:29:48  [ main:894 ] - [ INFO ]  number of splits:1
2020-11-20 13:29:48  [ main:956 ] - [ INFO ]  Submitting tokens for job: job_local1206094169_0001
2020-11-20 13:29:48  [ main:1044 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:29:48  [ main:1044 ] - [ INFO ]  Running job: job_local1206094169_0001
2020-11-20 13:29:48  [ Thread-18:1044 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:29:48  [ Thread-18:1048 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:29:48  [ Thread-18:1049 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:29:49  [ Thread-18:1308 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1308 ] - [ INFO ]  Starting task: attempt_local1206094169_0001_m_000000_0
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1323 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1327 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1328 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1330 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/test.txt:0+90316
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1381 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1383 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1804 ] - [ INFO ]  
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1805 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1805 ] - [ INFO ]  Spilling map output
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1806 ] - [ INFO ]  bufstart = 0; bufend = 47814; bufvoid = 104857600
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1806 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26194980(104779920); length = 19417/6553600
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1845 ] - [ INFO ]  Finished spill 0
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1848 ] - [ INFO ]  Task:attempt_local1206094169_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1863 ] - [ INFO ]  map
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1863 ] - [ INFO ]  Task 'attempt_local1206094169_0001_m_000000_0' done.
2020-11-20 13:29:49  [ LocalJobRunner Map Task Executor #0:1863 ] - [ INFO ]  Finishing task: attempt_local1206094169_0001_m_000000_0
2020-11-20 13:29:49  [ Thread-18:1864 ] - [ INFO ]  map task executor complete.
2020-11-20 13:29:49  [ Thread-18:1865 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:29:49  [ pool-6-thread-1:1865 ] - [ INFO ]  Starting task: attempt_local1206094169_0001_r_000000_0
2020-11-20 13:29:49  [ pool-6-thread-1:1869 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:29:49  [ pool-6-thread-1:1869 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:29:49  [ pool-6-thread-1:1869 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:29:49  [ pool-6-thread-1:1870 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2bc33068
2020-11-20 13:29:49  [ pool-6-thread-1:1878 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:29:49  [ EventFetcher for fetching Map Completion Events:1879 ] - [ INFO ]  attempt_local1206094169_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:29:49  [ localfetcher#1:1896 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1206094169_0001_m_000000_0 decomp: 527129 len: 527133 to MEMORY
2020-11-20 13:29:49  [ localfetcher#1:1900 ] - [ INFO ]  Read 527129 bytes from map-output for attempt_local1206094169_0001_m_000000_0
2020-11-20 13:29:49  [ localfetcher#1:1901 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 527129, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->527129
2020-11-20 13:29:49  [ EventFetcher for fetching Map Completion Events:1902 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:29:49  [ pool-6-thread-1:1903 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:29:49  [ pool-6-thread-1:1903 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:29:49  [ pool-6-thread-1:1907 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:29:49  [ pool-6-thread-1:1907 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 527121 bytes
2020-11-20 13:29:49  [ pool-6-thread-1:1910 ] - [ INFO ]  Merged 1 segments, 527129 bytes to disk to satisfy reduce memory limit
2020-11-20 13:29:49  [ pool-6-thread-1:1910 ] - [ INFO ]  Merging 1 files, 527133 bytes from disk
2020-11-20 13:29:49  [ pool-6-thread-1:1910 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:29:49  [ pool-6-thread-1:1910 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:29:49  [ pool-6-thread-1:1911 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 527121 bytes
2020-11-20 13:29:49  [ pool-6-thread-1:1911 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:29:49  [ pool-6-thread-1:1932 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 13:29:49  [ main:2048 ] - [ INFO ]  Job job_local1206094169_0001 running in uber mode : false
2020-11-20 13:29:49  [ main:2049 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:29:50  [ pool-6-thread-1:2119 ] - [ INFO ]  Task:attempt_local1206094169_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 13:29:50  [ pool-6-thread-1:2129 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:29:50  [ pool-6-thread-1:2129 ] - [ INFO ]  Task attempt_local1206094169_0001_r_000000_0 is allowed to commit now
2020-11-20 13:29:50  [ pool-6-thread-1:2159 ] - [ INFO ]  Saved output of task 'attempt_local1206094169_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/_temporary/0/task_local1206094169_0001_r_000000
2020-11-20 13:29:50  [ pool-6-thread-1:2160 ] - [ INFO ]  reduce > reduce
2020-11-20 13:29:50  [ pool-6-thread-1:2160 ] - [ INFO ]  Task 'attempt_local1206094169_0001_r_000000_0' done.
2020-11-20 13:29:50  [ pool-6-thread-1:2160 ] - [ INFO ]  Finishing task: attempt_local1206094169_0001_r_000000_0
2020-11-20 13:29:50  [ Thread-18:2160 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:29:51  [ main:3051 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:29:51  [ main:3052 ] - [ INFO ]  Job job_local1206094169_0001 completed successfully
2020-11-20 13:29:51  [ main:3062 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1054642
		FILE: Number of bytes written=2151579
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=180632
		HDFS: Number of bytes written=526761
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=4855
		Map output records=4855
		Map output bytes=47814
		Map output materialized bytes=527133
		Input split bytes=118
		Combine input records=4855
		Combine output records=51
		Reduce input groups=51
		Reduce shuffle bytes=527133
		Reduce input records=51
		Reduce output records=51
		Spilled Records=102
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=631242752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=90316
	File Output Format Counters 
		Bytes Written=526761
2020-11-20 13:29:59  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:30:28  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:30:32  [ main:3787 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 13:30:32  [ main:3787 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 13:30:32  [ main:3949 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:30:32  [ main:3953 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:30:32  [ main:3967 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:30:32  [ main:4024 ] - [ INFO ]  number of splits:1
2020-11-20 13:30:32  [ main:4087 ] - [ INFO ]  Submitting tokens for job: job_local238171688_0001
2020-11-20 13:30:32  [ main:4175 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:30:32  [ main:4175 ] - [ INFO ]  Running job: job_local238171688_0001
2020-11-20 13:30:32  [ Thread-18:4176 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:30:32  [ Thread-18:4180 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:32  [ Thread-18:4181 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:30:32  [ Thread-18:4224 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4224 ] - [ INFO ]  Starting task: attempt_local238171688_0001_m_000000_0
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4238 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4242 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4243 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4245 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4295 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4295 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4295 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4295 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4295 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:30:32  [ LocalJobRunner Map Task Executor #0:4297 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:30:33  [ main:5181 ] - [ INFO ]  Job job_local238171688_0001 running in uber mode : false
2020-11-20 13:30:33  [ main:5183 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7729 ] - [ INFO ]  
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  Spilling map output
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  bufstart = 0; bufend = 1209; bufvoid = 104857600
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7731 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7750 ] - [ INFO ]  Finished spill 0
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7752 ] - [ INFO ]  Task:attempt_local238171688_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7765 ] - [ INFO ]  map
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7765 ] - [ INFO ]  Task 'attempt_local238171688_0001_m_000000_0' done.
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:7765 ] - [ INFO ]  Finishing task: attempt_local238171688_0001_m_000000_0
2020-11-20 13:30:36  [ Thread-18:7766 ] - [ INFO ]  map task executor complete.
2020-11-20 13:30:36  [ Thread-18:7767 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:30:36  [ pool-6-thread-1:7767 ] - [ INFO ]  Starting task: attempt_local238171688_0001_r_000000_0
2020-11-20 13:30:36  [ pool-6-thread-1:7771 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:36  [ pool-6-thread-1:7771 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:36  [ pool-6-thread-1:7771 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:36  [ pool-6-thread-1:7773 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a0ae00d
2020-11-20 13:30:36  [ pool-6-thread-1:7781 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:30:36  [ EventFetcher for fetching Map Completion Events:7782 ] - [ INFO ]  attempt_local238171688_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:30:36  [ localfetcher#1:7800 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local238171688_0001_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:30:36  [ localfetcher#1:7804 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local238171688_0001_m_000000_0
2020-11-20 13:30:36  [ localfetcher#1:7805 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:30:36  [ EventFetcher for fetching Map Completion Events:7806 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:30:36  [ pool-6-thread-1:7806 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:36  [ pool-6-thread-1:7806 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:30:36  [ pool-6-thread-1:7810 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:36  [ pool-6-thread-1:7810 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:30:36  [ pool-6-thread-1:7811 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:30:36  [ pool-6-thread-1:7811 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:30:36  [ pool-6-thread-1:7811 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:30:36  [ pool-6-thread-1:7811 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:36  [ pool-6-thread-1:7812 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:30:36  [ pool-6-thread-1:7812 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:36  [ pool-6-thread-1:7835 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 13:30:36  [ Thread-18:7882 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:30:36  [ Thread-18:7893 ] - [ WARN ]  job_local238171688_0001
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:30:36  [ main:8191 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:30:36  [ main:8192 ] - [ INFO ]  Job job_local238171688_0001 failed with state FAILED due to: NA
2020-11-20 13:30:36  [ main:8202 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=189
		FILE: Number of bytes written=312232
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1053522
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1209
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=221
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=317194240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:30:36  [ main:8232 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:30:36  [ main:8247 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:30:36  [ main:8252 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:30:36  [ main:8261 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:30:36  [ main:8303 ] - [ INFO ]  number of splits:1
2020-11-20 13:30:36  [ main:8323 ] - [ INFO ]  Submitting tokens for job: job_local1932488439_0002
2020-11-20 13:30:36  [ main:8376 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:30:36  [ main:8376 ] - [ INFO ]  Running job: job_local1932488439_0002
2020-11-20 13:30:36  [ Thread-45:8377 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:30:36  [ Thread-45:8377 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:36  [ Thread-45:8377 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:30:36  [ Thread-45:8388 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8388 ] - [ INFO ]  Starting task: attempt_local1932488439_0002_m_000000_0
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8389 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8390 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8390 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8391 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8407 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8408 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8408 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8408 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8408 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:30:36  [ LocalJobRunner Map Task Executor #0:8408 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:30:37  [ main:9378 ] - [ INFO ]  Job job_local1932488439_0002 running in uber mode : false
2020-11-20 13:30:37  [ main:9378 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11712 ] - [ INFO ]  
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11712 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11712 ] - [ INFO ]  Spilling map output
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11712 ] - [ INFO ]  bufstart = 0; bufend = 1198; bufvoid = 104857600
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11712 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11715 ] - [ INFO ]  Finished spill 0
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11716 ] - [ INFO ]  Task:attempt_local1932488439_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11726 ] - [ INFO ]  map
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11726 ] - [ INFO ]  Task 'attempt_local1932488439_0002_m_000000_0' done.
2020-11-20 13:30:40  [ LocalJobRunner Map Task Executor #0:11726 ] - [ INFO ]  Finishing task: attempt_local1932488439_0002_m_000000_0
2020-11-20 13:30:40  [ Thread-45:11726 ] - [ INFO ]  map task executor complete.
2020-11-20 13:30:40  [ Thread-45:11727 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:30:40  [ pool-9-thread-1:11727 ] - [ INFO ]  Starting task: attempt_local1932488439_0002_r_000000_0
2020-11-20 13:30:40  [ pool-9-thread-1:11728 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:40  [ pool-9-thread-1:11728 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:40  [ pool-9-thread-1:11728 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:40  [ pool-9-thread-1:11728 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@509c3b4a
2020-11-20 13:30:40  [ pool-9-thread-1:11729 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:30:40  [ EventFetcher for fetching Map Completion Events:11730 ] - [ INFO ]  attempt_local1932488439_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:30:40  [ localfetcher#2:11730 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local1932488439_0002_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:30:40  [ localfetcher#2:11731 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local1932488439_0002_m_000000_0
2020-11-20 13:30:40  [ localfetcher#2:11731 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:30:40  [ EventFetcher for fetching Map Completion Events:11731 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:30:40  [ pool-9-thread-1:11731 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:40  [ pool-9-thread-1:11731 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:30:40  [ pool-9-thread-1:11732 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:40  [ pool-9-thread-1:11732 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:30:40  [ pool-9-thread-1:11733 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:30:40  [ pool-9-thread-1:11733 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:30:40  [ pool-9-thread-1:11733 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:30:40  [ pool-9-thread-1:11733 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:40  [ pool-9-thread-1:11733 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:30:40  [ pool-9-thread-1:11734 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:40  [ Thread-45:11786 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:30:40  [ Thread-45:11796 ] - [ WARN ]  job_local1932488439_0002
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:30:40  [ main:12387 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:30:40  [ main:12387 ] - [ INFO ]  Job job_local1932488439_0002 failed with state FAILED due to: NA
2020-11-20 13:30:40  [ main:12391 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=852
		FILE: Number of bytes written=626359
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1580283
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1198
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=219
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=93
		Total committed heap usage (bytes)=517996544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:30:40  [ main:12419 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:30:40  [ main:12436 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:30:40  [ main:12441 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:30:40  [ main:12450 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:30:40  [ main:12491 ] - [ INFO ]  number of splits:1
2020-11-20 13:30:40  [ main:12512 ] - [ INFO ]  Submitting tokens for job: job_local1733893181_0003
2020-11-20 13:30:41  [ main:12553 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:30:41  [ main:12553 ] - [ INFO ]  Running job: job_local1733893181_0003
2020-11-20 13:30:41  [ Thread-69:12553 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:30:41  [ Thread-69:12554 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:41  [ Thread-69:12554 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:30:41  [ Thread-69:12565 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12565 ] - [ INFO ]  Starting task: attempt_local1733893181_0003_m_000000_0
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12566 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12566 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12566 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12567 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12576 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12576 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12576 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12576 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12576 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:30:41  [ LocalJobRunner Map Task Executor #0:12576 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:30:42  [ main:13556 ] - [ INFO ]  Job job_local1733893181_0003 running in uber mode : false
2020-11-20 13:30:42  [ main:13556 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:30:42  [ communication thread:13779 ] - [ INFO ]  reduce > reduce
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15788 ] - [ INFO ]  
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15788 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15788 ] - [ INFO ]  Spilling map output
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15788 ] - [ INFO ]  bufstart = 0; bufend = 1196; bufvoid = 104857600
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15788 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15791 ] - [ INFO ]  Finished spill 0
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15792 ] - [ INFO ]  Task:attempt_local1733893181_0003_m_000000_0 is done. And is in the process of committing
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15802 ] - [ INFO ]  map
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15802 ] - [ INFO ]  Task 'attempt_local1733893181_0003_m_000000_0' done.
2020-11-20 13:30:44  [ LocalJobRunner Map Task Executor #0:15802 ] - [ INFO ]  Finishing task: attempt_local1733893181_0003_m_000000_0
2020-11-20 13:30:44  [ Thread-69:15802 ] - [ INFO ]  map task executor complete.
2020-11-20 13:30:44  [ Thread-69:15802 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:30:44  [ pool-12-thread-1:15802 ] - [ INFO ]  Starting task: attempt_local1733893181_0003_r_000000_0
2020-11-20 13:30:44  [ pool-12-thread-1:15803 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:44  [ pool-12-thread-1:15803 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:44  [ pool-12-thread-1:15803 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:44  [ pool-12-thread-1:15803 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a0811af
2020-11-20 13:30:44  [ pool-12-thread-1:15804 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:30:44  [ EventFetcher for fetching Map Completion Events:15804 ] - [ INFO ]  attempt_local1733893181_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:30:44  [ localfetcher#3:15805 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local1733893181_0003_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:30:44  [ localfetcher#3:15805 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local1733893181_0003_m_000000_0
2020-11-20 13:30:44  [ localfetcher#3:15805 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:30:44  [ EventFetcher for fetching Map Completion Events:15806 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:30:44  [ pool-12-thread-1:15806 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:44  [ pool-12-thread-1:15806 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:30:44  [ pool-12-thread-1:15807 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:44  [ pool-12-thread-1:15807 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:30:44  [ pool-12-thread-1:15807 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:30:44  [ pool-12-thread-1:15807 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:30:44  [ pool-12-thread-1:15807 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:30:44  [ pool-12-thread-1:15807 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:44  [ pool-12-thread-1:15808 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:30:44  [ pool-12-thread-1:15808 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:44  [ Thread-69:15846 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:30:44  [ Thread-69:15857 ] - [ WARN ]  job_local1733893181_0003
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:30:45  [ main:16564 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:30:45  [ main:16565 ] - [ INFO ]  Job job_local1733893181_0003 failed with state FAILED due to: NA
2020-11-20 13:30:45  [ main:16567 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1511
		FILE: Number of bytes written=940520
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2107044
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=26
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=13
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1196
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=219
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=517996544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:30:45  [ main:16596 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:30:45  [ main:16610 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:30:45  [ main:16614 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:30:45  [ main:16623 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:30:45  [ main:16664 ] - [ INFO ]  number of splits:1
2020-11-20 13:30:45  [ main:16683 ] - [ INFO ]  Submitting tokens for job: job_local1738170858_0004
2020-11-20 13:30:45  [ main:16727 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:30:45  [ main:16727 ] - [ INFO ]  Running job: job_local1738170858_0004
2020-11-20 13:30:45  [ Thread-93:16727 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:30:45  [ Thread-93:16727 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:45  [ Thread-93:16728 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:30:45  [ Thread-93:16740 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16740 ] - [ INFO ]  Starting task: attempt_local1738170858_0004_m_000000_0
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16741 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16741 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16741 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16742 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16751 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16751 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16751 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16751 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16751 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:30:45  [ LocalJobRunner Map Task Executor #0:16751 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:30:46  [ main:17732 ] - [ INFO ]  Job job_local1738170858_0004 running in uber mode : false
2020-11-20 13:30:46  [ main:17732 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:30:46  [ communication thread:17733 ] - [ INFO ]  reduce > reduce
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19742 ] - [ INFO ]  
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19742 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19742 ] - [ INFO ]  Spilling map output
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19742 ] - [ INFO ]  bufstart = 0; bufend = 1217; bufvoid = 104857600
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19742 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19745 ] - [ INFO ]  Finished spill 0
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19746 ] - [ INFO ]  Task:attempt_local1738170858_0004_m_000000_0 is done. And is in the process of committing
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19755 ] - [ INFO ]  map
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19755 ] - [ INFO ]  Task 'attempt_local1738170858_0004_m_000000_0' done.
2020-11-20 13:30:48  [ LocalJobRunner Map Task Executor #0:19755 ] - [ INFO ]  Finishing task: attempt_local1738170858_0004_m_000000_0
2020-11-20 13:30:48  [ Thread-93:19755 ] - [ INFO ]  map task executor complete.
2020-11-20 13:30:48  [ Thread-93:19756 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:30:48  [ pool-15-thread-1:19756 ] - [ INFO ]  Starting task: attempt_local1738170858_0004_r_000000_0
2020-11-20 13:30:48  [ pool-15-thread-1:19757 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:48  [ pool-15-thread-1:19757 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:48  [ pool-15-thread-1:19757 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:48  [ pool-15-thread-1:19757 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66c30360
2020-11-20 13:30:48  [ pool-15-thread-1:19758 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:30:48  [ EventFetcher for fetching Map Completion Events:19758 ] - [ INFO ]  attempt_local1738170858_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:30:48  [ localfetcher#4:19759 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local1738170858_0004_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:30:48  [ localfetcher#4:19759 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local1738170858_0004_m_000000_0
2020-11-20 13:30:48  [ localfetcher#4:19759 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:30:48  [ EventFetcher for fetching Map Completion Events:19759 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:30:48  [ pool-15-thread-1:19760 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:48  [ pool-15-thread-1:19760 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:30:48  [ pool-15-thread-1:19760 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:30:48  [ pool-15-thread-1:19761 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:48  [ Thread-93:19799 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:30:48  [ Thread-93:19810 ] - [ WARN ]  job_local1738170858_0004
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:30:49  [ main:20741 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:30:49  [ main:20741 ] - [ INFO ]  Job job_local1738170858_0004 failed with state FAILED due to: NA
2020-11-20 13:30:49  [ main:20745 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2170
		FILE: Number of bytes written=1254721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2633805
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=34
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1217
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=221
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=107
		Total committed heap usage (bytes)=688914432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:30:49  [ main:20775 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:30:49  [ main:20788 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:30:49  [ main:20792 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:30:49  [ main:20800 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:30:49  [ main:20840 ] - [ INFO ]  number of splits:1
2020-11-20 13:30:49  [ main:20860 ] - [ INFO ]  Submitting tokens for job: job_local1764259772_0005
2020-11-20 13:30:49  [ main:20901 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:30:49  [ main:20901 ] - [ INFO ]  Running job: job_local1764259772_0005
2020-11-20 13:30:49  [ Thread-117:20902 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:30:49  [ Thread-117:20902 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:49  [ Thread-117:20902 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:30:49  [ Thread-117:20913 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20913 ] - [ INFO ]  Starting task: attempt_local1764259772_0005_m_000000_0
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20913 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20913 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20913 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20914 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20934 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20935 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20935 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20935 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20935 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:30:49  [ LocalJobRunner Map Task Executor #0:20935 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:30:50  [ communication thread:21809 ] - [ INFO ]  reduce > reduce
2020-11-20 13:30:50  [ main:21905 ] - [ INFO ]  Job job_local1764259772_0005 running in uber mode : false
2020-11-20 13:30:50  [ main:21905 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23987 ] - [ INFO ]  
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23987 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23987 ] - [ INFO ]  Spilling map output
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23987 ] - [ INFO ]  bufstart = 0; bufend = 1206; bufvoid = 104857600
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23987 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23989 ] - [ INFO ]  Finished spill 0
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23990 ] - [ INFO ]  Task:attempt_local1764259772_0005_m_000000_0 is done. And is in the process of committing
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23999 ] - [ INFO ]  map
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23999 ] - [ INFO ]  Task 'attempt_local1764259772_0005_m_000000_0' done.
2020-11-20 13:30:52  [ LocalJobRunner Map Task Executor #0:23999 ] - [ INFO ]  Finishing task: attempt_local1764259772_0005_m_000000_0
2020-11-20 13:30:52  [ Thread-117:23999 ] - [ INFO ]  map task executor complete.
2020-11-20 13:30:52  [ Thread-117:24000 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:30:52  [ pool-18-thread-1:24001 ] - [ INFO ]  Starting task: attempt_local1764259772_0005_r_000000_0
2020-11-20 13:30:52  [ pool-18-thread-1:24002 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:52  [ pool-18-thread-1:24002 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:52  [ pool-18-thread-1:24002 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:52  [ pool-18-thread-1:24003 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27c7647f
2020-11-20 13:30:52  [ pool-18-thread-1:24003 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:30:52  [ EventFetcher for fetching Map Completion Events:24003 ] - [ INFO ]  attempt_local1764259772_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:30:52  [ localfetcher#5:24004 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local1764259772_0005_m_000000_0 decomp: 214 len: 218 to MEMORY
2020-11-20 13:30:52  [ localfetcher#5:24004 ] - [ INFO ]  Read 214 bytes from map-output for attempt_local1764259772_0005_m_000000_0
2020-11-20 13:30:52  [ localfetcher#5:24004 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 214, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->214
2020-11-20 13:30:52  [ EventFetcher for fetching Map Completion Events:24004 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:30:52  [ pool-18-thread-1:24005 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:52  [ pool-18-thread-1:24005 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:30:52  [ pool-18-thread-1:24005 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:52  [ pool-18-thread-1:24005 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:30:52  [ pool-18-thread-1:24006 ] - [ INFO ]  Merged 1 segments, 214 bytes to disk to satisfy reduce memory limit
2020-11-20 13:30:52  [ pool-18-thread-1:24006 ] - [ INFO ]  Merging 1 files, 218 bytes from disk
2020-11-20 13:30:52  [ pool-18-thread-1:24006 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:30:52  [ pool-18-thread-1:24006 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:30:52  [ pool-18-thread-1:24006 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:30:52  [ pool-18-thread-1:24006 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:30:52  [ Thread-117:24045 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:30:52  [ Thread-117:24055 ] - [ WARN ]  job_local1764259772_0005
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-499349534_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-499349534_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:102)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:112)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:99)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:30:53  [ main:24916 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:30:53  [ main:24916 ] - [ INFO ]  Job job_local1764259772_0005 failed with state FAILED due to: NA
2020-11-20 13:30:53  [ main:24918 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2833
		FILE: Number of bytes written=1569033
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3160566
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=23
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1206
		Map output materialized bytes=218
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=218
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=688914432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:30:53  [ main:24948 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:30:53  [ main:24964 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:30:53  [ main:24968 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:30:53  [ main:24977 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:30:53  [ main:25019 ] - [ INFO ]  number of splits:1
2020-11-20 13:30:53  [ main:25037 ] - [ INFO ]  Submitting tokens for job: job_local499701278_0006
2020-11-20 13:30:53  [ main:25075 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:30:53  [ main:25075 ] - [ INFO ]  Running job: job_local499701278_0006
2020-11-20 13:30:53  [ Thread-141:25075 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:30:53  [ Thread-141:25075 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:53  [ Thread-141:25075 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:30:53  [ Thread-141:25087 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25087 ] - [ INFO ]  Starting task: attempt_local499701278_0006_m_000000_0
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25087 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25087 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25087 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25088 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25096 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25096 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25096 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25096 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25096 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:30:53  [ LocalJobRunner Map Task Executor #0:25096 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:30:54  [ communication thread:25762 ] - [ INFO ]  reduce > reduce
2020-11-20 13:30:54  [ main:26079 ] - [ INFO ]  Job job_local499701278_0006 running in uber mode : false
2020-11-20 13:30:54  [ main:26079 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:34:53  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:35:04  [ main:10616 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 13:35:04  [ main:10617 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 13:35:04  [ main:10649 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:35:04  [ main:10654 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:35:04  [ main:10668 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:35:04  [ main:10732 ] - [ INFO ]  number of splits:1
2020-11-20 13:35:04  [ main:10822 ] - [ INFO ]  Submitting tokens for job: job_local1072380933_0001
2020-11-20 13:35:04  [ main:10963 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:35:04  [ main:10964 ] - [ INFO ]  Running job: job_local1072380933_0001
2020-11-20 13:35:04  [ Thread-35:10966 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:35:04  [ Thread-35:10970 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:04  [ Thread-35:10971 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:35:04  [ Thread-35:11021 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11021 ] - [ INFO ]  Starting task: attempt_local1072380933_0001_m_000000_0
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11050 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11057 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11058 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11061 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11124 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11125 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11125 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11125 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11125 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:35:04  [ LocalJobRunner Map Task Executor #0:11129 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:35:10  [ main:16653 ] - [ INFO ]  Job job_local1072380933_0001 running in uber mode : false
2020-11-20 13:35:10  [ main:16655 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19655 ] - [ INFO ]  
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19657 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19657 ] - [ INFO ]  Spilling map output
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19657 ] - [ INFO ]  bufstart = 0; bufend = 1209; bufvoid = 104857600
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19657 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19681 ] - [ INFO ]  Finished spill 0
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19687 ] - [ INFO ]  Task:attempt_local1072380933_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19703 ] - [ INFO ]  map
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19703 ] - [ INFO ]  Task 'attempt_local1072380933_0001_m_000000_0' done.
2020-11-20 13:35:13  [ LocalJobRunner Map Task Executor #0:19703 ] - [ INFO ]  Finishing task: attempt_local1072380933_0001_m_000000_0
2020-11-20 13:35:13  [ Thread-35:19704 ] - [ INFO ]  map task executor complete.
2020-11-20 13:35:13  [ Thread-35:19711 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:35:13  [ pool-9-thread-1:19711 ] - [ INFO ]  Starting task: attempt_local1072380933_0001_r_000000_0
2020-11-20 13:35:13  [ pool-9-thread-1:19722 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:13  [ pool-9-thread-1:19722 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:13  [ pool-9-thread-1:19723 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:13  [ pool-9-thread-1:19728 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@321955a
2020-11-20 13:35:13  [ pool-9-thread-1:19761 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:35:13  [ EventFetcher for fetching Map Completion Events:19764 ] - [ INFO ]  attempt_local1072380933_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:35:13  [ localfetcher#1:19810 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1072380933_0001_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:35:13  [ localfetcher#1:19814 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local1072380933_0001_m_000000_0
2020-11-20 13:35:13  [ localfetcher#1:19817 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:35:13  [ EventFetcher for fetching Map Completion Events:19818 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:35:13  [ pool-9-thread-1:19819 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:13  [ pool-9-thread-1:19820 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:35:13  [ pool-9-thread-1:19831 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:35:13  [ pool-9-thread-1:19831 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:35:13  [ pool-9-thread-1:19833 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:35:13  [ pool-9-thread-1:19833 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:35:13  [ pool-9-thread-1:19834 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:35:13  [ pool-9-thread-1:19834 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:35:13  [ pool-9-thread-1:19834 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:35:13  [ pool-9-thread-1:19835 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:13  [ pool-9-thread-1:19887 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 13:35:13  [ pool-9-thread-1:20075 ] - [ INFO ]  Task:attempt_local1072380933_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 13:35:13  [ pool-9-thread-1:20083 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:13  [ pool-9-thread-1:20083 ] - [ INFO ]  Task attempt_local1072380933_0001_r_000000_0 is allowed to commit now
2020-11-20 13:35:13  [ pool-9-thread-1:20107 ] - [ INFO ]  Saved output of task 'attempt_local1072380933_0001_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1072380933_0001_r_000000
2020-11-20 13:35:13  [ pool-9-thread-1:20108 ] - [ INFO ]  reduce > reduce
2020-11-20 13:35:13  [ pool-9-thread-1:20108 ] - [ INFO ]  Task 'attempt_local1072380933_0001_r_000000_0' done.
2020-11-20 13:35:13  [ pool-9-thread-1:20108 ] - [ INFO ]  Finishing task: attempt_local1072380933_0001_r_000000_0
2020-11-20 13:35:13  [ Thread-35:20108 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:35:14  [ main:20672 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:35:14  [ main:20673 ] - [ INFO ]  Job job_local1072380933_0001 completed successfully
2020-11-20 13:35:14  [ main:20689 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=852
		FILE: Number of bytes written=627737
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2107044
		HDFS: Number of bytes written=210
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1209
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=771751936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:35:14  [ main:20721 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:35:14  [ main:20734 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:35:14  [ main:20740 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:35:14  [ main:20746 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:35:14  [ main:20789 ] - [ INFO ]  number of splits:1
2020-11-20 13:35:14  [ main:20811 ] - [ INFO ]  Submitting tokens for job: job_local539023567_0002
2020-11-20 13:35:14  [ main:20863 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:35:14  [ main:20863 ] - [ INFO ]  Running job: job_local539023567_0002
2020-11-20 13:35:14  [ Thread-64:20864 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:35:14  [ Thread-64:20864 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:14  [ Thread-64:20864 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:35:14  [ Thread-64:20874 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20874 ] - [ INFO ]  Starting task: attempt_local539023567_0002_m_000000_0
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20875 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20875 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20875 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20876 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20919 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20919 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20919 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20919 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20919 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:35:14  [ LocalJobRunner Map Task Executor #0:20919 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:35:15  [ main:21866 ] - [ INFO ]  Job job_local539023567_0002 running in uber mode : false
2020-11-20 13:35:15  [ main:21867 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24060 ] - [ INFO ]  
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24061 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24061 ] - [ INFO ]  Spilling map output
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24061 ] - [ INFO ]  bufstart = 0; bufend = 1198; bufvoid = 104857600
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24061 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24064 ] - [ INFO ]  Finished spill 0
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24066 ] - [ INFO ]  Task:attempt_local539023567_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24072 ] - [ INFO ]  map
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24072 ] - [ INFO ]  Task 'attempt_local539023567_0002_m_000000_0' done.
2020-11-20 13:35:17  [ LocalJobRunner Map Task Executor #0:24072 ] - [ INFO ]  Finishing task: attempt_local539023567_0002_m_000000_0
2020-11-20 13:35:17  [ Thread-64:24072 ] - [ INFO ]  map task executor complete.
2020-11-20 13:35:17  [ Thread-64:24073 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:35:17  [ pool-12-thread-1:24074 ] - [ INFO ]  Starting task: attempt_local539023567_0002_r_000000_0
2020-11-20 13:35:17  [ pool-12-thread-1:24074 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:17  [ pool-12-thread-1:24075 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:17  [ pool-12-thread-1:24075 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:17  [ pool-12-thread-1:24075 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ffed372
2020-11-20 13:35:17  [ pool-12-thread-1:24075 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:35:17  [ EventFetcher for fetching Map Completion Events:24076 ] - [ INFO ]  attempt_local539023567_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:35:17  [ localfetcher#2:24077 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local539023567_0002_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:35:17  [ localfetcher#2:24077 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local539023567_0002_m_000000_0
2020-11-20 13:35:17  [ localfetcher#2:24077 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:35:17  [ EventFetcher for fetching Map Completion Events:24077 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:35:17  [ pool-12-thread-1:24078 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:17  [ pool-12-thread-1:24078 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:35:17  [ pool-12-thread-1:24079 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:35:17  [ pool-12-thread-1:24079 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:35:17  [ pool-12-thread-1:24080 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:35:17  [ pool-12-thread-1:24080 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:35:17  [ pool-12-thread-1:24080 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:35:17  [ pool-12-thread-1:24080 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:35:17  [ pool-12-thread-1:24080 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:35:17  [ pool-12-thread-1:24080 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:17  [ Thread-74:24122 ] - [ WARN ]  DataStreamer Exception
java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 13:35:17  [ Thread-64:24132 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:35:17  [ Thread-64:24140 ] - [ WARN ]  job_local539023567_0002
java.lang.Exception: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 13:35:18  [ main:24878 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:35:18  [ main:24878 ] - [ INFO ]  Job job_local539023567_0002 failed with state FAILED due to: NA
2020-11-20 13:35:18  [ main:24885 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=852
		FILE: Number of bytes written=626359
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1580283
		HDFS: Number of bytes written=210
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1198
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=219
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=393216000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:35:18  [ main:24908 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:35:18  [ main:24920 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:35:18  [ main:24926 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:35:18  [ main:24932 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:35:18  [ main:24975 ] - [ INFO ]  number of splits:1
2020-11-20 13:35:18  [ main:24999 ] - [ INFO ]  Submitting tokens for job: job_local1420021427_0003
2020-11-20 13:35:18  [ main:25049 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:35:18  [ main:25050 ] - [ INFO ]  Running job: job_local1420021427_0003
2020-11-20 13:35:18  [ Thread-89:25050 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:35:18  [ Thread-89:25050 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:18  [ Thread-89:25050 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:35:18  [ Thread-89:25062 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25062 ] - [ INFO ]  Starting task: attempt_local1420021427_0003_m_000000_0
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25063 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25064 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25064 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25065 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25107 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25107 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25107 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25107 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25108 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:35:18  [ LocalJobRunner Map Task Executor #0:25108 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:35:19  [ main:26051 ] - [ INFO ]  Job job_local1420021427_0003 running in uber mode : false
2020-11-20 13:35:19  [ main:26052 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28184 ] - [ INFO ]  
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28184 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28184 ] - [ INFO ]  Spilling map output
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28184 ] - [ INFO ]  bufstart = 0; bufend = 1196; bufvoid = 104857600
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28184 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28188 ] - [ INFO ]  Finished spill 0
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28195 ] - [ INFO ]  Task:attempt_local1420021427_0003_m_000000_0 is done. And is in the process of committing
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28203 ] - [ INFO ]  map
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28203 ] - [ INFO ]  Task 'attempt_local1420021427_0003_m_000000_0' done.
2020-11-20 13:35:21  [ LocalJobRunner Map Task Executor #0:28203 ] - [ INFO ]  Finishing task: attempt_local1420021427_0003_m_000000_0
2020-11-20 13:35:21  [ Thread-89:28203 ] - [ INFO ]  map task executor complete.
2020-11-20 13:35:21  [ Thread-89:28204 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:35:21  [ pool-15-thread-1:28205 ] - [ INFO ]  Starting task: attempt_local1420021427_0003_r_000000_0
2020-11-20 13:35:21  [ pool-15-thread-1:28206 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:21  [ pool-15-thread-1:28206 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:21  [ pool-15-thread-1:28206 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:21  [ pool-15-thread-1:28206 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@e2376ba
2020-11-20 13:35:21  [ pool-15-thread-1:28207 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:35:21  [ EventFetcher for fetching Map Completion Events:28207 ] - [ INFO ]  attempt_local1420021427_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:35:21  [ localfetcher#3:28209 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local1420021427_0003_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:35:21  [ localfetcher#3:28209 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local1420021427_0003_m_000000_0
2020-11-20 13:35:21  [ localfetcher#3:28210 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:35:21  [ EventFetcher for fetching Map Completion Events:28210 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:35:21  [ pool-15-thread-1:28210 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:21  [ pool-15-thread-1:28211 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:35:21  [ pool-15-thread-1:28211 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:35:21  [ pool-15-thread-1:28212 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:35:21  [ pool-15-thread-1:28212 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:35:21  [ pool-15-thread-1:28212 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:35:21  [ pool-15-thread-1:28212 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:35:21  [ pool-15-thread-1:28212 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:35:21  [ pool-15-thread-1:28213 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:35:21  [ pool-15-thread-1:28213 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:35:21  [ Thread-89:28246 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:35:21  [ Thread-89:28254 ] - [ WARN ]  job_local1420021427_0003
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-1922520482_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-1922520482_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_-1922520482_1 on 122.224.128.14 because DFSClient_NONMAPREDUCE_-1922520482_1 is already the current lease holder.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2882)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy12.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:100)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:115)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:102)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:35:22  [ main:29062 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:35:22  [ main:29063 ] - [ INFO ]  Job job_local1420021427_0003 failed with state FAILED due to: NA
2020-11-20 13:35:22  [ main:29068 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=1511
		FILE: Number of bytes written=940520
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2107044
		HDFS: Number of bytes written=418
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=15
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1196
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=219
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=148
		Total committed heap usage (bytes)=617611264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:35:22  [ main:29096 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:35:22  [ main:29108 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:35:22  [ main:29112 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:35:22  [ main:29119 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:35:22  [ main:29154 ] - [ INFO ]  number of splits:1
2020-11-20 13:35:22  [ main:29174 ] - [ INFO ]  Submitting tokens for job: job_local785898104_0004
2020-11-20 13:35:22  [ main:29221 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:35:22  [ main:29221 ] - [ INFO ]  Running job: job_local785898104_0004
2020-11-20 13:35:22  [ Thread-113:29222 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:35:22  [ Thread-113:29222 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:22  [ Thread-113:29222 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:35:22  [ Thread-113:29234 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29234 ] - [ INFO ]  Starting task: attempt_local785898104_0004_m_000000_0
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29235 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29235 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29235 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29236 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29243 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29243 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29243 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29243 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29243 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:35:22  [ LocalJobRunner Map Task Executor #0:29244 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:35:23  [ communication thread:30079 ] - [ INFO ]  reduce > reduce
2020-11-20 13:35:23  [ main:30223 ] - [ INFO ]  Job job_local785898104_0004 running in uber mode : false
2020-11-20 13:35:23  [ main:30223 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:35:25  [ Thread-19:31949 ] - [ ERROR ]  Failed to close inode 30475
java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]], original=[DatanodeInfoWithStorage[172.16.244.144:50010,DS-de009a19-f06b-42e8-8e88-0ffc39f5f26d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:925)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:988)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1156)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:454)
2020-11-20 13:36:18  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 13:36:22  [ main:3988 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 13:36:22  [ main:3989 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 13:36:23  [ main:4143 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:23  [ main:4149 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:23  [ main:4164 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:23  [ main:4223 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:23  [ main:4284 ] - [ INFO ]  Submitting tokens for job: job_local1658237224_0001
2020-11-20 13:36:23  [ main:4368 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:23  [ main:4368 ] - [ INFO ]  Running job: job_local1658237224_0001
2020-11-20 13:36:23  [ Thread-18:4369 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:23  [ Thread-18:4372 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:23  [ Thread-18:4373 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:23  [ Thread-18:4413 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4413 ] - [ INFO ]  Starting task: attempt_local1658237224_0001_m_000000_0
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4428 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4431 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4432 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4434 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4482 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4482 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4482 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4482 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4482 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:23  [ LocalJobRunner Map Task Executor #0:4484 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:24  [ main:5373 ] - [ INFO ]  Job job_local1658237224_0001 running in uber mode : false
2020-11-20 13:36:24  [ main:5375 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7745 ] - [ INFO ]  
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7746 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7746 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7746 ] - [ INFO ]  bufstart = 0; bufend = 1209; bufvoid = 104857600
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7746 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7762 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7765 ] - [ INFO ]  Task:attempt_local1658237224_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7780 ] - [ INFO ]  map
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7780 ] - [ INFO ]  Task 'attempt_local1658237224_0001_m_000000_0' done.
2020-11-20 13:36:26  [ LocalJobRunner Map Task Executor #0:7780 ] - [ INFO ]  Finishing task: attempt_local1658237224_0001_m_000000_0
2020-11-20 13:36:26  [ Thread-18:7780 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:26  [ Thread-18:7782 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:26  [ pool-6-thread-1:7782 ] - [ INFO ]  Starting task: attempt_local1658237224_0001_r_000000_0
2020-11-20 13:36:26  [ pool-6-thread-1:7786 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:26  [ pool-6-thread-1:7787 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:26  [ pool-6-thread-1:7787 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:26  [ pool-6-thread-1:7788 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b785687
2020-11-20 13:36:26  [ pool-6-thread-1:7796 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:26  [ EventFetcher for fetching Map Completion Events:7797 ] - [ INFO ]  attempt_local1658237224_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:26  [ localfetcher#1:7817 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1658237224_0001_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:36:26  [ localfetcher#1:7820 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local1658237224_0001_m_000000_0
2020-11-20 13:36:26  [ localfetcher#1:7821 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:36:26  [ EventFetcher for fetching Map Completion Events:7822 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:26  [ pool-6-thread-1:7823 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:26  [ pool-6-thread-1:7823 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:26  [ pool-6-thread-1:7826 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:26  [ pool-6-thread-1:7827 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:36:26  [ pool-6-thread-1:7827 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:26  [ pool-6-thread-1:7828 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:36:26  [ pool-6-thread-1:7828 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:26  [ pool-6-thread-1:7828 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:26  [ pool-6-thread-1:7828 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:36:26  [ pool-6-thread-1:7828 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:26  [ pool-6-thread-1:7851 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 13:36:26  [ Thread-18:7888 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:26  [ Thread-18:7898 ] - [ WARN ]  job_local1658237224_0001
java.lang.Exception: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_1378745638_1 on 122.224.128.14 because lease recovery is in progress. Try again later.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2918)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to APPEND_FILE /user/root/mr/data/cf/data/sim_result.txt
 for DFSClient_NONMAPREDUCE_1378745638_1 on 122.224.128.14 because lease recovery is in progress. Try again later.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2918)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2683)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:2982)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2950)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:655)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:421)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:328)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1808)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1877)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1847)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:348)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:318)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1166)
	at com.satan.hadoop.utils.HdfsUtil.appendContentToFile(HdfsUtil.java:100)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:115)
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserReducer.reduce(SimilarUserMapReduceJob.java:102)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 13:36:27  [ main:8384 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:36:27  [ main:8384 ] - [ INFO ]  Job job_local1658237224_0001 failed with state FAILED due to: NA
2020-11-20 13:36:27  [ main:8393 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=189
		FILE: Number of bytes written=313754
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1053522
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1209
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=0
		Reduce shuffle bytes=221
		Reduce input records=0
		Reduce output records=0
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316669952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:27  [ main:8462 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:27  [ main:8488 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:27  [ main:8493 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:27  [ main:8512 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:27  [ main:8566 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:27  [ main:8585 ] - [ INFO ]  Submitting tokens for job: job_local928217483_0002
2020-11-20 13:36:27  [ main:8638 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:27  [ main:8638 ] - [ INFO ]  Running job: job_local928217483_0002
2020-11-20 13:36:27  [ Thread-44:8638 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:27  [ Thread-44:8639 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:27  [ Thread-44:8639 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:27  [ Thread-44:8649 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8649 ] - [ INFO ]  Starting task: attempt_local928217483_0002_m_000000_0
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8650 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8650 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8651 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8651 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8666 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8666 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8666 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8666 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8666 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:27  [ LocalJobRunner Map Task Executor #0:8667 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:28  [ main:9642 ] - [ INFO ]  Job job_local928217483_0002 running in uber mode : false
2020-11-20 13:36:28  [ main:9643 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11812 ] - [ INFO ]  
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11812 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11812 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11812 ] - [ INFO ]  bufstart = 0; bufend = 1198; bufvoid = 104857600
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11812 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11815 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11816 ] - [ INFO ]  Task:attempt_local928217483_0002_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11824 ] - [ INFO ]  map
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11824 ] - [ INFO ]  Task 'attempt_local928217483_0002_m_000000_0' done.
2020-11-20 13:36:30  [ LocalJobRunner Map Task Executor #0:11825 ] - [ INFO ]  Finishing task: attempt_local928217483_0002_m_000000_0
2020-11-20 13:36:30  [ Thread-44:11825 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:30  [ Thread-44:11825 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:30  [ pool-9-thread-1:11825 ] - [ INFO ]  Starting task: attempt_local928217483_0002_r_000000_0
2020-11-20 13:36:30  [ pool-9-thread-1:11826 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:30  [ pool-9-thread-1:11826 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:30  [ pool-9-thread-1:11826 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:30  [ pool-9-thread-1:11827 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16bd2088
2020-11-20 13:36:30  [ pool-9-thread-1:11828 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:30  [ EventFetcher for fetching Map Completion Events:11828 ] - [ INFO ]  attempt_local928217483_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:30  [ localfetcher#2:11830 ] - [ INFO ]  localfetcher#2 about to shuffle output of map attempt_local928217483_0002_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:36:30  [ localfetcher#2:11830 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local928217483_0002_m_000000_0
2020-11-20 13:36:30  [ localfetcher#2:11830 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:36:30  [ EventFetcher for fetching Map Completion Events:11830 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:30  [ pool-9-thread-1:11831 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:30  [ pool-9-thread-1:11831 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:30  [ pool-9-thread-1:11832 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:30  [ pool-9-thread-1:11832 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:36:30  [ pool-9-thread-1:11832 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:30  [ pool-9-thread-1:11833 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:36:30  [ pool-9-thread-1:11833 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:30  [ pool-9-thread-1:11833 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:30  [ pool-9-thread-1:11833 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:36:30  [ pool-9-thread-1:11833 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:31  [ pool-9-thread-1:12034 ] - [ INFO ]  Task:attempt_local928217483_0002_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:31  [ pool-9-thread-1:12057 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:31  [ pool-9-thread-1:12057 ] - [ INFO ]  Task attempt_local928217483_0002_r_000000_0 is allowed to commit now
2020-11-20 13:36:31  [ pool-9-thread-1:12111 ] - [ INFO ]  Saved output of task 'attempt_local928217483_0002_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local928217483_0002_r_000000
2020-11-20 13:36:31  [ pool-9-thread-1:12112 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:31  [ pool-9-thread-1:12112 ] - [ INFO ]  Task 'attempt_local928217483_0002_r_000000_0' done.
2020-11-20 13:36:31  [ pool-9-thread-1:12112 ] - [ INFO ]  Finishing task: attempt_local928217483_0002_r_000000_0
2020-11-20 13:36:31  [ Thread-44:12112 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:31  [ main:12652 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:31  [ main:12652 ] - [ INFO ]  Job job_local928217483_0002 completed successfully
2020-11-20 13:36:31  [ main:12656 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=2174
		FILE: Number of bytes written=1252921
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3160566
		HDFS: Number of bytes written=208
		HDFS: Number of read operations=40
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=17
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1198
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=219
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=98
		Total committed heap usage (bytes)=1041235968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:31  [ main:12699 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:31  [ main:12714 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:31  [ main:12718 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:31  [ main:12729 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:31  [ main:12771 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:31  [ main:12793 ] - [ INFO ]  Submitting tokens for job: job_local1415491020_0003
2020-11-20 13:36:31  [ main:12835 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:31  [ main:12836 ] - [ INFO ]  Running job: job_local1415491020_0003
2020-11-20 13:36:31  [ Thread-71:12836 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:31  [ Thread-71:12836 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:31  [ Thread-71:12836 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:31  [ Thread-71:12849 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12849 ] - [ INFO ]  Starting task: attempt_local1415491020_0003_m_000000_0
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12850 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12851 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12851 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12852 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12862 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12862 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12862 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12862 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12862 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:31  [ LocalJobRunner Map Task Executor #0:12863 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:32  [ communication thread:13795 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:32  [ main:13840 ] - [ INFO ]  Job job_local1415491020_0003 running in uber mode : false
2020-11-20 13:36:32  [ main:13840 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15832 ] - [ INFO ]  
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15832 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15832 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15832 ] - [ INFO ]  bufstart = 0; bufend = 1196; bufvoid = 104857600
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15832 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15835 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15836 ] - [ INFO ]  Task:attempt_local1415491020_0003_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15844 ] - [ INFO ]  map
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15844 ] - [ INFO ]  Task 'attempt_local1415491020_0003_m_000000_0' done.
2020-11-20 13:36:34  [ LocalJobRunner Map Task Executor #0:15844 ] - [ INFO ]  Finishing task: attempt_local1415491020_0003_m_000000_0
2020-11-20 13:36:34  [ Thread-71:15844 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:34  [ Thread-71:15845 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:34  [ pool-12-thread-1:15845 ] - [ INFO ]  Starting task: attempt_local1415491020_0003_r_000000_0
2020-11-20 13:36:34  [ pool-12-thread-1:15845 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:34  [ pool-12-thread-1:15846 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:34  [ pool-12-thread-1:15846 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:34  [ pool-12-thread-1:15846 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42247b59
2020-11-20 13:36:34  [ pool-12-thread-1:15846 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:34  [ EventFetcher for fetching Map Completion Events:15846 ] - [ INFO ]  attempt_local1415491020_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:34  [ localfetcher#3:15847 ] - [ INFO ]  localfetcher#3 about to shuffle output of map attempt_local1415491020_0003_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:36:34  [ main:15847 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:36:34  [ localfetcher#3:15847 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local1415491020_0003_m_000000_0
2020-11-20 13:36:34  [ localfetcher#3:15847 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:36:34  [ EventFetcher for fetching Map Completion Events:15848 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:34  [ pool-12-thread-1:15848 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:34  [ pool-12-thread-1:15848 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:34  [ pool-12-thread-1:15849 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:34  [ pool-12-thread-1:15849 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:36:34  [ pool-12-thread-1:15849 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:34  [ pool-12-thread-1:15850 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:36:34  [ pool-12-thread-1:15850 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:34  [ pool-12-thread-1:15850 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:34  [ pool-12-thread-1:15850 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:36:34  [ pool-12-thread-1:15850 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:34  [ pool-12-thread-1:15959 ] - [ INFO ]  Task:attempt_local1415491020_0003_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:34  [ pool-12-thread-1:15968 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:34  [ pool-12-thread-1:15968 ] - [ INFO ]  Task attempt_local1415491020_0003_r_000000_0 is allowed to commit now
2020-11-20 13:36:34  [ pool-12-thread-1:15999 ] - [ INFO ]  Saved output of task 'attempt_local1415491020_0003_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1415491020_0003_r_000000
2020-11-20 13:36:34  [ pool-12-thread-1:16000 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:34  [ pool-12-thread-1:16000 ] - [ INFO ]  Task 'attempt_local1415491020_0003_r_000000_0' done.
2020-11-20 13:36:34  [ pool-12-thread-1:16000 ] - [ INFO ]  Finishing task: attempt_local1415491020_0003_r_000000_0
2020-11-20 13:36:34  [ Thread-71:16000 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:35  [ main:16849 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:35  [ main:16850 ] - [ INFO ]  Job job_local1415491020_0003 completed successfully
2020-11-20 13:36:35  [ main:16853 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=3492
		FILE: Number of bytes written=1881235
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4214088
		HDFS: Number of bytes written=624
		HDFS: Number of read operations=70
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=33
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1196
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=219
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1041235968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:35  [ main:16878 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:35  [ main:16892 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:35  [ main:16896 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:35  [ main:16905 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:35  [ main:16954 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:35  [ main:16974 ] - [ INFO ]  Submitting tokens for job: job_local960265444_0004
2020-11-20 13:36:35  [ main:17014 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:35  [ main:17014 ] - [ INFO ]  Running job: job_local960265444_0004
2020-11-20 13:36:35  [ Thread-98:17014 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:35  [ Thread-98:17015 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:35  [ Thread-98:17015 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:36  [ Thread-98:17026 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17027 ] - [ INFO ]  Starting task: attempt_local960265444_0004_m_000000_0
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17027 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17027 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17027 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17028 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17037 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17037 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17037 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17037 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17037 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:36  [ LocalJobRunner Map Task Executor #0:17037 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:36  [ main:18015 ] - [ INFO ]  Job job_local960265444_0004 running in uber mode : false
2020-11-20 13:36:36  [ main:18015 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20138 ] - [ INFO ]  
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20138 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20138 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20138 ] - [ INFO ]  bufstart = 0; bufend = 1217; bufvoid = 104857600
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20138 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20140 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20141 ] - [ INFO ]  Task:attempt_local960265444_0004_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20151 ] - [ INFO ]  map
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20151 ] - [ INFO ]  Task 'attempt_local960265444_0004_m_000000_0' done.
2020-11-20 13:36:39  [ LocalJobRunner Map Task Executor #0:20151 ] - [ INFO ]  Finishing task: attempt_local960265444_0004_m_000000_0
2020-11-20 13:36:39  [ Thread-98:20151 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:39  [ Thread-98:20152 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:39  [ pool-15-thread-1:20152 ] - [ INFO ]  Starting task: attempt_local960265444_0004_r_000000_0
2020-11-20 13:36:39  [ pool-15-thread-1:20153 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:39  [ pool-15-thread-1:20154 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:39  [ pool-15-thread-1:20154 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:39  [ pool-15-thread-1:20154 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@179e319a
2020-11-20 13:36:39  [ pool-15-thread-1:20154 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:39  [ EventFetcher for fetching Map Completion Events:20154 ] - [ INFO ]  attempt_local960265444_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:39  [ localfetcher#4:20155 ] - [ INFO ]  localfetcher#4 about to shuffle output of map attempt_local960265444_0004_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:36:39  [ localfetcher#4:20156 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local960265444_0004_m_000000_0
2020-11-20 13:36:39  [ localfetcher#4:20156 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:36:39  [ EventFetcher for fetching Map Completion Events:20156 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:39  [ pool-15-thread-1:20156 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:39  [ pool-15-thread-1:20157 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:39  [ pool-15-thread-1:20157 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:39  [ pool-15-thread-1:20157 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:36:39  [ pool-15-thread-1:20158 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:39  [ pool-15-thread-1:20158 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:36:39  [ pool-15-thread-1:20158 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:39  [ pool-15-thread-1:20158 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:39  [ pool-15-thread-1:20158 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:36:39  [ pool-15-thread-1:20159 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:39  [ pool-15-thread-1:20316 ] - [ INFO ]  Task:attempt_local960265444_0004_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:39  [ pool-15-thread-1:20327 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:39  [ pool-15-thread-1:20327 ] - [ INFO ]  Task attempt_local960265444_0004_r_000000_0 is allowed to commit now
2020-11-20 13:36:39  [ pool-15-thread-1:20352 ] - [ INFO ]  Saved output of task 'attempt_local960265444_0004_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local960265444_0004_r_000000
2020-11-20 13:36:39  [ pool-15-thread-1:20353 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:39  [ pool-15-thread-1:20353 ] - [ INFO ]  Task 'attempt_local960265444_0004_r_000000_0' done.
2020-11-20 13:36:39  [ pool-15-thread-1:20353 ] - [ INFO ]  Finishing task: attempt_local960265444_0004_r_000000_0
2020-11-20 13:36:39  [ Thread-98:20353 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:39  [ main:21019 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:39  [ main:21019 ] - [ INFO ]  Job job_local960265444_0004 completed successfully
2020-11-20 13:36:39  [ main:21022 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=4814
		FILE: Number of bytes written=2506579
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5267610
		HDFS: Number of bytes written=1042
		HDFS: Number of read operations=100
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=49
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1217
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=110
		Total committed heap usage (bytes)=1362100224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:40  [ main:21050 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:40  [ main:21065 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:40  [ main:21069 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:40  [ main:21077 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:40  [ main:21118 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:40  [ main:21139 ] - [ INFO ]  Submitting tokens for job: job_local1294111950_0005
2020-11-20 13:36:40  [ main:21176 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:40  [ main:21176 ] - [ INFO ]  Running job: job_local1294111950_0005
2020-11-20 13:36:40  [ Thread-125:21177 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:40  [ Thread-125:21177 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:40  [ Thread-125:21177 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:40  [ Thread-125:21187 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21187 ] - [ INFO ]  Starting task: attempt_local1294111950_0005_m_000000_0
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21188 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21188 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21188 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21189 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21209 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21209 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21209 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21209 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21209 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:40  [ LocalJobRunner Map Task Executor #0:21210 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:41  [ main:22181 ] - [ INFO ]  Job job_local1294111950_0005 running in uber mode : false
2020-11-20 13:36:41  [ main:22182 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24384 ] - [ INFO ]  
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24384 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24384 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24384 ] - [ INFO ]  bufstart = 0; bufend = 1206; bufvoid = 104857600
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24384 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24387 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24388 ] - [ INFO ]  Task:attempt_local1294111950_0005_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24397 ] - [ INFO ]  map
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24397 ] - [ INFO ]  Task 'attempt_local1294111950_0005_m_000000_0' done.
2020-11-20 13:36:43  [ LocalJobRunner Map Task Executor #0:24397 ] - [ INFO ]  Finishing task: attempt_local1294111950_0005_m_000000_0
2020-11-20 13:36:43  [ Thread-125:24397 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:43  [ Thread-125:24398 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:43  [ pool-18-thread-1:24398 ] - [ INFO ]  Starting task: attempt_local1294111950_0005_r_000000_0
2020-11-20 13:36:43  [ pool-18-thread-1:24399 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:43  [ pool-18-thread-1:24399 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:43  [ pool-18-thread-1:24399 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:43  [ pool-18-thread-1:24399 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a85e36b
2020-11-20 13:36:43  [ pool-18-thread-1:24400 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:43  [ EventFetcher for fetching Map Completion Events:24401 ] - [ INFO ]  attempt_local1294111950_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:43  [ localfetcher#5:24402 ] - [ INFO ]  localfetcher#5 about to shuffle output of map attempt_local1294111950_0005_m_000000_0 decomp: 214 len: 218 to MEMORY
2020-11-20 13:36:43  [ localfetcher#5:24402 ] - [ INFO ]  Read 214 bytes from map-output for attempt_local1294111950_0005_m_000000_0
2020-11-20 13:36:43  [ localfetcher#5:24402 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 214, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->214
2020-11-20 13:36:43  [ EventFetcher for fetching Map Completion Events:24403 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:43  [ pool-18-thread-1:24403 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:43  [ pool-18-thread-1:24403 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:43  [ pool-18-thread-1:24404 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:43  [ pool-18-thread-1:24404 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:36:43  [ pool-18-thread-1:24404 ] - [ INFO ]  Merged 1 segments, 214 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:43  [ pool-18-thread-1:24404 ] - [ INFO ]  Merging 1 files, 218 bytes from disk
2020-11-20 13:36:43  [ pool-18-thread-1:24404 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:43  [ pool-18-thread-1:24404 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:43  [ pool-18-thread-1:24405 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:36:43  [ pool-18-thread-1:24405 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:43  [ pool-18-thread-1:24507 ] - [ INFO ]  Task:attempt_local1294111950_0005_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:43  [ pool-18-thread-1:24516 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:43  [ pool-18-thread-1:24516 ] - [ INFO ]  Task attempt_local1294111950_0005_r_000000_0 is allowed to commit now
2020-11-20 13:36:43  [ pool-18-thread-1:24541 ] - [ INFO ]  Saved output of task 'attempt_local1294111950_0005_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1294111950_0005_r_000000
2020-11-20 13:36:43  [ pool-18-thread-1:24542 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:43  [ pool-18-thread-1:24542 ] - [ INFO ]  Task 'attempt_local1294111950_0005_r_000000_0' done.
2020-11-20 13:36:43  [ pool-18-thread-1:24542 ] - [ INFO ]  Finishing task: attempt_local1294111950_0005_r_000000_0
2020-11-20 13:36:43  [ Thread-125:24542 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:44  [ main:25195 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:44  [ main:25195 ] - [ INFO ]  Job job_local1294111950_0005 completed successfully
2020-11-20 13:36:44  [ main:25198 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=6134
		FILE: Number of bytes written=3135192
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6321132
		HDFS: Number of bytes written=1459
		HDFS: Number of read operations=130
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=65
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1206
		Map output materialized bytes=218
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=218
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=1482686464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:44  [ main:25229 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:44  [ main:25244 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:44  [ main:25249 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:44  [ main:25258 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:44  [ main:25300 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:44  [ main:25318 ] - [ INFO ]  Submitting tokens for job: job_local965362206_0006
2020-11-20 13:36:44  [ main:25358 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:44  [ main:25358 ] - [ INFO ]  Running job: job_local965362206_0006
2020-11-20 13:36:44  [ Thread-152:25358 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:44  [ Thread-152:25358 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:44  [ Thread-152:25358 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:44  [ Thread-152:25369 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25369 ] - [ INFO ]  Starting task: attempt_local965362206_0006_m_000000_0
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25370 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25370 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25370 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25371 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25379 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25379 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25379 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25379 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25379 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:44  [ LocalJobRunner Map Task Executor #0:25379 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:45  [ main:26363 ] - [ INFO ]  Job job_local965362206_0006 running in uber mode : false
2020-11-20 13:36:45  [ main:26363 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28683 ] - [ INFO ]  
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28683 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28683 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28683 ] - [ INFO ]  bufstart = 0; bufend = 1211; bufvoid = 104857600
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28684 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28686 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28687 ] - [ INFO ]  Task:attempt_local965362206_0006_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28699 ] - [ INFO ]  map
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28700 ] - [ INFO ]  Task 'attempt_local965362206_0006_m_000000_0' done.
2020-11-20 13:36:47  [ LocalJobRunner Map Task Executor #0:28700 ] - [ INFO ]  Finishing task: attempt_local965362206_0006_m_000000_0
2020-11-20 13:36:47  [ Thread-152:28700 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:47  [ Thread-152:28700 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:47  [ pool-21-thread-1:28700 ] - [ INFO ]  Starting task: attempt_local965362206_0006_r_000000_0
2020-11-20 13:36:47  [ pool-21-thread-1:28701 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:47  [ pool-21-thread-1:28701 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:47  [ pool-21-thread-1:28701 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:47  [ pool-21-thread-1:28701 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@664985c4
2020-11-20 13:36:47  [ pool-21-thread-1:28702 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:47  [ EventFetcher for fetching Map Completion Events:28702 ] - [ INFO ]  attempt_local965362206_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:47  [ localfetcher#6:28703 ] - [ INFO ]  localfetcher#6 about to shuffle output of map attempt_local965362206_0006_m_000000_0 decomp: 219 len: 223 to MEMORY
2020-11-20 13:36:47  [ localfetcher#6:28703 ] - [ INFO ]  Read 219 bytes from map-output for attempt_local965362206_0006_m_000000_0
2020-11-20 13:36:47  [ localfetcher#6:28703 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 219, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->219
2020-11-20 13:36:47  [ EventFetcher for fetching Map Completion Events:28703 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:47  [ pool-21-thread-1:28703 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:47  [ pool-21-thread-1:28703 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:47  [ pool-21-thread-1:28704 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:47  [ pool-21-thread-1:28704 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:36:47  [ pool-21-thread-1:28705 ] - [ INFO ]  Merged 1 segments, 219 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:47  [ pool-21-thread-1:28705 ] - [ INFO ]  Merging 1 files, 223 bytes from disk
2020-11-20 13:36:47  [ pool-21-thread-1:28705 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:47  [ pool-21-thread-1:28705 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:47  [ pool-21-thread-1:28705 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:36:47  [ pool-21-thread-1:28705 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:47  [ pool-21-thread-1:28820 ] - [ INFO ]  Task:attempt_local965362206_0006_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:47  [ pool-21-thread-1:28829 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:47  [ pool-21-thread-1:28829 ] - [ INFO ]  Task attempt_local965362206_0006_r_000000_0 is allowed to commit now
2020-11-20 13:36:47  [ pool-21-thread-1:28857 ] - [ INFO ]  Saved output of task 'attempt_local965362206_0006_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local965362206_0006_r_000000
2020-11-20 13:36:47  [ pool-21-thread-1:28857 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:47  [ pool-21-thread-1:28858 ] - [ INFO ]  Task 'attempt_local965362206_0006_r_000000_0' done.
2020-11-20 13:36:47  [ pool-21-thread-1:28858 ] - [ INFO ]  Finishing task: attempt_local965362206_0006_r_000000_0
2020-11-20 13:36:47  [ Thread-152:28858 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:48  [ main:29371 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:48  [ main:29371 ] - [ INFO ]  Job job_local965362206_0006 completed successfully
2020-11-20 13:36:48  [ main:29373 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=7458
		FILE: Number of bytes written=3762997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7374654
		HDFS: Number of bytes written=1878
		HDFS: Number of read operations=160
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=81
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1211
		Map output materialized bytes=223
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=223
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1482686464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:48  [ main:29402 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:48  [ main:29418 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:48  [ main:29422 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:48  [ main:29431 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:48  [ main:29473 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:48  [ main:29491 ] - [ INFO ]  Submitting tokens for job: job_local1876238895_0007
2020-11-20 13:36:48  [ main:29531 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:48  [ main:29531 ] - [ INFO ]  Running job: job_local1876238895_0007
2020-11-20 13:36:48  [ Thread-179:29531 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:48  [ Thread-179:29532 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:48  [ Thread-179:29532 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:48  [ Thread-179:29544 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29544 ] - [ INFO ]  Starting task: attempt_local1876238895_0007_m_000000_0
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29544 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29545 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29545 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29545 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29556 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29556 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29556 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29556 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29556 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:48  [ LocalJobRunner Map Task Executor #0:29556 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:49  [ main:30536 ] - [ INFO ]  Job job_local1876238895_0007 running in uber mode : false
2020-11-20 13:36:49  [ main:30536 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32697 ] - [ INFO ]  
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32697 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32697 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32697 ] - [ INFO ]  bufstart = 0; bufend = 1170; bufvoid = 104857600
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32697 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32699 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32700 ] - [ INFO ]  Task:attempt_local1876238895_0007_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32709 ] - [ INFO ]  map
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32709 ] - [ INFO ]  Task 'attempt_local1876238895_0007_m_000000_0' done.
2020-11-20 13:36:51  [ LocalJobRunner Map Task Executor #0:32709 ] - [ INFO ]  Finishing task: attempt_local1876238895_0007_m_000000_0
2020-11-20 13:36:51  [ Thread-179:32709 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:51  [ Thread-179:32710 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:51  [ pool-24-thread-1:32710 ] - [ INFO ]  Starting task: attempt_local1876238895_0007_r_000000_0
2020-11-20 13:36:51  [ pool-24-thread-1:32711 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:51  [ pool-24-thread-1:32711 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:51  [ pool-24-thread-1:32711 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:51  [ pool-24-thread-1:32711 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4bf8af98
2020-11-20 13:36:51  [ pool-24-thread-1:32711 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:51  [ EventFetcher for fetching Map Completion Events:32712 ] - [ INFO ]  attempt_local1876238895_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:51  [ localfetcher#7:32713 ] - [ INFO ]  localfetcher#7 about to shuffle output of map attempt_local1876238895_0007_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:36:51  [ localfetcher#7:32713 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local1876238895_0007_m_000000_0
2020-11-20 13:36:51  [ localfetcher#7:32713 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:36:51  [ EventFetcher for fetching Map Completion Events:32713 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:51  [ pool-24-thread-1:32714 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:51  [ pool-24-thread-1:32714 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:51  [ pool-24-thread-1:32715 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:36:51  [ pool-24-thread-1:32716 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:51  [ pool-24-thread-1:32829 ] - [ INFO ]  Task:attempt_local1876238895_0007_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:51  [ pool-24-thread-1:32838 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:51  [ pool-24-thread-1:32838 ] - [ INFO ]  Task attempt_local1876238895_0007_r_000000_0 is allowed to commit now
2020-11-20 13:36:51  [ pool-24-thread-1:32864 ] - [ INFO ]  Saved output of task 'attempt_local1876238895_0007_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1876238895_0007_r_000000
2020-11-20 13:36:51  [ pool-24-thread-1:32864 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:51  [ pool-24-thread-1:32865 ] - [ INFO ]  Task 'attempt_local1876238895_0007_r_000000_0' done.
2020-11-20 13:36:51  [ pool-24-thread-1:32865 ] - [ INFO ]  Finishing task: attempt_local1876238895_0007_r_000000_0
2020-11-20 13:36:51  [ Thread-179:32865 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:52  [ main:33541 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:52  [ main:33542 ] - [ INFO ]  Job job_local1876238895_0007 completed successfully
2020-11-20 13:36:52  [ main:33543 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=8794
		FILE: Number of bytes written=4394066
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8428176
		HDFS: Number of bytes written=2303
		HDFS: Number of read operations=190
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=97
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1170
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1718616064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:52  [ main:33575 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:52  [ main:33587 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:52  [ main:33590 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:52  [ main:33599 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:52  [ main:33640 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:52  [ main:33657 ] - [ INFO ]  Submitting tokens for job: job_local1407315478_0008
2020-11-20 13:36:52  [ main:33694 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:52  [ main:33694 ] - [ INFO ]  Running job: job_local1407315478_0008
2020-11-20 13:36:52  [ Thread-206:33694 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:52  [ Thread-206:33694 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:52  [ Thread-206:33694 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:52  [ Thread-206:33705 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33705 ] - [ INFO ]  Starting task: attempt_local1407315478_0008_m_000000_0
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33705 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33706 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33706 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33706 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33745 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33745 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33745 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33745 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33745 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:52  [ LocalJobRunner Map Task Executor #0:33745 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:53  [ main:34697 ] - [ INFO ]  Job job_local1407315478_0008 running in uber mode : false
2020-11-20 13:36:53  [ main:34697 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36590 ] - [ INFO ]  
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36590 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36590 ] - [ INFO ]  Spilling map output
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36590 ] - [ INFO ]  bufstart = 0; bufend = 1170; bufvoid = 104857600
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36590 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36592 ] - [ INFO ]  Finished spill 0
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36593 ] - [ INFO ]  Task:attempt_local1407315478_0008_m_000000_0 is done. And is in the process of committing
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36601 ] - [ INFO ]  map
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36601 ] - [ INFO ]  Task 'attempt_local1407315478_0008_m_000000_0' done.
2020-11-20 13:36:55  [ LocalJobRunner Map Task Executor #0:36601 ] - [ INFO ]  Finishing task: attempt_local1407315478_0008_m_000000_0
2020-11-20 13:36:55  [ Thread-206:36602 ] - [ INFO ]  map task executor complete.
2020-11-20 13:36:55  [ Thread-206:36602 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:36:55  [ pool-27-thread-1:36602 ] - [ INFO ]  Starting task: attempt_local1407315478_0008_r_000000_0
2020-11-20 13:36:55  [ pool-27-thread-1:36603 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:55  [ pool-27-thread-1:36603 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:55  [ pool-27-thread-1:36603 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:55  [ pool-27-thread-1:36603 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@170d74f2
2020-11-20 13:36:55  [ pool-27-thread-1:36604 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:36:55  [ EventFetcher for fetching Map Completion Events:36604 ] - [ INFO ]  attempt_local1407315478_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:36:55  [ localfetcher#8:36605 ] - [ INFO ]  localfetcher#8 about to shuffle output of map attempt_local1407315478_0008_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:36:55  [ localfetcher#8:36605 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local1407315478_0008_m_000000_0
2020-11-20 13:36:55  [ localfetcher#8:36605 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:36:55  [ EventFetcher for fetching Map Completion Events:36606 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:36:55  [ pool-27-thread-1:36606 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:55  [ pool-27-thread-1:36606 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:36:55  [ pool-27-thread-1:36606 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:55  [ pool-27-thread-1:36606 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:36:55  [ pool-27-thread-1:36607 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:36:55  [ pool-27-thread-1:36607 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:36:55  [ pool-27-thread-1:36607 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:36:55  [ pool-27-thread-1:36607 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:36:55  [ pool-27-thread-1:36607 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:36:55  [ pool-27-thread-1:36607 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:55  [ main:36701 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:36:55  [ pool-27-thread-1:36704 ] - [ INFO ]  Task:attempt_local1407315478_0008_r_000000_0 is done. And is in the process of committing
2020-11-20 13:36:55  [ pool-27-thread-1:36714 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:36:55  [ pool-27-thread-1:36714 ] - [ INFO ]  Task attempt_local1407315478_0008_r_000000_0 is allowed to commit now
2020-11-20 13:36:55  [ pool-27-thread-1:36738 ] - [ INFO ]  Saved output of task 'attempt_local1407315478_0008_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1407315478_0008_r_000000
2020-11-20 13:36:55  [ pool-27-thread-1:36738 ] - [ INFO ]  reduce > reduce
2020-11-20 13:36:55  [ pool-27-thread-1:36739 ] - [ INFO ]  Task 'attempt_local1407315478_0008_r_000000_0' done.
2020-11-20 13:36:55  [ pool-27-thread-1:36739 ] - [ INFO ]  Finishing task: attempt_local1407315478_0008_r_000000_0
2020-11-20 13:36:55  [ Thread-206:36739 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:36:56  [ main:37705 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:36:56  [ main:37705 ] - [ INFO ]  Job job_local1407315478_0008 completed successfully
2020-11-20 13:36:56  [ main:37707 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=10132
		FILE: Number of bytes written=5025136
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=9481698
		HDFS: Number of bytes written=2729
		HDFS: Number of read operations=220
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=113
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1170
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=47
		Total committed heap usage (bytes)=1803550720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:36:56  [ main:37734 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:36:56  [ main:37747 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:36:56  [ main:37752 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:36:56  [ main:37761 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:36:56  [ main:37801 ] - [ INFO ]  number of splits:1
2020-11-20 13:36:56  [ main:37820 ] - [ INFO ]  Submitting tokens for job: job_local920716559_0009
2020-11-20 13:36:56  [ main:37858 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:36:56  [ main:37858 ] - [ INFO ]  Running job: job_local920716559_0009
2020-11-20 13:36:56  [ Thread-233:37858 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:36:56  [ Thread-233:37859 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:56  [ Thread-233:37859 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:36:56  [ Thread-233:37870 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37870 ] - [ INFO ]  Starting task: attempt_local920716559_0009_m_000000_0
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37871 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37871 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37871 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37871 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37879 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37879 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37879 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37879 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37879 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:36:56  [ LocalJobRunner Map Task Executor #0:37879 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:36:57  [ main:38863 ] - [ INFO ]  Job job_local920716559_0009 running in uber mode : false
2020-11-20 13:36:57  [ main:38864 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41092 ] - [ INFO ]  
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41092 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41092 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41092 ] - [ INFO ]  bufstart = 0; bufend = 1194; bufvoid = 104857600
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41092 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41094 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41095 ] - [ INFO ]  Task:attempt_local920716559_0009_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41104 ] - [ INFO ]  map
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41104 ] - [ INFO ]  Task 'attempt_local920716559_0009_m_000000_0' done.
2020-11-20 13:37:00  [ LocalJobRunner Map Task Executor #0:41104 ] - [ INFO ]  Finishing task: attempt_local920716559_0009_m_000000_0
2020-11-20 13:37:00  [ Thread-233:41104 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:00  [ Thread-233:41105 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:00  [ pool-30-thread-1:41105 ] - [ INFO ]  Starting task: attempt_local920716559_0009_r_000000_0
2020-11-20 13:37:00  [ pool-30-thread-1:41105 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:00  [ pool-30-thread-1:41106 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:00  [ pool-30-thread-1:41106 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:00  [ pool-30-thread-1:41106 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4c13cf10
2020-11-20 13:37:00  [ pool-30-thread-1:41106 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:00  [ EventFetcher for fetching Map Completion Events:41106 ] - [ INFO ]  attempt_local920716559_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:00  [ localfetcher#9:41107 ] - [ INFO ]  localfetcher#9 about to shuffle output of map attempt_local920716559_0009_m_000000_0 decomp: 222 len: 226 to MEMORY
2020-11-20 13:37:00  [ localfetcher#9:41107 ] - [ INFO ]  Read 222 bytes from map-output for attempt_local920716559_0009_m_000000_0
2020-11-20 13:37:00  [ localfetcher#9:41107 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 222, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->222
2020-11-20 13:37:00  [ EventFetcher for fetching Map Completion Events:41108 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:00  [ pool-30-thread-1:41108 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:00  [ pool-30-thread-1:41108 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Merged 1 segments, 222 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Merging 1 files, 226 bytes from disk
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:00  [ pool-30-thread-1:41109 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:00  [ pool-30-thread-1:41110 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:00  [ pool-30-thread-1:41205 ] - [ INFO ]  Task:attempt_local920716559_0009_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:00  [ pool-30-thread-1:41213 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:00  [ pool-30-thread-1:41214 ] - [ INFO ]  Task attempt_local920716559_0009_r_000000_0 is allowed to commit now
2020-11-20 13:37:00  [ pool-30-thread-1:41240 ] - [ INFO ]  Saved output of task 'attempt_local920716559_0009_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local920716559_0009_r_000000
2020-11-20 13:37:00  [ pool-30-thread-1:41240 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:00  [ pool-30-thread-1:41241 ] - [ INFO ]  Task 'attempt_local920716559_0009_r_000000_0' done.
2020-11-20 13:37:00  [ pool-30-thread-1:41241 ] - [ INFO ]  Finishing task: attempt_local920716559_0009_r_000000_0
2020-11-20 13:37:00  [ Thread-233:41241 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:00  [ main:41872 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:00  [ main:41873 ] - [ INFO ]  Job job_local920716559_0009 completed successfully
2020-11-20 13:37:00  [ main:41874 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=11474
		FILE: Number of bytes written=5619892
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10535220
		HDFS: Number of bytes written=3157
		HDFS: Number of read operations=250
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=129
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1194
		Map output materialized bytes=226
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=226
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1803550720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:00  [ main:41901 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:00  [ main:41915 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:00  [ main:41920 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:00  [ main:41928 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:00  [ main:41972 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:00  [ main:41990 ] - [ INFO ]  Submitting tokens for job: job_local1587674715_0010
2020-11-20 13:37:01  [ main:42029 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:01  [ main:42029 ] - [ INFO ]  Running job: job_local1587674715_0010
2020-11-20 13:37:01  [ Thread-260:42029 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:01  [ Thread-260:42029 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:01  [ Thread-260:42030 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:01  [ Thread-260:42041 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42041 ] - [ INFO ]  Starting task: attempt_local1587674715_0010_m_000000_0
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42041 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42041 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42041 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42042 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42054 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42054 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42054 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42054 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42054 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:01  [ LocalJobRunner Map Task Executor #0:42055 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:02  [ main:43030 ] - [ INFO ]  Job job_local1587674715_0010 running in uber mode : false
2020-11-20 13:37:02  [ main:43030 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45108 ] - [ INFO ]  
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45109 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45109 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45109 ] - [ INFO ]  bufstart = 0; bufend = 1187; bufvoid = 104857600
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45109 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45110 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45111 ] - [ INFO ]  Task:attempt_local1587674715_0010_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45119 ] - [ INFO ]  map
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45119 ] - [ INFO ]  Task 'attempt_local1587674715_0010_m_000000_0' done.
2020-11-20 13:37:04  [ LocalJobRunner Map Task Executor #0:45119 ] - [ INFO ]  Finishing task: attempt_local1587674715_0010_m_000000_0
2020-11-20 13:37:04  [ Thread-260:45119 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:04  [ Thread-260:45120 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:04  [ pool-33-thread-1:45120 ] - [ INFO ]  Starting task: attempt_local1587674715_0010_r_000000_0
2020-11-20 13:37:04  [ pool-33-thread-1:45120 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:04  [ pool-33-thread-1:45121 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:04  [ pool-33-thread-1:45121 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:04  [ pool-33-thread-1:45121 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a14629c
2020-11-20 13:37:04  [ pool-33-thread-1:45121 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:04  [ EventFetcher for fetching Map Completion Events:45121 ] - [ INFO ]  attempt_local1587674715_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:04  [ localfetcher#10:45122 ] - [ INFO ]  localfetcher#10 about to shuffle output of map attempt_local1587674715_0010_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:37:04  [ localfetcher#10:45122 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local1587674715_0010_m_000000_0
2020-11-20 13:37:04  [ localfetcher#10:45122 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:37:04  [ EventFetcher for fetching Map Completion Events:45122 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:04  [ pool-33-thread-1:45123 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:04  [ pool-33-thread-1:45123 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:04  [ pool-33-thread-1:45123 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:37:04  [ pool-33-thread-1:45124 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:04  [ pool-33-thread-1:45238 ] - [ INFO ]  Task:attempt_local1587674715_0010_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:04  [ pool-33-thread-1:45247 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:04  [ pool-33-thread-1:45247 ] - [ INFO ]  Task attempt_local1587674715_0010_r_000000_0 is allowed to commit now
2020-11-20 13:37:04  [ pool-33-thread-1:45272 ] - [ INFO ]  Saved output of task 'attempt_local1587674715_0010_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1587674715_0010_r_000000
2020-11-20 13:37:04  [ pool-33-thread-1:45272 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:04  [ pool-33-thread-1:45272 ] - [ INFO ]  Task 'attempt_local1587674715_0010_r_000000_0' done.
2020-11-20 13:37:04  [ pool-33-thread-1:45272 ] - [ INFO ]  Finishing task: attempt_local1587674715_0010_r_000000_0
2020-11-20 13:37:04  [ Thread-260:45272 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:05  [ main:46032 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:05  [ main:46033 ] - [ INFO ]  Job job_local1587674715_0010 completed successfully
2020-11-20 13:37:05  [ main:46034 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=12818
		FILE: Number of bytes written=6219959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=11588742
		HDFS: Number of bytes written=3586
		HDFS: Number of read operations=280
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=145
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1187
		Map output materialized bytes=225
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=225
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2141192192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:05  [ main:46062 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:05  [ main:46077 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:05  [ main:46081 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:05  [ main:46091 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:05  [ main:46131 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:05  [ main:46148 ] - [ INFO ]  Submitting tokens for job: job_local581132737_0011
2020-11-20 13:37:05  [ main:46184 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:05  [ main:46184 ] - [ INFO ]  Running job: job_local581132737_0011
2020-11-20 13:37:05  [ Thread-287:46184 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:05  [ Thread-287:46185 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:05  [ Thread-287:46185 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:05  [ Thread-287:46194 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46194 ] - [ INFO ]  Starting task: attempt_local581132737_0011_m_000000_0
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46195 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46195 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46195 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46195 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46203 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46203 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46203 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46203 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46203 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:05  [ LocalJobRunner Map Task Executor #0:46204 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:06  [ main:47189 ] - [ INFO ]  Job job_local581132737_0011 running in uber mode : false
2020-11-20 13:37:06  [ main:47189 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49332 ] - [ INFO ]  
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49333 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49333 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49333 ] - [ INFO ]  bufstart = 0; bufend = 1191; bufvoid = 104857600
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49333 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49334 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49336 ] - [ INFO ]  Task:attempt_local581132737_0011_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49345 ] - [ INFO ]  map
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49345 ] - [ INFO ]  Task 'attempt_local581132737_0011_m_000000_0' done.
2020-11-20 13:37:08  [ LocalJobRunner Map Task Executor #0:49345 ] - [ INFO ]  Finishing task: attempt_local581132737_0011_m_000000_0
2020-11-20 13:37:08  [ Thread-287:49345 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:08  [ Thread-287:49346 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:08  [ pool-36-thread-1:49346 ] - [ INFO ]  Starting task: attempt_local581132737_0011_r_000000_0
2020-11-20 13:37:08  [ pool-36-thread-1:49346 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:08  [ pool-36-thread-1:49347 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:08  [ pool-36-thread-1:49347 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:08  [ pool-36-thread-1:49347 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@694420cb
2020-11-20 13:37:08  [ pool-36-thread-1:49348 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:08  [ EventFetcher for fetching Map Completion Events:49348 ] - [ INFO ]  attempt_local581132737_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:08  [ localfetcher#11:49349 ] - [ INFO ]  localfetcher#11 about to shuffle output of map attempt_local581132737_0011_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:37:08  [ localfetcher#11:49350 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local581132737_0011_m_000000_0
2020-11-20 13:37:08  [ localfetcher#11:49350 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:37:08  [ EventFetcher for fetching Map Completion Events:49350 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:08  [ pool-36-thread-1:49350 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:08  [ pool-36-thread-1:49350 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:08  [ pool-36-thread-1:49351 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:08  [ pool-36-thread-1:49351 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:37:08  [ pool-36-thread-1:49352 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:08  [ pool-36-thread-1:49352 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:37:08  [ pool-36-thread-1:49352 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:08  [ pool-36-thread-1:49352 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:08  [ pool-36-thread-1:49352 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:37:08  [ pool-36-thread-1:49352 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:08  [ pool-36-thread-1:49462 ] - [ INFO ]  Task:attempt_local581132737_0011_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:08  [ pool-36-thread-1:49472 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:08  [ pool-36-thread-1:49472 ] - [ INFO ]  Task attempt_local581132737_0011_r_000000_0 is allowed to commit now
2020-11-20 13:37:08  [ pool-36-thread-1:49498 ] - [ INFO ]  Saved output of task 'attempt_local581132737_0011_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local581132737_0011_r_000000
2020-11-20 13:37:08  [ pool-36-thread-1:49499 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:08  [ pool-36-thread-1:49499 ] - [ INFO ]  Task 'attempt_local581132737_0011_r_000000_0' done.
2020-11-20 13:37:08  [ pool-36-thread-1:49499 ] - [ INFO ]  Finishing task: attempt_local581132737_0011_r_000000_0
2020-11-20 13:37:08  [ Thread-287:49499 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:09  [ main:50199 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:09  [ main:50199 ] - [ INFO ]  Job job_local581132737_0011 completed successfully
2020-11-20 13:37:09  [ main:50201 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=14158
		FILE: Number of bytes written=6817370
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=12642264
		HDFS: Number of bytes written=4013
		HDFS: Number of read operations=310
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=161
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1191
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2141192192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:09  [ main:50228 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:09  [ main:50243 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:09  [ main:50247 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:09  [ main:50257 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:09  [ main:50301 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:09  [ main:50320 ] - [ INFO ]  Submitting tokens for job: job_local922771699_0012
2020-11-20 13:37:09  [ main:50365 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:09  [ main:50365 ] - [ INFO ]  Running job: job_local922771699_0012
2020-11-20 13:37:09  [ Thread-314:50365 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:09  [ Thread-314:50365 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:09  [ Thread-314:50365 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:09  [ Thread-314:50377 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50377 ] - [ INFO ]  Starting task: attempt_local922771699_0012_m_000000_0
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50378 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50378 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50378 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50379 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50420 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50420 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50420 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50420 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50420 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:09  [ LocalJobRunner Map Task Executor #0:50420 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:10  [ main:51365 ] - [ INFO ]  Job job_local922771699_0012 running in uber mode : false
2020-11-20 13:37:10  [ main:51366 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53449 ] - [ INFO ]  
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53450 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53450 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53450 ] - [ INFO ]  bufstart = 0; bufend = 1197; bufvoid = 104857600
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53450 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53451 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53452 ] - [ INFO ]  Task:attempt_local922771699_0012_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53671 ] - [ INFO ]  map
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53671 ] - [ INFO ]  Task 'attempt_local922771699_0012_m_000000_0' done.
2020-11-20 13:37:12  [ LocalJobRunner Map Task Executor #0:53671 ] - [ INFO ]  Finishing task: attempt_local922771699_0012_m_000000_0
2020-11-20 13:37:12  [ Thread-314:53671 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:12  [ Thread-314:53672 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:12  [ pool-39-thread-1:53672 ] - [ INFO ]  Starting task: attempt_local922771699_0012_r_000000_0
2020-11-20 13:37:12  [ pool-39-thread-1:53672 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:12  [ pool-39-thread-1:53673 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:12  [ pool-39-thread-1:53673 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:12  [ pool-39-thread-1:53673 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b8a90e
2020-11-20 13:37:12  [ pool-39-thread-1:53673 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:12  [ EventFetcher for fetching Map Completion Events:53673 ] - [ INFO ]  attempt_local922771699_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:12  [ localfetcher#12:53674 ] - [ INFO ]  localfetcher#12 about to shuffle output of map attempt_local922771699_0012_m_000000_0 decomp: 222 len: 226 to MEMORY
2020-11-20 13:37:12  [ localfetcher#12:53674 ] - [ INFO ]  Read 222 bytes from map-output for attempt_local922771699_0012_m_000000_0
2020-11-20 13:37:12  [ localfetcher#12:53674 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 222, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->222
2020-11-20 13:37:12  [ EventFetcher for fetching Map Completion Events:53675 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:12  [ pool-39-thread-1:53675 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:12  [ pool-39-thread-1:53675 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:12  [ pool-39-thread-1:53676 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:12  [ pool-39-thread-1:53676 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:12  [ pool-39-thread-1:53677 ] - [ INFO ]  Merged 1 segments, 222 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:12  [ pool-39-thread-1:53677 ] - [ INFO ]  Merging 1 files, 226 bytes from disk
2020-11-20 13:37:12  [ pool-39-thread-1:53677 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:12  [ pool-39-thread-1:53677 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:12  [ pool-39-thread-1:53677 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:12  [ pool-39-thread-1:53677 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:12  [ pool-39-thread-1:53784 ] - [ INFO ]  Task:attempt_local922771699_0012_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:12  [ pool-39-thread-1:53792 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:12  [ pool-39-thread-1:53793 ] - [ INFO ]  Task attempt_local922771699_0012_r_000000_0 is allowed to commit now
2020-11-20 13:37:12  [ pool-39-thread-1:53816 ] - [ INFO ]  Saved output of task 'attempt_local922771699_0012_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local922771699_0012_r_000000
2020-11-20 13:37:12  [ pool-39-thread-1:53816 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:12  [ pool-39-thread-1:53816 ] - [ INFO ]  Task 'attempt_local922771699_0012_r_000000_0' done.
2020-11-20 13:37:12  [ pool-39-thread-1:53816 ] - [ INFO ]  Finishing task: attempt_local922771699_0012_r_000000_0
2020-11-20 13:37:12  [ Thread-314:53816 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:13  [ main:54376 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:13  [ main:54376 ] - [ INFO ]  Job job_local922771699_0012 completed successfully
2020-11-20 13:37:13  [ main:54377 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=15500
		FILE: Number of bytes written=7424590
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13695786
		HDFS: Number of bytes written=4441
		HDFS: Number of read operations=340
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=177
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1197
		Map output materialized bytes=226
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=226
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=2222981120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:13  [ main:54403 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:13  [ main:54419 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:13  [ main:54423 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:13  [ main:54433 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:13  [ main:54478 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:13  [ main:54496 ] - [ INFO ]  Submitting tokens for job: job_local1633121325_0013
2020-11-20 13:37:13  [ main:54533 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:13  [ main:54533 ] - [ INFO ]  Running job: job_local1633121325_0013
2020-11-20 13:37:13  [ Thread-341:54533 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:13  [ Thread-341:54533 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:13  [ Thread-341:54533 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:13  [ Thread-341:54545 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54545 ] - [ INFO ]  Starting task: attempt_local1633121325_0013_m_000000_0
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54545 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54546 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54546 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54546 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54554 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54555 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54555 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54555 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54555 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:13  [ LocalJobRunner Map Task Executor #0:54555 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:14  [ main:55537 ] - [ INFO ]  Job job_local1633121325_0013 running in uber mode : false
2020-11-20 13:37:14  [ main:55537 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57591 ] - [ INFO ]  
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57591 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57591 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57591 ] - [ INFO ]  bufstart = 0; bufend = 1182; bufvoid = 104857600
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57591 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57593 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57594 ] - [ INFO ]  Task:attempt_local1633121325_0013_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57603 ] - [ INFO ]  map
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57603 ] - [ INFO ]  Task 'attempt_local1633121325_0013_m_000000_0' done.
2020-11-20 13:37:16  [ LocalJobRunner Map Task Executor #0:57603 ] - [ INFO ]  Finishing task: attempt_local1633121325_0013_m_000000_0
2020-11-20 13:37:16  [ Thread-341:57603 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:16  [ Thread-341:57603 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:16  [ pool-42-thread-1:57603 ] - [ INFO ]  Starting task: attempt_local1633121325_0013_r_000000_0
2020-11-20 13:37:16  [ pool-42-thread-1:57604 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:16  [ pool-42-thread-1:57604 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:16  [ pool-42-thread-1:57604 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:16  [ pool-42-thread-1:57604 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69d6880c
2020-11-20 13:37:16  [ pool-42-thread-1:57604 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:16  [ EventFetcher for fetching Map Completion Events:57604 ] - [ INFO ]  attempt_local1633121325_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:16  [ localfetcher#13:57605 ] - [ INFO ]  localfetcher#13 about to shuffle output of map attempt_local1633121325_0013_m_000000_0 decomp: 202 len: 206 to MEMORY
2020-11-20 13:37:16  [ localfetcher#13:57605 ] - [ INFO ]  Read 202 bytes from map-output for attempt_local1633121325_0013_m_000000_0
2020-11-20 13:37:16  [ localfetcher#13:57605 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 202, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->202
2020-11-20 13:37:16  [ EventFetcher for fetching Map Completion Events:57606 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:16  [ pool-42-thread-1:57606 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:16  [ pool-42-thread-1:57606 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 196 bytes
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Merged 1 segments, 202 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Merging 1 files, 206 bytes from disk
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 196 bytes
2020-11-20 13:37:16  [ pool-42-thread-1:57607 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:16  [ pool-42-thread-1:57708 ] - [ INFO ]  Task:attempt_local1633121325_0013_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:16  [ pool-42-thread-1:57716 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:16  [ pool-42-thread-1:57716 ] - [ INFO ]  Task attempt_local1633121325_0013_r_000000_0 is allowed to commit now
2020-11-20 13:37:16  [ pool-42-thread-1:57741 ] - [ INFO ]  Saved output of task 'attempt_local1633121325_0013_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1633121325_0013_r_000000
2020-11-20 13:37:16  [ pool-42-thread-1:57741 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:16  [ pool-42-thread-1:57741 ] - [ INFO ]  Task 'attempt_local1633121325_0013_r_000000_0' done.
2020-11-20 13:37:16  [ pool-42-thread-1:57741 ] - [ INFO ]  Finishing task: attempt_local1633121325_0013_r_000000_0
2020-11-20 13:37:16  [ Thread-341:57741 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:17  [ main:58548 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:17  [ main:58548 ] - [ INFO ]  Job job_local1633121325_0013 completed successfully
2020-11-20 13:37:17  [ main:58549 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=16806
		FILE: Number of bytes written=8035532
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=14749308
		HDFS: Number of bytes written=4851
		HDFS: Number of read operations=370
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=193
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1182
		Map output materialized bytes=206
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=206
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2222981120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:17  [ main:58577 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:17  [ main:58589 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:17  [ main:58593 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:17  [ main:58601 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:17  [ main:58642 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:17  [ main:58660 ] - [ INFO ]  Submitting tokens for job: job_local1575181135_0014
2020-11-20 13:37:17  [ main:58698 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:17  [ main:58698 ] - [ INFO ]  Running job: job_local1575181135_0014
2020-11-20 13:37:17  [ Thread-368:58698 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:17  [ Thread-368:58698 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:17  [ Thread-368:58698 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:17  [ Thread-368:58708 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58708 ] - [ INFO ]  Starting task: attempt_local1575181135_0014_m_000000_0
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58708 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58709 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58709 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58709 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58725 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58725 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58725 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58725 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58725 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:17  [ LocalJobRunner Map Task Executor #0:58725 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:18  [ main:59699 ] - [ INFO ]  Job job_local1575181135_0014 running in uber mode : false
2020-11-20 13:37:18  [ main:59699 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61751 ] - [ INFO ]  
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61751 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61751 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61751 ] - [ INFO ]  bufstart = 0; bufend = 1195; bufvoid = 104857600
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61751 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61753 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61754 ] - [ INFO ]  Task:attempt_local1575181135_0014_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61762 ] - [ INFO ]  map
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61763 ] - [ INFO ]  Task 'attempt_local1575181135_0014_m_000000_0' done.
2020-11-20 13:37:20  [ LocalJobRunner Map Task Executor #0:61763 ] - [ INFO ]  Finishing task: attempt_local1575181135_0014_m_000000_0
2020-11-20 13:37:20  [ Thread-368:61763 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:20  [ Thread-368:61763 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:20  [ pool-45-thread-1:61764 ] - [ INFO ]  Starting task: attempt_local1575181135_0014_r_000000_0
2020-11-20 13:37:20  [ pool-45-thread-1:61764 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:20  [ pool-45-thread-1:61764 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:20  [ pool-45-thread-1:61764 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:20  [ pool-45-thread-1:61764 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@722cec13
2020-11-20 13:37:20  [ pool-45-thread-1:61766 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:20  [ EventFetcher for fetching Map Completion Events:61766 ] - [ INFO ]  attempt_local1575181135_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:20  [ localfetcher#14:61767 ] - [ INFO ]  localfetcher#14 about to shuffle output of map attempt_local1575181135_0014_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:37:20  [ localfetcher#14:61767 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local1575181135_0014_m_000000_0
2020-11-20 13:37:20  [ localfetcher#14:61767 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:37:20  [ EventFetcher for fetching Map Completion Events:61767 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:20  [ pool-45-thread-1:61768 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:20  [ pool-45-thread-1:61768 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:20  [ pool-45-thread-1:61768 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:20  [ pool-45-thread-1:61768 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:37:20  [ pool-45-thread-1:61769 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:20  [ pool-45-thread-1:61769 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:37:20  [ pool-45-thread-1:61769 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:20  [ pool-45-thread-1:61769 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:20  [ pool-45-thread-1:61769 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:37:20  [ pool-45-thread-1:61769 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:21  [ pool-45-thread-1:62146 ] - [ INFO ]  Task:attempt_local1575181135_0014_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:21  [ pool-45-thread-1:62154 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:21  [ pool-45-thread-1:62154 ] - [ INFO ]  Task attempt_local1575181135_0014_r_000000_0 is allowed to commit now
2020-11-20 13:37:21  [ pool-45-thread-1:62181 ] - [ INFO ]  Saved output of task 'attempt_local1575181135_0014_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1575181135_0014_r_000000
2020-11-20 13:37:21  [ pool-45-thread-1:62182 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:21  [ pool-45-thread-1:62182 ] - [ INFO ]  Task 'attempt_local1575181135_0014_r_000000_0' done.
2020-11-20 13:37:21  [ pool-45-thread-1:62182 ] - [ INFO ]  Finishing task: attempt_local1575181135_0014_r_000000_0
2020-11-20 13:37:21  [ Thread-368:62182 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:21  [ main:62706 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:21  [ main:62707 ] - [ INFO ]  Job job_local1575181135_0014 completed successfully
2020-11-20 13:37:21  [ main:62708 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=18110
		FILE: Number of bytes written=8647859
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=15802830
		HDFS: Number of bytes written=5260
		HDFS: Number of read operations=400
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=209
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1195
		Map output materialized bytes=225
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=225
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2222981120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:21  [ main:62734 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:21  [ main:62747 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:21  [ main:62751 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:21  [ main:62761 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:21  [ main:62799 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:21  [ main:62817 ] - [ INFO ]  Submitting tokens for job: job_local1837267774_0015
2020-11-20 13:37:21  [ main:62854 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:21  [ main:62854 ] - [ INFO ]  Running job: job_local1837267774_0015
2020-11-20 13:37:21  [ Thread-395:62854 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:21  [ Thread-395:62854 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:21  [ Thread-395:62854 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:21  [ Thread-395:62864 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62864 ] - [ INFO ]  Starting task: attempt_local1837267774_0015_m_000000_0
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62864 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62865 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62865 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62865 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62876 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62876 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62876 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62876 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62876 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:21  [ LocalJobRunner Map Task Executor #0:62876 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:22  [ main:63859 ] - [ INFO ]  Job job_local1837267774_0015 running in uber mode : false
2020-11-20 13:37:22  [ main:63859 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65887 ] - [ INFO ]  
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65887 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65887 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65887 ] - [ INFO ]  bufstart = 0; bufend = 1185; bufvoid = 104857600
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65887 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65889 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65890 ] - [ INFO ]  Task:attempt_local1837267774_0015_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65898 ] - [ INFO ]  map
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65898 ] - [ INFO ]  Task 'attempt_local1837267774_0015_m_000000_0' done.
2020-11-20 13:37:24  [ LocalJobRunner Map Task Executor #0:65898 ] - [ INFO ]  Finishing task: attempt_local1837267774_0015_m_000000_0
2020-11-20 13:37:24  [ Thread-395:65899 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:24  [ Thread-395:65899 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:24  [ pool-48-thread-1:65899 ] - [ INFO ]  Starting task: attempt_local1837267774_0015_r_000000_0
2020-11-20 13:37:24  [ pool-48-thread-1:65900 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:24  [ pool-48-thread-1:65900 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:24  [ pool-48-thread-1:65900 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:24  [ pool-48-thread-1:65900 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26c57e95
2020-11-20 13:37:24  [ pool-48-thread-1:65901 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:24  [ EventFetcher for fetching Map Completion Events:65901 ] - [ INFO ]  attempt_local1837267774_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:24  [ localfetcher#15:65902 ] - [ INFO ]  localfetcher#15 about to shuffle output of map attempt_local1837267774_0015_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:37:24  [ localfetcher#15:65902 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local1837267774_0015_m_000000_0
2020-11-20 13:37:24  [ localfetcher#15:65902 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:37:24  [ EventFetcher for fetching Map Completion Events:65902 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:24  [ pool-48-thread-1:65903 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:24  [ pool-48-thread-1:65903 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:24  [ pool-48-thread-1:65904 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:37:24  [ pool-48-thread-1:65905 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:24  [ pool-48-thread-1:66020 ] - [ INFO ]  Task:attempt_local1837267774_0015_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:25  [ pool-48-thread-1:66030 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:25  [ pool-48-thread-1:66030 ] - [ INFO ]  Task attempt_local1837267774_0015_r_000000_0 is allowed to commit now
2020-11-20 13:37:25  [ pool-48-thread-1:66056 ] - [ INFO ]  Saved output of task 'attempt_local1837267774_0015_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1837267774_0015_r_000000
2020-11-20 13:37:25  [ pool-48-thread-1:66057 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:25  [ pool-48-thread-1:66057 ] - [ INFO ]  Task 'attempt_local1837267774_0015_r_000000_0' done.
2020-11-20 13:37:25  [ pool-48-thread-1:66057 ] - [ INFO ]  Finishing task: attempt_local1837267774_0015_r_000000_0
2020-11-20 13:37:25  [ Thread-395:66057 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:25  [ main:66862 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:25  [ main:66863 ] - [ INFO ]  Job job_local1837267774_0015 completed successfully
2020-11-20 13:37:25  [ main:66864 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=19444
		FILE: Number of bytes written=9261065
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=16856352
		HDFS: Number of bytes written=5684
		HDFS: Number of read operations=430
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=225
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1185
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:25  [ main:66891 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:25  [ main:66906 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:25  [ main:66911 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:25  [ main:66919 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:25  [ main:66961 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:25  [ main:66978 ] - [ INFO ]  Submitting tokens for job: job_local290499783_0016
2020-11-20 13:37:25  [ main:67014 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:25  [ main:67015 ] - [ INFO ]  Running job: job_local290499783_0016
2020-11-20 13:37:25  [ Thread-422:67015 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:25  [ Thread-422:67015 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:25  [ Thread-422:67015 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:26  [ Thread-422:67028 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67028 ] - [ INFO ]  Starting task: attempt_local290499783_0016_m_000000_0
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67028 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67028 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67029 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67030 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67039 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67039 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67039 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67039 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67039 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:26  [ LocalJobRunner Map Task Executor #0:67039 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:26  [ main:68015 ] - [ INFO ]  Job job_local290499783_0016 running in uber mode : false
2020-11-20 13:37:26  [ main:68015 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70045 ] - [ INFO ]  
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70046 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70046 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70046 ] - [ INFO ]  bufstart = 0; bufend = 1203; bufvoid = 104857600
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70046 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70048 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70049 ] - [ INFO ]  Task:attempt_local290499783_0016_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70058 ] - [ INFO ]  map
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70058 ] - [ INFO ]  Task 'attempt_local290499783_0016_m_000000_0' done.
2020-11-20 13:37:29  [ LocalJobRunner Map Task Executor #0:70058 ] - [ INFO ]  Finishing task: attempt_local290499783_0016_m_000000_0
2020-11-20 13:37:29  [ Thread-422:70058 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:29  [ Thread-422:70058 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:29  [ pool-51-thread-1:70058 ] - [ INFO ]  Starting task: attempt_local290499783_0016_r_000000_0
2020-11-20 13:37:29  [ pool-51-thread-1:70059 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:29  [ pool-51-thread-1:70059 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:29  [ pool-51-thread-1:70059 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:29  [ pool-51-thread-1:70059 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56a417df
2020-11-20 13:37:29  [ pool-51-thread-1:70060 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:29  [ EventFetcher for fetching Map Completion Events:70060 ] - [ INFO ]  attempt_local290499783_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:29  [ localfetcher#16:70060 ] - [ INFO ]  localfetcher#16 about to shuffle output of map attempt_local290499783_0016_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:37:29  [ localfetcher#16:70061 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local290499783_0016_m_000000_0
2020-11-20 13:37:29  [ localfetcher#16:70061 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:37:29  [ EventFetcher for fetching Map Completion Events:70061 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:29  [ pool-51-thread-1:70061 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:29  [ pool-51-thread-1:70061 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:29  [ pool-51-thread-1:70062 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:29  [ pool-51-thread-1:70062 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:37:29  [ pool-51-thread-1:70062 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:29  [ pool-51-thread-1:70062 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:37:29  [ pool-51-thread-1:70062 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:29  [ pool-51-thread-1:70062 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:29  [ pool-51-thread-1:70063 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:37:29  [ pool-51-thread-1:70063 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:29  [ pool-51-thread-1:70175 ] - [ INFO ]  Task:attempt_local290499783_0016_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:29  [ pool-51-thread-1:70183 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:29  [ pool-51-thread-1:70183 ] - [ INFO ]  Task attempt_local290499783_0016_r_000000_0 is allowed to commit now
2020-11-20 13:37:29  [ pool-51-thread-1:70210 ] - [ INFO ]  Saved output of task 'attempt_local290499783_0016_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local290499783_0016_r_000000
2020-11-20 13:37:29  [ pool-51-thread-1:70210 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:29  [ pool-51-thread-1:70210 ] - [ INFO ]  Task 'attempt_local290499783_0016_r_000000_0' done.
2020-11-20 13:37:29  [ pool-51-thread-1:70210 ] - [ INFO ]  Finishing task: attempt_local290499783_0016_r_000000_0
2020-11-20 13:37:29  [ Thread-422:70210 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:29  [ main:71021 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:29  [ main:71021 ] - [ INFO ]  Job job_local290499783_0016 completed successfully
2020-11-20 13:37:29  [ main:71023 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=20776
		FILE: Number of bytes written=9871320
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17909874
		HDFS: Number of bytes written=6107
		HDFS: Number of read operations=460
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=241
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1203
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:30  [ main:71049 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:30  [ main:71063 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:30  [ main:71067 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:30  [ main:71075 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:30  [ main:71115 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:30  [ main:71132 ] - [ INFO ]  Submitting tokens for job: job_local863950306_0017
2020-11-20 13:37:30  [ main:71167 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:30  [ main:71167 ] - [ INFO ]  Running job: job_local863950306_0017
2020-11-20 13:37:30  [ Thread-449:71167 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:30  [ Thread-449:71168 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:30  [ Thread-449:71168 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:30  [ Thread-449:71178 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71179 ] - [ INFO ]  Starting task: attempt_local863950306_0017_m_000000_0
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71179 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71179 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71179 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71180 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71195 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71195 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71195 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71195 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71195 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:30  [ LocalJobRunner Map Task Executor #0:71195 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:31  [ main:72171 ] - [ INFO ]  Job job_local863950306_0017 running in uber mode : false
2020-11-20 13:37:31  [ main:72172 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74303 ] - [ INFO ]  
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74303 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74303 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74303 ] - [ INFO ]  bufstart = 0; bufend = 1202; bufvoid = 104857600
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74303 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74305 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74306 ] - [ INFO ]  Task:attempt_local863950306_0017_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74315 ] - [ INFO ]  map
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74315 ] - [ INFO ]  Task 'attempt_local863950306_0017_m_000000_0' done.
2020-11-20 13:37:33  [ LocalJobRunner Map Task Executor #0:74315 ] - [ INFO ]  Finishing task: attempt_local863950306_0017_m_000000_0
2020-11-20 13:37:33  [ Thread-449:74315 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:33  [ Thread-449:74315 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:33  [ pool-54-thread-1:74315 ] - [ INFO ]  Starting task: attempt_local863950306_0017_r_000000_0
2020-11-20 13:37:33  [ pool-54-thread-1:74316 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:33  [ pool-54-thread-1:74316 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:33  [ pool-54-thread-1:74316 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:33  [ pool-54-thread-1:74316 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@62f4bb90
2020-11-20 13:37:33  [ pool-54-thread-1:74318 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:33  [ EventFetcher for fetching Map Completion Events:74318 ] - [ INFO ]  attempt_local863950306_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:33  [ localfetcher#17:74318 ] - [ INFO ]  localfetcher#17 about to shuffle output of map attempt_local863950306_0017_m_000000_0 decomp: 219 len: 223 to MEMORY
2020-11-20 13:37:33  [ localfetcher#17:74319 ] - [ INFO ]  Read 219 bytes from map-output for attempt_local863950306_0017_m_000000_0
2020-11-20 13:37:33  [ localfetcher#17:74319 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 219, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->219
2020-11-20 13:37:33  [ EventFetcher for fetching Map Completion Events:74319 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:33  [ pool-54-thread-1:74319 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:33  [ pool-54-thread-1:74319 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:33  [ pool-54-thread-1:74320 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:33  [ pool-54-thread-1:74320 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:37:33  [ pool-54-thread-1:74320 ] - [ INFO ]  Merged 1 segments, 219 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:33  [ pool-54-thread-1:74321 ] - [ INFO ]  Merging 1 files, 223 bytes from disk
2020-11-20 13:37:33  [ pool-54-thread-1:74321 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:33  [ pool-54-thread-1:74321 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:33  [ pool-54-thread-1:74321 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:37:33  [ pool-54-thread-1:74321 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:33  [ pool-54-thread-1:74420 ] - [ INFO ]  Task:attempt_local863950306_0017_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:33  [ pool-54-thread-1:74429 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:33  [ pool-54-thread-1:74429 ] - [ INFO ]  Task attempt_local863950306_0017_r_000000_0 is allowed to commit now
2020-11-20 13:37:33  [ pool-54-thread-1:74455 ] - [ INFO ]  Saved output of task 'attempt_local863950306_0017_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local863950306_0017_r_000000
2020-11-20 13:37:33  [ pool-54-thread-1:74455 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:33  [ pool-54-thread-1:74456 ] - [ INFO ]  Task 'attempt_local863950306_0017_r_000000_0' done.
2020-11-20 13:37:33  [ pool-54-thread-1:74456 ] - [ INFO ]  Finishing task: attempt_local863950306_0017_r_000000_0
2020-11-20 13:37:33  [ Thread-449:74456 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:34  [ main:75177 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:34  [ main:75178 ] - [ INFO ]  Job job_local863950306_0017 completed successfully
2020-11-20 13:37:34  [ main:75179 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=22112
		FILE: Number of bytes written=10483767
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=18963396
		HDFS: Number of bytes written=6532
		HDFS: Number of read operations=490
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=257
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1202
		Map output materialized bytes=223
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=223
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2691694592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:34  [ main:75205 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:34  [ main:75220 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:34  [ main:75224 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:34  [ main:75233 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:34  [ main:75274 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:34  [ main:75293 ] - [ INFO ]  Submitting tokens for job: job_local1606325865_0018
2020-11-20 13:37:34  [ main:75336 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:34  [ main:75337 ] - [ INFO ]  Running job: job_local1606325865_0018
2020-11-20 13:37:34  [ Thread-476:75337 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:34  [ Thread-476:75337 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:34  [ Thread-476:75337 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:34  [ Thread-476:75349 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75349 ] - [ INFO ]  Starting task: attempt_local1606325865_0018_m_000000_0
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75349 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75350 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75350 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75350 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75392 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75392 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75392 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75392 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75392 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:34  [ LocalJobRunner Map Task Executor #0:75393 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:35  [ main:76339 ] - [ INFO ]  Job job_local1606325865_0018 running in uber mode : false
2020-11-20 13:37:35  [ main:76339 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78343 ] - [ INFO ]  
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78344 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78344 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78344 ] - [ INFO ]  bufstart = 0; bufend = 1183; bufvoid = 104857600
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78344 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78345 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78346 ] - [ INFO ]  Task:attempt_local1606325865_0018_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78355 ] - [ INFO ]  map
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78355 ] - [ INFO ]  Task 'attempt_local1606325865_0018_m_000000_0' done.
2020-11-20 13:37:37  [ LocalJobRunner Map Task Executor #0:78355 ] - [ INFO ]  Finishing task: attempt_local1606325865_0018_m_000000_0
2020-11-20 13:37:37  [ Thread-476:78355 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:37  [ Thread-476:78356 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:37  [ pool-57-thread-1:78356 ] - [ INFO ]  Starting task: attempt_local1606325865_0018_r_000000_0
2020-11-20 13:37:37  [ pool-57-thread-1:78356 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:37  [ pool-57-thread-1:78356 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:37  [ pool-57-thread-1:78356 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:37  [ pool-57-thread-1:78357 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560b7913
2020-11-20 13:37:37  [ pool-57-thread-1:78357 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:37  [ EventFetcher for fetching Map Completion Events:78357 ] - [ INFO ]  attempt_local1606325865_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:37  [ localfetcher#18:78358 ] - [ INFO ]  localfetcher#18 about to shuffle output of map attempt_local1606325865_0018_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:37:37  [ localfetcher#18:78358 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local1606325865_0018_m_000000_0
2020-11-20 13:37:37  [ localfetcher#18:78358 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:37:37  [ EventFetcher for fetching Map Completion Events:78358 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:37  [ pool-57-thread-1:78359 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:37  [ pool-57-thread-1:78359 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:37  [ pool-57-thread-1:78360 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:37:37  [ pool-57-thread-1:78361 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:37  [ pool-57-thread-1:78466 ] - [ INFO ]  Task:attempt_local1606325865_0018_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:37  [ pool-57-thread-1:78475 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:37  [ pool-57-thread-1:78475 ] - [ INFO ]  Task attempt_local1606325865_0018_r_000000_0 is allowed to commit now
2020-11-20 13:37:37  [ pool-57-thread-1:78502 ] - [ INFO ]  Saved output of task 'attempt_local1606325865_0018_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1606325865_0018_r_000000
2020-11-20 13:37:37  [ pool-57-thread-1:78503 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:37  [ pool-57-thread-1:78503 ] - [ INFO ]  Task 'attempt_local1606325865_0018_r_000000_0' done.
2020-11-20 13:37:37  [ pool-57-thread-1:78503 ] - [ INFO ]  Finishing task: attempt_local1606325865_0018_r_000000_0
2020-11-20 13:37:37  [ Thread-476:78503 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:38  [ main:79347 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:38  [ main:79347 ] - [ INFO ]  Job job_local1606325865_0018 completed successfully
2020-11-20 13:37:38  [ main:79349 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=23450
		FILE: Number of bytes written=11099343
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=20016918
		HDFS: Number of bytes written=6958
		HDFS: Number of read operations=520
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=273
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1183
		Map output materialized bytes=225
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=225
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=48
		Total committed heap usage (bytes)=2771386368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:38  [ main:79381 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:38  [ main:79396 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:38  [ main:79400 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:38  [ main:79410 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:38  [ main:79452 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:38  [ main:79469 ] - [ INFO ]  Submitting tokens for job: job_local1132427269_0019
2020-11-20 13:37:38  [ main:79505 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:38  [ main:79505 ] - [ INFO ]  Running job: job_local1132427269_0019
2020-11-20 13:37:38  [ Thread-503:79505 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:38  [ Thread-503:79505 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:38  [ Thread-503:79505 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:38  [ Thread-503:79521 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79521 ] - [ INFO ]  Starting task: attempt_local1132427269_0019_m_000000_0
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79522 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79522 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79522 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79522 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79531 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79531 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79531 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79531 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79531 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:38  [ LocalJobRunner Map Task Executor #0:79531 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:39  [ main:80508 ] - [ INFO ]  Job job_local1132427269_0019 running in uber mode : false
2020-11-20 13:37:39  [ main:80508 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82523 ] - [ INFO ]  
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82523 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82523 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82523 ] - [ INFO ]  bufstart = 0; bufend = 1123; bufvoid = 104857600
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82523 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82525 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82526 ] - [ INFO ]  Task:attempt_local1132427269_0019_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82535 ] - [ INFO ]  map
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82535 ] - [ INFO ]  Task 'attempt_local1132427269_0019_m_000000_0' done.
2020-11-20 13:37:41  [ LocalJobRunner Map Task Executor #0:82535 ] - [ INFO ]  Finishing task: attempt_local1132427269_0019_m_000000_0
2020-11-20 13:37:41  [ Thread-503:82535 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:41  [ Thread-503:82535 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:41  [ pool-60-thread-1:82536 ] - [ INFO ]  Starting task: attempt_local1132427269_0019_r_000000_0
2020-11-20 13:37:41  [ pool-60-thread-1:82536 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:41  [ pool-60-thread-1:82536 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:41  [ pool-60-thread-1:82536 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:41  [ pool-60-thread-1:82536 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1683ff18
2020-11-20 13:37:41  [ pool-60-thread-1:82537 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:41  [ EventFetcher for fetching Map Completion Events:82537 ] - [ INFO ]  attempt_local1132427269_0019_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:41  [ localfetcher#19:82538 ] - [ INFO ]  localfetcher#19 about to shuffle output of map attempt_local1132427269_0019_m_000000_0 decomp: 226 len: 230 to MEMORY
2020-11-20 13:37:41  [ localfetcher#19:82538 ] - [ INFO ]  Read 226 bytes from map-output for attempt_local1132427269_0019_m_000000_0
2020-11-20 13:37:41  [ localfetcher#19:82538 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 226, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->226
2020-11-20 13:37:41  [ EventFetcher for fetching Map Completion Events:82538 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:41  [ pool-60-thread-1:82539 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:41  [ pool-60-thread-1:82539 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:41  [ pool-60-thread-1:82540 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:41  [ pool-60-thread-1:82540 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 221 bytes
2020-11-20 13:37:41  [ pool-60-thread-1:82540 ] - [ INFO ]  Merged 1 segments, 226 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:41  [ pool-60-thread-1:82540 ] - [ INFO ]  Merging 1 files, 230 bytes from disk
2020-11-20 13:37:41  [ pool-60-thread-1:82540 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:41  [ pool-60-thread-1:82540 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:41  [ pool-60-thread-1:82541 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 221 bytes
2020-11-20 13:37:41  [ pool-60-thread-1:82541 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:41  [ pool-60-thread-1:82634 ] - [ INFO ]  Task:attempt_local1132427269_0019_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:41  [ pool-60-thread-1:82643 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:41  [ pool-60-thread-1:82643 ] - [ INFO ]  Task attempt_local1132427269_0019_r_000000_0 is allowed to commit now
2020-11-20 13:37:41  [ pool-60-thread-1:82667 ] - [ INFO ]  Saved output of task 'attempt_local1132427269_0019_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1132427269_0019_r_000000
2020-11-20 13:37:41  [ pool-60-thread-1:82667 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:41  [ pool-60-thread-1:82667 ] - [ INFO ]  Task 'attempt_local1132427269_0019_r_000000_0' done.
2020-11-20 13:37:41  [ pool-60-thread-1:82667 ] - [ INFO ]  Finishing task: attempt_local1132427269_0019_r_000000_0
2020-11-20 13:37:41  [ Thread-503:82667 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:42  [ main:83516 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:42  [ main:83516 ] - [ INFO ]  Job job_local1132427269_0019 completed successfully
2020-11-20 13:37:42  [ main:83517 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=24802
		FILE: Number of bytes written=11677964
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=21070440
		HDFS: Number of bytes written=7391
		HDFS: Number of read operations=550
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=289
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1123
		Map output materialized bytes=230
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=230
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2771386368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:42  [ main:83550 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:42  [ main:83564 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:42  [ main:83569 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:42  [ main:83579 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:42  [ main:83618 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:42  [ main:83636 ] - [ INFO ]  Submitting tokens for job: job_local562618009_0020
2020-11-20 13:37:42  [ main:83672 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:42  [ main:83672 ] - [ INFO ]  Running job: job_local562618009_0020
2020-11-20 13:37:42  [ Thread-530:83673 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:42  [ Thread-530:83673 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:42  [ Thread-530:83673 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:42  [ Thread-530:83683 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83683 ] - [ INFO ]  Starting task: attempt_local562618009_0020_m_000000_0
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83684 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83684 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83684 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83684 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83692 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83692 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83692 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83692 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83692 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:42  [ LocalJobRunner Map Task Executor #0:83693 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:43  [ main:84676 ] - [ INFO ]  Job job_local562618009_0020 running in uber mode : false
2020-11-20 13:37:43  [ main:84676 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86694 ] - [ INFO ]  
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86695 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86695 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86695 ] - [ INFO ]  bufstart = 0; bufend = 1114; bufvoid = 104857600
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86695 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86696 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86697 ] - [ INFO ]  Task:attempt_local562618009_0020_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86707 ] - [ INFO ]  map
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86707 ] - [ INFO ]  Task 'attempt_local562618009_0020_m_000000_0' done.
2020-11-20 13:37:45  [ LocalJobRunner Map Task Executor #0:86707 ] - [ INFO ]  Finishing task: attempt_local562618009_0020_m_000000_0
2020-11-20 13:37:45  [ Thread-530:86707 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:45  [ Thread-530:86708 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:45  [ pool-63-thread-1:86708 ] - [ INFO ]  Starting task: attempt_local562618009_0020_r_000000_0
2020-11-20 13:37:45  [ pool-63-thread-1:86709 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:45  [ pool-63-thread-1:86709 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:45  [ pool-63-thread-1:86709 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:45  [ pool-63-thread-1:86709 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72e6e2d3
2020-11-20 13:37:45  [ pool-63-thread-1:86710 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:45  [ EventFetcher for fetching Map Completion Events:86710 ] - [ INFO ]  attempt_local562618009_0020_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:45  [ localfetcher#20:86711 ] - [ INFO ]  localfetcher#20 about to shuffle output of map attempt_local562618009_0020_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:37:45  [ localfetcher#20:86711 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local562618009_0020_m_000000_0
2020-11-20 13:37:45  [ localfetcher#20:86711 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:37:45  [ EventFetcher for fetching Map Completion Events:86712 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:45  [ pool-63-thread-1:86712 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:45  [ pool-63-thread-1:86712 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:45  [ pool-63-thread-1:86713 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:45  [ pool-63-thread-1:86713 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:45  [ pool-63-thread-1:86713 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:45  [ pool-63-thread-1:86713 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:37:45  [ pool-63-thread-1:86713 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:45  [ pool-63-thread-1:86713 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:45  [ pool-63-thread-1:86714 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:45  [ pool-63-thread-1:86714 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:45  [ pool-63-thread-1:86814 ] - [ INFO ]  Task:attempt_local562618009_0020_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:45  [ pool-63-thread-1:86823 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:45  [ pool-63-thread-1:86823 ] - [ INFO ]  Task attempt_local562618009_0020_r_000000_0 is allowed to commit now
2020-11-20 13:37:45  [ pool-63-thread-1:86848 ] - [ INFO ]  Saved output of task 'attempt_local562618009_0020_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local562618009_0020_r_000000
2020-11-20 13:37:45  [ pool-63-thread-1:86848 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:45  [ pool-63-thread-1:86849 ] - [ INFO ]  Task 'attempt_local562618009_0020_r_000000_0' done.
2020-11-20 13:37:45  [ pool-63-thread-1:86849 ] - [ INFO ]  Finishing task: attempt_local562618009_0020_r_000000_0
2020-11-20 13:37:45  [ Thread-530:86849 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:46  [ main:87682 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:46  [ main:87682 ] - [ INFO ]  Job job_local562618009_0020 completed successfully
2020-11-20 13:37:46  [ main:87684 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=26154
		FILE: Number of bytes written=12254647
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=22123962
		HDFS: Number of bytes written=7824
		HDFS: Number of read operations=580
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=305
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1114
		Map output materialized bytes=225
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=225
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2771386368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:46  [ main:87709 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:46  [ main:87723 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:46  [ main:87727 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:46  [ main:87735 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:46  [ main:87774 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:46  [ main:87791 ] - [ INFO ]  Submitting tokens for job: job_local2055103470_0021
2020-11-20 13:37:46  [ main:87826 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:46  [ main:87826 ] - [ INFO ]  Running job: job_local2055103470_0021
2020-11-20 13:37:46  [ Thread-557:87827 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:46  [ Thread-557:87827 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:46  [ Thread-557:87827 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:46  [ Thread-557:87837 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87838 ] - [ INFO ]  Starting task: attempt_local2055103470_0021_m_000000_0
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87838 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87838 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87838 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87839 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87857 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87857 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87857 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87857 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87857 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:46  [ LocalJobRunner Map Task Executor #0:87857 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:47  [ main:88828 ] - [ INFO ]  Job job_local2055103470_0021 running in uber mode : false
2020-11-20 13:37:47  [ main:88828 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91419 ] - [ INFO ]  
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91419 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91419 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91419 ] - [ INFO ]  bufstart = 0; bufend = 1167; bufvoid = 104857600
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91419 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91421 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91422 ] - [ INFO ]  Task:attempt_local2055103470_0021_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91431 ] - [ INFO ]  map
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91431 ] - [ INFO ]  Task 'attempt_local2055103470_0021_m_000000_0' done.
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91431 ] - [ INFO ]  Finishing task: attempt_local2055103470_0021_m_000000_0
2020-11-20 13:37:50  [ Thread-557:91432 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:50  [ Thread-557:91432 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:50  [ pool-66-thread-1:91432 ] - [ INFO ]  Starting task: attempt_local2055103470_0021_r_000000_0
2020-11-20 13:37:50  [ pool-66-thread-1:91432 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:50  [ pool-66-thread-1:91432 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:50  [ pool-66-thread-1:91433 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:50  [ pool-66-thread-1:91433 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@637c4cf4
2020-11-20 13:37:50  [ pool-66-thread-1:91433 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:50  [ EventFetcher for fetching Map Completion Events:91433 ] - [ INFO ]  attempt_local2055103470_0021_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:50  [ localfetcher#21:91434 ] - [ INFO ]  localfetcher#21 about to shuffle output of map attempt_local2055103470_0021_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:37:50  [ localfetcher#21:91434 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local2055103470_0021_m_000000_0
2020-11-20 13:37:50  [ localfetcher#21:91434 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:37:50  [ EventFetcher for fetching Map Completion Events:91434 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:50  [ pool-66-thread-1:91434 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:50  [ pool-66-thread-1:91435 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:50  [ pool-66-thread-1:91435 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:50  [ pool-66-thread-1:91435 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:50  [ pool-66-thread-1:91436 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:50  [ pool-66-thread-1:91436 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:37:50  [ pool-66-thread-1:91436 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:50  [ pool-66-thread-1:91436 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:50  [ pool-66-thread-1:91436 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:50  [ pool-66-thread-1:91436 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:50  [ pool-66-thread-1:91668 ] - [ INFO ]  Task:attempt_local2055103470_0021_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:50  [ pool-66-thread-1:91676 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:50  [ pool-66-thread-1:91677 ] - [ INFO ]  Task attempt_local2055103470_0021_r_000000_0 is allowed to commit now
2020-11-20 13:37:50  [ pool-66-thread-1:91702 ] - [ INFO ]  Saved output of task 'attempt_local2055103470_0021_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2055103470_0021_r_000000
2020-11-20 13:37:50  [ pool-66-thread-1:91703 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:50  [ pool-66-thread-1:91703 ] - [ INFO ]  Task 'attempt_local2055103470_0021_r_000000_0' done.
2020-11-20 13:37:50  [ pool-66-thread-1:91703 ] - [ INFO ]  Finishing task: attempt_local2055103470_0021_r_000000_0
2020-11-20 13:37:50  [ Thread-557:91703 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:50  [ main:91836 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:50  [ main:91836 ] - [ INFO ]  Job job_local2055103470_0021 completed successfully
2020-11-20 13:37:50  [ main:91837 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=27496
		FILE: Number of bytes written=12835385
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=23177484
		HDFS: Number of bytes written=8252
		HDFS: Number of read operations=610
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=321
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1167
		Map output materialized bytes=225
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=225
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2771386368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:50  [ main:91864 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:50  [ main:91877 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:50  [ main:91881 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:50  [ main:91890 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:50  [ main:91931 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:50  [ main:91948 ] - [ INFO ]  Submitting tokens for job: job_local862986929_0022
2020-11-20 13:37:50  [ main:91983 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:50  [ main:91983 ] - [ INFO ]  Running job: job_local862986929_0022
2020-11-20 13:37:50  [ Thread-584:91983 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:50  [ Thread-584:91983 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:50  [ Thread-584:91983 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:50  [ Thread-584:91993 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91993 ] - [ INFO ]  Starting task: attempt_local862986929_0022_m_000000_0
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91993 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91994 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91994 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:91994 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:92004 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:92004 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:92004 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:92004 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:92004 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:50  [ LocalJobRunner Map Task Executor #0:92005 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:51  [ main:92988 ] - [ INFO ]  Job job_local862986929_0022 running in uber mode : false
2020-11-20 13:37:51  [ main:92988 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95069 ] - [ INFO ]  
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95069 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95069 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95070 ] - [ INFO ]  bufstart = 0; bufend = 1156; bufvoid = 104857600
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95070 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95071 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95072 ] - [ INFO ]  Task:attempt_local862986929_0022_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95081 ] - [ INFO ]  map
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95081 ] - [ INFO ]  Task 'attempt_local862986929_0022_m_000000_0' done.
2020-11-20 13:37:54  [ LocalJobRunner Map Task Executor #0:95081 ] - [ INFO ]  Finishing task: attempt_local862986929_0022_m_000000_0
2020-11-20 13:37:54  [ Thread-584:95082 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:54  [ Thread-584:95082 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:54  [ pool-69-thread-1:95082 ] - [ INFO ]  Starting task: attempt_local862986929_0022_r_000000_0
2020-11-20 13:37:54  [ pool-69-thread-1:95083 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:54  [ pool-69-thread-1:95083 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:54  [ pool-69-thread-1:95083 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:54  [ pool-69-thread-1:95083 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@162c574f
2020-11-20 13:37:54  [ pool-69-thread-1:95083 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:54  [ EventFetcher for fetching Map Completion Events:95083 ] - [ INFO ]  attempt_local862986929_0022_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:54  [ localfetcher#22:95084 ] - [ INFO ]  localfetcher#22 about to shuffle output of map attempt_local862986929_0022_m_000000_0 decomp: 221 len: 225 to MEMORY
2020-11-20 13:37:54  [ localfetcher#22:95084 ] - [ INFO ]  Read 221 bytes from map-output for attempt_local862986929_0022_m_000000_0
2020-11-20 13:37:54  [ localfetcher#22:95084 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->221
2020-11-20 13:37:54  [ EventFetcher for fetching Map Completion Events:95085 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:54  [ pool-69-thread-1:95085 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:54  [ pool-69-thread-1:95085 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:54  [ pool-69-thread-1:95086 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:54  [ pool-69-thread-1:95086 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:54  [ pool-69-thread-1:95086 ] - [ INFO ]  Merged 1 segments, 221 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:54  [ pool-69-thread-1:95087 ] - [ INFO ]  Merging 1 files, 225 bytes from disk
2020-11-20 13:37:54  [ pool-69-thread-1:95087 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:54  [ pool-69-thread-1:95087 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:54  [ pool-69-thread-1:95087 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:37:54  [ pool-69-thread-1:95087 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:54  [ pool-69-thread-1:95189 ] - [ INFO ]  Task:attempt_local862986929_0022_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:54  [ pool-69-thread-1:95197 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:54  [ pool-69-thread-1:95197 ] - [ INFO ]  Task attempt_local862986929_0022_r_000000_0 is allowed to commit now
2020-11-20 13:37:54  [ pool-69-thread-1:95221 ] - [ INFO ]  Saved output of task 'attempt_local862986929_0022_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local862986929_0022_r_000000
2020-11-20 13:37:54  [ pool-69-thread-1:95222 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:54  [ pool-69-thread-1:95222 ] - [ INFO ]  Task 'attempt_local862986929_0022_r_000000_0' done.
2020-11-20 13:37:54  [ pool-69-thread-1:95222 ] - [ INFO ]  Finishing task: attempt_local862986929_0022_r_000000_0
2020-11-20 13:37:54  [ Thread-584:95222 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:54  [ main:95996 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:54  [ main:95996 ] - [ INFO ]  Job job_local862986929_0022 completed successfully
2020-11-20 13:37:54  [ main:95998 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=28838
		FILE: Number of bytes written=13413379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=24231006
		HDFS: Number of bytes written=8680
		HDFS: Number of read operations=640
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=337
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1156
		Map output materialized bytes=225
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=225
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=3404726272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:55  [ main:96024 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:55  [ main:96038 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:55  [ main:96042 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:55  [ main:96050 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:55  [ main:96090 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:55  [ main:96107 ] - [ INFO ]  Submitting tokens for job: job_local1739666406_0023
2020-11-20 13:37:55  [ main:96142 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:55  [ main:96142 ] - [ INFO ]  Running job: job_local1739666406_0023
2020-11-20 13:37:55  [ Thread-611:96142 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:55  [ Thread-611:96142 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:55  [ Thread-611:96142 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:55  [ Thread-611:96153 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96153 ] - [ INFO ]  Starting task: attempt_local1739666406_0023_m_000000_0
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96154 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96154 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96154 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96154 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96162 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96162 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96162 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96162 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96162 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:55  [ LocalJobRunner Map Task Executor #0:96162 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:37:56  [ main:97146 ] - [ INFO ]  Job job_local1739666406_0023 running in uber mode : false
2020-11-20 13:37:56  [ main:97146 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99424 ] - [ INFO ]  
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99424 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99424 ] - [ INFO ]  Spilling map output
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99424 ] - [ INFO ]  bufstart = 0; bufend = 1161; bufvoid = 104857600
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99424 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99426 ] - [ INFO ]  Finished spill 0
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99427 ] - [ INFO ]  Task:attempt_local1739666406_0023_m_000000_0 is done. And is in the process of committing
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99437 ] - [ INFO ]  map
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99437 ] - [ INFO ]  Task 'attempt_local1739666406_0023_m_000000_0' done.
2020-11-20 13:37:58  [ LocalJobRunner Map Task Executor #0:99437 ] - [ INFO ]  Finishing task: attempt_local1739666406_0023_m_000000_0
2020-11-20 13:37:58  [ Thread-611:99437 ] - [ INFO ]  map task executor complete.
2020-11-20 13:37:58  [ Thread-611:99437 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:37:58  [ pool-72-thread-1:99437 ] - [ INFO ]  Starting task: attempt_local1739666406_0023_r_000000_0
2020-11-20 13:37:58  [ pool-72-thread-1:99438 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:58  [ pool-72-thread-1:99438 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:58  [ pool-72-thread-1:99439 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:58  [ pool-72-thread-1:99439 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32b73df4
2020-11-20 13:37:58  [ pool-72-thread-1:99440 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:37:58  [ EventFetcher for fetching Map Completion Events:99440 ] - [ INFO ]  attempt_local1739666406_0023_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:37:58  [ localfetcher#23:99441 ] - [ INFO ]  localfetcher#23 about to shuffle output of map attempt_local1739666406_0023_m_000000_0 decomp: 223 len: 227 to MEMORY
2020-11-20 13:37:58  [ localfetcher#23:99441 ] - [ INFO ]  Read 223 bytes from map-output for attempt_local1739666406_0023_m_000000_0
2020-11-20 13:37:58  [ localfetcher#23:99441 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 223, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->223
2020-11-20 13:37:58  [ EventFetcher for fetching Map Completion Events:99442 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:37:58  [ pool-72-thread-1:99442 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:58  [ pool-72-thread-1:99442 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:37:58  [ pool-72-thread-1:99443 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:58  [ pool-72-thread-1:99443 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 218 bytes
2020-11-20 13:37:58  [ pool-72-thread-1:99443 ] - [ INFO ]  Merged 1 segments, 223 bytes to disk to satisfy reduce memory limit
2020-11-20 13:37:58  [ pool-72-thread-1:99443 ] - [ INFO ]  Merging 1 files, 227 bytes from disk
2020-11-20 13:37:58  [ pool-72-thread-1:99444 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:37:58  [ pool-72-thread-1:99444 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:37:58  [ pool-72-thread-1:99444 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 218 bytes
2020-11-20 13:37:58  [ pool-72-thread-1:99444 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:58  [ pool-72-thread-1:99552 ] - [ INFO ]  Task:attempt_local1739666406_0023_r_000000_0 is done. And is in the process of committing
2020-11-20 13:37:58  [ pool-72-thread-1:99561 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:37:58  [ pool-72-thread-1:99561 ] - [ INFO ]  Task attempt_local1739666406_0023_r_000000_0 is allowed to commit now
2020-11-20 13:37:58  [ pool-72-thread-1:99585 ] - [ INFO ]  Saved output of task 'attempt_local1739666406_0023_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1739666406_0023_r_000000
2020-11-20 13:37:58  [ pool-72-thread-1:99586 ] - [ INFO ]  reduce > reduce
2020-11-20 13:37:58  [ pool-72-thread-1:99586 ] - [ INFO ]  Task 'attempt_local1739666406_0023_r_000000_0' done.
2020-11-20 13:37:58  [ pool-72-thread-1:99586 ] - [ INFO ]  Finishing task: attempt_local1739666406_0023_r_000000_0
2020-11-20 13:37:58  [ Thread-611:99586 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:37:59  [ main:100149 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:37:59  [ main:100149 ] - [ INFO ]  Job job_local1739666406_0023 completed successfully
2020-11-20 13:37:59  [ main:100150 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=30184
		FILE: Number of bytes written=13997787
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=25284528
		HDFS: Number of bytes written=9110
		HDFS: Number of read operations=670
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=353
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1161
		Map output materialized bytes=227
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=227
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3404726272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:37:59  [ main:100189 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:37:59  [ main:100201 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:37:59  [ main:100205 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:37:59  [ main:100214 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:37:59  [ main:100251 ] - [ INFO ]  number of splits:1
2020-11-20 13:37:59  [ main:100269 ] - [ INFO ]  Submitting tokens for job: job_local25869344_0024
2020-11-20 13:37:59  [ main:100305 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:37:59  [ main:100305 ] - [ INFO ]  Running job: job_local25869344_0024
2020-11-20 13:37:59  [ Thread-638:100306 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:37:59  [ Thread-638:100306 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:59  [ Thread-638:100306 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:37:59  [ Thread-638:100316 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100316 ] - [ INFO ]  Starting task: attempt_local25869344_0024_m_000000_0
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100316 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100316 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100316 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100317 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100325 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100325 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100325 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100325 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100325 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:37:59  [ LocalJobRunner Map Task Executor #0:100325 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:00  [ main:101307 ] - [ INFO ]  Job job_local25869344_0024 running in uber mode : false
2020-11-20 13:38:00  [ main:101307 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103398 ] - [ INFO ]  
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103399 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103399 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103399 ] - [ INFO ]  bufstart = 0; bufend = 1143; bufvoid = 104857600
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103399 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103400 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103401 ] - [ INFO ]  Task:attempt_local25869344_0024_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103411 ] - [ INFO ]  map
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103411 ] - [ INFO ]  Task 'attempt_local25869344_0024_m_000000_0' done.
2020-11-20 13:38:02  [ LocalJobRunner Map Task Executor #0:103411 ] - [ INFO ]  Finishing task: attempt_local25869344_0024_m_000000_0
2020-11-20 13:38:02  [ Thread-638:103411 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:02  [ Thread-638:103412 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:02  [ pool-75-thread-1:103412 ] - [ INFO ]  Starting task: attempt_local25869344_0024_r_000000_0
2020-11-20 13:38:02  [ pool-75-thread-1:103413 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:02  [ pool-75-thread-1:103413 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:02  [ pool-75-thread-1:103413 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:02  [ pool-75-thread-1:103413 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66d9ea16
2020-11-20 13:38:02  [ pool-75-thread-1:103413 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:02  [ EventFetcher for fetching Map Completion Events:103413 ] - [ INFO ]  attempt_local25869344_0024_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:02  [ localfetcher#24:103414 ] - [ INFO ]  localfetcher#24 about to shuffle output of map attempt_local25869344_0024_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:38:02  [ localfetcher#24:103414 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local25869344_0024_m_000000_0
2020-11-20 13:38:02  [ localfetcher#24:103415 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:38:02  [ EventFetcher for fetching Map Completion Events:103415 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:02  [ pool-75-thread-1:103415 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:02  [ pool-75-thread-1:103415 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:02  [ pool-75-thread-1:103416 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:02  [ pool-75-thread-1:103416 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:38:02  [ pool-75-thread-1:103417 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:02  [ pool-75-thread-1:103417 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:38:02  [ pool-75-thread-1:103417 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:02  [ pool-75-thread-1:103417 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:02  [ pool-75-thread-1:103417 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:38:02  [ pool-75-thread-1:103417 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:02  [ pool-75-thread-1:103528 ] - [ INFO ]  Task:attempt_local25869344_0024_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:02  [ pool-75-thread-1:103537 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:02  [ pool-75-thread-1:103537 ] - [ INFO ]  Task attempt_local25869344_0024_r_000000_0 is allowed to commit now
2020-11-20 13:38:02  [ pool-75-thread-1:103571 ] - [ INFO ]  Saved output of task 'attempt_local25869344_0024_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local25869344_0024_r_000000
2020-11-20 13:38:02  [ pool-75-thread-1:103572 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:02  [ pool-75-thread-1:103572 ] - [ INFO ]  Task 'attempt_local25869344_0024_r_000000_0' done.
2020-11-20 13:38:02  [ pool-75-thread-1:103572 ] - [ INFO ]  Finishing task: attempt_local25869344_0024_r_000000_0
2020-11-20 13:38:02  [ Thread-638:103572 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:03  [ main:104314 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:03  [ main:104314 ] - [ INFO ]  Job job_local25869344_0024 completed successfully
2020-11-20 13:38:03  [ main:104315 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=31528
		FILE: Number of bytes written=14579828
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=26338050
		HDFS: Number of bytes written=9539
		HDFS: Number of read operations=700
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=369
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1143
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3404726272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:03  [ main:104348 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:03  [ main:104363 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:03  [ main:104368 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:03  [ main:104376 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:03  [ main:104417 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:03  [ main:104434 ] - [ INFO ]  Submitting tokens for job: job_local666953511_0025
2020-11-20 13:38:03  [ main:104468 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:03  [ main:104468 ] - [ INFO ]  Running job: job_local666953511_0025
2020-11-20 13:38:03  [ Thread-665:104469 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:03  [ Thread-665:104469 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:03  [ Thread-665:104469 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:03  [ Thread-665:104480 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104480 ] - [ INFO ]  Starting task: attempt_local666953511_0025_m_000000_0
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104481 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104481 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104481 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104482 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104503 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104504 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104504 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104504 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104504 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:03  [ LocalJobRunner Map Task Executor #0:104504 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:04  [ main:105473 ] - [ INFO ]  Job job_local666953511_0025 running in uber mode : false
2020-11-20 13:38:04  [ main:105473 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107471 ] - [ INFO ]  
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107471 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107471 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107471 ] - [ INFO ]  bufstart = 0; bufend = 1152; bufvoid = 104857600
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107471 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107473 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107474 ] - [ INFO ]  Task:attempt_local666953511_0025_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107482 ] - [ INFO ]  map
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107482 ] - [ INFO ]  Task 'attempt_local666953511_0025_m_000000_0' done.
2020-11-20 13:38:06  [ LocalJobRunner Map Task Executor #0:107482 ] - [ INFO ]  Finishing task: attempt_local666953511_0025_m_000000_0
2020-11-20 13:38:06  [ Thread-665:107482 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:06  [ Thread-665:107482 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:06  [ pool-78-thread-1:107483 ] - [ INFO ]  Starting task: attempt_local666953511_0025_r_000000_0
2020-11-20 13:38:06  [ pool-78-thread-1:107483 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:06  [ pool-78-thread-1:107483 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:06  [ pool-78-thread-1:107483 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:06  [ pool-78-thread-1:107483 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65986999
2020-11-20 13:38:06  [ pool-78-thread-1:107485 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:06  [ EventFetcher for fetching Map Completion Events:107485 ] - [ INFO ]  attempt_local666953511_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:06  [ localfetcher#25:107486 ] - [ INFO ]  localfetcher#25 about to shuffle output of map attempt_local666953511_0025_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:38:06  [ localfetcher#25:107486 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local666953511_0025_m_000000_0
2020-11-20 13:38:06  [ localfetcher#25:107486 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:38:06  [ EventFetcher for fetching Map Completion Events:107486 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:06  [ pool-78-thread-1:107486 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:06  [ pool-78-thread-1:107486 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:06  [ pool-78-thread-1:107487 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:06  [ pool-78-thread-1:107487 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:38:06  [ pool-78-thread-1:107487 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:06  [ pool-78-thread-1:107488 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:38:06  [ pool-78-thread-1:107488 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:06  [ pool-78-thread-1:107488 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:06  [ pool-78-thread-1:107488 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 215 bytes
2020-11-20 13:38:06  [ pool-78-thread-1:107488 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:06  [ pool-78-thread-1:107605 ] - [ INFO ]  Task:attempt_local666953511_0025_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:06  [ pool-78-thread-1:107614 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:06  [ pool-78-thread-1:107614 ] - [ INFO ]  Task attempt_local666953511_0025_r_000000_0 is allowed to commit now
2020-11-20 13:38:06  [ pool-78-thread-1:107641 ] - [ INFO ]  Saved output of task 'attempt_local666953511_0025_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local666953511_0025_r_000000
2020-11-20 13:38:06  [ pool-78-thread-1:107642 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:06  [ pool-78-thread-1:107642 ] - [ INFO ]  Task 'attempt_local666953511_0025_r_000000_0' done.
2020-11-20 13:38:06  [ pool-78-thread-1:107642 ] - [ INFO ]  Finishing task: attempt_local666953511_0025_r_000000_0
2020-11-20 13:38:06  [ Thread-665:107642 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:07  [ main:108482 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:07  [ main:108482 ] - [ INFO ]  Job job_local666953511_0025 completed successfully
2020-11-20 13:38:07  [ main:108483 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=32866
		FILE: Number of bytes written=15172114
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27391572
		HDFS: Number of bytes written=9965
		HDFS: Number of read operations=730
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=385
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1152
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3404726272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:07  [ main:108509 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:07  [ main:108523 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:07  [ main:108528 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:07  [ main:108537 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:07  [ main:108582 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:07  [ main:108601 ] - [ INFO ]  Submitting tokens for job: job_local146800277_0026
2020-11-20 13:38:07  [ main:108644 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:07  [ main:108644 ] - [ INFO ]  Running job: job_local146800277_0026
2020-11-20 13:38:07  [ Thread-692:108644 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:07  [ Thread-692:108644 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:07  [ Thread-692:108644 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:07  [ Thread-692:108662 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108663 ] - [ INFO ]  Starting task: attempt_local146800277_0026_m_000000_0
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108663 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108663 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108663 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108664 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108703 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108703 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108703 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108703 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108703 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:07  [ LocalJobRunner Map Task Executor #0:108704 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:08  [ main:109646 ] - [ INFO ]  Job job_local146800277_0026 running in uber mode : false
2020-11-20 13:38:08  [ main:109646 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111679 ] - [ INFO ]  
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111679 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111679 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111679 ] - [ INFO ]  bufstart = 0; bufend = 1167; bufvoid = 104857600
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111679 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111681 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111682 ] - [ INFO ]  Task:attempt_local146800277_0026_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111691 ] - [ INFO ]  map
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111691 ] - [ INFO ]  Task 'attempt_local146800277_0026_m_000000_0' done.
2020-11-20 13:38:10  [ LocalJobRunner Map Task Executor #0:111691 ] - [ INFO ]  Finishing task: attempt_local146800277_0026_m_000000_0
2020-11-20 13:38:10  [ Thread-692:111692 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:10  [ Thread-692:111692 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:10  [ pool-81-thread-1:111692 ] - [ INFO ]  Starting task: attempt_local146800277_0026_r_000000_0
2020-11-20 13:38:10  [ pool-81-thread-1:111693 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:10  [ pool-81-thread-1:111693 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:10  [ pool-81-thread-1:111693 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:10  [ pool-81-thread-1:111693 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5949139a
2020-11-20 13:38:10  [ pool-81-thread-1:111694 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:10  [ EventFetcher for fetching Map Completion Events:111698 ] - [ INFO ]  attempt_local146800277_0026_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:10  [ localfetcher#26:111699 ] - [ INFO ]  localfetcher#26 about to shuffle output of map attempt_local146800277_0026_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:38:10  [ localfetcher#26:111699 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local146800277_0026_m_000000_0
2020-11-20 13:38:10  [ localfetcher#26:111699 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:38:10  [ EventFetcher for fetching Map Completion Events:111699 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:10  [ pool-81-thread-1:111700 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:10  [ pool-81-thread-1:111700 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:10  [ pool-81-thread-1:111700 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:10  [ pool-81-thread-1:111700 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:38:10  [ pool-81-thread-1:111701 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:10  [ pool-81-thread-1:111701 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:38:10  [ pool-81-thread-1:111701 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:10  [ pool-81-thread-1:111701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:10  [ pool-81-thread-1:111701 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:38:10  [ pool-81-thread-1:111701 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:10  [ pool-81-thread-1:111819 ] - [ INFO ]  Task:attempt_local146800277_0026_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:10  [ pool-81-thread-1:111828 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:10  [ pool-81-thread-1:111828 ] - [ INFO ]  Task attempt_local146800277_0026_r_000000_0 is allowed to commit now
2020-11-20 13:38:10  [ pool-81-thread-1:111854 ] - [ INFO ]  Saved output of task 'attempt_local146800277_0026_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local146800277_0026_r_000000
2020-11-20 13:38:10  [ pool-81-thread-1:111855 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:10  [ pool-81-thread-1:111855 ] - [ INFO ]  Task 'attempt_local146800277_0026_r_000000_0' done.
2020-11-20 13:38:10  [ pool-81-thread-1:111855 ] - [ INFO ]  Finishing task: attempt_local146800277_0026_r_000000_0
2020-11-20 13:38:10  [ Thread-692:111855 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:11  [ main:112655 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:11  [ main:112655 ] - [ INFO ]  Job job_local146800277_0026 completed successfully
2020-11-20 13:38:11  [ main:112657 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=34200
		FILE: Number of bytes written=15764846
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=28445094
		HDFS: Number of bytes written=10389
		HDFS: Number of read operations=760
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=401
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1167
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=3411542016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:11  [ main:112682 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:11  [ main:112696 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:11  [ main:112701 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:11  [ main:112708 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:11  [ main:112747 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:11  [ main:112764 ] - [ INFO ]  Submitting tokens for job: job_local266621037_0027
2020-11-20 13:38:11  [ main:112798 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:11  [ main:112798 ] - [ INFO ]  Running job: job_local266621037_0027
2020-11-20 13:38:11  [ Thread-719:112798 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:11  [ Thread-719:112799 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:11  [ Thread-719:112799 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:11  [ Thread-719:112808 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112809 ] - [ INFO ]  Starting task: attempt_local266621037_0027_m_000000_0
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112809 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112809 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112809 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112810 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112819 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112819 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112819 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112819 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112819 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:11  [ LocalJobRunner Map Task Executor #0:112819 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:12  [ main:113802 ] - [ INFO ]  Job job_local266621037_0027 running in uber mode : false
2020-11-20 13:38:12  [ main:113802 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115937 ] - [ INFO ]  
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115937 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115937 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115937 ] - [ INFO ]  bufstart = 0; bufend = 1148; bufvoid = 104857600
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115938 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115939 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115940 ] - [ INFO ]  Task:attempt_local266621037_0027_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115949 ] - [ INFO ]  map
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115949 ] - [ INFO ]  Task 'attempt_local266621037_0027_m_000000_0' done.
2020-11-20 13:38:14  [ LocalJobRunner Map Task Executor #0:115949 ] - [ INFO ]  Finishing task: attempt_local266621037_0027_m_000000_0
2020-11-20 13:38:14  [ Thread-719:115949 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:14  [ Thread-719:115950 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:14  [ pool-84-thread-1:115950 ] - [ INFO ]  Starting task: attempt_local266621037_0027_r_000000_0
2020-11-20 13:38:14  [ pool-84-thread-1:115951 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:14  [ pool-84-thread-1:115951 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:14  [ pool-84-thread-1:115951 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:14  [ pool-84-thread-1:115951 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61b4ab20
2020-11-20 13:38:14  [ pool-84-thread-1:115951 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:14  [ EventFetcher for fetching Map Completion Events:115952 ] - [ INFO ]  attempt_local266621037_0027_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:14  [ localfetcher#27:115953 ] - [ INFO ]  localfetcher#27 about to shuffle output of map attempt_local266621037_0027_m_000000_0 decomp: 222 len: 226 to MEMORY
2020-11-20 13:38:14  [ localfetcher#27:115953 ] - [ INFO ]  Read 222 bytes from map-output for attempt_local266621037_0027_m_000000_0
2020-11-20 13:38:14  [ localfetcher#27:115953 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 222, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->222
2020-11-20 13:38:14  [ EventFetcher for fetching Map Completion Events:115953 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:14  [ pool-84-thread-1:115953 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:14  [ pool-84-thread-1:115953 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:14  [ pool-84-thread-1:115954 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:14  [ pool-84-thread-1:115954 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 217 bytes
2020-11-20 13:38:14  [ pool-84-thread-1:115955 ] - [ INFO ]  Merged 1 segments, 222 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:14  [ pool-84-thread-1:115955 ] - [ INFO ]  Merging 1 files, 226 bytes from disk
2020-11-20 13:38:14  [ pool-84-thread-1:115955 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:14  [ pool-84-thread-1:115955 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:14  [ pool-84-thread-1:115955 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 217 bytes
2020-11-20 13:38:14  [ pool-84-thread-1:115955 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:15  [ pool-84-thread-1:116068 ] - [ INFO ]  Task:attempt_local266621037_0027_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:15  [ pool-84-thread-1:116079 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:15  [ pool-84-thread-1:116079 ] - [ INFO ]  Task attempt_local266621037_0027_r_000000_0 is allowed to commit now
2020-11-20 13:38:15  [ pool-84-thread-1:116104 ] - [ INFO ]  Saved output of task 'attempt_local266621037_0027_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local266621037_0027_r_000000
2020-11-20 13:38:15  [ pool-84-thread-1:116104 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:15  [ pool-84-thread-1:116104 ] - [ INFO ]  Task 'attempt_local266621037_0027_r_000000_0' done.
2020-11-20 13:38:15  [ pool-84-thread-1:116104 ] - [ INFO ]  Finishing task: attempt_local266621037_0027_r_000000_0
2020-11-20 13:38:15  [ Thread-719:116105 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:15  [ main:116814 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:15  [ main:116814 ] - [ INFO ]  Job job_local266621037_0027 completed successfully
2020-11-20 13:38:15  [ main:116816 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=35538
		FILE: Number of bytes written=16357708
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29498616
		HDFS: Number of bytes written=10815
		HDFS: Number of read operations=790
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=417
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1148
		Map output materialized bytes=226
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=226
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3418357760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:15  [ main:116843 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:15  [ main:116856 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:15  [ main:116860 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:15  [ main:116868 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:15  [ main:116908 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:15  [ main:116925 ] - [ INFO ]  Submitting tokens for job: job_local1564374771_0028
2020-11-20 13:38:15  [ main:116960 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:15  [ main:116960 ] - [ INFO ]  Running job: job_local1564374771_0028
2020-11-20 13:38:15  [ Thread-746:116960 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:15  [ Thread-746:116961 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:15  [ Thread-746:116961 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:15  [ Thread-746:116973 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116973 ] - [ INFO ]  Starting task: attempt_local1564374771_0028_m_000000_0
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116973 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116973 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116974 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116982 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116982 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116982 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116982 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116982 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:15  [ LocalJobRunner Map Task Executor #0:116982 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:16  [ main:117964 ] - [ INFO ]  Job job_local1564374771_0028 running in uber mode : false
2020-11-20 13:38:16  [ main:117964 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120070 ] - [ INFO ]  
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120070 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120070 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120070 ] - [ INFO ]  bufstart = 0; bufend = 1210; bufvoid = 104857600
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120070 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120071 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120072 ] - [ INFO ]  Task:attempt_local1564374771_0028_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120082 ] - [ INFO ]  map
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120082 ] - [ INFO ]  Task 'attempt_local1564374771_0028_m_000000_0' done.
2020-11-20 13:38:19  [ LocalJobRunner Map Task Executor #0:120082 ] - [ INFO ]  Finishing task: attempt_local1564374771_0028_m_000000_0
2020-11-20 13:38:19  [ Thread-746:120082 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:19  [ Thread-746:120082 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:19  [ pool-87-thread-1:120082 ] - [ INFO ]  Starting task: attempt_local1564374771_0028_r_000000_0
2020-11-20 13:38:19  [ pool-87-thread-1:120083 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:19  [ pool-87-thread-1:120084 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:19  [ pool-87-thread-1:120084 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:19  [ pool-87-thread-1:120084 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a4eff71
2020-11-20 13:38:19  [ pool-87-thread-1:120085 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:19  [ EventFetcher for fetching Map Completion Events:120086 ] - [ INFO ]  attempt_local1564374771_0028_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:19  [ localfetcher#28:120086 ] - [ INFO ]  localfetcher#28 about to shuffle output of map attempt_local1564374771_0028_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:38:19  [ localfetcher#28:120086 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local1564374771_0028_m_000000_0
2020-11-20 13:38:19  [ localfetcher#28:120087 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:38:19  [ EventFetcher for fetching Map Completion Events:120087 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:19  [ pool-87-thread-1:120087 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:19  [ pool-87-thread-1:120087 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:19  [ pool-87-thread-1:120088 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:19  [ pool-87-thread-1:120088 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:38:19  [ pool-87-thread-1:120089 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:19  [ pool-87-thread-1:120089 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:38:19  [ pool-87-thread-1:120089 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:19  [ pool-87-thread-1:120089 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:19  [ pool-87-thread-1:120089 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:38:19  [ pool-87-thread-1:120089 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:19  [ pool-87-thread-1:120197 ] - [ INFO ]  Task:attempt_local1564374771_0028_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:19  [ pool-87-thread-1:120206 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:19  [ pool-87-thread-1:120206 ] - [ INFO ]  Task attempt_local1564374771_0028_r_000000_0 is allowed to commit now
2020-11-20 13:38:19  [ pool-87-thread-1:120232 ] - [ INFO ]  Saved output of task 'attempt_local1564374771_0028_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1564374771_0028_r_000000
2020-11-20 13:38:19  [ pool-87-thread-1:120233 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:19  [ pool-87-thread-1:120233 ] - [ INFO ]  Task 'attempt_local1564374771_0028_r_000000_0' done.
2020-11-20 13:38:19  [ pool-87-thread-1:120233 ] - [ INFO ]  Finishing task: attempt_local1564374771_0028_r_000000_0
2020-11-20 13:38:19  [ Thread-746:120233 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:19  [ main:120971 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:19  [ main:120971 ] - [ INFO ]  Job job_local1564374771_0028 completed successfully
2020-11-20 13:38:19  [ main:120972 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=36880
		FILE: Number of bytes written=16973632
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30552138
		HDFS: Number of bytes written=11243
		HDFS: Number of read operations=820
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=433
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1210
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3418357760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:19  [ main:121003 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:19  [ main:121019 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:19  [ main:121023 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:20  [ main:121032 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:20  [ main:121071 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:20  [ main:121088 ] - [ INFO ]  Submitting tokens for job: job_local361627071_0029
2020-11-20 13:38:20  [ main:121121 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:20  [ main:121122 ] - [ INFO ]  Running job: job_local361627071_0029
2020-11-20 13:38:20  [ Thread-773:121122 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:20  [ Thread-773:121122 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:20  [ Thread-773:121122 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:20  [ Thread-773:121132 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121132 ] - [ INFO ]  Starting task: attempt_local361627071_0029_m_000000_0
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121132 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121132 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121132 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121133 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121140 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121140 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121140 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121140 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121140 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:20  [ LocalJobRunner Map Task Executor #0:121140 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:21  [ main:122125 ] - [ INFO ]  Job job_local361627071_0029 running in uber mode : false
2020-11-20 13:38:21  [ main:122125 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124132 ] - [ INFO ]  
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124132 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124132 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124132 ] - [ INFO ]  bufstart = 0; bufend = 1215; bufvoid = 104857600
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124132 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124134 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124135 ] - [ INFO ]  Task:attempt_local361627071_0029_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124143 ] - [ INFO ]  map
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124143 ] - [ INFO ]  Task 'attempt_local361627071_0029_m_000000_0' done.
2020-11-20 13:38:23  [ LocalJobRunner Map Task Executor #0:124143 ] - [ INFO ]  Finishing task: attempt_local361627071_0029_m_000000_0
2020-11-20 13:38:23  [ Thread-773:124143 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:23  [ Thread-773:124144 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:23  [ pool-90-thread-1:124144 ] - [ INFO ]  Starting task: attempt_local361627071_0029_r_000000_0
2020-11-20 13:38:23  [ pool-90-thread-1:124145 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:23  [ pool-90-thread-1:124145 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:23  [ pool-90-thread-1:124145 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:23  [ pool-90-thread-1:124145 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19f402f6
2020-11-20 13:38:23  [ pool-90-thread-1:124145 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:23  [ EventFetcher for fetching Map Completion Events:124146 ] - [ INFO ]  attempt_local361627071_0029_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:23  [ localfetcher#29:124146 ] - [ INFO ]  localfetcher#29 about to shuffle output of map attempt_local361627071_0029_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:38:23  [ localfetcher#29:124147 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local361627071_0029_m_000000_0
2020-11-20 13:38:23  [ localfetcher#29:124147 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:38:23  [ EventFetcher for fetching Map Completion Events:124147 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:23  [ pool-90-thread-1:124147 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:23  [ pool-90-thread-1:124147 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:23  [ pool-90-thread-1:124148 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:23  [ pool-90-thread-1:124148 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:38:23  [ pool-90-thread-1:124149 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:23  [ pool-90-thread-1:124149 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:38:23  [ pool-90-thread-1:124149 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:23  [ pool-90-thread-1:124149 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:23  [ pool-90-thread-1:124149 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:38:23  [ pool-90-thread-1:124149 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:23  [ pool-90-thread-1:124262 ] - [ INFO ]  Task:attempt_local361627071_0029_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:23  [ pool-90-thread-1:124270 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:23  [ pool-90-thread-1:124270 ] - [ INFO ]  Task attempt_local361627071_0029_r_000000_0 is allowed to commit now
2020-11-20 13:38:23  [ pool-90-thread-1:124295 ] - [ INFO ]  Saved output of task 'attempt_local361627071_0029_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local361627071_0029_r_000000
2020-11-20 13:38:23  [ pool-90-thread-1:124295 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:23  [ pool-90-thread-1:124295 ] - [ INFO ]  Task 'attempt_local361627071_0029_r_000000_0' done.
2020-11-20 13:38:23  [ pool-90-thread-1:124295 ] - [ INFO ]  Finishing task: attempt_local361627071_0029_r_000000_0
2020-11-20 13:38:23  [ Thread-773:124296 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:24  [ main:125131 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:24  [ main:125131 ] - [ INFO ]  Job job_local361627071_0029 completed successfully
2020-11-20 13:38:24  [ main:125132 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=38214
		FILE: Number of bytes written=17588584
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=31605660
		HDFS: Number of bytes written=11667
		HDFS: Number of read operations=850
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=449
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1215
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3418357760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:24  [ main:125164 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:24  [ main:125180 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:24  [ main:125185 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:24  [ main:125193 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:24  [ main:125234 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:24  [ main:125250 ] - [ INFO ]  Submitting tokens for job: job_local1157256392_0030
2020-11-20 13:38:24  [ main:125285 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:24  [ main:125285 ] - [ INFO ]  Running job: job_local1157256392_0030
2020-11-20 13:38:24  [ Thread-800:125285 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:24  [ Thread-800:125285 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:24  [ Thread-800:125285 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:24  [ Thread-800:125294 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125295 ] - [ INFO ]  Starting task: attempt_local1157256392_0030_m_000000_0
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125295 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125295 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125295 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125296 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125312 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125312 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125313 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125313 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125313 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:24  [ LocalJobRunner Map Task Executor #0:125313 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:25  [ main:126290 ] - [ INFO ]  Job job_local1157256392_0030 running in uber mode : false
2020-11-20 13:38:25  [ main:126290 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128490 ] - [ INFO ]  
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128490 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128490 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128490 ] - [ INFO ]  bufstart = 0; bufend = 1189; bufvoid = 104857600
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128490 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128492 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128493 ] - [ INFO ]  Task:attempt_local1157256392_0030_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128501 ] - [ INFO ]  map
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128501 ] - [ INFO ]  Task 'attempt_local1157256392_0030_m_000000_0' done.
2020-11-20 13:38:27  [ LocalJobRunner Map Task Executor #0:128501 ] - [ INFO ]  Finishing task: attempt_local1157256392_0030_m_000000_0
2020-11-20 13:38:27  [ Thread-800:128501 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:27  [ Thread-800:128502 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:27  [ pool-93-thread-1:128502 ] - [ INFO ]  Starting task: attempt_local1157256392_0030_r_000000_0
2020-11-20 13:38:27  [ pool-93-thread-1:128502 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:27  [ pool-93-thread-1:128503 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:27  [ pool-93-thread-1:128503 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:27  [ pool-93-thread-1:128503 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ed77bb4
2020-11-20 13:38:27  [ pool-93-thread-1:128503 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:27  [ EventFetcher for fetching Map Completion Events:128503 ] - [ INFO ]  attempt_local1157256392_0030_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:27  [ localfetcher#30:128504 ] - [ INFO ]  localfetcher#30 about to shuffle output of map attempt_local1157256392_0030_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:38:27  [ localfetcher#30:128504 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local1157256392_0030_m_000000_0
2020-11-20 13:38:27  [ localfetcher#30:128504 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:38:27  [ EventFetcher for fetching Map Completion Events:128504 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:27  [ pool-93-thread-1:128505 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:27  [ pool-93-thread-1:128505 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:27  [ pool-93-thread-1:128505 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:27  [ pool-93-thread-1:128505 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:38:27  [ pool-93-thread-1:128506 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:27  [ pool-93-thread-1:128506 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:38:27  [ pool-93-thread-1:128506 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:27  [ pool-93-thread-1:128506 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:27  [ pool-93-thread-1:128506 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:38:27  [ pool-93-thread-1:128506 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:27  [ pool-93-thread-1:128622 ] - [ INFO ]  Task:attempt_local1157256392_0030_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:27  [ pool-93-thread-1:128630 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:27  [ pool-93-thread-1:128630 ] - [ INFO ]  Task attempt_local1157256392_0030_r_000000_0 is allowed to commit now
2020-11-20 13:38:27  [ pool-93-thread-1:128657 ] - [ INFO ]  Saved output of task 'attempt_local1157256392_0030_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1157256392_0030_r_000000
2020-11-20 13:38:27  [ pool-93-thread-1:128657 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:27  [ pool-93-thread-1:128657 ] - [ INFO ]  Task 'attempt_local1157256392_0030_r_000000_0' done.
2020-11-20 13:38:27  [ pool-93-thread-1:128657 ] - [ INFO ]  Finishing task: attempt_local1157256392_0030_r_000000_0
2020-11-20 13:38:27  [ Thread-800:128657 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:28  [ main:129298 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:28  [ main:129298 ] - [ INFO ]  Job job_local1157256392_0030 completed successfully
2020-11-20 13:38:28  [ main:129299 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=39544
		FILE: Number of bytes written=18207606
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=32659182
		HDFS: Number of bytes written=12089
		HDFS: Number of read operations=880
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=465
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1189
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3418357760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:28  [ main:129330 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:28  [ main:129343 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:28  [ main:129346 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:28  [ main:129355 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:28  [ main:129393 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:28  [ main:129410 ] - [ INFO ]  Submitting tokens for job: job_local161981155_0031
2020-11-20 13:38:28  [ main:129446 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:28  [ main:129446 ] - [ INFO ]  Running job: job_local161981155_0031
2020-11-20 13:38:28  [ Thread-827:129446 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:28  [ Thread-827:129446 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:28  [ Thread-827:129446 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:28  [ Thread-827:129456 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129456 ] - [ INFO ]  Starting task: attempt_local161981155_0031_m_000000_0
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129457 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129457 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129457 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129457 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129468 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129468 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129468 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129468 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129468 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:28  [ LocalJobRunner Map Task Executor #0:129468 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:29  [ main:130451 ] - [ INFO ]  Job job_local161981155_0031 running in uber mode : false
2020-11-20 13:38:29  [ main:130451 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132684 ] - [ INFO ]  
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132684 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132684 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132684 ] - [ INFO ]  bufstart = 0; bufend = 1214; bufvoid = 104857600
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132684 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132686 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132687 ] - [ INFO ]  Task:attempt_local161981155_0031_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132695 ] - [ INFO ]  map
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132695 ] - [ INFO ]  Task 'attempt_local161981155_0031_m_000000_0' done.
2020-11-20 13:38:31  [ LocalJobRunner Map Task Executor #0:132695 ] - [ INFO ]  Finishing task: attempt_local161981155_0031_m_000000_0
2020-11-20 13:38:31  [ Thread-827:132696 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:31  [ Thread-827:132696 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:31  [ pool-96-thread-1:132696 ] - [ INFO ]  Starting task: attempt_local161981155_0031_r_000000_0
2020-11-20 13:38:31  [ pool-96-thread-1:132697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:31  [ pool-96-thread-1:132697 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:31  [ pool-96-thread-1:132697 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:31  [ pool-96-thread-1:132697 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44f10318
2020-11-20 13:38:31  [ pool-96-thread-1:132698 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:31  [ EventFetcher for fetching Map Completion Events:132698 ] - [ INFO ]  attempt_local161981155_0031_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:31  [ localfetcher#31:132699 ] - [ INFO ]  localfetcher#31 about to shuffle output of map attempt_local161981155_0031_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:38:31  [ localfetcher#31:132699 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local161981155_0031_m_000000_0
2020-11-20 13:38:31  [ localfetcher#31:132699 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:38:31  [ EventFetcher for fetching Map Completion Events:132700 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:31  [ pool-96-thread-1:132700 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:31  [ pool-96-thread-1:132700 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:31  [ pool-96-thread-1:132701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:31  [ pool-96-thread-1:132701 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:38:31  [ pool-96-thread-1:132701 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:31  [ pool-96-thread-1:132701 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:38:31  [ pool-96-thread-1:132701 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:31  [ pool-96-thread-1:132701 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:31  [ pool-96-thread-1:132702 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:38:31  [ pool-96-thread-1:132702 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:31  [ pool-96-thread-1:132799 ] - [ INFO ]  Task:attempt_local161981155_0031_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:31  [ pool-96-thread-1:132807 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:31  [ pool-96-thread-1:132807 ] - [ INFO ]  Task attempt_local161981155_0031_r_000000_0 is allowed to commit now
2020-11-20 13:38:31  [ pool-96-thread-1:132834 ] - [ INFO ]  Saved output of task 'attempt_local161981155_0031_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local161981155_0031_r_000000
2020-11-20 13:38:31  [ pool-96-thread-1:132834 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:31  [ pool-96-thread-1:132834 ] - [ INFO ]  Task 'attempt_local161981155_0031_r_000000_0' done.
2020-11-20 13:38:31  [ pool-96-thread-1:132834 ] - [ INFO ]  Finishing task: attempt_local161981155_0031_r_000000_0
2020-11-20 13:38:31  [ Thread-827:132834 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:32  [ main:133459 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:32  [ main:133459 ] - [ INFO ]  Job job_local161981155_0031 completed successfully
2020-11-20 13:38:32  [ main:133461 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=40872
		FILE: Number of bytes written=18824305
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33712704
		HDFS: Number of bytes written=12510
		HDFS: Number of read operations=910
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=481
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1214
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=3311403008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:32  [ main:133534 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:32  [ main:133549 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:32  [ main:133554 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:32  [ main:133580 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:32  [ main:133632 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:32  [ main:133649 ] - [ INFO ]  Submitting tokens for job: job_local1254692530_0032
2020-11-20 13:38:32  [ main:133683 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:32  [ main:133683 ] - [ INFO ]  Running job: job_local1254692530_0032
2020-11-20 13:38:32  [ Thread-854:133683 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:32  [ Thread-854:133684 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:32  [ Thread-854:133684 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:32  [ Thread-854:133708 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133708 ] - [ INFO ]  Starting task: attempt_local1254692530_0032_m_000000_0
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133708 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133709 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133709 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133709 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133717 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133718 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133718 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133718 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133718 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:32  [ LocalJobRunner Map Task Executor #0:133718 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:33  [ main:134687 ] - [ INFO ]  Job job_local1254692530_0032 running in uber mode : false
2020-11-20 13:38:33  [ main:134687 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136822 ] - [ INFO ]  
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136822 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136822 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136822 ] - [ INFO ]  bufstart = 0; bufend = 1197; bufvoid = 104857600
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136822 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136823 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136824 ] - [ INFO ]  Task:attempt_local1254692530_0032_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136833 ] - [ INFO ]  map
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136833 ] - [ INFO ]  Task 'attempt_local1254692530_0032_m_000000_0' done.
2020-11-20 13:38:35  [ LocalJobRunner Map Task Executor #0:136833 ] - [ INFO ]  Finishing task: attempt_local1254692530_0032_m_000000_0
2020-11-20 13:38:35  [ Thread-854:136833 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:35  [ Thread-854:136834 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:35  [ pool-99-thread-1:136834 ] - [ INFO ]  Starting task: attempt_local1254692530_0032_r_000000_0
2020-11-20 13:38:35  [ pool-99-thread-1:136834 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:35  [ pool-99-thread-1:136834 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:35  [ pool-99-thread-1:136834 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:35  [ pool-99-thread-1:136834 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7406c9fb
2020-11-20 13:38:35  [ pool-99-thread-1:136835 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:35  [ EventFetcher for fetching Map Completion Events:136835 ] - [ INFO ]  attempt_local1254692530_0032_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:35  [ localfetcher#32:136836 ] - [ INFO ]  localfetcher#32 about to shuffle output of map attempt_local1254692530_0032_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:38:35  [ localfetcher#32:136836 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local1254692530_0032_m_000000_0
2020-11-20 13:38:35  [ localfetcher#32:136836 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:38:35  [ EventFetcher for fetching Map Completion Events:136836 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:35  [ pool-99-thread-1:136836 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:35  [ pool-99-thread-1:136836 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:35  [ pool-99-thread-1:136837 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:35  [ pool-99-thread-1:136837 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:38:35  [ pool-99-thread-1:136837 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:35  [ pool-99-thread-1:136837 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:38:35  [ pool-99-thread-1:136837 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:35  [ pool-99-thread-1:136838 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:35  [ pool-99-thread-1:136838 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:38:35  [ pool-99-thread-1:136838 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:35  [ pool-99-thread-1:136933 ] - [ INFO ]  Task:attempt_local1254692530_0032_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:35  [ pool-99-thread-1:136942 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:35  [ pool-99-thread-1:136942 ] - [ INFO ]  Task attempt_local1254692530_0032_r_000000_0 is allowed to commit now
2020-11-20 13:38:35  [ pool-99-thread-1:136967 ] - [ INFO ]  Saved output of task 'attempt_local1254692530_0032_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1254692530_0032_r_000000
2020-11-20 13:38:35  [ pool-99-thread-1:136967 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:35  [ pool-99-thread-1:136967 ] - [ INFO ]  Task 'attempt_local1254692530_0032_r_000000_0' done.
2020-11-20 13:38:35  [ pool-99-thread-1:136967 ] - [ INFO ]  Finishing task: attempt_local1254692530_0032_r_000000_0
2020-11-20 13:38:35  [ Thread-854:136967 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:36  [ main:137696 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:36  [ main:137696 ] - [ INFO ]  Job job_local1254692530_0032 completed successfully
2020-11-20 13:38:36  [ main:137697 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=42200
		FILE: Number of bytes written=19444226
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34766226
		HDFS: Number of bytes written=12931
		HDFS: Number of read operations=940
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=497
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1197
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3311403008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:36  [ main:137730 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:36  [ main:137746 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:36  [ main:137750 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:36  [ main:137758 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:36  [ main:137797 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:36  [ main:137814 ] - [ INFO ]  Submitting tokens for job: job_local30306076_0033
2020-11-20 13:38:36  [ main:137848 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:36  [ main:137849 ] - [ INFO ]  Running job: job_local30306076_0033
2020-11-20 13:38:36  [ Thread-881:137849 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:36  [ Thread-881:137849 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:36  [ Thread-881:137849 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:36  [ Thread-881:137859 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137859 ] - [ INFO ]  Starting task: attempt_local30306076_0033_m_000000_0
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137859 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137859 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137859 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137860 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137867 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137867 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137867 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137867 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137867 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:36  [ LocalJobRunner Map Task Executor #0:137868 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:37  [ main:138853 ] - [ INFO ]  Job job_local30306076_0033 running in uber mode : false
2020-11-20 13:38:37  [ main:138854 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140792 ] - [ INFO ]  
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140792 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140792 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140792 ] - [ INFO ]  bufstart = 0; bufend = 1206; bufvoid = 104857600
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140792 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140793 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140794 ] - [ INFO ]  Task:attempt_local30306076_0033_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140803 ] - [ INFO ]  map
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140803 ] - [ INFO ]  Task 'attempt_local30306076_0033_m_000000_0' done.
2020-11-20 13:38:39  [ LocalJobRunner Map Task Executor #0:140803 ] - [ INFO ]  Finishing task: attempt_local30306076_0033_m_000000_0
2020-11-20 13:38:39  [ Thread-881:140803 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:39  [ Thread-881:140803 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:39  [ pool-102-thread-1:140803 ] - [ INFO ]  Starting task: attempt_local30306076_0033_r_000000_0
2020-11-20 13:38:39  [ pool-102-thread-1:140804 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:39  [ pool-102-thread-1:140804 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:39  [ pool-102-thread-1:140804 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:39  [ pool-102-thread-1:140804 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@e429d19
2020-11-20 13:38:39  [ pool-102-thread-1:140804 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:39  [ EventFetcher for fetching Map Completion Events:140805 ] - [ INFO ]  attempt_local30306076_0033_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:39  [ localfetcher#33:140805 ] - [ INFO ]  localfetcher#33 about to shuffle output of map attempt_local30306076_0033_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:38:39  [ localfetcher#33:140805 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local30306076_0033_m_000000_0
2020-11-20 13:38:39  [ localfetcher#33:140805 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:38:39  [ EventFetcher for fetching Map Completion Events:140806 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:39  [ pool-102-thread-1:140806 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:39  [ pool-102-thread-1:140806 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:39  [ pool-102-thread-1:140806 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:38:39  [ pool-102-thread-1:140807 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:39  [ main:140863 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:38:39  [ pool-102-thread-1:140915 ] - [ INFO ]  Task:attempt_local30306076_0033_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:39  [ pool-102-thread-1:140925 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:39  [ pool-102-thread-1:140925 ] - [ INFO ]  Task attempt_local30306076_0033_r_000000_0 is allowed to commit now
2020-11-20 13:38:39  [ pool-102-thread-1:140962 ] - [ INFO ]  Saved output of task 'attempt_local30306076_0033_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local30306076_0033_r_000000
2020-11-20 13:38:39  [ pool-102-thread-1:140962 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:39  [ pool-102-thread-1:140962 ] - [ INFO ]  Task 'attempt_local30306076_0033_r_000000_0' done.
2020-11-20 13:38:39  [ pool-102-thread-1:140962 ] - [ INFO ]  Finishing task: attempt_local30306076_0033_r_000000_0
2020-11-20 13:38:39  [ Thread-881:140962 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:40  [ main:141864 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:40  [ main:141864 ] - [ INFO ]  Job job_local30306076_0033 completed successfully
2020-11-20 13:38:40  [ main:141866 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=43524
		FILE: Number of bytes written=20058275
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=35819748
		HDFS: Number of bytes written=13350
		HDFS: Number of read operations=970
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=513
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1206
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=219
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3311403008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:40  [ main:141903 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:40  [ main:141918 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:40  [ main:141923 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:40  [ main:141935 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:40  [ main:141983 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:40  [ main:142000 ] - [ INFO ]  Submitting tokens for job: job_local694992327_0034
2020-11-20 13:38:41  [ main:142035 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:41  [ main:142035 ] - [ INFO ]  Running job: job_local694992327_0034
2020-11-20 13:38:41  [ Thread-908:142036 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:41  [ Thread-908:142036 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:41  [ Thread-908:142036 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:41  [ Thread-908:142047 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142047 ] - [ INFO ]  Starting task: attempt_local694992327_0034_m_000000_0
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142048 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142048 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142048 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142048 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142057 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142057 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142057 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142057 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142057 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:41  [ LocalJobRunner Map Task Executor #0:142057 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:42  [ main:143037 ] - [ INFO ]  Job job_local694992327_0034 running in uber mode : false
2020-11-20 13:38:42  [ main:143037 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145052 ] - [ INFO ]  
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145052 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145052 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145052 ] - [ INFO ]  bufstart = 0; bufend = 1199; bufvoid = 104857600
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145052 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145054 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145055 ] - [ INFO ]  Task:attempt_local694992327_0034_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145063 ] - [ INFO ]  map
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145063 ] - [ INFO ]  Task 'attempt_local694992327_0034_m_000000_0' done.
2020-11-20 13:38:44  [ LocalJobRunner Map Task Executor #0:145063 ] - [ INFO ]  Finishing task: attempt_local694992327_0034_m_000000_0
2020-11-20 13:38:44  [ Thread-908:145063 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:44  [ Thread-908:145064 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:44  [ pool-105-thread-1:145064 ] - [ INFO ]  Starting task: attempt_local694992327_0034_r_000000_0
2020-11-20 13:38:44  [ pool-105-thread-1:145064 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:44  [ pool-105-thread-1:145064 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:44  [ pool-105-thread-1:145064 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:44  [ pool-105-thread-1:145065 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@45f40de
2020-11-20 13:38:44  [ pool-105-thread-1:145066 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:44  [ EventFetcher for fetching Map Completion Events:145066 ] - [ INFO ]  attempt_local694992327_0034_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:44  [ localfetcher#34:145067 ] - [ INFO ]  localfetcher#34 about to shuffle output of map attempt_local694992327_0034_m_000000_0 decomp: 219 len: 223 to MEMORY
2020-11-20 13:38:44  [ localfetcher#34:145067 ] - [ INFO ]  Read 219 bytes from map-output for attempt_local694992327_0034_m_000000_0
2020-11-20 13:38:44  [ localfetcher#34:145067 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 219, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->219
2020-11-20 13:38:44  [ EventFetcher for fetching Map Completion Events:145067 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:44  [ pool-105-thread-1:145067 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:44  [ pool-105-thread-1:145067 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:44  [ pool-105-thread-1:145068 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:44  [ pool-105-thread-1:145068 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:38:44  [ pool-105-thread-1:145068 ] - [ INFO ]  Merged 1 segments, 219 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:44  [ pool-105-thread-1:145069 ] - [ INFO ]  Merging 1 files, 223 bytes from disk
2020-11-20 13:38:44  [ pool-105-thread-1:145069 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:44  [ pool-105-thread-1:145069 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:44  [ pool-105-thread-1:145069 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 213 bytes
2020-11-20 13:38:44  [ pool-105-thread-1:145069 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:44  [ pool-105-thread-1:145171 ] - [ INFO ]  Task:attempt_local694992327_0034_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:44  [ pool-105-thread-1:145180 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:44  [ pool-105-thread-1:145180 ] - [ INFO ]  Task attempt_local694992327_0034_r_000000_0 is allowed to commit now
2020-11-20 13:38:44  [ pool-105-thread-1:145208 ] - [ INFO ]  Saved output of task 'attempt_local694992327_0034_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local694992327_0034_r_000000
2020-11-20 13:38:44  [ pool-105-thread-1:145208 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:44  [ pool-105-thread-1:145208 ] - [ INFO ]  Task 'attempt_local694992327_0034_r_000000_0' done.
2020-11-20 13:38:44  [ pool-105-thread-1:145208 ] - [ INFO ]  Finishing task: attempt_local694992327_0034_r_000000_0
2020-11-20 13:38:44  [ Thread-908:145209 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:45  [ main:146047 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:45  [ main:146048 ] - [ INFO ]  Job job_local694992327_0034 completed successfully
2020-11-20 13:38:45  [ main:146051 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=44850
		FILE: Number of bytes written=20676197
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=36873270
		HDFS: Number of bytes written=13770
		HDFS: Number of read operations=1000
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=529
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1199
		Map output materialized bytes=223
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=223
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3311403008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:45  [ main:146077 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:45  [ main:146091 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:45  [ main:146096 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:45  [ main:146104 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:45  [ main:146156 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:45  [ main:146197 ] - [ INFO ]  Submitting tokens for job: job_local1670478110_0035
2020-11-20 13:38:45  [ main:146242 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:45  [ main:146242 ] - [ INFO ]  Running job: job_local1670478110_0035
2020-11-20 13:38:45  [ Thread-935:146242 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:45  [ Thread-935:146242 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:45  [ Thread-935:146242 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:45  [ Thread-935:146253 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146253 ] - [ INFO ]  Starting task: attempt_local1670478110_0035_m_000000_0
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146253 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146253 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146253 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146254 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146274 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146274 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146274 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146274 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146274 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:45  [ LocalJobRunner Map Task Executor #0:146275 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:46  [ main:147245 ] - [ INFO ]  Job job_local1670478110_0035 running in uber mode : false
2020-11-20 13:38:46  [ main:147245 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149340 ] - [ INFO ]  
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149340 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149340 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149340 ] - [ INFO ]  bufstart = 0; bufend = 1170; bufvoid = 104857600
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149340 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149341 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149342 ] - [ INFO ]  Task:attempt_local1670478110_0035_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149351 ] - [ INFO ]  map
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149351 ] - [ INFO ]  Task 'attempt_local1670478110_0035_m_000000_0' done.
2020-11-20 13:38:48  [ LocalJobRunner Map Task Executor #0:149351 ] - [ INFO ]  Finishing task: attempt_local1670478110_0035_m_000000_0
2020-11-20 13:38:48  [ Thread-935:149351 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:48  [ Thread-935:149352 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:48  [ pool-108-thread-1:149352 ] - [ INFO ]  Starting task: attempt_local1670478110_0035_r_000000_0
2020-11-20 13:38:48  [ pool-108-thread-1:149352 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:48  [ pool-108-thread-1:149352 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:48  [ pool-108-thread-1:149352 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:48  [ pool-108-thread-1:149352 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c5ba483
2020-11-20 13:38:48  [ pool-108-thread-1:149352 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:48  [ EventFetcher for fetching Map Completion Events:149353 ] - [ INFO ]  attempt_local1670478110_0035_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:48  [ localfetcher#35:149353 ] - [ INFO ]  localfetcher#35 about to shuffle output of map attempt_local1670478110_0035_m_000000_0 decomp: 194 len: 198 to MEMORY
2020-11-20 13:38:48  [ localfetcher#35:149353 ] - [ INFO ]  Read 194 bytes from map-output for attempt_local1670478110_0035_m_000000_0
2020-11-20 13:38:48  [ localfetcher#35:149353 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
2020-11-20 13:38:48  [ EventFetcher for fetching Map Completion Events:149354 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:48  [ pool-108-thread-1:149354 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:48  [ pool-108-thread-1:149354 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:48  [ pool-108-thread-1:149354 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:48  [ pool-108-thread-1:149354 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-20 13:38:48  [ pool-108-thread-1:149355 ] - [ INFO ]  Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:48  [ pool-108-thread-1:149355 ] - [ INFO ]  Merging 1 files, 198 bytes from disk
2020-11-20 13:38:48  [ pool-108-thread-1:149355 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:48  [ pool-108-thread-1:149355 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:48  [ pool-108-thread-1:149355 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 188 bytes
2020-11-20 13:38:48  [ pool-108-thread-1:149355 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:48  [ pool-108-thread-1:149465 ] - [ INFO ]  Task:attempt_local1670478110_0035_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:48  [ pool-108-thread-1:149472 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:48  [ pool-108-thread-1:149473 ] - [ INFO ]  Task attempt_local1670478110_0035_r_000000_0 is allowed to commit now
2020-11-20 13:38:48  [ pool-108-thread-1:149498 ] - [ INFO ]  Saved output of task 'attempt_local1670478110_0035_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1670478110_0035_r_000000
2020-11-20 13:38:48  [ pool-108-thread-1:149498 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:48  [ pool-108-thread-1:149498 ] - [ INFO ]  Task 'attempt_local1670478110_0035_r_000000_0' done.
2020-11-20 13:38:48  [ pool-108-thread-1:149498 ] - [ INFO ]  Finishing task: attempt_local1670478110_0035_r_000000_0
2020-11-20 13:38:48  [ Thread-935:149498 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:49  [ main:150253 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:49  [ main:150253 ] - [ INFO ]  Job job_local1670478110_0035 completed successfully
2020-11-20 13:38:49  [ main:150254 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=46134
		FILE: Number of bytes written=21297200
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=37926792
		HDFS: Number of bytes written=14169
		HDFS: Number of read operations=1030
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=545
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1170
		Map output materialized bytes=198
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=198
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=3223322624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:49  [ main:150280 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:49  [ main:150295 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:49  [ main:150299 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:49  [ main:150308 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:49  [ main:150346 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:49  [ main:150363 ] - [ INFO ]  Submitting tokens for job: job_local1465122757_0036
2020-11-20 13:38:49  [ main:150397 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:49  [ main:150397 ] - [ INFO ]  Running job: job_local1465122757_0036
2020-11-20 13:38:49  [ Thread-962:150397 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:49  [ Thread-962:150397 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:49  [ Thread-962:150397 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:49  [ Thread-962:150491 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150491 ] - [ INFO ]  Starting task: attempt_local1465122757_0036_m_000000_0
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150492 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150492 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150492 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150493 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150501 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150501 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150501 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150501 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150501 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:49  [ LocalJobRunner Map Task Executor #0:150501 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:50  [ main:151400 ] - [ INFO ]  Job job_local1465122757_0036 running in uber mode : false
2020-11-20 13:38:50  [ main:151400 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153716 ] - [ INFO ]  
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153716 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153716 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153716 ] - [ INFO ]  bufstart = 0; bufend = 1218; bufvoid = 104857600
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153716 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153718 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153718 ] - [ INFO ]  Task:attempt_local1465122757_0036_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153726 ] - [ INFO ]  map
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153726 ] - [ INFO ]  Task 'attempt_local1465122757_0036_m_000000_0' done.
2020-11-20 13:38:52  [ LocalJobRunner Map Task Executor #0:153726 ] - [ INFO ]  Finishing task: attempt_local1465122757_0036_m_000000_0
2020-11-20 13:38:52  [ Thread-962:153726 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:52  [ Thread-962:153726 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:52  [ pool-111-thread-1:153726 ] - [ INFO ]  Starting task: attempt_local1465122757_0036_r_000000_0
2020-11-20 13:38:52  [ pool-111-thread-1:153727 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:52  [ pool-111-thread-1:153727 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:52  [ pool-111-thread-1:153727 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:52  [ pool-111-thread-1:153727 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b3af925
2020-11-20 13:38:52  [ pool-111-thread-1:153727 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:52  [ EventFetcher for fetching Map Completion Events:153727 ] - [ INFO ]  attempt_local1465122757_0036_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:52  [ localfetcher#36:153728 ] - [ INFO ]  localfetcher#36 about to shuffle output of map attempt_local1465122757_0036_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:38:52  [ localfetcher#36:153728 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local1465122757_0036_m_000000_0
2020-11-20 13:38:52  [ localfetcher#36:153728 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:38:52  [ EventFetcher for fetching Map Completion Events:153728 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:52  [ pool-111-thread-1:153728 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:52  [ pool-111-thread-1:153728 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:52  [ pool-111-thread-1:153729 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:52  [ pool-111-thread-1:153729 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:38:52  [ pool-111-thread-1:153729 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:52  [ pool-111-thread-1:153730 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:38:52  [ pool-111-thread-1:153730 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:52  [ pool-111-thread-1:153730 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:52  [ pool-111-thread-1:153730 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:38:52  [ pool-111-thread-1:153730 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:52  [ pool-111-thread-1:153832 ] - [ INFO ]  Task:attempt_local1465122757_0036_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:52  [ pool-111-thread-1:153841 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:52  [ pool-111-thread-1:153841 ] - [ INFO ]  Task attempt_local1465122757_0036_r_000000_0 is allowed to commit now
2020-11-20 13:38:52  [ pool-111-thread-1:153867 ] - [ INFO ]  Saved output of task 'attempt_local1465122757_0036_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1465122757_0036_r_000000
2020-11-20 13:38:52  [ pool-111-thread-1:153867 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:52  [ pool-111-thread-1:153867 ] - [ INFO ]  Task 'attempt_local1465122757_0036_r_000000_0' done.
2020-11-20 13:38:52  [ pool-111-thread-1:153867 ] - [ INFO ]  Finishing task: attempt_local1465122757_0036_r_000000_0
2020-11-20 13:38:52  [ Thread-962:153867 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:53  [ main:154405 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:53  [ main:154406 ] - [ INFO ]  Job job_local1465122757_0036 completed successfully
2020-11-20 13:38:53  [ main:154406 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=47414
		FILE: Number of bytes written=21918511
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=38980314
		HDFS: Number of bytes written=14566
		HDFS: Number of read operations=1060
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=561
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1218
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3223322624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:53  [ main:154437 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:53  [ main:154454 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:53  [ main:154457 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:53  [ main:154465 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:53  [ main:154503 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:53  [ main:154519 ] - [ INFO ]  Submitting tokens for job: job_local578933398_0037
2020-11-20 13:38:53  [ main:154553 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:53  [ main:154553 ] - [ INFO ]  Running job: job_local578933398_0037
2020-11-20 13:38:53  [ Thread-989:154554 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:53  [ Thread-989:154554 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:53  [ Thread-989:154554 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:53  [ Thread-989:154563 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154564 ] - [ INFO ]  Starting task: attempt_local578933398_0037_m_000000_0
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154564 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154564 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154564 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154565 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154573 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154573 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154573 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154573 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154573 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:53  [ LocalJobRunner Map Task Executor #0:154573 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:54  [ main:155554 ] - [ INFO ]  Job job_local578933398_0037 running in uber mode : false
2020-11-20 13:38:54  [ main:155554 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157585 ] - [ INFO ]  
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157585 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157585 ] - [ INFO ]  Spilling map output
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157585 ] - [ INFO ]  bufstart = 0; bufend = 1150; bufvoid = 104857600
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157585 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157588 ] - [ INFO ]  Finished spill 0
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157588 ] - [ INFO ]  Task:attempt_local578933398_0037_m_000000_0 is done. And is in the process of committing
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157597 ] - [ INFO ]  map
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157597 ] - [ INFO ]  Task 'attempt_local578933398_0037_m_000000_0' done.
2020-11-20 13:38:56  [ LocalJobRunner Map Task Executor #0:157597 ] - [ INFO ]  Finishing task: attempt_local578933398_0037_m_000000_0
2020-11-20 13:38:56  [ Thread-989:157597 ] - [ INFO ]  map task executor complete.
2020-11-20 13:38:56  [ Thread-989:157598 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:38:56  [ pool-114-thread-1:157598 ] - [ INFO ]  Starting task: attempt_local578933398_0037_r_000000_0
2020-11-20 13:38:56  [ pool-114-thread-1:157598 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:56  [ pool-114-thread-1:157598 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:56  [ pool-114-thread-1:157598 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:56  [ pool-114-thread-1:157598 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5692434
2020-11-20 13:38:56  [ pool-114-thread-1:157599 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:38:56  [ EventFetcher for fetching Map Completion Events:157600 ] - [ INFO ]  attempt_local578933398_0037_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:38:56  [ localfetcher#37:157600 ] - [ INFO ]  localfetcher#37 about to shuffle output of map attempt_local578933398_0037_m_000000_0 decomp: 216 len: 220 to MEMORY
2020-11-20 13:38:56  [ localfetcher#37:157600 ] - [ INFO ]  Read 216 bytes from map-output for attempt_local578933398_0037_m_000000_0
2020-11-20 13:38:56  [ localfetcher#37:157600 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 216, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->216
2020-11-20 13:38:56  [ EventFetcher for fetching Map Completion Events:157601 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:38:56  [ pool-114-thread-1:157601 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:56  [ pool-114-thread-1:157601 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:38:56  [ pool-114-thread-1:157601 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:56  [ pool-114-thread-1:157601 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 210 bytes
2020-11-20 13:38:56  [ pool-114-thread-1:157602 ] - [ INFO ]  Merged 1 segments, 216 bytes to disk to satisfy reduce memory limit
2020-11-20 13:38:56  [ pool-114-thread-1:157602 ] - [ INFO ]  Merging 1 files, 220 bytes from disk
2020-11-20 13:38:56  [ pool-114-thread-1:157602 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:38:56  [ pool-114-thread-1:157602 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:38:56  [ pool-114-thread-1:157602 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 210 bytes
2020-11-20 13:38:56  [ pool-114-thread-1:157602 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:56  [ pool-114-thread-1:157713 ] - [ INFO ]  Task:attempt_local578933398_0037_r_000000_0 is done. And is in the process of committing
2020-11-20 13:38:56  [ pool-114-thread-1:157721 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:38:56  [ pool-114-thread-1:157721 ] - [ INFO ]  Task attempt_local578933398_0037_r_000000_0 is allowed to commit now
2020-11-20 13:38:56  [ pool-114-thread-1:157745 ] - [ INFO ]  Saved output of task 'attempt_local578933398_0037_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local578933398_0037_r_000000
2020-11-20 13:38:56  [ pool-114-thread-1:157746 ] - [ INFO ]  reduce > reduce
2020-11-20 13:38:56  [ pool-114-thread-1:157746 ] - [ INFO ]  Task 'attempt_local578933398_0037_r_000000_0' done.
2020-11-20 13:38:56  [ pool-114-thread-1:157746 ] - [ INFO ]  Finishing task: attempt_local578933398_0037_r_000000_0
2020-11-20 13:38:56  [ Thread-989:157746 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:38:57  [ main:158564 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:38:57  [ main:158564 ] - [ INFO ]  Job job_local578933398_0037 completed successfully
2020-11-20 13:38:57  [ main:158566 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=48738
		FILE: Number of bytes written=22536866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=40033836
		HDFS: Number of bytes written=14985
		HDFS: Number of read operations=1090
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=577
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1150
		Map output materialized bytes=220
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=220
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3223322624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:38:57  [ main:158590 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:38:57  [ main:158605 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:38:57  [ main:158609 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:38:57  [ main:158618 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:38:57  [ main:158657 ] - [ INFO ]  number of splits:1
2020-11-20 13:38:57  [ main:158674 ] - [ INFO ]  Submitting tokens for job: job_local2015768131_0038
2020-11-20 13:38:57  [ main:158707 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:38:57  [ main:158707 ] - [ INFO ]  Running job: job_local2015768131_0038
2020-11-20 13:38:57  [ Thread-1016:158708 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:38:57  [ Thread-1016:158708 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:57  [ Thread-1016:158708 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:38:57  [ Thread-1016:158718 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158718 ] - [ INFO ]  Starting task: attempt_local2015768131_0038_m_000000_0
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158719 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158719 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158719 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158719 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158727 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158727 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158727 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158727 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158727 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:38:57  [ LocalJobRunner Map Task Executor #0:158727 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:38:58  [ main:159708 ] - [ INFO ]  Job job_local2015768131_0038 running in uber mode : false
2020-11-20 13:38:58  [ main:159708 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161647 ] - [ INFO ]  
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161647 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161647 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161647 ] - [ INFO ]  bufstart = 0; bufend = 1180; bufvoid = 104857600
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161647 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161649 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161650 ] - [ INFO ]  Task:attempt_local2015768131_0038_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161658 ] - [ INFO ]  map
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161658 ] - [ INFO ]  Task 'attempt_local2015768131_0038_m_000000_0' done.
2020-11-20 13:39:00  [ LocalJobRunner Map Task Executor #0:161658 ] - [ INFO ]  Finishing task: attempt_local2015768131_0038_m_000000_0
2020-11-20 13:39:00  [ Thread-1016:161658 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:00  [ Thread-1016:161659 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:00  [ pool-117-thread-1:161659 ] - [ INFO ]  Starting task: attempt_local2015768131_0038_r_000000_0
2020-11-20 13:39:00  [ pool-117-thread-1:161660 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:00  [ pool-117-thread-1:161660 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:00  [ pool-117-thread-1:161660 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:00  [ pool-117-thread-1:161660 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@727f2737
2020-11-20 13:39:00  [ pool-117-thread-1:161660 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:00  [ EventFetcher for fetching Map Completion Events:161661 ] - [ INFO ]  attempt_local2015768131_0038_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:00  [ localfetcher#38:161661 ] - [ INFO ]  localfetcher#38 about to shuffle output of map attempt_local2015768131_0038_m_000000_0 decomp: 222 len: 226 to MEMORY
2020-11-20 13:39:00  [ localfetcher#38:161662 ] - [ INFO ]  Read 222 bytes from map-output for attempt_local2015768131_0038_m_000000_0
2020-11-20 13:39:00  [ localfetcher#38:161662 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 222, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->222
2020-11-20 13:39:00  [ EventFetcher for fetching Map Completion Events:161662 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:00  [ pool-117-thread-1:161662 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:00  [ pool-117-thread-1:161662 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:00  [ pool-117-thread-1:161663 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:00  [ pool-117-thread-1:161663 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:39:00  [ pool-117-thread-1:161664 ] - [ INFO ]  Merged 1 segments, 222 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:00  [ pool-117-thread-1:161664 ] - [ INFO ]  Merging 1 files, 226 bytes from disk
2020-11-20 13:39:00  [ pool-117-thread-1:161664 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:00  [ pool-117-thread-1:161664 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:00  [ pool-117-thread-1:161664 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 216 bytes
2020-11-20 13:39:00  [ pool-117-thread-1:161664 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:00  [ main:161714 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:39:00  [ pool-117-thread-1:161761 ] - [ INFO ]  Task:attempt_local2015768131_0038_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:00  [ pool-117-thread-1:161770 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:00  [ pool-117-thread-1:161770 ] - [ INFO ]  Task attempt_local2015768131_0038_r_000000_0 is allowed to commit now
2020-11-20 13:39:00  [ pool-117-thread-1:161795 ] - [ INFO ]  Saved output of task 'attempt_local2015768131_0038_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2015768131_0038_r_000000
2020-11-20 13:39:00  [ pool-117-thread-1:161795 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:00  [ pool-117-thread-1:161795 ] - [ INFO ]  Task 'attempt_local2015768131_0038_r_000000_0' done.
2020-11-20 13:39:00  [ pool-117-thread-1:161795 ] - [ INFO ]  Finishing task: attempt_local2015768131_0038_r_000000_0
2020-11-20 13:39:00  [ Thread-1016:161795 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:01  [ main:162715 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:01  [ main:162715 ] - [ INFO ]  Job job_local2015768131_0038 completed successfully
2020-11-20 13:39:01  [ main:162716 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=50072
		FILE: Number of bytes written=23158438
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=41087358
		HDFS: Number of bytes written=15409
		HDFS: Number of read operations=1120
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=593
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1180
		Map output materialized bytes=226
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=226
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3223322624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:01  [ main:162746 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:01  [ main:162760 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:01  [ main:162765 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:01  [ main:162773 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:01  [ main:162814 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:01  [ main:162831 ] - [ INFO ]  Submitting tokens for job: job_local1527516523_0039
2020-11-20 13:39:01  [ main:162866 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:01  [ main:162866 ] - [ INFO ]  Running job: job_local1527516523_0039
2020-11-20 13:39:01  [ Thread-1043:162866 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:01  [ Thread-1043:162866 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:01  [ Thread-1043:162866 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:01  [ Thread-1043:162876 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162876 ] - [ INFO ]  Starting task: attempt_local1527516523_0039_m_000000_0
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162877 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162877 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162877 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162877 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162888 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162888 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162888 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162888 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162888 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:01  [ LocalJobRunner Map Task Executor #0:162888 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:02  [ main:163870 ] - [ INFO ]  Job job_local1527516523_0039 running in uber mode : false
2020-11-20 13:39:02  [ main:163870 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165981 ] - [ INFO ]  
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165981 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165981 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165981 ] - [ INFO ]  bufstart = 0; bufend = 1186; bufvoid = 104857600
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165981 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165982 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165983 ] - [ INFO ]  Task:attempt_local1527516523_0039_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165994 ] - [ INFO ]  map
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165994 ] - [ INFO ]  Task 'attempt_local1527516523_0039_m_000000_0' done.
2020-11-20 13:39:04  [ LocalJobRunner Map Task Executor #0:165994 ] - [ INFO ]  Finishing task: attempt_local1527516523_0039_m_000000_0
2020-11-20 13:39:04  [ Thread-1043:165994 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:04  [ Thread-1043:165994 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:04  [ pool-120-thread-1:165995 ] - [ INFO ]  Starting task: attempt_local1527516523_0039_r_000000_0
2020-11-20 13:39:04  [ pool-120-thread-1:165995 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:04  [ pool-120-thread-1:165995 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:04  [ pool-120-thread-1:165995 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:04  [ pool-120-thread-1:165995 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64a94f2e
2020-11-20 13:39:04  [ pool-120-thread-1:165996 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:04  [ EventFetcher for fetching Map Completion Events:165996 ] - [ INFO ]  attempt_local1527516523_0039_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:04  [ localfetcher#39:165997 ] - [ INFO ]  localfetcher#39 about to shuffle output of map attempt_local1527516523_0039_m_000000_0 decomp: 220 len: 224 to MEMORY
2020-11-20 13:39:04  [ localfetcher#39:165997 ] - [ INFO ]  Read 220 bytes from map-output for attempt_local1527516523_0039_m_000000_0
2020-11-20 13:39:04  [ localfetcher#39:165997 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220
2020-11-20 13:39:04  [ EventFetcher for fetching Map Completion Events:165998 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:04  [ pool-120-thread-1:165998 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:04  [ pool-120-thread-1:165998 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:04  [ pool-120-thread-1:165999 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:04  [ pool-120-thread-1:165999 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:39:04  [ pool-120-thread-1:165999 ] - [ INFO ]  Merged 1 segments, 220 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:04  [ pool-120-thread-1:166000 ] - [ INFO ]  Merging 1 files, 224 bytes from disk
2020-11-20 13:39:04  [ pool-120-thread-1:166000 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:04  [ pool-120-thread-1:166000 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:04  [ pool-120-thread-1:166000 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 214 bytes
2020-11-20 13:39:04  [ pool-120-thread-1:166000 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:05  [ pool-120-thread-1:166103 ] - [ INFO ]  Task:attempt_local1527516523_0039_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:05  [ pool-120-thread-1:166111 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:05  [ pool-120-thread-1:166111 ] - [ INFO ]  Task attempt_local1527516523_0039_r_000000_0 is allowed to commit now
2020-11-20 13:39:05  [ pool-120-thread-1:166136 ] - [ INFO ]  Saved output of task 'attempt_local1527516523_0039_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1527516523_0039_r_000000
2020-11-20 13:39:05  [ pool-120-thread-1:166136 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:05  [ pool-120-thread-1:166136 ] - [ INFO ]  Task 'attempt_local1527516523_0039_r_000000_0' done.
2020-11-20 13:39:05  [ pool-120-thread-1:166137 ] - [ INFO ]  Finishing task: attempt_local1527516523_0039_r_000000_0
2020-11-20 13:39:05  [ Thread-1043:166137 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:05  [ main:166875 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:05  [ main:166875 ] - [ INFO ]  Job job_local1527516523_0039 completed successfully
2020-11-20 13:39:05  [ main:166876 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=51414
		FILE: Number of bytes written=23780286
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=42140880
		HDFS: Number of bytes written=15837
		HDFS: Number of read operations=1150
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=609
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1186
		Map output materialized bytes=224
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=224
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=3139436544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:05  [ main:166902 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:05  [ main:166915 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:05  [ main:166919 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:05  [ main:166926 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:05  [ main:166964 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:05  [ main:166980 ] - [ INFO ]  Submitting tokens for job: job_local1026711656_0040
2020-11-20 13:39:05  [ main:167012 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:05  [ main:167012 ] - [ INFO ]  Running job: job_local1026711656_0040
2020-11-20 13:39:05  [ Thread-1070:167012 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:05  [ Thread-1070:167012 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:05  [ Thread-1070:167012 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:05  [ Thread-1070:167023 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:05  [ LocalJobRunner Map Task Executor #0:167023 ] - [ INFO ]  Starting task: attempt_local1026711656_0040_m_000000_0
2020-11-20 13:39:05  [ LocalJobRunner Map Task Executor #0:167023 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:05  [ LocalJobRunner Map Task Executor #0:167023 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:05  [ LocalJobRunner Map Task Executor #0:167023 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167024 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167032 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167032 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167032 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167032 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167032 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:06  [ LocalJobRunner Map Task Executor #0:167032 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:06  [ main:168014 ] - [ INFO ]  Job job_local1026711656_0040 running in uber mode : false
2020-11-20 13:39:06  [ main:168014 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170219 ] - [ INFO ]  
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170219 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170219 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170219 ] - [ INFO ]  bufstart = 0; bufend = 1185; bufvoid = 104857600
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170219 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170221 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170222 ] - [ INFO ]  Task:attempt_local1026711656_0040_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170230 ] - [ INFO ]  map
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170230 ] - [ INFO ]  Task 'attempt_local1026711656_0040_m_000000_0' done.
2020-11-20 13:39:09  [ LocalJobRunner Map Task Executor #0:170230 ] - [ INFO ]  Finishing task: attempt_local1026711656_0040_m_000000_0
2020-11-20 13:39:09  [ Thread-1070:170230 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:09  [ Thread-1070:170231 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:09  [ pool-123-thread-1:170231 ] - [ INFO ]  Starting task: attempt_local1026711656_0040_r_000000_0
2020-11-20 13:39:09  [ pool-123-thread-1:170231 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:09  [ pool-123-thread-1:170231 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:09  [ pool-123-thread-1:170232 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:09  [ pool-123-thread-1:170232 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1296b6eb
2020-11-20 13:39:09  [ pool-123-thread-1:170233 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:09  [ EventFetcher for fetching Map Completion Events:170233 ] - [ INFO ]  attempt_local1026711656_0040_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:09  [ localfetcher#40:170233 ] - [ INFO ]  localfetcher#40 about to shuffle output of map attempt_local1026711656_0040_m_000000_0 decomp: 202 len: 206 to MEMORY
2020-11-20 13:39:09  [ localfetcher#40:170234 ] - [ INFO ]  Read 202 bytes from map-output for attempt_local1026711656_0040_m_000000_0
2020-11-20 13:39:09  [ localfetcher#40:170234 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 202, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->202
2020-11-20 13:39:09  [ EventFetcher for fetching Map Completion Events:170234 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:09  [ pool-123-thread-1:170234 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:09  [ pool-123-thread-1:170234 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 196 bytes
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Merged 1 segments, 202 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Merging 1 files, 206 bytes from disk
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:09  [ pool-123-thread-1:170235 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 196 bytes
2020-11-20 13:39:09  [ pool-123-thread-1:170236 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:09  [ pool-123-thread-1:170337 ] - [ INFO ]  Task:attempt_local1026711656_0040_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:09  [ pool-123-thread-1:170347 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:09  [ pool-123-thread-1:170347 ] - [ INFO ]  Task attempt_local1026711656_0040_r_000000_0 is allowed to commit now
2020-11-20 13:39:09  [ pool-123-thread-1:170373 ] - [ INFO ]  Saved output of task 'attempt_local1026711656_0040_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1026711656_0040_r_000000
2020-11-20 13:39:09  [ pool-123-thread-1:170374 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:09  [ pool-123-thread-1:170374 ] - [ INFO ]  Task 'attempt_local1026711656_0040_r_000000_0' done.
2020-11-20 13:39:09  [ pool-123-thread-1:170374 ] - [ INFO ]  Finishing task: attempt_local1026711656_0040_r_000000_0
2020-11-20 13:39:09  [ Thread-1070:170374 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:09  [ main:171020 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:09  [ main:171020 ] - [ INFO ]  Job job_local1026711656_0040 completed successfully
2020-11-20 13:39:09  [ main:171021 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=52716
		FILE: Number of bytes written=24402302
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=43194402
		HDFS: Number of bytes written=16245
		HDFS: Number of read operations=1180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=625
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1185
		Map output materialized bytes=206
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=206
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3139436544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:10  [ main:171053 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:10  [ main:171068 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:10  [ main:171072 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:10  [ main:171080 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:10  [ main:171119 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:10  [ main:171136 ] - [ INFO ]  Submitting tokens for job: job_local937123463_0041
2020-11-20 13:39:10  [ main:171173 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:10  [ main:171173 ] - [ INFO ]  Running job: job_local937123463_0041
2020-11-20 13:39:10  [ Thread-1097:171173 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:10  [ Thread-1097:171173 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:10  [ Thread-1097:171173 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:10  [ Thread-1097:171182 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171182 ] - [ INFO ]  Starting task: attempt_local937123463_0041_m_000000_0
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171182 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171183 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171183 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171183 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171191 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171191 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171191 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171191 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171191 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:10  [ LocalJobRunner Map Task Executor #0:171191 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:11  [ main:172174 ] - [ INFO ]  Job job_local937123463_0041 running in uber mode : false
2020-11-20 13:39:11  [ main:172174 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174326 ] - [ INFO ]  
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174326 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174326 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174326 ] - [ INFO ]  bufstart = 0; bufend = 1192; bufvoid = 104857600
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174326 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174327 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174328 ] - [ INFO ]  Task:attempt_local937123463_0041_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174337 ] - [ INFO ]  map
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174337 ] - [ INFO ]  Task 'attempt_local937123463_0041_m_000000_0' done.
2020-11-20 13:39:13  [ LocalJobRunner Map Task Executor #0:174337 ] - [ INFO ]  Finishing task: attempt_local937123463_0041_m_000000_0
2020-11-20 13:39:13  [ Thread-1097:174337 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:13  [ Thread-1097:174337 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:13  [ pool-126-thread-1:174338 ] - [ INFO ]  Starting task: attempt_local937123463_0041_r_000000_0
2020-11-20 13:39:13  [ pool-126-thread-1:174338 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:13  [ pool-126-thread-1:174338 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:13  [ pool-126-thread-1:174338 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:13  [ pool-126-thread-1:174338 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65070d87
2020-11-20 13:39:13  [ pool-126-thread-1:174339 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:13  [ EventFetcher for fetching Map Completion Events:174339 ] - [ INFO ]  attempt_local937123463_0041_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:13  [ localfetcher#41:174340 ] - [ INFO ]  localfetcher#41 about to shuffle output of map attempt_local937123463_0041_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:39:13  [ localfetcher#41:174340 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local937123463_0041_m_000000_0
2020-11-20 13:39:13  [ localfetcher#41:174340 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:39:13  [ EventFetcher for fetching Map Completion Events:174340 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:13  [ pool-126-thread-1:174340 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:13  [ pool-126-thread-1:174340 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:13  [ pool-126-thread-1:174341 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:13  [ pool-126-thread-1:174341 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:39:13  [ pool-126-thread-1:174342 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:13  [ pool-126-thread-1:174342 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:39:13  [ pool-126-thread-1:174342 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:13  [ pool-126-thread-1:174342 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:13  [ pool-126-thread-1:174342 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:39:13  [ pool-126-thread-1:174342 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:13  [ pool-126-thread-1:174446 ] - [ INFO ]  Task:attempt_local937123463_0041_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:13  [ pool-126-thread-1:174454 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:13  [ pool-126-thread-1:174454 ] - [ INFO ]  Task attempt_local937123463_0041_r_000000_0 is allowed to commit now
2020-11-20 13:39:13  [ pool-126-thread-1:174479 ] - [ INFO ]  Saved output of task 'attempt_local937123463_0041_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local937123463_0041_r_000000
2020-11-20 13:39:13  [ pool-126-thread-1:174479 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:13  [ pool-126-thread-1:174479 ] - [ INFO ]  Task 'attempt_local937123463_0041_r_000000_0' done.
2020-11-20 13:39:13  [ pool-126-thread-1:174479 ] - [ INFO ]  Finishing task: attempt_local937123463_0041_r_000000_0
2020-11-20 13:39:13  [ Thread-1097:174479 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:14  [ main:175180 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:14  [ main:175180 ] - [ INFO ]  Job job_local937123463_0041 completed successfully
2020-11-20 13:39:14  [ main:175181 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=54012
		FILE: Number of bytes written=25021365
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44247924
		HDFS: Number of bytes written=16650
		HDFS: Number of read operations=1210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=641
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1192
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3139436544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:14  [ main:175212 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:14  [ main:175224 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:14  [ main:175228 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:14  [ main:175236 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:14  [ main:175283 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:14  [ main:175317 ] - [ INFO ]  Submitting tokens for job: job_local1789953668_0042
2020-11-20 13:39:14  [ main:175352 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:14  [ main:175352 ] - [ INFO ]  Running job: job_local1789953668_0042
2020-11-20 13:39:14  [ Thread-1124:175352 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:14  [ Thread-1124:175353 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:14  [ Thread-1124:175353 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:14  [ Thread-1124:175362 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175362 ] - [ INFO ]  Starting task: attempt_local1789953668_0042_m_000000_0
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175363 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175363 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175363 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175363 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175371 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175372 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175372 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175372 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175372 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:14  [ LocalJobRunner Map Task Executor #0:175372 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:15  [ main:176353 ] - [ INFO ]  Job job_local1789953668_0042 running in uber mode : false
2020-11-20 13:39:15  [ main:176353 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178459 ] - [ INFO ]  
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178459 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178459 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178459 ] - [ INFO ]  bufstart = 0; bufend = 1211; bufvoid = 104857600
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178459 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178461 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178462 ] - [ INFO ]  Task:attempt_local1789953668_0042_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178471 ] - [ INFO ]  map
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178471 ] - [ INFO ]  Task 'attempt_local1789953668_0042_m_000000_0' done.
2020-11-20 13:39:17  [ LocalJobRunner Map Task Executor #0:178471 ] - [ INFO ]  Finishing task: attempt_local1789953668_0042_m_000000_0
2020-11-20 13:39:17  [ Thread-1124:178471 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:17  [ Thread-1124:178471 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:17  [ pool-129-thread-1:178471 ] - [ INFO ]  Starting task: attempt_local1789953668_0042_r_000000_0
2020-11-20 13:39:17  [ pool-129-thread-1:178472 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:17  [ pool-129-thread-1:178472 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:17  [ pool-129-thread-1:178472 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:17  [ pool-129-thread-1:178472 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2771464b
2020-11-20 13:39:17  [ pool-129-thread-1:178474 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:17  [ EventFetcher for fetching Map Completion Events:178474 ] - [ INFO ]  attempt_local1789953668_0042_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:17  [ localfetcher#42:178475 ] - [ INFO ]  localfetcher#42 about to shuffle output of map attempt_local1789953668_0042_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:39:17  [ localfetcher#42:178475 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local1789953668_0042_m_000000_0
2020-11-20 13:39:17  [ localfetcher#42:178475 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:39:17  [ EventFetcher for fetching Map Completion Events:178475 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:17  [ pool-129-thread-1:178476 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:17  [ pool-129-thread-1:178476 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:17  [ pool-129-thread-1:178476 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:17  [ pool-129-thread-1:178476 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:39:17  [ pool-129-thread-1:178477 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:17  [ pool-129-thread-1:178477 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:39:17  [ pool-129-thread-1:178477 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:17  [ pool-129-thread-1:178477 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:17  [ pool-129-thread-1:178477 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:39:17  [ pool-129-thread-1:178477 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:17  [ pool-129-thread-1:178577 ] - [ INFO ]  Task:attempt_local1789953668_0042_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:17  [ pool-129-thread-1:178586 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:17  [ pool-129-thread-1:178586 ] - [ INFO ]  Task attempt_local1789953668_0042_r_000000_0 is allowed to commit now
2020-11-20 13:39:17  [ pool-129-thread-1:178612 ] - [ INFO ]  Saved output of task 'attempt_local1789953668_0042_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1789953668_0042_r_000000
2020-11-20 13:39:17  [ pool-129-thread-1:178613 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:17  [ pool-129-thread-1:178613 ] - [ INFO ]  Task 'attempt_local1789953668_0042_r_000000_0' done.
2020-11-20 13:39:17  [ pool-129-thread-1:178613 ] - [ INFO ]  Finishing task: attempt_local1789953668_0042_r_000000_0
2020-11-20 13:39:17  [ Thread-1124:178613 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:18  [ main:179364 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:18  [ main:179364 ] - [ INFO ]  Job job_local1789953668_0042 completed successfully
2020-11-20 13:39:18  [ main:179366 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=55340
		FILE: Number of bytes written=25643646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=45301446
		HDFS: Number of bytes written=17071
		HDFS: Number of read operations=1240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=657
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1211
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3139436544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:18  [ main:179391 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:18  [ main:179406 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:18  [ main:179410 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:18  [ main:179418 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:18  [ main:179459 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:18  [ main:179476 ] - [ INFO ]  Submitting tokens for job: job_local962767687_0043
2020-11-20 13:39:18  [ main:179511 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:18  [ main:179511 ] - [ INFO ]  Running job: job_local962767687_0043
2020-11-20 13:39:18  [ Thread-1151:179511 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:18  [ Thread-1151:179511 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:18  [ Thread-1151:179511 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:18  [ Thread-1151:179522 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179522 ] - [ INFO ]  Starting task: attempt_local962767687_0043_m_000000_0
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179522 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179522 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179522 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179523 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179532 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179532 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179532 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179533 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179533 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:18  [ LocalJobRunner Map Task Executor #0:179533 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:19  [ main:180514 ] - [ INFO ]  Job job_local962767687_0043 running in uber mode : false
2020-11-20 13:39:19  [ main:180514 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182535 ] - [ INFO ]  
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182535 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182535 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182535 ] - [ INFO ]  bufstart = 0; bufend = 1170; bufvoid = 104857600
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182535 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182537 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182538 ] - [ INFO ]  Task:attempt_local962767687_0043_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182547 ] - [ INFO ]  map
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182547 ] - [ INFO ]  Task 'attempt_local962767687_0043_m_000000_0' done.
2020-11-20 13:39:21  [ LocalJobRunner Map Task Executor #0:182547 ] - [ INFO ]  Finishing task: attempt_local962767687_0043_m_000000_0
2020-11-20 13:39:21  [ Thread-1151:182547 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:21  [ Thread-1151:182548 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:21  [ pool-132-thread-1:182548 ] - [ INFO ]  Starting task: attempt_local962767687_0043_r_000000_0
2020-11-20 13:39:21  [ pool-132-thread-1:182549 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:21  [ pool-132-thread-1:182549 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:21  [ pool-132-thread-1:182549 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:21  [ pool-132-thread-1:182549 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52cfe503
2020-11-20 13:39:21  [ pool-132-thread-1:182550 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:21  [ EventFetcher for fetching Map Completion Events:182550 ] - [ INFO ]  attempt_local962767687_0043_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:21  [ localfetcher#43:182551 ] - [ INFO ]  localfetcher#43 about to shuffle output of map attempt_local962767687_0043_m_000000_0 decomp: 216 len: 220 to MEMORY
2020-11-20 13:39:21  [ localfetcher#43:182551 ] - [ INFO ]  Read 216 bytes from map-output for attempt_local962767687_0043_m_000000_0
2020-11-20 13:39:21  [ localfetcher#43:182551 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 216, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->216
2020-11-20 13:39:21  [ EventFetcher for fetching Map Completion Events:182552 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:21  [ pool-132-thread-1:182552 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:21  [ pool-132-thread-1:182552 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:21  [ pool-132-thread-1:182553 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:21  [ pool-132-thread-1:182553 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 210 bytes
2020-11-20 13:39:21  [ pool-132-thread-1:182554 ] - [ INFO ]  Merged 1 segments, 216 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:21  [ pool-132-thread-1:182554 ] - [ INFO ]  Merging 1 files, 220 bytes from disk
2020-11-20 13:39:21  [ pool-132-thread-1:182554 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:21  [ pool-132-thread-1:182554 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:21  [ pool-132-thread-1:182554 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 210 bytes
2020-11-20 13:39:21  [ pool-132-thread-1:182555 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:21  [ pool-132-thread-1:182665 ] - [ INFO ]  Task:attempt_local962767687_0043_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:21  [ pool-132-thread-1:182674 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:21  [ pool-132-thread-1:182674 ] - [ INFO ]  Task attempt_local962767687_0043_r_000000_0 is allowed to commit now
2020-11-20 13:39:21  [ pool-132-thread-1:182701 ] - [ INFO ]  Saved output of task 'attempt_local962767687_0043_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local962767687_0043_r_000000
2020-11-20 13:39:21  [ pool-132-thread-1:182701 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:21  [ pool-132-thread-1:182702 ] - [ INFO ]  Task 'attempt_local962767687_0043_r_000000_0' done.
2020-11-20 13:39:21  [ pool-132-thread-1:182702 ] - [ INFO ]  Finishing task: attempt_local962767687_0043_r_000000_0
2020-11-20 13:39:21  [ Thread-1151:182702 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:22  [ main:183523 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:22  [ main:183523 ] - [ INFO ]  Job job_local962767687_0043 completed successfully
2020-11-20 13:39:22  [ main:183524 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=56666
		FILE: Number of bytes written=26262942
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=46354968
		HDFS: Number of bytes written=17491
		HDFS: Number of read operations=1270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=673
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1170
		Map output materialized bytes=220
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=220
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=3059744768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:22  [ main:183551 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:22  [ main:183573 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:22  [ main:183578 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:22  [ main:183587 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:22  [ main:183632 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:22  [ main:183650 ] - [ INFO ]  Submitting tokens for job: job_local389863710_0044
2020-11-20 13:39:22  [ main:183687 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:22  [ main:183687 ] - [ INFO ]  Running job: job_local389863710_0044
2020-11-20 13:39:22  [ Thread-1178:183687 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:22  [ Thread-1178:183687 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:22  [ Thread-1178:183687 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:22  [ Thread-1178:183697 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183697 ] - [ INFO ]  Starting task: attempt_local389863710_0044_m_000000_0
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183697 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183698 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183698 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183698 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183705 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183705 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183705 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183705 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183705 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:22  [ LocalJobRunner Map Task Executor #0:183706 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:23  [ main:184691 ] - [ INFO ]  Job job_local389863710_0044 running in uber mode : false
2020-11-20 13:39:23  [ main:184691 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186833 ] - [ INFO ]  
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186833 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186834 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186834 ] - [ INFO ]  bufstart = 0; bufend = 1208; bufvoid = 104857600
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186834 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186835 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186836 ] - [ INFO ]  Task:attempt_local389863710_0044_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186844 ] - [ INFO ]  map
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186844 ] - [ INFO ]  Task 'attempt_local389863710_0044_m_000000_0' done.
2020-11-20 13:39:25  [ LocalJobRunner Map Task Executor #0:186844 ] - [ INFO ]  Finishing task: attempt_local389863710_0044_m_000000_0
2020-11-20 13:39:25  [ Thread-1178:186844 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:25  [ Thread-1178:186845 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:25  [ pool-135-thread-1:186845 ] - [ INFO ]  Starting task: attempt_local389863710_0044_r_000000_0
2020-11-20 13:39:25  [ pool-135-thread-1:186845 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:25  [ pool-135-thread-1:186846 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:25  [ pool-135-thread-1:186846 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:25  [ pool-135-thread-1:186846 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15f1d838
2020-11-20 13:39:25  [ pool-135-thread-1:186846 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:25  [ EventFetcher for fetching Map Completion Events:186846 ] - [ INFO ]  attempt_local389863710_0044_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:25  [ localfetcher#44:186847 ] - [ INFO ]  localfetcher#44 about to shuffle output of map attempt_local389863710_0044_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:39:25  [ localfetcher#44:186847 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local389863710_0044_m_000000_0
2020-11-20 13:39:25  [ localfetcher#44:186848 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:39:25  [ EventFetcher for fetching Map Completion Events:186848 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:25  [ pool-135-thread-1:186848 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:25  [ pool-135-thread-1:186848 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:25  [ pool-135-thread-1:186849 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:25  [ pool-135-thread-1:186849 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:39:25  [ pool-135-thread-1:186850 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:25  [ pool-135-thread-1:186850 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:39:25  [ pool-135-thread-1:186850 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:25  [ pool-135-thread-1:186850 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:25  [ pool-135-thread-1:186850 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:39:25  [ pool-135-thread-1:186850 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:25  [ pool-135-thread-1:186950 ] - [ INFO ]  Task:attempt_local389863710_0044_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:25  [ pool-135-thread-1:186959 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:25  [ pool-135-thread-1:186959 ] - [ INFO ]  Task attempt_local389863710_0044_r_000000_0 is allowed to commit now
2020-11-20 13:39:25  [ pool-135-thread-1:186984 ] - [ INFO ]  Saved output of task 'attempt_local389863710_0044_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local389863710_0044_r_000000
2020-11-20 13:39:25  [ pool-135-thread-1:186985 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:25  [ pool-135-thread-1:186985 ] - [ INFO ]  Task 'attempt_local389863710_0044_r_000000_0' done.
2020-11-20 13:39:25  [ pool-135-thread-1:186985 ] - [ INFO ]  Finishing task: attempt_local389863710_0044_r_000000_0
2020-11-20 13:39:25  [ Thread-1178:186985 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:26  [ main:187701 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:26  [ main:187701 ] - [ INFO ]  Job job_local389863710_0044 completed successfully
2020-11-20 13:39:26  [ main:187701 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=57992
		FILE: Number of bytes written=26882374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=47408490
		HDFS: Number of bytes written=17911
		HDFS: Number of read operations=1300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=689
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1208
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3059744768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:26  [ main:187732 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:26  [ main:187744 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:26  [ main:187748 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:26  [ main:187758 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:26  [ main:187795 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:26  [ main:187813 ] - [ INFO ]  Submitting tokens for job: job_local136119820_0045
2020-11-20 13:39:26  [ main:187847 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:26  [ main:187847 ] - [ INFO ]  Running job: job_local136119820_0045
2020-11-20 13:39:26  [ Thread-1205:187847 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:26  [ Thread-1205:187847 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:26  [ Thread-1205:187848 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:26  [ Thread-1205:187859 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187859 ] - [ INFO ]  Starting task: attempt_local136119820_0045_m_000000_0
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187859 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187860 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187860 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187860 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187868 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187868 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187868 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187868 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187869 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:26  [ LocalJobRunner Map Task Executor #0:187869 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:27  [ main:188851 ] - [ INFO ]  Job job_local136119820_0045 running in uber mode : false
2020-11-20 13:39:27  [ main:188851 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190837 ] - [ INFO ]  
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190837 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190837 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190837 ] - [ INFO ]  bufstart = 0; bufend = 1172; bufvoid = 104857600
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190837 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190839 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190840 ] - [ INFO ]  Task:attempt_local136119820_0045_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190848 ] - [ INFO ]  map
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190848 ] - [ INFO ]  Task 'attempt_local136119820_0045_m_000000_0' done.
2020-11-20 13:39:29  [ LocalJobRunner Map Task Executor #0:190848 ] - [ INFO ]  Finishing task: attempt_local136119820_0045_m_000000_0
2020-11-20 13:39:29  [ Thread-1205:190848 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:29  [ Thread-1205:190849 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:29  [ pool-138-thread-1:190849 ] - [ INFO ]  Starting task: attempt_local136119820_0045_r_000000_0
2020-11-20 13:39:29  [ pool-138-thread-1:190850 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:29  [ pool-138-thread-1:190850 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:29  [ pool-138-thread-1:190850 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:29  [ pool-138-thread-1:190850 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19146686
2020-11-20 13:39:29  [ pool-138-thread-1:190851 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:29  [ EventFetcher for fetching Map Completion Events:190851 ] - [ INFO ]  attempt_local136119820_0045_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:29  [ localfetcher#45:190852 ] - [ INFO ]  localfetcher#45 about to shuffle output of map attempt_local136119820_0045_m_000000_0 decomp: 218 len: 222 to MEMORY
2020-11-20 13:39:29  [ localfetcher#45:190852 ] - [ INFO ]  Read 218 bytes from map-output for attempt_local136119820_0045_m_000000_0
2020-11-20 13:39:29  [ localfetcher#45:190852 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->218
2020-11-20 13:39:29  [ EventFetcher for fetching Map Completion Events:190852 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:29  [ pool-138-thread-1:190853 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:29  [ pool-138-thread-1:190853 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:29  [ pool-138-thread-1:190853 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  Merged 1 segments, 218 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  Merging 1 files, 222 bytes from disk
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2020-11-20 13:39:29  [ pool-138-thread-1:190854 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:29  [ main:190856 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:39:29  [ pool-138-thread-1:190951 ] - [ INFO ]  Task:attempt_local136119820_0045_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:29  [ pool-138-thread-1:190959 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:29  [ pool-138-thread-1:190959 ] - [ INFO ]  Task attempt_local136119820_0045_r_000000_0 is allowed to commit now
2020-11-20 13:39:29  [ pool-138-thread-1:190984 ] - [ INFO ]  Saved output of task 'attempt_local136119820_0045_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local136119820_0045_r_000000
2020-11-20 13:39:29  [ pool-138-thread-1:190984 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:29  [ pool-138-thread-1:190984 ] - [ INFO ]  Task 'attempt_local136119820_0045_r_000000_0' done.
2020-11-20 13:39:29  [ pool-138-thread-1:190984 ] - [ INFO ]  Finishing task: attempt_local136119820_0045_r_000000_0
2020-11-20 13:39:29  [ Thread-1205:190984 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:30  [ main:191859 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:30  [ main:191859 ] - [ INFO ]  Job job_local136119820_0045 completed successfully
2020-11-20 13:39:30  [ main:191860 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=59322
		FILE: Number of bytes written=27502044
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=48462012
		HDFS: Number of bytes written=18333
		HDFS: Number of read operations=1330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=705
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1172
		Map output materialized bytes=222
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=222
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3059744768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:30  [ main:191890 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:30  [ main:191905 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:30  [ main:191909 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:30  [ main:191918 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:30  [ main:191963 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:30  [ main:191979 ] - [ INFO ]  Submitting tokens for job: job_local449646389_0046
2020-11-20 13:39:30  [ main:192012 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:30  [ main:192012 ] - [ INFO ]  Running job: job_local449646389_0046
2020-11-20 13:39:30  [ Thread-1232:192013 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:30  [ Thread-1232:192013 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:30  [ Thread-1232:192013 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:30  [ Thread-1232:192022 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:30  [ LocalJobRunner Map Task Executor #0:192023 ] - [ INFO ]  Starting task: attempt_local449646389_0046_m_000000_0
2020-11-20 13:39:30  [ LocalJobRunner Map Task Executor #0:192023 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:30  [ LocalJobRunner Map Task Executor #0:192023 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:30  [ LocalJobRunner Map Task Executor #0:192023 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192024 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192032 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192032 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192032 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192032 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192032 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:31  [ LocalJobRunner Map Task Executor #0:192032 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:31  [ main:193015 ] - [ INFO ]  Job job_local449646389_0046 running in uber mode : false
2020-11-20 13:39:31  [ main:193015 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195055 ] - [ INFO ]  
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195055 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195055 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195055 ] - [ INFO ]  bufstart = 0; bufend = 1175; bufvoid = 104857600
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195055 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195057 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195058 ] - [ INFO ]  Task:attempt_local449646389_0046_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195066 ] - [ INFO ]  map
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195066 ] - [ INFO ]  Task 'attempt_local449646389_0046_m_000000_0' done.
2020-11-20 13:39:34  [ LocalJobRunner Map Task Executor #0:195066 ] - [ INFO ]  Finishing task: attempt_local449646389_0046_m_000000_0
2020-11-20 13:39:34  [ Thread-1232:195066 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:34  [ Thread-1232:195067 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:34  [ pool-141-thread-1:195067 ] - [ INFO ]  Starting task: attempt_local449646389_0046_r_000000_0
2020-11-20 13:39:34  [ pool-141-thread-1:195067 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:34  [ pool-141-thread-1:195067 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:34  [ pool-141-thread-1:195067 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:34  [ pool-141-thread-1:195067 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@714dfe63
2020-11-20 13:39:34  [ pool-141-thread-1:195068 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:34  [ EventFetcher for fetching Map Completion Events:195068 ] - [ INFO ]  attempt_local449646389_0046_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:34  [ localfetcher#46:195069 ] - [ INFO ]  localfetcher#46 about to shuffle output of map attempt_local449646389_0046_m_000000_0 decomp: 214 len: 218 to MEMORY
2020-11-20 13:39:34  [ localfetcher#46:195069 ] - [ INFO ]  Read 214 bytes from map-output for attempt_local449646389_0046_m_000000_0
2020-11-20 13:39:34  [ localfetcher#46:195069 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 214, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->214
2020-11-20 13:39:34  [ EventFetcher for fetching Map Completion Events:195070 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:34  [ pool-141-thread-1:195070 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:34  [ pool-141-thread-1:195070 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:34  [ pool-141-thread-1:195071 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:34  [ pool-141-thread-1:195071 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:39:34  [ pool-141-thread-1:195071 ] - [ INFO ]  Merged 1 segments, 214 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:34  [ pool-141-thread-1:195072 ] - [ INFO ]  Merging 1 files, 218 bytes from disk
2020-11-20 13:39:34  [ pool-141-thread-1:195072 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:34  [ pool-141-thread-1:195072 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:34  [ pool-141-thread-1:195072 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:39:34  [ pool-141-thread-1:195072 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:34  [ pool-141-thread-1:195173 ] - [ INFO ]  Task:attempt_local449646389_0046_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:34  [ pool-141-thread-1:195181 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:34  [ pool-141-thread-1:195181 ] - [ INFO ]  Task attempt_local449646389_0046_r_000000_0 is allowed to commit now
2020-11-20 13:39:34  [ pool-141-thread-1:195206 ] - [ INFO ]  Saved output of task 'attempt_local449646389_0046_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local449646389_0046_r_000000
2020-11-20 13:39:34  [ pool-141-thread-1:195206 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:34  [ pool-141-thread-1:195207 ] - [ INFO ]  Task 'attempt_local449646389_0046_r_000000_0' done.
2020-11-20 13:39:34  [ pool-141-thread-1:195207 ] - [ INFO ]  Finishing task: attempt_local449646389_0046_r_000000_0
2020-11-20 13:39:34  [ Thread-1232:195207 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:35  [ main:196030 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:35  [ main:196030 ] - [ INFO ]  Job job_local449646389_0046 completed successfully
2020-11-20 13:39:35  [ main:196031 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=60644
		FILE: Number of bytes written=28123222
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=49515534
		HDFS: Number of bytes written=18751
		HDFS: Number of read operations=1360
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=721
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1175
		Map output materialized bytes=218
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=218
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3059744768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:35  [ main:196057 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:35  [ main:196072 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:35  [ main:196077 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:35  [ main:196086 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:35  [ main:196128 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:35  [ main:196144 ] - [ INFO ]  Submitting tokens for job: job_local162194973_0047
2020-11-20 13:39:35  [ main:196180 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:35  [ main:196180 ] - [ INFO ]  Running job: job_local162194973_0047
2020-11-20 13:39:35  [ Thread-1259:196180 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:35  [ Thread-1259:196180 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:35  [ Thread-1259:196180 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:35  [ Thread-1259:196190 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196190 ] - [ INFO ]  Starting task: attempt_local162194973_0047_m_000000_0
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196190 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196190 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196190 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196191 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196198 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196198 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196198 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196198 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196198 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:35  [ LocalJobRunner Map Task Executor #0:196198 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:36  [ main:197180 ] - [ INFO ]  Job job_local162194973_0047 running in uber mode : false
2020-11-20 13:39:36  [ main:197181 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199361 ] - [ INFO ]  
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199361 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199361 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199361 ] - [ INFO ]  bufstart = 0; bufend = 1189; bufvoid = 104857600
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199361 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199363 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199364 ] - [ INFO ]  Task:attempt_local162194973_0047_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199373 ] - [ INFO ]  map
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199373 ] - [ INFO ]  Task 'attempt_local162194973_0047_m_000000_0' done.
2020-11-20 13:39:38  [ LocalJobRunner Map Task Executor #0:199373 ] - [ INFO ]  Finishing task: attempt_local162194973_0047_m_000000_0
2020-11-20 13:39:38  [ Thread-1259:199373 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:38  [ Thread-1259:199374 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:38  [ pool-144-thread-1:199374 ] - [ INFO ]  Starting task: attempt_local162194973_0047_r_000000_0
2020-11-20 13:39:38  [ pool-144-thread-1:199374 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:38  [ pool-144-thread-1:199375 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:38  [ pool-144-thread-1:199375 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:38  [ pool-144-thread-1:199375 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35dc4b59
2020-11-20 13:39:38  [ pool-144-thread-1:199375 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:38  [ EventFetcher for fetching Map Completion Events:199375 ] - [ INFO ]  attempt_local162194973_0047_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:38  [ localfetcher#47:199376 ] - [ INFO ]  localfetcher#47 about to shuffle output of map attempt_local162194973_0047_m_000000_0 decomp: 214 len: 218 to MEMORY
2020-11-20 13:39:38  [ localfetcher#47:199376 ] - [ INFO ]  Read 214 bytes from map-output for attempt_local162194973_0047_m_000000_0
2020-11-20 13:39:38  [ localfetcher#47:199376 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 214, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->214
2020-11-20 13:39:38  [ EventFetcher for fetching Map Completion Events:199377 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:38  [ pool-144-thread-1:199377 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:38  [ pool-144-thread-1:199377 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:38  [ pool-144-thread-1:199378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:38  [ pool-144-thread-1:199378 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:39:38  [ pool-144-thread-1:199378 ] - [ INFO ]  Merged 1 segments, 214 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:38  [ pool-144-thread-1:199378 ] - [ INFO ]  Merging 1 files, 218 bytes from disk
2020-11-20 13:39:38  [ pool-144-thread-1:199378 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:38  [ pool-144-thread-1:199378 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:38  [ pool-144-thread-1:199379 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:39:38  [ pool-144-thread-1:199379 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:38  [ pool-144-thread-1:199776 ] - [ INFO ]  Task:attempt_local162194973_0047_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:38  [ pool-144-thread-1:199784 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:38  [ pool-144-thread-1:199784 ] - [ INFO ]  Task attempt_local162194973_0047_r_000000_0 is allowed to commit now
2020-11-20 13:39:38  [ pool-144-thread-1:199808 ] - [ INFO ]  Saved output of task 'attempt_local162194973_0047_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local162194973_0047_r_000000
2020-11-20 13:39:38  [ pool-144-thread-1:199808 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:38  [ pool-144-thread-1:199808 ] - [ INFO ]  Task 'attempt_local162194973_0047_r_000000_0' done.
2020-11-20 13:39:38  [ pool-144-thread-1:199808 ] - [ INFO ]  Finishing task: attempt_local162194973_0047_r_000000_0
2020-11-20 13:39:38  [ Thread-1259:199809 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:39  [ main:200186 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:39  [ main:200186 ] - [ INFO ]  Job job_local162194973_0047 completed successfully
2020-11-20 13:39:39  [ main:200186 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61958
		FILE: Number of bytes written=28744468
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=50569056
		HDFS: Number of bytes written=19165
		HDFS: Number of read operations=1390
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=737
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1189
		Map output materialized bytes=218
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=218
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2984247296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:39  [ main:200214 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:39  [ main:200224 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:39  [ main:200228 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:39  [ main:200236 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:39  [ main:200273 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:39  [ main:200289 ] - [ INFO ]  Submitting tokens for job: job_local2129310840_0048
2020-11-20 13:39:39  [ main:200323 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:39  [ main:200323 ] - [ INFO ]  Running job: job_local2129310840_0048
2020-11-20 13:39:39  [ Thread-1286:200323 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:39  [ Thread-1286:200323 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:39  [ Thread-1286:200323 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:39  [ Thread-1286:200332 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200333 ] - [ INFO ]  Starting task: attempt_local2129310840_0048_m_000000_0
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200333 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200333 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200333 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200333 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200341 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200341 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200341 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200341 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200341 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:39  [ LocalJobRunner Map Task Executor #0:200341 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:40  [ main:201328 ] - [ INFO ]  Job job_local2129310840_0048 running in uber mode : false
2020-11-20 13:39:40  [ main:201328 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203295 ] - [ INFO ]  
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203295 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203295 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203295 ] - [ INFO ]  bufstart = 0; bufend = 1167; bufvoid = 104857600
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203295 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203296 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203297 ] - [ INFO ]  Task:attempt_local2129310840_0048_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203306 ] - [ INFO ]  map
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203306 ] - [ INFO ]  Task 'attempt_local2129310840_0048_m_000000_0' done.
2020-11-20 13:39:42  [ LocalJobRunner Map Task Executor #0:203306 ] - [ INFO ]  Finishing task: attempt_local2129310840_0048_m_000000_0
2020-11-20 13:39:42  [ Thread-1286:203306 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:42  [ Thread-1286:203306 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:42  [ pool-147-thread-1:203306 ] - [ INFO ]  Starting task: attempt_local2129310840_0048_r_000000_0
2020-11-20 13:39:42  [ pool-147-thread-1:203307 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:42  [ pool-147-thread-1:203307 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:42  [ pool-147-thread-1:203307 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:42  [ pool-147-thread-1:203307 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35c02d5d
2020-11-20 13:39:42  [ pool-147-thread-1:203308 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:42  [ EventFetcher for fetching Map Completion Events:203308 ] - [ INFO ]  attempt_local2129310840_0048_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:42  [ localfetcher#48:203309 ] - [ INFO ]  localfetcher#48 about to shuffle output of map attempt_local2129310840_0048_m_000000_0 decomp: 214 len: 218 to MEMORY
2020-11-20 13:39:42  [ localfetcher#48:203309 ] - [ INFO ]  Read 214 bytes from map-output for attempt_local2129310840_0048_m_000000_0
2020-11-20 13:39:42  [ localfetcher#48:203309 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 214, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->214
2020-11-20 13:39:42  [ EventFetcher for fetching Map Completion Events:203309 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:42  [ pool-147-thread-1:203310 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:42  [ pool-147-thread-1:203310 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:42  [ pool-147-thread-1:203310 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:42  [ pool-147-thread-1:203310 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:39:42  [ pool-147-thread-1:203311 ] - [ INFO ]  Merged 1 segments, 214 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:42  [ pool-147-thread-1:203311 ] - [ INFO ]  Merging 1 files, 218 bytes from disk
2020-11-20 13:39:42  [ pool-147-thread-1:203311 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:42  [ pool-147-thread-1:203311 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:42  [ pool-147-thread-1:203311 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 208 bytes
2020-11-20 13:39:42  [ pool-147-thread-1:203311 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:42  [ main:203331 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:39:42  [ pool-147-thread-1:203403 ] - [ INFO ]  Task:attempt_local2129310840_0048_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:42  [ pool-147-thread-1:203411 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:42  [ pool-147-thread-1:203411 ] - [ INFO ]  Task attempt_local2129310840_0048_r_000000_0 is allowed to commit now
2020-11-20 13:39:42  [ pool-147-thread-1:203434 ] - [ INFO ]  Saved output of task 'attempt_local2129310840_0048_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local2129310840_0048_r_000000
2020-11-20 13:39:42  [ pool-147-thread-1:203435 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:42  [ pool-147-thread-1:203435 ] - [ INFO ]  Task 'attempt_local2129310840_0048_r_000000_0' done.
2020-11-20 13:39:42  [ pool-147-thread-1:203435 ] - [ INFO ]  Finishing task: attempt_local2129310840_0048_r_000000_0
2020-11-20 13:39:42  [ Thread-1286:203435 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:43  [ main:204336 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:43  [ main:204336 ] - [ INFO ]  Job job_local2129310840_0048 completed successfully
2020-11-20 13:39:43  [ main:204337 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=63272
		FILE: Number of bytes written=29369010
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=51622578
		HDFS: Number of bytes written=19579
		HDFS: Number of read operations=1420
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=753
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1167
		Map output materialized bytes=218
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=218
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2984247296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:43  [ main:204363 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:43  [ main:204378 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:43  [ main:204382 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:43  [ main:204390 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:43  [ main:204430 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:43  [ main:204447 ] - [ INFO ]  Submitting tokens for job: job_local34514964_0049
2020-11-20 13:39:43  [ main:204481 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:43  [ main:204481 ] - [ INFO ]  Running job: job_local34514964_0049
2020-11-20 13:39:43  [ Thread-1313:204481 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:43  [ Thread-1313:204481 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:43  [ Thread-1313:204481 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:43  [ Thread-1313:204492 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204493 ] - [ INFO ]  Starting task: attempt_local34514964_0049_m_000000_0
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204493 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204493 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204493 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204494 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204503 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204503 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204503 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204503 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204503 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:43  [ LocalJobRunner Map Task Executor #0:204503 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:44  [ main:205481 ] - [ INFO ]  Job job_local34514964_0049 running in uber mode : false
2020-11-20 13:39:44  [ main:205481 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207557 ] - [ INFO ]  
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207557 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207557 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207557 ] - [ INFO ]  bufstart = 0; bufend = 1194; bufvoid = 104857600
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207557 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207559 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207560 ] - [ INFO ]  Task:attempt_local34514964_0049_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207570 ] - [ INFO ]  map
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207570 ] - [ INFO ]  Task 'attempt_local34514964_0049_m_000000_0' done.
2020-11-20 13:39:46  [ LocalJobRunner Map Task Executor #0:207570 ] - [ INFO ]  Finishing task: attempt_local34514964_0049_m_000000_0
2020-11-20 13:39:46  [ Thread-1313:207570 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:46  [ Thread-1313:207571 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:46  [ pool-150-thread-1:207571 ] - [ INFO ]  Starting task: attempt_local34514964_0049_r_000000_0
2020-11-20 13:39:46  [ pool-150-thread-1:207571 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:46  [ pool-150-thread-1:207571 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:46  [ pool-150-thread-1:207571 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:46  [ pool-150-thread-1:207571 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15e9730a
2020-11-20 13:39:46  [ pool-150-thread-1:207572 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:46  [ EventFetcher for fetching Map Completion Events:207572 ] - [ INFO ]  attempt_local34514964_0049_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:46  [ localfetcher#49:207573 ] - [ INFO ]  localfetcher#49 about to shuffle output of map attempt_local34514964_0049_m_000000_0 decomp: 215 len: 219 to MEMORY
2020-11-20 13:39:46  [ localfetcher#49:207573 ] - [ INFO ]  Read 215 bytes from map-output for attempt_local34514964_0049_m_000000_0
2020-11-20 13:39:46  [ localfetcher#49:207573 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->215
2020-11-20 13:39:46  [ EventFetcher for fetching Map Completion Events:207573 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:46  [ pool-150-thread-1:207573 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:46  [ pool-150-thread-1:207573 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:46  [ pool-150-thread-1:207574 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:46  [ pool-150-thread-1:207574 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:39:46  [ pool-150-thread-1:207575 ] - [ INFO ]  Merged 1 segments, 215 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:46  [ pool-150-thread-1:207575 ] - [ INFO ]  Merging 1 files, 219 bytes from disk
2020-11-20 13:39:46  [ pool-150-thread-1:207575 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:46  [ pool-150-thread-1:207575 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:46  [ pool-150-thread-1:207575 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 209 bytes
2020-11-20 13:39:46  [ pool-150-thread-1:207575 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:46  [ pool-150-thread-1:207695 ] - [ INFO ]  Task:attempt_local34514964_0049_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:46  [ pool-150-thread-1:207704 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:46  [ pool-150-thread-1:207704 ] - [ INFO ]  Task attempt_local34514964_0049_r_000000_0 is allowed to commit now
2020-11-20 13:39:46  [ pool-150-thread-1:207730 ] - [ INFO ]  Saved output of task 'attempt_local34514964_0049_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local34514964_0049_r_000000
2020-11-20 13:39:46  [ pool-150-thread-1:207731 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:46  [ pool-150-thread-1:207731 ] - [ INFO ]  Task 'attempt_local34514964_0049_r_000000_0' done.
2020-11-20 13:39:46  [ pool-150-thread-1:207731 ] - [ INFO ]  Finishing task: attempt_local34514964_0049_r_000000_0
2020-11-20 13:39:46  [ Thread-1313:207731 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:47  [ main:208489 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:47  [ main:208489 ] - [ INFO ]  Job job_local34514964_0049 completed successfully
2020-11-20 13:39:47  [ main:208491 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=64588
		FILE: Number of bytes written=29987535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=52676100
		HDFS: Number of bytes written=19994
		HDFS: Number of read operations=1450
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=769
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1194
		Map output materialized bytes=219
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=219
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2984247296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:47  [ main:208520 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:47  [ main:208535 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:47  [ main:208540 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:47  [ main:208549 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:47  [ main:208591 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:47  [ main:208608 ] - [ INFO ]  Submitting tokens for job: job_local984076584_0050
2020-11-20 13:39:47  [ main:208641 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:47  [ main:208641 ] - [ INFO ]  Running job: job_local984076584_0050
2020-11-20 13:39:47  [ Thread-1340:208642 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:47  [ Thread-1340:208642 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:47  [ Thread-1340:208642 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:47  [ Thread-1340:208652 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208652 ] - [ INFO ]  Starting task: attempt_local984076584_0050_m_000000_0
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208652 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208652 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208653 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208653 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208660 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208660 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208660 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208660 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208660 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:47  [ LocalJobRunner Map Task Executor #0:208661 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:48  [ main:209646 ] - [ INFO ]  Job job_local984076584_0050 running in uber mode : false
2020-11-20 13:39:48  [ main:209646 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211847 ] - [ INFO ]  
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211847 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211847 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211847 ] - [ INFO ]  bufstart = 0; bufend = 1183; bufvoid = 104857600
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211847 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211849 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211850 ] - [ INFO ]  Task:attempt_local984076584_0050_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211958 ] - [ INFO ]  map
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211959 ] - [ INFO ]  Task 'attempt_local984076584_0050_m_000000_0' done.
2020-11-20 13:39:50  [ LocalJobRunner Map Task Executor #0:211959 ] - [ INFO ]  Finishing task: attempt_local984076584_0050_m_000000_0
2020-11-20 13:39:50  [ Thread-1340:211959 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:50  [ Thread-1340:211959 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:50  [ pool-153-thread-1:211959 ] - [ INFO ]  Starting task: attempt_local984076584_0050_r_000000_0
2020-11-20 13:39:50  [ pool-153-thread-1:211959 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:50  [ pool-153-thread-1:211960 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:50  [ pool-153-thread-1:211960 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:50  [ pool-153-thread-1:211960 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19caa415
2020-11-20 13:39:50  [ pool-153-thread-1:211960 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:50  [ EventFetcher for fetching Map Completion Events:211960 ] - [ INFO ]  attempt_local984076584_0050_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:50  [ localfetcher#50:211961 ] - [ INFO ]  localfetcher#50 about to shuffle output of map attempt_local984076584_0050_m_000000_0 decomp: 217 len: 221 to MEMORY
2020-11-20 13:39:50  [ localfetcher#50:211961 ] - [ INFO ]  Read 217 bytes from map-output for attempt_local984076584_0050_m_000000_0
2020-11-20 13:39:50  [ localfetcher#50:211961 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 217, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->217
2020-11-20 13:39:50  [ EventFetcher for fetching Map Completion Events:211961 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:50  [ pool-153-thread-1:211961 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:50  [ pool-153-thread-1:211961 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:50  [ pool-153-thread-1:211962 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:50  [ pool-153-thread-1:211962 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:39:50  [ pool-153-thread-1:211962 ] - [ INFO ]  Merged 1 segments, 217 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:50  [ pool-153-thread-1:211963 ] - [ INFO ]  Merging 1 files, 221 bytes from disk
2020-11-20 13:39:50  [ pool-153-thread-1:211963 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:50  [ pool-153-thread-1:211963 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:50  [ pool-153-thread-1:211963 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 211 bytes
2020-11-20 13:39:50  [ pool-153-thread-1:211963 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:51  [ pool-153-thread-1:212323 ] - [ INFO ]  Task:attempt_local984076584_0050_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:51  [ pool-153-thread-1:212331 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:51  [ pool-153-thread-1:212331 ] - [ INFO ]  Task attempt_local984076584_0050_r_000000_0 is allowed to commit now
2020-11-20 13:39:51  [ pool-153-thread-1:212355 ] - [ INFO ]  Saved output of task 'attempt_local984076584_0050_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local984076584_0050_r_000000
2020-11-20 13:39:51  [ pool-153-thread-1:212356 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:51  [ pool-153-thread-1:212356 ] - [ INFO ]  Task 'attempt_local984076584_0050_r_000000_0' done.
2020-11-20 13:39:51  [ pool-153-thread-1:212356 ] - [ INFO ]  Finishing task: attempt_local984076584_0050_r_000000_0
2020-11-20 13:39:51  [ Thread-1340:212356 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:51  [ main:212654 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:51  [ main:212655 ] - [ INFO ]  Job job_local984076584_0050 completed successfully
2020-11-20 13:39:51  [ main:212656 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=65910
		FILE: Number of bytes written=30610559
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=53729622
		HDFS: Number of bytes written=20412
		HDFS: Number of read operations=1480
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=785
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1183
		Map output materialized bytes=221
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=221
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=2835349504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 13:39:51  [ main:212688 ] - [ INFO ]  Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2020-11-20 13:39:51  [ main:212703 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 13:39:51  [ main:212708 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 13:39:51  [ main:212715 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 13:39:51  [ main:212755 ] - [ INFO ]  number of splits:1
2020-11-20 13:39:51  [ main:212771 ] - [ INFO ]  Submitting tokens for job: job_local1285605621_0051
2020-11-20 13:39:51  [ main:212805 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 13:39:51  [ main:212805 ] - [ INFO ]  Running job: job_local1285605621_0051
2020-11-20 13:39:51  [ Thread-1367:212805 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 13:39:51  [ Thread-1367:212805 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:51  [ Thread-1367:212805 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 13:39:51  [ Thread-1367:212815 ] - [ INFO ]  Waiting for map tasks
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212815 ] - [ INFO ]  Starting task: attempt_local1285605621_0051_m_000000_0
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212815 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212815 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212815 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212816 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212823 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212823 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212824 ] - [ INFO ]  soft limit at 83886080
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212824 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212824 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 13:39:51  [ LocalJobRunner Map Task Executor #0:212824 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 13:39:52  [ main:213808 ] - [ INFO ]  Job job_local1285605621_0051 running in uber mode : false
2020-11-20 13:39:52  [ main:213808 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215787 ] - [ INFO ]  
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215787 ] - [ INFO ]  Starting flush of map output
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215787 ] - [ INFO ]  Spilling map output
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215787 ] - [ INFO ]  bufstart = 0; bufend = 1185; bufvoid = 104857600
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215787 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215789 ] - [ INFO ]  Finished spill 0
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215789 ] - [ INFO ]  Task:attempt_local1285605621_0051_m_000000_0 is done. And is in the process of committing
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215798 ] - [ INFO ]  map
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215798 ] - [ INFO ]  Task 'attempt_local1285605621_0051_m_000000_0' done.
2020-11-20 13:39:54  [ LocalJobRunner Map Task Executor #0:215798 ] - [ INFO ]  Finishing task: attempt_local1285605621_0051_m_000000_0
2020-11-20 13:39:54  [ Thread-1367:215798 ] - [ INFO ]  map task executor complete.
2020-11-20 13:39:54  [ Thread-1367:215798 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 13:39:54  [ pool-156-thread-1:215798 ] - [ INFO ]  Starting task: attempt_local1285605621_0051_r_000000_0
2020-11-20 13:39:54  [ pool-156-thread-1:215799 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 13:39:54  [ pool-156-thread-1:215799 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 13:39:54  [ pool-156-thread-1:215799 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 13:39:54  [ pool-156-thread-1:215799 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@144b912d
2020-11-20 13:39:54  [ pool-156-thread-1:215800 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 13:39:54  [ EventFetcher for fetching Map Completion Events:215800 ] - [ INFO ]  attempt_local1285605621_0051_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 13:39:54  [ localfetcher#51:215801 ] - [ INFO ]  localfetcher#51 about to shuffle output of map attempt_local1285605621_0051_m_000000_0 decomp: 204 len: 208 to MEMORY
2020-11-20 13:39:54  [ localfetcher#51:215801 ] - [ INFO ]  Read 204 bytes from map-output for attempt_local1285605621_0051_m_000000_0
2020-11-20 13:39:54  [ localfetcher#51:215801 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 204, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->204
2020-11-20 13:39:54  [ EventFetcher for fetching Map Completion Events:215801 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 13:39:54  [ pool-156-thread-1:215801 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:54  [ pool-156-thread-1:215801 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 13:39:54  [ pool-156-thread-1:215802 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:54  [ pool-156-thread-1:215802 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 198 bytes
2020-11-20 13:39:54  [ pool-156-thread-1:215802 ] - [ INFO ]  Merged 1 segments, 204 bytes to disk to satisfy reduce memory limit
2020-11-20 13:39:54  [ pool-156-thread-1:215802 ] - [ INFO ]  Merging 1 files, 208 bytes from disk
2020-11-20 13:39:54  [ pool-156-thread-1:215802 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 13:39:54  [ pool-156-thread-1:215802 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 13:39:54  [ pool-156-thread-1:215803 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 198 bytes
2020-11-20 13:39:54  [ pool-156-thread-1:215803 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:54  [ main:215814 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 13:39:54  [ pool-156-thread-1:215905 ] - [ INFO ]  Task:attempt_local1285605621_0051_r_000000_0 is done. And is in the process of committing
2020-11-20 13:39:54  [ pool-156-thread-1:215914 ] - [ INFO ]  1 / 1 copied.
2020-11-20 13:39:54  [ pool-156-thread-1:215914 ] - [ INFO ]  Task attempt_local1285605621_0051_r_000000_0 is allowed to commit now
2020-11-20 13:39:54  [ pool-156-thread-1:215939 ] - [ INFO ]  Saved output of task 'attempt_local1285605621_0051_r_000000_0' to hdfs://master:9000/tmp/path/output/_temporary/0/task_local1285605621_0051_r_000000
2020-11-20 13:39:54  [ pool-156-thread-1:215939 ] - [ INFO ]  reduce > reduce
2020-11-20 13:39:54  [ pool-156-thread-1:215939 ] - [ INFO ]  Task 'attempt_local1285605621_0051_r_000000_0' done.
2020-11-20 13:39:54  [ pool-156-thread-1:215939 ] - [ INFO ]  Finishing task: attempt_local1285605621_0051_r_000000_0
2020-11-20 13:39:54  [ Thread-1367:215939 ] - [ INFO ]  reduce task executor complete.
2020-11-20 13:39:55  [ main:216819 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 13:39:55  [ main:216819 ] - [ INFO ]  Job job_local1285605621_0051 completed successfully
2020-11-20 13:39:55  [ main:216820 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=67210
		FILE: Number of bytes written=31237938
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54783144
		HDFS: Number of bytes written=20819
		HDFS: Number of read operations=1510
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=801
	Map-Reduce Framework
		Map input records=51
		Map output records=50
		Map output bytes=1185
		Map output materialized bytes=208
		Input split bytes=135
		Combine input records=50
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=208
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2835349504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=0
2020-11-20 14:26:04  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 14:26:05  [ main:879 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 14:26:05  [ main:880 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 14:26:05  [ main:1067 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 14:26:05  [ main:1071 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 14:26:05  [ main:1084 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 14:26:05  [ main:1158 ] - [ INFO ]  number of splits:1
2020-11-20 14:26:05  [ main:1214 ] - [ INFO ]  Submitting tokens for job: job_local1464016904_0001
2020-11-20 14:26:05  [ main:1294 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 14:26:05  [ main:1295 ] - [ INFO ]  Running job: job_local1464016904_0001
2020-11-20 14:26:05  [ Thread-18:1295 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 14:26:05  [ Thread-18:1298 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:26:05  [ Thread-18:1299 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 14:26:05  [ Thread-18:1346 ] - [ INFO ]  Waiting for map tasks
2020-11-20 14:26:05  [ LocalJobRunner Map Task Executor #0:1346 ] - [ INFO ]  Starting task: attempt_local1464016904_0001_m_000000_0
2020-11-20 14:26:05  [ LocalJobRunner Map Task Executor #0:1359 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:26:05  [ LocalJobRunner Map Task Executor #0:1363 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:26:05  [ LocalJobRunner Map Task Executor #0:1363 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:26:05  [ LocalJobRunner Map Task Executor #0:1365 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+526761
2020-11-20 14:26:06  [ LocalJobRunner Map Task Executor #0:1409 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 14:26:06  [ LocalJobRunner Map Task Executor #0:1409 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 14:26:06  [ LocalJobRunner Map Task Executor #0:1409 ] - [ INFO ]  soft limit at 83886080
2020-11-20 14:26:06  [ LocalJobRunner Map Task Executor #0:1409 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 14:26:06  [ LocalJobRunner Map Task Executor #0:1409 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 14:26:06  [ LocalJobRunner Map Task Executor #0:1411 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 14:26:06  [ main:2297 ] - [ INFO ]  Job job_local1464016904_0001 running in uber mode : false
2020-11-20 14:26:06  [ main:2298 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8598 ] - [ INFO ]  
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8598 ] - [ INFO ]  Starting flush of map output
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8598 ] - [ INFO ]  Spilling map output
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8598 ] - [ INFO ]  bufstart = 0; bufend = 22244; bufvoid = 104857600
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8598 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214196(104856784); length = 201/6553600
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8624 ] - [ INFO ]  Finished spill 0
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8627 ] - [ INFO ]  Task:attempt_local1464016904_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8639 ] - [ INFO ]  map
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8639 ] - [ INFO ]  Task 'attempt_local1464016904_0001_m_000000_0' done.
2020-11-20 14:26:13  [ LocalJobRunner Map Task Executor #0:8639 ] - [ INFO ]  Finishing task: attempt_local1464016904_0001_m_000000_0
2020-11-20 14:26:13  [ Thread-18:8639 ] - [ INFO ]  map task executor complete.
2020-11-20 14:26:13  [ Thread-18:8641 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 14:26:13  [ pool-6-thread-1:8641 ] - [ INFO ]  Starting task: attempt_local1464016904_0001_r_000000_0
2020-11-20 14:26:13  [ pool-6-thread-1:8645 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:26:13  [ pool-6-thread-1:8646 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:26:13  [ pool-6-thread-1:8646 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:26:13  [ pool-6-thread-1:8648 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5aeb7f7d
2020-11-20 14:26:13  [ pool-6-thread-1:8655 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 14:26:13  [ EventFetcher for fetching Map Completion Events:8657 ] - [ INFO ]  attempt_local1464016904_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 14:26:13  [ localfetcher#1:8678 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1464016904_0001_m_000000_0 decomp: 4648 len: 4652 to MEMORY
2020-11-20 14:26:13  [ localfetcher#1:8681 ] - [ INFO ]  Read 4648 bytes from map-output for attempt_local1464016904_0001_m_000000_0
2020-11-20 14:26:13  [ localfetcher#1:8682 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 4648, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4648
2020-11-20 14:26:13  [ EventFetcher for fetching Map Completion Events:8683 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 14:26:13  [ pool-6-thread-1:8684 ] - [ INFO ]  1 / 1 copied.
2020-11-20 14:26:13  [ pool-6-thread-1:8684 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 14:26:13  [ pool-6-thread-1:8688 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 14:26:13  [ pool-6-thread-1:8689 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 4644 bytes
2020-11-20 14:26:13  [ pool-6-thread-1:8690 ] - [ INFO ]  Merged 1 segments, 4648 bytes to disk to satisfy reduce memory limit
2020-11-20 14:26:13  [ pool-6-thread-1:8690 ] - [ INFO ]  Merging 1 files, 4652 bytes from disk
2020-11-20 14:26:13  [ pool-6-thread-1:8691 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 14:26:13  [ pool-6-thread-1:8691 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 14:26:13  [ pool-6-thread-1:8691 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 4644 bytes
2020-11-20 14:26:13  [ pool-6-thread-1:8692 ] - [ INFO ]  1 / 1 copied.
2020-11-20 14:26:13  [ pool-6-thread-1:8711 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 14:26:13  [ pool-6-thread-1:8842 ] - [ INFO ]  Task:attempt_local1464016904_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 14:26:13  [ pool-6-thread-1:8849 ] - [ INFO ]  1 / 1 copied.
2020-11-20 14:26:13  [ pool-6-thread-1:8850 ] - [ INFO ]  Task attempt_local1464016904_0001_r_000000_0 is allowed to commit now
2020-11-20 14:26:13  [ pool-6-thread-1:8876 ] - [ INFO ]  Saved output of task 'attempt_local1464016904_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/data/sim_result/_temporary/0/task_local1464016904_0001_r_000000
2020-11-20 14:26:13  [ pool-6-thread-1:8876 ] - [ INFO ]  reduce > reduce
2020-11-20 14:26:13  [ pool-6-thread-1:8876 ] - [ INFO ]  Task 'attempt_local1464016904_0001_r_000000_0' done.
2020-11-20 14:26:13  [ pool-6-thread-1:8877 ] - [ INFO ]  Finishing task: attempt_local1464016904_0001_r_000000_0
2020-11-20 14:26:13  [ Thread-18:8877 ] - [ INFO ]  reduce task executor complete.
2020-11-20 14:26:13  [ main:9318 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 14:26:13  [ main:9319 ] - [ INFO ]  Job job_local1464016904_0001 completed successfully
2020-11-20 14:26:13  [ main:9328 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=9714
		FILE: Number of bytes written=583838
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2107044
		HDFS: Number of bytes written=4544
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=51
		Map output records=51
		Map output bytes=22244
		Map output materialized bytes=4652
		Input split bytes=135
		Combine input records=51
		Combine output records=51
		Reduce input groups=51
		Reduce shuffle bytes=4652
		Reduce input records=51
		Reduce output records=51
		Spilled Records=102
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=1171259392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=526761
	File Output Format Counters 
		Bytes Written=4544
2020-11-20 14:27:29  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 14:27:30  [ main:648 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 14:27:30  [ main:648 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 14:27:30  [ main:833 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 14:27:30  [ main:838 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 14:27:30  [ main:852 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 14:27:30  [ main:930 ] - [ INFO ]  number of splits:1
2020-11-20 14:27:30  [ main:994 ] - [ INFO ]  Submitting tokens for job: job_local441727536_0001
2020-11-20 14:27:30  [ main:1085 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 14:27:30  [ main:1085 ] - [ INFO ]  Running job: job_local441727536_0001
2020-11-20 14:27:30  [ Thread-18:1086 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 14:27:30  [ Thread-18:1089 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:27:30  [ Thread-18:1090 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 14:27:30  [ Thread-18:1127 ] - [ INFO ]  Waiting for map tasks
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1127 ] - [ INFO ]  Starting task: attempt_local441727536_0001_m_000000_0
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1142 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1146 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1146 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1148 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/ua.base:0+1792501
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1198 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1198 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1198 ] - [ INFO ]  soft limit at 83886080
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1198 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1198 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 14:27:30  [ LocalJobRunner Map Task Executor #0:1200 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 14:27:31  [ main:2091 ] - [ INFO ]  Job job_local441727536_0001 running in uber mode : false
2020-11-20 14:27:31  [ main:2093 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 14:27:36  [ communication thread:7152 ] - [ INFO ]  map > map
2020-11-20 14:27:37  [ main:8115 ] - [ INFO ]   map 33% reduce 0%
2020-11-20 14:27:39  [ communication thread:10155 ] - [ INFO ]  map > map
2020-11-20 14:27:40  [ main:11128 ] - [ INFO ]   map 49% reduce 0%
2020-11-20 14:27:42  [ communication thread:13159 ] - [ INFO ]  map > map
2020-11-20 14:27:43  [ LocalJobRunner Map Task Executor #0:13733 ] - [ INFO ]  map > map
2020-11-20 14:27:43  [ LocalJobRunner Map Task Executor #0:13735 ] - [ INFO ]  Starting flush of map output
2020-11-20 14:27:43  [ LocalJobRunner Map Task Executor #0:13735 ] - [ INFO ]  Spilling map output
2020-11-20 14:27:43  [ LocalJobRunner Map Task Executor #0:13735 ] - [ INFO ]  bufstart = 0; bufend = 897963; bufvoid = 104857600
2020-11-20 14:27:43  [ LocalJobRunner Map Task Executor #0:13735 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 25852120(103408480); length = 362277/6553600
2020-11-20 14:27:43  [ main:14140 ] - [ INFO ]   map 63% reduce 0%
2020-11-20 14:27:44  [ LocalJobRunner Map Task Executor #0:15341 ] - [ INFO ]  Finished spill 0
2020-11-20 14:27:44  [ LocalJobRunner Map Task Executor #0:15345 ] - [ INFO ]  Task:attempt_local441727536_0001_m_000000_0 is done. And is in the process of committing
2020-11-20 14:27:44  [ LocalJobRunner Map Task Executor #0:15373 ] - [ INFO ]  map
2020-11-20 14:27:44  [ LocalJobRunner Map Task Executor #0:15373 ] - [ INFO ]  Task 'attempt_local441727536_0001_m_000000_0' done.
2020-11-20 14:27:44  [ LocalJobRunner Map Task Executor #0:15373 ] - [ INFO ]  Finishing task: attempt_local441727536_0001_m_000000_0
2020-11-20 14:27:44  [ Thread-18:15373 ] - [ INFO ]  map task executor complete.
2020-11-20 14:27:44  [ Thread-18:15375 ] - [ INFO ]  Waiting for reduce tasks
2020-11-20 14:27:44  [ pool-6-thread-1:15375 ] - [ INFO ]  Starting task: attempt_local441727536_0001_r_000000_0
2020-11-20 14:27:44  [ pool-6-thread-1:15380 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:27:44  [ pool-6-thread-1:15381 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:27:44  [ pool-6-thread-1:15381 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:27:44  [ pool-6-thread-1:15383 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6cf37b3e
2020-11-20 14:27:44  [ pool-6-thread-1:15393 ] - [ INFO ]  MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-11-20 14:27:44  [ EventFetcher for fetching Map Completion Events:15395 ] - [ INFO ]  attempt_local441727536_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-11-20 14:27:44  [ localfetcher#1:15421 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local441727536_0001_m_000000_0 decomp: 30748992 len: 30748996 to MEMORY
2020-11-20 14:27:44  [ localfetcher#1:15447 ] - [ INFO ]  Read 30748992 bytes from map-output for attempt_local441727536_0001_m_000000_0
2020-11-20 14:27:44  [ localfetcher#1:15448 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 30748992, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30748992
2020-11-20 14:27:44  [ EventFetcher for fetching Map Completion Events:15449 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2020-11-20 14:27:44  [ pool-6-thread-1:15450 ] - [ INFO ]  1 / 1 copied.
2020-11-20 14:27:44  [ pool-6-thread-1:15450 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-11-20 14:27:44  [ pool-6-thread-1:15454 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 14:27:44  [ pool-6-thread-1:15454 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-20 14:27:44  [ pool-6-thread-1:15484 ] - [ INFO ]  Merged 1 segments, 30748992 bytes to disk to satisfy reduce memory limit
2020-11-20 14:27:44  [ pool-6-thread-1:15484 ] - [ INFO ]  Merging 1 files, 30748996 bytes from disk
2020-11-20 14:27:44  [ pool-6-thread-1:15484 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2020-11-20 14:27:44  [ pool-6-thread-1:15484 ] - [ INFO ]  Merging 1 sorted segments
2020-11-20 14:27:44  [ pool-6-thread-1:15485 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 30748984 bytes
2020-11-20 14:27:44  [ pool-6-thread-1:15485 ] - [ INFO ]  1 / 1 copied.
2020-11-20 14:27:44  [ pool-6-thread-1:15505 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-11-20 14:27:45  [ main:16142 ] - [ INFO ]   map 100% reduce 0%
2020-11-20 14:27:50  [ communication thread:21384 ] - [ INFO ]  reduce > reduce
2020-11-20 14:27:51  [ main:22160 ] - [ INFO ]   map 100% reduce 100%
2020-11-20 14:27:52  [ pool-6-thread-1:22584 ] - [ INFO ]  Task:attempt_local441727536_0001_r_000000_0 is done. And is in the process of committing
2020-11-20 14:27:52  [ pool-6-thread-1:22592 ] - [ INFO ]  reduce > reduce
2020-11-20 14:27:52  [ pool-6-thread-1:22592 ] - [ INFO ]  Task attempt_local441727536_0001_r_000000_0 is allowed to commit now
2020-11-20 14:27:52  [ pool-6-thread-1:22616 ] - [ INFO ]  Saved output of task 'attempt_local441727536_0001_r_000000_0' to hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/_temporary/0/task_local441727536_0001_r_000000
2020-11-20 14:27:52  [ pool-6-thread-1:22617 ] - [ INFO ]  reduce > reduce
2020-11-20 14:27:52  [ pool-6-thread-1:22617 ] - [ INFO ]  Task 'attempt_local441727536_0001_r_000000_0' done.
2020-11-20 14:27:52  [ pool-6-thread-1:22617 ] - [ INFO ]  Finishing task: attempt_local441727536_0001_r_000000_0
2020-11-20 14:27:52  [ Thread-18:22617 ] - [ INFO ]  reduce task executor complete.
2020-11-20 14:27:52  [ main:23165 ] - [ INFO ]  Job job_local441727536_0001 completed successfully
2020-11-20 14:27:52  [ main:23176 ] - [ INFO ]  Counters: 35
	File System Counters
		FILE: Number of bytes read=61498356
		FILE: Number of bytes written=92814084
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3585002
		HDFS: Number of bytes written=30743224
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=90570
		Map output records=90570
		Map output bytes=897963
		Map output materialized bytes=30748996
		Input split bytes=112
		Combine input records=90570
		Combine output records=943
		Reduce input groups=943
		Reduce shuffle bytes=30748996
		Reduce input records=943
		Reduce output records=943
		Spilled Records=1886
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=983564288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1792501
	File Output Format Counters 
		Bytes Written=30743224
2020-11-20 14:28:07  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 14:28:07  [ main:611 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 14:28:07  [ main:612 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 14:28:07  [ main:820 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 14:28:07  [ main:827 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 14:28:07  [ main:843 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 14:28:08  [ main:917 ] - [ INFO ]  number of splits:1
2020-11-20 14:28:08  [ main:980 ] - [ INFO ]  Submitting tokens for job: job_local917469263_0001
2020-11-20 14:28:08  [ main:1077 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 14:28:08  [ main:1077 ] - [ INFO ]  Running job: job_local917469263_0001
2020-11-20 14:28:08  [ Thread-18:1078 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 14:28:08  [ Thread-18:1081 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:28:08  [ Thread-18:1082 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 14:28:08  [ Thread-18:1125 ] - [ INFO ]  Waiting for map tasks
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1125 ] - [ INFO ]  Starting task: attempt_local917469263_0001_m_000000_0
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1143 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1147 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1147 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1150 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+30743224
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  soft limit at 83886080
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 14:28:08  [ LocalJobRunner Map Task Executor #0:1215 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 14:28:09  [ main:2079 ] - [ INFO ]  Job job_local917469263_0001 running in uber mode : false
2020-11-20 14:28:09  [ main:2081 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 14:33:15  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 14:33:16  [ main:1042 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 14:33:16  [ main:1042 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 14:33:16  [ main:1085 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 14:33:16  [ main:1092 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 14:33:16  [ main:1111 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 14:33:16  [ main:1216 ] - [ INFO ]  number of splits:1
2020-11-20 14:33:16  [ main:1299 ] - [ INFO ]  Submitting tokens for job: job_local2023805324_0001
2020-11-20 14:33:16  [ main:1426 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 14:33:16  [ main:1427 ] - [ INFO ]  Running job: job_local2023805324_0001
2020-11-20 14:33:16  [ Thread-35:1428 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 14:33:16  [ Thread-35:1433 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:33:16  [ Thread-35:1434 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 14:33:16  [ Thread-35:1479 ] - [ INFO ]  Waiting for map tasks
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1480 ] - [ INFO ]  Starting task: attempt_local2023805324_0001_m_000000_0
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1504 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1509 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1510 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1519 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+30743224
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1554 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1554 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1554 ] - [ INFO ]  soft limit at 83886080
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1554 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1554 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 14:33:16  [ LocalJobRunner Map Task Executor #0:1558 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 14:33:26  [ LocalJobRunner Map Task Executor #0:11105 ] - [ INFO ]  Starting flush of map output
2020-11-20 14:33:26  [ main:11105 ] - [ INFO ]  Job job_local2023805324_0001 running in uber mode : false
2020-11-20 14:33:26  [ main:11107 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 14:33:26  [ Thread-35:11114 ] - [ INFO ]  map task executor complete.
2020-11-20 14:33:26  [ Thread-35:11210 ] - [ WARN ]  job_local2023805324_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:53)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 14:33:27  [ main:12114 ] - [ INFO ]  Job job_local2023805324_0001 failed with state FAILED due to: NA
2020-11-20 14:33:27  [ main:12120 ] - [ INFO ]  Counters: 0
2020-11-20 14:34:12  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 14:34:13  [ main:706 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 14:34:13  [ main:707 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 14:34:13  [ main:913 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 14:34:13  [ main:918 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 14:34:13  [ main:930 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 14:34:13  [ main:1009 ] - [ INFO ]  number of splits:1
2020-11-20 14:34:13  [ main:1074 ] - [ INFO ]  Submitting tokens for job: job_local1430341861_0001
2020-11-20 14:34:13  [ main:1165 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 14:34:13  [ main:1165 ] - [ INFO ]  Running job: job_local1430341861_0001
2020-11-20 14:34:13  [ Thread-18:1166 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 14:34:13  [ Thread-18:1170 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:34:13  [ Thread-18:1172 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 14:34:13  [ Thread-18:1211 ] - [ INFO ]  Waiting for map tasks
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1212 ] - [ INFO ]  Starting task: attempt_local1430341861_0001_m_000000_0
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1230 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1235 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1244 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+30743224
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1298 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1298 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1298 ] - [ INFO ]  soft limit at 83886080
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1298 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1298 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 14:34:13  [ LocalJobRunner Map Task Executor #0:1301 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 14:34:33  [ main:21454 ] - [ INFO ]  Job job_local1430341861_0001 running in uber mode : false
2020-11-20 14:34:33  [ LocalJobRunner Map Task Executor #0:21454 ] - [ INFO ]  Starting flush of map output
2020-11-20 14:34:33  [ main:21456 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 14:34:33  [ Thread-18:21462 ] - [ INFO ]  map task executor complete.
2020-11-20 14:34:34  [ Thread-18:21565 ] - [ WARN ]  job_local1430341861_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.satan.hadoop.cf.userCF.SimilarUserMapReduceJob$SimilarUserMapper.setup(SimilarUserMapReduceJob.java:53)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-11-20 14:34:34  [ main:22463 ] - [ INFO ]  Job job_local1430341861_0001 failed with state FAILED due to: NA
2020-11-20 14:34:34  [ main:22469 ] - [ INFO ]  Counters: 0
2020-11-20 14:35:05  [ main:0 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-11-20 14:35:06  [ main:664 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2020-11-20 14:35:06  [ main:665 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2020-11-20 14:35:06  [ main:890 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-11-20 14:35:06  [ main:895 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-11-20 14:35:06  [ main:947 ] - [ INFO ]  Total input paths to process : 1
2020-11-20 14:35:07  [ main:1028 ] - [ INFO ]  number of splits:1
2020-11-20 14:35:07  [ main:1097 ] - [ INFO ]  Submitting tokens for job: job_local1516999836_0001
2020-11-20 14:35:07  [ main:1201 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2020-11-20 14:35:07  [ main:1202 ] - [ INFO ]  Running job: job_local1516999836_0001
2020-11-20 14:35:07  [ Thread-18:1202 ] - [ INFO ]  OutputCommitter set in config null
2020-11-20 14:35:07  [ Thread-18:1206 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:35:07  [ Thread-18:1208 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-11-20 14:35:07  [ Thread-18:1251 ] - [ INFO ]  Waiting for map tasks
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1252 ] - [ INFO ]  Starting task: attempt_local1516999836_0001_m_000000_0
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1275 ] - [ INFO ]  File Output Committer Algorithm version is 1
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1280 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1280 ] - [ INFO ]   Using ResourceCalculatorProcessTree : null
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1289 ] - [ INFO ]  Processing split: hdfs://master:9000/user/root/mr/data/cf/data/score_matrix/part-r-00000:0+30743224
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1344 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1344 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1344 ] - [ INFO ]  soft limit at 83886080
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1344 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1344 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2020-11-20 14:35:07  [ LocalJobRunner Map Task Executor #0:1347 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-11-20 14:35:10  [ main:4992 ] - [ INFO ]  Job job_local1516999836_0001 running in uber mode : false
2020-11-20 14:35:18  [ main:12151 ] - [ INFO ]   map 0% reduce 0%
2020-11-20 14:41:13  [ communication thread:367753 ] - [ INFO ]  map > map
2020-11-20 14:41:21  [ communication thread:375273 ] - [ INFO ]  map > map
2020-11-20 14:41:24  [ communication thread:378278 ] - [ INFO ]  map > map
2020-11-20 14:41:27  [ communication thread:381282 ] - [ INFO ]  map > map
2020-11-20 14:41:30  [ communication thread:384287 ] - [ INFO ]  map > map
2020-11-20 14:41:33  [ communication thread:387291 ] - [ INFO ]  map > map
2020-11-20 14:41:36  [ communication thread:390296 ] - [ INFO ]  map > map
2020-11-20 14:41:36  [ main:390316 ] - [ INFO ]   map 1% reduce 0%
2020-11-20 14:41:39  [ communication thread:393302 ] - [ INFO ]  map > map
2020-11-20 14:41:42  [ communication thread:396306 ] - [ INFO ]  map > map
2020-11-20 14:41:45  [ communication thread:399307 ] - [ INFO ]  map > map
2020-11-20 14:41:48  [ communication thread:402311 ] - [ INFO ]  map > map
2020-11-20 14:41:51  [ communication thread:405314 ] - [ INFO ]  map > map
2020-11-20 14:41:54  [ communication thread:408319 ] - [ INFO ]  map > map
2020-11-20 14:41:57  [ communication thread:411324 ] - [ INFO ]  map > map
2020-11-20 14:42:00  [ communication thread:414328 ] - [ INFO ]  map > map
2020-11-20 14:42:03  [ communication thread:417330 ] - [ INFO ]  map > map
2020-11-20 14:42:03  [ main:417390 ] - [ INFO ]   map 2% reduce 0%
2020-11-20 14:42:06  [ communication thread:420335 ] - [ INFO ]  map > map
2020-11-20 14:42:09  [ communication thread:423336 ] - [ INFO ]  map > map
2020-11-20 14:42:12  [ communication thread:426340 ] - [ INFO ]  map > map
2020-11-20 14:42:15  [ communication thread:429342 ] - [ INFO ]  map > map
2020-11-20 14:42:18  [ communication thread:432345 ] - [ INFO ]  map > map
2020-11-20 14:42:21  [ communication thread:435350 ] - [ INFO ]  map > map
2020-11-20 14:42:24  [ communication thread:438355 ] - [ INFO ]  map > map
2020-11-20 14:42:24  [ main:438435 ] - [ INFO ]   map 3% reduce 0%
2020-11-20 14:42:27  [ communication thread:441360 ] - [ INFO ]  map > map
2020-11-20 14:42:30  [ communication thread:444361 ] - [ INFO ]  map > map
2020-11-20 14:42:33  [ communication thread:447365 ] - [ INFO ]  map > map
2020-11-20 14:42:36  [ communication thread:450368 ] - [ INFO ]  map > map
2020-11-20 14:42:39  [ communication thread:453373 ] - [ INFO ]  map > map
2020-11-20 14:42:42  [ communication thread:456375 ] - [ INFO ]  map > map
2020-11-20 14:42:45  [ communication thread:459377 ] - [ INFO ]  map > map
2020-11-20 14:42:45  [ main:459483 ] - [ INFO ]   map 4% reduce 0%
2020-11-20 14:42:48  [ communication thread:462381 ] - [ INFO ]  map > map
2020-11-20 14:42:51  [ communication thread:465381 ] - [ INFO ]  map > map
2020-11-20 14:42:54  [ communication thread:468385 ] - [ INFO ]  map > map
2020-11-20 14:42:57  [ communication thread:471388 ] - [ INFO ]  map > map
2020-11-20 14:43:00  [ communication thread:474392 ] - [ INFO ]  map > map
2020-11-20 14:43:00  [ main:474515 ] - [ INFO ]   map 5% reduce 0%
2020-11-20 14:43:03  [ communication thread:477396 ] - [ INFO ]  map > map
2020-11-20 14:43:06  [ communication thread:480399 ] - [ INFO ]  map > map
2020-11-20 14:43:09  [ communication thread:483400 ] - [ INFO ]  map > map
2020-11-20 14:43:12  [ communication thread:486405 ] - [ INFO ]  map > map
2020-11-20 14:43:15  [ communication thread:489409 ] - [ INFO ]  map > map
2020-11-20 14:43:18  [ communication thread:492410 ] - [ INFO ]  map > map
2020-11-20 14:43:18  [ main:492561 ] - [ INFO ]   map 6% reduce 0%
2020-11-20 14:43:21  [ communication thread:495414 ] - [ INFO ]  map > map
2020-11-20 14:43:24  [ communication thread:498416 ] - [ INFO ]  map > map
2020-11-20 14:43:27  [ communication thread:501417 ] - [ INFO ]  map > map
2020-11-20 14:43:30  [ communication thread:504417 ] - [ INFO ]  map > map
2020-11-20 14:43:33  [ communication thread:507423 ] - [ INFO ]  map > map
2020-11-20 14:43:36  [ communication thread:510427 ] - [ INFO ]  map > map
2020-11-20 14:43:36  [ main:510615 ] - [ INFO ]   map 7% reduce 0%
2020-11-20 14:43:39  [ communication thread:513429 ] - [ INFO ]  map > map
2020-11-20 14:43:42  [ communication thread:516431 ] - [ INFO ]  map > map
2020-11-20 14:43:45  [ communication thread:519434 ] - [ INFO ]  map > map
2020-11-20 14:43:48  [ communication thread:522437 ] - [ INFO ]  map > map
2020-11-20 14:43:51  [ communication thread:525443 ] - [ INFO ]  map > map
2020-11-20 14:43:51  [ main:525653 ] - [ INFO ]   map 8% reduce 0%
2020-11-20 14:43:54  [ communication thread:528448 ] - [ INFO ]  map > map
